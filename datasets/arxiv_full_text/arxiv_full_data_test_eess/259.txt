{"title": "Realistic Image Degradation with Measured PSF", "tag": "eess", "abstract": " Training autonomous vehicles requires lots of driving sequences in all situations\\cite{zhao2016}. Typically a simulation environment (software-in-the-loop, SiL) accompanies real-world test drives to systematically vary environmental parameters. A missing piece in the optical model of those SiL simulations is the sharpness, given in linear system theory by the point-spread function (PSF) of the optical system. We present a novel numerical model for the PSF of an optical system that can efficiently model both experimental measurements and lens design simulations of the PSF. The numerical basis for this model is a non-linear regression of the PSF with an artificial neural network (ANN). The novelty lies in the portability and the parameterization of this model, which allows to apply this model in basically any conceivable optical simulation scenario, e.g. inserting a measured lens into a computer game to train autonomous vehicles. We present a lens measurement series, yielding a numerical function for the PSF that depends only on the parameters defocus, field and azimuth. By convolving existing images and videos with this PSF model we apply the measured lens as a transfer function, therefore generating an image as if it were seen with the measured lens itself. Applications of this method are in any optical scenario, but we focus on the context of autonomous driving, where quality of the detection algorithms depends directly on the optical quality of the used camera system. With the parameterization of the optical model we present a method to validate the functional and safety limits of camera-based ADAS based on the real, measured lens actually used in the product. ", "text": "ﬁrst glance seem strange zernike polynomials expressedly developed describe aberrations optical systems zernike polynomials successfully used develop extremely complex optical system nonetheless zernike polynomials ineffective mass production lenses aberrations huge comparison diffraction-limited optical systems like telescopes microscopes. mass production lenses large number zernike polynomials need taken account rendering process unusable ﬁtting modeling real measured lenses. lens designed help appropriate software like opticstudio code oslo. standard output software packages take tolerances temperature shifts account. whole software package would become optical transfer function numerical point view completely impractical highdimensional tolerance studies. also packages lack central requirement sequential raytracing offers limited possibility depth object space mandatory real dscenes used setups automobile industry. publications anns estimate optical aberrations publications address problem parameterization mass production. ﬁrst publication application speciﬁc atmospheric phase-front aberrations telescopes obvious generalize process sil/hil requirements presented here. blind deconvolution second publication even limited working images using spatially invariant exactly require. training autonomous vehicles requires lots driving sequences situations. typically simulation environment accompanies real-world test drives systematically vary environmental parameters. missing piece optical model simulations sharpness given linear system theory point-spread function optical system. present novel numerical model optical system efﬁciently model experimental measurements lens design simulations psf. numerical basis model non-linear regression artiﬁcial neural network novelty lies portability parameterization model allows apply model basically conceivable optical simulation scenario e.g. inserting measured lens computer game train autonomous vehicles. present lens measurement series yielding numerical function depends parameters defocus ﬁeld azimuth. convolving existing images videos model apply measured lens transfer function therefore generating image seen measured lens itself. applications method optical scenario focus context autonomous driving quality detection algorithms depends directly optical quality used camera system. parameterization optical model present method validate functional safety limits camera-based adas based real measured lens actually used product. optical models camera system validation camera-based adas autonomous driving functional safety limits used camera systems need quantitatively determined. numerical test methods play central role functional validation. required process certain production parameters tolerances systematically varied given range e.g. operating temperature range optical quality camera system evaluated. setup images video sequences modiﬁed camera looks operating parameters unfortunately currently exists ﬂexible optical model allows process comprehensive efﬁcient manner. principle optical properties lens completely described optical transfer function frequency space accordingly point spread function image space concerned paper highly non-linear function apparent parameterization mass production tolerances hence exists error model mass production cameras neither analytical numerical. figure model overview takes number input parameters outputs psf. report model parameters defocus image height azimuth according measurement parameters. lens lens elements possibly ir-cut ﬁlter included seventh element therefore optically active surfaces surface tolerances least position direction variables excluding topic surface deviations. rotational symmetry apparently assumed. fig. qualitatively depicts three measured psfs lens different image ﬁeld clearly demonstrates strong variation quality intensity distribution. required mathematical-numerical model describes properties real lenses function limited dependent variables. regression especially non-linear regression artiﬁcial neural networks highly asymmetric functions established ongoing ﬁeld research ’learns’ function training appropriate number examples. training function training well according parameters used input ﬁrst layer ann. operation input parameters used evaluates function given parameter position. goal novel model depicted fig. takes number input parameters evaluates output function parameters. input parameters principle variable depend actual simulation goal. e.g. tolerance calculation tolerance measure might used input ann. report three input parameters defocus image height azimuth parameters accord three measurement parameters strength approach ﬂexible number type inputs used broad variety different simulation scenarios. used mean square error distance metric train ann. details training process published separately. measurement data taken collaboration company trioptics wedel germany. used measurement system trioptics imagemaster used setup effective pixelsize dpixeleffective .µm. combination photopic vision ﬁlter monochromatic ccdsensor measured data cover chromatic aberrations. left future work. overall lenses measured based three different lens designs automotive camera modules. work selected single lens meaning training neural network based solely measurement data lens specimen. lens focal length ﬁeld-of-view measurement three parameters defocus image height azimuth image height varied −.mm azimuth full circle defocus measurement time restrictions parameter sampling evenly distributed. basically measurement series lens recorded high in-plane resolution defocus resolution reduced in-plane resolution high resolution larger range defocus. ﬁrst series resulted measured psfs second psfs. fig. shows measured psfs used lens single plane defocus i.e. shown psfs defocus value note psfs positions scale fig. actual psfs enlarged make visible. therefore outer circle accords image height real psfs much smaller. ﬁrst important step downsample high resolution scans ﬁrst target image sensor pixel size high resolution measurement necessary. second resolution determines size amount training data hence required computing resources. article cropped downsampled data pixel size approximately resulting work resolution mainly restricted limited computing power. example process shown fig. based input data varied structure used learning algorithm. fig. shows example prediction process given lens sample. three columns represent three different ﬁeld positions fig. upper shows actual measurement lower output given input parameters. inset displays high resolution measurement image respective psf. distance metric yields satisfactory agreement measurement model. improving accuracy prediction focus studies. nonetheless model distinctly varying spatial distribution especially changing quality modeled faithfully. summary therefore apply model psfs transfer function existing images. goal validating setup simulate modify scenarios look like taken different circumstances. example temperature expansion plastic holder lead defocus giving blurred image. therefore image data either simulated already recorded data needs modiﬁed reﬂect circumstances. optical question hand means existing images need convolved appropriate transfer function. section describes steps used convolve existing ﬁlter process described using example image fig. image taken high quality consumer camera since measurements valid certain image height black every pixel outside range imitating undersized aperture image sensor given pixel size. aperture visible fig. using model unique valid pixel image sensor. optically would accord real physical situation light every viewing direction within angular resolution travels lens path hence psf. convolving every single pixel appropriate numerically cumbersome though opted practical approach manually determining rois interpolating results. dots fig. represent corners rois. actually would interesting research question right determine quantitative limit size separate every pixel required. note every pixel target image course convolved neighbouring pixels treated exact determined figure construction weighting function bilinear interpolation psf. left single kernel simple bilinear weighing middle four kernels right resulting ﬁnal kernel. since kernels pixels positioned closely together similar sample smaller number psfs interpolate fully convoluted image based those. achieve choose uniformly spaced grid pixels across image every valid pixel image inside rectangle consisting four points grid. using bilinear interpolation calculate kernel based those. maximum error interpolation estimated comparing bilinear interpolation’s result ann’s. every sampled point corner four rectangular parts image. four areas create sampled point center shown fig. weighting four bigger rectangles appropriately adding values exact result convolution corresponding psfs could calculated bilinear interpolation. weighting scheme four fig. shows application weight function fig. right image thus result convolution whole area four different psfs only instead different psfs according pixel-exact model. resulting degraded image process depicted fig. spatially varying convolved original image right appropriate position. completeness also applied standard blind deconvolution minimize inﬂuence original lens physical size original image larger maximum radius measurement performance measured lens strongly declines toward edge image circle. real application size imager would selected rectangle distinctly within circle hence strong blurring edges would visible. note simulation defocus value whole image i.e. depth information present. sense fig. similar output standard lens design software user chooses function trace example image lens design. differentiates optical model presented paper ability include depth information formation resulting image. therefore next section discusses depth. camera-based adas ﬁxed-focus systems lens-imager position determined alignment procedure production. therefore objects different distances also different image distances relation principle planes i.e. defocus value respect image plane ﬁxed quality currently found test setups. example thermal expansion camera head central validation question every camera maker mainly defocussing effect thermal expansion plastic holding components. defocussing expressed therefore model setup simulator examines camera response real algorithm blurring effect real measured psf. systematically varying allows systematically test validate function safety limits adas algorithms respect temperature expansion camera head. work shows feasibility approach. several different optimizations expansions pursuing. first spatial resolution measurement well model distance metric training neural network also varied reﬂect spatial information like cnns. finally direct comparison simulated driving scene real measured counterpart important step demonstrating ability limits universal optical model. alignment mentioned introduction strength optical model allows depth information hence exact focus position used best knowledge feature optical simulations. idea applicable optical tracing computer game like z-buffering. different possibilities calculate value scenarios. simple example consider opengl-like d-engine uses z-buffer measure depth information z-buffer information linearized scaled yield real values using simple lens formula defocus value relation given image plane determined. demonstrate feature applied model linear depth gradient simple checkerboard image value varied left right positive maximum measurement value negative maximum setup corresponds roughly checkerboard object space strongly tilted respect optical axis camera system. clarity used spatially invariant i.e. position information thus blurring stems value defous course unrealistic effects depth decreasing lens performance large ﬁeld separated. looking closely left right edge fig. subtle differences blurring because lens exhibits asymmetric function positive negative values shows nicely quality simulation possible novel optical model. presented universal optical model able included measured lens data within optical simulations tracing z-buffering. context testing validating algorithms autonomous driving opens research quantum optics carried university hamburg resulting doctorate university siegen started working optical designer camera-based adas company kostal became professor physics university applied sciences d¨usseldorf researches optical metrology optical models simulation context autonomous driving. he’s member spie participating norming efforts ieee currently serves advisory board autosens conference. cambridge edition elodie choquet olivier levecq mamadou n’diaye marshall perrin r´emi soummer. james webb space telescope optical simulation testbed design three-lens anastigmat telescope simulator. proc. spie space telescopes instrumentation volume s.j. weddell r.y. webb. neural network architecture reconstruction turbulence degraded point spread functions. proceedings image vision computing zealand pages schuler burger harmeling sch¨olkopf. machine learning approach non-blind image deconvolution. ieee conference computer vision pattern recognition pages june frank. rosenblatt. principles neurodynamics; perceptrons theory brain mechanisms. spartan books washington rumelhart hinton williams. learning internal representations error propagation. david rumelhart james mcclelland corporate research group editors parallel distributed processing explorations microstructure cognition vol. pages press cambridge vasileios belagiannis christian rupprecht gustavo carneiro nassir navab. robust optimization deep regression. international conference computer vision ieee december university applied sciences d¨usseldorf thesis work forms basis publication developed degradation algorithms focus efﬁcient convolution. currently master student university studying electrical engineering. hatem zakour received b.eng. university applied sciences d¨usseldorf thesis work implemented ﬁrst neural networks regression publication. currently master student university studying electrical engineering. university applied sciences d¨usseldorf. bachelors thesis examined inﬂuence noise algorithms measurements. master thesis developed environment used publication. currently pursuing focus presented universal optical model application test validate algorithms autonomous driving.", "year": "2018"}