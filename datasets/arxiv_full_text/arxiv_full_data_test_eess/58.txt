{"title": "Speaker-independent machine lip-reading with speaker-dependent viseme  classifiers", "tag": "eess", "abstract": " In machine lip-reading, which is identification of speech from visual-only information, there is evidence to show that visual speech is highly dependent upon the speaker [1]. Here, we use a phoneme-clustering method to form new phoneme-to-viseme maps for both individual and multiple speakers. We use these maps to examine how similarly speakers talk visually. We conclude that broadly speaking, speakers have the same repertoire of mouth gestures, where they differ is in the use of the gestures. ", "text": "avletters dataset train test recognisers based upon mappings. dataset consists four british-english speakers reciting alphabet seven times. full-faces speakers tracked using active appearance models lip-only combined shape appearance features extracted. select features known out-perform feature methods machine visual-only lip-reading figure shows count phonemes appear phoneme transcription allowing duplicate pronunciations beep pronunciation dictionary used throughout experiments british english constructed using separate training test data using seven fold cross-validation total speaker utters words seven recitations alphabet selected test folds turn included training folds. toolkit build hidden markov model classiﬁers whose models viseme classes map. ﬂat-start hmms hcompv reestimate times forced alignment seventh eighth re-estimates. finally recognise using hvite output results hresults. models three state hmms associated gaussian mixture components. recognition network constrains output letters alphabet. therefore measure accuracy letterscorrect machine lip-reading identiﬁcation speech visual-only information evidence show visual speech highly dependent upon speaker here phoneme-clustering method form phoneme-to-viseme maps individual multiple speakers. maps examine similarly speakers talk visually. conclude broadly speaking speakers repertoire mouth gestures differ gestures. index terms visual-only speech recognition computer lipreading visemes classiﬁcation pattern recognition speakerindependence speaker identity known important recognition speech visual-only information audio speech. difﬁculties dealing visual speech ﬁndamental units recognition term viseme loosely deﬁned mean visually indistinguishable unit speech visemes usually deﬁned grouping together number phonemes indistinguishable visual appearance. several many-to-one mappings phonemes visemes proposed investigated idea using speaker-dependent visemes presented. method summarised follows phonemes clustered groups based confusions identiﬁed step two. clustering algorithm permits phonemes grouped single viseme phoneme confused others within consonant vowel phonemes permitted mixed within viseme class. result process phoneme-to-viseme speaker—for details resulted small improvement speaker-dependent recognition question arises extent maps independent speaker speaker independence might examined. particular interested interaction data used train models viseme classes themselves. establish baseline performance using speakerdependent speaker dependent models testing data derived speaker. table depicts maps constructed. resulting maps listed table /garb/ viseme made phonemes appear output recogniser. viseme listed associated mutually-confused phonemes e.g. made phonemes {/ah/ /iy/ /ow/ /uw/}. means phoneme recognition four phonemes {/ah/ /iy/ /ow/ /uw/} confused three viseme. tests recognisers trained single speaker recognise data different speakers. done four speakers using maps speakers data speakers. hence speaker construct speakers—this depicted table next experiment train models speech single speaker vary speaker-dependent maps. isolates effects recognition effect different viseme classes. speaker test following third experiments multi-speaker form viseme classes. constructed using phoneme confusions produced speakers shown table test follows explained table maps many-to-one mapping possibility creating visual homophones. example phonetic realisation word using become indistinguishable. vocabulary letters a–z. permitting variations pronunciation show total unique words word translated words phonemes visemes table higher volume homophones greater chance substitution errors. recognisers signiﬁcantly worse hmms results speaker around equivalent performance guessing. correlates similar tests independent hmm’s attribute possible effects either visual units incorrect trained incorrect speaker. figure word recognition measured correctness classiﬁers constructed single-speaker independent maps four speakers avl. baseline maps error bars show standard error. tests speaker speaker speaker ﬁnally speaker word correctness improved substantially implies previous poor performance choice visemes rather badly trained hmms. mance within error range scores outside error range scores likewise decreases recognition performance values negative. best four maps followed ﬁnally susceptible speaker identity. note order matches decreasing order quantity visemes speaker-dependent viseme sets i.e. similar phoneme classes visemes better recognition performance. ties table hazen saenko c.-h. glass segment-based audio-visual speech recognizer data collection development initial experiments proceedings international conference multimodal interfaces ser. icmi york available http//doi.acm.org/./. matthews baker active appearance models revisited international journal computer vision vol. available http//www.springerlink. com/openurl.asp? young evermann gales hain kershaw moore odell ollason povey valtchec woodland book cambridge university engineering department available http//htk.eng.cam.ac.uk/docs/docs.shtml bear owen harvey b.-j. theobald some observations computer lip-reading moving dream reality spie security+ defence. international society optics photonics better maps less homorphous words. table phoneme pairs {/ax/ /eh/} {/m/ /n/} {/ey/ /iy/} present three speakers {/ah/ /iy/} {/l/ /m/} pairs speakers. single-phoneme visemes /ch/ present three times twice. figure shows correctness viseme class sets. multi-speaker classiﬁers built tested speaker therefore tests test maps plot repeat baseline reference. signiﬁcant difference speaker speaker word recognition reduced eradicated. interesting speaker speakerdependent recognition best speakers performs multi-speaker viseme classes signiﬁcantly. maybe speaker unique visual talking style reduces similarities speakers compare maps tables similarities. mostly know speaker time removed within maps. however compare speaker-dependent maps table different picture. speaker signiﬁcantly affected introduction /ow/ /uw/ viseme /v/. speaker word recognition less half speaker principal conclusion seen comparing figures figure figure shows substantial reduction performance system truing speaker test speaker. question arises whether degradation wrong choice wrong training data recognisers. conclude choice causes degradation since retrain hmms regain much performance. regain performance irrespective whether chosen different speaker multi-speaker independently speaker. important conclusion since tells repertoire appearances vary signiﬁcantly across speakers. comforting since prospect recognition using symbol alphabet varies speaker daunting. reinforced tables differences speakers signiﬁcant ones.", "year": "2017"}