{"title": "A Human Visual System-Based 3D Video Quality Metric", "tag": "eess", "abstract": " Although several 2D quality metrics have been proposed for images and videos, in the case of 3D efforts are only at the initial stages. In this paper, we propose a new full-reference quality metric for 3D content. Our method is modeled around the HVS, fusing the information of both left and right channels, considering color components, the cyclopean views of the two videos and disparity. Performance evaluations showed that our 3D quality metric successfully monitors the degradation of quality caused by several representative types of distortion and it has 86% correlation with the results of subjective evaluations. ", "text": "caused depth inaccuracy. main drawback approach unable accurately measure overall quality attempt fuse associated factors. authors propose quality metric combination quality metrics disparity quality. however method fails include color components. another shortcoming cyclopean view quality taken account. recently full-reference quality metric proposed designed specifically mobile content. although metric addresses shortcomings quality metrics still strongly dependent block matching measuring similarity block structures depth maps. moreover performance verified compressed videos. paper propose full-reference quality metric includes quality fused right left views similar human visual system combines quality views quality depth maps. proposed metric tailored different applications takes account display size video resolution distance viewer display. performance proposed metric validated subjective tests using reference modified videos itu-r bt.- recommendation. rest paper organized follows section dedicated description proposed metric. subjective tests presented section results discussions provided section section concludes paper. proposed human-visual-system-based quality metric takes account quality individual views quality cyclopean view well quality depth information follows although several quality metrics proposed images videos case efforts initial stages. paper propose full-reference quality metric content. method modeled around fusing information left right channels considering color components cyclopean views videos disparity. performance evaluations showed quality metric successfully monitors degradation quality caused several representative types distortion correlation results subjective evaluations. assessing quality content much difficult content. existing quality metrics cannot directly used evaluate quality since take account effect depth binocular properties human visual system efforts result correlation objective subjective test results. example proposed approach existing quality metrics applied right left views separately results averaged views quantitatively evaluate quality picture. account effect depth evaluating quality content researchers proposed quality metric based temporal spatial variance disparity motion scene. proposed metric takes account effect depth include effect associated quality factors contrast sharpness. addition method uses quality measure accurately represent human visual system. another group researchers categorized content distortions monoscopic stereoscopic types proposed separate metrics type distortions approach monoscopic quality metric quantitatively measures distortions caused blur noise contrast-change stereoscopic metric exclusively measures distortions luma information view divided blocks. note block size chosen video applications significantly reduce complexity approach allowing structural similarities views. video applications blocks used. order model cyclopean view matching blocks detected information matching blocks left right views needs fused. apply d-dct transform pair matching blocks generate dct-blocks contain coefficients fused blocks. since human visual system sensitive frequencies cyclopean view keep first level coefficients dct-block discard ones. another property human visual system sensitivity contrast. take account feature derive contrast sensitivity function modeling mask apply dct-block frequencies importance human visual system assigned bigger weights. illustrated follows cyclopean-view model pair matching blocks right left views lowfrequency d-dct coefficients fused view horizontal vertical indices coefficients modeling mask. derived based idea presented utilizes jpeg quantization table creates mask includes larger coefficients visually important elements. derive mask similar adopt jpeg quantization table create mask. note jpeg quantization tables obtained series psychovisual experiments determine visibility thresholds basis functions. based this coefficients human visual system sensitive quantized less coefficients visually important content course distorted views weighting constants. weighting constants chosen quality measures used method given different importance order lead best possible results. fig. illustrates flow chart proposed method. following subsections elaborate different quality measures used method. weighting constants decided based subjective tests presented section proposed quality metric considers independent quality view compared corresponding reference view shown equation quality distorted right view respect matching reference view calculated follows luma information reference distorted right views respectively chroma information reference right-view chroma information distorted right-view weighting constants visual information fidelity index details). note since sensitivity human visual system different luminance chrominance different weighting constants assigned them. quality left view calculated fashion. amazing properties human stereo vision fusion left right views scene single cyclopean view. comply human visual system include quality cyclopean view proposed quality metric well note quality cyclopean view different quality individual views measure quality cyclopean view first imitate binocular vision corresponding areas left right views. done finding matching blocks right left views mean depth values block normalized reference depth map. local disparity variance calculated block size area since area fully projected onto fovea watching display typical viewing distance meters. reference depth normalized respect maximum value frame depth values range depth value pixel outer block within normalized reference depth map. find weighting factors proposed quality metric validate performance performed subjective tests using different databases sequences selected test videos video database digital multimedia university british columbia datasets contain videos fast motion slow motion dark bright scenes human non-human subjects wide range depth. specifications test videos summarized table four different types distortions applied eight stereo-videos. following distortions commonly used evaluate performance quality metrics. level distortion case leads visible artefacts turn allow correlate subjective tests mean opinion score objective results. compression. application instead quantizing coefficients would like scale values bigger weights assigned visually important content mask designed ratio among coefficients inversely proportional ratio corresponding elements quantization table jpeg. since mask needs applied d-dct blocks cubic interpolation used up-sample coefficients mask create mask. moreover elements mask selected average equal one. guarantees that case uniform distortion distribution quality block within distorted cyclopean view coincides average quality view. obtain cyclopean-view model blocks within distorted reference views quality cyclopean view calculated follows cyclopean-view model matching block pair reference view xc'i cyclopeanview model matching block pair distorted view idct stands inverse discrete cosine transform depth reference view depth distorted view total number blocks view constant ssim structural similarity metric designed specifically measuring similarities images ssim compares structure images take account effect small geometric distortions. equation small geometric distortions right left images reflected depth thus index depth distorted video respect original videoâ€™s depth used scaling factor conjunction ssim. allows measuring quality cyclopean view accurately. considering geometrical distortions source vertical parallax causes severe discomfort viewers equation empirically assigned importance given index quality depth information plays important role perceptual quality content reason included quality metric denoted equation quality depth becomes important several different depth levels scene. contrary scene limited number depth levels quality depth plays less important role overall quality. given observations approach chose quality short training session viewers shown distorted reference stereoscopic test sequences random order viewer would watch reference distorted versions sequence consecutively without knowing video reference one. test videos four-second gray interval provided allowing viewers rate perceptual quality content relax eyes watching next video. here perceptual quality reflects whether displayed scene looks pleasant general. particular subjects asked rate combination naturalness depth impression comfort suggested quality levels ranking videos score indicated highest quality indicated lowest quality. collecting experimental results removed outliers based itu-r recommendation bt.- mean opinion scores viewers calculated. depth maps reference distorted stereo videos estimated using depth estimation reference software provided mpeg video activities find weighting factors similar studies least mean square technique used difference metric values values minimized training video set. objective determine best values weighting constants result minimum mean square errors index mos. table shows resulting values constants. performance evaluation metric tested using validation dataset. fig. shows relationship resulting values quality metric entire validation different distortions logistic fitting curve used clearly indicate correlation subjective results results derived objective metric. observed objective metric manages clearly distinguish resulting visual quality degradation. spearman ratio objective quality metric whole validation dataset four representative kinds distortion shows strong statistical dependency subjective objective results. applying five above-mentioned distortions eight stereo videos obtain distorted stereo videos. subjective evaluations performed using training tune weighting parameters metric denoted equation subsequent subjective tests performed evaluate quality metric using validating dataset. viewing conditions subjective tests according itu-r recommendation bt.- twenty-one observers participated subjective tests ranging years old. subjects none marginal image video viewing experience. screened color visual acuity also stereo vision evaluation performed using full hyundai passive glasses. settings follows brightness contrast color display settings based mpeg recommendations subjective evaluation proposals submitted response video coding call proposals xing perkis wang perceptual quality assessment stereoscopic images based image quality metrics disparity analysis international workshop video processing quality metrics consumer electronics vpqm arizona egiazarian astola ponomarenko lukin battisti carli full reference quality metrics based international workshop video processing quality metrics scottsdale future work performance objective quality metric compared existing metrics. moreover investigate performance metric mobile applications well video coding applications. paper proposed quality metric video. approach combined quality views quality cyclopean view quality depth maps. performance evaluations validation dataset subjective test results revealed fact proposed quality metric almost correlation subjective test results.", "year": "2018"}