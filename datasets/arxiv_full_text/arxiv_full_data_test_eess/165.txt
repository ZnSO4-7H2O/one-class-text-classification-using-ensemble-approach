{"title": "Kernel-based Inference of Functions over Graphs", "tag": "eess", "abstract": " The study of networks has witnessed an explosive growth over the past decades with several ground-breaking methods introduced. A particularly interesting -- and prevalent in several fields of study -- problem is that of inferring a function defined over the nodes of a network. This work presents a versatile kernel-based framework for tackling this inference problem that naturally subsumes and generalizes the reconstruction approaches put forth recently by the signal processing on graphs community. Both the static and the dynamic settings are considered along with effective modeling approaches for addressing real-world problems. The herein analytical discussion is complemented by a set of numerical examples, which showcase the effectiveness of the presented techniques, as well as their merits related to state-of-the-art methods. ", "text": "study networks witnessed explosive growth past decades several ground-breaking methods introduced. particularly interesting prevalent several ﬁelds study problem inferring function deﬁned nodes network. work presents versatile kernel-based framework tackling inference problem naturally subsumes generalizes reconstruction approaches forth recently signal processing graphs community. static dynamic settings considered along eﬀective modeling approaches addressing real-world problems. herein analytical discussion complemented numerical examples showcase eﬀectiveness presented techniques well merits related state-of-the-art methods. numerous applications arising diverse disciplines involve inference networks modelling nodal attributes signals take values vertices underlying graph allows associated inference tasks leverage node dependencies captured graph structure. many real settings often aﬀords work limited number node observations inherent restrictions particular inference task hand. social networks example individuals reluctant share personal information; sensor networks nodes report observations sporadically order save energy; brain networks acquiring node samples involve invasive procedures context frequently encountered challenge often emerges inferring attributes every node network given attributes subset nodes. typically formulated task reconstructing function deﬁned nodes given information values. reconstruction functions graphs studied machine learning community context semi-supervised learning term transductive regression classiﬁcation existing approaches assume smoothness respect graph sense neighboring vertices similar values devise nonparametric methods targeting primarily task reconstructing binary-valued signals. function estimation also investigated recently community signal processing graphs term signal reconstruction approaches commonly adopt parametric estimation tools rely bandlimitedness signal interest assumed span principal eigenvectors graph’s laplacian matrix. unifying framework tackling signal reconstruction problems traditional time-invariant well challenging time-varying setting. begin comprehensive presentation kernel-based learning solving problems signal reconstruction graphs data-driven techniques presented based multi-kernel learning enables combining optimally kernels given dictionary simultaneously estimating graph function solving single optimization problem case prior information available semi-parametric estimators discussed incorporate seamlessly structured prior information signal estimators move problem reconstructing time-evolving functions dynamic graphs kernel-based framework extended accommodate time-evolving setting building notion graph extension speciﬁc choices lend reduced complexity online solver next ﬂexible model introduced captures multiple forms time dynamics kernel-based learning employed derive online solver eﬀects online selecting optimal combination kernels on-the-ﬂy analytical exposition parts supplemented numerical tests based real synthetic data highlight eﬀectiveness methods providing examples interesting realistic problems address. notation scalars denoted lowercase characters vectors bold lowercase matrices bold uppercase; entry matrix superscripts respectively denote transpose pseudo-inverse. matrices vec{a} rekronecker latter deﬁned rm×m rn×n n-th column identity matrix rn×n positive deﬁnite represented inn. ||x|| ||x|| ||x||in cone positive deﬁnite finally stands kronecker delta matrices denoted expectation. deﬁnitions graph speciﬁed tuple vertex adjacency matrix whose )-th entry denotes non-negative edge weight vertices simplicity assumed graph self-loops i.e. chapter focuses undirected graphs graph said unweighted either edge deﬁned vertices adjacent connected neighbors laplacian matrix deﬁned diag symmetric posmap value represents attribute feature political alignment annual income person social network. signal thus represented problem statement. suppose collection noisy samples {ys|ys es}s available models noise contains indices sampled vertices given assuming knowledge kernel methods constitute workhorse machine learning nonlinear function estimation popularity attributed simplicity ﬂexibility good performance. here present kernel regression unifying framework graph signal reconstruction along so-called representer theorem. kernel function deﬁning symmetric positive semideﬁnite matrix entries intuitively basis function measuring similarity values note signals graphs expansion ﬁnite since ﬁnite-dimensional. thus expressed compact form loss measures estimated function observed vertices {vns}s collected deviates data constitutes popular choice increasing function used promote smoothness typical choices including regularization estimating functions graphs conventional kernels gaussian kernel cannot adopted underlying graph signals deﬁned metric space. indeed vertex addition scaling norm ||vn|| naturally deﬁned alternative embed euclidean space feature invoke conventional kernel laplacian matrix laplacian kernels well motivated since constitute graph counterpart so-called translation-invariant kernels euclidean spaces section reviews laplacian kernels provides beneﬁcial insights terms interpolating signals highlights versatility capturing information graph fourier transform estimated signal. depends desirable properties target function expected have. table summarizes well-known examples arising speciﬁc choices point prudent oﬀer interpretations insights operation laplacian kernels. towards objective note ﬁrst regularizer comprises projections onto eigenspace referred graph fourier transform spog parlance consequently called frequency components. so-called bandlimited functions spog refer whose frequency components exist inside band adopting aforementioned spog notions intuitively interpret role bandlimited kernels. indeed follows regularizer strongly penalizes corresponding large thus promoting speciﬁc structure frequency domain. speciﬁcally prefers large whenever small vice versa. fact expected decrease smooth motivates adoption heavily penalized. therefore setting small pagerank whereby sought-after signal essentially deﬁned limiting distribution simple underlying random surﬁng process. random surﬁng processes also domain knowledge historical data. suppose without loss generality zero-mean random variables. lmmse estimator given linear estimator lmmse minimizing e||f lmmse|| short interpret kernel ridge regression lmmse estimator signal covariance matrix equal also lmmse interpretation also suggests usage kernel matrix enables signal reconstruction even graph topology unknown. although discussion hinges kernel ridge regression setting kernel estimator form beneﬁt vertex-covariance kernels too. contemporary networks sets nodes depend among multiple types relationships ordinary networks cannot capture consequently generalizing traditional single-layer multilayer networks organize nodes diﬀerent groups called layersis well motivated. kernel-based approaches function reconstruction multilayer graphs also selection pertinent kernel matrix paramount importance performance kernel-based methods section presents approach eﬀects kernel selection graph signal reconstruction. algorithms complementary strengths presented. rely user-speciﬁed kernel dictionary best kernel built dictionary data driven way. fact speciﬁc determined therefore kernel selection tantamount rkhs selection. consequently kernel dictionary {κm}m gives rise rkhs dictionary {hm}m form algorithm identify best subset rkhss therefore kernels entails unknowns next alternative approach discussed reduce number variables price beeing able assure sparse kernel expansion. approaches discussed applicable various problems certainly limited modeling assumptions make. particular performance algorithms belonging parametric family restricted well signals actually adhere selected model. nonparametric models hand oﬀer ﬂexibility robustness cannot readily incorporate information available priori. practice however uncommon neither approaches alone suﬃces reliable inference. consider instance employmentoriented social network linkedin suppose goal estimate salaries users given information salaries few. clearly besides network connections exploiting available information regarding users’ education level work experience could beneﬁt reconstruction task. true problems arising link analysis exploitation web’s hierarchical structure task estimating importance pages recommender systems inferring preference scores every item given users’ feedback particular items could cast signal reconstruction problem item correlation graph. data sparsity imposes severe limitations quality pure collaborative ﬁltering methods exploiting side information items known alleviate limitations leading considerably improved recommendation performance promising direction endow nonparametric methods prior information relies semi-parametric approach whereby signal interest modeled superposition parametric nonparametric component former leverages side information latter accounts deviations parametric part also promote smoothness using kernels graphs. section outline simple reliable semi-parametric estimators complementary strengths detailed fp]t fnp]t βmbm captures known signal structure basis {bm}m nonparametric term belongs rkhs accounts deviations span goal section eﬃcient reliable estimation given since vector represented deﬁning matrix entries solving entails minimization variables. clearly dealing large-scale graphs could lead prohibitively large computational cost. reduce complexity semi-parametric version representer theorem employed establishes tuned e.g. cross-validation minimize generalization error well-documented merits signal estimation quantized data substituting yields convex non-smooth quadratic problem solved eﬃciently using e.g. interior-point methods section reports signal reconstruction performance diﬀerent methods using real well synthetic data. performance estimators assessed monte carlo simulation comparing normalized mean-square error months july august september selected. construct graph vertices corresponding airports highest traﬃc whenever number ﬂights airports exceeds within observation window connect corresponding nodes edge. signal constructed averaging arrival delay inbound ﬂights selected airport. total signals considered ﬁrst used training remaining testing weights edges airports learned using training data based technique described table lists nmse rmse minutes task predicting arrival delay airports delay randomly selected collection airports observed. second corresponds ridge regression estimator uses nearly-optimal estimated covariance kernel. next rows correspond multi-kernel approaches dictionary diﬀusion kernels values uniformly spaced rest rows pertain graph-bandlimited estimators table demonstrates reliable performance covariance kernels well herein discussed multi-kernel approaches relative competing alternatives. semi-parametric reconstruction. erd˝os-r`enyi graph probability edge presence nodes generated formed superimposing bandlimited signal plus piecewise constant signal {γi} eigenvectors associated smallest eigenvalues laplacian matrix; {vi} vertex sets clusters obtained spectral clustering indicator vector entries otherwise. parametric basis {vi} used estimators capturing prior knowledge vertices sampled uniformly random. subsequent experiments evaluate performance semi-parametric graph kernel estimators sp-gk sp-gk resulting using respectively; parametric considers parametric term nonparametric considers nonparametric term graph-bandlimited estimators assume bandlimited model bandwidth experiments diﬀusion kernel parameter employed. first white gaussian noise variance added sample yield signalto-noise ratio snre fig. presents nmse diﬀerent methods. expected limited ﬂexibility parametric approaches aﬀects ability capture true signal structure. estimator achieves smaller nmse amount available samples adequate. semi-parametric estimators found outperform approaches exhibiting reliable reconstruction even samples. illustrate beneﬁts employing diﬀerent loss functions compare performance sp-gk sp-gk presence outlying noise. sample contaminated gaussian noise large variance probability fig. demonstrates robustness sp-gk attributed \u0001−insensitive loss function experiments networks exhibit time-varying connectivity patterns time-varying node attributes arise plethora network science related applications. sometimes dynamic network topologies switch ﬁnite number discrete states governed sudden changes underlying dynamics challenging problem arises setting reconstructing time-evolving functions graphs given values subset vertices time instants. eﬃciently exploiting spatiotemporal dynamics markedly impact sampling costs reducing number vertices need observed attain target performance. reduction paramount importance certain applications monitoring time-dependent activity diﬀerent regions brain invasive electrocorticography observing vertex requires implantation intracranial electrode assume function interest adheres speciﬁc vector autoregressive model. works target time-invariant functions aﬀord tracking suﬃciently slow variations. case dictionary learning approach distributed algorithms unfortunately ﬂexibility algorithms capture spatial information also limited since focuses laplacian regularization whereas require signal bandlimited. deﬁnitions time-varying graph tuple vertex rn×n adjacency matrix time whose )-th entry assigns weight pair vertices time time-invariant graph special case adopting deﬁne non-negative weights self-edges undirected time-varying function signal graph time indices. value vertex time thought value attribute time values time collected observed. resulting samples expressed models observation error. letting ys]t observations conveniently expressed goal latter obtained possibly based previous estimate complexity time slot must independent solve problems rely assumption evolves smoothly space time structured dynamics incorporated known. evolving functions possibly dynamic graphs notion graph extension time dimension receives treatment spatial dimension. versatility kernel-based methods leverage spatial information thereby inherited broadened account temporal dynamics well. vantage point also accommodates time-varying sampling sets topologies. unfortunately estimator account possible relation e.g. instance varies slowly time estimate well beneﬁt leveraging observations time instants exploiting temporal dynamics potentially reduces handle single snapshot necessitates appropriate reformutime-invariant function. appealing possibility replace extended version vertex replicated times yield extended vertex −))-th entry extended adjacency matrix equals weight edge vn)). time-varying function thus replaced extended time-invariant counterpart deﬁnition denote vertex time-varying graph. graph vertex adjacency matrix extended graph t-th diagonal block equals edges connecting vertices time instant represented solid lines whereas edges connecting vertices diﬀerent time instants represented dashed lines. space-time kernel captures complex spatiotemporal dynamics. topology time invariant speciﬁed bidimensional plane spatiotemporal frequency similar regarding present therefore provides estimates past present future values solution online problem comprises set=. obtained solving closed form applying however approach yield desirable online algorithm since therefore increasing reason approach satisfactory since online problem formulation requires complexity time slot desired algorithm independent algorithm satisfy requirement provides exact estimate presented next kernel matrix positive deﬁnite matrix satisfying generalizes probabilistic since latter recovered upon setting covariance matrix probabilistic assumptions made probabilistic stronger involved kkf. speciﬁcally probabilistic must adhere linear state-space model known transition matrix state noise uncorrelated time known covariance matrix furthermore observation noise must uncorrelated time known covariance matrix. correspondingly performance guarantees probabilistic also stronger resulting estimate optimal mean-square error sense among linear estimators. furthermore jointly gaussian probabilistic estimate optimal mean-square error sense among estimators. contrast requirements proposed much weaker since specify must evolve smoothly respect given extended graph. expected performance guarantees similarly weaker; e.g. however since generalizes probabilistic reconstruction performance former judiciously selected cannot worse reconstruction performance latter given criterion. caveat however selection necessarily easy. increases becomes eventually prohibitive. since distributed versions kalman ﬁlter well studied decentralized algorithms pursued reduce computational complexity. multi-kernel kriged kalman ﬁlters following section applies framework presented online dataadaptive estimators speciﬁcally spatio-temporal model presented judiciously captures dynamics space time. based model criterion time space formulated online algorithm derived aﬀordable computational complexity kernels preselected. bypass need selecting appropriate kernel section discusses data-adaptive multi-kernel learning extension estimator learns optimal kernel on-the-ﬂy. att− generic transition matrix chosen e.g. adjacency possibly directed transition graph capturing state error. state transition matrix att− selected accordance prior information available. simplicity estimation motivates random walk model att− hand adherence graph prompts selection att− case amounts diﬀusion process time-invariant graph equivalent section focus deriving estimators based also accommodate using aforementioned reformulation. capturing slow dynamics time state space equation term accounting fast dynamics motivated application hand kriging terminology said model small-scale spatial ﬂuctuations whereas captures so-called trend. decomposition often dictated sampling interval captures slow dynamics relative sampling interval fast variations modeled modeling approach motivated prediction network delays represents queuing delay propagation transmission processing delays. likewise predicting prices across diﬀerent stocks captures daily evolution stock market correlated across stocks time samples describes unexpected changes daily drop stock market political statements assumed uncorrelated time. spatio-temporal model represent multiple forms spatiotemporal dynamics judicious selection associated parameters. batch estimator time yields guide selection appropriate kernel matrices. constraints imply adherence since deﬁned time-evolving potential approach select laplacian kernels slot complexity grows fortunately ﬁltered solutions attained kernel kriged kalman ﬁlter online fashion. proof reader referred iteration proposed kekrikf summarized algorithm online estimator signal interest promotes desired properties smoothness graph using diﬀerent existing krikf approaches graphs kekrikf takes account underlying graph structure estimating furthermore using also accommodate dynamic graph topologies. finally noted kekrikf encompasses special case krikf relies knowing statistical properties function lack prior information prompts development data-driven approaches eﬃciently learn appropriate kernel matrix. next section discuss online approach achieving goal. regularization parameters eﬀect ball constraint weighted account ﬁrst three terms growing observe optimization problem gives time varying estimates allowing track optimal change time respectively. separately convex variables. solve alternating minimization strategies employed suggest optimizing respect variable keeping variables ﬁxed considered ﬁxed reduces solved algorithm estimates ﬁxed replaced frank-wolfe algorithm kernel matrices belong laplacian family eﬃcient algorithms exploit common eigenspace kernels dictionary developed proposed method reduces unless otherwise stated compared estimators include distributed least squares reconstruction step size µdlsr parameter βdlsr; least mean-squares algorithm step size µlms; bandlimited instantaneous estimator results applying separately instantaneous estimator diﬀusion kernel parameter dlsr bl-ie also bandwidth parameter reconstruction extended graphs. ﬁrst experiment dataset obtained epilepsy study used showcase example analysis electrocorticography data next experiment utilizes ecog time series electrodes implanted patient’s brain onset seizure. symmetric time-invariant adjacency matrix obtained using method ecog data onset seizure. function comprises electrical signal n-th electrode t-th sampling instant onset seizure period samples. values normalized subtracting temporal mean time series onset seizure. goal experiment illustrate reconstruction performance capturing complex spatio-temporal dynamics brain signals. size space-time kernel created time-invariant covariance kernel sample covariance matrix time series onset seizure time-invariant results clearly show superior reconstruction performance successfully exploits statistics signal available among competing approaches even small number samples. result suggests ecog diagnosis technique could eﬃciently conducted even smaller number intracranial electrodes posite impact patient’s experience. reconstruction kekrikf. second dataset provided national climatic data center comprises hourly temperature measuments measuring stations across continental united states time-invariant graph constructed based geographical distances. value represents temperature recorded n-th station t-th day. kernel sηin multikernel kriged kalman ﬁlter conﬁgured with contains diﬀusion kernels parameters {σ}m drawn gaussian distribution mean variance contains sηin parameters {sη}m drawn gaussian distribution mean variance speciﬁc kernel selection kekrikf leads smallest nmse error selected using cross validation. observe mkrikf captures spatio-temporal dynamics successfully explores pool available kernels achieves superior performance. third dataset provided world bank group comprises gross domestic product capita values countries years time-invariant graph constructed using correlation values ﬁrst years diﬀerent countries. graph function denotes value reported n-th country t-th year graph fourier transform values shows graph frequencies take small values large values otherwise. motivated aforementioned observation kkrikf conﬁgured band-reject kernel results applying fig. illustrates actual well estimates greece contained sampled countries. clearly mkrikf learns pertinent kernels data achieves roughly performance kkrikf conﬁgured manually obtain smallest possible nmse. task reconstructing functions deﬁned graphs arises naturally plethora applications. kernel-based approach oﬀers clear principled intuitive tackling problem. chapter gave contemporary treatment framework focusing time-invariant time-evolving domains. methods presented herein oﬀer potential providing expressive tackle interesting real-world problems. besides illustrating eﬀectiveness discussed approaches tests also chosen showcase interesting application areas well reasonable modeling approaches interested readers build upon. details models discussed theoretical properties reader referred references therein. acknowledgement. research supported grants", "year": "2017"}