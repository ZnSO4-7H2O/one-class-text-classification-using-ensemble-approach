{"title": "Random Euler Complex-Valued Nonlinear Filters", "tag": "eess", "abstract": " Over the last decade, both the neural network and kernel adaptive filter have successfully been used for nonlinear signal processing. However, they suffer from high computational cost caused by their complex/growing network structures. In this paper, we propose two random Euler filters for complex-valued nonlinear filtering problem, i.e., linear random Euler complex-valued filter (LRECF) and its widely-linear version (WLRECF), which possess a simple and fixed network structure. The transient and steady-state performances are studied in a non-stationary environment. The analytical minimum mean square error (MSE) and optimum step-size are derived. Finally, numerical simulations on complex-valued nonlinear system identification and nonlinear channel equalization are presented to show the effectiveness of the proposed methods. ", "text": "abstract—over last decade neural network kernel adaptive ﬁlter successfully used nonlinear signal processing. however suffer high computational cost caused complex/growing network structures. paper propose random euler ﬁlters complex-valued nonlinear ﬁltering problem i.e. linear random euler complexvalued ﬁlter widely-linear version possess simple ﬁxed network structure. transient steady-state performances studied non-stationary environment. analytical minimum mean square error optimum step-size derived. finally numerical simulations complex-valued nonlinear system identiﬁcation nonlinear channel equalization presented show effectiveness proposed methods. development adaptive ﬁltering complex-valued adaptive ﬁlter found applications diverse ﬁelds radar imaging fourier analysis mobile communications seismics estimation direction arrival beamforming modeling identiﬁcation complex-valued nonlinear systems traditional linear adaptive ﬁltering techniques suffer poor performance. examples situations include nonlinear system identiﬁcation nonlinear channel equalization. order model nonlinear systems serval methods proposed last half century include neural networks polynomial spline fourier ﬁlters mention few. order directly process complex values neural networks complex-valued neural network developed splitting-complex fullycomplex activation functions used. major drawback cvnns heavy computational complexity. several different types cvnns presented multiplayer percetron networks radial basis function networks recurrent neural networks echo state network complex noncircular signals proposed separates architecture constituent components recurrent architecture memoryless output layer. complex-chebyshev expansion input signal complex-chebyshev functionallink network designed linear ﬁltering expanded signal higher dimensional space. maps original input space inﬁnite dimensional rkhs speciﬁc kernel. kernel chosen gaussian kernel growing network. real kernel ﬁlter serval adaptive algorithms proposed kernel least mean square kernel afﬁne projection kernel recursive least-squares kernel projected subgradient methods. using complexiﬁcation real rkhss complex reproducing kernels complex kernel adaptive ﬁltering introduced wide-linear model enhancements complex-valued/quaternion-valued kernel approach found however order kernel ﬁlters grows linearly number input data. overcome severe drawback several low-complexity techniques developed sparse klms quantized klms klms l-norm regularization. recently according bochner’s theorem rahimi recht suggested popular approach i.e. random fourier features approximate real kernel evaluation kafs based random fourier features random fourier ﬁltering proposed original input data mapped ﬁnite dimensional space. thus compared enables learning nonlinear functions efﬁcient fashion. mean square recursive least squares developed rff. furthermore distributed presented networks unfortunately rffs deal real-valued nonlinear systems. paper propose random euler complex-valued ﬁlters deal complex-valued nonlinear ﬁltering problem. firstly based complexiﬁcation real rkhss bochner’s theorem detailed derivation linear random euler complex-valued ﬁlter presented. then employing widely-linear model wirtinger’s derivative widely-linear random euler complex-valued ﬁlter designed. ﬁxed network structure proposed schemes enjoy computational complexity compared kernel ﬁlter. theoretical analysis mean stability mean-square convergence proposed methods performed non-stationary environment modeled random-walk model. results closed-form expression steady-state mean square error obtained indicates optimum step-size non-stationary environment. finally experiments conducted evaluate performance proposed ﬁlters including complex-valued nonlinear system identiﬁcation nonlinear channel equalization. rest paper organized follows. section brief review presented. section provides derivation lrecf wlrecf. mean mean-square behaviors analyzed section section presents monte carlo simulations. finally conclusions drawn section paper matrices represented boldface capital letters vectors column vectors denoted boldface lowercase letters. symbols listed follows column vector formed stacking columns matrix; absolute value complex number; real part complex number; imaginary part complex number; expectation operator. section performances proposed schemes terms mean stability mean-square convergence investigated. instead analyzing proposed method separately mainly focus wlrecf scheme includes lrecf method special case. order make performance analysis tractable assumptions introduced. euler representation coin approach lrecf. fig. illustrates architecture. seen lrecf ﬁxed network structure obviously different growing structure cklms. msesta υvect −vec. used step-size msesta tends minimum non-stationary system know optimum step-size given µopt corresponding minimum msenonstamin συσq√ϕφ vect a−vec vect a−vec. section monte carlo simulations presented. first examine convergence performance proposed ﬁlters nonlinear system identiﬁcation task carried out. then nonlinear channel equalization task considered. evaluate ﬁltering performance used deﬁned running matlab windows experiment settings used fig. demonstrates lrecf effectively approximates cklms lower complexity. proposed wlrecf method could outperform cklms lrecf schemes. wlrecf requires computations lrecf. effect step-size examine effect step-size performance proposed schemes emse curves proposed wlrecf different displayed fig. fig. fig. fig. experiment settings used fig. seen choice step-size determines compromise fast convergence rate small steady-state emse. ﬁxed small suffer slow convergence rate. large lead improved convergence performance high computational cost shown fig. ﬁxed large small suffer poor convergence performance illustrated fig. hence achieve fast convergence rate steady-state error chosen appropriately according application. equalization time delay. additive observation noise zero-mean gaussian signal variance values parameters testing samples fig. gives symbol classiﬁcation performance equalizers proposed wlrecf. verify analyses section theoretical transient curves proposed wlrecf non-stationary environment plotted fig. fig. according model unknown channel randomly generated length initial weight vector adaptive ﬁlter input highly noncircular circular. step-size complex-valued least mean square fair comparison stepsizes proposed algorithms also parameters fig. learning curves circular noncircular input signals depicted. fig. fig. show proposed schemes achieve improved performance compared clms. also shown proposed methods lrecf inferior wlrecf. section know lrecf approximation cklms. growing network cklms poses computational well memory issues large learning samples fig. diagram symbol classiﬁcation performance using proposed wlrecf. input signal case output signal case output signal case output signal case paper proposed random euler ﬁlters i.e. lrecf wlrecf complex-valued nonlinear ﬁlter. basis complexiﬁcation real rkhss bochner’s theorem lrecf ﬁlter ﬁrstly derived. then using widely-linear model wirtinger’s derivative wlrecf also obtained. compared wellknown complex-valued klms proposed random euler ﬁlters enjoy computational complexity ﬁxed network structures. addition theoretical expressions characterize transient steady-state behaviors proposed schemes presented random-walk nonstationary environment. series simulations ﬁnally demonstrated effectiveness proposed methods theoretical results. bouboulis slavakis theodoridis adaptive learning complex reproducing kernel hilbert spaces employing wirtinger’s subgradients ieee trans. neural netw. learn. syst. vol. zhao zhang adaptively combined functional link artiﬁcial neural network equalizer nonlinear communication channel ieee trans. neural netw. vol. apr. zhang zheng recursive adaptive sparse exponential functional link neural network nonlinear impulsive noise environment ieee trans. neural netw. learn. syst. vol. ./tnnls... adali complex-valued adaptive signal processing using nonlinear functions adv. signal process. special issue emerging mach. learn. tech. signal process. jelfs hulle prłncipe mandic augmented echo state network nonlinear adaptive ﬁltering complex noncircular signals ieee trans. neural networks vol. jan. jiang feng complex-chebyshev functional link neural network behavioral model broadband wireless power ampliﬁers ieee trans. microw. theory tech. vol. jun. slavakis theodoridis yamada adaptive constrained learning reproducing kernel hilbert spaces robust beamforming case ieee trans. signal process. vol. parreira bermudez richard tourneret stochastic behavior analysis gaussian kernel-least-mean-square algorithm ieee trans. signal process. vol. bouboulis pougkakiotis theodoridis efﬁcient klms krls algorithms random fourier feature perspective proc. ieee statist. signal process. workshop y.-m. huang qian shrinkage linear widely linear complex-valued least mean squares algorithms adaptive beamforming ieee trans. signal process. vol. jan.", "year": "2018"}