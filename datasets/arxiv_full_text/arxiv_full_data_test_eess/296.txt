{"title": "Cooperative Multi-Agent Reinforcement Learning for Low-Level Wireless  Communication", "tag": "eess", "abstract": " Traditional radio systems are strictly co-designed on the lower levels of the OSI stack for compatibility and efficiency. Although this has enabled the success of radio communications, it has also introduced lengthy standardization processes and imposed static allocation of the radio spectrum. Various initiatives have been undertaken by the research community to tackle the problem of artificial spectrum scarcity by both making frequency allocation more dynamic and building flexible radios to replace the static ones. There is reason to believe that just as computer vision and control have been overhauled by the introduction of machine learning, wireless communication can also be improved by utilizing similar techniques to increase the flexibility of wireless networks. In this work, we pose the problem of discovering low-level wireless communication schemes ex-nihilo between two agents in a fully decentralized fashion as a reinforcement learning problem. Our proposed approach uses policy gradients to learn an optimal bi-directional communication scheme and shows surprisingly sophisticated and intelligent learning behavior. We present the results of extensive experiments and an analysis of the fidelity of our approach. ", "text": "table parallels classic digital signal processing modern machine learning tools. ﬁlter convolves signal kernel convolutional layer neural network does. filter ﬁlter feedback recurrent cell performs computation feedback. least mean squares equalizer updates parameters equalization ﬁlter using gradient descent gradient descent used optimize parameters neural networks. finally source coding seeks smaller representation data autoencoder attempts compress input data bottleneck decode wireless communication domain traditionally characterized manually designed signal processing blocks similar hand-crafted features used traditional computer vision. low-level functions modulation error correcting codes carefully designed optimize performance radios various channel conditions. addition traditional radio systems strictly co-designed lower levels stack compatibility efﬁciency. although enabled radio communications succeed despite hardware constraints also introduced lengthy standardization processes imposed static allocation radio spectrum. various initiatives undertaken research community tackle problem artiﬁcial spectrum scarcity making frequency allocation dynamic building collaborative networks replace static ones. prominent initiatives darpa spectrum collaboration challenge ﬁrstof-its-kind collaborative machine-learning competition overcome scarcity radio frequency spectrum. work investigate modern reinforcement learning techniques alleviate rigidity traditional radio network design. intend replace ordinary radio blocks modulation demodulation high-capacity models agnostic speciﬁc function instead learned data-driven manner. parallels classic digital signal processing blocks machine learning tools abstract—traditional radio systems strictly co-designed lower levels stack compatibility efﬁciency. although enabled success radio communications also introduced lengthy standardization processes imposed static allocation radio spectrum. various initiatives undertaken research community tackle problem artiﬁcial spectrum scarcity making frequency allocation dynamic building ﬂexible radios replace static ones. reason believe computer vision control overhauled introduction machine learning wireless communication also improved utilizing similar techniques increase ﬂexibility wireless networks. work pose problem discovering low-level wireless communication schemes ex-nihilo agents fully decentralized fashion reinforcement learning problem. proposed approach uses policy gradients learn optimal bi-directional communication scheme shows surprisingly sophisticated intelligent learning behavior. present results extensive experiments analysis ﬁdelity approach. recent years automatically learned features replaced hand-designed ﬁlters computer vision problems yielding much higher accuracy benchmark tasks image classiﬁcation object detection. results achieved training deep neural network end-to-end pixels output probabilities large amount training data. process optimizing network minimize prediction error model learns meaningful low-level spatial features form activations hidden layers network theoretical bound performance layers always added increase expressiveness model recent research using deep networks exceeded human level performance tasks image classiﬁcation data-driven reinforcement learning approaches also proven effective tool approximately solving control problems object manipulation robotic locomotion. classically problems solved constructing dynamics model system optimizing trajectory using local linear models ilqr ﬁnite-difference methods. modern approaches solve trajectory optimization modelling problem actor inputs actions system receives state reward signal response. actor responsible maximizing reward signal. derivative technique multiagent cooperative learning recently gaining popularity method solving simple logic games involving multiple actors justify assumption high-capacity models able learn low-level radio functions. contrast domains data training easily generated large-scale simulations. finally show possible actors learn modulation schemes communication sharing ﬁxed string domainspeciﬁc knowledge task. rest work organized follows section section discuss related work give background information wireless communication reinforcement learning. section presents preliminary analysis data driven approaches classic radio tasks. section introduces problem fully decentralized multi-agent setting learning modulation. section present solution results respectively. finally concluding remarks given section viii. research presented work spans many ﬁelds related works grouped research topic. first review early approaches parameter optimization radiorelated tasks explore machine learning algorithms communication domain ﬁnish describing recent work distributed deep reinforcement learning. concept using parameter optimization radiorelated tasks ﬁrst introduced widrow applied gradient descent problem equalization form least mean squares equalizer optimizes ﬁlter parameters ﬁxed length ﬁlter counteract effects multipath channel work also links back optimization single perceptrons. lloyd came algorithm k-means unsupervised learning solving problem demodulating pulsecode modulation. work published serves standard solution solving k-means. interdisciplinary work widrow lloyd pioneers digital wireless communication machine learning. since widrow’s early work research neural architectures machine learning techniques address problems communications taken many directions. ibnkahla’s comprehensive review intersection communications machine learning testament impressive efforts made area research. survey lists various learning-based approaches adaptive equalization nonlinear channel modeling coding error correcting codes spread spectrum applications network planning modulation detection many more. vastness ﬁeld refer reader review. research making radio agents adaptive achieve cooperative goals began mitola introduced concept cognitive radio proposal cognitive radios model-based reasoning achieve competency radio related tasks using supervised unsupervised learning. review cognitive radio work years erative multi-agent tasks. foerster applied variants deep q-networks without experience replay prisoner’s games multiple agents. considered problems require agents communicate simple noiseless channel small bandwidth develop collaborative strategy. mordatch abbeel show grounded compositional language emerge agents communicate intentions order maximize reward. finally abadi andersen study problem learning encryption agents help adversary. though works concerned level details wirelessly transmitting digital signals incorporate communication agents essential part communication protocol given upfront ﬁgured training. however works rely several assumptions apart fully decentralized setting foerster implement decentralized execution centralized training using single parameters agents. mordatch abbeel’s work also trains single policy assumes fully differentiable environment communication protocol. lastly abadi andersen relax problem allowing agents exchange rewards parameters. contrast approach aims fully decentralize learning process minimize real system. gives hope fully distributed deep reinforcement learning possible. figure shows simpliﬁed model generic communication link. goal every setting transmit information source across channel sink help carrier. channel abstract description means transmit information transmitter receiver typically corrupts signal e.g. adding delays noise echos stem physical nature carrier. fig. simple model communication link transmitter receiver transmitter source coding removes redundancies source signal channel coding systematically adds redundancy error correction. modulation used impose information carrier conveys channel. receiver side processes reversed reconstruct original signal. constellation points e.g. qpsk apart -qam. hence noise power density misclassiﬁcations symbols less likely qpsk -qam modulation. however -qam conveys twice amount bits symbol consequentially doubles rate. thus obviously exists trade-off rate resilience errors among different modulation schemes. higher noise usually necessitates lower order modulation hence lower rate. improve resilience transmission furthermore makes sense sequences minimal hamming distance adjacent constellation points. number errors minimized certain symbol gets confused neighbor. mapping scheme guarantees every pair directly neighboring constellation points hamming distance dmin called gray coding. noise power density refers power spectral density noise given noise power unit bandwidth. calculate total noise power integrate bandwidth signal. work ignore problem source channel coding focus modulation demodulation carrier. wireless communication utilizes electromagnetic waves carrier convey information across wireless link radios. waves described sinusoidal functions time space. ignoring details propagation wave induces voltage signal antenna given point space. interpret signal parts in-phase component quadrature component plus sinusoidal functions respectively. orthogonal multiples period receiver electromagnetic wave extract functions signal independently. thus interpret components independent degrees freedom transmission information. purpose dealing in-phase quadrature component equation shows think signal real part complex number multiplied carrier signal eiπf signal modulates carrier digital modulation allow certain values plot valid values complex plane called constellation diagram individual value results constellation point. given maximum number valid points certain modulation scheme assign sequence length points individually. transmitting information transmitter modulates electromagnetic wave setting value constellation point certain duration symbol. series bits transmitted consecutively sending symbols conveys given number bits. transmitter receiver agree upfront modulation scheme well mapping constellation points sequences successfully transmit message. figure shows common modulation schemes four bits symbol. radio hardware well signal propagation wireless channel perfect instead attenuate corrupt signal. various effects simpliﬁed additive white gaussian noise process zero mean variance in-phase quadrature component. receiver side noise leads errors symbol accidentally mapped wrong constellation point noise. normalized constellation diagram quantify performance different modulation schemes noise usually examines mean error rate across different noise situations given eb/n ratio. mean energy noise power density. eb/n normalized signal-to-noise ratio also known snr-per-bit. figure shows performance comparison traditional modulations schemes across different noise levels. links applications found widrow’s seminal work. fact raises question well modern machine learning approaches perform digital radio tasks since share common ancestor. fig. principle equalizer discrete-time samples continuous signal initialized weights ﬁlter outputs convoluted signal given corrupted signal training correct signal known thus equalizer calculate error reconstructed signal correct signal adaptive algorithm updates weights ﬁlter learning rate direction steepest descent energy error signal wireless communication signal propagate directly transmitter receiver lineof-sight path also gets reﬂected objects environment thus every time step receiver receives superposition signal delayed attenuated copies plus additive noise leads intersymbol interference. effect multipath propagation equivalent convolution input signal channel impulse response characterizes wireless environment. thus output signal channel modeled fig. left multipath propagation wireless signal leads superposition signal delayed attenuated copies receiver. right modeled convolution addition complex gaussian random variable uncompensated inter-symbol interference would lead detection errors dealt demodulation called equalization. figure shows ﬁrst approaches equalization least mean squared equalizer developed widrow hoff interestingly equalizer neural architectures gradient descent update parameters. difﬁcult problems ﬁeld artiﬁcial intelligence today sequential decision making stochastic systems. problems characterized environment whose state evolves probabilistic function actions taken actor. reinforcement learning algorithms direct agent choose optimal actions. work pose problem learning low-level wireless communication schemes decentralized fashion reinforcement learning problem propose policy gradient algorithm solution. section introduces markov decision processes policy search score function gradient estimator vanilla policy gradient algorithm central approach. markov decision processes formalism reasoning decision making uncertainty. environment takes states actor takes actions discrete time steps. based state action taken every time step actor receives scalar reward. mdps satisfy markov property information relevant dynamics system deﬁne state current state action affect transition next state. formally deﬁned tuple possible states world. probability distribution initial states. possible actions. state transition distribution. state action gives probability system transitions state scalar reward distribution. state reached action deﬁnes probability distribution across scalar rewards. episodic realization proceeds follows. first initial state sampled then decision-making agent takes action state sampled reward sampled process repeats terminal state reached. reward full episode maximize expected reward diverse problem setups based information available agent structure state action spaces. example approaches assume agent probabilistic model state-transition distribution since explicit model system approach model-free. successful approaches aforementioned problem either compute value state directly optimize decision-making strategy markov property mdps sufﬁces choose action function current state work take approach work directly space policies. stochastic policy deﬁnes probability distribution actions given states parameters distribution. seek parameters achieve highest expected reward given scenario framed following optimization problem optimization problem explicitly solvable case knows dynamics model reward function example linear-quadratic case using ilqr algorithm however work considering model-free case. model known agent must environment experience update parameters repeat process over. form learning known policy gradient method experience agent computes approximation gradient updates parameters. since section brief point reader following resources background. in-depth look mdps in-depth look reinforcement learning algorithms indepth look policy gradients reinforcement learning diverse ﬁeld rich history. past limited computation power simple tabular algorithms restricted reinforcement learning simple lowdimensional tasks. combined value functions state models policies approximated high capacity models known deep reinforcement learning. deep reinforcement learning many recent successes e.g. helicopter ﬂight beating human experts game continuous control section explore general machine learning algorithms perform standard wireless communication problem modulation demodulation. question seek address well generic gradient descent approach without domain speciﬁc knowledge works tasks exist well known solutions. training single learning agent together ﬁxed conventional counterpart hope estimate learnability modulation demodulation exploring generalized complex collaborative setting. ﬁrst question would like answer well agent recognize demodulate unknown signal based known sequence transmitted actual payload data. contrast prior work oftentimes considers parameter tuning across known modulation schemes runs classiﬁcation supervised learning setting assume prior knowledge common modulation schemes initialization k-means algorithm plays important role. variant k-means++ scheme instead sampling initial means probabilistic manner simply choose points maximize distance previously chosen initial means. evaluation analysis examine well clustering approach works data modulated common modulation schemes. ﬁrst send preamble create clustering mapping cluster means back bits. then large chunk data transmitted evaluate bit-error rate learned demodulator. besides also record number clusters algorithm identiﬁed plot measures different noise intensities. table shows hyperparameters used training. focus evaluation case transmitter sends data modulated -qam. among modulation schemes order four smaller -qam complex hence interesting analyze found results bpsk qpsk -psk deliver similar results. using standard modulation scheme allows compare performance algorithm conventional decoder baseline assumes full knowledge modulation thus serves statistical upper bound. fig. performance comparison demodulation unsupervised clustering assuming known preamble symbols versus conventional decoder -qam. yellow line shows algorithm’s estimate number constellation points data. problem statement problem formulated follows given transmitter arbitrary ﬁxed modulation scheme constellation points transmits known preamble large unknown batch payload data across awgn channel bit-error rate achieve across transmission payload various noise conditions? since assume knowledge usual modulation schemes problems boils unsupervised clustering problem. algorithm number clusters received samples assign cluster mapping samples strings given known preamble demodulate payload learned demodulator. approach lloyd’s algorithm solve variant k-means clustering called jump method based information-theoretic approach clustering presented algorithm runs k-means every number ...n received sequence every complex sample interpreted point space. analysis limit running k-means ﬁxed number iterations algorithm calculates minimum average distortion clustering. deﬁnition minimum average distortion twodimensional random variable representing real imaginary part received samples. means given closest mean given sample norm. minimum average distortion deﬁned minimum variance across possible clusterings setting ﬁnite training sequence expectation gets replaced sample mean across training samples. values distortion function collected algorithm computes jump function jk=...n discrete derivative inverse distortion function algorithm uses value maximizes k-means clustering return cluster means. found clustering label cluster common string across points within cluster thus creating mapping complex values back strings. logic behind algorithm becomes apparent think distortion develops increase assuming k-means algorithm converges distortion always decrease higher clusters explain variance dataset better fewer ones. however increase beyond actual number splitting clusters marginally decrease distortion. thus looking jump transformed distortion function points number clusters beyond diving dataset explain much variance. information mathematical support fig. bit-error rate different noise levels parametrized length preamble used training. blue curve shows performance standard coherent -qam demodulator figure shows bit-error rate schemes trained different preamble lengths. algorithm trained long preamble poorly presence high noise underestimation number clusters. however eb/n ratio increases past algorithm quickly converges performance baseline. algorithm trained examples despite giving best estimate number clusters never reaches baseline performance small number samples leads imprecise guess cluster means. result conclude simple non-parametric unsupervised clustering well demodulating received signals based known preamble comparison standard coherent demodulators. later move multi-agent setting obviously need neural architectures sophisticated learning algorithms sole purpose demodulation shared preamble. turn around setting well agent learn functionality modulator communicate given receiver. receiver static demodulate signal based common modulation scheme however assume knowledge common modulation schemes transmitter. goal transmitter minimize expected error rate receiver. problem statement transmitter given random ﬁxed binary preamble consecutively maps ﬁxedlength strings preamble complex symbols symbols send awgn channel receiver receives receiver demodulates noisy signals using ﬁxed modulation scheme recovers finally transmitter receives reward based difference preamble sent sequence receiver decoded. figure shows performance terms number identiﬁed clusters transmission -qammodulated data. high eb/n ratios learned decoder matches performance baseline. although algorithm performs poorly identifying correct number clusters high noise situations resulting still close ideal solution break down. since mappings constellation points spatially correlated algorithm gets approximately number bits right even mapping multiple clusters single point. thus matter algorithm underestimates number clusters confuses constellation points resulting error close statistical expectation. figure gives intuition different noise situations terms eb/n ratio. figure shows development number identiﬁed clusters time different preamble lengths. high number training samples leads algorithm underestimate number clusters constellations points middle -qam indistinguishable noisy quadratic shape constellation diagram best explained four clusters. training fewer samples algorithm slightly overestimates number clusters number samples cluster low. however comparison runs converges fastest. used conjunction adam optimizer train network using vanilla policy gradient algorithm described section iii-b. contrast policy gradient algorithm described before episode length input transmission output associated reward taken single episode training. necessary temporal structure actions taken. state case past history transmissions rewards modeled explicitly network. gradient estimator then simply results found network capable learning approximations qpsk -psk -qam three four transmissions respectively reasonable preambles lengths hundred symbols within hundred iterations. figure shows typical learning curve set-up given ﬁxed -qam receiver. learning progress quantiﬁed bit-error rate preamble transmission shows rapid decrease within ﬁrst iterations network explores positions constellation points minimize error rate. that transmitter learned constellation points right position dictated receiver. subsequently starts exploit learned constellation reducing standard deviation sampling process leads slow steady decrease ber. results conﬁrm loss signal expressive enough network learn intelligible communication scheme. fig. bit-error rate number training iterations system learning transmitter ﬁxed -qam receiver. hyperparameters initial parameters refer table approach transmitter parametrized neural network takes input single string given length outputs single complex symbol. uses bipolar representation represent bits. network fully connected hidden layer uses relu activation function hidden units fully connected single neuron calculates encourage exploration output transmitter drawn complex normal distribution parameterized output trainable standard deviation seen another variable weight neural network. figure visualizes architecture transmitter. fig. architecture transmitter. ﬁxed number bits used input fully connected neural network outputs real imaginary mean complex output symbols sampled i.i.d. multivariate gaussian distribution parametrized real imaginary means separate variable representing standard deviations distribution. agent receives loss signal environment equal l-norm sent preamble preamble recovered receiver plus factor corresponding energy complex symbols outputted transmitter allows network optimize minimizing error rate also trading energy signal. negative loss used advantage estimator computing sfge expected reward. gradient studying agents learn receive transmit given static counterpart obvious question whether possible combine aspects train receiver transmitter simultaneously. previously mentioned intend solve problem agents allowed communicate strictly unknown noisy channel using respective learned digital communication scheme. unlike previous work area signiﬁcantly relaxed problem allowing shared weights shared gradients fully differentiable communication process longer clear reward signal computed communicated agents. propose following approach solution problem described above. actors agent agent share ﬁxed string acts preamble. agent contains transmitter receiver. transmitters instance neural network section iv-b takes string input outputs complex number represents actor’s transmission string. receiver runs k-nearest neighbors complex number comparing rest modulated preamble generates guess transmission. noise function channel parametrized fig. full system decentralized reward. agent share ﬁxed preamble echo back forth noisy channel difference sent received preamble compute reward rew. receiver distinct behaviors depending type signal receives. receives modulated preamble demodulate symbol help known modulated symbols preamble. instead receives modulated preamble along another modulated signal demodulate latter signal ﬁnding nearest neighbors former. secondary behavior receiver combat noise agent transmitter adds modulation preamble gives agent receiver noisy idea modulation scheme used agent transmitter receiver produce educated demodulation agent sends agent receives echoed version ˆˆb; agent calculates reward symbol negative loss −li; agent calculates agent performs gradient update parameters; agent switch roles; quality gradient updates agent dependent quality agent’s transmitter. interdependency training complex optimization problem signal constantly changing internal external updates. thus exploration plays important role learning process investigate visualization interpretation dynamics next section. section describe results thorough analysis approach. first comment training behavior reveals interesting strategies learn robust modulation scheme. next qualitatively describe inﬂuence hyperparameters learning progress ﬁnal scheme. finally give quantitative results performance learned modulation schemes. quantitative results collected depicted terms mean standard deviation across runs different random seeds. provide agents preamble length hyperparameter. described above agents take turns transmitting receiving preambles echos awgn channel record loss agent’s transmitter every time step. figure shows development modulation scheme given transmitter hyperparameters listed table plots produced transmitter modulate sequence strings modulation scheme learned certain number iterations recording complex outputs. point represents modulation single string overall plot visualizes means standard deviations network iteration. noteworthy observation that upon splitting agent reliably chooses every subset constellations points minimizes hamming distance points subset resulting steadily decreasing throughout training. transmitting four bits network learns groups four constellation points internally gray coded global gray coding across whole constellation. likely fact locally gray coded solutions represent local minima global gray code trivial combinatorial problem. implement techniques escaping minima simulated annealing reasonable network generally fall locally gray coded solutions. graphs clear training broken distinct phases ultimately converging optimal solution represents rotated version -qam. initially constellation points near origin high variance. random initialization network’s weights biases breaks initial symmetry. hundred iterations network splits points clusters eight constellation points each. next network splits points four clusters four constellation points line goes origin. around iterations begins split points eight clusters constellation points direction perpendicular original cluster direction. splitting clusters time constellation point individual position constellation diagram. finally network reduces standard deviation transmitted points converges optimal scheme similar rotated version -qam. note randomness plots stem awgn channel since plots constructed outputs transmitter. instead point clouds demonstrate stochasticity neural network’s outputs. energy symbol restricted penalized soft loss network initially increase average energy beyond ﬁnal constellation allow greater exploration mapping. gives network enough room split clusters noise situation without increasing error rate. achieves reasonably rate splitting clusters moving constellation points begin reduce symbol energy pareto-optimal point versus energy trade-off. figure shows mean energy symbol develops training time. contrast figure shows result case energy output signals restricted. maximum mean symbol energy across constellation points hard-clamped unit circle network cannot simply increase output energy counter noise anymore. conventional radio system would usually decrease order modulation scheme presence higher noise e.g. -qam qpsk. however ﬁxed length input four bits network choice arrange possible constellation points way. figure increasing noise power density steadily reduces number indistinguishable clusters individual points eight clusters constellation points four clusters four constellation points noise especially harsh. interesting network chooses sacriﬁce exploring constellation space. around certain value happens approximately case transmitters stick discovered schemes subsequently decrease standard deviation sampling lower further. restricted agent explores faster longer smaller initial necessary convergence. across clusters minimize hamming distance rest bits clusters. thus network inherently learns concept decreasing order modulation scheme presence noise. result especially surprising system cannot exploit lower order scheme reduce forced send four bits symbol. section vii-c present insight networks behaves presented fashion nonetheless. figure shows bit-error rate preamble decreases training case full system without restricted energy comparison single agent transmitter section iv-b. bit-error rate preamble represents loss training minus energy penalty. three depicted runs based dissimilar eb/n values training necessitate different hyperparameters converge thus absolute values compared however qualitative comparison reveals single transmitter system converges much faster less variance come resilient modulation scheme receiver dictates. full system variance error rate large period time mean energy symbol stays relatively high. transmitters learning fairly diverse mappings early subsection qualitatively describes inﬂuence hyperparameters initialization learning behavior convergence algorithm. around hyperparameter sweeps random search fashion good evaluation process study inﬂuence parameters learning performance. table shows parameter search space. preamble length number symbols preamble determines sample size gradient approximation since network parameters updated transmission. longer preambles offer precise reward thus less noisy update steps preambles longer symbols signiﬁcantly increase training time become impractical testing. initial standard deviation initial standard deviation transmitter plays important role learning process controls level exploration agent exploration versus exploitation trade-off. initial values standard deviation large prevent agent learning reasonable number iterations values small stymie exploration process cause network prematurely converge unstable constellation. step size convergence algorithm ﬁnal shape constellation sensitive variations step size gradient update. small step sizes lead excessively long training duration large step sizes cause instantaneous splitting clusters stability. experiments able tune ﬁxed learning rate adam algorithm ﬁnal constellation automatically converges. however guarantee stability across many different conditions would wise implement kind learning rate decay. noise power density noise power density awgn channel adds uncertainty learning progress noise levels effect learning realistic. fact symbol energy clipped penalized soft power loss factor agent simply increase mean symbol energy compensate noise. case noise power density less important consider noise power density might unintuitive measure reader provide conversion chart values resulting eb/n ratio standard -qam table reference eb/n implies noise power density channel equal mean energy bit. every addition leads doubling eb/n ratio. note cannot directly link noise power density eb/n values learned modulation schemes network vary mean output energy depending current noise level. visualization different noise levels also refer figure power constraint equation determines contribution mean output power training loss. energy symbol unconstrained constellations points would simply without limit order increase eb/n ratio. however excessively high factor inhibits splitting clusters thus learning process whole. loss factor output power soft constraint network still increase symbol energy helps decreasing term. alternative power loss factor hard constraint forces output energy transmitter smaller equal approach achieve normalizing symbol amplitudes value largest mean symbol energy network largest mean energy greater refer restricted energy case. number hidden units number hidden units determines expressiveness neural network forms transmitter. however expressive architecture necessarily perform better. found increasing number hidden units past approximately using even multiple hidden layers improve performance slows learning. receiver determines number neighboring points considered determine sequence assigned constellation point. described section iv-a possible demodulate signal clustering algorithm well even short preamble lengths. however powerful demodulator lead transmitter stick ﬁrst best random constellation instead exploring space noise-resistant scheme. hence limit order motivate transmitter scheme works even weak demodulators thus robust. training iterations number training iterations determines often send preamble back forth stop training process evaluate resulting modulation scheme. found good hyperparameters leads convergence within ﬁrst iterations less. hence ﬁxed number iterations since value evaluating modulation scheme converged. hand evaluation learned constellation points represented means converge even faster. initial weights biases figure shows sampled output transmitter figure another seed random generator provides initial weights biases network. although network converges equivalent constellation training process runs different stages. effect also observed high variance bit-error rate stages training found initializing weights biases network normally distributed values variance means normally distributed values bias worked well runs. random initialization proved important break initial symmetries network converge meaningful modulation scheme. note force energy sampled symbols strictly smaller since normalize mean. logic behind ﬁnal transmitter longer stochastic policy learning resulting means learning process. normalizing sample basis would stymie learning progress. figure shows performance modulation schemes learned different noise situations training preamble length terms ber. although learned modulation schemes errorprone standard -qam learning process stable since varying noise power density small impact result. high resilience noise training achieved network option trade-off symbol energy versus unrestricted case. fact scheme learned high noise power density performs slightly better ones. observation explained fact network forced learn robust transmission scheme high noise power restricts much feasible mapping space increases likelihood transmission errors. fig. performance modulation schemes learned different preamble lengths noise power density training. hyperparameters refer table blue line represents performance standard -qam. figure shows results sweep preamble lengths noise power density. since sweeps lower stable interested point learning breaks thus chose high value performance improves increasing preamble length expected longer preamble provides samples score function gradient estimator improving robustness network. graph network preamble length extremely variable performance visualized high standard deviation high eb/n ratios. although signiﬁcant increase performance increasing preamble length symbols observe marginal improvement jumping symbols. predict increases preamble length would bring performance even close -qam baseline trade-off number symbols need transmitted learning process would render approach infeasible realistic scenarios. describing training process qualitatively following plots show numerical results performance analysis learned modulation schemes. generate plots train system provided hyperparameters extract learned modulation scheme represented mean output possible input sequence. transmit million symbols modulated scheme different eb/n levels across channel receiver. since want analyze learned modulation scheme performance receiver transmit long preamble symbols perfectly recreate constellation points receiver averaging noise. finally reconstructed mapping demodulate noisy samples measure bit-error rate transmission. fig. performance modulation schemes learned different noise power densities unrestricted energy case. hyperparameters refer table blue line represents performance standard -qam. importance ﬂexible radio design conﬁrmed initiation darpa spectrum collaboration challenge devoted entirely task building collaborative radio agents machine learning. work began noting similarities signal processing radio domain machine learning techniques. tested observation series preliminary analysis datadriven approaches modulation demodulation digital signals. using preliminary results formulated problem agents learning modulation schemes entirely decentralized fashion solved using modern deep reinforcement learning techniques. finally thoroughly analyzed performance algorithm extensive experiments discussion. conclude possible learn physical modulation ex-nihilo decentralized learning process resilient noise. surprising network tends learn standard modulation schemes results conjunction highly orchestrated behavior observed training process remarkable. reward function deﬁned entirely terms error rate symbol energy contains information induce structured behavior network reward shaping direct measurement noise neural network rather shallow. beginning training reward signal holds almost useful information quality tied performance transmitter agent. nonetheless agents learn balance exploration versus exploitation trade-off increase symbol energy counteract noise cluster subsets constellations points according hamming distance employ local gray-coding converge without learning rate decay implement standard modulation schemes even adapt modulation scheme noise level. future work would interesting increase capabilities agents deal complex settings. possible next step give agents option decide many bits encode transmitted symbol. furthermore next step would generalize channel linear time-invariant multipath model considerably harder longer memoryless. since work signal proven rich enough enable learning kinds modulation techniques valid question whether could also enable learning equalization pre-coding decentralized fashion. finally present results performance modulation schemes learned restricted symbol energy different noise levels. figure seen increasing noise power density beyond training prevents network splitting clusters single constellation points. behavior leads high error rates schemes constellation points mapped cluster become indistinguishable. figure shows schemes learned high receiver statistically bits differ constellation points within cluster wrong. fig. performance modulation schemes learned different noise power densities energy restricted case. parameters refer table blue line represents performance standard -qam. vertical lines refer noise level training eb/n curve -qam. plot also shows given ﬁxed input four bits symbol splitting constellation separate points represented curve always better keeping clusters. difference curve representing clusters purple yellow curve representing clusters staggeringly high high eb/n values. however referring noise level training back performance curve -qam reveals maximum possible decrease splitting clusters actually high noise situations. difference feasible curve even lower. thus interpret network simply incentive split clusters further would marginally decrease given noise situation. even tenfold increase learning rate change said behavior. feature unanticipated desirable agents automatically switch lower order modulation scheme high noise. however assumes agents also exploit beneﬁts encoding less bits symbol architecture currently cannot. zeng y.-c. liang hoang zhang review spectrum sensing cognitive radio challenges solutions eurasip journal advances signal processing vol. mordatch abbeel emergence grounded compositional language multi-agent populations corr vol. abs/. available http//arxiv.org/abs/. jordan sastry ballianda autonomous helicopter ﬂight reinforcement learning. nips vol. schulman optimizing expectations deep reinforcement learning stochastic computation graphs ph.d. dissertation eecs department university california berkeley available http//www.eecs.berkeley.edu/pubs/techrpts/ /eecs--.html silver huang maddison guez sifre driessche schrittwieser antonoglou panneershelvam lanctot mastering game deep neural networks tree search nature vol. sugar james finding number clusters dataset information-theoretic approach journal american statistical association vol. available http//dx.doi.org/./ arthur vassilvitskii k-means++ advantages careful seeding proceedings eighteenth annual acm-siam symposium discrete algorithms. society industrial applied mathematics szegedy vanhoucke ioffe shlens wojna rethinking inception architecture computer vision proceedings ieee conference computer vision pattern recognition bertsekas bertsekas bertsekas bertsekas dynamic programming optimal control. athena scientiﬁc belmont vol. foerster assael freitas whiteson learning communicate deep multi-agent reinforcement learning advances neural information processing systems digital communications–a survey signal processing vol. mitola maguire cognitive radio making software radios personal ieee personal communications vol.", "year": "2018"}