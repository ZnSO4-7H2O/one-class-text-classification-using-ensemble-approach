{"title": "Near-Optimal Sparse Sensing for Gaussian Detection with Correlated  Observations", "tag": "eess", "abstract": " Detection of a signal under noise is a classical signal processing problem. When monitoring spatial phenomena under a fixed budget, i.e., either physical, economical or computational constraints, the selection of a subset of available sensors, referred to as sparse sensing, that meets both the budget and performance requirements is highly desirable. Unfortunately, the subset selection problem for detection under dependent observations is combinatorial in nature and suboptimal subset selection algorithms must be employed. In this work, different from the widely used convex relaxation of the problem, we leverage submodularity, the diminishing returns property, to provide practical near optimal algorithms suitable for large-scale subset selection. This is achieved by means of low-complexity greedy algorithms, which incur a reduced computational complexity compared to their convex counterparts. ", "text": "deﬁne matrices reserved represent gaussian normal distribution. notation read distributed according represent transposition matrix inversion respectively. diag refers diagonal matrix argument respectively. matrix determinant natural logarithm respectively. tr{·} denotes matrix trace operator. denote entry vector entry matrix respectively. calligraphic letters denote sets e.g. vector denotes vector ones indices given zeros complementary reduced-size measurement vector whose entries belong selection matrix binary matrix composed rows identity matrix deﬁned even though unknown interested cases desirable perform inference reduced measurement set. notation based either considered interchangeable function simple greedy procedure presented algorithm ﬁnds solution provides least constant fraction optimal value. context function ground considered non-decreasing holds sets theorem condition number λmax/λmin minimum eigenvalue λmin maximum eigenvalue λmax admits decomposition βλmin signal-to-noise ratio function -approximately submodular notice determinant consists product signal-to-noise ratio inversely proportional loss signal-to-noise ratio furthermore determinant given product form equivalently cost function solution maximizing greedily submodular surrogate solution maximizing greedily signal-to-noise ratio therefore proposed cost function perfectly suitable large-scale problems especially instances denotes obtained greedy solution i.e. obtained greedily maximizing snr. however maximum function attained provides function value limiting case", "year": "2017"}