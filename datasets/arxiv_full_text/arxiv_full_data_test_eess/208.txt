{"title": "Leveraging Native Language Speech for Accent Identification using Deep  Siamese Networks", "tag": "eess", "abstract": " The problem of automatic accent identification is important for several applications like speaker profiling and recognition as well as for improving speech recognition systems. The accented nature of speech can be primarily attributed to the influence of the speaker's native language on the given speech recording. In this paper, we propose a novel accent identification system whose training exploits speech in native languages along with the accented speech. Specifically, we develop a deep Siamese network-based model which learns the association between accented speech recordings and the native language speech recordings. The Siamese networks are trained with i-vector features extracted from the speech recordings using either an unsupervised Gaussian mixture model (GMM) or a supervised deep neural network (DNN) model. We perform several accent identification experiments using the CSLU Foreign Accented English (FAE) corpus. In these experiments, our proposed approach using deep Siamese networks yield significant relative performance improvements of 15.4 percent on a 10-class accent identification task, over a baseline DNN-based classification system that uses GMM i-vectors. Furthermore, we present a detailed error analysis of the proposed accent identification system. ", "text": "problem automatic accent identiﬁcation important several applications like speaker proﬁling recognition well improving speech recognition systems. accented nature speech primarily attributed inﬂuence speaker’s native language given speech recording. paper propose novel accent identiﬁcation system whose training exploits speech native languages along accented speech. speciﬁcally develop deep siamese network based model learns association accented speech recordings native language speech recordings. siamese networks trained i-vector features extracted speech recordings using either unsupervised gaussian mixture model supervised deep neural network model. perform several accent identiﬁcation experiments using cslu foreign accented english corpus. experiments proposed approach using deep siamese networks yield signiﬁcant relative performance improvements -class accent identiﬁcation task baseline dnn-based classiﬁcation system uses i-vectors. furthermore present detailed error analysis proposed accent identiﬁcation system. recent years many voice-driven technologies achieved signiﬁcant robustness needed mass deployment. largely signiﬁcant advances automatic speech recognition technologies deep learning algorithms. however variability speech accents pose signiﬁcant challenge state-of-the-art speech systems. particular large sections english-speaking population world face difﬁculties interacting voice-driven agents english mis-match speech accents ∗this work carried help research grant awarded microsoft research india summer workshop artiﬁcial social intelligence. seen training data. accented nature speech primarily attributed inﬂuence speaker’s native language. work focus problem accent identiﬁcation user’s native language automatically determined non-native speech. viewed ﬁrst step towards building accent-aware voice-driven systems. accent identiﬁcation non-native speech bears resemblance task language identiﬁcation however accent identiﬁcation harder task many cues speaker’s native language lost suppressed non-native speech. nevertheless expect speaker’s native language reﬂected acoustics individual phones used non-native language speech along pronunciations words grammar. work focus acoustic characteristics accent induced speaker’s native language. present detailed error analysis proposed system reveals confusions among accent predictions contained within language family corresponding native language. section outlines i-vector feature extraction process. section describes siamese network-based model accent identiﬁcation. experimental results detailed section section provides error analysis proposed approach. denote block diagonal matrix diagonal blocks ni..nci identity matrix. denote vector obtained splicing sx..sxc. easily shown posterior distribution i-vector pλ|x gaussian covariance mean denotes posterior expectation operator. solution computed thus i-vector estimation performed iterating estimation posterior distribution update total variability matrix instead using gmm-ubm based computation ivectors also dnn-based context dependent state posteriors generate sufﬁcient statistics used i-vector computation mixture components replaced senone classes present output dnn. speciﬁcally used replaced posterior probability estimate senone given input acoustic feature vector total number senones parameter parameters model computed phonotactic model based approaches acoustic model based approaches explored accent identiﬁcation past. recently i-vector based representations part state-of-the-art speaker recognition language recognition systems applied task accent recognition. i-vector systems used gmm-based background models found outperform competitive baseline systems language recognition systems speaker recognition systems shown promising results deep neural network model based i-vector extraction also none previous approaches exploited speech native languages training accent identiﬁcation systems best knowledge. work attempts develop accent recognition systems using components. techniques outlined derived previous work joint factor analysis i-vectors follow notations used training data speakers used train model parameters denote mixture component weights mean vectors covariance matrices respectively mixture components. here vector dimension assumed diagonal matrix dimension gmm-based i-vector representations denote universal background model supervector concatenation dimensionality denote block diagonal matrix size whose diago denote blocks low-level feature sequence input recording denotes frame index. denotes number frames recording. denote recording supervector concatenation speaker adapted means speaker then i-vector model order estimate i-vectors iterative algorithm used. begin random initialization total variability matrix denote alignment probability assigning feature vector mixture comuse large number positive negative training samples learn distance metric accented speech i-vectors language i-vectors. test time compare accented speech test i-vector representative language i-vector choose language whose i-vector representations nearest accented speech i-vector according distance metric learned siamese network. experiment different strategies determine language i-vectors constructed test time. section discusses details test strategies. experiments used cslu foreign accented english release database consists telephonequality spontaneous english speech native speakers different languages. -class accent identiﬁcation task using accented english speakers different languages amount data brazilian portuguese hindi farsi german hungarian italian mandarin chinese russian spanish tamil native language speech used cslu languages corpus contains telephone-quality continuous speech abovementioned languages. many speakers cslu languages corpus also recorded speech samples cslu foreign accented english corpus. samples siamese networks neural network models designed learn similarity function pairs input representations. architecture consists identical neural networks shared weights input pair samples. objective function minimizes maximizes similarity pair inputs depending whether belong category not. achieved optimizing contrastive loss function containing dual terms component reduces contribution positive training examples component increases contribution negative training examples figure shows illustration siamese network used accent identiﬁcation. training example comprises pair input i-vectors corresponding accented speech sample language speech sample binary label indicating whether native language underlying accented speech sample exactly matches language speech sample. positive training examples correspond accented speech i-vectors paired native language i-vectors speaker. negative examples paired accented speech i-vectors i-vectors languages different underlying accented speech sample. training instances twin networks shared parameters produce outputs {ff} corresponding input i-vectors whole network speakers used construct positive examples training siamese network. table gives detailed statistics data used experiments along training development test splits. splits created using stratiﬁed random sampler proportion different accents remains almost same. based i-vectors -component trained dimensional i-vectors extracted using formulation given sec. features referred i-vectors rest paper. trained dimensional mfcc features mean variance normalized utterance level. training data used obtained multilingual corpora nist switchboard english database training i-vectors acoustic model developed switchboard using kaldi toolkit model generates -dimensional senone posterior features used i-vector extraction i-vector training based dnnubm uses data nist switchboard. dimensional i-vectors model i-vectors length normalized classiﬁer training. performance evaluation used accent identiﬁcation accuracy primary metric evaluate proposed approach. computed percentage utterances correctly identiﬁed abovementioned accents. table shows performance various baseline accent identiﬁcation systems using i-vectors i-vectors input features. used lda-based classiﬁer reduces dimensionality input vectors linear projection onto lower dimensional space maximizes separation classes. also built classiﬁer using radial basis function kernel. finally nnet feed-forward neural network trained optimize categorical cross-entropy using adam optimization algorithm implemented using scikit-learn library nnet implemented using keras toolkit hyper-parameters models tuned using validation set. table observe classiﬁers using i-vectors clearly outperform classiﬁers using i-vectors. intuitive ivectors carry information underlying phones. nnet classiﬁers perform comparably outperformed linear classiﬁer inherent non-linearity data. tried various conﬁgurations siamese networks along varying ratios positive negative training examples. tuning validation siamese architecture yielded best result consisted hidden layers nodes dropout rate ﬁrst hidden layer used rmsprop optimizer glorot initialization network network trained positive negative training pairs. accents equally distributed across positive negative pairs. table lists accuracies siamese network-based classiﬁers using different strategies choose language ivectors test time. ﬁrst extracted random sample language i-vectors computed mean lowest output scores. language least distant accented test sample chosen predicted output. system referred siamese-. siamese refers system computed mean language i-vector across i-vectors particular language. siamese- ﬁrst clustered language i-vectors clusters using k-means algorithm following computed cluster means chose language whose cluster mean minimally distant accented test sample. finally siamese- augments siamese- neural network classiﬁer second trained distance measures computed siamese- model accent classes predicts target accent class. network trained table compares performance best-performing siamese network best-performing baseline systems table consistent improvements using siamese network classiﬁer best baseline system validation test set. improvements hold i-vectors i-vectors used input features. baseline systems used made accented english samples training make native language speech samples. compare siamese network-based approach techniques exploit speech data native languages training. first analogously nnet train -layer feedforward neural network input features consisting language i-vectors concatenated accent i-vectors. system referred nnet-append. build second system call nnet-nonid-twin identical twin network siamese architecture shown figure except weights twin networks shared. finally also investigate transfer learning based approach referred nnet-transfer. system train -layer feed-forward neural network using language ivectors predict underlying language. then resulting weights hidden layers initialization neural network uses accent i-vectors inputs predict underlying accent. table compares three systems siamese- introduced table observe proposed siamese-network system outperforms systems also access native language i-vectors. cslu foreign accented speech corpus contains perceptual judgments accents utterances. accented speech sample independently annotated accent strength scale judged three native american english speakers. table shows siamese network-based classiﬁer performs utterances grouped according accent strength. intuitively accent strength increases classiﬁer accuracy increases. despite fact test predominantly contains utterances accent strength interesting average accuracy test samples much higher samples rated accent strength. table shows accuracies baseline systems best siamese network based system siamese- correct accent among accent predictions. observe accuracies dramatically improve across three individual systems moving -best -best -best accuracies. indicates signiﬁcant part confusions seen across classes conﬁned predictions. also combine outputs three individual systems. adopt simple majority voting strategy choose prediction systems agree upon. three systems predict different accent classes choose accent predicted siamese-. also weighted voting strategy. outputs siamese- converted posterior probabilities using softmax layer. weighted combination probabilities nnet siamese- used determine accent highest probability. n-best accuracies combined systems shown table expected observe performance gains combining outputs three individual systems; gains larger -best -best cases. illustrative visualize accent predictions made proposed siamese network-based classiﬁer order learn main confusions prevalent system. visualize confusion matrix siamese- classiﬁer test samples using heat shown figure darker/bigger bubbles column given indicate larger number samples predicted being accent labeled column. accent class figure shows sizable number test examples correctly predicted evidenced dark bubbles along diagonal. also darklycolored bubble along non-diagonal indicating strong evidence confusion. example hindi-accented english samples often confused tamil-accented conversely tamil-accents test samples mistaken hindi-accents. intuitive given accents closely related correspond geographical region. indeed group languages according language families belong i.e. {ma} {fa} corresponding confusion matrix exhibits less confusion shown figure paper explore problem accent identiﬁcation non-native english speech. propose novel approach based deep siamese neural networks uses i-vectors extracted accented speech native language speech samples learns semantic distance between feature representations. -class accent identiﬁcation task proposed approach outperforms neural network-based classiﬁer using gmm-based i-vectors dnn-based i-vectors relative accuracy improvements respectively. work focused acoustic characteristics accent induced speaker’s native language. accents also correlated speciﬁc lexical realizations words terms pronunciations variations word usage grammar. future work plan explore incorpoauthors thank organizers msr-asi workshop monojit choudhury kalika bali sunayana sitaram opportunity help well project team members abhinav jain gayatri bhat sakshi kalra support. also gratefully acknowledge logistical support microsoft research india project well access microsoft azure cloud computing resources. najim dehak patrick kenny r´eda dehak pierre dumouchel pierre ouellet front-end factor analysis speaker veriﬁcation ieee transactions audio speech language processing vol. najim dehak patrick kenny r´eda dehak pierre dumouchel pierre ouellet front-end factor analysis speaker veriﬁcation ieee transactions audio speech language processing vol. mitchell mclaren nicolas scheffer luciana ferrer application convolutional neural networks speaker recognition noisy conditions proceeding interspeech jane bromley isabelle guyon yann lecun eduard s¨ackinger roopak shah signature veriﬁcation using siamese time delay neural network proceedings nips najim dehak pedro torres-carrasquillo douglas reynolds reda dehak language recognition i-vectors dimensionality reduction proceedings interspeech mohamad hasan bahari rahim saeidi hugo hamme david leeuwen accent recognition using i-vector gaussian mean supervector gaussian posterior probability supervector proceedings spontaneous telephone speech icassp. ieee alexandros lazaridis elie khoury jean-philippe goldman mathieu avanzi s´ebastien marcel philip garner swiss french regional accent identiﬁcation proceedings odyssey maryam najaﬁan saeid safavi phil weber martin russell identiﬁcation british english regional accents using fusion i-vector multi-accent phonotactic systems proceedings odyssey luciana ferrer aaron lawson mitchell mclaren nicolas scheffer application convolutional neural networks language identiﬁcation noisy conditions proc. speaker odyssey workshop daniel povey arnab ghoshal gilles boulianne lukas burget ondrej glembek nagendra goel mirko hannemann petr motlicek yanmin qian petr schwarz silovsky georg stemmer karel vesely kaldi speech recognition toolkit proceedings asru nitish srivastava geoffrey hinton alex krizhevsky ilya sutskever ruslan salakhutdinov dropout simple prevent neural networks overﬁtting. journal machine learning research vol.", "year": "2017"}