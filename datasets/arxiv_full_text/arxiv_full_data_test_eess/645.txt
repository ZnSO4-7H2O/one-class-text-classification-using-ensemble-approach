{"title": "Age Group Classification with Speech and Metadata Multimodality Fusion", "tag": "eess", "abstract": " Children comprise a significant proportion of TV viewers and it is worthwhile to customize the experience for them. However, identifying who is a child in the audience can be a challenging task. Identifying gender and age from audio commands is a well-studied problem but is still very challenging to get good accuracy when the utterances are typically only a couple of seconds long. We present initial studies of a novel method which combines utterances with user metadata. In particular, we develop an ensemble of different machine learning techniques on different subsets of data to improve child detection. Our initial results show a 9.2\\% absolute improvement over the baseline, leading to a state-of-the-art performance. ", "text": "this systems trained understand adults children’s voices hard analyze fully developed vocal tracts improve performance intermediate system identify users. paper investigate child identiﬁcation voice commands metadata combination improve classiﬁcation accuracy. gender identiﬁcation speech problem much research done area results perfect. particular task identify adults kids becomes challenging utterances couple seconds long. investigate novel multimodel approach improve classiﬁer accuracy combining speech data rich usage metadata speciﬁcally extract features separately speech usage data build individual models fused together improve classiﬁer performance. results described section speaker information accent gender used improve speech understanding provide background information advance human-computer interactions. tract undergoes changes starting birth continues throughone’s found fundamental frequencies directly correspond ages professional singers. later naini homayounpour investigated correspondence mfccs shimmer jitter speaker’s age. found jitter shimmer indeed help distinguish ages wider rages. application advanced machine learning techniques children comprise signiﬁcant proportion viewers worthwhile customize experience them. however identifying child audience challenging task. present initial studies novel method combines utterances user metadata. particular develop ensemble different machine learning techniques different subsets data improve child detection. initial results show absolute improvement baseline leading state-of-the-art performance. building recent breakthroughs speech understanding people cellphones questions expect reasonable answers movie recommendations. identity user plays role personalizing improving actions. instance case movie request general probabilistic model work well. consider case child asks watch ruby animated television series automatic speech recognition system mistakenly resolves popular movie downstream natural language processing module. knowledge system could errors returning age-relevant results. unfortunately scenario quite common considering even state-of-the-art systems produce results understanding children’s speech. couple reasons metze achieved human level performance longer speech segments short utterances challenging classify correctly. recent work similar task gender identiﬁcation levitan revealed human level performance achievable short utterances well. work build prominent research approach investigate performance challenging real world data domain utterances second long. addition speech analyze metadata commonly ignored explore fusion multiple models classiﬁcation task. compare performance three models based random forest deep learning report results. speech data collected random week year’s time span manually labeled human annotators male female kid. since don’t ground truth labels labels gold standard. male female labels combined adult class. audio short average seconds long command user watch spongebob cnn. total instances labeled utterances labeled kid. normalize data random sampled utterances adult label. done create balanced dataset instances. data split train test sets ratio leaving training instances testing sets. cross validation train used development optimize algorithms. ﬁnal results reported test set. addition voice commands collected user metadata. data contains general usage patterns date time expected audience type requested show. data covers month activity makes data meager. result ignore dates weekdays instead. additionally calculate likelihood request made children’s show given weekday hour. times date converted user local time zones. addition hand written rule treats commands feature extraction step audio preprocessed normalized. preprocessing step silences removed keep user commands. normalization step mitigate variance speech normalizing volume. common preprocessing step used systems. preprocessing steps extract features input train acoustic model. order validate quality preprocessing steps acoustic features extracted preprocessed normalized audio. acoustic feature extraction opensource tool opensmile opensmile well known utility produces state-of-the-art acoustic features often used annual interspeech paralinguistic challenges deﬁne baseline. source code includes conﬁguration ﬁles different features. conﬁguration experiments paraling is.conf. version introduced interspeech paralinguistic challenge challenge create predictive models gender classiﬁcation. also tried experiment conﬁguration ﬁles; however showed lower performance. extract acoustic features user utterance. features created ﬁrst extracting level descriptors frame level step window size. llds include total features mfccs energy jitter etc. that derive deltas llds apply functions. list functions shown table complete feature description found addition speech explore user requests. despite ever-changing content phrases words identify viewer’s age. system utterance extract transcript. since commands short speciﬁc domain simple bag-of-word language model sufﬁcient. dictionary unique utterance also metadata weekday hour. intuition including data content targeted particular audience respect time day. example news tend evening hours children oriented shows shown morning day. addition show-type request distribution given device. distribution derived computing percentage children’s shows shows watched speciﬁc time. derive distribution score hour entire month time period given device. command comes mark assuming adults awake hours. result feature datasets created time usage data contains usage frequency hour weekday well content type ratio usage data includes distribution kids non-kids content requested given device. ratio calculated hour given device general. considering usage patterns users without children vary datasets important information make better classiﬁcation decisions. classiﬁcation well known algorithms support vector machines random forest algorithms show state-of-the-art performances speaker classiﬁcation tasks algorithm works creating support vectors separating classes n-dimensional space dimension represented feature. separation done ﬁnding largest separation margin features classes vector. random forest tree based ensemble algorithm work running multiple decision tree algorithms known weak learners time. algorithm random selects features makes decisions. results learner combined provide prediction. models trained using scikit-learn toolkit open-source machine learning library. algorithms used training. however best algorithm used test data. deep learning shown useful technique many areas including audio processing. build deep network classiﬁer four hidden layers. layer fully connected dropout rate reduce overﬁtting sigmoid activation function last layer uses softmax activation dropout rate. size layer chosen ﬁrst generalize features narrow feature space size. best architecture following layer sizes ﬁrst last layers acoustic feature input predicted binary class output respectively. network trained overnight consumer level gpu. training start audio preprocessing applying energy normalization silence removal techniques. energy normalization useful method improve performance results need tested determine approach applicable task. removal silences hand valid step increase accuracy. determining best audio normalization train separate model feature audio time usage data show-type request distribution. models tested cross validation scores reported section test sets used evaluate models previously unseen data. avoid overﬁtting tuning algorithms train data cross validation development dataset. point three datasets acoustic data time usage content type ratio. model evaluated separately leveraging multi-domain data apply feature model level fusion methods. experiment combining features three domains single feature vector train additional model features. time perform model level fusion trained model’s output probability used inputs adaboost ensemble learning algorithm apply approach test data. evaluation done using cross validation test dataset. baseline interspeech paralinguistic gender challenge’s pipeline data used challenge different terms audio domain quality utterances average longer. longer audio segment provide information making task easier. more challenge classify users groups perform binary classiﬁcation. reason cannot directly compare scores. however follow steps replicate challenge’s pipeline unaltered data score baseline. accuracy baseline deﬁned ﬁrst step choose best normalization approach. create three subsets audio withnormalization energy level normalized silence removed utterances. order technique works best apply random forest subset. results shown table table energy holds important information speaker normalizing worsens predictions. contrary removing silences signiﬁcantly improves results classiﬁers. reason keep silence removal preprocessing step pipeline omit energy normalization. addition random forest outperforms algorithm majority cases conﬁrms results similar tasks. random forest used rest experiments main algorithm utterance classiﬁcation. metadata language features also tested random forest algorithms. algorithm applied three datasets time usage data show-type request distribution language bag-of-word features. performance described table time usage show-type ratio provide little information user bag-of-word model shows prediction accuracy result better compares metadata worse acoustic features alone. random forest outperforms three domain data. reason random forest main machine learning algorithm data. experiments tested means cross validation training development set. time complexity deep learning algorithm during cross validation. decided best normalization machine learning algorithm ready performance test data set. results test data comparable cross validation train set. table shows time based model provides accuracy. expectation higher score data set. hypothesis content providers time slots target different groups audience. weekend mornings animated shows weekday nights news examples such. reason might commands children shows come parents. also explored show-type requests device capture user interest. turned least predictive data model. idea users children request child oriented content. however insufﬁcient data size show-type distribution attributed result larger data improve performance. need investigation. acoustic based models predictive. random forest shows improved results compared baseline deep learning method outperformed models showed accuracy. explore feature level model level fusion approaches improve results. techniques known ways combine multi-domain data. concatenated features four data sets trained random forest model. produced somewhat unpredictable result. accuracy model improve even worsened producing accuracy. seems combining available features single vector introduces noise data sparsity problem. acoustic model alone outperforms feature lever fusion approach. approach algorithm adaboost adaptive model iteratively boosts weak learner focus harder cases training dataset. input model class probabilities models random forest based acoustic time usage show-type requests bag-of-words language model deep learning based acoustic model. results achieved approach produce accuracy manifesting absolute improvement. closer investigation results table algorithm works better identify children false positives. however model produces higher error predicting adult voices children. table shows gender based confusion matrix. table observe algorithm makes error distinguishing female children voices. comes fact female voices broader acoustic range compare male result overlap children’s. work focused improving child adult user classiﬁcation voice metadata. metadata provides additional information user time show-categories show-type distribution. type data often ignored during research. found multi-domain feature level fusion help improve results. however combining models using ensemble model fusion improves performance. system achieves accuracy task produces state-of-the-art results. future work would like work improve model investigating capturing acoustic differences female child voices since current system produces error classifying groups. also would like compare performance human engineered features deep learning based feature representation. addition semi-supervised approaches gain popularity. data labeling costly time consuming process that problem requires human annotators. leveraging large amount unlabeled data improve results even further.", "year": "2018"}