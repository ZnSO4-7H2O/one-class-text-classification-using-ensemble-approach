{"title": "Representation Learning of Music Using Artist Labels", "tag": "eess", "abstract": " In music domain, feature learning has been conducted mainly in two ways: unsupervised learning based on sparse representations or supervised learning by semantic labels such as music genre. However, finding discriminative features in an unsupervised way is challenging and supervised feature learning using semantic labels may involve noisy or expensive annotation. In this paper, we present a supervised feature learning approach using artist labels annotated in every single track as objective meta data. We propose two deep convolutional neural networks (DCNN) to learn the deep artist features. One is a plain DCNN trained with the whole artist labels simultaneously, and the other is a Siamese DCNN trained with a subset of the artist labels based on the artist identity. We apply the trained models to music classification and retrieval tasks in transfer learning settings. The results show that our approach is comparable to previous state-of-the-art methods, indicating that the proposed approach captures general music audio features as much as the models learned with semantic labels. Also, we discuss the advantages and disadvantages of the two models. ", "text": "music domain feature learning conducted mainly ways unsupervised learning based sparse representations supervised learning semantic labels music genre. however ﬁnding discriminative features unsupervised challenging supervised feature learning using semantic labels involve noisy expensive annotation. paper present supervised feature learning approach using artist labels annotated every single track objective meta data. propose deep convolutional neural networks learn deep artist features. plain dcnn trained whole artist labels simultaneously siamese dcnn trained subset artist labels based artist identity. apply trained models music classiﬁcation retrieval tasks transfer learning settings. results show approach comparable previous state-of-the-art methods indicating proposed approach captures general music audio features much models learned semantic labels. also discuss advantages disadvantages models. representation learning feature learning actively explored recent years alternative feature engineering data-driven approach particularly using deep neural networks applied area music information retrieval well paper propose novel audio feature learning method using deep convolutional neural networks artist labels. early feature learning approaches mainly based unsupervised learning algorithms. used convolutional deep belief network learn structured acoustic patterns spectrogram showed learned features achieve higher performance mel-frequency cepstral coefﬁcients genre artist classiﬁcation. since then researchers applied various jiyoung park jongpil jangyeon park jung-woo juhan nam. licensed creative commons attribution international license attribution jiyoung park jongpil jangyeon park jung-woo juhan nam. representation learning music using artist labels international society music information retrieval conference paris france unsupervised learning algorithms sparse coding k-means restricted boltzmann machine focused learning meaningful dictionary spectrogram exploiting sparsity. unsupervised learning approaches promising exploit abundant unlabeled audio data limited single dual layers sufﬁcient represent complicated feature hierarchy music. hand supervised feature learning progressively explored. early approach mapping single frame spectrogram genre mood labels pre-trained deep neural networks using hiddenunit activations audio features recently approach handled context transfer learning using deep convolutional neural networks leveraging large-scaled datasets recent advances deep learning showed hierarchically learned features effective diverse music classiﬁcation tasks. however semantic labels genre mood timbre descriptions tend noisy sometimes ambiguous annotate tagged crowd. also high-quality annotation music experts known highly time-consuming expensive. meanwhile artist labels meta data annotated songs naturally album release. objective information disagreement. furthermore considering every artist his/her style music artist labels regarded terms describe diverse styles music. thus model discriminate different artists music model assumed explain various characteristics music. paper verify hypothesis using dcnn models trained identify artist audio track. basic dcnn model softmax output units corresponds artist. siamese dcnn trained subset artist labels mitigate excessive size output layer plain dcnn large-scale dataset used. training models regard feature extractor apply artist features three different genre datasets experiment settings. first directly similar songs using artist features k-nearest neighbors. second conduct transfer learning adapter features datasets. results show proposed approach captures useful features unseen audio datasets figure shows proposed dcnn models learn audio features using artist labels. basic model trained standard classiﬁcation problem. siamese model trained using pair-wise similarity anchor artist artists. section describe detail. widely used d-cnn model music classiﬁcation model uses mel-spectrogram bins input layer. conﬁgured dcnn one-dimensional convolution layers slide single temporal dimension. model composed convolution pooling layers illustrated figure batch normalization rectiﬁed linear unit activation layer used every convolution layer. finally used categorical cross entropy loss prediction layer. train model classify artists instead semantic labels used many music classiﬁcation tasks. example number artists used becomes classiﬁcation problem identiﬁes artists. training extracted -dimensional feature vector last hidden layer used ﬁnal audio feature learned using artist labels. since representation identity predicted linear softmax classiﬁer regard highest-level artist feature. dataset artists last hidden layer size number parameters learn last weight matrix reach second whenever artists added dataset model must trained entirely. solve limitations using siamese dcnn model. siamese neural network consists twin networks provides share weights conﬁguration. unique inputs network optimizes similarity scores architecture extended positive negative examples optimization step. take three examples anchor item positive item negative item model often called triplet networks successfully applied music metric learning relative similarity scores song triplets available model extended several negative samples instead negative triplet network. technique called negative sampling popularly used word embedding latent semantic model using technique could effectively approximate full softmax function output class extremely large approximate full softmax output basic model siamese neural networks using negative sampling technique. regarding artist labels negative sampling treating identical artist’s song anchor song positive sample artists’ songs negative samples. method illustrated figure following relevance score anchor song feature song feature measured also note testing actually used whole experiments paper used source dataset training models feature extractors. reason ﬁltered split data future work used artists baseline experiment setting. contains total songs training validation split thus constructed size tagging dataset compare artist-label models tag-label model. tags songs ﬁrst ﬁltered previous works among list ﬁltered used tags randomly selected songs split size artist set. preprocessing computed spectrogram using samples hanning window samples size sampling rate. converted mel-spectrogram bins along magnitude compression. chose seconds context window dcnn input experiments optimal length works well music classiﬁcation task. second long audio randomly extracted context size audio networks single example. input normalization performed dividing standard deviation subtracting mean value across training data. optimized loss using stochastic gradient descent nesterov momentum learning rate decay. dropout applied output last activation layer models. reduce learning rate valid loss stopped decreasing initial learning rate basic models siamese model. zeropadding applied convolution layer maintain size. imize positive relationships. maxmargin hinge loss margins positive negative examples preliminary experiments siamese model negative sampling successfully trained max-margin loss function between objectives deﬁned follows margin denotes positive example negative examples respectively. also gridsearched number negative samples margin ﬁnally number negative samples margin value shared audio model used approach exactly conﬁguration basic model. order verify usefulness artist labels presented models constructed another model architecture basic model using semantic tags. model output layer size corresponds number labels. hereafter categorize artist-label model tag-label model compare performance. section describe source datasets train artist-label models tag-label model. also introduce target datasets evaluating three models. finally training details explained. models trained million song dataset along -second digital preview clips. artist labels naturally annotated onto every song thus simply used them. label used last.fm dataset augmented msd. dataset contains annotation matches msd. number songs belongs artist extremely skewed make fair comparison among three models difﬁcult. thus selected songs artist evenly ﬁltered artists less this. also conﬁgured several sets artist lists effect number artists model performances divided songs training validation testing respectively sets contain less artists. artist sets partitioned songs artists reach validation already become songs even song artist already sufﬁcient validating model performance. system implemented python keras tensorﬂow-gpu back-end keras. used nvidia tesla machines training models. code models available link reproducible research apply learned audio features genre classiﬁcation target task different approaches feature similarity-based retrieval transfer learning. section describe feature extraction feature evaluation methods. work models evaluated three song-level genre classiﬁcation tasks. thus divided -second audio clip segments match model input size -dimension features last hidden layer averaged single song-level feature vector used following tasks. tasks require song-to-song distances cosine similarity used match siamese model’s relevance score. ﬁrst evaluated models using mean average precision considering genre labels relevant items. after obtaining ranked list song based cosine similarity measured following classiﬁed audio examples using k-nearest neighbors classiﬁer linear softmax classiﬁer. evaluation metric experiment classiﬁcation accuracy. ﬁrst classiﬁed audio examples using k-nn classify input audio largest number genres among nearest features training set. number experiment. method regarded similarity-based classiﬁcation. also classiﬁed audio using linear softmax classiﬁer. purpose experiment verify much audio features unseen datasets linearly separable learned feature space. ﬁrst compare artist-label models tag-label model trained dataset size results shown table feature similarity-based retrieval using artist-based siamese model outperforms rest target datasets. genre classiﬁcation tasks tag-label model works slightly better rest datasets trend becomes stronger classiﬁcation using linear softmax. considering source task tag-based model contains genre labels mainly result attribute similarity labels source target tasks. therefore draw conclusions experiment. first artist-label model effective similarity-based tasks trained proposed siamese networks thus useful music retrieval. second semantic-based model effective genre semantic label tasks thus useful human-friendly music content organization. focus comparison artist-label models. table siamese model generally outperforms basic model. however difference become attenuated classiﬁcation tasks siamese model even worse datasets. among them notable siamese model signiﬁcantly worse basic model naver music dataset genre classiﬁcation using k-nn even though based feature similarity. dissected result whether related cultural difference training data target data figure shows detailed classiﬁcation accuracy genre naver dataset. three genres ‘trot’‘k-pop ballad’ ‘kids’ exist training dataset basic model outperforms siamese model whereas results opposite genres. indicates basic model robust unseen genres music. hand siamese model slightly over-ﬁts training although effectively captures artist features. effect number artists analyze artist-label models investigating number artists training dcnn affects performance. figure results show similarity-based retrieval genre classiﬁcation using k-nn linear softmax respectively according increasing number training artists. show performance generally proportional number artists trends quite different models. similarity-based retrieval siamese model signiﬁcantly higher basic model number artists greater also number artists increases siamese model consistently goes slight lower speed whereas basic model saturates artists. hand performance changes classiﬁcation tasks. gtzan dataset basic model better artists siamese model reverses artists. naver dataset basic model consistently better. small results mixed classiﬁers. again results explained interpretation models section summary siamese model seems table comparison previous state-of-the-art models classiﬁcation accuracy results. linear softmax classiﬁer used features extracted artist-label models trained artists. result obtained using provided code dataset work better similarity-based tasks basic model robust different genres music. addition siamese model capable trained large number artists. comparison state-of-the-arts effectiveness artist labels also supported comparison previous state-of-the-art models table result report artist-label models trained artists using linear softmax classiﬁer. table proposed models comparable previous state-of-the-art methods. visualize extracted feature provide better insight discriminative power learned features using artist labels. used dcnn trained classify artists feature extractor. collecting feature vectors embedded -dimensional vectors using t-distributed stochastic neighbor embedding artist visualization collect subset wellknown artists. figure shows artists’ songs appropriately distributed based genre vocal style gender. example artists similar genre music closely located female singers close except maria callas classical opera singer. interestingly songs michael jackson close female vocals distinctive high-pitched tone. figure shows visualization features extracted gtzan dataset. even though dcnn trained discriminate artist labels well clustered genre. also observe genres disco rock hip-hop divided groups might belong different sub-genres. work presented models learn audio feature representation using artist labels instead semantic labels. compared artist-label models taglabel model. ﬁrst basic dcnn consisting softmax output layer predict artist belong artists used. second siamese-style architecture maximizes relative similarity score between small subset artist labels based artist identity. last model optimized using labels architecture ﬁrst model. models trained used feature extractors validated models song retrieval genre classiﬁcation tasks three different datasets. three interesting results found experiments. first artistlabel models particularly siamese model comparable outperform tag-label model. indicates cost-free artist-label effective expensive possibly noisy tag-label. second siamese model showed best performances song retrieval task datasets tested. indicate pair-wise relevance score loss siamese model helps feature similarity-based search. third large number artists increases model performance. result also useful artists easily increased large number. future work investigate artist-label siamese model thoroughly. first plan investigate advanced audio model architecture diverse loss pair-wise relevance score functions. second model easily re-trained using added artists because model ﬁxed output layer. property evaluated using cross-cultural data using extremely small data yoshua bengio aaron courville pascal vincent. representation learning review perspectives. ieee transactions pattern analysis machine intelligence thierry bertin-mahieux daniel ellis brian whitman paul lamere. million song dataset. proc. international society music information retrieval conference volume pages isabelle guyon yann lecun eduard s¨ackinger roopak shah. signature veriﬁcation using siamese time delay neural network. advances neural information processing systems pages keunwoo choi george fazekas mark sandler. automatic tagging using deep convolutional neural networks. proc. international society music information retrieval conference pages keunwoo choi gy¨orgy fazekas mark sandler kyunghyun cho. convolutional recurrent neural networks music classiﬁcation. proc. ieee international conference acoustics speech signal processing pages keunwoo choi gy¨orgy fazekas mark sandler kyunghyun cho. transfer learning music classiﬁcation regression tasks. proc. international conference music information retrieval pages micha¨el defferrard kirell benzi pierre vandergheynst xavier bresson. dataset music analysis. proc. international society music information retrieval conference pages sander dieleman benjamin schrauwen. multiscale approaches music audio feature learning. international society music information retrieval conference pages sander dieleman benjamin schrauwen. end-toend learning music audio. proc. ieee international conference acoustics speech signal processing pages philippe hamel douglas eck. learning features music audio deep belief networks. proc. international conference music information retrieval pages mikael henaff kevin jarrett koray kavukcuoglu yann lecun. unsupervised learning sparse features scalable audio classiﬁcation. proc. international conference music information retrieval pages po-sen huang xiaodong jianfeng deng alex acero larry heck. learning deep structured semantic models search using clickthrough data. proc. international conference conference information knowledge management pages eric humphrey juan bello yann lecun. feature learning deep architectures directions music informatics. journal intelligent information systems sergey ioffe christian szegedy. batch normalization accelerating deep network training reducing internal covariate shift. international conference machine learning pages il-young jeong kyogu lee. learning temporal features using deep neural network application music genre classiﬁcation. proc. international society music information retrieval conference pages honglak peter pham largman andrew unsupervised feature learning audio classiﬁcation using convolutional deep belief networks. advances neural information processing systems pages jongpil juhan nam. multi-level multiscale feature aggregation using pretrained convolutional neural networks music auto-tagging. ieee signal processing letters kailun zhiyao duan changshui zhang. deep ranking triplet matchnet music metric learning. proc. ieee international conference acoustics speech signal processing pages pranay manocha rohan badlani anurag kumar ankit shah benjamin elizalde bhiksha raj. content-based representations audio using siamese neural networks. proc. ieee international conference acoustics speech signal processing tomas mikolov ilya sutskever chen greg corrado jeff dean. distributed representations words phrases compositionality. advances neural information processing systems pages juhan jorge herrera malcolm slaney julius smith. learning sparse feature representations music annotation retrieval. proc. international conference music information retrieval pages jordi pons thomas lidy xavier serra. experimenting musically motivated convolutional neural networks. proc. international workshop content-based multimedia indexing pages schl¨uter christian osendorfer. music similarity estimation mean-covariance restricted boltzmann machine. proc. international conference machine learning applications pages erik schmidt youngmoo kim. learning emotion-based acoustic features deep belief networks. proc. ieee workshop applications signal processing audio acoustics pages yonatan vaizman brian mcfee gert lanckriet. codebook-based audio feature representation music information retrieval. ieee/acm transactions audio speech language processing w¨ulﬁng martin riedmiller. unsupervised learning local features music classiﬁcation. proc. international society music information retrieval conference pages chin-chia yi-hsuan yang. dual-layer bag-of-frames model music genre classiﬁcation. proc. ieee international conference acoustics speech signal processing pages", "year": "2017"}