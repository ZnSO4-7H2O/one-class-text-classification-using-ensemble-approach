{"title": "Learning from Between-class Examples for Deep Sound Recognition", "tag": "eess", "abstract": " Deep learning methods have achieved high performance in sound recognition tasks. Deciding how to feed the training data is important for further performance improvement. We propose a novel learning method for deep sound recognition: Between-Class learning (BC learning). Our strategy is to learn a discriminative feature space by recognizing the between-class sounds as between-class sounds. We generate between-class sounds by mixing two sounds belonging to different classes with a random ratio. We then input the mixed sound to the model and train the model to output the mixing ratio. The advantages of BC learning are not limited only to the increase in variation of the training data; BC learning leads to an enlargement of Fisher's criterion in the feature space and a regularization of the positional relationship among the feature distributions of the classes. The experimental results show that BC learning improves the performance on various sound recognition networks, datasets, and data augmentation schemes, in which BC learning proves to be always beneficial. Furthermore, we construct a new deep sound recognition network (EnvNet-v2) and train it with BC learning. As a result, we achieved a performance surpasses the human level. ", "text": "deep learning methods achieved high performance sound recognition tasks. deciding feed training data important performance improvement. propose novel learning method deep sound recognition between-class learning strategy learn discriminative feature space recognizing between-class sounds between-class sounds. generate between-class sounds mixing sounds belonging different classes random ratio. input mixed sound model train model output mixing ratio. advantages learning limited increase variation training data; learning leads enlargement fisher’s criterion feature space regularization positional relationship among feature distributions classes. experimental results show learning improves performance various sound recognition networks datasets data augmentation schemes learning proves always beneﬁcial. furthermore construct deep sound recognition network train learning. result achieved performance surpasses human level. sound recognition conventionally conducted applying classiﬁers local features mfcc log-mel features convolutional neural networks achieved success image recognition tasks recently proven effective tasks related series data speech recognition natural language processing researchers applied cnns sound recognition tasks achieved high performance amount quality training data feed important machine learning particularly deep learning. various approaches proposed improve sound recognition performance. ﬁrst approach efﬁciently limited training data data augmentation. researchers proposed increasing training data variation altering shape property sounds adding background noise researchers also proposed using additional training data created mixing multiple training examples second approach external data knowledge. aytar proposed learning rich sound representations using large amount unlabeled video datasets pre-trained image recognition networks. sound dataset expansion also conducted paper novel third approach propose learning method deep sound recognition between-class learning strategy learn discriminative feature space recognizing between-class sounds between-class sounds. generate between-class sounds mixing sounds belonging different classes random ratio. input mixed sound model train network output mixing ratio. method focuses characteristic sound generate sound simply adding waveform data sounds. advantages learning limited increase variation training data; learning leads enlargement fisher’s criterion feature space regularization positional relationship among feature distributions classes. experimental results show learning improves performance various sound recognition networks datasets data augmentation schemes learning proves always beneﬁcial. furthermore constructed deep sound recognition network trained learning. result achieved error rate benchmark dataset esc- surpasses human level. argue learning different so-called data augmentation methods introduced above. although learning regarded data augmentation method viewpoint using augmented data novelty point method mixing multiple sounds rather learning method training model output mixing ratio. fundamentally different idea previous data augmentation methods. general data augmentation methods improve generalization ability generating additional training data likely appear testing phase. thus problem solved training testing phase. hand learning uses mixed data labels training mixed data appear testing phase. learning method improve classiﬁcation performance solving problem predicting mixing ratio different classes. best knowledge ﬁrst time learning method employs mixing ratio between different classes proposed. intuitively describe learning method effective demonstrate effectiveness learning wide-ranging experiments. introduce recent deep learning methods sound recognition. piczak proposed apply cnns log-mel features extracted waveforms. log-mel feature calculated frame sound represents magnitude frequency area considering human auditory perception piczak created feature-map arranging log-mel features frame along time axis calculated delta log-mel feature ﬁrst temporal derivative static log-mel feature. piczak classiﬁed static delta feature-maps treating two-channel input manner quite similar inputs image. log-mel feature-map exhibits locality time frequency domains therefore accurately classify feature-map cnn. refer method logmel-cnn. researchers also proposed methods learn sounds directly waveforms including feature extraction. aytar proposed sound recognition network using convolutional pooling layers named soundnet learned sound feature using large amount unlabeled videos also proposed network using convolutional pooling layers stacked layers. reported network layers performed best. tokozume harada proposed network using convolutional pooling layers named envnet. first envnet extracts frequency feature short duration section convolutional pooling layers obtain feature-map. next classiﬁes feature-map convolutional pooling layers similar manner logmel-cnn. learning waveform still challenging problem difﬁcult learn waveform features limited training data. however performance systems close logmel-cnn. describe approaches achieve high sound recognition performance views approaches involving efﬁcient limited training data involving external data/knowledge. first describe data augmentation approach efﬁciently using limited training data. standard important data augmentation methods cropping training data variation increases able figure pipeline learning. create training example mixing sounds belonging different classes random ratio. input mixed sound model train model output mixing ratio using loss. efﬁciently train network short section training sound cropped original data whole section input network. similar method generally used test phase. multiple sections test data input stride average output predictions used classify test sound. salamon bello proposed usage additional training data created time stretching pitch shifting dynamic range compression adding background noise chosen external dataset. researchers also proposed using additional training data created mixing multiple training examples. parascandolo applied method polyphonic sound event detection. takahashi applied method single-label sound event classiﬁcation sounds belonging class mixed. method different employ mixing ratio different classes training. next describe approaches utilizing external data/knowledge. aytar proposed learn rich sound representations using pairs image sound included large amount unlabeled video dataset. transferred knowledge pre-trained large-scale image recognition networks sound recognition network minimizing kl-divergence output predictions image recognition networks sound network. used output hidden layer sound recognition network feature applying target sound classiﬁcation problem. classiﬁed linear svm. could train deep sound recognition network achieve accuracy benchmark dataset esc- method. section propose novel learning method deep sound recognition learning. fig. shows pipeline learning. standard learning select single training example dataset input model. train model output contrast learning select training examples different classes examples using random ratio. input mixed data model train model output mixing ratio. learning uses mixed data labels thus never uses pure data labels training. note examples testing phase. first provide details learning section mainly explain method mixing sounds carefully designed achieve good performance. then section explain learning leads discriminative feature space. learning optimizes model using mini-batch stochastic gradient descent standard learning does. data label mini-batch generated mixing training examples belonging different classes. here describe training examples. sounds belonging different classes randomly selected training dataset one-hot labels. note already preprocessed applied data augmentation length input network. generate random ratio sets data labels ratio. labels simply train model output mixing ratio. explain simplest method however following mixing formula slightly better considering sound energy proportional square amplitude however auditory perception sound mixed eqn. would difference sound pressure level large. example amplitude times large sound would still dominant mixed sound. case training model label inappropriate. consider using coefﬁcient instead sounds sound pressure level respectively. deﬁne auditory perception mixed sound becomes hypothesize ratio auditory perception network amplitude main component functions cnns conv/fc relu pooling average pooling satisfy homogeneity ignore bias. equation ratio amplitude using unit conversion decibels amplitudes solve finally obtain proposed mixing method show mixing method performs better eqn. experiments. calculate sound pressure level using a-weighting considering human auditory perception sensitive high frequency areas. also simpler sound pressure metrics root mean square energy instead a-weighting sound pressure level. however performance worsens show experiments. create short windows sound calculate time series a-weighted sound pressure levels then deﬁne maximum time series optimization deﬁne model function model parameters respectively. input generated mini-batch data {x}n expect mini-batch ratio labels {t}n represent expected class probability distribution. therefore kl-divergence labels model outputs loss function instead usual cross-entropy loss. optimize kl-divergence back-propagation stochastic gradient descent differentiable leaning leads enlargement fisher’s criterion explain reason fig. deep neural networks linearly-separable features learned hidden layer close output layer figure learning enlarges fisher’s criterion feature space training model output mixing ratio classes. hypothesize mixed sound mixr projected point near internally dividing point considering characteristic sounds. middle fisher’s criterion small mixed examples projected classes learning gives large penalty. right fisher’s criterion large mixed examples projected betweenclass points learning gives small penalty. therefore learning leads feature space. besides generate sound simply adding waveform data sounds humans recognize sounds perceive sounds louder softer mixed sound. therefore expected internally dividing point input space almost corresponds semantic feature space least sounds. then feature distribution mixed sounds class class certain ratio would located near internally dividing point original feature distribution class variance feature distribution mixed sounds proportional original feature distribution class investigate whether hypothesis correct visualized feature distributions standard-learned model using pca. used activations envnet training data results shown fig. magenta circles represent feature distribution mixed sounds bark rain ratio black dotted line represents trajectory feature input mixture particular sounds model changing mixing ratio ﬁgure shows mixture sounds projected point near internally dividing point features features mixed sounds distributed classes expected. fisher’s criterion small feature distribution mixed sounds becomes large would large overlap feature distribution class case mixed sounds projected classes shown ﬁgure model cannot output mixing ratio. learning gives penalty situation learning trains model output mixing ratio. fisher’s criterion large hand overlap becomes small model becomes able output mixing ratio learning gives small penalty. therefore learning enlarges fisher’s criterion classes feature space. expect learning also effect regularizing positional relationship among class feature distributions. standard learning constraint positional relationship among classes long features classes linearly separable. found standard-learned model sometimes misclassiﬁes mixed sound class class class fig. shows example transition output probability standard-learned model input mixture particular training sounds model changing mixing ratio output probability bark monotonically increases rain monotonically decreases expected model classiﬁes mixed sound baby mixing ratio within range undesirable state little possibility mixed sound classes becomes sound classes. case assume features class distributed fig. decision boundary class appears class class trajectory features mixed sounds crosses decision boundary class learning avoid situation decision boundary class appears classes learning trains model output mixing ratio instead misclassifying mixed sound different classes. show transition output probability fig. using examples used fig. assume features class distributed fig. feature distributions three classes make acute-angled triangle decision boundary class appear class class note assumed dimension feature space greater equal number classes minus however network generally designed such problem. learning enlarges fisher’s criterion time regularizes positional relationship among classes feature space. hence learning improves generalization ability. figure learning regularizes positional relationship classes feature space training model misclassify mixed sound different classes. learning avoids situation decision boundary class appears classes. datasets. used esc- esc- urbansoundk train evaluate models. esc- esc- urbansoundk contain total examples consisting classes respectively. removed completely silent sections value equal beginning examples esc- esc- datasets. converted sound ﬁles monaural -bit ﬁles. evaluated performance methods using k-fold cross-validation using original fold settings. performed cross-validation times esc- esc- showed standard error. preprocessing data augmentation. used simple preprocessing data augmentation scheme. input length network training phase padded zeros side training sound randomly cropped section padded sound. mixed cropped sounds random ratio using learning. testing phase also padded zeros side test sound cropped sections padded sound regular intervals. input crops network averaged softmax outputs. input data regularized range dividing full range -bit recordings. learning settings. models trained nesterov’s accelerated gradient using momentum weight decay mini-batch size difference learning settings standard learning number training epochs. learning tends require training epochs standard learning standard learning tends overﬁt many training epochs. validate comparison ﬁrst identiﬁed appropriate standard learning setting network dataset doubled number training epochs using learning. later section examine relationship number training epochs performance. table comparison standard learning learning. performed k-fold cross validation using original fold settings. performed cross-validation times esc- esc- datasets show standard error. learning improves performance models datasets even strong data augmentation scheme. envnet-v trained learning performs best surpasses human performance esc-. first trained various types existing networks. selected envnet network using convolutions soundnet networks using convolution logmel-cnn network using log-mel features. logmel-cnn improved version logmel-cnn designed which convolutional layers apply batch normalization output remove dropout note networks training codes implementation using chainer results summarized upper half table learning improved performance networks datasets. performance esc- esc- urbansoundk improved .–.% .–.% .–.% respectively. show training curves envnet esc- fig. note curves show average trials. standard learning. main differences envnet envnet-v follows envnet uses sampling rate input waveforms whereas envnet-v uses khz; envnet consists layers whereas envnet-v consists layers. detailed conﬁguration provided appendix. results also shown upper half table training curves esc- given fig. performance also improved learning degree improvement greater networks error rate envnet-v trained learning lowest esc- urbansoundk among models including logmel-cnn uses powerful hand-crafted features. moreover error rate esc- comparable human performance reported piczak point envnet-v well designed learning successfully elicits true value deep network. compared performances standard learning using stronger data augmentation scheme. addition zero padding random cropping used scale augmentation factor randomly selected gain augmentation factor randomly selected scale augmentation performed zero padding using linear interpolation gain augmentation performed inputting network results envnet-v shown lower half table training curves esc- given fig. learning performance signiﬁcantly improved even used strong data augmentation scheme. furthermore performance esc- surpasses human performance learning performs well various networks datasets data augmentation schemes using learning always beneﬁcial. investigated relationship performance number training epochs previously described experiments conducted using different numbers training epochs fig. shows error rate envnet esc- esc- various numbers training epochs. ﬁgure shows standard learning approximately training epochs sufﬁcient esc-. however number insufﬁcient learning. although learning performed better standard learning epochs improved performance achieved using training epochs however number training epochs small performance learning lower standard learning. learning always improves performance long sufﬁciently large number training epochs. additionally number training epochs needed would become large many classes. understand part important learning conducted ablation analysis. trained envnet esc- using various settings. results shown table also performed -fold cross-validation times show standard error. mixing method. compared mixing formula calculation method sound pressure levels shown table proposed mixing method using eqn. a-weighting performed best. considering difference sound pressure levels important learning method used deﬁne sound pressure levels also effect performance. label. compared different labels applied mixed sound. shown table proposed ratio label performed best. applied single label dominant sound trained model using softmax cross entropy loss performance improved compared standard learning. applied multi-label trained model using sigmoid cross entropy loss performance better using single label. however performance worse using ratio label cases. model learn between-class examples efﬁciently using ratio label. number mixed classes. investigated relationship performance number sound classes mixed. table means mixed sounds belonging class similar takahashi means completely randomly selected sounds mixed; sometimes sounds class. means mixed three sounds belonging different classes probabilities respectively. mixed three sounds generated mixing ratio mixed three sounds using method extended version eqn. three classes. shown table proposed performed best. also achieved good performance. interesting note performance worse despite larger variation training data. believe important factor training data variation rather enlargement fisher’s criterion regularization positional relationship among feature distributions. mixing sounds leads increased training data variation expect cannot efﬁciently achieve them. mix. finally investigated occurs examples within network. input sounds mixed model performed forward calculation mixing point. mixed activations sounds mixing point performed rest forward calculation. mixed activations simply shown table performance tended improve mixed examples layer near input layer. performance best mixed input space. mixing input space best choice performs best also require additional forward/backward computation easy implement. proposed novel learning method deep sound recognition called learning. method improved performance various networks datasets data augmentation schemes. moreover achieved performance surpasses human level constructing deeper network named envnet-v training learning. learning simple powerful method improves various sound recognition methods elicits true value large-scale networks. furthermore learning innovative discriminative feature space learned betweenclass examples without inputting pure examples. assume core idea learning generic could contribute improvement performance tasks modalities. jort gemmeke daniel ellis dylan freedman jansen wade lawrence channing moore manoj plakal marvin ritter. audio ontology human-labeled dataset audio events. icassp kuba łopatka paweł zwan andrzej czy˙zewski. dangerous sound event recognition using support vector machine classiﬁers. advances multimedia network information system technologies table shows detailed learning settings standard learning. trained model beginning learning rate initial divided learning rate epoch listed schedule. improve convergence used smaller learning rate ﬁrst warmup epochs. terminated training epochs epochs. doubled epochs schedule using learning mentioned paper. table shows conﬁguration envnet-v used experiments. envnet-v consists convolutional layers fully connected layers max-pooling layers. sampling rate standard recording setting higher resolution existing networks order rich high-frequency information. basic idea motivated envnet advantages successful networks incorporated. first extract short-time frequency features ﬁrst temporal convolutional layers pooling layer second swap axes convolve time frequency domains later layers part hierarchically extract temporal features stacking convolutional pooling layers decreasing kernel size similar manner soundnet furthermore stack multiple convolutional layers small kernel size similar manner extract rich features. finally produce output predictions fc–fc following softmax activation. single output prediction calculated input samples padding convolutional layers. apply relu activation hidden layers batch normalization output conv–conv. also apply dropout output weight initialization convolutional layers. initialize weights fully", "year": "2017"}