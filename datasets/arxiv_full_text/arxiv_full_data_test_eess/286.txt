{"title": "Informed Group-Sparse Representation for Singing Voice Separation", "tag": "eess", "abstract": " Singing voice separation attempts to separate the vocal and instrumental parts of a music recording, which is a fundamental problem in music information retrieval. Recent work on singing voice separation has shown that the low-rank representation and informed separation approaches are both able to improve separation quality. However, low-rank optimizations are computationally inefficient due to the use of singular value decompositions. Therefore, in this paper, we propose a new linear-time algorithm called informed group-sparse representation, and use it to separate the vocals from music using pitch annotations as side information. Experimental results on the iKala dataset confirm the efficacy of our approach, suggesting that the music accompaniment follows a group-sparse structure given a pre-trained instrumental dictionary. We also show how our work can be easily extended to accommodate multiple dictionaries using the DSD100 dataset. ", "text": "elementwise -norm encourages matrix sparse regularizer dominates area research known sparse coding frequently used audio separation another attractive regularizer low-rank regularizer trace norm singular values employed favor low-rank solutions regularizer often seen singing voice separation recent years last least informed audio source separation want fuse external annotations ﬁnal optimized solution helpful annotations close correct solution requirement following regularizer magnitude spectrogram denotes annotations annotations obtained corresponding musical scores speciﬁc techniques tracking vocal melody contour. evidenced above regularization quite versatile incorporate model assumptions model answers problem itself. still information packed regularizer dictionary related work below. abstract—singing voice separation attempts separate vocal instrumental parts music recording fundamental problem music information retrieval. recent work singing voice separation shown low-rank representation informed separation approaches able improve separation quality. however low-rank optimizations computationally inefﬁcient singular value decompositions. therefore paper propose lineartime algorithm called informed group-sparse representation separate vocals music using pitch annotations side information. experimental results ikala dataset conﬁrm efﬁcacy approach suggesting music accompaniment follows group-sparse structure given pretrained instrumental dictionary. also show work easily extended accommodate multiple dictionaries using dataset. served mixtures known source separation successfully applied various ﬁelds including communications medical imaging audio inverse problem well-posed unique solution depends data continuously. speciﬁcally singing voice separation separate singing voice instrumentals numerous applications music information retrieval unfortunately case microphone sources unique solution mathematically impossible monaural source separation generally ill-posed prevalent approach ill-posed problem minx formulate regularizer incorporates prior assumptions manuscript received month revised month accepted month date publication month date current version month associate editor coordinating review manuscript approving publication prof. xxxxxxxx xxxxxxxx. authors research center information technoltakshunlike traditional rpca robust gross errors. music spectrograms assume instrumentals repetitive vocals sparse rpca applied problem assumption reasonable musical instruments tend relatively stable regular harmonic patterns sing note time. main drawback approach observation many empty rows representation promising strategy inverse problem encourage sparsity given instrumental dictionary. together idea informed separation incorporating vocal annotations arrive following formulation denotes -norms rows sparsity kind group sparsity call informed group-sparse representation case vocal annotations unavailable zero simply call group-sparse representation observation strengthened fact group sparsity successfully applied audio processing models solve since norms nonsmooth. moreover additional equality constraint satisﬁed. case alternating direction method multipliers applied. admm works ﬁrst rewriting constraint augmented lagrange function updating variable alternating fashion convergence. although convergence admm fully proven often converges practice thus solve ﬁrst introduce auxiliary variables alternating updates rewrite optimization problem follows resulting sparse matrix often contains instrumental solo percussion partial solution problem incorporate reliable annotations sparse part using informed rpca follows present informed group-sparse representation model section experimental results section iii. extension multiple dictionaries also described tested conclude section jazz popular music well known chord symbols enough compactly represent harmonic structure piece. motivate representation begin simple chord sequence c-g-f-g-c instrumental part chord notations). learned dictionary chords chords represented melody annotations long feature datasets mirk ikala unavailable approximations still obtained using existing pitch tracking algorithms melodia evaluate performance gsri source separation competition dataset called ikala dataset dataset contains -second mono clips humanlabeled vocal pitch contours. instrumentals vocals mixed signal-to-noise ratio. randomly select songs training leaving songs test set. songs downsampled reduce memory usage short-time fourier transform -point hann window overlap used obtain spectrograms magnitude spectrogram gsri separated components reconstructed inverse stft using original phase vocal annotations ﬁrst transform human-labeled vocal pitch contours time-frequency binary mask. authors proposed harmonic mask similar passes integral multiples vocal fundamental frequencies vocal fundamental frequency time order harmonic width mask simply deﬁne vocal annotations denotes hadamard product. experimental setup shown fig. algorithms compared summarized table methods require prior training. completeness propose informed simply replacing norm trace norm. resulting subproblem minj solved singular value thresholding convergence criteria appliuse non-negative sparse coding spams toolbox train instrumental dictionary. given input frames nnsc learns dictionary solving following joint optimization problem solutions obtained analogously. finally update lagrange multipliers algorithm linear time rely uses -norm instead trace norm. given input rm×n rm×k assume assume number iterations small running time algorithm following iteration obtain nondecreasing sequence pure admm however higher values faster convergence practice. faster variant known inexact augmented lagrangian method dizi dizi interpreted magnitude spectrograms former represents instrumentals whole latter represent decomposed components associated dictionary. call informed multiple-group-sparse representation test whether multiple dictionaries feasible idea dataset contains songs training testing. theme restrict pop/singer-songwriter subset. song contains four sources perform either mgsri train dictionaries bass drums other respectively. solving instrumentals whole used comparison. reduce computations downmix mono downsample pitch contour labels create running melodia ground truth vocals. eliminate possible effect dictionary size train gsri dictionary atoms. choose paper proposed novel gsri method incorporates instrumental dictionary vocal annotations inform source separation process. experimental results shown gsri achieves best performance terms instrumental gnsdr gsdr gsir running time making gsri best candidate desoloing applications. also successfully extended gsri multiple-dictionary case. conclusion experiments shown group sparsity achieves comparable results low-rankness dictionary efﬁcient manner. instrumentals vocals separation performance measured eval toolbox version terms source-to-distortion ratio source-to-interferences ratio sources-to-artifacts ratio higher values indicate better separation. also compute normalized improvement using initial mixture baseline report average result denoted preﬁx test set. important measure gnsdr measures overall performance improvement. addition also report total running time algorithm system ram. make several observations results running times shown table first informed algorithms clearly outperforms uninformed counterparts ascertaining usefulness informed separation. second performance gsri lrri comparable gsri performing slightly better music accompaniment part lrri performing slightly better vocal part. third advantage learned dictionary shown superiority families rpca family music accompaniment part. means dictionary successfully learned relevant information performs better plain sinusoids. fourth running time family fastest showing speed improvement removing svds. fifth informed versions rpca slower uninformed ones case gsri iterates much faster lrri. makes gsri attractive alternatives. finally remark faster rpca applied much smaller ryyn¨anen virtanen paulus klapuri accompaniment separation karaoke application based automatic melody transcription proc. ieee int. conf. multimedia expo p.-s. huang chen smaragdis hasegawa-johnson singing-voice separation monaural recordings using robust principal component analysis proc. ieee int. conf. acoust. speech signal process. sprechmann bronstein sapiro real-time online singing voice separation monaural recordings using robust low-rank modeling proc. int. soc. music inform. retrieval conf. w.-h. tsai h.-c. automatic evaluation karaoke singing based pitch volume rhythm features ieee trans. audio speech language process. vol. nakano yoshii goto vocal timbre analysis using latent dirichlet allocation cross-gender vocal timbre similarity proc. ieee int. conf. acoust. speech signal process. vincent bertin gribonval bimbot from blind guided audio source separation models side information improve separation sound ieee signal process. mag. vol. ikemiya yoshii itoyama singing voice analysis editing based mutually dependent estimation source separation proc. ieee int. conf. acoust. speech signal process. t.-s. chan t.-c. z.-c. h.-w. chen y.-h. yang jang vocal activity informed singing voice separation ikala dataset proc. ieee int. conf. acoust. speech signal process. bryan mysore wang source separation polyphonic music interactive user-feedback piano roll display proc. int. soc. music inform. retrieval conf. liutkus j.-l. durrieu daudet richard overview informed audio source separation proc. int. workshop image anal. multimedia interactive services jeong informed source separation monaural music limited binary time-frequency annotation proc. ieee int. conf. acoust. speech signal process. c.-l. j.-s. jang improvement singing voice separation monaural recordings using mir-k dataset ieee trans. audio speech language process. vol. salamon g´omez melody extraction polyphonic music signals using pitch contour characteristics ieee trans. audio speech language process. vol. coker improvising jazz. englewood cliffs prentice-hall yuan model selection estimation regression grouped variables roy. stat. soc. vol. lef`evre bach f´evotte itakura-saito nonnegative matrix factorization group sparsity proc. ieee int. conf. acoust. speech signal process. o’hanlon nagano keriven plumbley nonnegative group sparsity subspace note modelling polyphonic transcription ieee/acm trans. audio speech language process. vol. sci. comput. vol. grave obozinski bach trace lasso trace norm regularization correlated designs advances neural information processing systems virtanen mesaros ryyn¨anen combining pitch-based inference non-negative spectrogram factorization separating vocals polyphonic music proc. isca tutorial research workshop statistical perceptual audition durrieu david richard musically motivated mid-level representation pitch estimation musical audio source separation ieee sel. topics signal process. vol.", "year": "2018"}