{"title": "Graph Sampling for Covariance Estimation", "tag": "eess", "abstract": " In this paper the focus is on subsampling as well as reconstructing the second-order statistics of signals residing on nodes of arbitrary undirected graphs. Second-order stationary graph signals may be obtained by graph filtering zero-mean white noise and they admit a well-defined power spectrum whose shape is determined by the frequency response of the graph filter. Estimating the graph power spectrum forms an important component of stationary graph signal processing and related inference tasks such as Wiener prediction or inpainting on graphs. The central result of this paper is that by sampling a significantly smaller subset of vertices and using simple least squares, we can reconstruct the second-order statistics of the graph signal from the subsampled observations, and more importantly, without any spectral priors. To this end, both a nonparametric approach as well as parametric approaches including moving average and autoregressive models for the graph power spectrum are considered. The results specialize for undirected circulant graphs in that the graph nodes leading to the best compression rates are given by the so-called minimal sparse rulers. A near-optimal greedy algorithm is developed to design the subsampling scheme for the non-parametric and the moving average models, whereas a particular subsampling scheme that allows linear estimation for the autoregressive model is proposed. Numerical experiments on synthetic as well as real datasets related to climatology and processing handwritten digits are provided to demonstrate the developed theory. ", "text": "abstract—in paper focus subsampling well reconstructing second-order statistics signals residing nodes arbitrary undirected graphs. second-order stationary graph signals obtained graph ﬁltering zero-mean white noise admit well-deﬁned power spectrum whose shape determined frequency response graph ﬁlter. estimating graph power spectrum forms important component stationary graph signal processing related inference tasks wiener prediction inpainting graphs. central result paper sampling signiﬁcantly smaller subset vertices using simple least squares reconstruct second-order statistics graph signal subsampled observations importantly without spectral priors. nonparametric approach well parametric approaches including moving average autoregressive models graph power spectrum considered. results specialize undirected circulant graphs graph nodes leading best compression rates given so-called minimal sparse rulers. near-optimal greedy algorithm developed design subsampling scheme non-parametric moving average models whereas particular subsampling scheme allows linear estimation autoregressive model proposed. numerical experiments synthetic well real datasets related climatology processing handwritten digits provided demonstrate developed theory. graph signals could stochastic nature modeled output graph ﬁlter whose input also random signal interested sampling processing stationary graph signals stochastic signals deﬁned graphs second-order statistics invariant similar time series graph setting. second-order stationary graph signals characterized well-deﬁned graph power spectrum. generated graph ﬁltering white noise graph power spectrum ﬁltered signal characterized squared magnitude frequency response ﬁlter; second-order statistics graph signals equivalently graph power spectrum essential solve inference problems graphs bayesian setting smoothing prediction inpainting deconvolution; bayesian inference problems. inference problems solved designing optimum wiener-like ﬁlters graph power spectrum forms crucial component ﬁlter designs. order compute graph power spectrum traditional methods require processing signals graph nodes. sheer quantity data scale graph often inhibit reconstruction method. therefore main question address paper reconstruct graph power spectrum observing small subset graph nodes? graphs mathematical objects used describing explaining relationships complex datasets appear commonly modern data analysis. nodes graph denote entities edges encode pairwise relationship entities. examples complex-structured data beyond traditional time-series include gene regulatory networks brain networks transportation networks social economic networks processing signals residing nodes graph taking account relationships explained edges graph recently receiving signiﬁcant amount interest. particular generalizing well drawing parallels classical time-frequency analysis tools graph data analysis incorporating irregular structure graph signals deﬁned emerging area research authors faculty electrical engineering mathematics computer science delft university technology netherlands. email {s.p.chepuri;g.j.t.leus}tudelft.nl. work supported kaust-mit-tud consortium grant osr-sensors-. conference precursor manuscript appeared ninth ieee sensor array multichannel signal processing workshop janeiro brazil june notion stationarity signals graphs related deﬁnitions found brieﬂy explained next section well. several techniques graph power spectrum estimation discussed based observations nodes. paper consider problem reconstructing second-order statistics signals graphs subsampled observations. fact reconstructing graph power spectrum instead graph signal enables subsample graph signal even without spectral priors different perspective compared subsampling graph signal reconstruction imposes spectral prior enables graph signal reconstruction. proposed concept basically generalizes ﬁeld compressive covariance sensing graph setting. paper reconstruct second-order statistics stationary graph signals observations available nodes using simple reconstruction methods least squares. contributions summarized following main results circulant graphs special case graphs circulant identiﬁability results elegant. subset nodes resulting best compression rates given so-called minimal sparse rulers. reminiscent compressive covariance sensing data reside regular support time series speciﬁc instance circulant graph. parametric approach also possible model graph power spectrum using small number parameters e.g. graph signals modeled moving average autoregressive graph ﬁlters. reconstruction second-order statistics graph signal boils estimation moving average autoregressive coefﬁcients. parameterization allows higher compression. graph power spectrum modeled using moving average graph ﬁlter secondorder statistics recovered using least squares number moving average ﬁlter coefﬁcients. graph power spectrum modeled using autoregressive graph ﬁlter autoregressive ﬁlter coefﬁcients recovered using linear least squares subsampler design proposed samplers deterministic perform node subsampling. subsampler design therefore becomes discrete combinatorial optimization problem. spectral domain moving average case subsampler designed using near-optimal greedy algorithm. however autoregressive approach sampler design depends also data thus mean squared error optimal design possible. fact restrict low-complexity linear estimator autoregressive ﬁlter coefﬁcients. nevertheless present suboptimal technique design subsampler autoregressive case well. remainder paper organised follows. preliminary concepts graph signal processing discussed section proposed least squares based reconstruction second-order statistics based subsampled observations discussed section iii. connections compressive covariance sensing time-series sensing data residing circulant graphs discussed section section graph power spectrum represented small number parameters moving average autoregressive models parameters reconstructed using least squares subsampled observations. section discuss validity results provided paper ﬁnite data records. assumption data follows gaussian distribution maximum likelihood estimator related cram´er-rao bound also derived. section design sparse sampling matrices based low-complexity greedy algorithms discussed. examples illustrate proposed framework provided section viii. finally paper concludes section notation used paper described follows. upper boldface letters used matrices overbar denotes complex conjugation denotes transpose denotes complex conjugate transpose. shorthand notation diag refers diagonal matrix argument main diagonal. diagr represents diagonal matrix identity matrix. e{·} denotes expectation operation. norm refers number non-zero entries i.e. |wn|. logarithms natural. tr{·} matrix trace operator. det{·} matrix determinant. rank denotes rank matrix. λmin{a} denotes means positive semideﬁnite matrix. denotes symmetric matrices size denotes cardinality denotes kronecker product denotes khatri-rao columnwise kronecker product refers matrix vectorization operator. full column rank tall matrix left inverse given column span null space denoted null respectively. properties frequently used paper consider dataset elements denoted live irregular structure represented undirected graph vertex {v··· denotes nodes edge reveals connection nodes i.e. i.e. indexed node graph therefore introduce operator nonzero entry denoted also nonzero zero graph-shift operator different choices include graph laplacian adjacency matrix respective variants. undirected graphs symmetric thus admits following eigenvalue decomposition provide notion frequency graph setting forms orthonormal fourier-like basis graph signals graph frequencies denoted hence graph fourier transform graph tistical time invariance stationarity signals deﬁned regular structures random graph signals made sake completeness summarize deﬁnitions follows. simplicity focus graph signals zero mean assume either known zero preprocessing data discussed section viii. generate zero-mean second-order stationary graph signals graph ﬁltering zero-mean white variance noise covariance matrix then zeromean second-order stationary graph signal modeled valid graph ﬁlter. ﬁltered signal zero mean covariance matrix deﬁned conforms second property listed deﬁnition generally graph ﬁltering second-order stationary graph signal also results second-order stationary graph signal nonnegative vector diag referred graph power spectral density graph power spectrum. formally introduce graph power spectrum following deﬁnition. second-order stationarity preserved linear graph ﬁltering. means stationary graph signals prescribed graph power spectrum generated ﬁltering white noise graph power spectrum ﬁltered signal reshaped according frequency response graph ﬁlter result graph power spectrum reveals critical information second-order stationary graph signal thus estimating graph power spectrum recovering second-order statistics graph signal useful many applications. data graph setting context graph signal processing works consider subsampling graph signal assuming spectral prior reconstruct approach principle also possible recovering second-order statistics however goal reconstruct second-order statistics computationally advantageous allows stronger compression avoid intermediate step reconstructing storing paper therefore focus recovering graph second-order statistics directly subsampled graph signals. refer problem graph covariance subsampling. extension compressive covariance sensing graph covariance subsampling non-trivial. second-order stationary signals regular support covariance matrix clear structure enables elegant subsampler design second-order stationary graph signals residing arbitrary graphs covariance matrix admit clear structure easily exploited general. spond sensing devices probes brain networks) sparse sampling scheme results signiﬁcant reduction hardware storage communications costs next reduction processing costs. although non-parametric approach cost computing order uncompressed case cost reduction prominent problems discussed later section further compute assumed true covariance matrix available practical scenario ﬁnite data records discussed section although linear system equations solved using least squares nonnegativity constraints spectral prior easily accounted solving summarized following remark. follows discuss illustrate connections compressive covariance sensing datasets reside regular structures using circulant graph also designing compression matrix much elegant circulant graphs. discrete-time ﬁnite periodic data represented using directed cycle graphs direction edge represents evolution time past future. edge directions ignored cases e.g. interested exploiting regular fourier transform dealing spatial domain underlying data time-reversible stochastic process invariant reversal time scale cases data represented using undirected cycle graph fig. circulant matrix. know circulant matrix diagonalized discrete fourier transform matrix. words graph fourier transform matrix related graph consist orthonormal vectors circulant graph-shift operators eigenvalue decomposition required compute graph fourier transform matrix model matrix introduced section iii. denote indices selected graph related entries contain distinct values matrix means that every must exist least pair elements satisﬁes difference kronecker product sets property φ)ψs full column rank hence second-order statistics estimated using subsampling nodes. here achieve compression rate similarly minimal sparse ruler elements results compression rate sparse rulers values tabulated computing minimal sparse rulers combinatorial problem known expressions. nevertheless subsamplers coprime nested sparse samplers computed using closed-form expression also valid covariance subsamplers. however minimal sparse rulers thus provide best compression rate. reconstructing second-order statistics signals residing circulant graph elegant reconstructing second-order statistics stationary time-series. design subsamplers general graphs however challenging. subject section vii. section focus parametric representation graph power spectrum. particular focus moving average autoregressive parametric models. typically model order much smaller length graph signal since recover parameters much stronger compression achieved. also means that need store transmit fewer parameters could used generate realizations second-order stationary graph signals parametric methods viewed alternative approach going graph spectral domain avoided instead processing done directly graph vertex domain. before assume stationary graph signal generated graph ﬁltering zero-mean unit-variance white noise. recall section impose structure graph ﬁlter assume graph ﬁlter ﬁnite impulse response all-zero form moving average graph signal order g-ma coefﬁcients {hk}l− length-l vector collects g-ma coefﬁcients moving average models particularly useful represent smooth graph power spectrum expression basically means express covariance matrix polynomial graph shift operator min{l unknown expansion coefﬁcients {bk}q− collected vector completely characterize covariance matrix words assume linear parametrization covariance matrix using hermitian matrices means that length entries related g-ma parameters arrive simple least squares estimator ignore structure therefore slight abuse notation henceforth refer g-ma coefﬁcients. depending shape power spectrum much smaller number graph nodes thus allowing higher compression. case value recalling degree minimal polynomial matrices although knowing moving average ﬁlter coefﬁcients equivalent knowing might interesting study relation power spectrum relate vector vector using matrix-vector accounts kronecker structure unknowns solved using algebraic methods developed introducing rank- matrix solve using standard rank relaxation techniques solving system non-linear equations trival therefore follows develop technique g-ar modeling well graph sampling g-ar parameters recovered using non-iterative linear estimators. using notation describe speciﬁc subsampling scheme adopt g-ar models explain later advantage particular subsampling scheme. suppose observe graph nodes sparse subsampling matrix }k×n denote containing indices subsampled nodes furthermore also observe nodes -hop neighborhood nodes {φp}p speciﬁcally observe nodes matrix also total number observations gather. sampling scheme inspired extend reconstructing second-order statistics recognizing fact compressed observations satisfy g-ar model. sake presentation make abstraction redundancies observations arise nonzero diagonal entries powers shift-operator overlapping nodes within different neighborhoods. note subsampling scheme g-ar model different subsampling schemes discussed sections observe subset nodes related neighborhood well. example suppose node degree acquire second equality structure shift operator operates neighboring nodes thus expressed column selection operation ×kk. choice particular subsampling previously used equations related covariance matrix i.e. φrxφh resulted equations unknowns. addition this since access {yk}p also equations corresponding covariances observations {yk}p results following system equations every node least neighbor picking node would already lead overdetermined system. words recover g-ar spectrum amounts observing nodes. example recall cycle graph fig. nodes every node degree two. order recover g-ar parameters graphs need observe least nodes using technique. depending graph scheme might lead compression nodes might neighborhoods. words proposed scheme useful sparse graphs small estimate seen sections compressed covariance matrix special structure parameterized small number parameters section provide least squares estimator maximum likelihood estimator cram´er-rao lower bound ﬁnite data records scenario. therefore summarize results derived paper inﬁnite data records also valid scenarios ﬁnite data records. furthermore least squares problem also solved constraint leads constrained least squares problem least squares estimators derived thus assume data distribution reasonable data probability density function. follows discuss special case observations gaussian distributed. suppose compressed data consists realizations sequence independent identically distributed gaussian random vectors {y}ns length-k vector cram´errao bound matrix inverse fisher information matrix. entry fisher information matrix given seen design subsampling matrix crucial reconstruction graph secondorder statistics. theorem know conditions subsampling matrix valid covariance subsampler still designed. alternatively random compression matrices drawn certain probability space used almost surely satisfy conditions theorem however might practical graph setting random compression matrices usually dense nature compute linear combinations uncompressed graph signals made available central location. hand choose sparse sampling matrix essentially node selection subsampled graph signals processed. therefore follows develop algorithm design sparse subsampling matrix. consider structured sparse sampling matrix }k×n entries matrix determined structured subsampling matrix diagr }k×n guided component selection vector indicates subsection design subsampling matrix estimators based spectral domain approach vertex domain parametric moving average model observation matrices cases share common structure. particular convex relaxation boolean nonconvex problem cost functions relaxed solved using convex optimization express convex optimization problem introduce auxiliary variable related length-n vector vec. since diag diag diag write relaxing boolean constraints constraints cardinality constraint ℓ-norm constraint rank- constraint obtain following optimization problem submodular greedy optimization involved complexity solving convex relaxed problem keeping mind large scale problems arise graph setting focus optimization problem submodularity notion based property diminishing returns useful solving discrete combinatorial optimization problems form submodularity formally deﬁned follows. subsampling matrix spectral domain moving average approaches designed ofﬂine observation matrix depending data depends graphical model contrast optimal ofﬂine subsampler design autoregressive case possible fact observation matrix depends data choose best subset nodes requires observations nodes. side effect modeling graph autoregressive signal arrive elegant linear estimator. nevertheless suppose second-order statistics available e.g. training data estimated subsampled observations using nonparametric moving average approach approximating secondorder statistics white noise suboptimal sampler designed techniques similar section vii-a. alternatively high-complexity non-linear estimator afforded modeling graph autoregressive process using dependence observation matrix data avoided case subsampler designed ofﬂine using techniques underline algorithms provided design sparse samplers different cases also used design mean squared error optimal sparse samplers compressive covariance sensing framework words although minimal sparse rulers satisfy identiﬁability conditions reconstruct second-order statistics stationary time-series algorithms provided paper needed guarantee desired reconstruction performance. synthetic data experiments using synthetic data random sensor graph nodes generated using gspbox generated graph topology seen figure colored nodes represent value graph signal realization. graph stationary signals generated graph ﬁltering zeromean unit-variance white noise ﬁlter squared magnitude frequency response shown figure frequency fig. sampling random graphs nodes synthetic data. sampled graph nodes highlighted circles around nodes node coloring simply denotes realization graph signal. non-parametric model moving average model autoregressive model -hop neighborhood around node indicated circle observed. response instance approximated using ﬁlter coefﬁcients. shift operator graph laplacian matrix. snapshots form sample covariance matrix experiments. non-parametric model using algorithm ﬁrst design subsampler selecting rows matrix structured manner determined show figure least squares estimate graph power spectrum obtained observing nodes reasonably well true power spectrum. figure selected graph nodes indicated black circle. however particular sampling pattern seen here. example. before perform subset selection matrix structured manner using algorithm show figure least squares estimate graph power spectrum computed using observations nodes nodes sampling pattern case shown figure seen greedy algorithm selects graph nodes clustered manner moving average model assumes power spectrum smooth. parametric autoregressive approach graph power spectrum parameterized parameters. case choose graph node largest degree also observe nodes -hop neighborhood selected node; observed nodes fig. sampling m¨obius ladder circulant graph nodes. sampled graph nodes highlighted circles around nodes node coloring simply denotes realization graph signal. minimal sparse ruler based sampling sampling based submodular design spectrum minimal sparse ruler computed using greedy submodular design. shown figure example observe nodes nodes reconstruct graph power spectrum. least squares estimate g-ar power spectrum seen figure although recover parameters observe nodes -hop neighborhood every selected node figure also provide performance results based synthetic dataset. particular show different number snapshots performance estimators terms normalized mean squared error deﬁned begin with figure shows performance developed least squares estimator nonparametric approach i.e. compression. example performance loss compression reduces increases. furthermore also that although least squares estimator slope cram´er-rao lower bound achieve cram´er-rao lower bound. reduced solving weighted least squares estimator incurs additional computational cost inverting updating weighting matrix. particular scenario although full-column rank matrix figure performance moving average approach before performance loss compression also number snapshots increases performance saturates. limited ﬁlter order performance gets better increasing ﬁlter order. however increasing ﬁlter order worsens condition number might resort singular value decomposition based techniques solve least squares value assumed known. also compared non-parametric model smaller ﬁlter order less sensitive perturbations. figure reasonable performance maximum possible compression finally figure show performance autoregressive model solve using least squares. although similar behavior respect performance loss compression respect error saturation limited ﬁlter order important thing notice autoregressive model similar performance moving average model fewer parameters. synthetic dataset illustrate graph sampling theory developed circulant graphs using m¨obius ladder structure ﬁnds applications within molecular chemistry m¨obius ladder nodes shown figure graph circulant adjacency matrix shift operator. seen section circulant graphs possible elegantly compute optimal sparse samplers. minimal sparse rulers length sampling given corresponding selected nodes figure alternatively also determine sampling using algorithm show selected nodes figure question greedily designed sparse sampler compare minimal sparse ruler. answer this plot figure singular values ruler computed using greedy submodular design. example resulting spectrum sparse samplers similar greedy submodular design slightly worse condition number fig. sampling graphs weather stations. sampled graph nodes highlighted circles around nodes node coloring simply denotes realization graph signal. non-parametric model moving average model autoregressive model -hop neighborhood around node indicated circle observed. spectral covariance matrix. graph power spectrum based snapshots. markers along x-axis indicate eigenvalues adjacency matrix real dataset real dataset temperature measurements collected across different weather stations french region brittany. nearest neighbor graph constructed using available coordinates weather station node least neighbours. reconstructed graph seen figure alternatively method suggested used construct sparse graph based training data. observations weather station available. adjacency matrix shift operator example. removed mean station independently thus forcing ﬁrst moment zero artiﬁcially obtain removing mean temperature data records nearly stationary graph i.e. sample covariance matrix spectral covariance figure stationarity dataset shift operator increases processing socalled intrinsic mode functions temperature recordings instead data detailed simply mean-removed dataset here. carry experiments synthetic data. non-parametric moving average approaches samplers designed using greedy algorithm discussed section vii-a. particular non-parametric approach observe nodes nodes shown black circles figure moving average approach observe nodes recover g-ma parameters. finally autoregressive approach model graph power spectrum scalar parameter. select node largest degree indicated circle figure also observe nodes one-hop neighborhood selected node. observe nodes total case. uncompressed graph power spectrum computed available temperature measurements well least squares estimate graph power spectrum computed subsampled observations using non-parametric parametric approaches seen figure shape estimated power spectrum different approaches similar empirical graph power spectrum. real dataset concluding demonstrate potential parametric modeling well sampling graph setting example using usps dataset focus digit sake illustration. construct nearest neighbor graph fig. sampling nearest neighbor graph built using digit usps dataset. spectral covariance matrix graph power spectrum based image snapshots. markers along x-axis indicate eigenvalues laplacian matrix. realizations generated images obtained graph ﬁltering white noise. here g-ma ﬁlter coefﬁcients obtained observing pixels. seen section possible model graph power spectrum fewer parameters means need store transmit parameters achieve stronger compression rates. illustrate this perform experiment view digit usps dataset realization graph second-order stationary signal obtained graph ﬁltering white noise using graph moving average ﬁlter figure show empirical graph power spectrum computed images graph power spectrum computed using moving average method sampling pixels well quickly learn parameters interest without visiting entire training set. next based reconstructed graph power spectrum obtained sampling pixels generate realizations graph signals graph ﬁltering white noise frequency response nonnegativity constraint). realizations shown figure resulting signals shape digit corroborating signal stationary nearest neighbor graph importantly signals generated fewer parameters estimated observing small subset pixels. paper focused sampling reconstructing second-order statistics stationary graph signals. main contribution paper observing signiﬁcantly smaller subset vertices using simple least squares estimators reconstruct second-order statistics graph signal subsampled observations importantly without spectral priors. results provided generalize compressive covariance sensing framework graph setting. nonparametric approach well parametric approaches including moving average autoregressive models graph power spectrum discussed. near-optimal low-complexity greedy algorithm developed design sparse sampling matrix selects subset graph nodes. guimera mossa turtschi amaral worldwide transportation network anomalous centrality community structure cities’ global roles proc. national acad. sciences vol. shuman narang frossard ortega vandergheynst emerging ﬁeld signal processing graphs extending high-dimensional data analysis networks irregular domains ieee signal process. mag. vol. sandryhaila moura data analysis signal processing graphs representation processing massive data sets irregular structure ieee signal process. mag. vol. ottersten stoica covariance matching estimation techniques array signal processing applications digital signal processing vol. scharf statistical signal processing. chepuri leus hero learning sparse graphs smoothness prior proc. ieee international conference acoustics speech signal processing orleans mar. girault goncalves fleury semi-supervised learning graph signal mapping graph signal wiener ﬁlter interpretation proc. ieee international conference acoustics speech signal processing florence italy anis gadde ortega towards sampling theorem signals arbitrary graphs proc. ieee international conference acoustics speech signal processing florence italy tsitsvero barbarossa lorenzo uncertainty principle sampling signals deﬁned graphs proc. asilomar conference signals systems computers california nov. varma chen kovaˇcevi´c spectrum-blind signal recovery graphs proc. ieee international workshop comp. adv. multi-sensor adaptive processing cancun mexico dec. chen varma sandryhaila kovaˇcevi´c discrete signal processing graphs sampling theory ieee trans. signal process. vol.", "year": "2017"}