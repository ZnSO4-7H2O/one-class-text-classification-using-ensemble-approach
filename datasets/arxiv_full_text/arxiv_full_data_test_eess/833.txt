{"title": "Automatic Minimisation of Masking in Multitrack Audio using Subgroups", "tag": "eess", "abstract": " The iterative process of masking minimisation when mixing multitrack audio is a challenging optimisation problem, in part due to the complexity and non-linearity of auditory perception. In this article, we first propose a multitrack masking metric inspired by the MPEG psychoacoustic model. We investigate different audio processing techniques to manipulate the frequency and dynamic characteristics of the signal in order to reduce masking based on the proposed metric. We also investigate whether or not automatically mixing using subgrouping is beneficial or not to perceived quality and clarity of a mix. Evaluation results suggest that our proposed masking metric when used in an automatic mixing framework can be used to reduce inter-channel auditory masking as well as improve the perceived quality and perceived clarity of a mix. Furthermore, our results suggest that using subgrouping in an automatic mixing framework can be used to improve the perceived quality and perceived clarity of a mix. ", "text": "abstract—the iterative process masking minimisation mixing multitrack audio challenging optimisation problem part complexity non-linearity auditory perception. article ﬁrst propose multitrack masking metric inspired mpeg psychoacoustic model. investigate different audio processing techniques manipulate frequency dynamic characteristics signal order reduce masking based proposed metric. also investigate whether automatically mixing using subgrouping beneﬁcial perceived quality clarity mix. evaluation results suggest proposed masking metric utilised automatic mixing framework reduces inter-channel auditory masking well improves perceived quality perceived clarity mix. furthermore results suggest using subgrouping automatic mixing framework also improve perceived quality perceived clarity mix. index terms—auditory masking; multitrack mixing; mpeg; equalization; dynamic range processing; subgrouping; numerical optimisation; perceived emotion tory system occurs whenever presence strong audio signal makes temporal spectral neighbourhood weaker audio signals imperceptible frequency masking occur stimuli simultaneously presented auditory system. relative shapes masker’s maskee’s magnitude spectra determine extent presence certain spectral energy mask presence spectral energy. temporal masking characteristic auditory system sounds hidden masking signal occurring masked signal. effectiveness temporal masking attenuates exponentially onset offset masker simpliﬁed explanation masking phenomena strong noise tone masker creates excitation sufﬁcient strength basilar membrane. excitation pattern neural representation pattern resonance basilar membrane caused given sound area around characteristic frequency masker’s signal location effectively blocks detection weaker signals examples frequency temporal masking shown figure figure respectively. fig. schematic drawing illustrate characterise regions within pre-masking simultaneous masking post masking occur. note post-masking uses different time origin premasking simultaneous masking. process mixing sound sources inevitably mask another reduces ability fully hear distinguish sound source. partial masking occurs whenever audibility sound degraded presence content sound still perceived. masking reduction involves trial error adjustment relative levels spatial positioning frequency dynamic characteristics individual audio tracks. practice masking reduction process embodies iterative search process similar numerical optimisation theory masking reduction therefore thought optimisation problem provides insight methodology automatic mixing order reduce masking. given certain controls multitrack ﬁnal output thought optimal solution system equations describe masking relationship audio tracks multitrack recording. frequency processing dynamics processing subgrouping three main aspects masking minimisation investigation. equalisation effectively reduce masking manipulating spectral contour different instruments less frequency domain interference audio track. dynamic range processing nonlinear audio effect alter dynamic contour signal order reduce masking time. classic operations dynamics processing equalisation control separate domains audio signal. combined ﬁltering dynamics processing implies larger control space reduce masking much precisely effectively frequency time aspects using either processor alone subgrouping allows localise application frequency dynamics processing speciﬁc instrument types would typically share similar timbre dynamic range spectral content. principle aspects automating masking reduction process creation model masking multitrack audio correlates well human perception development audio techniques algorithms reduce masking without causing unpleasant audio artefacts. article present novel intelligent mixing system uses psychoacoustic model numerical optimisation technique subgroups. based this propose novel masking metric multitrack audio. selected control parameters equalisation dynamic range compression effects optimised iteratively using particle swarm algorithm toward desired described masking metric. test hypothesis whether using subgroups beneﬁcial automatic mixing systems. also test subgrouping impact perceived emotion recording. formal subjective evaluation form listening experiment conducted assess system performance mixes produced humans. structure paper summarised follows. section discuss background masking metrics subgrouping measuring emotional response music. section describes methodology formed automatic multitrack masking minimisation system conducted subsequent listening test. section performance evaluations presented ﬁnally background perceptual models capable predicting masking behaviour received much attention years particularly ﬁelds audio coding masked threshold signal approximated inform bitallocation algorithm. proposes method adjusting masking threshold audio coding make decoded signal robust quantisation noise unmasking. masking models also often used image audio watermarking similar models used distortion measurement sound quality assessment nonlinear time-domain ﬁlter banks used allow excitation pattern calculation whilst maintaining good temporal resolution. another simple masking model used remove perceptually irrelevant timefrequency components. advanced signal processing masking models closer physiology include single-band model accounts number frequency temporal masking experiments ’modulation ﬁlter bank’ subsequently added analyse temporal envelope output gammatone ﬁlter whose output half-rectiﬁed pass ﬁltered simulating frequency place transform across basilar membrane receptor potentials inner hair cells building upon proposed modulation ﬁlter bank masking model called computational auditory signal-processing perception model presented accounts various aspects masking modulation detection however mentioned models output masked threshold measurement masking considered situation signal fully masked. explored partial loudness mobile telephone ring tones variety everyday background sounds e.g. trafﬁc based psychoacoustic loudness models proposed comparing excitation patterns maskee masker introduced quantitative measure masking multitrack recording. similarly masked-to-unmasked ratio related original loudness instrument loudness proposed previous attempts perform masking reduction audio mixing include aimed achieve equal average perceptual loudness frequencies amongst multi-track channels based assumption individual tracks overall equal loudness across frequency bands. however assumption valid approach directly address spectral masking. designed simpliﬁed measure masking based best practices sound engineering introduced automatic multitrack equalisation system. however simple masking measure might correlate well perception human hearing evident evaluation. applied partial loudness model adjusts levels tracks within multitrack order counteract masking. similar techniques investigated optimisation framework however performed basic level number different multitrack masking metrics available combined perform cross-analysis multitracks. quantify amount masking investigating interaction excitation patterns maskee masker maskee individual track masker combination tracks multitrack. done utilising cross-adaptive architecture proposed masking metrics discuss make cross adaptive architecture. however ﬁrst masking metrics discuss based perceptual loudness work moore ﬁnal masking metric discuss based spectral magnitude. procedure derive loudness partial loudness track multitrack summarised follows multitrack consists sources prerecorded onto tracks. track therefore contains audio signal source given transformation outer middle inner simulated ﬁxed linear ﬁlter. multi-resolution short time fourier transform comprising parallel ffts performs spectral analysis input signal. spectral frame ﬁltered bank level-dependent roex ﬁlters whose centre frequencies range khz. spectral ﬁltering represents displacement distribution tuning characteristics across human basilar membrane. account masking excitation patterns target track masker respect calculated described masker supplementary accompanying tracks related target track given sound heard isolation intensity represented excitation pattern converted speciﬁc loudness represents loudness output auditory ﬁlter. partial masking scenario concurrent masker partial speciﬁc loudness calculated. detailed mathematical transformations obtain speciﬁc partial speciﬁc loudness found across whole scale produces total unmasked masked instantaneous loudness. instantaneous loudness frames smoothed reﬂect time-response auditory system described averaged scalar perceptual loudness partial loudness illustrated figure lphon loudness maskee isolation lphon partial loudness maskee masked rest mix. loudness unit phon opposed sones used moore’s original loudness model discussed initially. authors subsequently gating procedure measure masking instrument actively playing. work sina authors auditory model measure masking. based measurement spectral magnitude. amount masking track frequency time causes track frequency time given early stages mixing editing process multitrack engineer typically group instrument tracks subgroups example would grouping guitar tracks guitar tracks vocal tracks vocal tracks. subgrouping speed workﬂow allowing engineer manipulate number tracks once instance changing level drums fader movement instead changing level drum track individually note also achieved voltage controlled ampliﬁer group concept similar subgroup speciﬁed faders moved unison ‘master fader’ without ﬁrst summing channels bus. however subgrouping also allows processing cannot achieved manipulation individual tracks. nonlinear processing dynamic range compression equalisation applied subgroup processor affect sources differently would applied every track individually. example typical subgrouping setup seen figure little known engineers choose apply audio processing techniques studies looking problem subgrouping touched brieﬂy authors tested assumption gentle bus/mix compression helps blend things better found true give much insight subgrouping generally used. authors explored potential hierarchical approach multitrack mixing using instrument class guide processing techniques. however providing deeper understanding subgrouping paper. subgrouping also used similarly applied drums instrument types explored. although subgrouping well documented used extensively areas audio engineering production. previous work investigated subgrouping implemented mixing audio utilised recommendations course study. number different methods measuring emotional responses music. self-report three methods often used measuring emotional responses music physiological measurements facial expression analysis. perhaps common self-report method listeners rate extent perceive feel particular emotion happiness. techniques assess affect using likert scale choosing visual representation emotion feeling. example visual representation selfassessment manikin user asked rate scales arousal valence dominance based illustrative picture. another method present listeners list possible emotions indicate hear. examples differential emotion scale positive negative affect schedule panas participants requested rate words characterize emotion feeling. differential emotion scale contains words emotions. would examples categorical approach mentioned previously methods presented constitute different types self-report lead concerns validity results response bias. fortunately people tend attuned feeling furthermore gabrielsson came conclusion self-reports best natural method study emotional responses music conducting review empirical studies emotion perception however caveat retrospective self-report ‘duration neglect’ listener forget momentary point intensity emotion attempted measured. main hypothesis test proposed automatic mixing system used reduce amount auditory masking occurs multitrack subsequently improve perceived quality. also tested hypotheses using subgroups generating automatic improve perceived quality clarity subgroups automatic mixing system impact perceived emotions listener automatic mixes subgroups. hypotheses evaluated examination objective performance subjective listening tests. audio processing control parameters subgrouping multitrack song used experiment created subgroups based typically grouped instrumentation vocals drums guitars etc. similar approach used allowed optimisation mixing technique presented create number sub-mixes create ﬁnal mixing submixes together. essentially gave multi-layer optimisation framework. subgrouping used automatic optimisation mixing technique applied audio tracks once. loudness normalisation applied optimisation mixing technique employed loudness normalisation audio track multitrack. performed loudness normalisation audio tracks using itu-r speciﬁcation audio track loudness normalised lufs except case lead vocal loudness normalised lufs. made lead vocal louder everything else usually important audio track within subgroup mixed also loudness normalised lufs except case vocal subgroups would lufs. equalisation designed six-band equaliser applied optimisation process. different cascaded second-order ﬁlters designed cover typical frequency range used mixing. ﬁlter speciﬁcation shown table dynamic range compression digital compressor model employed approach feed-forward compressor smoothed branching peak detector typical parameters dynamic range compressor includes threshold ratio attack release times make-up gain. case adjusting dynamic signal reduce masking optimisation values threshold ratio attack release control parameters optimised. since dynamics main focus rather level make-up gain track compensate loudness differences dynamic processing. make-up gain track given pattern threshold partitions. masking threshold determined providing offset excitation pattern value offset strongly depends nature masker. tonality indices evaluated partition used determine offset renormalised convolved signal energy converts global masking level. values offset interpolated based tonality index noise masker frequency-dependent value deﬁned standard tonal masker. interpolated offset compared frequency dependent minimum value minval deﬁned mpeg- standard larger value used signal noise ratio. standard noise masking tone tone masking noise partitions. offset obtained weighting maskers estimated tonality index. partitioned threshold derived current frame compared previous frames threshold quiet. maximum three values chosen actual threshold. energy scale-factor band threshold scale-factor band calculated described similar way. thus ﬁnal masker-tosignal ratio scale-factor band deﬁned cross-adaptive mpeg masking metric adapt masking threshold algorithm mpeg audio coding multitrack masking metric based cross-adaptive architecture ﬂowchart system illustrated figure masking metric mpeg psychoacoustic model audio coding audio compression algorithms compress audio data large part removing acoustically irrelevant parts audio signal. mpeg psychoacoustic model plays central role compression algorithm. model produces time-adaptive spectral pattern emulates sensitivity human sound perception system. model analyses signal computes masking thresholds function frequency block diagram figure illustrates simpliﬁed stages involved psychoacoustic model. procedure derive masking thresholds summarised follows. complex spectrum input signal calculated using standard forward fft. tonality index function frequency calculated based local peaks audio power spectrum. index gives measure whether component tone-like noiselike. index interpolated pure tonemasking-noise noise-masking-tone values. tonality index based measure predictability tonal components predictable thus higher tonality indices strong signal component reduces audibility weaker components critical band also neighbouring bands. psychoacoustic model emulates applying spreading function spread energy critical band across bands. total masking energy audio frame derived convolution spreading function maskers. spreading function used model given objective function numerical optimisation approach used order derive optimal inputs would result balanced mix. deﬁning objective functions number parameters deﬁned used optimisation algorithm. denote total number tracks multitrack denote total number control parameters. masking metrics given describe amount masking track function control parameters note represents whole control parameters tracks. values tend multitrack inﬂuences complexity nonlinearity perception masking. changes control parameter track affect masking particular track also masking tracks. optimisation problem nonlinear non-convex formulation information available optimisation routine returns function values. thus particle swarm optimisation approach used guide optimisation routine solution space. experiment setup participants twenty four participants good hearing recruited. male female ages ranged participants degree critical listening skills participant knew critical listening involved trained previously worked studio. stimuli songs used experiment different sec. mono mixes song. mixes automatically generated using proposed algorithm used subgroups not. straight threshold track caused accompanying tracks. denote mathematical transformations mpeg psychoacoustic model derive masking threshold. thus compute numerical optimisation algorithm multitrack masking minimisation process treated optimisation problem concerned minimising vector-valued objective function described masking metric. systematically varies input variables control parameters audio effect applied computes value function error objective function within tolerance value reaches maximum number iterations masking metric reduced zero. function bounds minimum maximum values used band equaliser dynamic range compressors based audio engineering literature consulted professional practitioner audio engineering ﬁeld detailed table instrument gain bands subgroup gain bands instrument ratio subgroup ratio instrument threshold subgroup threshold instrument attack subgroup attack instrument release subgroup release used smaller minimum maximum equalisation gains mixing subgroups together since majority inter-channel auditory masking would removed mixing individual instrument tracks. audio tracks. finally human mixes selected quality high quality song determined previous experiment. human mixes created using standard audio processing tools available tools able without added reverb mixes created intention producing best possible mix. songs sourced open multitrack testbed loudness normalised mixes using itu-r speciﬁcation avoid bias towards mixes louder others. song name genre number tracks number subgroups many instrument type shown table pre-experiment questionnaire provided pre-experiment questionnaire. preexperiment questionnaire asked simple questions related hearing musical experience music production experience music genre preference participant’s conﬁdence critical listening skills. also question respect tired started study. participant indicated tired asked attempt experiment later time rested. experiment types half participants experiment type half experiment type experiment type parts second part common both. required participants rate mixes song listened terms preference. required participants rate mixes song listened terms well could distinguish sources present participant listen compare automatically generated mixes. rate perceived emotion along three scales. scales arousal valence tension songs mixes used experiment presented random order. setup user interface experiment either took place dedicated listening room university external music studio environment. participant studio desk front laptop used experiment. audio heard either pair loudspeakers sennheiser headphones participant could adjust volume audio comfortable level. results section present results related optimisation procedure used generate automatic mixes. furthermore present results subjective evaluation automatic mixes mixes rated preference clarity participant’s perceived emotion. placed mixed unmixed audio used experiment online repository https //goo.gl/ufed. results optimised automatic mixing figure present results optimisation process used meantime mixing different subgroups mixing subgroups mixing tracks together one. x-axis graph indicates many iterations optimisation process occurred solution found found. y-axis indicates masking present. results four songs analysed follow similar trend. vocal tracks mixed amount inter-channel masking occurred similar tracks mixed took less time optimal solution. suggests inter-channel masking occurred among vocalists. expected subgroups less tracks generally took less iterations converge. drums instrument type took iterations converge exception lead partly explained number sources drums subgroup since often took iterations mixing tracks. summarise results figure table present many iterations required type song change masking occurred average amount masking remained. numbers parentheses number tracks used average meantime tracks meantime subgroups lead tracks lead subgroups alone tracks alone subgroups blue tracks blue subgroups covered tracks covered subgroups subjective evaluation results preference asked half participants rate based preference results illustrated figure figure results songs used experiment organised type. ﬁgure shows mean values across participants boxes conﬁdence intervals thin vertical lines represent standard deviation. songs ordered type follows meantime lead alone blue under covered sky. mean scores summed mixes hover around never greater corresponding automatic mixes. however overlapping conﬁdence intervals summed mixes automatic mixes without subgroups. furthermore also slight overlap automatic mixes subgroups prevalent. compare automatic types song automatic mixes used subgroups preferred average automatic mixes subgroups. supports main hypothesis subgroups improving perceived quality automatic mix. however overlapping conﬁdence intervals meantime alone under covered sky. nearly cases except lead case lead automatic subgrouping scores average human quality scores also overlapping conﬁdence intervals lead types automatic human alone types automatic human under covered types automatic human figure results individual mixes taken mean across different songs. boxes conﬁdence intervals thin vertical lines represent standard deviation. trend increasing means going summed human apparent automatic mixes performed better summed mixes supports main hypothesis however slight conﬁdent interval overlap summed mixes automatic support second hypothesis clearly preference mixes subgroups. however conﬁdence interval overlap either human types. figure mean scores summed mixes never greater corresponding automatic mixes. indicates automatic mixes perceived greater clarity average summed mixes. however overlapping conﬁdence intervals summed mixes automatic mixes without subgroups. furthermore also occurred songs meantime blue compared summed automatic compare automatic types song automatic mixes used subgroups better clarity rating average automatic mixes subgroups three songs. also overlapping conﬁdence intervals four songs. comparing automatic mixes human mixes human mixes outperforming automatic mixes nearly cases except lead case lead automatic subgrouping scores average quality scores also could perceive emotional difference mixes along three affect dimensions arousal valence dominance. used results test hypothesis using subgroups emotional impact perceived emotions listener. found hypothesis true cases signiﬁcant result found illustrated figure table figure objectively show proposed intelligent mixing system able reduce amount inter-channel auditory masking occurs changing parameters equaliser dynamic range compressor audio track. mixing cases able reduce amount inter-channel masking iterations optimisation procedure. table shows reduction masking signiﬁcantly less four songs mixing subgroups versus tracks. suggests masking reduced mixing subgroups instrumentation would similar. figure present mean score type participating groups group evaluated preference group evaluated mixes clarity. automatic mixes preferred average summed mixes agrees main hypothesis. however automatic mixes never outperformed human mixes. also automatic mixes used subgroups preferred average automatic mixes subgroups. supports second hypothesis. however three cases overlapping conﬁdence intervals. figure show evidence second hypothesis true. figure trend increasing means going summed human apparent automatic mixes performed better summed mixes terms clarity supports main hypothesis reducing auditory masking. support second hypothesis preference terms clarity mixes subgroups. automatic mixes preferred average summed mixes clarity agrees main hypothesis. results show evidence proposed de-masking method provides clarity human average. however automatic subgroups performed better human mix. also overlapping conﬁdence automatic mixes human mixes respect clarity. automatic mixes used subgroups better perceived clarity average automatic mixes subgroups. supports second hypothesis. however examined clarity results individual songs occurred three songs overlapping conﬁdence intervals four songs. results clarity group higher average preference group. might suggest technique presented might better de-masking technique overall mixing technique conclusion paper described automation loudness normalisation equalisation dynamic range compression order improve overall quality reducing interchannel auditory masking. adapted extended masking threshold algorithm mpeg psychoacoustic model order measure inter-channel auditory masking. ultimately proposed intelligent system masking minimisation using numerical optimisation technique. tested hypothesis proposed intelligent system used generate automatic reduced removed majority masking present would made difﬁcult demonstrate effectiveness inter-channel auditory masking metric. process applying correct gain equalisation dynamic range settings multitrack challenging time consuming task. believe framework proposed could useful developing systems beginner amateur music producers could assistive tool giving initial settings compressors tracks reﬁned engineer. acknowledgements authors would like thank participants study epsrc funding research. would also like thank nouran zedan assistance. auditory masking improved perceived quality. paper also tested hypothesis using subgroups generating automatic improve perceived quality clarity mix. tested using subgrouping affects perceived emotion automatic mix. evaluated hypotheses subjective listening test. able show objectively subjectively novel intelligent mixing system proposed reduced amount inter-channel auditory masking occurred mixes improved perceived quality. however results match results human mixes cases. furthermore results subjective listening test implied subgrouping improves perceived quality perceived clarity automatic automatic mixes subgroups. however results suggested using subgroups little effect perceived emotion mixes. shown true cases. future work clear proposed intelligent mixing system scope improvement. could improved equalisation dynamic range compression settings changed frame frame based inter-channel auditory masking metric. currently equalisation dynamic range settings static entire track. experienced participants subjective listening test mentioned could hear this. also believe optimisation procedure could improved larger optimality tolerance tolerance reached another nonlinear solver begins using results initial conditions. examine figure many optimisation procedures satisfactory solution less iterations. reiss black partial loudness multitrack mixing audio engineering society conference international conference semantic audio audio engineering society dennis schnabel numerical methods unconstrained optimization nonlinear equations. siam pestana automatic mixing systems using adaptive digital audio effects. thesis universidade cat´olica portuguesa kennedy particle swarm optimization encyclopedia maha maher chokri blind audio watermarking scheme based neural network psychoacoustic model error correcting code wavelet domain communications control signal processing isccsp international symposium ieee plasberg kleijn sensitivity matrix using advanced auditory models speech audio processing ieee transactions audio speech language processing vol. watson clark tellegen development validation brief measures positive negative affect panas scales. journal personality social psychology vol. grewe nagel kopiez altenm ¨uller emotions time synchronicity development subjective physiological facial affective reactions music. emotion vol. eerola lartillot toiviainen prediction multidimensional emotional ratings music audio using multivariate regression models. international society music information retrieval conference gabrielsson emotion perceived emotion felt different? musicae scientiae vol. suppl schubert continuous self-report methods handbook music emotion theory research applications vol. ronan moffat gunes reiss automatic subgrouping multitrack audio proc. international conference digital audio effects case smart. focal press giannoulis massberg reiss digital dynamic range compressor design tutorial analysis journal audio engineering society vol. johnston estimation perceptual entropy using noise masking criteria acoustics speech signal processing icassp-. international conference ieee karjalainen auditory model evaluation sound quality audio systems acoustics speech signal processing ieee international conference icassp’. vol. ieee thiede treurniet bitto schmidmer sporer beerends colomes peaq-the standard objective measurement perceived audio quality journal audio engineering society vol. beerends d.-s. kroon ghitza objective assessment speech audio qualitytechnology applications ieee transactions audio speech language processing vol. balazs laback eckel deutsch time–frequency sparsity removing perceptually irrelevant components using simple model simultaneous masking ieee transactions audio speech language processing vol. ¨uschel kohlrausch quantitative model effectivesignal processing auditory system. model structure journal acoustical society america vol. kollmeier kohlrausch modeling auditory processing amplitude modulation. detection masking narrow-band carriers journal acoustical society america vol. jepsen ewert computational model human auditory signal processing perception journal acoustical society america vol. glasberg moore development evaluation model predicting audibility time-varying sounds presence background sounds journal audio engineering society vol. aichinger sontacchi schneider-stickler describing transparency mixdowns masked-to-unmasked-ratio audio engineering society convention audio engineering society perez-gonzalez reiss automatic equalization multichannel audio using cross-adaptive methods audio engineering society convention audio engineering society z¨olzer dafx digital audio effects. john wiley sons reiss intelligent systems mixing multichannel audio international conference digital signal processing ieee moore masking human auditory system audio engineering society conference collected papers digital audio bitrate reduction audio engineering society wichern robertson wishnick quantitative analysis masking multitrack mixes using loudness loss audio engineering society convention audio engineering society pestana reiss intelligent audio production strategies informed best practices audio engineering society conference international conference semantic audio audio engineering society leonard king reiss analysis evaluation audio features multitrack music mixtures international society music information retrieval conference october", "year": "2018"}