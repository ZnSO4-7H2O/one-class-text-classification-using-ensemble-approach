{"title": "Student-Teacher Learning for BLSTM Mask-based Speech Enhancement", "tag": "eess", "abstract": " Spectral mask estimation using bidirectional long short-term memory (BLSTM) neural networks has been widely used in various speech enhancement applications, and it has achieved great success when it is applied to multichannel enhancement techniques with a mask-based beamformer. However, when these masks are used for single channel speech enhancement they severely distort the speech signal and make them unsuitable for speech recognition. This paper proposes a student-teacher learning paradigm for single channel speech enhancement. The beamformed signal from multichannel enhancement is given as input to the teacher network to obtain soft masks. An additional cross-entropy loss term with the soft mask target is combined with the original loss, so that the student network with single-channel input is trained to mimic the soft mask obtained with multichannel input through beamforming. Experiments with the CHiME-4 challenge single channel track data shows improvement in ASR performance. ", "text": "technique called student-teacher learning. propose train teacher network takes beamformed signal obtained multichannel speech enhancement input predicts high-quality speech masks. then student network takes noisy signal input trained mimic mask predicted teacher network. conventionally student-teacher learning used reduce complexity network. example less complex student model fewer parameters tries mimic soft targets complex teacher model. student-teacher training used selfsupervised learning acoustic model student model tries mimic effects multichannel speech enhancement using single channel inputs. achieved training student network noisy training data input mimic soft posteriors teacher network trained enhanced speech. addition beneﬁts using soft targets compared hard targets acoustic models also shown advocated knowledge distillation. paper follows blstm-mask based beamforming proposed cross-entropy loss terms speech mask target noise mask target. speech mask predicted model also used singlechannel enhancement paper uses baseline. additional loss term based cross entropy soft mask teacher network target. effectiveness proposed method investigated using single channel track chime- dataset chime- dataset consists real simulated data common simulation data prepare clean noise targets. proposed method uses soft mask teacher network target obtained even real data real simulation data training stage. also unique aspect proposed method. additionally four different speech enhancement metrics perceptual evaluation speech quality short-time objective intelligibility measure extended stoi speech distortion ratio used part experiments discuss performance speech enhancement addition performance. section ﬁrst describes mask prediction method using binary cross entropy loss basic component paper. also describes mask-based beamformer estimate beamforming ﬁlters based estimated masks. spectral mask estimation using bidirectional long short-term memory neural networks widely used various speech enhancement applications achieved great success applied multichannel enhancement techniques mask-based beamformer. however masks used single channel speech enhancement severely distort speech signal make unsuitable speech recognition. paper proposes studentteacher learning paradigm single channel speech enhancement. beamformed signal multichannel enhancement given input teacher network obtain soft masks. additional cross-entropy loss term soft mask target combined original loss student network single-channel input trained mimic soft mask obtained multichannel input beamforming. experiments chime- challenge single channel track data shows improvement performance. index terms speech enhancement speech recognition mask estimation blstm student-teacher learning presence background noise reverberation degrades performance automatic speech recognition system. performance noise robust greatly improved using multiple microphones instead using single microphone especially mask-based beamforming techniques shown outstanding results scenario many systems chime- challenge techniques speech enhancement. example bidirectional long short-term memory neural network accurately predict speech masks given noisy spectrogram. speech noise masks turn used calculate cross power spectral density matrices noise target speech used generalized eigenvalue beamformer beamforming ﬁlter however compared success multichannel speech enhancement single-channel speech enhancement well established especially method combined speech processing applications including speaker recognition single-channel speech enhancement especially based deep neural networks studied many research groups promising performance improvement terms speech enhancement metrics hearing purposes. however often observe degradation performance single-channel enhancement preprocessing step spectral distortions induced enhancement. paper focuses single-channel speech enhancement overcome issue. idea single-channel multichannel speech enhancement using well known m-dimensional complex spectral value time frequency matrices m-dimensional complex beamforming ﬁlter estimated. paper adopts beamformer obtained maximizing expected respect frequency given equation below general well-denoised making spacial information beamforming operation compared single-channel enhanced signal introduced section paper proposes singlemultichannel speech enhancement properties designs objective function single-channel enhancement using mask obtained multichannel enhancement better soft label. dominant speech component time-frequency second noise mask denotes noise component ideal binary speech mask target ibmx frame frequency deﬁned based signal-to-noise ratio thresholding where power spectrum clean speech signal power spectrum noise signal time-frequency ideal binary noise mask ibmn also calculated similar way. given sequence -length noisy speech magnitude spectra b=|t blstm network predicts speech mask noise mask time-frequency follows note since either ﬁrst second term right hand side becomes zero. type target particular called hard label student-teacher learning knowledge distillation context. enhanced signal denotes single-channel enhancement). although single channel enhancement requires prediction speech mask noise mask used obtain noise matrix multichannel scenario discussed next section. section extends deal multichannel signal number channels. single channel mask estimation previous section applied multichannel signal corresponding speech mask noise mask channel obtained. linear interpolation weights. student model trained loss function expects learn multichannel enhancement ability within singlechannel enhancement framework. figure illustrates proposed student-teacher training paradigm. formulations discussed given parallel clean speech noise usually obtained real recording. however proposed network obtain soft target real data simply applying multichannel speech enhancement real data. scenario student-teacher loss term lossst exactly mimics teacher network. setup loss function obtained switching student-teacher loss combined loss real simulation data follows kaldi speech recognition toolkit used experiments. baseline provided chime- challenge used comparing different mask models. mask network implemented using chainer neural network toolkit cross-validation loss calculated since beamformed signal already well-denoised teacher network provides high-quality speech mask. alternatively original clean signal used input instead beamformed signal train teacher model. however problem estimating speech mask given clean signal trivial network welltrained trivial condition. cross-validation loss setup found parameter choice gave best performance amongst different values tried. interesting ﬁnding since result indicates soft targets obtained teacher model would effect performance supervised targets. also trained student model additional real data discussed section shows improvement real test owing inclusion real training data desired property real environments. channel training data also enhanced development evaluation data using baseline blstm mask included part training performance slightly better using original noisy data evaluation data slightly worse development data. development evaluation data enhanced using best student models performance improved signiﬁcantly compared using original noisy data conditions. also observed similar improvement real test trained student model real data. four different scores described section pesq stoi estoi computed several enhancement methods shown table channel clean signal track convolved room impulse response used reference signal. different masking models gave signiﬁcantly better scores four metrics compared using noisy data without enhancement although observe considerable difference scores amongst models. addition comparing tables observe clear correlations speech enhancement scores wers also suggests need careful investigation objective function blstm-based enhancement purpose. proposed training paradigm mask estimation using blstms based student-teacher training single channel speech enhancement. showed proposed studentteacher technique improved performance original noisy speech enhanced speech obtained conventional blstm masking. future work evaluate speech enhancement techniques strong backend including time delay neural network lattice-free version maximum mutual information using development data every epoch training teacher network. training stopped loss decrease anymore epochs patience model least cross-validation loss chosen. channel data used estimate target masks beamformed data. student network trained batch mode minibatch comprised frames channels utterance. compare performance different masking models ﬁrst prepared baseline would neutral enhancement method using noisy data channels training data. performed enhancement development evaluation sets ofﬁcial -channel track chime- dataset different models decoded enhanced speech systems. results experiments shown table performance teacher model better original blstm mask expected although degraded performance non-enhanced noisy speech. second experiments focused proposed student models found different conﬁgurations student models performed better teacher model. note experiment ﬁxed number epochs several models additionally investigated dependency validation loss shown figure found necessarily give best results best validation score different hyper-parameter introduced empirically found epochs cases seemed give good performance. result indicates choosing epoch based development data seems better criterion enhancement-driven vincent watanabe nugraha barker marxer analysis environment microphone data simulation mismatches robust speech recognition computer speech language vol. beerends hollier hekstra perceptual evaluation speech quality method speech quality assessment telephone networks codecs ieee international conference acoustics speech signal processing taal hendriks heusdens jensen algorithm intelligibility prediction time-frequency weighted noisy speech ieee transactions audio speech language processing vol. sept jensen taal algorithm predicting intelligibility speech masked modulated noise maskers ieee/acm transactions audio speech language processing vol. povey ghoshal boulianne burget glembek goel hannemann motlicek qian schwarz kaldi speech recognition toolkit ieee workshop automatic speech recognition understanding tokui oono hido clayton chainer nextgeneration open source framework deep learning proceedings workshop machine learning systems twenty-ninth annual conference neural information processing systems waibel hanazawa hinton shikano lang phoneme recognition using time-delay neural networks readings speech recognition. elsevier peddinti povey khudanpur time delay neural network architecture efﬁcient modeling long temporal contexts interspeech barker marxer vincent watanabe third chimespeech separation recognition challenge dataset task baselines ieee workshop automatic speech recognition understanding kinoshita delcroix gannot habets haebumbach kellermann leutnant maas nakatani summary reverb challenge state-ofthe-art remaining challenges reverberant speech processing research eurasip journal advances signal processing higuchi yoshioka nakatani robust mvdr beamforming using time-frequency masks online/ofﬂine noise ieee international conference acoustics speech signal processing heymann drude haeb-umbach neural network based spectral mask estimation acoustic beamforming ieee international conference acoustics speech signal processing vincent watanabe nugraha barker marxer analysis environment microphone data simulation mismatches robust speech recognition computer speech language vol. warsitz haeb-umbach blind acoustic beamforming based generalized eigenvalue decomposition ieee transactions audio speech language processing vol. hori chen erdogan hershey roux mitra watanabe multi-microphone speech recognition integrating beamforming robust feature extraction advanced dnn/rnn backend computer speech language vol. narayanan wang ideal ratio mask estimation using deep neural networks robust speech recognition ieee international conference acoustics speech signal processing erdogan hershey watanabe roux phasesensitive recognition-boosted speech separation using deep recurrent neural networks ieee international conference acoustics speech signal processing watanabe hori roux hershey studentteacher network learning enhanced features ieee international conference acoustics speech signal processing", "year": "2018"}