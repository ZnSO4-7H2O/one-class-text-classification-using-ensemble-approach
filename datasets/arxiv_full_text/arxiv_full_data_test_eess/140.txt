{"title": "Multilingual Adaptation of RNN Based ASR Systems", "tag": "eess", "abstract": " In this work, we focus on multilingual systems based on recurrent neural networks (RNNs), trained using the Connectionist Temporal Classification (CTC) loss function. Using a multilingual set of acoustic units poses difficulties. To address this issue, we proposed Language Feature Vectors (LFVs) to train language adaptive multilingual systems. Language adaptation, in contrast to speaker adaptation, needs to be applied not only on the feature level, but also to deeper layers of the network. In this work, we therefore extended our previous approach by introducing a novel technique which we call \"modulation\". Based on this method, we modulated the hidden layers of RNNs using LFVs. We evaluated this approach in both full and low resource conditions, as well as for grapheme and phone based systems. Lower error rates throughout the different conditions could be achieved by the use of the modulation. ", "text": "work focus multilingual systems based recurrent neural networks trained using connectionist temporal classiﬁcation loss function. using multilingual acoustic units poses difﬁculties. address issue proposed language feature vectors train language adaptive multilingual systems. language adaptation contrast speaker adaptation needs applied feature level also deeper layers network. work therefore extended previous approach introducing novel technique call modulation. based method modulated hidden layers rnns using lfvs. evaluated approach full resource conditions well grapheme phone based systems. lower error rates throughout different conditions could achieved modulation. training multilingual speech recognition systems requires special methods. low-resource conditions training systems data multiple languages improves performance. resource rich environment using data multiple languages often improve performance might event affect negatively. cases adaptation techniques required improve recognition accuracy neural networks adapted language characteristics proven perform better. similar speaker adaptation adapted networks outperform unadapted ones. however language adaptation challenging speaker adaptation collecting training data several hundred speakers possible. amount speakers enables networks generalize upon speaker properties. language adaptation order magnitude less languages available speakers. renders generalization across languages difﬁcult. another factor task itself. trained data multiple speakers language targets e.g. phone states used. different languages feature different sometimes overlapping sets targets. although speech recognition different languages different tasks related since languages spoken humans. limits sound inventory sounds produced human vocal tract. also languages potentially share sound inventories well targets network trained applying language adaptation techniques therefore enable networks generalize better. encoding language properties using e.g. lfvs like showed past allow networks trained language adaptive exploit similarities differences languages. unlike traditional gmm/hmm dnn/hmm based systems rnn/ctc based setups require explicit modelling context dependent states would need adapted. based rnns systems trained towards learning features based language properties order able better perform multilingual scenario. outlined related works section several techniques language adaptation proposed traditional systems past. proposed lfvs additional input features language adaptation. paper introduce novel approach integrating lfvs recurrent network architectures based idea meta-pi networks. effectiveness approach demonstrated series experiments showing method presented applied fulllow-resource conditions. addition also omitted pronunciation dictionary built systems using graphemes only. multilingual scenario particularly challenging network required learn pronunciations multiple languages parallel. evaluate systems token error rate primary measure trained networks. also incorporated based language model decoding determine word error rate tailed description method proposed section described experimental setup section followed results experiments paper concludes section also outline possible future work. poral classiﬁcation loss function require frame-level labels. aligns sequence tokens automatically. traditional systems phones graphemes combined used acoustic modeling units given enough training data even whole words used prior emergence neural networks systems typically built using gmm/hmm based approach. methods training/adapting systems crossmultilingually proposed handle data sparsity process clustering context-independent phones contextdependent ones also adapted account crossmultilinguality recurrent nature rnns powerful tool model sequential dependencies rendering need context-dependent targets superﬂuous. using context-independent targets advantage clustering required. resource constraint scenario data additional source languages used improve performance. dnns typically trained steps pre-training ﬁne-tuning. shown pre-training step language independent ﬁne-tuning modiﬁed multiple ways account additional languages. approach includes shared hidden layers language dependent output layers combining multiple output layers also possible feeding additional input features neural network common adaptation. popular approach speaker adaptation supply i-vectors encode speaker characteristics low-dimensional representation. speaker adaptive neural networks trained dimensional codes also extracted using neural networks called bottleneck speaker vectors past proposed similar methods adapt dnns multiple languages. ﬁrst introduced method encoding language identity using one-hot encoding enhanced method similar bsvs extracting language feature vectors vectors shown encode language properties instead language identity alone even languages seen training. past proposed methods adapting multilingual neural network based systems languages using lfvs. language feature vectors low-dimensional representation language properties extracted neural network. network trained discriminate languages based tonal features pitch typically used systems. similar architecture extraction bnfs used. architecture featured bottleneck second last layer. training output activations layer used lfvs. perform adaptation appended lfvs acoustic features similar appending i-vectors speaker adaptation. results section included error rates using method contrastive experiments denoted app. method shown reduce error rates multilingual gmm/hmm dnn/hmm well rnn/ctc based systems. appending features speaker adaptation acoustic features ﬁtting changes speaker characteristics reﬂected within signal. multiple adaptation methods like vtln fmllr directly operate acoustic features proposed. holds true i-vector based adaptation speaker adaptive systems trained directly shift input features based speaker properties language properties higher order concept contrast speaker variations. aspects based acoustics e.g. phone multiple languages language speciﬁc coloring observed degree. aspects like phonotactics different sets acoustic units require adaptation methods beyond transformation acoustic features. here adding features deeper layers potentially enables better adaptation. possibility method ﬁrst introduced part meta-pi networks. aspect meta-pi connections allow modulate output units multiplication coefﬁcient. applied language adaptation modulated outputs hidden layers lfvs. based language features output lstm cells attenuated emphasized. forces cells hidden layer learn adapt features based language properties. modulation considered related dropout training connections dropped random used network conﬁguration shown figure basic architecture inspired baidu’s deepspeech combines tdnn/cnn layers bi-directional lstm layers. output layer feed-forward layer maps output last lstm layer targets. chose number lstm cells layer multiple dimensionality lfvs. could structure hidden layer groups lstm cells containing equal amount units. output group modulated dimension lfvs. ﬁgure shows conﬁgurations method applied time. preliminary experiments determined modulating output second lstm layer result best performance. based experiments euronews corpus contains data languages. language broadcast news recordings available. experiments used combination languages based availability pronunciation dictionaries. ﬁltered utterances based length omitting short ones also removed ones transcript characters. noises annotated basic single noise marker covering different noise types ranging music background human noises. therefore omitted utterances marked noise. applying ﬁltering approx. data remained language split training test data. training created acoustic units used phones graphemes. pronunciation dictionaries created using marytts merging monolingual dictionaries mapped phone-symbols multilingual phone using deﬁnition articulatory features marytts’ language description ﬁles. addition systems based phones also trained networks using graphemes acoustic units. indicate word boundaries additional token used. multilingual bottleneck features used input features. ml-bnfs network trained using data languages input features network tonal features pitch extracted using window frame-shift. network trained using stochastic gradient descent nesterov momentum factor mini-batch updates batch size applied together batch normalization. utterances sorted ascending length stabilize training shorter utterances easier align. used based trained graphemes described featured hidden layer lstm cells. model trained limited sentences consisting training utterances acoustic model only. language models typically trained several millions sentences much training data. model provide indication whether improvements observed also result better word level speech recognition system. evaluated proposed method varying conditions availability pronunciation dictionary amount data. system without language adaptation used baseline. first used token error rate primary measure determine performance without external models. decoding procedure greedily search best path. addition also determined word error rate using first evaluated graphemes acoustic modeling units. started using network conﬁguration part lstm cells layer trained using data language adding lfvs tdnn layers lower applying method presented lowers even more. similar gains observed using full works. additional experiment increased number lstm cells layer shown table decreases absolute terms difference addition modulation becomes smaller. lstm cells layer similar improvements could achieved contrast grapheme based setup modulating layers improves performance simple addition ters grapheme based systems german turkish lower compared phone based counterparts. reason quality pronunciation dictionary created fully automatically based system. determine greedy decoding using char based english subset test data. results shown table indicate improvements also observable decoding language model. notion graphemes evaluated systems based phonemes acoustic modelling units. starting limited data improvements modulation addition observed. using available training data increasing number unlike speaker adaptation collection data covering hundreds speakers feasible collecting data many languages next impossible. optimizing adaptation method therefore maximize performance multilingual scenario. presented improved method language adaptation rnns multilingual setting. modulating outputs layer showed improvements appending lfvs input features. karel vesely martin karaﬁat frantisek grezl mithe languagelos janda ekaterina egorova independent bottleneck features proceedings spoken language technology workshop ieee. ieee. frantisek gr´ezl martin karaﬁ´at karel vesely adaptation multilingual stacked bottle-neck neural network structure language acoustics speech signal processing ieee alex graves santiago fern´andez faustino gomez j¨urgen schmidhuber connectionist temporal classiﬁcation labelling unsegmented sequence data recurrent neural networks proceedings international conference machine learning. dongpeng chen brian cheung-chi leung sunil sivadas joint acoustic modeling triphones trigraphemes multi-task learning deep neural networks low-resource speech recognition acoustics speech signal processing ieee kornel laskowski mattias heldner jens edlund fundamental frequency variation spectrum proceedings swedish phonetics conference gothenburg sweden june john hampshire alex waibel meta-pi network building distributed knowledge representations robust multisource pattern recognitio ieee transactions pattern analysis machine intelligence vol. geoffrey hinton nitish srivastava alex krizhevsky ilya sutskever ruslan salakhutdinov improving neural networks preventing co-adaptation feature detectors arxiv preprint arxiv. marc schr¨oder j¨urgen trouvain german textto-speech synthesis system mary tool research development teaching international journal speech technology vol. ilya sutskever james martens george dahl geoffrey hinton importance initialization momentum deep learning proceedings international conference machine learning thomas zenkel ramon sanabria florian metze niehues matthias sperber sebastian st¨uker alex waibel comparison decoding strategies acoustic models arxiv preprint arxiv.", "year": "2017"}