{"title": "An Efficient Human Visual System Based Quality Metric for 3D Video", "tag": "eess", "abstract": " Stereoscopic video technologies have been introduced to the consumer market in the past few years. A key factor in designing a 3D system is to understand how different visual cues and distortions affect the perceptual quality of stereoscopic video. The ultimate way to assess 3D video quality is through subjective tests. However, subjective evaluation is time consuming, expensive, and in some cases not possible. The other solution is developing objective quality metrics, which attempt to model the Human Visual System (HVS) in order to assess perceptual quality. Although several 2D quality metrics have been proposed for still images and videos, in the case of 3D efforts are only at the initial stages. In this paper, we propose a new full-reference quality metric for 3D content. Our method mimics HVS by fusing information of both the left and right views to construct the cyclopean view, as well as taking to account the sensitivity of HVS to contrast and the disparity of the views. In addition, a temporal pooling strategy is utilized to address the effect of temporal variations of the quality in the video. Performance evaluations showed that our 3D quality metric quantifies quality degradation caused by several representative types of distortions very accurately, with Pearson correlation coefficient of 90.8 %, a competitive performance compared to the state-of-the-art 3D quality metrics. ", "text": "abstract stereoscopic video technologies introduced consumer market past years. factor designing system understand different visual cues distortions affect perceptual quality stereoscopic video. ultimate assess video quality subjective tests. however subjective evaluation time consuming expensive cases possible. solution developing objective quality metrics attempt model human visual system order assess perceptual quality. although several quality metrics proposed still images videos case efforts initial stages. paper propose full-reference quality metric content. method mimics fusing information left right views construct cyclopean view well taking account sensitivity contrast disparity views. addition temporal pooling strategy utilized address effect temporal variations quality video. performance evaluations showed quality metric quantifies quality degradation caused several representative types distortions accurately pearson correlation coefficient competitive performance compared state-of-the-art quality metrics. introduction technology consumer market recent years challenges industry face assessing quality content evaluating viewer’s quality experience several accurate quality metrics designed content still room improvement comes video quality assessment reliability accuracy quality metrics. assessing quality content much difficult content. case well-known factors brightness contrast sharpness affect perceptual quality. case depth perception changes impact factors overall perceived video quality. although effect factors video quality extensively studied limited understanding factors affect perceptual quality. addition factors scene’s depth range display size technology used display known quality factors solely affect video quality effect video quality study presented seuntiens identifies additional quality factors presence naturalness also affect perception. factors particular interest nowadays since potential relevance design evaluation interactive media. chen suggest including quality factors depth quantity visual comfort overall quality content. shown quality factors closer correlation overall video quality compared quality factors considering existing quality metrics account quality factors ignore effect quality factors depth binocular properties human visual system using metrics evaluate quality videos yields correlation subjective results verified applying existing quality metrics right left views separately averaging values views comparing results subjective evaluations account effect quality factors evaluating quality content proposed quality metric based temporal spatial disparity variations. however proposed metric include effect d-associated quality factors contrast sharpness. known overall perceived quality dependent depth perception general picture quality mean square error used quality measure known performance accurately representing human visual system moreover method utilizes disparity information instead actual depth result inaccuracies case occlusions. addition using disparity instead depth amount disparity correspond different perceived depths depending viewing conditions. boev categorized distortions work partly supported natural sciences engineering research council canada grant stpgp institute computing information cognitive systems ubc. pourazad icics university british columbia telus communications inc. canada authors electrical engineering department icics university british columbia vancouver canada content monoscopic stereoscopic types proposed separate metrics type distortions approach monoscopic quality metric quantitatively measures distortions caused blur noise contrast-change stereoscopic metric exclusively measures distortions caused depth inaccuracies. main drawback approach unable accurately measure overall quality attempt fuse associated factors index. considering quality experience’ refers overall palatability stereo pair limited image impairments quality assessment studies propose combine measure depth perception quality individual views. study formulates quality efficient combination depth quality quality individual views. depth quality evaluated based error squared disparities reference pictures distorted quality view measured structural similarity index another group researchers proposes form quality index combining ssim index individual views mean absolute difference squared disparities reference content distorted methods presented quality individual views directly used assess overall quality. however watching brain fuses views single mental view known cyclopean view. suggests incorporating quality cyclopean view instead individual views order design accurate quality metrics shao considered binocular visual characteristics design full-reference image quality metric. approach left-right consistency check performed classify view non-corresponding binocular fusion binocular suppression regions. quality region evaluated separately using local amplitude phase features reference distorted views combined overall score another work chen propose full-reference quality metric assesses quality cyclopean view image instead individual right left view images. approach cyclopean view generated using binocular rivalry model energy gabor filter bank responses left right images utilized model stimulus strength imitate rivalrous selection cyclopean image quality. work later extended taking account various quality metrics cyclopean view quality evaluation generating disparity correspondences. results study show taking account binocular rivalry objective content quality assessment process correlation objective subjective quality scores increases especially case asymmetrically distorted content similarly study quality cyclopean view taken account design full-reference quality metric mobile applications called phvs-d study information left right channels fused using ddct transform generate cyclopean view. then local block dis-similarities reference distorted cyclopean views estimated using block structures. weighted average used phvs-d quality index. although proposed schemes take account quality cyclopean view ignore depth effect scene. quality cyclopean view fully represent perceived watching stereo pair reflects impairment associated cyclopean image. overall human judgment quality changes depending scene’s depth level impairments content noticeable occur areas depth level scene changes. thus measure depth quality addition quality cyclopean view taken account design quality metric. example approach full-reference phsd quality metric proposed similar phvs-d phsd fuses information left right views simulate cyclopean view measure quality. take account effect depth disparity maps reference distorted content well local disparity variance incorporated. phsd specifically designed video compression applications mobile devices. although phsd proposed evaluating quality video utilize temporal pooling strategy address effect temporal variations quality video. temporal pooling schemes series fidelity scores associated different frames single quality score represents entire video sequence existing full-reference stereoscopic quality metrics either designed images utilize temporal pooling. addition full-reference stereoscopic quality evaluation methods also several no-reference stereoscopic quality assessment methods proposed literature demonstrate competitive performance compared full-reference metrics note no-reference quality metrics estimate perceptual quality distorted content without using information reference content. recent works chen proposed no-reference quality assessment method natural stereopairs employs binocular rivalry extract quality features train support vector machine measure quality stereopairs another work sohn authors proposed no-reference quality assessment framework stereoscopic images modeling binocular quality perception context blurriness blockiness even though above-mentioned stereoscopic quality metrics algorithms no-reference still demonstrate high performance compared full-reference quality metrics images paper propose full-reference quality metric combines quality cyclopean view quality depth map. order assess degradation caused factors cyclopean view local image patch fusion method incorporated extract local stereoscopic structural similarities. information left right channels fused using d-dct transform. then extract local quality values using structural similarity index calculate similarity reference cyclopean frame distorted one. moreover effect depth quality experience taken account depth quality component considering impact binocular vision perceived quality every depth level. variance disparity similarity disparity maps incorporated take account depth information proposed quality prediction model. hvs-based metrics used design instead former ones reported represent perception human visual system accurately temporal pooling strategy used address recency worst section quality effects. recency effect refers high influence last seconds video viewer’s ultimate decision video quality. worst section quality effect denotes severe effect video segment worst quality judgment viewers. proposed metric tailored different applications takes account display size video resolution. performance proposed method verified extensive subjective experiments using large database stereoscopic videos various simulated representative types distortions. moreover performance proposed scheme compared state-of-the-art quality metrics terms efficiency well complexity. main contributions paper summarized follows design formulate quality measures cyclopean view depth propose quality metric combination quality measures effectively predicts quality content presence different types distortions take account temporal quality effects display size video resolution design quality metric create large database stereoscopic videos containing several different representative types distortions occur multiview video compression transmission display process verify performance proposed quality assessment method large-scale subjective tests provide comprehensive comparison state-of-the-art quality metrics. mentioned introduction section binocular perception mechanism human visual system fuses view pictures single called cyclopean view image. addition perceived depth affects overall perceptual quality picture. proposed human-visual-system-based quality metric takes account quality cyclopean view quality depth information. cyclopean view quality component evaluates general quality cyclopean image depth quality component measures effect depth binocular perception overall quality. cyclopean view generated view pictures cyclopean view generation process. mimic binocular fusion best matching blocks within views found search process. matching blocks combined frequency domain generate cyclopean view block. block fusion contrast sensitivity function taken account masking process. then local similarities resulted cyclopean images integrated overall cyclopean view quality component depth quality component constructed taking account quality depth maps well impact depth variances distortions perceived differently different levels depth present scene depth variances computed part depth quality component method. size blocks geometry system structure depth quality component selected considering fovea visual focus hvs. fig. illustrates flowchart proposed framework following subsections elaborate proposed method. quality cyclopean view qcyclopean imitate binocular vision form cyclopean view image combine corresponding areas left right views. luma information view divided blocks. block left view similar block right view found utilizing disparity information. method depth assumed available stereo views. depth either captured using depth capturing device generated stereo matching techniques. many algorithms available literature disparity generation. mpeg depth estimation reference software dense disparity generation. note extract left-to-right disparity. ders disparity generation suggested dense disparity available input. note cyclopean view generation scheme need find best match block pixels. however dense disparity provides disparity value pixel. address problem approximate disparity value block taking median disparity values pixels within block. depth information block inverse relationship disparity value disparity value block find approximate coordinates corresponding block view. fig. illustrates approximate corresponding block block right view vertical coordinate horizontal coordinate differs amount disparity note blocks necessarily matching pair blocks fused since position approximated based median disparity values pixels within block case occlusions median value provide accurate estimate block disparity result mismatch. find accurate matching block apply matching block technique based exhaustive search defined search range around using mean square error cost function. fig. best match within search range. note block size search range chosen based display resolution. instance case resolution video choose block size search area since performance evaluations shown best possible sizes significantly reduce overall complexity approach allowing efficiently extract local structural similarities views. process identifying matching blocks right view left view done reference distorted stereo sets. note distortions influence search results since search performed reference video frames search results used identify matching blocks reference pair well distorted pair. order generate cyclopean view matching blocks detected information matching blocks left right views needs fused. apply d-dct transform pair matching blocks generate dct-blocks contain coefficients fused blocks. level dct-block includes coefficients lower frequencies compared bottom one. since human visual system sensitive frequencies cyclopean view keep dct-block corresponding lower frequency coefficients discard ones. next step consider sensitivity human visual system contrast also affects perceived image quality take account property need prioritize frequencies important hvs. similar idea presented utilize proposed jpeg quantization tables. jpeg quantization tables obtained series psychovisual experiments designed determine visibility thresholds basis functions. based this coefficients represent frequencies higher sensitivity human visual system quantized less coefficients visually important content preserved course compression. application instead quantizing coefficients decided scale bigger weights assigned visually important content. achieve this adopt jpeg quantization table create contrast sensitivity function modeling mask ratio among coefficients inversely proportional ratio corresponding elements jpeg quantization table. applying modeling mask d-dct blocks frequencies importance human visual system assigned bigger weights. illustrated follows cyclopean-view model domain pair matching blocks right left views represents low-frequency d-dct coefficients fused view denotes element-wise multiplication modeling mask. elements modeling mask selected average equal one. guarantees that case uniform distortion distribution quality block within distorted cyclopean view coincides average quality view. since modeling mask needs applied d-dct blocks applications require greater cubic interpolation used up-sample coefficients mask create mask cyclopean-view model matching block pair reference view xc'i cyclopean-view model matching block pair distorted view idct stands inverse discrete cosine transform total number blocks view constant exponent ssim structural similarity index value decided based subjective tests presented section quality depth qdepth depth information plays important role perceptual quality content. quality depth becomes important several different depth levels scene. contrary scene limited number depth levels quality depth plays less important role overall quality. suggests considering variance depth conjunction depth quality reflect importance depth quality. however variance depth required taken account locally scene portion scene fully projected onto fovea watching display typical viewing distance. fig. illustrates relationship block size projected onto fovea distance viewer. observed length square block screen fully projected onto fovea calculated follows length block proper viewing distance display half angle viewer’s highest visual acuity. proper distance viewer display decided based size display. range sharpness vision drops quickly beyond range. length block translated pixel units follows mean depth values block normalized reference depth map. reference depth normalized respect maximum value frame depth values range depth value pixel outer block within normalized reference depth map. previous study relationship depth quality overall video quality verified among existing state-of-the-art quality metrics visual information fidelity index depth maps highest correlation mean opinion scores viewers also worth mentioning ssim term compares structure images take account effect small geometric distortions geometrical distortions source vertical parallax causes severe discomfort viewers geometric distortions right left images reflected depth map. therefore used compare quality depth distorted content respect reference details vif) follows depth reference view depth distorted view visual information local variance block fidelity index constant exponents total number blocks depth reference view. note latter part equation performs summation normalized local variances. variance term computed block according normalized maximum possible variance value blocks. summation divided total number blocks provide average normalized local variance value interval constructing overall metric quality distorted cyclopean view depth evaluated final form quality metric defined follows cyclopean-view model matching block pair reference view xc'i cyclopean-view model matching block pair distorted view idct stands inverse discrete cosine transform total number blocks view constant exponents ssim structural similarity index depth reference view depth distorted view visual information fidelity local variance block depth reference view. exponent parameters determined subsection since different frames video different influence human judgment quality overall quality video sequence found assigning weights frame quality scores according influence overall quality. subjective tests video quality assessment shown subjects’ ultimate decisions video quality highly influenced last seconds video moreover video segment worst quality highly affects judgment viewers true mainly subjects keep distorted segment video memory much segments good fair quality temporal pooling algorithms proposed series fidelity scores associated different frames single quality score represents entire video sequence address recency worst section quality effects temporal pooling strategy used study discussed subsection overall approach proposed study evaluate quality content illustrated flowchart fig. matlab implementation metric available online site constant exponents find constant exponents quality metric validate performance performed subjective tests using different databases estimate exponent constants proposed metric denoted equation terms calculated video training dataset. determine best values exponent constants need maximize pearson correlation coefficient. evaluate correlation vectors wide range values select values result highest correlation. accuracy robustness obtained exponents confirmed measuring correlation values indices validation video temporal pooling strategy study address recency worst section quality effects used exponentially weighted minkowski summation temporal pooling mechanism shown exponentially weighted minkowski summation strategy outperforms existing temporal pooling methods histogram-based pooling averaging mean value last frames local minimum value scores successive frames. exponentially weighted minkowski summation formulated follows total number frames minkowski exponent exponential time constant controls strength recency effect. higher values result overall score influenced frame largest degradation. order find best values pearson correlation coefficient calculated wide range parameters training video set. moreover order adjust proposed metric asymmetric video content overall quality right left view corresponding depth maps identical reference depth base view finding matching blocks switched views every frame. result overall quality biased quality view dominance effect section provides details experiment setup video sets used experiments parameters proposed metric. data adjust parameters proposed scheme verify performance used different video data sets specifications training validation video sets summarized table table respectively. sequences selected test videos video database digital multimedia university british columbia sequences provided mpeg standardization activities subjective studies datasets contain videos fast motion slow motion dark bright scenes human non-human subjects wide range depth effects. note test sequences adopted naturally captured stereoscopic videos i.e. contain views captured using side-by-side cameras. mpeg sequences however originally multiview sequences several views video. multiview sequences views recommended mpeg common test conditions used video sequence amount spatial temporal perceptual information measured according recommendation results reported table table spatial perceptual information first edges video frame detected using sobel filter then standard deviation pixels sobel-filtered frame computed maximum value frames chosen represent spatial information content scene. temporal perceptual information based upon motion difference consecutive frames. measure first difference pixel values coordinates consecutive frames calculated. then standard deviation pixels frame computed maximum value frames measure motion adjacent frames result higher values fig. shows spatial temporal information indexes test sequence recommended addition spatial temporal information sequence shown table table also provide information scene’s depth bracket. depth bracket scene defined amount space used shot sequence since information regarding objects/camera coordinates available sequences adopt disparity depth conversion method introduced find depth object respect viewer. report approximate averaged-over-frames depth difference closest farthest visually important objects. visually important objects chosen based visual attention model takes account various saliency attributes brightness intensity contrast color depth motion texture. observed table table training test videos similar distribution properties makes possible compute required parameters proposed quality metric using training video ones performance evaluations test video set. order evaluate performance proposed quality metric addition general distortions used quality metric studies take account distortions occur video content delivery display. suggested scheme delivering content transmit three simultaneous views scene corresponding depth maps synthesize extra views receiver support multiview screens process delivered content might distorted compression views compression depth maps view synthesizing. distortions applied content quality videos evaluated subjectively objectively using metric existing state-of-the-art metrics. note levels distortions applied content lead visible artifacts turn allow correlate subjective tests mean opinion score objective results. high compression views right left views simulcast coded using hevc-based encoder delay configuration setting size used. quantization parameter investigate performance proposed metric different compression-distortion levels visible artifacts. depth distorted stereo pair generated using ders high compression depth depth view compressed using hevcbased encoder delay profile size then right view synthesized using decoded depth original left view. view synthesis performed using view synthesis reference software also depth synthesized view generated using ders quality stereo pair including synthesized right view original left view compared reference one. high compression content right left view video sequences corresponding depth maps encoded using hevc-based video encoder random access high efficiency configuration. size values according mpeg common test conditions d-hevc view synthesis using views stereo pair corresponding depth view synthesized vsrs stereo pair generated result sets distorted stereo pairs formed synthesized view left view right one. then depth maps generated distorted stereo pairs using ders study capturing artifacts considered proposed quality metric full-reference metric requires reference comparison. words assumed video content corresponding depth sequences already properly captured goal evaluate perceived quality processing/distortions applied. distortions introduced content acquisition using rangefinder sensors considered experiments. addition take account effect crosstalk amount crosstalk depends display technology used. assume display imposes amount crosstalk reference distorted content. design quality metric takes account effect crosstalk information amount crosstalk different intensity level different display systems required. stereo videos. subjective test setup viewing conditions subjective tests according itu-r recommendation bt.- evaluation performed using full hyundai passive glasses. peak luminance screen cd/m color temperature according mpeg recommendations subjective evaluation proposals submitted response video coding call proposals wall behind monitor illuminated uniform light source light level less monitor peak luminance. total subjects participated subjective test sessions ranging years old. subjects none marginal image video viewing experience. screened color blindness visual acuity stereovision acuity subjective evaluations performed training validation data sets test session started short training session subjects became familiar video distortions ranking scheme test procedure. test sessions using single stimulus method videos different qualities shown subjects random order test video seconds long four-second gray interval provided test videos allow viewers rate perceptual quality content relax eyes watching next video. discrete quality levels ranking videos score indicated highest quality indicated lowest quality. here perceptual quality reflects whether displayed scene looks pleasant general. particular subjects asked rate combination naturalness depth impression comfort suggested collecting experimental results removed outliers experiments mean opinion scores remaining viewers calculated. outlier detection performed accordance itu-r bt.- annex assigning constant exponents pooling parameters find constant exponents equation quality components calculated videos training set. note experiment block size chosen measuring variance disparity. case then exponent values result highest correlation metric values corresponding training distorted video sets selected selected constant exponents β=.. order find minkowski exponent parameter exponential time constant temporal pooling pearson correlation coefficient calculated wide range parameters training video set. words parameters exhaustively swept wide range enable find highest stable maximum point accuracy function. extensive numerical evaluations show effect slight changes selected pooling parameters negligible overall metric performance. performance evaluations shown result highest correlation subjective tests quality metric results. section evaluate performance component quality metric well overall performance validation data set. performance also compared state-of-the-art quality metrics. performance quality metric discussed following subsections. contribution quality components metric order investigate contribution cyclopean view depth quality components quality metric predicting overall correlation quality component values validating dataset studied calculating spearman rank order correlation coefficient pearson correlation coefficient root-mean-square error rmse measure accuracy prediction quality components measures statistical dependency subjective objective results. words spearman ratio assesses well relationship variables described using monotonic function i.e. measures monotonicity mapping quality metric mos. addition measure consistency mapping quality metric component outlier ratios calculated table shows rmse cyclopean view depth quality components hvd. observed quality components proposed metric demonstrate high correlation mean opinion score following subsection overall performance hybrid combination quality components analyzed. overall performance metric prove efficiency quality metric performance compared state-of-the-art quality metrics using validation dataset. compare proposed quality metric phvs-d phsd note parameters phvs-d phsd originally customized mobile applications. fair comparison parameters updated screen. addition follow considered common practice evaluating quality metrics compare performance several quality metrics including psnr ssim movie quality frames views measured separately using quality metrics average quality frames views calculated. order perform comprehensive evaluation performance proposed method addition full-reference quality metrics also include no-reference quality metric proposed sohn experiments. table provides overview quality metrics used experiments. fig. shows relationship resulting values quality metric entire validation different distortions logistic fitting curve used case clearly illustrate correlation subjective results results derived metric. logistic fitting curve formulated follows denotes horizontal axis represents vertical axis diagram fitting parameters. fig. shows objective metric demonstrates strong correlation results. order evaluate statistical relationship quality metrics subjective results rmse calculated different quality metrics entire validation dataset illustrated table observed performance quantifying quality entire validation dataset presence representative types distortions superior objective metrics terms accuracy monotonicity consistency. particular pearson correlation coefficient metric spearman correlation ratio rmse observed hybrid combination cyclopean view depth quality components improved correlation quality indices values table statistical performance different quality metrics whole validation dataset performance presence different types distortions evaluate performance proposed metric predicting quality content presence different types distortions statistical relationship indices values analyzed separately type distortion. table shows values various quality metrics different types distortions validation dataset. observed quality metric either outperforms quality metrics performance quite comparable predicting quality distorted content. results table show superior performance proposed quality metric specifically video coding view synthesizing applications. note case simulcast video compression performance quality metric slightly lower video compression case. quality depth maps generated compressed stereo videos simulcast coding scenario effect temporal pooling performance evaluations demonstrated table presents statistical comparison various quality metrics. except movie rest metrics table originally designed assessing quality images take account temporal aspect video content. address this exponentially weighted minkowski pooling mechanism used conjunction image quality metrics convert frame quality scores single meaningful score video instead averaging scores frames. note parameters exponentially weighted minkowski pooling optimized quality metric separately achieve highest scores. values different quality metrics applying temporal pooling reported table observed temporal pooling general tends improve performance metrics. improvement substantial case quality metrics psnr ssim lower assessment performance presence distortions temporally variant visual artifacts compression view synthesis depth compression. observed table that general temporal pooling significant impact performance different quality metrics reason distortions added original videos section highly variant time. reason video database contains videos distortion densities change drastically frame frame. result visual quality different parts videos vary significantly time. order investigate effect temporal pooling distortions highly variant time perform additional tests using videos containg time-variant distortions. note simulcast compression depth compression video compression view synthesis distortions applied frame independently almost visually consistent entire video sequence. reason consider distortions experiment. types artifacts considered ones show spiky appearance frames appear rest frames. following distortions considered additional experiment white gaussian noise white gaussian noise zero mean variance value varying temporally applied right left views; ders used generate depth distorted stereo pair variance value frame selected randomly subjective experiments performed evaluate performance different metrics temporal pooling. table shows results experiment. observed temporal pooling implies much stronger effect case distortions densities highly variant time. particular maximum effect introduced temporal pooling occures psnr increase pcc. moreover average improvements table temporal pooling improvements table pcc. sensitivity method constant exponents method presented paper based training quality model using training video testing validation video set. kinds approaches convincing necessary study robustness algorithm changes parameters used design. order evaluate robustness proposed quality metric constant exponents first choose optimal parameters e.g. ones reported section then evaluate values exponents slightly changed. wide range observed rate change significant. particular parameters swept intervals β≤.. intervals degrade significantly. minimum value intervals occurs β=.. complexity identifying matching areas right left views considered computationally complex procedures implementation. explained section model cyclopean view block within view matching block within view detected exhaustive search. illustrated fig. matching block found performing exhaustive search around reduce complexity instead performing full search disparity used find matching areas within views. block left view assume horizontal coordinate matching block right view equal coordinate block left view plus disparity block left view. approximation shown fig. right view chosen matching block left view. using approach called fast-hvd computational complexity reduced significantly. experimental results show fast-hvd method rmse outlier ratio confirms complexity fast-hvd quality metric less original quality metric performance almost similar note disparity information modeling binocular fusion views fast-hvd cyclopean view quality component slightly correlated depth quality component. however disparity information used different quality components. specifically disparity information incorporated cyclopean view generation used find matching blocks goal fuse views create intermediate cyclopean image. however depth information used depth quality component directly used consider effect smooth/fast variations depth level effect distortions depth quality. addition please note depth quality component utilize image intensity values all. cyclopean view image intermediate image constructed fusion views. depth specifies much object perceived outside/inside display screen. observed table table quality component predict overall extent. however combination components demonstrates high accuracy. computational complexity different algorithms usually expressed complexity degree order mathematically measured. mathematical measurement computational complexity various quality metrics terms complexity degree order difficult. thus compare complexity different quality metrics measure simulation time metric. comparative experiment performed win-bit workstation intel core memory. experiment ensured program running machine. metric applied number frames total simulation time measured. moreover simulation time metric relative psnr calculated follows average simulation times frame different quality metrics well relative simulation time quality metric respect psnr reported table observed complexity fast-hvd less terms simulation time. although times complex psnr terms simulation time complexity still much less quality metrics phsd phsd-d movie times complex psnr. relative simulation time versus value different quality metrics illustrated fig. observed proposed quality metric fast implementation perform well computational complexity moderate. summary performance evaluations spearman pearson correlation ratio analysis showed quality metric quantifies degradation quality caused several representative types distortions competitively compared state-of-the-art quality metrics. future work improve temporal pooling approach used including factors motion depth scene frame rate. paper proposed full-reference quality metric called video applications. approach models human stereoscopic vision fusing information left right views d-dct transform takes account sensitivity human visual system contrast well depth information scene. addition temporal pooling mechanism utilized account temporal variations video quality. adjust parameters quality metric evaluate performance prepared database reference distorted videos representative types distortions. performance evaluations revealed proposed quality metric achieves average correlation outperforming state-of-the-art quality metrics. proposed metric tailored different applications takes account display size video resolution. wang bovik mean squared error love leave ieee signal processing magazine vol. january boev gotchev egiazarian aksay g.b. akar towards compound stereo-video quality metric specific encoder-based framework sheikh bovic image information visual quality ieee transactions image processing vol. feb. tanimoto fujii suzuki video depth estimation reference software image segmentation block matching iso/iec barten contrast sensitivity human effects image quality spie press egiazarian astola ponomarenko lukin battisti carli full reference quality metrics based international irwin visual memory within across fixations movements visual cognition scene preparation reading banitalebi-dehkordi pourazad nasiopoulos study relationship depth quality overall video quality video database digital multimedia university british columbia available http//dml.ece.ubc.ca/data/hvd/ hamberg ridder time-varying image quality modeling relation instantaneous overall quality society motion picture iso/iec jtc/sc/wg common test conditions hevcavc-based doc. switzerland november recommendation subjective video quality assessment methods multimedia applications sobel history definition sobel operator iso/iec jtc/sc/wg d-hevc test model january geneva. sullivan wiegand overview high efficiency video coding standard ieee transactions circuits hevc fraunhofer https//hevc.hhi.fraunhofer.de/ view synthesis reference software wg.sc.org march recommendation itu-r bt.- methodology subjective assessment quality television pictures iso/iec jtc/sc/wg document call proposals video coding technology mpeg meeting geneva march hyunh-thu callet barkowsky video quality assessment challenges future trends ieee international", "year": "2018"}