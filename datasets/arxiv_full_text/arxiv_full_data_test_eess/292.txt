{"title": "Speech Dereverberation Based on Integrated Deep and Ensemble Learning  Algorithm", "tag": "eess", "abstract": " Reverberation, which is generally caused by sound reflections from walls, ceilings, and floors, can result in severe performance degradation of acoustic applications. Due to a complicated combination of attenuation and time-delay effects, the reverberation property is difficult to characterize, and it remains a challenging task to effectively retrieve the anechoic speech signals from reverberation ones. In the present study, we proposed a novel integrated deep and ensemble learning algorithm (IDEA) for speech dereverberation. The IDEA consists of offline and online phases. In the offline phase, we train multiple dereverberation models, each aiming to precisely dereverb speech signals in a particular acoustic environment; then a unified fusion function is estimated that aims to integrate the information of multiple dereverberation models. In the online phase, an input utterance is first processed by each of the dereverberation models. The outputs of all models are integrated accordingly to generate the final anechoic signal. We evaluated the IDEA on designed acoustic environments, including both matched and mismatched conditions of the training and testing data. Experimental results confirm that the proposed IDEA outperforms single deep-neural-network-based dereverberation model with the same model architecture and training data. ", "text": "reverberation generally caused sound reﬂections walls ceilings ﬂoors result severe performance degradation acoustic applications. complicated combination attenuation time-delay effects reverberation property difﬁcult characterize remains challenging task effectively retrieve anechoic speech signals reverberation ones. present study proposed novel integrated deep ensemble learning algorithm speech dereverberation. idea consists ofﬂine online phases. ofﬂine phase train multiple dereverberation models aiming precisely dereverb speech signals particular acoustic environment; uniﬁed fusion function estimated aims integrate information multiple dereverberation models. online phase input utterance ﬁrst processed dereverberation models. outputs models integrated accordingly generate ﬁnal anechoic signal. evaluated idea designed acoustic environments including matched mismatched conditions training testing data. experimental results conﬁrm proposed idea outperforms single deep-neural-network-based dereverberation model model architecture training data. realistic environments perceived speech signal comprise original speech multiple copies attenuated timedelayed signals combination signals cause serious performance degradation speech-related applications. example distant-talking speech signiﬁcantly degrades performance automatic speech recognition speaker identiﬁcation meanwhile adverse effects reverberation lower sound quality intelligibility hearing-impaired normal-hearing listeners past various speech dereverberation methods developed. goal methods extract anechoic speech signals reverberant ones enhance performance speech-related applications improve sound quality intelligibility simultaneously listeners reverberant environments. model-based method estimates clean signal employing priori knowledge time–frequency speech structures second category homomorphic ﬁltering technique adopts homomorphic transformation decompose reverberant signal time domain cepstral domain thus separates reverberation input cepstral coefﬁcients simple subtraction operation channel-inversion methods belong third category considers reverberation convolution original sound room impulse response thereby performs inverse ﬁltering deconvolve captured signal even though three categories approaches shown provide satisfactory performance usually require accurate estimation time-varied always accessible practice recently deep neural network models show strong regression capabilities used address speech dereverberation issue main concept model characterize non-linear spectral mapping reverberant anechoic speech training stage. testing stage trained model used generate dereverbed utterances given input reverberant signals. concept applied perform denoising dereverberation simultaneously despite providing notable improvements traditional algorithms dnn-based dereverberation methods achieve optimal performance matched training testing reverberant conditions. improve performance environmentaware dnn-based dereverberation system proposed selects optimal models online perform dereverberation contrary idea used present study extends previous work deep denoise autoencoder speech enhancement proposes novel integrated deep ensemble learning algorithm speech dereverberation. idea consists ofﬂine online phases. ofﬂine phase multiple ddae-based dereverberation models prepared aiming precisely dereverb speech signals particular acoustic environment. then uniﬁed fusion model estimated integrate information multiple dereverberation models estimate clean speech. online phase input reverberant speech ﬁrst processed dereverberation models simultaneously outputs integrated ultimately generate anechoic signals. ensemble learning strategy proven able improve system performance speech enhancement adopted task increase generalization ability ddaes. introduced reegy popularly used shown provide improved performance preliminary experiments show using highway strategy improve speech dereverberation performance task. section ﬁrst introduce highway-ddae fig. shows ﬂowchart hddae dereverberation ofﬂine phase. ﬁgure clean– reverb speech pairs domain prepared ﬁrst form training data i-frame vectors supervised training procedure conducted placing clean reverb respectively output input sides hddae model. model hidden layers have σ{·} nonlinear mapping function weight matrices bias vectors respectively. notably output hidden layer cascades possibly address vanishing gradient problem training process hddae parameter consisting determined accordingly optimizing following mean squared error function sub-section present proposed idea speech dereverberation. mentioned earlier ofﬂine online phases. ofﬂine phase consists ensemble preparation ensemble integration stages shown figs. respectively. stage fig. reverberant conditions thus reverb data divided subsets namely subsets training data together corresponding clean training sets clean–reverb training sets training pair used train hddae model. therefore hddae models hddae hddae hddaep estimated stage. sults experiments conducted using mandarin hearing noise test ddae-based dereverberation system achieves best quality intelligibility scores training testing conditions similar however performance degrades signiﬁcantly mismatched conditions training testing. evaluated results indicate proposed idea outperforms ddae-based dereverberation system trained matched condition signiﬁcantly improves speech quality intelligibility matched mismatched conditions. rest paper organized follows. spectralmapping-based speech dereverberation system reviewed section then proposed idea introduced section experimental setup analyses presented section section concludes ﬁndings. represent clean utterance additive noise respectively; operation convolution; denotes environmental ﬁlter. fig. shows block diagram spectralmapping-based speech dereverberation system goal retrieve anechoic speeches reverberant signals seen fig. ﬁrst converted spectrogram representation carrying short time fourier transform next feature extraction process conducted extract logarithmic power spectrogram features incorporate context information features prepared concatenating adjacent static feature frames feature vector i.e. superscript denotes vector transposition. dnn-based dereverberation system compensates estimated directly restored magnitude spectrum |ˆsf spectral restoration function. finally dereverbed spectrogram |ˆsf |exp updated magnitude |ˆsf original phase converted back time domain inverse stft reconstruct enhanced time signal noted consider reverberant clean signal zero present study focus dereverberation task. evaluated proposed idea using mhint sentences containing utterances pronounced native mandarin male speaker recorded reverberation-free environment sampling rate khz. database utterances selected clean training data utterances used testing data speech dereverberation task. three distinct reverberant rooms simulated room size room size room size unit room sizes meter. positions speakers receivers randomly initialized room ﬁxed providing rirs considerations three different reverberant environments provided deriving rirs contaminate clean training data form clean–reverb training accordingly. addition generated values deteriorate testing utterances form testing set. image model applied perform rirs using generator finally prepared reverberant utterances training testing sets respectively. study speech utterance ﬁrst windowed successive frames frame size shift respectively. frame vector -dimensional derived stft extended dimensions terms mentioned section include context information acoustic feature vector. result sizes input output layers ddae-based dereverberation system shown fig. respectively. ddae-based dereverberation system four types hddae-based architectures implemented comparisons single hddae model three hidden layers trained entire training dataset single hddae model three hidden layers trained dataset composed speciﬁc condition single hddae model hidden layers trained entire training dataset proposed idea model hddae. hddae. hddae. stage model three hidden layers convolutional layers layer containing channels fully-connected layer nodes) stage fig. notably hidden layer hddaes composed nodes. speech dereverberation scenarios evaluated quality test terms perceptual evaluation speech quality perceptual test terms short-time objective intelligibility speech distortion index test score ranges pesq stoi respectively. higher scores pesq stoi denote better sound quality intelligibility respectively. hand measures degree speech distortion lower indicates smaller speech distortions thus better performance. fig. shows speech spectrograms corresponding clean reverberation processed hddaea processed ideaa. ﬁgure spectrogram idea presents clearer spectral characteristics hddaea; please note regions white blocks. harmonic structures high–frequency components also clear. then outputs hddae models combined input train model. study construct model using convolutional neural network hidden layers shown consisting convolution operations cj{·} sample vector input fully connected hidden layer {·}. convolution operation applies ﬁlters order extract feature maps obtain local time–frequency structures achieve robust feature representations provided features hidden layer fully connected feed-forward network ﬁnally obtain estimated output layer cnn. notably nonlinear mapping function σ{·} applied modulate output hidden layer. addition parameters randomly initialized optimized minimizing objective function ﬁrst list pesq scores hddae. hddae. hddae. evaluated either matched mismatched testing reverberant conditions table results baseline hddaea also listed table comparisons. addition averaged pesq scores methods testing environments shown last column table hddae. hddae. table. hddae. best pesq score testing conditions achieved hddaet trained matched condition. addition quality utterances degrades signiﬁcantly dereverberation systems mismatched environments pesq scores could even lower baseline observations indicate ddae-based dereverberation system effectively enhance speech quality property reverberation known beforehand performance degrade dramatically environments training testing conditions different. meanwhile hddaea provides best averaged pesq score. result indicates model trained diverse training robust varying testing environments. table lists averaged results pesq stoi unprocessed speech hddaea hddaea ideaa testing utterances table evaluation matrices ddae-based approaches outperform unprocessed reverberation. results indicate effectiveness hddae-based dereverberation systems. addition better pesq stoi scores hddaea hddaea indicate additional hidden layers hddae necessarily increase system performance task. hand ideaa yields highest sound quality intelligibility lowest signal distortion conﬁrming effectiveness proposed idea dereverberation task. compare pesq scores ideaa hddaea matched mismatched testing environments; results listed tables respectively tables observe pesq scores obtained ideaa hddaea consistently decrease increasing revealing dereverberation performance negatively correlated value. addition ideaa outperforms hddaea testing conﬁrming ensemble modeling achieve better results single model training data number layers models. experimental results ﬁrst noted singlehddae-based systems could achieve good dereverberation performance matched conditions performance degraded signiﬁcantly systems tested mismatched conditions showing hddae models trained address speciﬁc reverberation conditions limited generalization capabilities. addition model hddaea trained using training data outperformed individual hddae models terms pesq scores testing environments. moreover compared model hddaea model ideaa provided better results conﬁrming collecting information multiple environments train matched hddae models integrating information outputs models diverse reverberation conditions covered high dereverberation performance achieved. roman woodruff speech intelligibility reverberation ideal binary masking effects early reﬂections signal-to-noise ratio threshold journal acoustical society america vol. nakatani yoshioka kinoshita miyoshi b.-h. juang speech dereverberation based variancenormalized delayed linear prediction ieee transactions audio speech language processing vol. hikichi delcroix miyoshi inverse ﬁltering speech dereverberation less sensitive noise room transfer function ﬂuctuations eurasip journal applied signal processing vol. xiao speech dereverberation enhancement recognition using dynamic features constrained deep neural networks feature adaptation eurasip journal advances signal processing vol. reverberation-time-aware approach speech dereverberation based deep neural networks ieee/acm transactions audio speech language processing vol. tsao c.-h. ensemble speaker speaking environment modeling approach robust speech recognition ieee transactions audio speech language processing vol. taal hendriks heusdens jensen algorithm intelligibility prediction time–frequency weighted noisy speech ieee transactions audio speech language processing vol.", "year": "2018"}