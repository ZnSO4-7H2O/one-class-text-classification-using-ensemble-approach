{"title": "MaD TwinNet: Masker-Denoiser Architecture with Twin Networks for  Monaural Sound Source Separation", "tag": "eess", "abstract": " Monaural singing voice separation task focuses on the prediction of the singing voice from a single channel music mixture signal. Current state of the art (SOTA) results in monaural singing voice separation are obtained with deep learning based methods. In this work we present a novel deep learning based method that learns long-term temporal patterns and structures of a musical piece. We build upon the recently proposed Masker-Denoiser (MaD) architecture and we enhance it with the Twin Networks, a technique to regularize a recurrent generative network using a backward running copy of the network. We evaluate our method using the Demixing Secret Dataset and we obtain an increment to signal-to-distortion ratio (SDR) of 0.37 dB and to signal-to-interference ratio (SIR) of 0.23 dB, compared to previous SOTA results. ", "text": "monaural singing voice separation task focuses prediction singing voice single channel music mixture signal. current state results monaural singing voice separation obtained deep learning based methods. work present novel deep learning based method learns long-term temporal patterns structures musical piece. build upon recently proposed masker-denoiser architecture enhance twin networks technique regularize recurrent generative network using backward running copy network. evaluate method using demixing secret dataset obtain increment signal-to-distortion ratio signal-to-interference ratio compared previous sota results. music source separation active research area context audio signal processing machine learning. task estimate musical sources observed musical mixture signals. biggest challenges music source separation estimation singing voice monaural mixture signals high overlap sources exhibit various signal representations timefrequency masking modern state method estimate mask neural networks various architectures. given strong long-term temporal patterns structures music architectures model long time dependencies e.g. recurrent neural networks seem great music source separation task. local structures usually dominating learning signal because focuses recent information known issue rnns pointed many seminar works e.g. result longterm temporal patterns music might modeled correctly learning signal heavily inﬂuenced local structures means focus local structures instead long-term temporal patterns twin network eﬀective regularize generative rnns generation conditioned input make also take account expected future content. technique uses second generates output backward direction insures hidden states networks close. paper presenting method performs music source separation using twinnet capable model long-term structures music. evaluate proposed method focusing singing voice separation work builds upon method masking denoising simultaneously main contributions paper present method improves previous objective sota respectively. method less computationally intensive comparing presented uses recurrent inference rest paper organized follows. section give brief overview related work source separation task approaches. proposed method thoroughly presented section followed experimental procedure described section obtained results reported discussed section section concludes work. common approach estimate individual sources monaural mixtures apply time-varying ﬁlters mixture signal straightforward derive apply ﬁlters treat audio signals widesense stationary compute time-frequency representation signals short-time fourier transformation then source estimate obtained case sources known priori source dependent masks computed employing ratios known sources’ time-frequency representations selecting appropriate method mask computation sources known outside scope work. interested readers kindly referred following works however important note mask computation open optimization problem many cases assumptions source additivity phase dependencies made many mask computations. sources observed mixture known priori supervised approaches relying deep learning based optimization yielded state-of-the-art results deep learning approaches singing voice separation distinguished three categories. ﬁrst category includes methods train deep neural network predict conditioned features computed using magnitude spectrogram denotes matrix entry-wise absolute value operator. considered appropriate deep learning approaches lack upper limit mask shown tasks like singing voice separation deep learning approaches trained predict masks outperformed methods relying pre-computed masks. latter methods discussed following paragraphs. second category follows idea introduced denoising autoencoders speciﬁcally dnns trained recover target source magnitude spectrogram corrupted version corrupted version assumed observed mixture magnitude spectrogram methods observed performance separation highly dependent post-processing steps involved either fusion multiple trained dnns and/or postprocessing steps masking mixture signal using outcome dnns aiming encapsulate process masking deep learning optimization routines approaches third category introduced skip connections dnns. skip connections propagate mixture signal information paths. ﬁrst information path typical forward propagation layers dnns second information path allows directly reach output dnns used mask using yielding ﬁnal estimate. speciﬁcally work employs deep rnns trained yield magnitude estimates sources concurrently approach allow deep rnns learn masking process rather output magnitude estimates used compute mask. main ambition also learn masking process work proposed usage highway networks allow masked directly output neural network layer. extension temporal sequences employing gated recurrent units presented term skip-ﬁltering connections introduced. deep ladder-structured convolutional neural network presented. output used mask input provide magnitude estimates singing voice. used denoising hand architectures prone learn statistical irregularities data making architectures robust small data perturbations encoder-decoder robust interferences sources concurrently active mixture signal tackle problems masker-denoiser architecture introduced architecture builds upon incorporating sparse transformation stochastic-depth optimization step used generate mask applied ﬁnal step skip-ﬁltering connections responsible eliminating remaining interferences music sources although approach provided state-of-the-art results deep learning based monaural singing voice separation quality decoded mask relying stochastic optimization data-driven depth decoder recurrent inference consequence reported results experimental procedure suggest recurrent inference imposes computationally cumberoptimization process model given available data singing voice separation. tackle that propose replace recurrent inference process recently developed twin network similarly bidirectional twinnet employs backward running network. bidirectional rnns limited used representation learning twinnet applied generative rnn. addition original twinnet adds second recurrent network copy original exception aggregates output backward direction. second twinnet adds term loss function depends trainable function backward running network. loss function pushes together hidden states forward backward co-temporal timesteps. cost ensures hidden state forward network encodes information stored state backward network. words twinnet cost encourages anticipate future encoded backward running resulting better modeling past future context rnn. twinnet hypothesis timefrequency mask singing voice separation remain regardless direction chooses traverse sequence frames time-frequency representation mixture signal. parts. ﬁrst part takes mixture magnitude spectrogram input time-domain audio input estimates target source magnitude spectrogram mixture predicting time-frequency ﬁlter applying input outputs estimated magnitude spectrogram target source. second part takes output ﬁrst part input predicts applies denoising mask outputs ﬁltered version input. since input ﬁrst part mixture signal output estimate signal target source frame time-frequency ﬁlter ﬁrst part timefrequency mask. similarly since input second part representation target source output representation source frame time-frequency ﬁlter second part denoising ﬁlter. ﬁrst part method denoted masker second denoiser. masker denoiser neural network architectures based daes according initial paper daes daes learn stochastically manifold clean data. source separation understood process transforms samples corrupted data manifold samples reside manifold clean data transformation audio data understood using time-frequency masking want include optimization graph generation mask denoising ﬁlter. consequently setup method masker predict mask applied input magnitude spectrogram denoiser predict values denoising ﬁlter applied output masker. employ skip-ﬁltering connections allow deﬁne magnitude spectrogram target source target masker denoiser output last neural network layer masker denoiser would mask denoising ﬁlter respectively. claim direction chooses view time-frequency representation mixture signal aﬀect mask used order separate singing voice mixture. additionally hypothesize reverse traversing time-frequency representation mixture make masker learn anticipate strong temporal patterns structures music. reasons recently proposed twinnet regularizing masker training method illustrated figure thoroughly presented below. proposed method takes input audio signal mixture sources outputs audio signal target source method uses deep neural network architecture consists used input rnnenc. forward rnnenc takes sequence input backward hidden states forward backward rnns respectively rnnenc frame concatenated summed input cm×n magnitude overlap factor order context results sequences form rt×n≥ whole input signal ceiling function. used input next part method masker. masker consists frequency trimming process bi-directional recurrent neural network encoder forward decoder sparsifying transform implemented rectiﬁed linear unit feed-forward neural network skip-ﬁltering connections. input masker sequence output predicted magnitude j-th target source evaluation/testing process backward associated parts used. finally optimization graph preceding parts network backward receiving gradient signal objective backward rnn. means input backward disconnected computation graph used optimize backward rnn. work twinnet training regularize dec. claim rnndec greatly beneﬁt compensating future time frames strong temporal patterns structures music. twinnet duplicate/twin rnndec sparsifying transform skip-connections seen figure input twinnet henc output dec. apply cost regularization rnndec. aﬃne transform used evaluation/testing. work transmit gradient signal twinnet back rnnenc order imbue compensation future values encoding part masker well. output twinnet used optimize twin obtained exactly expect implemented masking process masker introduce artifacts magnitude spectrogram separated source. reason employ extra learnable time-frequency ﬁlter applied order reﬁne latter make close possibly perceive process denoising hence figure illustration hidden states regularization twinnet. forward depicted green color. twinnet twinnet regularization depicted magenta color usage backward regularizer forward training proposed target make forward capable model better long-term temporal structures patters sequences processes. authors hidden states backward target hidden states forward deterministic seen figure speciﬁcally original proposal twinnet authors consider sequence inputs aiming estimating density target maximizing log-likelihood using forward process non-linear transrnns grus initialized using orthogonal initialization technique matrices using random samples normal distribution biases initialized zeros. parameters jointly optimized using adam algorithm learning rate equal batch size gradient norm clipping equal applied. method implemented using pytorch framework code found online. iterating overlapping subsequences analyzed input signal estimates aggregated together reshaped form magnitude target source obtain complex-valued representation means griﬃn-lim algorithm uses synthesis window mixture’s phase information. inverse stft applied compute time-domain samples target source ˆxj=. jointly train components method. treat twin matrices unnormalized probabilities allowing generalized kullback-leibler divergence cost function employed objective masker energy main diagonal. observed high energy main diagonal wfnnm results source-dependent activity detector rather source-dependent ﬁlter. employ λ||wfnndec|| assess performance proposed method focusing task singing voice separation. development subset demixing secret dataset non-bleeding/non-instrumental stems medleydb training approach supervised fashion. total training consists mixtures corresponding individual sources. evaluation subset used measuring objective performance methods terms signal-to-distortion ratio signalto-interference ratio proposed music source separation evaluation campaign multitrack contained available data used generate monaural version four sources averaging available channels. target used training outcome ideal ratio masking process scaled factor masking scaling processes performed avoid inconsistencies time delays and/or mixing gains mixture signal singing voice apparent stems medleydb dataset. experiments observed inconsistencies mixing gains yielded target source estimates lacked amplitude slightly decreasing performance masker. length sequences context information parameter values chosen initial proposal architecture compared proposed method established sota approaches solely deal monaural singing voice separation. approaches corresponding results listed on-line results page signal separation evaluation campaign music signals approach denoted supervised approach yield estimates ideal and/or masks used process mixture magnitude spectrogram. method denoted http//pytorch.org/ https//github.com/dr-costas/mad-twinnet http//www.sisec.audiolabs-erlangen.de https//sisec.audiolabs-erlangen.de//results/// mm-rinf mim-ninf based methods none uses twinnet regularization. mim-rinf approach incorporates recurrent inference stochastic optimization rnndec using maximum number iterations termination threshold equal mim-ninf approach incorporate recurrent inference optimization procedure vanilla architecture. finally supervised method based robust principal component analysis singing voice separation also taken consideration objective assessment rpca-based method denoted jeo. results mentioned approaches obtained reported results following evaluation data protocol proposed sisec-mus figures plots obtained results employed metrics compared previous sota results. table median values obtained results compared previous approaches. median value proposed used sisec. online demo separated audio sequences available. seen table figures metrics twinnet method achieves higher scores previous approaches. speciﬁcally figure seen twinnet achieves better score previous better approach time twinnet smaller range values mim-rinf approach indicating consistency expected results mimrinf approach. since basic diﬀerence mim-* approaches twinnet recurrent inference results indicate usage twinnet leads robust methods. additionally twinnet surpasses aspects presented approaches figure almost trend observed results depicted figure again madtwinnet surpasses previous monaural approaches terms achieved sir. madtwinnet approach seems yield higher values compared mim-rinf approach. compared results seen clearly twinnet regularization increase performance architecture. paper proposed method music source separation able model past future context musical sound source. augmented previously proposed architecture recently proposed twinnet. masker outputs ﬁrst estimate magnitude spectrogram targeted source denoiser enhances ﬁrst estimate removing artifacts introduced masker. used twinnet regularize masker. evaluated proposed method using free dataset focusing singing voice separation task. results showed increase previous obtained sota results task. speciﬁcally reached increase respectively. obtained results show twinnet enhance performance architecture. following work propose focus towards end-toend methods meaning neural network receive input produce output audio samples directly. make time-frequency transformation included optimization graph probably yield superior results. part computations leading results performed titan-x donated nvidia drossos. drossos virtanen wish acknowledge csc-it center science finland computational resources. serdyuk would like acknowledge support following agencies research funding computing support samsung nserc calcul qu´ebec compute canada canada research chairs cifar. s.-i. mimilakis supported european union’s framework programme grant agreement macsenet. authors would like thank magron naithani valuable comments feedback writing process.", "year": "2018"}