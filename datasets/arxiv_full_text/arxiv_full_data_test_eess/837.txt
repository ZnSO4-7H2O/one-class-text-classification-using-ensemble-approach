{"title": "Learning Environmental Sounds with Multi-scale Convolutional Neural  Network", "tag": "eess", "abstract": " Deep learning has dramatically improved the performance of sounds recognition. However, learning acoustic models directly from the raw waveform is still challenging. Current waveform-based models generally use time-domain convolutional layers to extract features. The features extracted by single size filters are insufficient for building discriminative representation of audios. In this paper, we propose multi-scale convolution operation, which can get better audio representation by improving the frequency resolution and learning filters cross all frequency area. For leveraging the waveform-based features and spectrogram-based features in a single model, we introduce two-phase method to fuse the different features. Finally, we propose a novel end-to-end network called WaveMsNet based on the multi-scale convolution operation and two-phase method. On the environmental sounds classification datasets ESC-10 and ESC-50, the classification accuracies of our WaveMsNet achieve 93.75% and 79.10% respectively, which improve significantly from the previous methods. ", "text": "abstract—deep learning dramatically improved performance sounds recognition. however learning acoustic models directly waveform still challenging. current waveform-based models generally time-domain convolutional layers extract features. features extracted single size ﬁlters insufﬁcient building discriminative representation audios. paper propose multi-scale convolution operation better audio representation improving frequency resolution learning ﬁlters cross frequency area. leveraging waveform-based features spectrogram-based features single model introduce twophase method fuse different features. finally propose novel end-to-end network called wavemsnet based multi-scale convolution operation two-phase method. environmental sounds classiﬁcation datasets esc- esc- classiﬁcation accuracies wavemsnet achieve respectively improve signiﬁcantly previous methods. environmental sounds wide range everyday audio events. problem environmental sound classiﬁcation crucial machines understand surroundings. growing research multimedia applications. deep learning successfully applied task generally achieved better results traditional methods random forest ensemble support vector machine majority models spectrogram representation input log-mel features compress amplitude scale mel-spectrograms. representations often transformed compact forms audio features depending task. processes designed based acoustic knowledge engineering efforts features might suit classiﬁer well. recently increasing focus extended end-to-end learning approach level waveform features could learned directly waveform rather designed experts. commonly used approach using time-domain convolution operation waveform extract features audio representation classiﬁcation. many matched even surpassed performances employ spectral-based features. papers found complementarity waveform features analytic signal transformation combining kinds features notable improvement classiﬁcation accuracy. works trained several independent models calculated average output probabilities model. however still deﬁciencies existing methods. firstly previous methods ﬁxed size ﬁlters employed time-series waveform extract features. however always trade-off choosing ﬁlter size. wide windows give good frequency resolution sufﬁcient ﬁlters high frequency range. narrow windows learn dispersed bands frequency resolution feature extracted single size ﬁlters might insufﬁcient building discriminative representation dilemma. secondly average method make full complementary information waveform features spectrogram features. remains seen whether learn combination automatically different features single mode. address issues propose novel multiscale convolutional neural network extract features ﬁlter banks multiple different scales fuse log-mel features model. show multi-scale outperforms single-scale models around classiﬁcation accuracy ﬁlters number currently best-performing method using merely waveform input. employing proposed feature fusion method accuracy classiﬁcation improved. summary unique contributions paper threefold analyze inherent deﬁciencies single-scale method features extraction propose novel multi-scale time-domain convolution operation extract discriminative features improving frequency resolution learning ﬁlters cross frequency area. remainder paper organized follows. section discusses related work. section gives method network architecture. section presents experimental process results also analyze results section. finally section concludes paper. years designing appropriate feature representation building suitable classiﬁer features used treated separate problems sound classiﬁcation task example acoustic researchers using zero-crossing rate mel-frequency cepstral coefﬁcients features train random forest ensemble support vector machine methods classiﬁcation stage separated feature extraction designed features might optimal classiﬁcation task. recently deep learning based classiﬁers used task particular convolutional neural network observed work better problem since classiﬁer useful capturing energy modulations across time frequency-axis audio spectrograms well suited classiﬁer task spectral-based features mfcc gtcc teo-based gtcc commonly used input extract abstract features task. piczak proposed state-of-the-art method task using log-mel features deltas -channel input. end-to-end learning approach successfully used image classiﬁcation text domain audio domain learning audio explored mainly automatic speech recognition task reported performance similar even superior models using spectral-based features input. end-to-end learning approach also applied music auto-tagging tasks well tokozume employed end-to-end system task ﬁrst time approach used traditional ﬁxed ﬁlter size stride length. abundant features would learned. papers learned features ﬁxed another features train time. authors found noticeable improvements supplementing log-mel ﬁlter banks features. pre-trained individual models used wave log-mel input respectively calculate prediction window probability-voting using average output networks. explore efﬁcient method combine kinds features model paper. popular approach learns waveform passing waveform time-domain convolution ﬁxed ﬁlter size followed pooling step create invariance phase shifts downsample signal. so-called single-scale model fig. shows. however features extracted single-scale model discriminative enough. first although increasing time frequency resolution employed representation desirable uncertainty principle imposes theoretical limit combined. analyze signal time frequency together zoom time equivalent amount zoom frequency vice versa. hand frequency resolution critical classiﬁcation task wide windows employed waveform learn low-frequency area ignoring high-frequency part narrow windows behave opposite way. always trade-off. single-scale always balance them. activation function length additive bias. three scales chosen representatively thus learn high frequency features ﬁlters short window applied small stride information different features performance optimal. explore learning method extract complementary information different features single end-to-end model. propose two-phase method feature fusion aims joining log-mel features ﬁrst phase feature extractor trained multi-scale feature rh×w extracted directly time-series waveforms reqency time dimension respectively. second phase same-dimension log-mel features rh×w stack waveform features form two-channels feature map. convolved learnable kernels activation function form output feature rh×w waveforms. low-frequency features contrary employ long window applied larger stride. time wish learn high frequency resolution long window feature maps different scales concatenate alone requency axis multi-scale pooling employed downsize feature dimension time axis. considering waveform analytic signal transformation mainstream approaches training several independent models calculating average output probabilities model. improvement classiﬁcation performance simple combination indicates multi-scale features capacity complement log-mel features. represent selections multi-scale feature log-mel feature respectively output produced kernel output given additive bias ﬁne-tune backend network keeping parameters feature extractor ﬁxed back propagation. overcome vanishing gradient problem designed shallow backend network. deeper networks extract abstract features deepening network layer small gradients little effect weights front network even residual connection used reducing number backend network layers ﬁrst layers could good ability extract discrepant features convergent possible. according above propose multi-scale convolutional neural network feature fusion fig. shows. firstly apply multi-scale convolution operation input waveform. three scales chosen scale ﬁlters ﬁrst layer. another convolutional layer followed create invariance phase shifts ﬁlter size stride aggressively reduce temporal resolution pooling layer scale feature map. non-overlapping max-pooling. then concatenate three feature together multi-scale feature shown fig. then backend network applied multi-scale feature seen time-frequency representation. four convolutional layers followed. small receptive ﬁeld requency×time layers. small ﬁlter size reduces number parameters layer control model sizes computation cost. apply non-overlapping pooling convolutional layers. finally apply fully connected layers neurons output layer many neurons number classes. adopt auxiliary layers called batch normalization convolutional layer alleviates problem exploding vanishing gradients common problem optimizing deep architectures. normalizes output batch previous layer gradients well behaved. layer applied accelerate training phase. exactly model training phases. training randomly select seconds waveform input employed tokozume testing phase probability-voting strategy. rectiﬁed linear units applied layer. momentum stochastic gradient descent optimizer train network momentum model epochs convergence. learning rate ﬁrst epochs next epochs next epochs last epochs. weights model initialized scratch without pretrained model gammatone initialization want learn complements feature handcraft features mel-scale feature. dropout layers followed full connected layer dropout rate avoid overﬁtting. weight parameters subjected regularization coefﬁcient esc- esc- datasets public labeled sets environmental recordings used experiments. dataset comprises equally balanced classes clip seconds sampled .khz. classes divided major groups animals natural soundscapes water sounds human non-speech sound interior/domestic sounds exterior/urban noises. dataset provides exposure variety sound sources common quite distinct differences nuanced esc- selection classes dataset. datasets prearranged folds comparable cross-validation experiments used folds. fair comparison folds division proposed evaluation. audios downsampled want keep high frequency information. shufﬂe training data perform data augmentation. hypothesize applying multi-scale convolution operation could allow scale learn ﬁlters selective frequencies efﬁciently represent. test hypothesis train variant models single scales. compare performance constant ﬁlter size three different scales small receptive ﬁeld model middle receptive ﬁeld model large receptive ﬁeld model three models remain corresponding scale triple ﬁlters conv conv layers fair comparison multi-scale. three variant models trained separately. input rest network fig. table shows accuracies using multi-scale features single-scale features take waveform input. experiments conduct different ﬁlter sizes strides pooling size training. observe wavemsnet substantially improve performance improvement compared model respectively ﬁlters number esc- dataset. also multi-scale model achieves lest improvement esc-. knowledge best-performing end-to-end model waveform input. signiﬁcantly improvement single-scale multi-scale proves different scales learned discriminative features waveform. further improvement notable larger dataset implies model good generalization ability. piczaks tokozumes logmel-cnn envnet d-cnn-esc alexnet googlenet aytar envnet logmel-cnn wavemsnet ﬁrst phase wavemsnet second phase human performance sign indicates system simple combination softmax frozen. accuracies greatly improved esc- esc- datasets second phase. comparison improvement datasets keep parameters conv conv updatable. improvements obvious second phase freeze parameters not. infer log-mel features disturb networks front part aiming extracting features waveform. furthermore compare one-phase training method fuse multi-scale features log-mel features beginning. performances degrade respectively layers would optimized different hyper-parameters. network would hard take account waveform log-mel unify training phase one. two-phase method combines waveformbased features spectral-based features single model instead training separate models previous works outperforms others. proposed work compared studies literature table wavemsnet trained phase accuracy esc- esc- match performance untrained human participants datasets fig. shows responses multi-scale feature maps. ﬁlters learn band-pass ﬁlters. scale learned dispersed bands across frequency extract feature frequency trend center frequency matches mel-scale frequency resolution lower. contrary scale learned high frequency resolution bands locate frequency area. sufﬁcient ﬁlters high frequency range. scale behaves scale iii. indicts different scales could learn discrepant features ﬁlter banks split responsibilities based efﬁciently represent. explains multi-scale models better performance single-scale models shown table fig. effectiveness multi-scale models. verify effectiveness multi-scale. compare wavemsnet three backend networks alexnet resnet. esc- multi-scale models superior single-scale ones regardless backend networks. widely used well-preformed ﬁeld image. alexnet resnet fig. demonstrates multi-scale models consistently outperform single-scale models. indicates multi-scale models wide range effectiveness. shallow network vanishing gradient problem well suppressed back-propagating. ﬁrst layers network converge better wavemsnet matches even exceeds deep convolutional neural network. train backend network log-mel features form network simply combine wavemsnet calculating average output probabilities model. shown table accuracy esc- esc-. improvement accuracy indicates multi-scale features extracted waveforms highly complementary logmel features. two-phase method fuse features. ﬁrst phase waveform input train wavemsnet. second phase fuse log-mel features multiscale features introduced section iii-b. ﬁne-tune layers conv keep front part network freezing. second training phase parameters update layers conv update conv conv. fig. frequency response multi-scale feature maps. left shows frequency response feature product scale middle corresponds scale right corresponds scale iii. paper proposed multi-scale operates directly waveform inputs. presented model learn efﬁcient representations multiple scales. achieves state-of-the-art model using waveform input. two-phase training method fused waveform log-mel features single model signiﬁcant improvement classiﬁcation accuracy esc- esc- datasets. furthermore analyzed discrimination features learning different scales insight reasons performance improvement. piczak dataset environmental sound classiﬁcation proceedings annual conference multimedia. press available http//dl.acm.org/ citation.cfm?doid=. tokozume harada learning environmental sounds endto-end convolutional neural network ieee international conference acoustics speech signal processing sainath vinyals senior convolutional long short-term memory fully connected deep neural networks ieee international conference acoustics speech signal processing rakotomamonjy gasso histogram gradients timefrequency representations audio scene classiﬁcation ieee/acm transactions audio speech language processing vol. vacher j.-f. serignat chaillol sound classiﬁcation smart room environment approach using methods ieee conference speech technology human-computer dialogue publishing house romanian academy vol. krizhevsky sutskever hinton imagenet classiﬁcation deep convolutional neural networks international conference neural information processing systems simonyan zisserman very deep convolutional networks large-scale image recognition arxiv preprint arxiv. zhang deep residual learning image recognition computer vision pattern recognition ioffe szegedy batch normalization accelerating deep network training reducing internal covariate shift international conference machine learning", "year": "2018"}