{"title": "Which phoneme-to-viseme maps best improve visual-only computer  lip-reading?", "tag": "eess", "abstract": " A critical assumption of all current visual speech recognition systems is that there are visual speech units called visemes which can be mapped to units of acoustic speech, the phonemes. Despite there being a number of published maps it is infrequent to see the effectiveness of these tested, particularly on visual-only lip-reading (many works use audio-visual speech). Here we examine 120 mappings and consider if any are stable across talkers. We show a method for devising maps based on phoneme confusions from an automated lip-reading system, and we present new mappings that show improvements for individual talkers. ", "text": "abstract. critical assumption current visual speech recognition systems visual speech units called visemes mapped units acoustic speech phonemes. despite number published maps infrequent eﬀectiveness tested particularly visual-only lip-reading examine mappings consider stable across talkers. show method devising maps based phoneme confusions automated lip-reading system present mappings show improvements individual talkers. phonemes discriminate sounds language visual equivalent although precisely deﬁned visemes; working deﬁnition viseme phonemes identical appearance lips. therefore phoneme falls viseme class viseme many phonemes many-to-one mapping. computer lip-reading several possibilities phoneme-to-viseme mappings listed example tables mappings often consonant-only mappings devised single-talker data devised highly stylised vocabularies example). useful starting points mapping cover phonemes. consider possibility using combinations various known mappings cover consonants cover vowels total consonant maps eight vowel maps paired produce maps test. avletters dataset train test recognisers based upon mappings. dataset british-english talkers reciting alphabet seven times. four talkers training involves tracking faces active appearance models extracting combined shape appearance features. select features known out-perform feature methods machine visual-only lipreading {/ei/ {/ei/ /æ/} {//} {/i/ /y/} {/u/ /w/} {/au/} {/o/ /oi/ /u/} {/u/ /h/} {/e/ /ai/ /a/} {/u/} {/u/ /o/} {/au/ /oi/} /a/} {/æ/ /ai/ /ei/} /i/} {/a/ /ai/ /ei/ /i/} {/oi/ /o/} {/au/} /u/} {/i/ /i/} {/e/ /ei/ /æ/} {/a/ /au/ /ai/ {/o/ /oi/ /u/} {/u/ /u/} {/i/ /hh/} {/au/ /u/} {/u/ /u/} {/u/ /u/} {/æ/ /ei/ /ai/} {/i/ {/o/ /oi/ /au/ /h/} {/u/} {/u/ /u/} {/au/} {/i/ /i/} {//} {/i/ /æ/} {/e/ /i/} {/u/} /ei/} figure shows count phonemes training component silence phoneme omitted. often case rare phonemes british english represented division phoneme across viseme classes vary diﬀerent map. mappings contractive illustrated table lists ratio phonemes visemes thus table woodward covers consonant phonemes four viesmes confusion factor whereas jeﬀers vowels maps cover phonemes mapped eight visemes. {/p/ /m/} {/f/ /v/} {/t/ /d/} {/s/ /z/} {/k/ /g/} {/w/} {/r/} {/l/ /n/} {/t/ /z/} {/g/ /n/} {/l/ /t/} {/s/ /z/} {/ts/ /dz/ /z/} {/r/} {/t/ /d/} {/f/ /v/} {/p/ /m/} {/p/ /m/} {/w/} {/f/ /v/} {/t/} {/l/} {/d/ /n/} {/s/ /ts/ /j/} {/y/ /n/} {/p/ /m/} {/t/ /d/} {/w/ /s/} {/k/ /g/} {/s/ /ts/ /j/} {/y/} {/z/} {/f/} {/v/} {/t/ /r/} {/k/ /m/} {/p/ /b/} {/f/ /v/} {/s/ /dz/ /ts/} {/t/ /l/} {/p/ /m/} {/f/} {/r/ /w/} {/s/ /dz/ /ts/} {/l/} {/r/} {/y/} {/b/ /p/} {/s/ /h/} {/ts/ /dz/ /z/} {/n/} {/f/ /v/} {/t/ /k/} {/p/ /m/} {/f/ /v/} {/k/ /g/} {/s/ /ts/ /dz/} {/n/ /d/} {/l/} {/r/} {/t/} {/f/ /v/} {/r/ /w/} {/p/ /m/} {/t/ /d/} {/ts/ /dz/ /z/} {/g/ /n/} {/s/ /z/} {/d/ /t/} {/p/ /m/} {/f/ /v/} {/w/ /r/} {/t/ /z/} {/l/} {/t/ /d/} {/s/ /ts/ /dz/} {/k/ /g/} {/d/ /d/} {/g/ /h/} {/f/ /v/} {/r/ /w/} {/dz/ /ts/ /z/} {/p/ /m/} {/l/ /y/} {/s/ /z/} {/t/ /n/} {/s/ /dz/ /ts/} {/f/ /v/} {/n/ /w/} {/p/ /m/} {/t/ /d/} {/p/ /m/} {/f/ /v/} {/w/ /w/} {/s/ /z/} {/s/ /ts/ /j/} {/t/ /n/} {/y/} {/t/} {/l/} {/k/ /n/} {/h/} {/r/} {/p/ /m/} {/f/ /v/} /d/} {/s/ /z/} {/w/} {/s/ /z/} {/r/} {/t/ /j/} {/l/} deliberately omit following phonemes mappings; /si/ /axr/ /en/ /el/ /em/ /axr/ /em/ /epi/ /tcl/ /dcl/ /en/ /gcl/ kcl/ /axr/ /em/ /el/ /nx/ /en/ /dx/ /eng/ /ux/ american diacritics appropriate british english phonetic dataset. note phonemes appear across existing maps mapping uses phonemes. missing phonemes viseme grouped garbage viseme ensures measure performance previously described viseme sets. creating deﬁning visemes within existing map. labels assuming mapping tested using build viseme-level hidden markov model recognisers using states mixture components state. implement leave-one-out seven-fold cross validation. seven folds selected seven utterances alphabet talker avl. hmms initialised using ‘ﬂat start’ training re-estimated eight times force-aligned using htk’s hvite. training completed re-estimating hmms three times. word recognition less accurate viseme recognition. however viseme recognition performance fair test since viseme diﬀerent number visemes. instead words common comparator crossreferenced viseme ultimately diﬀerence sets interested rather absolute level performance. consonant along x-axis paired vowel map. figure show vowel along x-axis paired consonant map. x-axes ordered mean correctness. means clearly ‘best’ performing consonants vowels talkers. comparing consonant maps figure disney vowels signiﬁcantly worse others paired consonant maps. vowels overlap majority error bars suggesting little signiﬁcant diﬀerence whole group bozkurt vowels consistently mean upper error disney jeﬀers hazen vowels. comparing vowel maps figure hazen best consonants margin mean whereas woodward franks bottom performance. best performance terms correctness combination vowels consonants jeﬀers close second best combination lee’s consonants vowels much smaller error bar. given provides best pairing existing phoneme visemes maps alternatives perform better? ﬁrst approach talker-dependent maps based upon phoneme confusion matrices generated visual-only automated recognition system using phoneme classiﬁers. phoneme ever correctly identiﬁed quickly allocated viseme single phoneme. every pair chosen largest set. second viseme determined remaining phonemes phonemes accounted for. within process phonemes grouped viseme class phonemes within candidate group mutually confused. phoneme assigned viseme class longer considered grouping possible viseme combinations include phoneme discarded. phoneme recognition produces confusions consonant vowel phonemes make types permits vowel consonant phonemes mixed within viseme second restricts visemes vowel consonant phonemes only. maps talker table tightly confused maps phonemes within viseme confused phoneme recognition. /ai/ /u/} {/b/ /ei/ {/d/ /s/} {/ts/ /l/} {/t/} {/w/} {/f/} {/k/} /v/} {/dz/ /z/} {/a/ /u/} /ai/ /ei/ /s/} {/e/ /y/} {/l/ /n/} /f/} {/z/} ts/} {/t/} {/a/} {/u/ /u/} {/dz/ /k/} {/b/ /p/} {/ei/ /n/} {/d/ /p/} {/b/ /s/} {/l/ /m/} /e/} {/i/} {/a/} {/dz/} {/u/} {/z/} {/y/} {/ts}/ {/ai/} {//} {/a/} {/dz/} {/k/ /w/} {/u/} {/z/} {/v/} {/u/} /ai/ /ei/ {/m/ /n/} /p/} {/k/ /w/} {/d/ /s/} {/f/} {/v/} {/a/} {/z/} {/ts/} {/b/} {/u/} {/dz/ /t/} {/b/} {/u/} {/l/} {/u/} /u/} {/a/ /ei/} /ei/} {/d/ {/ts/ /l/} {/k/} {/z/} {/w/} {/f/} {/m/ /n/} {/dz/ /v/} {/b/ /y/} {/ai/ /ei/ /u/} {/u/} {//} {/e/} {//} {/a/} {/v/ /w/} {/k/} {/d/ /b/} {/t/} {/ts/} {/l/ /n/} {/dz/ /y/} {/f/ /s/} {/ei/ /i/} {/ai/} /e/} {//} {/d/ /t/} {/l/ /m/} {/k/ /w/} {/ts/} {/u/} {/y/} {/u/} {/a/} {/z/} {/b/ /s/} {/v/} {/dz/} {/f/ /n/} /ai/ /ei/} /e/} {/m/ /n/} {/k/ /l/} {/dz/ /t/} {/b/} {/u/} {/y/} {/u/} {/a/} {/w/} {/f/} {/v/} {/ts/} {/d/ /s/} vowel consonant phonemes) second approach relaxes condition requiring confusion phonemes. execute second pass viseme sets. single-phoneme viseme classes permitted merge existing multi-phoneme classes share confusions class. event phone multiple class confusions merged class greatest confusion. term loosely confused maps. sets vowel consonant phonemes mixed separate. ﬁnal maps table four talkers. looking tables identical visemes type talkers conﬁrms variability individual talker visual speech observe none visemes match previously suggested visemes comparison study figure shows word recognition performance using tightly confused loosely confused talker. also shown performance using benchmark. talker viseme signiﬁcantly improves upon benchmark performance signiﬁcant improvements talker talker minor improvement within error bars talker talkers types split vowels consonant maps demonstrate improvement benchmark talker tightly confused split vowels consonants shows signiﬁcant {/b/ /ei/ /k/} /ai/ /u/} {/dz/ /z/} {/a/ /u/} {/d/ /t/} {/ts/ /l/} /v/}{// /v/} {/a/ /ai/ /ei/ /ts/} {/e/ /y/} {/l/ /n/} /f/} {/z/} {/b/ /p/} {/u/ /u/} {/dz/ /k/} /ai/ /ei/ /n/} /ts/} {/b/ /v/} {/dz/} {/u/} {/z/} {/l/ /u/} {/d/ /t/} {/k/ /w/} {/a/} /ai/ /ts/ /ei/ {/a/ /n/} /y/} {/dz/ /t/} {/k/ /w/} {/u/} {/d/ /s/} {/b/} classiﬁcation mapping permitting mixing vowels consonants talker talker talker talker classiﬁcation mapping restricting mixing vowels consonants talker talker talker /u/} {/a/ /ai/} /ei/} {/b/ /y/} {/k/} {/z/} {/m/} {/l/} {/d/ /t/} {/ts/} {/dz/ /z/} {/a/ /ai/ /ei/ /u/} {/k/ /w/} {/f/ /s/} {/ts/ /n/} {/dz/ /y/} {/b/ /d/} {/z/} /ai/ /ei/} /e/} {/b/ /v/} {/d/ /t/} {/y/} {/dz/} {/u/} {/z/} {/u/} /e/} {/l/ /m/} {/k/ /w/} {/f/ /n/} {/a/} {/ts/} /ai/ /ei/} {/ts/ /w/} {/d/ /v/} {/m/ /n/} {/f/} {/a/} {/dz/ /t/} {/u/} {/u/} {/y/} {/b/} improvement. comparing mixed consonant vowel maps split consonant vowel maps split maps always better mixed maps talkers data. comparing loosely confused maps versus tightly confused maps tight confusions better four talkers equal third talkers highest confusion factor maps despite tightly confused viseme including single phoneme-viseme classes confused parts tightly confused classes. completed comprehensive experimental study previously suggested maps shown best previously published maps. puzzlingly mapping popular among engineers lipreading systems ﬁnding immediate use. also outlined possible build phoneme-to-viseme maps systematic using confusion matrices real recognisers. believe principled approach previous methods whose method bound fisher visemes) also allows comparison talkers using phonetic terminology. shown automatic method need worse visemes exceed performance. acknowledge dataset still rather small sparsely represented phonemes unlikely accurately modelled. future would fig. word correctness using tightly confused loosely confused viseme sets based phoneme recognition confusions. speaker dependent loosely coupled tightly coupled mixed mixed vowels consonant phonemes within viseme classes split separated vowel consonant visemes", "year": "2017"}