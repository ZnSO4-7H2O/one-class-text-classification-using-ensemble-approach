{"title": "MTGAN: Speaker Verification through Multitasking Triplet Generative  Adversarial Networks", "tag": "eess", "abstract": " In this paper, we propose an enhanced triplet method that improves the encoding process of embeddings by jointly utilizing generative adversarial mechanism and multitasking optimization. We extend our triplet encoder with Generative Adversarial Networks (GANs) and softmax loss function. GAN is introduced for increasing the generality and diversity of samples, while softmax is for reinforcing features about speakers. For simplification, we term our method Multitasking Triplet Generative Adversarial Networks (MTGAN). Experiment on short utterances demonstrates that MTGAN reduces the verification equal error rate (EER) by 67% (relatively) and 32% (relatively) over conventional i-vector method and state-of-the-art triplet loss method respectively. This effectively indicates that MTGAN outperforms triplet methods in the aspect of expressing the high-level feature of speaker information. ", "text": "architecture modules introduced addition basic encoder. first tail conditional behind encoder. generator produces samples embeddings encoders random noise. merging encoders similar framework proved superiority. after passing encoder-decoder structure noise samples generalization ability variety terms speech context unrelated environment information. discriminator guarantees authenticity similarity generated samples features speaker remain because following restrictions. classiﬁer takes samples generator data input. last layer classiﬁer used softmax loss whose labels speakers’ training set. module improves ability encoder extract distinctive features speakers. train test method different datasets analyse transferability algorithm. baselines include i-vector/plda system softmax method triplet method experimental results show algorithm achieves accuracy much better baseline systems. extensive experiments conﬁrms mtgan ability extract speaker related features vanilla triplet loss methods. appearance d-vector signiﬁes birth systems entire framework. milestone ﬁeld leads large amount works dnn. that works achieve good results i-vector/plda methods. instance presents convolutional time-delay deep neural network structure claims much better i-vector systems case short time speech. area works focus adjustment network structure utilization training technologies. however terms zero-shot tasks like whose training test irrelevant suitable method proposed rather optimizing network structure. claims using softmax loss like leads poor performance test sets different training sets. paper propose enhanced triplet method improves encoding process embeddings jointly utilizing generative adversarial mechanism multitasking optimization. extend triplet encoder generative adversarial networks softmax loss function. introduced increasing generality diversity samples softmax reinforcing features speakers. simpliﬁcation term method multitasking triplet generative adversarial networks experiment short utterances demonstrates mtgan reduces veriﬁcation equal error rate conventional i-vector method state-of-the-art triplet loss method respectively. effectively indicates mtgan outperforms triplet methods aspect expressing high-level feature speaker information. index terms generative adversarial networks speaker veriﬁcation triplet loss automatic speaker veriﬁcation refers process identifying speaker’s unknown utterance given registered voice database. important non-contact biometric identiﬁcation technique widely studied past years ﬁeld formed mainstream i-vector/plda however plenty works found end-to-end systems composed deep neural networks surpass traditional methods aspects especially short-utterance condition. besides speaker veriﬁcation short voice great practical value motivates research methods. recently metric learning methods dnns attract attention. triplet loss popular ﬁeld pattern recognition facenet novel method face recognition. that zhang apply method speaker veriﬁcation. triplet method proved useful large amount works improved basis essential thought triplet loss minimize intraclass distance maximizing inter-class distance. theoretically effective classiﬁcation tasks considering limited training samples reverberation ambient noise during recording triplet loss limitations task speaker veriﬁcation. absence guidance restriction encoders vanilla triplet loss usually extract features unrelated speaker’s resulting poor performance. furthermore generalization ability important zero-shot learning. training encoders entirely training without augmentation makes triplet methods less general test set. address aforementioned issues propose enhance triplet loss figure architecture multitasking triplet generative adversarial networks. parameters shared among networks triplet samples. enroll/test phase embeddings produced encoder used calculate distance. best viewed color. long time still many subsequent works adopted multi-channel approach enhance tightness intra-class samples. proposed structure quadruplet network improve transferability triplet loss test set. works like directly modify deﬁnition distance margin. inspired facenet improved sampling method triplet loss combined triplet loss resnet applied ﬁrst time. that also proposed structure called tristounet speaker veriﬁcation using combination bidirectional lstm triplet loss. proposed deep speaker tackle text-dependent text-independent tasks. deep speaker also proves pretrained softmax network conducive improve triplet methods. methods mentioned adopted variety ways improving none combine triplet loss multitasking methods. despite deepspeaker uses pre-trained softmax network loss item training process. random noise introduced avoid mode collapse. fake samples generated generator. ﬁrst item equation represents probability discriminator holds real sample true second item represents probability discriminator holds fake sample false. applications related computer vision. however researchers utilize ﬁeld speech lately. apply denoise enhance voice. improve process speech recognition gan. people also combine triplet loss explore applications. concretely proposed triplet network generate samples specially triplet loss. proposed tripletgan minimize distance real data fake data maximizing distance different fake data. ﬁeld speech previous work data enhancement. best knowledge proposed enhance triplet loss task speaker veriﬁcation. encoder module used extract features samples. last fully-connected layer outputs dimension embedding represents speaker information original sample. enroll/test stage embedding used calculating distance unknown utterance registered utterances. speciﬁcally conditional architecture. inputs generator random noise also embeddings encoder. output generator fake samples expected look like original samples. discriminator kinds inputs real sample fake sample generator. classiﬁer similarly feed fake samples real samples classiﬁer module. output module one-hot vector whose size equal number speaker training set. figure generative samples training process. ﬁrst contains fbanks encoder second contains fake samples generated generator. left right order training. stage preprocessing extract mel-fbank audio slice. length slice melﬁlters thus dimension input admittedly difﬁcult train instability especially multitasking situation. like works choose modify dcgan architecture proposed utilize stateof-the-art training skills wgan-gp generative samples training process shown figure dataset utilize training librispeech consists clean part other part. other part experiment explores inﬂuence number speakers. test dataset timit dataset covers english phonemes. reason train test different datasets explore transferability algorithms. terms evaluation settings randomly choose utterances enrollment utterances test. represent samples class represent samples different classes. hyper-parameter margin deﬁnes distance intra-class samples inter-class samples. experiments. algorithm take advantage cosine distance measure differences embeddings produced encoder. second term softmax loss classiﬁer whose labels speakers’ training set. triplet loss softmax loss named encoder loss function measure encoder’s ability extracting features. last loss functions come generator discriminator thus whole loss function expressed riplet ωlsof tmax represents weight coefﬁcient item. consideration generating diversity optimize generator times discriminator. determined experiments respectively. accuracy convergence speed triplet approach heavily depend sampling method problem detailedly discussed tremendous combinations utterances totally result impossible consider possibility. proposed semi-hard negative exploration sample triplet pairs followed method searches triplet pairs inside mini-batch thus effective timesaving. deep speaker also propose search anchor-negative pairs across multiple gpus. comparing random selection semi-hard negative selection selecting method matter long large amounts people used epoch. thus directly random sampling method algorithm. totally obtain n*a*p*k*j figure left curves. results methods displayed. back-end methods used i-vector system. right different embedding dimensions. five kinds dimensions embeddings displayed. methods. results reported table shows methods tiny case large number people. also number selected people inﬂuence number samples person. epoch displayed figure embedding’s dimension also important factor inﬂuences expressing ability system. therefore compared eers different dimensions results displayed right part figure results table summarize triplet method indeed outperforms i-vector softmax methods. however method achieves better result faster convergence speed. analysis think simple triplet method limited ability feature extraction poor performance data transfer. later period training triplet loss close zero phenomenon indicates reached limit speaker veriﬁcation task current features. encoder extracts features speaker information also independent factors. section ablation experiments prove framework feasible. results different conditions shown table first verify necessity module structure. removed three modules time carried experiments settings. results prove structure removal modules canbehave effectively mtgan. among three situations removal classiﬁer greatest impact means softmax loss important improving feature extraction process. compared difference random sampling method semi-hard negative method proposed network architecture applied inception-resnetv tested selecting people epoch last experiment explore impact number people training set. added other part librispeech training experiment people. although convergence speed became slower increased after enlarging training set. cannot fail note phenomenon output layer classiﬁer related number training speaker. size network increase larger dataset train model. study present novel end-to-end text-independent speaker veriﬁcation system short utterances named mtgan. extend triplet loss classiﬁer generative adversarial networks form multitasking framework. triplet loss designed clustering softmax loss help extracting features speaker information. results demonstrate algorithm achieves lower higher accuracy i-vector methods triplet methods. besides method faster convergence speed vanilla triplet methods.through ablation experiments conclusions. conﬁrm softmax loss plays signiﬁcant role extracting features semi-hard negative method random method tiny situation selecting large number people batch. also observe expected training people helps improve performance. believe work provides ideas inspirations speaker veriﬁcation community introduces methods. although framework much room improve think experimental results help others understand task speaker veriﬁcation clearly. chen duan schulman sutskever abbeel infogan interpretable representation learning information maximizing generative adversarial nets neural information processing systems barcelona spain zhang wang seqgan sequence generative adversarial nets policy gradient aaai conference artiﬁcial intelligence francisco california michelsanti conditional generative adversarial networks speech enhancement noise-robust speaker veriﬁcation interspeech stockholm sweden ioffe szegedy batch normalization accelerating deep network training reducing internal covariate shift ieee international conference machine learning lille france panayotov chen povey khudanpur librispeech corpus based public domain audio books ieee international conference acoustics speech signal processing brisbane australia variani mcdermott moreno dominguez deep neural networks small footprint textdependent speaker veriﬁcation ieee international conference acoustics speech signal processing florence italy schroff kalenichenko philbin probabilistic linear discriminant analysis inferences identity ieee international conference computer vision pattern recognition boston cheng gong zhou wang zheng end-to-end text-independent speaker veriﬁcation triplet loss short utterances ieee international conference computer vision pattern recognition vegas nevada chen chen zhang huang beyond triplet loss deep quadruplet network person re-identiﬁcation ieee international conference computer vision pattern recognition honolulu hawaii radford metz chintala unsupervised representation learning deep convolutional generative adversarial networks international conference learning representation juan puerto rico", "year": "2018"}