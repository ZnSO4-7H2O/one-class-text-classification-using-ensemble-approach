{"title": "Binary Compressive Sensing via Smoothed $\\ell_0$ Gradient Descent", "tag": "eess", "abstract": " We present a Compressive Sensing algorithm for reconstructing binary signals from its linear measurements. The proposed algorithm minimizes a non-convex cost function expressed as a weighted sum of smoothed $\\ell_0$ norms which takes into account the binariness of signals. We show that for binary signals the proposed algorithm outperforms other existing algorithms in recovery rate while requiring a short run time. ", "text": "present algorithm section iii. section present experimental results compare performance proposed algorithm algorithms. conclude paper remarks section types models binary signals considered literature deterministic vector binary sparse i.e. entries random vector whose entries independent identically distributed probability abstract—we present compressive sensing algorithm reconstructing binary signals linear measurements. proposed algorithm minimizes non-convex cost function expressed weighted smoothed norms takes account binariness signals. show binary signals proposed algorithm outperforms existing algorithms recovery rate requiring short time. compressive sensing method signal processing aims reconstruct signals relatively small number measurements. shown sparse signals reconstructed sampling rate less nyquist rate exploiting sparsity paper focus binary compressive sensing restricts signals interest binary }-valued signals widely used engineering applications fault detection single-pixel image reconstruction digital communications related works follows nakarmi rahnavard designed sensing matrix tailored binary signal reconstruction. wang combined norm norm reconstruct sparse binary signals. nagahara exploited weighted norms effectively reconstruct signals whose entries integer-valued particular binary signals bitonal images. keiper analyzed phase transition binary basis pursuit. note previous work based convex optimization. indeed convex optimization based algorithms allow performance guarantee rich mathematical tools. however found notoriously slow largescale applications compared greedy methods orthogonal matching pursuit hand greedy methods like fast often worse recovery rate convex optimization methods. work propose fast algorithm high recovery rate. taking binariness signals account algorithm gradient descent method based smoothed norm numerical experiments show proposed algorithm compares favorably previously proposed algorithms terms recovery rate speed. method works generally continuous-valued signals sparse i.e. signals whose entries mostly zero. however solving minimization requires combinatorial search therefore np-hard mohammadi adapted algorithm particularly non-negative signals. algorithm called constrained smoothed method incorporates non-negativity constraints introducing weight functions cost function. empirically shows better performance reconstruction non-negative signals. intuition behind boxed straightforward norm minimization promotes sparsity solution restriction reduces feasible solutions. recently keiper analyzed performance boxed reconstructing binary signals. nagahara proposed following method reconstruction discrete signals whose entries chosen independently ﬁnite alphabets priori known probability distribution. special case binary signals formulated utilize norm smoothed version respectively however take account binary. hand boxed utilize norm another speciﬁcally adjusted binary setting. natural question arises achieve better recovery rate binary signals adjusting binary setting? note boxed takes account binariness imposing restriction straightforward apply trick call resulting algorithms boxed boxed respectively. boxed still np-hard like boxed shows clear improvement requiring similar amount time however recovery rate boxed signiﬁcantly worse boxed note since e−t/ minimizing boxed forces small zi’s within restriction incorporated cost function. optimization problem reads follows small large proposed algorithm comprised nested loops. outer loop slowly decrease iteratively search optimal solution coarse scale decreasing factor decreases also gradually increase larger penalty solutions entries outside range inner loop performs gradient descent iterations function boxed given outer loop. iteration gradient descent solution projected feasible solutions exactly except justiﬁed initial estimate minimum norm solution i.e. initialization value discussed also choice step-size gradient descent justiﬁed choice derived using fact except implementation. point discontinuity deteriorate performance gradient descent. replace function smooth function however cost increased time. experiment tested bssl randomly generated binary signals compared cs/bcs algorithms. random gaussian matrices considered measurement matrix entries drawn independently standard normal distribution. parameter varied step-size binary signal generated drawing entries independently compute measurement vector respective algorithms introduced section obtain solution vector approximated reconstruction additionally consider orthogonal matching pursuit fast greedy algorithm sparse signal reconstruction. following considered performance evaluation failure perfect reconstruction noise signal ratio kx−zk time. experiments repeated times results averaged. parameter ﬁne-tuned bssl σmin considered reconstruction -pixel bitonal image given fig. following setup added pixel random gaussian noise mean-zero standard deviation shown fig. e−πi/k k-point matrix. randomly subsampled obtain half-sized vector measurement matrix corresponding submatrix fig. shows reconstructed images bssl entrywise rounding nagahara discrete signal reconstruction absolute values ieee signal processing letters vol. keiper kutyniok pfander compressed sensing ﬁnite-valued signals linear algebra applications mohimani babaie-zadeh jutten fast approach overcomplete sparse decomposition based smoothed norm ieee transactions signal processing vol. donoho tanner precise undersampling theorems pro{ optimal tuning parameter searched stepsize value chosen. bssl chose parameter rough estimate sparsity bitonal image σmin parameters bssl. respective time bssl also given tab. work proposed fast algorithm reconstruction binary signals based gradient descent method smooth relaxation techniques. showed binary signals algorithm outperforms cs/bcs methods terms recovery rate speed. future work includes detailed analysis bssl stability/robustness extensions ternary ﬁnite alphabet signals.", "year": "2018"}