{"title": "Reconstruction of Compressively Sensed Images using Convex Tikhonov  Sparse Dictionary Learning and Adaptive Spectral Filtering", "tag": "eess", "abstract": " Sparse representation using over-complete dictionaries have shown to produce good quality results in various image processing tasks. Dictionary learning algorithms have made it possible to engineer data adaptive dictionaries which have promising applications in image compression and image enhancement. The most common sparse dictionary learning algorithms use the techniques of matching pursuit and K-SVD iteratively for sparse coding and dictionary learning respectively. While this technique produces good results, it requires a large number of iterations to converge to an optimal solution. In this article, we use a closed form stabilized convex optimization technique for both sparse coding and dictionary learning. The approach results in providing the best possible dictionary and the sparsest representation resulting in minimum reconstruction error. Once the image is reconstructed from the compressively sensed samples, we use adaptive frequency and spatial filtering techniques to move towards exact image recovery. It is clearly seen from the results that the proposed algorithm provides much better reconstruction results than conventional sparse dictionary techniques for a fixed number of iterations. Depending inversely upon the number of details present in the image, the proposed algorithm reaches the optimal solution with a significantly lower number of iterations. Consequently, high PSNR and low MSE is obtained using the proposed algorithm for our compressive sensing framework. ", "text": "bases wavelet bases empirically known yield sparse representations estimation problem solved bases transformation elements signal. rather using empirical dictionaries step learn basis dictionary signal itself that basis signal sparsest representation. technique sparse dictionary learning helps achieve purpose. thus established dictionaries provide universal bases represent data resulting sparse representations lesser sparsity obtained using data adaptive dictionaries. either case over-complete dictionaries need used data efficiently represented sparsely. conventional techniques employ matching pursuit algorithm sparse coding k-svd algorithm data adaptive dictionary learning technique involves iterative execution sparse coding dictionary update obtain optimal solution terms sparsity reconstruction error. sparse dictionary learning technique also applied compressed sensing past decade literature compressed sensing introduce idea compressive sensing multiplication matrix signal sensed thus undetermined system considered signal input lower dimensional signal produced output processed pipeline. case however sensing system characterized sensing matrix must signal compressive sensing. step consider sparse sensing matrix rank deficient. thus away sensing parts signal incident sensing system. intuitively refers involving dual compressive stage compressed sensing pipeline. article optimized technique built convex optimization framework tikhonov regularization complement efficient image recovery scheme reconstruct compressively sensed images without assuming structure sensed images. representation using over-complete dictionaries shown produce good quality results various image processing tasks. dictionary learning algorithms made possible engineer data adaptive dictionaries promising applications image compression image enhancement. common sparse dictionary learning algorithms techniques matching pursuit k-svd iteratively sparse coding dictionary learning respectively. technique produces good results requires large number iterations converge optimal solution. article closed form stabilized convex optimization technique sparse coding dictionary learning. approach results providing best possible dictionary sparsest representation resulting minimum reconstruction error. image reconstructed compressively sensed samples adaptive frequency spatial filtering techniques move towards exact image recovery. clearly seen results proposed algorithm provides much better reconstruction results conventional sparse dictionary techniques fixed number iterations. depending inversely upon number details present image proposed algorithm reaches optimal solution significantly iterations. consequently high psnr obtained using proposed algorithm compressive sensing framework. classic nyquist-whittaker-shannon sampling theorem dictates sample least twice many samples unit time signal maximum frequency content signal order reconstruct efficiently sampled version however exploit structural properties signal sparsity away fewer samples achieve complete reconstruction. basis compressed sensing tools compressed sensing signal possesses structure mentioned above. original signal doesn’t structure sparsity induce transforming signal onto appropriate bases wavelet bases. signal’s sparse representation weights associated previously chosen best atoms changed incorporate contribution atom. also note that move higher sparsity lower sparsity l-sparse representation reconstruction error reduces lowering sparsity. dictionary update dictionary updated every sparse coding stage. every atom dictionary first find signals atom sparse representation. stage sparse representations using atom. available weights sparse representation solve convex optimization problem find best atom reduce dataset using atom using ridge regression technique. repeated atoms dictionary. completes dictionary update stage followed next cycle sparse coding. compressed sensing framework nonoverlapping square boxes fixed window size. every image block unroll image block square matrix column vector append make pass image. assume signal sensed compressively compressive image sensing context established above column unrolled block image. also suppose exists sparse representation signal thus dimension less note sensing matrix part compressed sensing system. thus sense instead thus sense less. apply sparse dictionary learning technique introduced above represent proposed framework begin process randomly initializing dictionary. random initialization approach reduce time consumption initialization process opposed resulting initialization techniques like clustering. algorithm uses l-regularized convex optimization technique sparse coding dictionary update. since involves solving linear inverse problem sometimes rank deficient underdetermined systems respectively tikhonov regularization stabilize optimization noise. closed form solution tikhonov regularization also known ridge regression used find optimal solution hypothesis. technique logical extension conventional methods used sdl. ridge regression thus helps obtain best possible solution terms sparsity every cycle sparse representation dictionary update. tikhonov regularization effectively truncates part weighted small singular values system making output stabilized presence noise. highly essential channel noise sensing basic idea sparse coding based identifying atoms calculating respective weights linear closely similar original data point. approach stabilized least squares convex optimization problem trying reduce mean squared error original reconstructed signal. thus using tikhonov regularization find optimal solution sparse representation produces least reconstruction error. fundamental principle dictionary update based upon philosophy improving dictionary atom-byatom data points using particular atom. conventional techniques k-svd incorporate error vector representative vector data reconstruction error minimized. look optimization point view. given weights data points’ sparse representation original data find vector using ridge regression technique represents optimal solution minimize reconstruction error data. proposed compressed sensing framework using discussed following sections. sparse coding sparse coding data done using dictionary. dictionary either established basis like discrete cosine transform learned data. algorithm solve regularized convex optimization problem sparse coding. every data point begin finding appropriate weight atom dictionary. assume given data points effectively represented using dictionary atom. find best weights given signal corresponding atoms dictionary using tikhonov regularization. sparse coding system uses adaptive sparsity scheme allows system non-zero values data point’s sparse representation. note that atom chosen included also observe single iteration algorithm reach near optimal solution unlike techniques. result proposed algorithm provide excellent reconstructions running iterations reducing algorithmic time. finally explored effect sparsity reconstruction data quality observed algorithm sparsity reduces psnr improves. observation reasoned based dictionary update sparse coding done using algorithm. first cycle using particular dictionary find quasioptimal weights atom sparse coding stage resulting -sparse representation original signal. since weights already optimal given iteration atom chosen approximate original signal considering previous atom fixed approximation error increases. thus sparse coding technique using normally converge -sparse algorithm representation following dictionary update stage find quasi-optimal atoms complement quasi-optimal weights results optimized solution first cycle algorithm itself. since systems often full rank introduce null space error propagates iterations. thus recovered signal xrec assembled image performing reverse unrolling operation observe characteristic noise pattern image seen center-shifted frequency spectrum image output sparse dictionary learning stage. desired noise free signal viz. lies center spectrum. thus create elliptical filter mask image automatically processing spectrum recovered image detecting noise peaks. desired image recovered inverse fourier transform spectral filtering followed appropriate gamma transformation. study performance characteristics proposed algorithm conventional techniques used compressed sensing recovery consider dataset points represented features consistent throughout study. table show results proposed algorithm using complete dictionary atoms lambda equals zero compares conventional techniques. seen algorithm provides better results terms psnr mse. table provides results test setup iterations. similar improvement results observed case well. apply algorithm compressive sensing sample image dimensions image divided non-overlapping equal size blocks size sensing matrix rows. dictionary consisting atoms considered. evident number atoms dictionary increase fewer iterations required reach optimal solution. however since compressed sensing task limit dictionary size atoms thus making complete. blocks sparse coded using non-zero value proposed algorithm. sensing matrices highly rank deficient incorporate dual compressive sensing generated randomly check credibility proposed framework. iterations changes easily distinguishable human eye. moreover suggested intuitively reconstruction better sense samples. using blocks larger window size introduces reconstruction error highly minimizes number iterations increase. time larger blocks introduce higher scope sense compressively. using smaller block sizes convex sparse dictionary learning algorithm leads lower reconstuction mse. however using smaller block sizes significant increases number signals sparse coded. increases run-time algorithm. mentioned earlier trade-off runtime compression ratio reconstruction error depends application best chosen domain expert. article proposed algorithm image recovery compressively sensed images using regularized convex sparse dictionary learning adaptive spectral filtering. algorithm works better conventional techniques used task. also observe results using tikhonov regularization sparse coding dictionary learning considered preferable choice. however computational complexity matrix inversion multiplication larger datasets proposed method require significantly larger run-time conventional techniques. technique modified using variable block sizes depending level detail image blocks local variance larger block sizes sparse coded using complete dictionary whereas image blocks exhibiting larger local variance learnt using smaller block sizes using over-complete dictionaries. adaptive spectral mask designed learn arbitrary masks rather ones constrained geometric prior. thus application specific trade-off exists hyper-parameters proposed technique best chosen adaptively validation. figures represent reconstructed image objective scores ssim iteration proposed algorithmic framework cases recovery done compressive sensing sample image different sensing matrices generated randomly. also observed algorithm reaches almost optimal solution nishant deepak keni rizwan ahmed ansari convex optimization based sparse dictionary learning image compression ieee international conference signal processing integrated networks september michal aharon michael elad alfred bruckstein k-svd algorithm designing overcomplete dictionaries sparse representation ieee transactions signal processing vol. november luisa polania kenneth barner multi-scale dictionary learning compressive sensing ieee digital signal processing signal processing education meeting sukanya patil rajbabu velmurugan ajit rajwade dictionary learning poisson compressed sensing ieee international conference accoustics speech signal processing minghao fengjiao guan haifeng yongmin yang hailong compressed sensing based dictionary learning reconstructing blade timing signals prognostics system health management conference", "year": "2018"}