{"title": "Deep Neural Networks for Multiple Speaker Detection and Localization", "tag": "eess", "abstract": " We propose to use neural networks for simultaneous detection and localization of multiple sound sources in human-robot interaction. In contrast to conventional signal processing techniques, neural network-based sound source localization methods require fewer strong assumptions about the environment. Previous neural network-based methods have been focusing on localizing a single sound source, which do not extend to multiple sources in terms of detection and localization. In this paper, we thus propose a likelihood-based encoding of the network output, which naturally allows the detection of an arbitrary number of sources. In addition, we investigate the use of sub-band cross-correlation information as features for better localization in sound mixtures, as well as three different network architectures based on different motivations. Experiments on real data recorded from a robot show that our proposed methods significantly outperform the popular spatial spectrum-based approaches. ", "text": "direction-of-arrival without making strong assumptions. surprisingly learning-based methods address problem multiple sound sources particular simultaneous detection localization multiple voices real multi-party scenarios well studied. although earliest attempts using neural networks date back recently researchers started attention learning-based approaches. large increase computational power advances deep neural networks several methods shown achieve promising single performance nevertheless methods detecting source focusing research localization accuracy. particular formulate problem classiﬁcation audio input class label associated location optimizing posterior probability labels. unfortunately posterior probability encoding cannot easily extended multiple sound source situations. neural networks trained localizing single source applied multi-source localization pooling network outputs multiple time frames however method requires known number sources long period time input pooling. limitations make practical real applications. localization sources addressed encodes output marginal posterior probability vectors. however ad-hoc location-based ordering introduced decide source-to-vector assignment rendering posteriors dependent encoding somewhat ambiguous. source need predicted ﬁrst source alone second another signal preceding label present. abstract— propose neural networks simultaneous detection localization multiple sound sources human-robot interaction. contrast conventional signal processing techniques neural network-based sound source localization methods require fewer strong assumptions environment. previous neural network-based methods focusing localizing single sound source extend multiple sources terms detection localization. paper thus propose likelihood-based encoding network output naturally allows detection arbitrary number sources. addition investigate sub-band cross-correlation information features better localization sound mixtures well three different network architectures based different motivations. experiments real data recorded robot show proposed methods signiﬁcantly outperform popular spatial spectrum-based approaches. sound source localization speaker detection crucial components multi-party human-robot interaction robot needs precisely detect speaker responds appropriately addition robust output essential analysis provides reliable source information combined modalities towards improved hri. although studied decades still challenging topic real applications following conditions traditionally considered signal processing problem. solutions analytically derived assumptions signal noise environment however many assumptions hold well abovementioned conditions severely impact performance. alternatively researchers recently adopted machine learning approaches neural networks indeed sufﬁcient amount data principle learn mapping localization cues *this research partially funded european unions horizon research innovation programme grant agreement {weipeng.he petr.motlicek odobez}idiap.ch denotes delay discrete domain complex conjugation denotes real part complex number. peak gcc-phat used estimate tdoa. however real condition gcc-phat corrupted noise reverberation. therefore full gcc-phat function input feature instead single estimation tdoa. experiments center delays gcc-phat mel-scale ﬁlter bank gcc-phat optimal tdoa estimation multiple source signals since equally sums frequency bins disregarding sparsity speech signals time-frequency domain randomly distributed noise stronger signal bins. preserve delay information frequency band allow sub-band analysis propose gcc-phat mel-scale ﬁlter bank hence second type input feature formulated ﬁlter index transfer function f-th mel-scaled triangular ﬁlter support fig. shows example gccfb frame speech signals overlap. corresponds gcc-phat individual frequency band. frequency-based decomposition allows estimation tdoas looking local areas rather across frequency bins. example areas marked green rectangles correspond separate sources different delays produce high cross-correlation values different frequency bands experiments mel-scale ﬁlters covering frequencies encoding design multiple output coding likelihood sound source direction. speciﬁcally output encoded vector {oi} values associated individual azimuth direction values deﬁned maximum gaussian-like functions centered around true doas paper investigates nn-based methods applied real scenarios contrast previous studies methods required cope short input overlapping speech unknown number sources strong ego-noise. emphasize application real conditions testing methods recorded data robot pepper. paper propose three architectures multiple based different motivations. adopt likelihood-based output encoding handle arbitrary number sources. investigate employment sub-band cross correlation information input feature better localization cues speech mixtures. experiments indicate proposed methods signiﬁcantly outperform baseline methods. section describe proposed models multiple ssl. consider localization sounds azimuth direction individual time frames long. denote number sources number microphones input signal represented short time fourier transforms microphone index frequency discrete domain. omit time index clarity none methods described exploit context information temporal relations. input features generalized cross-correlation phase transform popular method estimating time difference arrival microphones important clue ssl. here types features based gcc-phat frame level. gcc-phat coefﬁcients ﬁrst type input feature represented center gcc-phat values microphone pairs used gcc-phat channel formulated last layer fully connected layer sigmoid activation function. sigmoid function bounded range desired output. according experiments helps network converge better result. cnn-gccfb fully connected suitable highdimensional input features large dimension introduces large amount parameters trained making network computationally expensive prone overﬁtting. convolutional neural networks learn local features reduced amount parameters using weight sharing. leads idea using input feature gccfb. structure shown fig. consists four convolutional layers fully connected layer output local features shift invariant since position feature important ssl. therefore apply pooling convolution. instead apply ﬁlters stride expecting network learns spatial downsampling. tsnn-gccfb cnn-gccfb considers input features images without taking properties account yield best model. thus third architecture design weight sharing network knowledge gccfb generally predominant speech source thus analysis implicit estimation frequency band information aggregated broadband prediction. features delay different microphone pairs correspond locally. instead feature extraction ﬁlters take whole delay axis account. based considerations propose two-stage neural network ﬁrst stage extracts latent features ﬁlter bank repeatedly applying subnet individual frequency regions span delays ground truth j-th source value control width gaussian-like curves denotes angular distance. output coding resembles spatial spectrum function peaks true doas unlike posterior probability coding likelihood-based coding constrained probability distribution zero sound source contains peaks sources. coding handle detection arbitrary number sources. addition soft assignment output values contrast assignment posterior coding takes correlation adjacent directions account allowing better generalization neural networks. mlp-gcc illustrated fig. mlp-gcc uses gcc-phat input contains three hidden layers fully-connected layer rectiﬁed linear unit activation function batch normalization microphone pairs. second stage aggregates information across frequencies neighbor area outputs likelihood sound doa. similarly subnet repeatedly used doas second stage. train network adopt two-step training scheme first train subnet ﬁrst stage using likelihood desired latent feature. obtain frequency-related features help converge better result next step. second step stages trained end-to-end manner. experiments subnet -hidden-layer subnet -hidden-layer mlp. hidden layers size development evaluation learning-based methods collected sets real data loudspeaker human subjects pepper recording sets. four microphones head forming rectangle microphones directional forward look direction. audio signals received microphones strongly affected robot’s noise inside head. sample rate khz. recording loudspeakers collected data recording clean speech played loudspeakers clean speech data selected corpus contains spontaneous speech people interacting meetings. loudspeakers attached markers automatically located camera robot. data recorded rooms different sizes robot loudspeakers random places. programmed robot move head automatically acquire large diversity loudspeaker-torobot positions. recording human subjects evaluate methods real collected second dataset involves human subjects recording subjects spoke robot phrases interactions. dataset includes recordings single utterances well overlapping ones. manually annotated voice activity detection labels automatically acquired mouth position running multiple person tracker detection convolutional pose machine known number sources select highest peaks output predicted doas match ground truth doas compute mean absolute error addition consider accuracy percentage correct predictions. saying prediction correct mean error prediction less given admissible error unknown number sources consider ability detection localization. this make predictions based compute precision recall curve varying prediction threshold precision percentage correct predictions among predictions. recall percentage correct detection ground truth sources. table shows results localization known number sources. loudspeaker dataset three proposed models achieve average less error accuracy best baseline method error accuracy. human subject dataset baseline methods slightly better frames single source. however proposed methods outperform baseline methods terms accuracy especially frames overlapping sources. note that loudspeaker dataset general challenging contains samples lower wider range azimuth directions. sources rear difﬁcult detect directivity microphones. terms simultaneous detection localization unknown number sources proposed methods outperform baseline methods achieving approximately precision recall datasets among three proposed models tsnn-gccfb achieves best results better performance overlapping frames. justiﬁes usage sub-band feature two-stage structure beneﬁcial multiple ssl. also notice that unlike signal processing approaches nn-based methods affected condition unknown number sources. indicates output coding data-driven approach effective detecting number sources. demonstration video accompanied paper. paper investigated neural network models simultaneous detection localization speakers. proposed likelihood-based output coding making possible train detect arbitrary number overlapping sound sources. collected large amount real data including recordings loudspeakers humans training evaluation. results comprehensive evaluation show proposed methods signiﬁcantly outperform traditional spatial spectrumbased methods. current study potentially limited training data samples likely cover possible combinations source positions since number combinations grows exponentially number sources. future work explore network models generalize multiple sound sources limited training data. also explore robustness challenging noise cocktail party noise. furthermore investigate incorporation temporal context omitted experiments. brandstein silverman robust method speech signal time-delay estimation reverberant rooms ieee international conference acoustics speech signal processing vol. apr. vol.. youssef argentieri zarader learning-based approach robust binaural sound localization ieee/rsj international conference intelligent robots systems nov. xiao zhao zhong jones chng learning-based approach direction arrival estimation noisy reverberant environments ieee international conference acoustics speech signal processing apr. takeda komatani sound source localization based deep neural networks directional activate function exploiting phase information ieee international conference acoustics speech signal processing mar. takeda komatani discriminative multiple sound source localization based deep neural networks using independent location model ieee spoken language technology workshop dec. mccowan carletta kraaij ashby bourban flynn guillemot hain kadlec karaiskos others meeting corpus proceedings international conference methods techniques behavioral research vol. nakamura nakadai asano hasegawa tsujino intelligent sound source localization dynamic environments ieee/rsj international conference intelligent robots systems oct.", "year": "2017"}