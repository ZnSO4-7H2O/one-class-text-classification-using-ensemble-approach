{"title": "A General Approach for Construction of Deterministic Compressive Sensing  Matrices", "tag": "eess", "abstract": " In this paper, deterministic construction of measurement matrices in Compressive Sensing (CS) is considered. First, by employing the column replacement concept, a theorem for construction of large minimum distance linear codes containing all-one codewords is proposed. Then, by applying an existing theorem over these linear codes, deterministic sensing matrices are constructed. To evaluate this procedure, two examples of constructed sensing matrices are presented. The first example contains a matrix of size ${{p}^{2}}\\times {{p}^{3}}$ and coherence ${1}/{p}\\;$, and the second one comprises a matrix with the size $p\\left( p-1 \\right)\\times {{p}^{3}}$ and coherence ${1}/{\\left( p-1 \\right)}\\;$, where $p$ is a prime integer. Based on the Welch bound, both examples asymptotically achieve optimal results. Moreover, by presenting a new theorem, the column replacement is used for resizing any sensing matrix to a greater-size sensing matrix whose coherence is calculated. Then, using an example, the outperformance of the proposed method is compared to a well-known method. Simulation results show the satisfying performance of the column replacement method either in created or resized sensing matrices. ", "text": "abstract paper deterministic construction measurement matrices compressive sensing considered. first employing column replacement concept theorem construction large minimum distance linear codes containing all-one codewords proposed. then applying existing theorem linear codes deterministic sensing matrices constructed. evaluate procedure examples constructed sensing matrices presented. ﬁrst example contains matrix size coherence second comprises matrix size coherence prime integer. based welch bound examples asymptotically achieve optimal results. moreover presenting theorem column replacement used resizing sensing matrix greater-size sensing matrix whose coherence calculated. then using example outperformance proposed method compared wellknown method. simulation results show satisfying performance column replacement method either created resized sensing matrices. whose sparsity order indicates number non-zero entries. then problem illustrated am×nxn× shows measurement vector am×n sampling matrix sampling worthwhile provided original signal uniquely exactly reconstructed. sparsest solution problem using l-norm minimization investigated leads np-hard problem simplify issue l-norm minimization solution proposed am×n must satisfy so-called restricted isometry property then exactly uniquely reconstructed using l-norm minimization. mentioned signal sampled appropriate sampling matrix am×n could reconstructed solving related l-norm minimization problem. latter problem also solved using greedy algorithms orthogonal matching pursuit algorithm modiﬁcations beginning gaussian sensing matrices whose elements independent identically distributed proposed satisfy high probability matrices number rows columns sparsity order related deterministic sensing matrices used. even though huge number k-sparse signals evaluation given deterministic sensing matrix frustrating matrix still satisfy coherence enough. deterministic used satisfy order shows degree polynomial coefﬁcients galois ﬁeld considering polynomials ﬁnite projective spaces instead ﬁnite ﬁeld extension devore’s construction lower coherence sensing matrices algebraic geometry codes also utilized deterministic sensing matrices construction. binary structures seen combining similar reed-solomon generator matrices tensor product utilizing generated codewords complex-valued deterministic sensing matrience less twice welch bound developed employing codes creating large minimum distance codewords binary bipolar ternary deterministic sensing matrices obtained. overcome limitation matricesâ sizes methods developed resize sensing matrices complex valued sensing matrices. aspect note sufﬁcient condition meaning might matrices satisfying condition even rip-less used sensing matrices matrices satisfy weaker condition so-called statistical proposed. paper construct coherence sensing matrices theorem employing large minimum distance linear codes containing all-one codeword ﬁrst introduced then exhibit procedure employing column replacement concept create large minimum distance linear codes containing all-one codeword. secondly present examples theorem constructing sensing matrices applied proposed matrices compute coherence resulting matrices. next comparing results well-known sensing matrices exhibit generality proposed method. deterministic sensing matrices posed structure outweighs terms coherence owing fact method considers coherence lesser rows matrix construction. notable mentioned examples asymptotically optimal welch bound. finally utilize column replacement method resize sensing matrices calculate coherence. presenting example show size sensing matrices procedure results better sensing matrices sense coherence compared kronecker product developed rest paper follows. section contains main results. section using computer simulations performance sensing matrices compared existing matrices. section concludes paper. theorem enables think coherence sensing matrices provided create large minimum distance matrix codewords. create matrices based column replacement matrices follows. apply column replacement method matrices code propose matrix. proved columns matrix also codewords minimum distance function primary pattern matrices. therefore criteria minimum distance large enough apply theorem using column replacement method deﬁne prove following theorem construct large minimum distance linear codes. ′×)· moreover suppose columns an×pk ′×pkk′ form respectively obvious an×pk ′×pkk′ ′×pkk′ sizes respectively. trivially minimum distances linear codes created codewords ap×p pp×p i.e. dmin d′min minimum distance cp×p thus equal inferred ′×pkk′ matrix whose columns also codewords linear subspace. note although used characteristic columns ′×pkk′ exactly d′min elements common corresponding columns an×pk dmin arbitrary column ¯ap×p corresponds column aγα+γ matrix ap×p superscript considered accentuate correspondence columns ¯ap×p elements p′p×p simplify here employ column replacement concept resize deterministic sensing matrix illustrate resizing matrix given greater size method leads matrix lower coherence ﬁrst indicate theorem develop method theorem normalized vectors furthermore ments distinct columns matrix elements common. trivially true statements. then coherence cmn×l= means column replacement am×n based pattern matrix pn×l factor resulted theorem based ap×p pp×p matrix size coherence matrix according theorem ap×p need matrix size reach size words sensing matrix size whose coherence according p+p+ therefore compare proposed method random sensing matrices. consider three different scenarios verify examples presented section iii. results shown based average independent trials different k-sparse signals. scenario measurement matrix performance veriﬁed based recovery percentage well output sparsity order increasing input augmented reconstruction algorithm orthogonal matching pursuit suitable solve l-minimization problems. ﬁrst scenario examine example matrices size coherence generated ﬁnite ﬁeld sensing matrix size coherence ﬁnite ﬁeld construction leads size coherence results depicted figs. sparsity order considered fig.. apparently proposed deterministic sensing matrices better meanwhile deterministic structures surpass random sensing matrices sense recovery percentage well output snr. columns matrix then arbitrarily choose rows matrix construct trivially matrix therefore applying theorem obtain binary sensk result example resembles hence shows generality approach. size coherence pp×p matrix whose columns codewords erated generator matrix obviously codewords pp×p minimum distance equal therefore arbitrary columns pp×p element much diverse applicable structures manipulating theorem moreover seen example resizing approach increase size sampling matrices also approach obtain well-structured sensing matrices. finally simulation results showed utilizing proposed column replacement method constructed matrices perform better existing deterministic sensing matrices approximately size. moreover simulation results conﬁrmed suggested procedure resizing sensing matrices perform much better compared kronecker product method. rows matrix size coherence therefore resize resulting matrix coherence although severely unfair construction; could obtain matrix size reduce size also consider gaussian sensing matrix size finally figs. sparsity ﬁxed generate fig. illustrate results third scenario proposed method resizing deterministic sensing matrices. seen example method performs better kronecker product method. notice kept available columns structure reveals another advantage proposed method. column replacement concept used construct coherence deterministic sensing matrices problems. first method employed create deterministic sensing matrices. applied matrices linear codewords generate matrix linear codewords suitable creating sensing matrices. using examples comparing existing asymptotically optimal matrices illustrated generality proposed method. secondly exploited column replacement method resize existing sensing matrices found bound coherence resulted matrices. using example especial case shown method behaves better kronecker product method developed observe special case theorem results matrices proposed hence", "year": "2018"}