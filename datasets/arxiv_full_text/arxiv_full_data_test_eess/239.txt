{"title": "Neural Style Transfer for Audio Spectograms", "tag": "eess", "abstract": " There has been fascinating work on creating artistic transformations of images by Gatys. This was revolutionary in how we can in some sense alter the 'style' of an image while generally preserving its 'content'. In our work, we present a method for creating new sounds using a similar approach, treating it as a style-transfer problem, starting from a random-noise input signal and iteratively using back-propagation to optimize the sound to conform to filter-outputs from a pre-trained neural architecture of interest.  For demonstration, we investigate two different tasks, resulting in bandwidth expansion/compression, and timbral transfer from singing voice to musical instruments. A feature of our method is that a single architecture can generate these different audio-style-transfer types using the same set of parameters which otherwise require different complex hand-tuned diverse signal processing pipelines. ", "text": "fascinating work creating artistic transformations images gatys revolutionary sense alter style image generally preserving content. work present method creating sounds using similar approach. demonstration investigate different tasks resulting bandwidth expansion/compression timbral transfer singing voice musical instruments. present machine learning technique generating music audio signals. focus work develop techniques parallel proposed artistic style transfer images gatys present cases modifying audio signal generate sounds. feature method single architecture generate different audio-style-transfer types using parameters otherwise require complex hand-tuned diverse signal processing pipelines. finally propose investigate generation spectrograms noise satisfying optimization criterion derived features derived ﬁlter-activations convolutional neural net. potential ﬂexibility sound-generating approach discussed. recent work applying architectures computer vision acoustic scene analysis. particular uses standard architectures alexnet vgg-net resnet sound understanding. performance gains vision models translated audio domain well. work used mel-ﬁlter-bank input representation short-time fourier transform log-magnitude instead. desire high-resolution audio representation perfect reconstruction possible e.g. grifﬁn-lim reconstruction experiments work audio spectrogram representation duration frame-size frame-step fft-size audio sampling rate khz. core success neural style transfer vision optimize input signal starting random noise take features interest derived activations different layers passing convolutional based classiﬁer trained content input image. follow similar approach modiﬁcations audio signals. first train standard alexnet architecture smaller receptive size instead larger receptive ﬁelds used original work. retain audio resolution along time frequency larger receptive ﬁelds would yield poor localization audio reconstruction results audible artifacts. also additional loss terms order match averaged timbral energy envelope. applications correspond timbre transfer musical instruments explicit knowledge features pitch note onset time type instrument alexnet trained audio spectograms distinguish classes musical instrument sounds convolutions pooling total layers objective function minimizing cross-entropy loss using adam optimizer focus experiments imposing style tuning fork harp resulting bandwidth compression fundamental transferring style violin note singing voice resulting bandwidth expansion. thus form cross-synthesis imposing style instrument content another applications similar explored various hyper-parameters single/multiple layers extract features optimization. goal single parameter setting perform tasks without explicitly develop hand-crafted rules. traditionally distinct signal processing based approaches tasks. subplots figs. a)-d) log-magnitude spectrograms y-axis -khz x-axis -.s. note fig. approach changes timbre also increases bandwidth signal seen strength higher harmonics. objective equation drives reconstructed spectrogram xrecon random noise spectra minimizes weighted loss terms denoting content loss style loss measure deviation temporal frequency energy envelopes respectively style audio. found matching weighted energy contour frequency energy contour namely averaged time loss function helped achieving improved quality. energy term loss function required gram matrix incorporate temporal dynamics target audio style would generally follow content included. figure shows gaussian noise start input optimize harp sound tuning fork neural style transferred output having content harp style tuning fork https//youtu.be/ulwbseigcde figure shows gaussian noise start input optimize singing sound violin note neural style transferred output content singing style violin. https//youtu.be/rpgbkfsuc proposed novel synthesize audio treating style-transfer problem starting random-noise input signal iteratively using back-propagation optimize sound conform ﬁlter-outputs pre-trained neural architecture. examples intended explore illustrate nature style transfer spectrograms musical examples subjects ongoing work. ﬂexibility approach promising results date indicate interesting future sound cross-synthesis methods. believe work extended many audio synthesis/modiﬁcation techniques based loss-term formulations problem interest excited hear lies ahead. acknowledgments authors would like thank andrew ng’s group stanford artiﬁcial intelligence laboratory computing resources. prateek verma would like thank ziang discussion challenges problem alexandre alahi style transfer work computer vision.", "year": "2018"}