{"title": "Classification vs. Regression in Supervised Learning for Single Channel  Speaker Count Estimation", "tag": "eess", "abstract": " The task of estimating the maximum number of concurrent speakers from single channel mixtures is important for various audio-based applications, such as blind source separation, speaker diarisation, audio surveillance or auditory scene classification. Building upon powerful machine learning methodology, we develop a Deep Neural Network (DNN) that estimates a speaker count. While DNNs efficiently map input representations to output targets, it remains unclear how to best handle the network output to infer integer source count estimates, as a discrete count estimate can either be tackled as a regression or a classification problem. In this paper, we investigate this important design decision and also address complementary parameter choices such as the input representation. We evaluate a state-of-the-art DNN audio model based on a Bi-directional Long Short-Term Memory network architecture for speaker count estimations. Through experimental evaluations aimed at identifying the best overall strategy for the task and show results for five seconds speech segments in mixtures of up to ten speakers. ", "text": "task estimating maximum number concurrent speakers single channel mixtures important various audio-based applications blind source separation speaker diarisation audio surveillance auditory scene classiﬁcation. building upon powerful machine learning methodology develop deep neural network estimates speaker count. dnns efﬁciently input representations output targets remains unclear best handle network output infer integer source count estimates discrete count estimate either tackled regression classiﬁcation problem. paper investigate important design decision also address complementary parameter choices input representation. evaluate stateof-the-art audio model based bi-directional long short-term memory network architecture speaker count estimations. experimental evaluations aimed identifying best overall strategy task show results seconds speech segments mixtures speakers. cocktail-party scenario many concurrent speakers different applications envisioned localization crowd monitoring surveillance speech recognition speaker separation. scenario typical assumption number concurrent speakers known turns paramount importance effectiveness subsequent processings. unfortunately real world applications information actual number concurrent speakers often available. surprisingly methods proposed address task counting number speakers. estimating maximum number concurrent speakers closely related difﬁcult problem identifying them topic speaker diarisation call system identiﬁes speakers ﬁrst counting detection. systems often segments speaker active discriminate speakers. comparisons found ∗international audio laboratories erlangen joint institution friedrich-alexander-universit¨at figure illustration application scenario three concurrent speakers respective speech activity. bottom plot shows number concurrently active speakers maximum targeted output. segments made discriminate temporally locate speakers within given recording. sources fully overlapped real cocktail party environments segmentation hardly feasible. speaker overlap prevalent cocktail-party scenario developing algorithm detect speakers challenging. study therefore attempt directly estimate speaker count instead counting identiﬁcation. refer strategy direct count estimation. multichannel signal processing count estimation usually achieved estimating directions arrival clustering ﬁrst single channel method based thresholding amplitude modulation patterns proposed authors propose energy feature based temporally averaged mel-scale ﬁlter outputs. recent work number speakers estimated applying hierarchical clustering ﬁxed-length audio segments. main weakness method rely assumption segments speaker active. another vein andrei et.al. proposed algorithm correlates single frames multi-speaker mixtures single-speaker utterances. motivated recent impressive successes deep learning approaches various audio-related tasks focus developing method direct count estimation. computer vision count estimation using dnns recently achieved state-of-the-art performance main paradigms found literature purpose namely regression classiﬁcation. work want build upon ﬁndings achieve direct count estimation speakers. main contributions formulate speaker count estimation problem either classiﬁcation regression task propose neural network architecture based state-of-the-art blstm network infer number speakers short audio segments finally present experimental results different problem formulations well input feature representations identify best strategy task. sake reproducibility pre-trained network test dataset made available download accompanying website. problem formulation consider task estimating maximum number concurrent speakers single channel audio mixture achieved applying mapping time domain signal samples representing linear mixture unique single speaker speech signals naturally speakers active every time instance. therefore sample introduce latent binary speech activity variable then task estimate assume additional prior information except maximum number concurrent speakers kmax available representing upper limit estimation. figure illustrate setup cocktail-party scenario featuring speakers. system proposed paper non-negative time-frequency input representation rd×f instead denote total number time frames frequency sub-bands respectively. study choose deep neural network mapping function input output given optimal parameters learned supervised training. output necessarily direct source count therefore introduce decision function trained supervised manner using training database examples. work want investigate three different choices output distributions well corresponding decision functions classiﬁcation output distribution directly taken discrete discarding meaning concerning ordering different possible values. given particular input network generates posterior output probability classes using softmax activation function maximum posteriori decision function chosen simply picks likely class max. notwithstanding conceptual simplicity classiﬁcation drawbacks. first intuitive ranking different estimates lost e.g. depend second largest possible count kmax given priori. despite limitations classiﬁcation-based approaches successfully applied deep neural networks counting objects images. gaussian regression regression derived output distribution deﬁned real line. output distribution setting assumed gaussian associated cost function classical squared error. inference given output network best discrete value consistent model simply rounding operator gaussian regression achieved state-of-the-art counting performance computer vision using deep learning frameworks discrete poisson modelling comes modelling count data often shown effective adopt poisson distribution first strategy retains advantage classiﬁcation approach directly pick probabilistic model actual discrete observations avoiding somewhat artiﬁcial trick introducing latent variable would rounded yield observation. second model avoids inconvenience classiﬁcation approach completely drop dependencies classes. advantages poisson distribution used studies devising deep architectures counting systems instance shown number objects images well modelled poisson distribution. inspired previous works also consider poisson output distribution denotes poisson distribution scale parameter setup cost function learning time poisson negative log-likelihood deep architecture test time provides predicted scale parameter summarizes whole output distribution. decision function setting considered several alternatives. ﬁrst option resort estimation pick mode distribution point estimate. however experiments showed posterior median yields better estimates given various audio-related applications share common architecture designs often found incorporating domain knowledge extensive hyperparameter searches. proposed task source count estimation however domain knowledge difﬁcult incorporate study aims revealing best strategy address problem. therefore network built upon existing blstm-rnn architecture already shown considerable amount generalization various audio applications recurrent neural network similar fully connected network except applies weights recursively input sequence. rnns detect structure sequential data arbitrary length. makes ideal model time series however practice temporal context learnt limited time instances vanishing gradient problem alleviate problem forgetting factors proposed. popular gated recurrent cells long short-term memory cell. effectiveness proven various applications lstms state-of-the-art approach speech recognition singing voice detection work employed bi-directional lstm three hidden layers whose sizes similar architecture introduced blstm robust compared simple lstm since input information past well future used learn weights. information blstms reader referred given input sequence output recurrent layer either last step output full sequence. found employing full sequence output last recurrent layer feeding fully connected output layer important context rnns count estimation. furthermore added temporal pooling layer pooling size reduce number parameters fully connected layer. temporal pooling intuitively problem formulation maximum number sources speciﬁc number frames. introduced section count estimation problem addressed using three different strategies. decision functions suitable output activation loss used shown table except parameters models parameters. since realistic dataset fully overlapped speakers available chose generate synthetic mixtures. recognize simulated cocktail-party environment mixtures lack conversational aspect human communication provide controlled environment helps understand solves count estimation problem. speaker independent solution selected speech corpus large number different speakers instead large number utterances yielding larger number unique mixtures. training selected librispeech clean- dataset includes hours clean speech english utterances speakers revealed section maximum number concurrent speakers requires annotation activity individual speaker. even though librispeech comes annotations often consistent across different corpora. therefore generated annotations based voice activity detection algorithm work used implementation chromium browser part webrtc standard generate single training sample draw unique speakers corpus. speakers select random utterance resampled sampling rate apply vad. method conﬁgured using size further estimate used remove silence beginning utterance recording. next step utterances speaker drawn corpus desired duration reached. both audio recording annotation utterance concatenated. procedure repeated speakers time domain signals created. signals mixed peak normalized avoid clipping. mixtures transformed time-frequency matrix deﬁned section ground truth output computed using matrix based equation follow proposal include non-speech examples training data avoid using zero input samples this used acoustic scenes dataset create negative training samples using procedure described above. environmental sounds could include speech scenes cafe/restaurant grocery store metro station omitted. application closely relates source separation desirable trained system robust gain variations. therefore important make sure cannot leverage gain factors mixture. found averaged energy across frames input sample already solid indicator number speakers. accomodate ﬁndings normalize average euclidean norm frames used additionally common machine learning scale normalized input representation feature dimensions zero mean unit variance/standard deviation across whole training dataset. train network poisson sampling balance number samples experiments chose medium-sized training dataset samples resulting total training items containing seconds audio resulting hours training material. actual duration input reduced seconds selecting random excerpt mixture. excerpt equation evaluated generate single sample combined mini-batches samples. network seeing slightly different samples training epoch. found procedure help speeding stochastic gradient based training process. trained using adam optimizer addition training dataset created separate validation dataset samples using different speakers librispeech dev-clean. early stopping applied monitoring validation loss reduce effect overﬁtting. training never exceeded epochs. evaluated proposed network architecture main parameters three proposed output distributions four different input representations. allow controlled test environment time limit number training iterations certain parameters experiment speakers mixed snr. experimental parameters training three times different random seeds report averaged results minimize random effects caused early stopping. used librispeech test-clean subsets generate unique unseen speaker mixtures seconds duration test kmax since dealing novel task description related speaker count estimation techniques like introduced section could hardly used baselines. speciﬁcally work fully overlapped speech scale size dataset since requires crosscorrelate full database another. finally proposes feature employ fully automated system. translated method data-driven approach employed vector quantizer optimal mapping respect squares criterion figure mean absolute error ground truth count error bars show conﬁdence intervals. results averaged different feature representations output distributions task chose several different input representations well-established speech application. expect high frequency resolution needed discriminate time frequency bins overlapped speech segments belong single speaker. compared following input representations based frame length stft magnitude short-time fourier transform computed using hann windows. resulting input logstft logarithmically scaled magnitudes stft representation using log. resulting input compute mapping stft output directly onto basis using triangular ﬁlters. resulting input mfcc first mel-frequency cepstral coefﬁcients. resulting input intermediate output treated either classiﬁcation regression problem evaluate ﬁnal output discrete regression problem. therefore evaluate performance using mean absolute error also used evaluate count related tasks best parameters performed training evaluation parameters resulting trained networks. average network trained epochs early stopping engaged. training duration seconds epoch nvidia gpu. present results terms input representation output distribution figure overall trend count error similar regardless parametrisation models able reliably distinguish followed nearly linear increase seen classiﬁcation networks learned maximum across dataset hence prediction error decreases reaches maximum. classiﬁcation based models intrinsically access maximum number sources determined output vector dimensionality. figure indicates classiﬁcation outperforms distributions poisson regression performs better gaussian regression conﬁrms ﬁndings made object counts. respect input representation shown figure despite larger input dimension choosing linear stft generally results better performance compared logstft mfcc. detailed analysis distribution feature combinations shown space constraints reveals stft classiﬁcation performs best. model achieves results baseline performs slightly better mean estimator predicting show level overestimation underestimation depict responses confusion matrix unlike humans generally tend underestimate task speaker count estimation proposed model slightly overestimates smaller introduced task estimating maximum number concurrent speakers simulated cocktail-party environment using data-driven approach. evaluated three different methods output integer source count estimates conjunction deﬁning cost function optimize. experiments revealed tradeoff better overall performance requiring maximum number speakers estimated prior knowledge slightly worse performance treated regression problem using poisson distribution. furthermore investigated evaluated suitable input representations. ﬁnal proposed blstm based classiﬁcation model achieves mean absolute error less speakers zero speakers. think ﬁrst study data-driven speaker count estimation opens ﬁeld interesting research. future work would evaluate optimize network structures convolutional neural networks investigate strategy machine learning source count model pursues solve problem.", "year": "2017"}