{"title": "Attacking Speaker Recognition With Deep Generative Models", "tag": "eess", "abstract": " In this paper we investigate the ability of generative adversarial networks (GANs) to synthesize spoofing attacks on modern speaker recognition systems. We first show that samples generated with SampleRNN and WaveNet are unable to fool a CNN-based speaker recognition system. We propose a modification of the Wasserstein GAN objective function to make use of data that is real but not from the class being learned. Our semi-supervised learning method is able to perform both targeted and untargeted attacks, raising questions related to security in speaker authentication systems. ", "text": "modern generative models sophisticated enough produce fake speech samples indistinguishable real human speech. section provide summary existing neural speech synthesis models architectures. wavenet generative neural network trained end-to-end model quantized audio waveforms. model fully probabilistic autoregressive using stack causal convolutional layers condition predictive distribution audio sample previous ones. produced impressive results generation speech audio conditioned speaker text become standard baseline neural speech generative models. samplernn another autoregressive architecture successfully used generate speech music samples. samplernn uses hierarchical structure deep rnns model dependencies sample sequence. deep operates different temporal resolution model long term short term dependencies. recent work deep learning architectures also introduced presence adversarial examples small perturbations original inputs normally imperceptible humans nevertheless cause architecture generate incorrect deliberately chosen output. brilliant papers analyze origin adversarial attacks describe simple efﬁcient techniques creating perturbations fast gradient sign method vision domain describe technique attacking facial recognition systems. attacks physically realizable inconspicuous allowing attacker impersonate another individual. speech domain describe paper investigate ability generative adversarial networks synthesize spooﬁng attacks modern speaker recognition systems. ﬁrst show samples generated samplernn wavenet unable fool cnn-based speaker recognition system. propose modiﬁcation wasserstein objective function make data real class learned. semi-supervised learning method able perform targeted untargeted attacks raising questions related security speaker authentication systems. speaker authentication systems deployed security critical applications industries like banking forensics home automation. like domains industries beneﬁted recent advancements deep learning lead improved accuracy trainability speech authentication systems. despite improvement efﬁciency systems evidence shows susceptible adversarial attacks thus motivating current focus understanding adversarial attacks ﬁnding countermeasures detect deﬂect designing systems provably correct respect mathematically-speciﬁed requirements parallel advancements speech authentication neural speech generation also seen huge progress recent years combination advancements begs natural question best knowledge answered generative adversarial networks generative models recently used produce incredibly authentic samples variety ﬁelds. core idea gans minimax game played generator network discriminator network extends naturally ﬁeld speaker authentication spooﬁng. best knowledge gans used purpose speech synthesis. uses conditional purpose speech enhancement i.e. taking input speech signal outputting denoised waveform. model tackles reverse problem using gans learn certain representations given speech spectrogram. speaker recognition system used experiments based framework described figure ﬁrst module bottom pre-processing step extracts mel-spectrogram waveform described section second module convolutional neural network performs multi-speaker classiﬁcation using mel-spectrogram. modiﬁed version alexnet warn readers unlike classiﬁer operates mel-spectrogram slightly different number nodes layer. train speaker classiﬁer using melspectrograms speech datasets including speakers nist speaker cstr vctk single speaker blizzard. speaker classiﬁer rejection path other class trained environmental sounds using samples esc- dataset. model achieves approximately test accuracy interested designing input makes classiﬁcation system predict target class chosen adversary. untargeted attacks adversary interested conﬁdent prediction regardless class predicted long \"other\" class. untargeted attacks essentially designed fool classiﬁer thinking fake speech sample real. note successful targeted attack deﬁnition successful untargeted attack well. experiments three speech datasets dataset environmental sounds shown table datasets used public provide audio clips different lengths quality language content. addition samples listed table used globally conditioned samplernn wavenet fake samples available web. samples generated samplernn wavenet blizzard dataset cstr vctk respectively. data pre-processing dependent model trained. samplernn wavenet audio reduced quantized using µ-law companding transformation referenced model based wasserstein pre-process data converting removing silences using webrtc voice activity detector referenced speaker recognition system data pre-processed resampling necessary removing silences using aforemetioned vad. samplernn wavenet operate sample level i.e. waveform thus requiring feature extraction. features used neural speaker recognition system based mel-spectrograms dynamic range compression. melspectrogram obtained projecting spectrogram onto scale. python library librosa project spectrogram onto bands window size equal samples size equal samples i.e. long frames. dynamic range compression computed constraints computing power extreme difﬁculty training wavenet used samples wavenet models pre-trained thousand iterations. parameters models kept ability wavenet perform untargeted attacks amounts using model trained entire corpus. targeted attacks difﬁcult found single speaker’s data enough train wavenet converge successfully. construct speaker-dependent samples relied samples pre-trained models globally conditioned speaker based informal listening experiments samples sound similar real speech speaker question. similarly wavenet found best samplernn samples came models pretrained high number iterations. accordingly obtained samples three-tiered architecture trained blizzard dataset mentioned section hour corpus single female speaker’s narration. also downloaded samples online repositories including samples original paper’s online repository https//soundcloud.com/samplernn/sets qualitatively found less noise ours. experiments wasserstein gradient penalty found makes model converge better regular wgan experiments trained wgan-gp produce melspectrograms target speaker speakers. critic iteration batch samples target speaker batch data uniformly sampled speakers. used popular architectures generator/critic pairs dcgan resnet performing untargeted attacks wgan-gp relatively straightforward simply train wgan-gp using speakers dataset. however natural attack targeted trained directly fool speaker recognition system naive approach targeted attacks train data single target speaker. drawback approach critic consequence generator access universal properties speech. circumvent problem rely semi-supervised learning propose modiﬁcation critic’s objective function allows learn differentiate real samples generated samples also real speech samples target speaker real speech samples speakers. adding term critic’s loss encourages discriminator classify real speech samples untargeted speakers fake ex∼pg distribution samples speakers tunable scaling factor. note equation longer direct approximation wasserstein distance. rather provides balance distance fake distribution real distance speakers’ distribution target speaker’s one. refer objective function mixed loss. initially able converge targeted loss model used parameters namely critic iterations generator iteration gradient penalty weight batch size generator critic trained using adam optimizer however parameters found highest weight could successfully order circumvent problems train model made modiﬁcations setup including setting standard deviation dcgan discriminator’s weight initialization iterations accommodate critic’s access additional data mixed loss function increased generator’s learning rate. finally added gaussian noise target speaker data prevent overﬁtting. using improved wasserstein gans framework trained generators construct mel-spectrogram images noise vector. visual results demonstrated figure recognizable mel-spectrogram-like features data generator iterations iterations generated samples indistinguishable real ones. training took around hours iterations single nvidia gkgl gpu. within framework train models untargeted attacks using data available speakers speaker recognition systems trained irrespective class label. show subsection untargeted model able generate data real distribution enough variety used perform adversarial attacks. figure depicts gan-trained generator successfully learns speakers across dataset without mode collapsing. described earlier models targeted attacks trained manners conditioning model additional information e.g. class labels described using data label interest. ﬁrst approach might result mode collapse drawback second approach discriminator consequence generator access universal properties speech. targeted attacks subsection show results using objective function described equation allows using data speakers. speaker audio data test compute mel-spectrogram descibred section resulting mel-spectrogram recognizer extract -dimensional feature ﬁrst fullyconnected layer pre-trained model trained real speech dataset speaker ids. deep feature/embedding used train k-nearest-neighbor classiﬁer equal trained wgan-gp entirety nist corpus single speaker vctk corpus single speaker blizzard dataset. samples models either downloaded created wavenet globally conditioned single vctk corpus speaker samplernn trained data blizzard dataset. results wgan-gp demonstrated figure samples generated samplernn wavenet models none predictions made classiﬁer match target speaker. also trained wgan-gp without mixed loss different speakers. histogram predictions figure shows wgan-gp results speaker improved wgan-gp loss achieves error rate mixed loss achieves error rate producing increase accuracy. research investigated speech generative models perform adversarial attacks speaker recognition systems. show samples autoregressive models trained i.e. samplernn wavenet downloaded able fool speaker recognizers used research. hand show adversarial examples generated networks successful performing targeted untargeted adversarial attacks given speaker recognition used herein. zhizheng nicholas evans tomi kinnunen junichi yamagishi federico alegre haizhou spooﬁng countermeasures speaker veriﬁcation survey speech communication vol. christian szegedy wojciech zaremba ilya sutskever joan bruna dumitru erhan goodfellow fergus intriguing properties neural networks arxiv preprint arxiv. yuxuan wang skerry-ryan daisy stanton yonghui weiss navdeep jaitly zongheng yang ying xiao zhifeng chen samy bengio tacotron fully end-to-end text-to-speech synthesis model arxiv preprint arxiv. aäron oord sander dieleman heiga karen simonyan oriol vinyals alex graves kalchbrenner andrew senior koray kavukcuoglu wavenet generative model audio corr abs/. ishaan gulrajani rithesh kumar shubham jain jose sotelo aaron courville yoshua bengio samplernn unconditional end-to-end neural audio generation model arxiv preprint arxiv. mahmood sharif sruti bhagavatula lujo bauer michael reiter accessorize crime real stealthy attacks state-of-the-art face recognition proceedings sigsac conference computer communications security. nicholas carlini pratyush mishra tavish vaidya yuankai zhang micah sherr clay shields david wagner wenchao zhou hidden voice commands usenix security symposium austin yanick lukic carlo vogt oliver dürr thilo stadelmann speaker identiﬁcation clustering using convolutional neural networks machine learning signal processing ieee international workshop ieee alex krizhevsky ilya sutskever geoffrey hinton imagenet classiﬁcation deep convolutional neural networks advances neural information processing systems adham zeidan armin lehmann ulrich trick webrtc enabled multimedia conferencing collaboration solution world telecommunications congress proceedings kishore prahallad anandaswarup vadapalli naresh elluru mantena pulugundla bhaskararao murthy king karaiskos black blizzard challenge –indian language task blizzard challenge workshop vol. goodfellow jean pouget-abadie mehdi mirza bing david warde-farley sherjil ozair aaron courville yoshua bengio generative adversarial nets advances neural information processing systems alec radford luke metz soumith chintala unsupervised representation learning deep convolutional generative adversarial networks arxiv preprint arxiv. christian ledig lucas theis ferenc huszár jose caballero andrew cunningham alejandro acosta andrew aitken alykhan tejani johannes totz zehan wang photo-realistic single image superresolution using generative adversarial network arxiv preprint arxiv.", "year": "2018"}