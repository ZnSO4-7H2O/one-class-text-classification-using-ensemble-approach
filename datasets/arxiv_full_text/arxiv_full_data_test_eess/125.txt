{"title": "Monaural Singing Voice Separation with Skip-Filtering Connections and  Recurrent Inference of Time-Frequency Mask", "tag": "eess", "abstract": " Singing voice separation based on deep learning relies on the usage of time-frequency masking. In many cases the masking process is not a learnable function or is not encapsulated into the deep learning optimization. Consequently, most of the existing methods rely on a post processing step using the generalized Wiener filtering. This work proposes a method that learns and optimizes (during training) a source-dependent mask and does not need the aforementioned post processing step. We introduce a recurrent inference algorithm, a sparse transformation step to improve the mask generation process, and a learned denoising filter. Obtained results show an increase of 0.49 dB for the signal to distortion ratio and 0.30 dB for the signal to interference ratio, compared to previous state-of-the-art approaches for monaural singing voice separation. ", "text": "singing voice separation based deep learning relies usage time-frequency masking. many cases masking process learnable function encapsulated deep learning optimization. consequently existing methods rely post processing step using generalized wiener ﬁltering. work proposes method learns optimizes source-dependent mask need aforementioned post processing step. introduce recurrent inference algorithm sparse transformation step improve mask generation process learned denoising ﬁlter. obtained results show increase signal distortion ratio signal interference ratio compared previous state-of-the-art approaches monaural singing voice separation. problem music source separation received attention ﬁelds audio signal processing deep learning adopted solution estimation time-varying source-dependent ﬁlter applied mixture performing ﬁltering operation done treating audio signals wide-sense stationary. involves transforming mixture signal using short-time fourier transform then source-dependent ﬁltering operation applied complex-valued coeﬃcients mixture signal. formally time-domain j-th source-dependent ﬁlter henceforth denoted mask. shown preferred estimating j-th source derive mask generalized wiener ﬁltering using α-power magnitude spectrograms deep learning methods music source separation trained using synthetically created mixtures divided categories. ﬁrst category methods predict mask directly mixture magnitude spectrum requires optimal given training target. however information unknown approximation computed training data using empirically chosen values hypothesis source magnitude spectra additive true realistic audio signals implies models optimized predict non-optimal masks. methods second category estimate sources mixture. approach widely adopted since straightforward employing denoising autoencoders noise corresponding addition sources. however masks dependent exception works presented methods jointly learned optimized masking processes described highway networks shown able approximate masking process monaural solo source separation robust alternative presented. approach uses recurrent encoder-decoder skipﬁltering connections allow source-dependent mask generation process applicable monaural singing voice separation. however generated masks robust interferences music sources thus requiring post-processing step using generalized wiener ﬁltering work present method source separation learns generate source-dependent mask require generalized wiener ﬁltering postprocessing step. introduce novel recurrent inference algorithm inspired sparsifying transform generating mask recurrent inference allows proposed method stochastic depth rnns mask generation process computing hidden latent representations presumably better generating mask. sparsifying transform used approximate mask using output recurrent inference. method mask prediction based mentioned assumptions additivity magnitude spectrogram sources part optimization process based deterministic function. additionally method incorporates rnns instead feed-forward convolutional layers mask prediction. allows method exploit memory rnns eﬃciency modeling longer time dependencies input data. rest paper organized follows section presents proposed method followed section provides information followed experimental procedure. section presents obtained results experimental procedure section concludes work. proposed method takes input time domain samples mixture outputs time domain samples targeted source. model consists four parts. ﬁrst part implements analysis pre-processing input. second part generates applies mask thus creating ﬁrst estimate magnitude spectrogram targeted source. third part enhances estimate learning applying denoising ﬁlter fourth part constructs time domain samples target source. call second part masker third denoiser. diﬀerentiate masker denoiser masker optimized predict time-frequency mask whereas denoiser enhances result obtained time-frequency masking. implement masker using single layer bi-directional encoder single layer decoder feed-forward layer skip-ﬁltering connections magnitude spectrogram mixture output ffn. implement denoiser using encoder decoder skip-ﬁltering connections input denoiser output ffndec. jointly train masker denoiser using criteria based generalized kullback-leibler divergence shown robust criterion matching magnitude spectrograms. rnns gated recurrent units proposed method illustrated figure vector containing time-domain samples monaural mixture sources sampled .khz. compute stft time frames samples segmented hamming window size samples. time frame zero-padded subsequent stft retain positive frequencies corresponding ﬁrst frequency sub-bands. yields complex-valued time-frequency representation cm×n corresponding magnitude rm×n≥ split ceiling function. subsequence overlaps preceding empirical factor stage. subsequence denoted |yin| furthermore produce low-bandwidth version frequency sub-bands frame yielding |ytr| |ytr|. operation retains information rt×f≥ output masker likely contain interferences sources denoiser aims learn denoising ﬁlter enhancing magnitude spectrogram estimated masking procedure. denoising ﬁlter implemented encoder-decoder architecture ffnenc ffndec fig. ffnenc ffndec shared weights time frames. ﬁnal enhanced magnitude spectrogram estimate target source ˆyj| |yj| magnitude spectrogram true source diag{·} denotes elements main diagonal matrix vector norm squared matrix norm respectively λmask λdec scalars. λrec following condition applies connections used ease training recurrent inference mask prediction inspired recent optimization methods employing stochastic depth propose recurrent inference algorithm processes latent variables rnndec aﬀect mask generation. algorithm order employ stochastic depth network parts responsible predicting mask increasing performance method. recurrent inference iterative process consists reevaluating latent variables produced rnndec convergence criterion reached thus avoiding need specify ﬁxed number applications rnndec. stopping criterion threshold mean-squared-error consecutive estidec lmse threshold τterm. maximum mates number iterations used avoid inﬁnite iterations convergence mentioned consecutive estimates. used singing voice i.e. source-dependent trainable function rnndec. recurrent inference performed using algorithm relu element-wise rectiﬁed linear unit function producing sparse approximation target sparsiﬁcation performed order improve interference reduction penalization elements main diagonal wmask ensure generated mask something trivial reconstruction losses using ensure source-dependent mask generated minimizes aforementioned distance. squared matrix norm employed improve generalization model. processing subsequence using proposed method estimates concatenated together form ˆyj| rm×n≥ singing voice retrieve complexvalued stft means iterations griﬃnlim algorithm initialized mixture’s phase development subset demixing secret dataset non-bleeding/non-instrumental stems medleydb training validation proposed method. evaluation subset used testing objective performance method. multi-track contained audio corpus monaural version four sources generated averaging available channels. training true source element-wise multiplied factor performed avoid inconsistencies time delays mixing gains mixture signal singing voice length sequences modeling approximately seconds thresholds minimization τrec τmin corresponding scalars λmask λdec hidden hidden matrices gradient norm clipping equal total number epochs. reported parameters chosen experimentally random audio ﬁles drawn development subset dsd. implementation based pytorch. compared method state-of-the-art approaches dealing monaural singing voice separation following standard metrics namely signal noise ratio signal distortion ratio expressed rules proposed music source separation evaluation campaign compared methods deep ffns predicting binary soft masks combined provide source estimates convolutional encoder-decoder magnitude source estimation without trainable mask approximation iii) mim-hw deep highway networks music source separation approximating ﬁltering process retrained using development subset mim-dwf mim-dwf+ encoder-decoder models combined generalized wiener ﬁltering trained development subset additional stems medleydb methods denoted mimhw mim-dwf mim-dwf+ re-implemented purposes work. rest methods used reported evaluation results obtained proposed methods denoted gru-nri include recurrent inference algorithm methods using diﬀerent hyper-parameters recurrent inference algorithm gru-riss parametrized using maximum number iterations iter τterm gru-risl parametrized using maximum number iterations iter τterm selected table summarizes results objective evaluation aforementioned methods showing median values obtained metrics. proposed method based recurrent inference sparsifying transform able provide state-of-the-art results monaural singing voice separation without necessity post-processing steps generalized wiener ﬁltering and/or additionally trained deep neural networks. compared methods approximate masking processes signiﬁcant improvements overall median performance metrics especially masks learned function case cha. using proposed method gain observed mim-dwf+ grurisl mim-dwf gru-riss. finally allowing larger number iterations recursive inference mask generation performance using skip-ﬁltering connections increase outperforms previous methods mim-dwf mim-dwf+ cost loss sir. demo proposed method available https//js-mim.github.io/mss_pytorch/. work presented approach singing voice separation require post-processing using generalized wiener ﬁltering. introduced skip-ﬁltering connections sparsifying transform yielding comparable results approaches rely generalized wiener ﬁltering. furthermore introduced recurrent inference algorithm shown provide state-of-the-art results monaural singing voice separation. experimental results show extensions outperform previous deep learning based approaches singing voice separation. research leading results received funding european union’s framework programme grant agreement macsenet. part computations leading results performed titan-x donated drossos nvidia. authors would like thank paul magron precious feedback.", "year": "2017"}