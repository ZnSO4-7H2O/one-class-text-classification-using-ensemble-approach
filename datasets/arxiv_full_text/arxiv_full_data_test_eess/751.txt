{"title": "Speaker Verification using Convolutional Neural Networks", "tag": "eess", "abstract": " In this paper, a novel Convolutional Neural Network architecture has been developed for speaker verification in order to simultaneously capture and discard speaker and non-speaker information, respectively. In training phase, the network is trained to distinguish between different speaker identities for creating the background model. One of the crucial parts is to create the speaker models. Most of the previous approaches create speaker models based on averaging the speaker representations provided by the background model. We overturn this problem by further fine-tuning the trained model using the Siamese framework for generating a discriminative feature space to distinguish between same and different speakers regardless of their identity. This provides a mechanism which simultaneously captures the speaker-related information and create robustness to within-speaker variations. It is demonstrated that the proposed method outperforms the traditional verification methods which create speaker models directly from the background model. ", "text": "abstract—in paper novel convolutional neural network architecture developed speaker veriﬁcation order simultaneously capture discard speaker non-speaker information respectively. training phase network trained distinguish different speaker identities creating background model. crucial parts create speaker models. previous approaches create speaker models based averaging speaker representations provided background model. overturn problem ﬁne-tuning trained model using siamese framework generating discriminative feature space distinguish different speakers regardless identity. provides mechanism simultaneously captures speaker-related information create robustness within-speaker variations. demonstrated proposed method outperforms traditional veriﬁcation methods create speaker models directly background model. speaker veriﬁcation identity query spoken utterance conﬁrmed comparing gallery known speakers. speaker veriﬁcation categorized text-dependent textindependent. text-independent restriction considered utterances. hand textdependent setting speakers repeat phrase. variational nature former setup considers challenging task since system must able clearly distinguish speaker non-speaker characteristics uttered phrases. general procedure speaker veriﬁcation consists three phases development enrollment evaluation. development background model must created capturing speaker-related information. enrollment speaker models created using background model. finally evaluation recently advent deep learning different applications speech image recognition network pruning data-driven approaches using deep neural networks also proposed effective feature learning automatic speech recognition speaker recognition also deep architecture mostly treated black boxes approaches based information theory presented multimodal feature extraction demonstrated promising results traditional successful model speaker veriﬁcation gaussian mixture model-universal background model i-vector main disadvantage models unsupervised nature since trained objectively speaker veriﬁcation setup. methods proposed supervise aforementioned models training svm-based gmm-ubms plda i-vectors model advent convolutional neural networks promising results action recognition scene understanding recently proposed well speaker speech recognition work propose siamese neural networks operate traditional speech features mfccs instead feature higherlevel representation speaker-related characteristics. moreover show advantage utilizing effective pair selection method veriﬁcation purposes. convolutional neural networks recently used speech recognition deep models effectively proposed utilized textindependent setup research efforts locally connected networks utilized well although setup textdependent. works deep networks employed feature extractors create speaker models evaluations. investigate cnns speciﬁcally trained end-to-end veriﬁcation purposes furthermore employ feature extractors distinguish speaker non-speaker information. speaker models using score function highest score predicted speaker. considering one-vs-all setup stage equivalent binary classiﬁcation problem traditional equal error rate used model evaluation. false reject rate false accept rate determined predeﬁned threshold errors become equal operating point eer. usually scoring function simple cosine similarity score employed. score measured similarity representation test utterance targeted speaker model. speaker veriﬁcation protocol categorized evaluation. general view speaker veriﬁcation protocol depicted explain phases section special emphasis adapted deep learning. different research efforts proposed variety methods implementing adapting protocol i-vector d-vector system development speaker utterances utilized creating background model representation. different elements speaker model type deep networks bayesian models training objective forms speaker representation type. main motivation behind employing architecture powerful speaker feature extractor. enrollment stage distinct model created speaker identity. speaker utterances utilized speaker model generation. case dnns phase speaker utterances input model created previous phase outputs integrated method create unique speaker model. speaker representation provided averaging outputs common choice used public voxceleb dataset experiments contains around utterances speakers around utterances speaker identities used testing. dataset balanced based gender spanned different ethnicities accents. audios extracted uploaded videos youtube captured wide variety challenging multi-speaker settings including background chatter overlapping speech channel noise different qualities recording. general statistics dataset available table audio features extracted re-sampled khz. spectrogram generation hamming windows step size used point spectrum. used -second audio stream yields spectrogram size mean variance normalization used. voice activity detection performed well. generated spectrum log-energy ﬁlter banks hamming window alongside ﬁrst second order derivatives generated form input feature map. feature extraction speechpy library utilized. architecture similar vgg-m widely used image classiﬁcation speech-related applications details available table iii. modiﬁed architecture considerations adapted input pipeline pooling layer size shrunk smaller architecture faster training empirically found less prone overﬁtting. main reason pooling time keep temporal claimed increase robustness temporal variations. practice found degrading performance perform pooling time dimension. observations investigated veriﬁed well. usual method train softmax loss function classiﬁcation features extracted fullyconnected layer prior softmax. however reasonable criticism method softmax loss criterion tries identify speakers verify available identity one-vs-all setup inconsistent speaker veriﬁcation protocol. instead utilize siamese neural network proposed implemented many research efforts siamese architecture consists identical cnns. main goal create common feature subspace discrimination match nonmatch pairs based distance metric. model demonstrated fig. general idea pairs belong identity distance common feature subspace close possible possible otherwise. assume input pairs system distance pair input output subspace deﬁned −norm vectors) distance computed follows comparison. gmm-ubm gmm-ubm method mfccs coefﬁcients cepstral mean variance normalisation used. training universal background model made mixture components iterations training data used. i-vectors i-vectors system widely known state-of-the-art representations operate frame-level proposed probabilistic linear discriminant analysis also used i-vector dimensionality reduction used tensorflow deep learning framework model trained nvidia pascal gpu. data augmentation used development phase. batch normalization employed robustness internal covariate shifts less affected initialization veriﬁcation training network classiﬁer ﬁne-tune network training siamese architecture epochs. unlike procedure used freeze weights layer ﬁne-tuning. speaker veriﬁcation followed protocol provided identities names start used testing. subjects used purpose training testing though. subjects create match non-match pairs veriﬁcation purposes. mentioned proposed end-to-end architecture alongside adapting active learning procedure pair selection speaker veriﬁcation application. observed effective online pair selection method addition training system end-to-end fashion outperform traditional method uses background models speaker representation. proposed architecture also trained feature extractor traditional speech features rather audio directly capturing inter-speaker intra-speaker variations. krizhevsky sutskever hinton imagenet classiﬁcation deep convolutional neural networks advances neural information processing systems hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath deep neural networks acoustic modeling speech recognition shared views four research groups ieee signal processing magazine vol. pool tran dally learning weights connections efﬁcient neural network advances neural information processing systems scheffer ferrer mclaren novel scheme speaker recognition using phonetically-aware deep neural network acoustics speech signal processing ieee international conference ieee moreno gonzalez-dominguez deep neural networks small footprint text-dependent speaker veriﬁcation acoustics speech signal processing ieee international conference ieee garcia-romero espy-wilson analysis i-vector length normalization speaker recognition systems twelfth annual conference international speech communication association tran bourdev fergus torresani paluri learning spatiotemporal features convolutional networks computer vision ieee international conference ieee abdel-hamid a.-r. mohamed jiang deng penn convolutional neural networks speech recognition ieee/acm transactions audio speech language processing vol. sainath a.-r. mohamed kingsbury ramabhadran deep convolutional neural networks lvcsr acoustics speech signal processing ieee international conference ieee richardson reynolds dehak deep neural network approaches speaker language recognition ieee signal processing letters vol. y.-h. chen lopez-moreno sainath visontai alvarez parada locally-connected convolutional neural networks small footprint speaker recognition sixteenth annual conference international speech communication association heigold moreno bengio shazeer end-toend text-dependent speaker veriﬁcation acoustics speech signal processing ieee international conference ieee kenny boulianne ouellet dumouchel joint factor analysis versus eigenchannels speaker recognition ieee transactions audio speech language processing vol. chopra hadsell lecun learning similarity metric discriminatively application face veriﬁcation computer vision pattern recognition cvpr ieee computer society conference vol. ieee varior haloi wang gated siamese convolutional neural network architecture human re-identiﬁcation european conference computer vision springer abadi agarwal barham brevdo chen citro corrado davis dean devin ghemawat goodfellow harp irving isard jozefowicz kaiser kudlur levenberg man´e monga moore murray olah schuster shlens steiner sutskever talwar tucker vanhoucke vasudevan vi´egas vinyals warden wattenberg wicke zheng tensorflow large-scale machine learning heterogeneous systems software available tensorﬂow.org. ioffe szegedy batch normalization accelerating deep network training reducing internal covariate shift international conference machine learning", "year": "2018"}