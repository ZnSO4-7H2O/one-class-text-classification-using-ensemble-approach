{"title": "Complex-Valued Restricted Boltzmann Machine for Direct Speech  Parameterization from Complex Spectra", "tag": "eess", "abstract": " This paper describes a novel energy-based probabilistic distribution that represents complex-valued data and explains how to apply it to direct feature extraction from complex-valued spectra. The proposed model, the complex-valued restricted Boltzmann machine (CRBM), is designed to deal with complex-valued visible units as an extension of the well-known restricted Boltzmann machine (RBM). Like the RBM, the CRBM learns the relationships between visible and hidden units without having connections between units in the same layer, which dramatically improves training efficiency by using Gibbs sampling or contrastive divergence (CD). Another important characteristic is that the CRBM also has connections between real and imaginary parts of each of the complex-valued visible units that help represent the data distribution in the complex domain. In speech signal processing, classification and generation features are often based on amplitude spectra (e.g., MFCC, cepstra, and mel-cepstra) even if they are calculated from complex spectra, and they ignore phase information. In contrast, the proposed feature extractor using the CRBM directly encodes the complex spectra (or another complex-valued representation of the complex spectra) into binary-valued latent features (hidden units). Since the visible-hidden connections are undirected, we can also recover (decode) the complex spectra from the latent features directly. Our speech coding experiments demonstrated that the CRBM outperformed other speech coding methods, such as methods using the conventional RBM, the mel-log spectrum approximate (MLSA) decoder, etc. ", "text": "representations based amplitude spectra speech traditionally used speech signal processing input features speech recognition output features speech synthesis amplitude spectra effective relevant auditory ﬁeld tasks phase spectra. amplitude spectral representation also used however features include amplitude spectra theoretically lack phase information single amplitudebased features cannot completely recover original complex spectra reasonable computational resources easily even using well-known grifﬁn-lim algorithm reported generated speech signals direct waveform modiﬁcation synthesis much natural methods based phase reconstruction amplitude spectra. furthermore many cases kinds signal processing deal complex-valued actual data fmri images wireless signals acoustic intensity etc. machine learning models—that neural networks boltzmann machines non-negative matrix factorization extensions proposed represent complex-valued data previous work proposed extended model namely complex-valued tackle representing complex-valued data rbm-based approach particular. crbm includes three important characteristics. firstly crbm connections across dimensions layers connections visible hidden units like rbms. restrictions make exceedingly easy estimate parameters using gibbs sampling cannot seen extension boltzmann machine feeds complex-valued data connections across dimensions difﬁculties parameter estimation. secondly unlike conventional crbm restricts connections different visible units still connections real imaginary parts visible unit. therefore crbm represents complex-valued data distribution accurately rbms especially correlations real imaginary parts. thirdly crbm represents complex-valued visible units rectangular form abstract—this paper describes novel energy-based probabilistic distribution represents complex-valued data explains apply feature extraction complex-valued spectra. proposed model complex-valued restricted boltzmann machine designed deal complex-valued visible units extension wellknown restricted boltzmann machine like crbm learns relationships visible hidden units without connections units layer dramatically improves training efﬁciency using gibbs sampling contrastive divergence another important characteristic crbm also connections real imaginary parts complex-valued visible units help represent data distribution complex domain. speech signal processing classiﬁcation generation features often based amplitude spectra even calculated complex spectra ignore phase information. contrast proposed feature extractor using crbm directly encodes complex spectra binary-valued latent features since visible-hidden connections undirected also recover complex spectra latent features directly. speech coding experiments demonstrated crbm outperformed speech coding methods methods using conventional mel-log spectrum approximate decoder etc. wide range research ﬁelds artiﬁcial intelligence machine learning signal processing includes image classiﬁcation speech recognition etc. many models proposed tools deep learning; widely-used famous models deep belief-net stacks multiple restricted boltzmann machines layer-by-layer. probabilistic model consists visible hidden units often used alone feature extractor generator classiﬁer pre-training scheme deep neural networks. many extensions proposed task speciﬁcation indicates parameters contains bias parameters visible units bias connection parameters hidden units weight parameters visible-hidden units ri×j standard deviation parameters associated dimension independent gaussian visible units deﬁne diag returns diagonal matrix whose diagonal vector argument indicates element-wise square operation). parameters often estimated using maximum likelihood gradient descent/ascent given training partial gradients parameters expected likelihood consists real imaginary components traditional representation methods complex-valued data include dubm based polar form phase amplitude components. generate samples distribution straightforwardly crbm. conditional probability visible units given hidden units form complex-normal distribution makes real imaginary components gaussian-distributed. showed crbm sufﬁciently recovered amplitude phase components well real imaginary components speech coding experiments. also propose improvements learning techniques crbm-based speech parameterization. first reduce number dimensions feeding complexvalued visible features obtained complex principal component analysis crbm instead complex spectra. next employ maximum likelihood parameter generation generate trajectories cpca features better representation speech sequences. finally extend adam algorithm deal complex-valued parameters makes convergence model training faster steepest descent/ascent. experiments compare performance improved crbm method speech coding methods conventional mel-log spectrum approximate etc. paper organized follows. section brieﬂy review conventional present proposed model crbm section section present improvement methods crbm using cpca. section propose complex-valued sequence generation method based mlpg. section show experimental results conclude ﬁndings section restricted boltzmann machine widely used energy-based models convenient representing latent features cannot observed surely exist background. bernoulli-bernoulli originally introduced freund deﬁnes distribution binary-valued visible variables binary-valued hidden variables undirected real-valued connection weights ri×j shown fig. numbers dimensions respective visible hidden units indicates binary set. later extended deal real-valued data known gaussian-bernoulli shown fig. however reported difﬁculties original gb-rbm unstable training parameters. later proposed improved learning method gb-rbm overcome difﬁculties. remainder paper refer improved gb-rbm unless otherwise stated. modeling using joint probability conventional rbms directly conditional probability visible units speciﬁes binaryrealvalued variables eqs. indicate. words conditional probability visible units specify complex-valued variables order feed complex-valued variables model. approach deﬁne extension feeds complex-valued data forms conditional probability visible units complex normal distribution real-valued cost function still used parameter estimation extended rbm— namely complex-valued furthermore crbm wegive restriction connections visible units hidden units enables easy estimation parameters does. however allow model connections real imaginary parts order capture relationships real imaginary parts complex-valued visible unit. denotes complex-conjugate denotes hermitiantranspose. ci×j bias parameters visible units hidden units biased connection weights visible hidden units respectively. order make restrictions extended covariance matrix consists covariance matrix pseudo-covariance matrix c—both diagonal matrices—as expectation value approximated using gibbs sampling efﬁciently contrastive divergence deﬁnition eqs. conditional probabilities form quite simple distributions indicate multivariate gaussian distribution mean variance matrix multi-dimensional bernoulli distribution success probabilities element-wise sigmoid function respectively. eqs. indicates easily compute iteration drawing samples given given used gibbs sampling true bb-rbm. case bb-rbm conditional probabilities turn following complex-valued learning rate. simple suitable large amount training data speech slow convergence speed. therefore propose another efﬁcient learning method complex-valued adaptive momentum motivated real-valued adam algorithm cadam introduce auxiliary parameters update parameters conﬁrms energy function probability distribution real-valued connections complex-valued visible units conjugates dimension connections different dimensions. diag decompose gb-rbm parameters eqs. fig. depicts concatenating representation complex-valued data using gb-rbm. example negative partial differentials real imaginary parts bias parameters energy function representation derived comparing energy functions eqs. latter energy function includes cross term rxyy) former energy function not. therefore claim crbm representation extends conventional gb-rbm connections real imaginary parts dimension weights fig. diagonal vector rxy. furthermore gb-rbm representation gradients regarding real imaginary parts bias visible units example calculated independently eqs. indicate gradients bias visible units crbm representation calculated using real imaginary terms indicates. make model convergence better gb-rbm. complex spectra compression using cpca paper represent trajectories complexvalued speech spectra. general number dimensions complex spectra tends large update using gradients manner similar improved gb-rbm second term right-hand side usually requires high computational cost. however restrictions crbm second term efﬁciently approximated using gibbs sampling similar conventional rbms. relationships complex representation using gb-rbm also represent complex-valued vector real space using conventional gbrbm feeds double-sized concatenated vector paper estimate optimum sequence using complex-valued gradient method similar discussed previous section. speciﬁcally using initial sequence frame-wise optima static features from order conﬁrm effectiveness proposed crbm ﬁrst conducted simple experiment using one-dimensional complex-valued artiﬁcial data artiﬁcially created data illustrated fig. black dots correlations real imaginary parts. experiment compared crbm conventional real-valued visible units; real part another imaginary part. trained models hidden units using steepest speech window length complex spectra dimensions makes difﬁcult dynamic features segment features input model sizable number parameters. therefore reduced dimensions using complex principal component analysis paper. indicate diagonal matrix diagonal elements inverse eigenvalues empirical covariance matrix complex matrix whose columns complex eigenvectors corresponding eigenvalues. conversely recover complex spectra calculate inversion speech modeling experiments discussed later used concatenated features calculated using visible units crbm cpca degree complex spectra analyzed window length dynamics calculated .zt+ .zt−. total dimensions visible units crbm experiments crbm trained maximize expected likelihood concatenated feature set. apply crbm represent speech spectra need improvements compare feature extraction methods speech. section improved methods dealing trajectory modeling presented. inversely decoded calculating expectations visible units wˆht frame-by-frame. however speech signals sequences; correlations adjacent frames speech. paper employ trajectory modeling sequence generation instead frame-wise modeling. proposed efﬁcient method recovers complex-valued visible units involving correlations among neighbor frames based maximum likelihood parameter generation mlpg algorithm estimate optimum sequence features static dynamic features based maximum likelihood estimation. cannot directly applied complex-valued features; therefore present following formulation. training crbm estimated optimum sequence cpca features number frames test speech encoded features table pesq crbm methods changing number hidden units methods notation trajectory estimation; otherwise frame-wise estimation. denotes grifﬁn-lim algorithm. perceptual evaluation speech quality recovered signals using inverse short-time fourier transform overlap-add method cpca features changing number dimensions shown table table shows pesq similar higher therefore used rest experiments terms sufﬁcient quality dimensional reduction. methods compared compared proposed method previous model feeds concatenated real-valued vectors real imaginary parts cpca features trajectory version feeds static dynamic features another rbm-based method compared trained using -dimensional real-valued features obtained amplitude spectra followed visible units recovered speech signals using grifﬁnlim algorithm models evaluated changing number hidden units crbms trained using stochastic gradient method -size mini-batches epochs learning rate complex adam parameters rbms except using real-valued steepest ascent adam. gradient method estimate sequence used epochs learning rate also compared proposed method traditional speech coding cepstral mel-cepstral analysis. cepstral coefﬁcients recovered speech using magnitude approximation ﬁlter -dimensional mel-cepstral coefﬁcients restored speech using mel-log spectrum approximate ﬁlter finally compared world high-quality speech analysis-by-synthesis system. objective evaluation fig. shows mean-squared error calculated training comparing crbm cadam counterparts. shown fig. crbms converged quickly counterparts rbms cadam algorithm considerably effective csa. table illustrates gradient ascent learning rate momentum batch size number epochs training randomly generated samples models; samples crbm shown dots fig. shown dots bottom fig. shown figure proposed crbm could represent distribution complex-valued artiﬁcial data accurately rbm. crbm captures relationships real imaginary parts conventional not. secondly conducted speech encoding experiments using speech signals sentences training another tests pronounced female announcer speech corpora. speech signals downsampled original processed -dimensional complex spectra using short-time fourier transform window length size followed cpca obtain complex-valued features. total number training data order decide much reduce number dimensions cpca examined table compares peak signal-to-noise ratio crbm order analyze magnitude phase reconstruction crbm actually effective. according table crbm relative improvement points terms magnitude relative improvement points terms phase. demonstrates crbm effectively represent complex-valued data particular respect phase. therefore although magnitude spectra crbm reconstruction similar generated speech crbm outperformed terms pesq shown table iii. subjective evaluation finally conducted subjective experiments based mean opinion score participants gathered crowdsourcing. participant asked rank synthesized natural speech -point scale terms speech quality mcep world based frame-wise synthesis used frame-wise estimation crbm rather trajectory estimation experiments. fig. shows results subjective evaluation. shown fig. crbm performed best methods except world. also conducted pairwise t-tests combination observed signiﬁcant differences conﬁdence pairs except difference mcep. proposed complex-valued novel probabilistic model extends order feed complex-valued data. paper also includes improved learning methods modeling speech dimensionalityreduction complex-valued data using cpca cadam learning algorithm estimate complex-valued parameters effectively trajectory modeling generation method complex-valued data based mlpg. experimental results showed effectiveness proposed method objective subjective criteria compared speech coding methods except world. although crbm fell step short world terms quality specialized coding method speech crbm also used coding signals music images array signals etc. investigate high ability crbm applications future. performance crbm methods test showing proposed method outperformed rest regardless number hidden units. performance crbms comparable rbms crbms hidden units highly improved performance compared rbms. hidden unit crbms represents complexvalued patterns independently rbms; i.e. crbms higher ability representing complex-valued data rbms. table summarizes performance method best conditions. methods based crbm trained using cadam adam algorithms. interestingly crbm frame-wise modeling outperformed trajectory modeling crbm implicitly represents phase information complex-valued data framewise features crbm recovered speech sufﬁciently. furthermore proposed trajectory modeling improved accuracy extracting correlations complexvalued features adjacent frames performed best training-based methods. performance proposed method even comparable world high-quality synthesis methods. unlike traditional speech coding crbms directly encode arbitrary complex-valued features binary-valued features hidden layers like deep boltzmann machine adding connections previous current hidden/visible units like recurrent temporal boltzmann machine changing energy function form conditional probability hidden units gaussian distribution complex normal distribution etc. deep extension also used pre-training method complex neural networks future work includes extensions. sohn zhou learning selecting features jointly point-wise gated boltzmann machines icml nakashika takiguchi minami non-parallel training voice conversion using adaptive restricted boltzmann machine ieee/acm transactions audio speech language processing vol. takaki kameoka yamagishi direct modeling frequency spectra waveform generation based phase recovery dnn-based speech synthesis proc. interspeech kobayashi toda neubig sakti nakamura statistical singing voice conversion direct waveform modiﬁcation based spectrum differential proc. interspeech seung learning parts objects nonnegative matrix factorization nature vol. morise yokomori ozawa world vocoder-based high-quality speech synthesis system real-time applications ieice transactions information systems vol. toru nakashika received b.e. m.e. degrees computer science kobe university respectively. summer student researcher research tokyo research laboratory. september august visiting researcher image group insa lyon france. year continued research doctoral student kobe university received dr.eng. degree computer science assistant professor kobe university april currently assistant professor university electro-communications chofu japan. received ieice young researcher’s award speech field ipsj ongaku symposium excellent paper award member ieee ieice asj. shinji takaki received b.e. degree computer science received m.e. ph.d. degree scientiﬁc engineering simulation nagoya institute technology nagoya japan respectively. september january visiting researcher university edinburgh university. since april project researcher national institute informatics japan. research interests include statistical machine learning speech synthesis. member acoustical society japan information processing society japan. junichi yamagishi associate professor national institute informatics japan. also senior research fellow centre speech technology research university edinburgh awarded ph.d. tokyo institute technology thesis pioneered speaker-adaptive speech synthesis awarded tejima prize best ph.d. thesis tokyo institute technology since authored coauthored refereed papers international journals conferences. awarded itakura prize acoustic society japan kiyasu special industrial achievement award information processing society japan young scientists prize minister education science technology jsps prize respectively. organizers special sessions spooﬁng countermeasures automatic speaker veriﬁcation interspeech asvspoof evaluation interspeech voice conversion challenge interspeech asvspoof evaluation interspeech member speech language technical committee served associate editor ieee/acm transactions audio speech language processing lead guest editor ieee journal selected topics signal processing special issue spooﬁng countermeasures automatic speaker veriﬁcation.", "year": "2018"}