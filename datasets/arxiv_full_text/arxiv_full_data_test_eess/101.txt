{"title": "Jointly Tracking and Separating Speech Sources Using Multiple Features  and the generalized labeled multi-Bernoulli Framework", "tag": "eess", "abstract": " This paper proposes a novel joint multi-speaker tracking-and-separation method based on the generalized labeled multi-Bernoulli (GLMB) multi-target tracking filter, using sound mixtures recorded by microphones. Standard multi-speaker tracking algorithms usually only track speaker locations, and ambiguity occurs when speakers are spatially close. The proposed multi-feature GLMB tracking filter treats the set of vectors of associated speaker features (location, pitch and sound) as the multi-target multi-feature observation, characterizes transitioning features with corresponding transition models and overall likelihood function, thus jointly tracks and separates each multi-feature speaker, and addresses the spatial ambiguity problem. Numerical evaluation verifies that the proposed method can correctly track locations of multiple speakers and meanwhile separate speech signals. ", "text": "paper propose systematic multi-feature trackingand-separation framework based generalized labeled multibernoulli ﬁlter shown fig. ﬁrst obtain multiple speaker features sound mixtures detecting locations candidate speakers extracting corresponding speech signals estimating related acoustic identities extracted vector associated speaker features candidate speaker i.e. location pitch corresponding speech signals treated integral multi-feature target observation. multi-feature vectors forms multi-target multi-feature observations tracked proposed multi-feature glmb. moreover since standard implementations glmb framework track feature necessary adaptations required support multi-feature tracking. categorize location pitch transitioning features non-stationary sound signal non-transitioning feature. multi-feature glmb recursion transitioning features ﬁrst-order markov transition models directly used track conﬁrmation update step non-transitioning feature zeroed prediction step assigned associated extracted sound update step. also propose state transition function measurement likelihood function multiple transitioning features. multi-feature glmb tracking ﬁlter produces labeled tracks respective speakers corresponding pitch estimates well separated sound signals. furthermore also addresses ambiguity problem speakers locate closely pitch information used separate multi-feature glmb tracking algorithm vice versa. paper proposes novel joint multi-speaker tracking-andseparation method based generalized labeled multi-bernoulli multi-target tracking ﬁlter using sound mixtures recorded microphones. standard multi-speaker tracking algorithms usually track speaker locations ambiguity occurs speakers spatially close. proposed multi-feature glmb tracking ﬁlter treats vectors associated speaker features multi-target multi-feature observation characterizes transitioning features corresponding transition models overall likelihood function thus jointly tracks separates multi-feature speaker addresses spatial ambiguity problem. numerical evaluation veriﬁes proposed method correctly track locations multiple speakers meanwhile separate speech signals. multi-speaker tracking using microphones important task smart environments automatic camera steering video conferencing. numerous acoustic multi-speaker tracking algorithms found literature using various techniques mutual information cross-correlation spatial localization particle ﬁltering speaker tracking. generic multi-target tracking ﬁlters also implemented track multiple speakers online provided speaker location estimates multi-target observations. existing implementations multispeaker tracking methods however usually track spatial locations respective speakers. moreover spatial tracking ambiguity problem speakers spatially close other because relying location information alone tracking ﬁlters would take single speaker hence unable correctly identify separate sound sources mixture. separating original source signals mixtures recorded microphones also wide range applications automatic meeting transcription speaker recognition. many blind source separation methods developed based independent component analysis timefrequency masking techniques. however challenging methods continuously separate moving sources. thus location-based source separation methods e.g. wideband beamforming methods often employed additional source separation step obtaining location tracking results. complex conjugate operation respectively short-time fourier transforms microphone signals time frame sampling frequency thus short-time used integration becomes summation.) distance ˆςki correspond local peaks ξmcc−phat integer denotes number detected speakers frame indicates candidate speaker detected thus assuming general spurious estimates miss detections exhibit temporal consistency time frame next estimates true speakers follow kinematic model tracking ﬁlters applied track speaker locations. approach also applied tracking multiple features shown section speech signals estimates ˆςki extracted sound mixtures recorded microphones. implement wideband weighted least square beamforming method sound extraction. beamformer uses ﬁlter-and-sum structure taps channel. mainlobe steers speaker ˆςki corresponding sidelobe ranges ˆςki frequency range used real-valued optimal weight vector ˆςki obtained according wideband beamformer extracted sound ˆski corresponds speaker location ˆςki used extract speaker’s acoustic identity e.g. pitch gaussian mixture model parameters etc. paper pitch simple acoustic identity pitch estimated short segment voiced sound different speakers usually different pitch pitch speaker usually distributed within limited range. numerous pitch estimation methods found literature. employ pefac method averaged estimate frame denote ˆfki. multi-feature glmb random ﬁnite labeled state space multi-feature target state vector denote associated location pitch feature states well sound signal respectively) label space labels unique i.e. probability density δ-glmb form given probability hypothesis labels represents history association targets observations. probability distribution target state distinct label indicator indicates whether labels matches δ-glmb completely characterized parameters references detailed studies δ-glmb tracking ﬁlters.) multi-feature glmb recursion also consists multiobject update step based bayes inference chapmankolmogorov prediction step based state transition models. following deﬁnitions clutter assumed poisson localization average clutter points scan i.e. method section produces almost clean location estimates reverberation. probability target state detected paper g)|x denotes multi-feature likelihood measurement generated ˆsθ) update. sound separation respective speakers time achieved concatenating sound signals target label. assuming transitioning features statistically independent proposed multi-feature likelihood function g)|f g)|ζ paper. standard deviations observation location pitch respectively. update maximum posteriori estimate cardinality chosen highest weighted corresponding hypothesis used multitarget multi-feature tracking results. velocity time step follows normal distribution i.e. model parameters respectively rate constant steady-state root-mean-square velocity random motions speakers. standard deviation transition pitch. adaptive measurement-driven target births generated target births assumed follow normal distributions around previous measurement standard deviation pitch respectively. nonstationary sound signals treated non-transitioning feature thus targets carry sound prediction next update step multi-feature glmb recursion. section veriﬁes demonstrates performance proposed multi-feature glmb framework scenario three speakers. setup shown left panel fig. room dimensions microphone array locates composed microphones evenly distributed circle diameter clarity choose anechoic scenario speaker locate speaker moves respect center microphone array. fig. plots normalized ground truth speech signals respective speakers well mixture captured microphones. obviously using location information alone standard implementations tracking methods take speaker speaker. fig. provides ground truth locations estimated speaker locations pitch separated sound signals. panel depicts ground truth locations straight line segments estimated locations symbol tracking results solid colored symbols. quality separated sound signals evaluated using peass metric compared ground truth signals. results provided tab. also compare performance blind speech separation methods i.e. underdetermined convolutive blind source separation degenerative unmixing estimation technique using blind separation techniques speaker speaker regarded speaker. thus separated sound signals speaker compared mixture speaker speaker general duet ucbss methods obtain close overall perceptual scores duet method seems provide consistent performance ucbss comparing target-related perceptual score artifactsrelated perceptual scores ucbss signiﬁcantly higher interference-related perceptual score duet. overall proposed method provides consistent superior performance three separated speakers according perceptual scores. paper presents novel systematic implementation multifeature glmb tracking method jointly track multiple speakers separate sound signals speech mixtures also resolve ambiguity location tracking speakers locate spatially close. treats vector candidate speaker location pitch sound multi-feature target observation jointly extracts tracks features bayes recursion. experimental results demonstrate encouraging results studied scenario. future work improvement still possible e.g. applying complicated microphone setup selecting different speaker features improving feature extraction methods. fig. joint tracking separation results proposed methods. panels show estimation tracking results speakers’ location pitch. bottom three panels show corresponding separated sound signals. different colored symbols represent different speakers. ground truth separate lines locations. thus using location information alone apparently tracking ﬁlters detect speakers. however considering also pitch information proposed method correctly found three speakers. second panel shows pitch estimates tracking results associated location estimates tracking results panel. panels associated location pitch estimates spurious errors follow consistent kinematic patterns time thus ﬁltered glmb tracker. also tracking ﬁlter requires time steps conﬁrm track. reasonable measurement-driven birth model adaptive target births. pitch estimates different speakers ﬂuctuate different levels time signiﬁcant jump pitch level time around helps tracker conﬁrm speaker starting bottom three panels fig. plots extracted sound signals respective speakers. comparing fig. speech signals recovered speaker. thus proposed multi-feature glmb tracking-and-separation method jointly track separate multiple speakers. location tracking accuracy evaluated using optimal sub-pattern assignment metric cut-off parameter order parameter thus cardinality estima. fig. tion error contributes ospa error shows overall ospa location tracking errors within multi-feature glmb achieves comparable location tracking charles knapp clifford carter generalized correlation method estimation time delay ieee transactions acoustics speech signal processing vol. douglas reynolds sira gonzalez mike brookes pefac-a pitch estimation algorithm robust high levels noise ieee/acm transactions audio speech language processing vol. nonlinear ﬁltering speaker tracking noisy reverberant envi ieee international conference ronments acoustics speech signal processing proceedings.. ieee vol. shoufeng tuong sven nordholm measurement driven birth model generalized labeled multibernoulli ﬁlter international conference control automation information sciences ieee valentin emiya emmanuel vincent niklas harlander volker hohmann subjective objective quality assessment audio source separation ieee transactions audio speech language processing vol. darren ward eric lehmann robert williamson particle ﬁltering algorithms tracking acoustic source reverberant environment ieee transactions speech audio processing vol. ba-ngu sumeetpal singh wing wing-kin ba-ngu sumeetpal singh adrian baddeley tracking unknown time-varying number speakers using tdoa measurements random ﬁnite approach ieee transactions signal processing vol. fotios talantzis acoustic source localization tracking framework using particle ﬁltering information theory ieee transactions audio speech language processing vol. ba-tuong ba-ngu antonio cantoni analytic implementations cardinalized probability hypothesis density ﬁlter ieee transactions signal processing vol. hiroshi sawada mukai shoko araki shoji makino robust precise method solving permutation problem frequency-domain blind source separation ieee transactions speech audio processing vol. taesu hagai attias soo-young te-won blind source separation exploiting higher-order frequency dependencies ieee transactions audio speech language processing vol. vaninirappuputhenpurayil gopalan reju ngee yann soon underdetermined convolutive blind source separation time–frequency masking ieee transactions audio speech language processing vol. simon doclo marc moonen design broadband beamformers robust gain phase errors microphone array characteristics ieee transactions signal processing vol.", "year": "2017"}