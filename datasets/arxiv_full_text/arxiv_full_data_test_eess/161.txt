{"title": "Multilingual Training and Cross-lingual Adaptation on CTC-based Acoustic  Model", "tag": "eess", "abstract": " Multilingual models for Automatic Speech Recognition (ASR) are attractive as they have been shown to benefit from more training data, and better lend themselves to adaptation to under-resourced languages. However, initialisation from monolingual context-dependent models leads to an explosion of context-dependent states. Connectionist Temporal Classification (CTC) is a potential solution to this as it performs well with monophone labels.  We investigate multilingual CTC in the context of adaptation and regularisation techniques that have been shown to be beneficial in more conventional contexts. The multilingual model is trained to model a universal International Phonetic Alphabet (IPA)-based phone set using the CTC loss function. Learning Hidden Unit Contribution (LHUC) is investigated to perform language adaptive training. In addition, dropout during cross-lingual adaptation is also studied and tested in order to mitigate the overfitting problem.  Experiments show that the performance of the universal phoneme-based CTC system can be improved by applying LHUC and it is extensible to new phonemes during cross-lingual adaptation. Updating all the parameters shows consistent improvement on limited data. Applying dropout during adaptation can further improve the system and achieve competitive performance with Deep Neural Network / Hidden Markov Model (DNN/HMM) systems on limited data. ", "text": "approach extracts language-independent phonetic knowledge bottleneck layer multilingual model uses bottleneck features additional input train acoustic model target language knowledge also transferred replacing output layer well trained model retraining model predict targets low-resourced languages models based conventional dnn/hmm framework order perform well dnns model context-dependent states mitigate error associated markov assumption. however creates challenges multilingual cross-lingual large increase context dependent labels arising phone mismatch. although approaches adapt cluster trees proposed simple effective replace whole output layer targets train completely network using bottleneck features. recently connectionist temporal classiﬁcation framework successful training neural network trained convert sequence acoustic features sequence phones graphemes. based systems learn model context implicitly recurrent neural network even monophone-based systems achieve equal better performance dnn/hmm hybrid systems large amount data available thus gets around problem context-dependent state mismatch require prior alignments input output making multilingual cross-lingual modeling simpler straightforward. ctc-based models however sensitive amount training data. advantage training dnn/hmm exploited adequate data available. therefore hypothesize training model multilingually exploit network sharing data multiple languages language adaptive training also boost performance dnn/hmm discuss universal phoneme-based multilingual model language adaptive training section given fact multilingual model outputs monophone targets hypothesize universal phoneme-based multilingual model serve strong prior model cross-lingual adaptation target language required. instead removing entire output layer discarding information output layer multilingual model retained easily extended unseen phonemes target languages. different cross-lingual adaptation approaches based framework discussed section order minimize overﬁtting problem observed preliminary experiments dropout technique introduced section experimental results analysis provided multilingual models automatic speech recognition attractive shown beneﬁt training data better lend adaptation underresourced languages. however initialisation monolingual context-dependent models leads explosion contextdependent states. connectionist temporal classiﬁcation potential solution performs well monophone labels. investigate multilingual context adaptation regularisation techniques shown beneﬁcial conventional contexts. multilingual model trained model universal international phonetic alphabet -based phone using loss function. learning hidden unit contribution investigated perform language adaptive training. addition dropout during cross-lingual adaptation also studied tested order mitigate overﬁtting problem. experiments show performance universal phoneme-based system improved applying lhuc extensible phonemes crosslingual adaptation. updating parameters shows consistent improvement limited data. applying dropout adaptation improve system achieve competitive performance deep neural network hidden markov model systems limited data. index terms multilingual crosslingual adaptation lhuc dropout automatic speech recognition systems improved dramatically recent years. although shown recognition accuracy reach human parity certain tasks building systems good performance requires training data. sufﬁcient data available languages like english issues data scarcity arise under-resourced languages. recently increased interest rapidly developing high performance systems limited data. common solution explore universal phonetic structures among different languages sharing hidden layers deep neural networks hidden layers considered universal feature extractor. therefore trained jointly using data multiple languages beneﬁt speech recognition systems built multilingual dnns shown provide consistent advantages especially low-resourced languages ancommon approach creating models low-resourced languages transfer knowledge learned wellresourced languages target language. bottleneck denotes possible paths correspond repetitions labels insertions blank token. conditional probability labels time step estimated using neural network. model trained maximize equation using gradient descent required gradients computed using forward-backward algorithm main goal multilingual acoustic modelling share acoustic data across multiple languages order learn common properties shared among languages. many presentday languages evolved common ancestors. therefore natural share common graphemes phonemes. recently building end-to-end multilingual speech recognition systems universal grapheme investigated however graphemes differ language language. languages nothing common terms graphemes also share common phonemes. motivation propose multilingual architecture uses universal output label consisting union phonemes multiple languages. universal phone either derived data-driven obtained international phonetic alphabet study monolingual phones merged share symbol table. network trained model universal phoneme targets using loss function data multiple languages. since multilingual network models targets suffer problem ipa-dnn. learning hidden unit contribution ﬁrst proposed method speaker adaptation linearly re-combines hidden units speakerenvironment-dependent manner. investigation lhuc language adaptive training provided figure approaches adapt multilingual model target language. shows multilingual model. output layer replaces multilingual targets. hidden layers ﬁxed output layer re-estimated. also update parameters shown multilingual model extended phonemes adding connections. adaptation performed updating parameters. given language-speciﬁc data lhuc re-scales contributions hidden units model withactually modifying feature receptors. languagedependent amplitude function introduced modify hidden unit output unit layer language adaptable language-dependent parameter rersl parametrised function sigmoid function range usually used. transformation function hidden layer. instance feedforward recurrent connection non-linear activation long short-term memory block. corresponding activations. hidden units trained capture good average representations language-speciﬁc representations estimating language-speciﬁc hidden unit amplitudes training language. paper lhuc combined loss function context language adaptive training. framework shared hidden layers extracted multilingual considered intelligent feature extractor transferable across languages therefore interesting investigate hidden layers ctc-based model carried distinguish phonemes languages. connectionist temporal classiﬁcation approach objective function allows end-to-end training without requiring frame-level alignment input target labels. allows repetitions output labels extends target labels additional blank symbol represents probability emitting labels particular time step. introduces intermediate representation called path. path sequence labels frame level allowing repetitions blank inserted labels. label sequence represented possible paths mapped input sequence conditional probability obtained summing probabilities paths correspond target label sequence inserting repetitions labels blank tokens i.e. basic procedure cross-lingual model adptation model simple. ﬁrst proposed models output layer removed randomly initialized softmax layer corresponding target language phone added hidden layers. usually hidden layers ﬁxed softmax layer re-estimated using training data target language. enough data available tuning entire network considered. major advantage universal phoneme-based multilingual model multilingual monophone modeling gets around problem mismatch context-dependent states. therefore becomes straightforward extend existing multilingual model extra phonemes target language coming. therefore propose extend multilingual output layer adding connections unseen phones target language rather discarding information already learned output layer. shown weights connecting unseen phones randomly initialized trained scratch. others quickly adapted multilingual model little adaptation data. many preliminary experiments consistent overﬁtting observed limited data. although adapting multilingual model mitigates overﬁtting extent problem still exists. dropout well established feed forward networks also proved signiﬁcantly improve performance lstm networks sequence labelling tasks recently various approaches dropout feedforward recurrent connections explored context inspired work propose combine dropout cross-lingual adaptation minimize overﬁtting low-resourced languages. dropout approach applied work combination dropout different levels described dropout feed forward connections dropout applied feed forward connections sequence level composite lstm cell unit dropped. dropout mask retained across complete utterance eliminate cross-sampling noise. lstm cell state time respectively denote forget gate input gate input vector time represents lstm output time corresponding weights bias represents dropout mask time mask retained across complete sequence. investigated performance proposed universal phoneme-based model english french german english data obtained wall street journal corpus data preparation gave hours transcribed speech. french data extracted bref globalphone corpora consist hours data. german broadcast news corpus used hours data training. total hours multilingual data used multilingual training. training data quite clean read speech similar acoustic conditions. cross-lingual adaptation experiments portuguese spanish globalphone considered target low-resourced languages hours hours data respectively. log-mel ﬁlterbank coefﬁcients used -dimensional acoustic features together ﬁrst second-order derivatives derived frames frame shift. features normalized mean subtraction variance normalization speaker basis. monolingual phones mapped symbols merged phonemes create universal phone multilingual training. multilingual model layers bidirectional long short-term memory cells layer direction. weights models randomly initialized trained using stochastic gradient descent momentum. learning rate used early stopping validation applied select best model. decoding individual weighted ﬁnite-state transducer decoding graphs built using languagespeciﬁc lexica language models. section presents experimental results study. previous research shown adequate amount data training good ctc-based system. ﬁrst evaluated better model trained using data multiple languages. comparison multilingual baseline monolingual systems listed table shows monolingual systems still perform better multilingual model even though trained around hours data. observed similar result previous work ipa-based universal system. although universal multilingual modelling enjoys richer data resources mixture data creates variation especially identical symbols shared among different languages. result consistent another recent independent study motivates apply language adaptive training multilingual model. shown last table multilingual combined lhuc improves performance yields better similar word error rate monolingual languages. initial experiments observed multilingual model trained lhuc cannot yield improvement standard multilingual model adapted language. therefore standard multilingual model trained languages used seed model following cross-lingual experiments denoted ml-. ﬁrst goal work create universal phoneme based multilingual model interested transfer ability languages training data limited. order perform cross-lingual adaptation three approaches investigated re-training output layer keeping parameters ﬁxed; re-training output layer also updating parameters; extending multilingual model randomly initializing weights last layer phonemes updating whole network. experiments different amounts data conducted using approaches. fig. shows comparisons. ﬁgure found adaptation approaches outperform monolingual training limited data impossible train good model using less hours data. however adaptation multilingual model still achieve good performance. adaptation data hours monolingual training beats adaptation output layer. moreover updating parameters performs better re-training output layer cases means hidden blstm layers completely transferable like keeping multilingual output layer extending multilingual network yields additional improvement. however difference becomes marginal increase adaptation data. cross-lingual adaptation especially limited data. validate hypothesis multilingual models chosen seed models adaptation spanish namely model trained english french german model adapted portuguese spanish phone consists phonemes. seen covers phonemes presence portuguese. adaptations conducted based seed models. shown table adaptation yields consistent improvement ml-. multilingual model covers phonemes adaptation. believe become stronger stronger multilingual prior model cross-lingual adaptation extending model languages. order validate hypothesis dropout minimize overﬁtting low-resourced languages another experiments conducted compared dnn/hmm system. table details results. systems trained adapted hours portuguese data. dnn/hmm system models contextdependent states obtained decision tree clustering hidden layers consisting units. thus contains slightly parameters models. clear table dnn/hmm performs much better model trained scratch hours data. dropout monolingual model improves performance cross-lingual adaptation multilingual yields improvement. applying dropout cross-lingual adaptation reduced. however improvement much dropout monolingual ctc. conjecture dropout cross-lingual adaptation model help avoid overﬁtting limited data. however cross-lingual adaptation help dropout achieve competitive performance monolingual dnn/hmm system hours data; previous research shows least hours data required enable reach similar performance graves fern´andez gomez schmidhuber connectionist labelling unsegmented sequence data recurrent neural networks proceedings international conference machine learning senior irsoy graves beaufays schalkwyk learning acoustic frame labeling speech recognition recurrent neural networks proceedings ieee international conference acoustics speech signal processing miao gowayyed metze waibel empirical exploration acoustic models proceedings ieee international conference acoustics speech signal processing seltzer towards language-universal end-toend speech recognition arxiv preprint arxiv. toshniwal sainath weiss moreno weinstein multilingual speech recognition single end-to-end model arxiv preprint arxiv. swietojanski renals learning hidden unit contributions unsupervised speaker adaptation neural network acoustic models proceedings ieee workshop spoken language technology sat-lhuc speaker adaptive training learning hidden unit contributions proceedings ieee international conference acoustics speech signal processing schultz schlippe globalphone multilingual text speech database languages proceedings ieee international conference acoustics speech signal processing demonstrated lhuc applied ctcbased multilingual training mitigate problem arising mixture data various languages. universal phoneme-based multilingual extensible phonemes cross-lingual adaptation updating parameters shows consistent improvement limited data. combined dropout adaptation ctc-based model shows competitive performance dnn/hmm even hours data. xiong droppo huang seide seltzer stolcke zweig microsoft conversational speech recognition system proceedings ieee international conference acoustics speech signal processing j.-t. huang deng gong cross-language knowledge transfer using multilingual deep neural network shared hidden layers proceedings ieee international conference acoustics speech signal processing t¨uske pinto willett schl¨uter investigation cross-and multilingual features matched mismatched acoustical conditions proceedings ieee international conference acoustics speech signal processing gales knill ragni rath speech recognition keyword spotting resource languages babel project research cued spoken language technologies under-resourced languages thomas ganapathy hermansky multilingual features low-resource lvcsr systems proceedings ieee international conference acoustics speech signal processing gr´ezl karaﬁ´at vesel`y adaptation multilingual stacked bottle-neck neural network structure language proceedings ieee international conference acoustics speech signal processing ghoshal swietojanski renals multilingual training deep neural networks proceedings ieee international conference acoustics speech signal processing hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath deep neural networks acoustic modeling speech recognition shared views four research groups ieee signal processing magazine schultz waibel polyphone decision tree specialization language adaptation proceedings ieee international conference acoustics speech signal processing", "year": "2017"}