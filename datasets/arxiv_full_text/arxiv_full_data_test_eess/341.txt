{"title": "Snapshot light-field laryngoscope", "tag": "eess", "abstract": " The convergence of recent advances in optical fabrication and digital processing yields a new generation of imaging technology: light-field cameras, which bridge the realms of applied mathematics, optics, and high-performance computing. Herein for the first time, we introduce the paradigm of light-field imaging into laryngoscopy. The resultant probe can image the three-dimensional (3D) shape of vocal folds within a single camera exposure. Furthermore, to improve the spatial resolution, we developed an image fusion algorithm, providing a simple solution to a long-standing problem in light-field imaging. ", "text": "university illinois urbana-champaign department electrical computer engineering wright urbana harbin institute technology center ultra-precision optoelectronic instrument yikuang harbin china university arizona college optical sciences tucson university illinois urbana-champaign beckman institute advanced science technology mathews ave. urbana abstract. convergence recent advances optical fabrication digital processing yields generation imaging technology—light-field cameras bridge realms applied mathematics optics highperformance computing. herein first time introduce paradigm light-field imaging laryngoscopy. resultant probe image three-dimensional shape vocal folds within single camera exposure. furthermore improve spatial resolution developed image fusion algorithm providing simple solution long-standing problem light-field imaging. back-reflected light collected objective lens forming intermediate image distal gradient-index lens tube lens magnified image directed towards followed extracting series image patch pairs {ℎ𝑖𝑖𝑙𝑙𝑖𝑖}𝑖𝑖=𝑛𝑛 𝑙𝑙𝑖𝑖 denote image patches extracted original downsampled images respectively index enumerating image patches. save image patches dictionary 𝐷𝐷𝑟𝑟𝑟𝑟𝑟𝑟. patch 𝑝𝑝𝑗𝑗 elemental image search 𝐷𝐷𝑟𝑟𝑟𝑟𝑟𝑟 identify nine patches {𝑙𝑙𝑘𝑘′}𝑘𝑘= smallest distances norm 𝑝𝑝𝑗𝑗. estimate high-resolution representation ℎ�𝑗𝑗 𝑝𝑝𝑗𝑗 𝑤𝑤𝑘𝑘=𝑒𝑒𝑒𝑒𝑝𝑝−�𝑝𝑝𝑗𝑗−𝑙𝑙𝑘𝑘′� 𝑆𝑆𝑏𝑏. figure shows elemental images formed behind correspondent algorithm based correlation distance. brief first extract feature sets �𝑓𝑓𝑖𝑖�𝑖𝑖=𝑚𝑚 �𝑓𝑓𝑖𝑖�𝑖𝑖=𝑚𝑚 elemental images respectively. feature 𝑓𝑓𝑖𝑖 search correspondent neighborhood �𝑓𝑓𝑖𝑖�𝑖𝑖=𝑚𝑚 identify 𝑓𝑓𝑗𝑗′ distance 𝑓𝑓𝑖𝑖. term 𝑓𝑓𝑗𝑗′ matched feature 𝑓𝑓𝑖𝑖. next calculate disparity disparity calculated relative distance matched image pixels. twocoordinate denote absolute distance matched pixels disparity calculated 𝐷𝐷=𝑑𝑑−𝑡𝑡 pitch. using distance detector array distance virtual image 𝑆𝑆𝑏𝑏. substituting 𝑑𝑑=𝐷𝐷+𝑡𝑡 yields calculate object depth project virtual image 𝑆𝑆𝑏𝑏 back object space. relation experimentally determined calibration. intermediate image point 𝑆𝑆𝑏𝑏. group pixels values single pixel next compare value diffraction limit calculated 𝑅𝑅𝑑𝑑=/𝑟𝑟= 𝑁𝑁𝑁𝑁/.𝜆𝜆 radius airy disk wavelength incident light 𝑁𝑁𝑁𝑁 numerical aperture. given 𝜆𝜆=. 𝑁𝑁𝑁𝑁 𝑅𝑅𝑑𝑑=. lp/mm", "year": "2018"}