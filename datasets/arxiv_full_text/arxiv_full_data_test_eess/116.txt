{"title": "Full-info Training for Deep Speaker Feature Learning", "tag": "eess", "abstract": " In recent studies, it has shown that speaker patterns can be learned from very short speech segments (e.g., 0.3 seconds) by a carefully designed convolutional & time-delay deep neural network (CT-DNN) model. By enforcing the model to discriminate the speakers in the training data, frame-level speaker features can be derived from the last hidden layer. In spite of its good performance, a potential problem of the present model is that it involves a parametric classifier, i.e., the last affine layer, which may consume some discriminative knowledge, thus leading to `information leak' for the feature learning. This paper presents a full-info training approach that discards the parametric classifier and enforces all the discriminative knowledge learned by the feature net. Our experiments on the Fisher database demonstrate that this new training scheme can produce more coherent features, leading to consistent and notable performance improvement on the speaker verification task. ", "text": "recent studies shown speaker patterns learned short speech segments carefully designed convolutional time-delay deep neural network model. enforcing model discriminate speakers training data frame-level speaker features derived last hidden layer. spite good performance potential problem present model involves parametric classiﬁer i.e. last afﬁne layer consume discriminative knowledge thus leading ‘information leak’ feature learning. paper presents full-info training approach discards parametric classiﬁer enforces discriminative knowledge learned feature net. experiments fisher database demonstrate training scheme produce coherent features leading consistent notable performance improvement speaker veriﬁcation task. automatic speaker veriﬁcation important biometric authentication technology found broad range applications current methods categorized groups statistical model approach gained popularity neural model approach emerged recently attracted much interest perhaps famous statistical model gaussian mixture model-universal background model factorizes variance speech signals models individual speakers conditioned factorization. subsequent models design subspace structures improve statistical strength including joint factor analysis approach i-vector model improvements obtained either discriminative models plda phonetic knowledge transfer work supported national natural science foundation china grant national basic research program china grant no.cb. lantian zhiyuan tang joint ﬁrst authors. dong wang corresponding author neural model approach also studied many years however popular statistical model approach recently training large-scale neural models becomes feasible. primary success reported ehsan text-dependent task frame-level speaker features extracted last hidden layer deep neural network utterancebased speaker representations derived averaging frame-level features. learning frame-level speaker features merit paves deeper understanding speech signals. direction however investigated researchers quickly found relatively performance d-vector approach simple back-end i.e. average-based utterance representation. therefore many researchers turn seek complicated back-end models e.g. used features build conventional i-vector systems. researchers focused end-to-end approach learned utterance-level representations directly e.g. spite reasonable success ‘fat back-end’ methods follow feature learning direction originated ehsan assumption speaker traits short-time identiﬁable learned frame-level many speech processing tasks much simpler including asv. fortunately recent study showed frame-level speaker feature learning feasible short speech segment highly representative speaker features learned convolutional time-delay structure. study showed speaker features rather powerful discriminate speakers short cough laugh work well cross-lingual scenarios also carefully compared feature learning approach end-to-end approach found feature learning approach generally performed better partly effective training scheme paper follows deep feature learning thread extends previous work motivation present ct-dnn architecture involves parametric classiﬁer training feature learning component feature net. means part knowledge involved training data used learn classiﬁer ultimately thrown away leading potential ‘information leak’. paper present full-info training approach removes parametric classiﬁer enforces discriminative knowledge learned feature net. experiments fisher database demonstrated task discriminate speakers training however features used tasks e.g. discriminate authenticate speakers joint training suboptimal. classiﬁer involves free parameters part discriminant information learned classiﬁer which unfortunately thrown away performing identiﬁcation/veriﬁcation tasks speakers. possible solution discard parametric classiﬁer using speaker features classify speakers directly. speciﬁcally frame-level speaker features derived speaker training represented average speaker features belonging speaker given speech frames belonging speaker speaker feature frame produced feature parameterized speaker vectors speech frame classiﬁed simple classiﬁer follows next section brieﬂy describe ct-dnn model proposed speaker feature learning present full-info training approach section experiments reported section paper concluded section fig. shows ct-dnn structure presented demonstrated several studies model consists convolutional component time-delay component. output component projected feature layer. activations units layer length normalization form framelevel speaker features. model training feature layer fully connected afﬁne function output layer whose units correspond speakers training data essentially classiﬁer discriminates target speakers training data basis input speech frame. training performed maximize cross entropy classiﬁer output ground truth label. demonstrated speaker features inferred ct-dnn structure highly discriminative conﬁrming conjecture speaker traits largely shorttime spectral patterns identiﬁed frame level. t-th speech frame corresponding ground truth label. note cost function involves free parameters discriminative knowledge provided training data solely learned feature net. reason call approach full-info training. existing speaker feature learning models either vanilla structure proposed ehsan ct-dnn model involve components feature classiﬁer shown fig. feature produces speakersensitive features classiﬁer uses features discriminate speakers training data. ct-dnn case features produced last hidden layer classiﬁer log-linear model non-linear activation function softmax. emphasize feature classiﬁer jointly trained. optimal optimizing simple appears speaker vectors design iterative scheme perform optimization usual neural training. shown fig. keep network structure unchanged. training epoch speaker vectors re-estimated according speaker vectors used replace parameters log-linear classiﬁer epoch started following regular back-propagation algorithm. note normalized length used update classiﬁer otherwise forward computation last afﬁne layer equal experimented various conﬁgurations implement iterative training found allowing parameters classiﬁer updated within epoch works slightly better keeping ﬁxed. another experience test scenarios short-duration scenario long-duration scenario. scenarios involve test conditions. short-duration scenario test conditions test utterances contain frames respectively equivalently seconds. long-duration scenario test conditions length test utterances seconds respectively. test scenarios/conditions involve pooled malefemale-dependent trials. gender-dependent tests exhibit trend report results pooled trials. note condition length test utterances size effective context window ct-dnn model i.e. single speaker feature derived. build baseline systems i-vector system dvector system based ct-dnn structure. ivector system feature involves -dimensional mfccs plus energy augmented ﬁrst second order derivatives. consists gaussian components dimensionality i-vector space entire system trained following kaldi recipe. plda used scoring. d-vector system feature involves dimensional fbanks symmetric -frame window used splice neighboring frames. number output units corresponding number speakers training data. speaker features dimensions equal i-vectors. utterance-level d-vectors derived averaging frame-level speaker features. kaldi recipe reproduce results published online. scoring approach cosine distance either original -dimensional d-vectors -dimensional lda-projected vectors. previous experiments show normalize within-speaker variation turn normalizes scores different speakers. important speaker veriﬁcation based global threshold requires scores comparable across speakers. results terms equal error rate reported table observed d-vector baseline works better i-vector baseline short-term conditions worse long-term conditions. tendency previous studies pre-trained ct-dnn model used initial full-info training; random initialization feature required training ‘warmed using speaker vectors produced pre-trained ct-dnn model. warm-up training converges iterative full-info started. full-info training possesses several advantages firstly discriminant knowledge involved training data learned feature training data used effectively; secondly full-info training frame-level features encouraged aggregate corresponding speaker vectors hence coherent; thirdly distance metric used full-info training consistent measure used test phase asv. improved consistency important applying speaker features task. note full-info training used end-to-end approaches though focus learning frame-level features rather utterance-level representations learning multiple speakers rather speaker pairs end-to-end approaches training consists male female speakers utterances randomly selected fisher database speaker seconds speech segments. dataset used training t-matrix plda models i-vector system ct-dnn model d-vector system. way. interestingly short-term test conditions performance cosine distance improved projection performance outperforms baseline. indicates full-info training necessarily improve strength single speaker features; instead encourages coherent generalizable features. consistent discussion section fig. presents change validation-set frame accuracy iterative training process epoch represents basic ct-dnn model regarded ‘warm-up’ model. warm-up training converges iterative full-info training started. observed accuracy increased within epoch epoch initial accuracy starts higher value previous epoch. indicates increased coherence frame-level speaker features speaker vectors. note accuracies start stage epoch adaptable last afﬁne layer. t-sne used visualize speaker features -dimensional space. fig. choose several utterances different speakers draw speaker features produced without full-info training. observed speaker features highly discriminative matter whether full-info training applied. however full-info training produces coherent features. paying attention circled features observe speakers whose features located separated areas left picture aggregate together right picture. clearly demonstrates full-info training encourages coherent features. fig. deep speaker features plotted t-sne color representing speaker. shows features produced original ct-dnn model shows features produced ct-dnn model trained full-info training. paper proposed full-info training approach enforces speaker discrimination knowledge provided training data learned feature thus avoiding ‘information leak’ caused parametric classiﬁer involved conventional learning structure. tested method speaker veriﬁcation task fisher nicolas scheffer luciana ferrer mitchell novel scheme speaker recognition mclaren using phonetically-aware deep neural network acoustics speech signal processing ieee international conference ieee shi-xiong zhang zhuo chen yong zhao jinyu yifan gong end-to-end attention based textdependent speaker veriﬁcation spoken language technology workshop ieee. ieee david snyder pegah ghahremani daniel povey daniel garcia-romero yishay carmiel sanjeev khudanpur deep neural network-based speaker embeddings spoken lanend-to-end speaker veriﬁcation guage technology workshop ieee. ieee patrick kenny gilles boulianne pierre ouellet pierre dumouchel joint factor analysis versus eigenchannels speaker recognition ieee transactions audio speech language processing vol. najim dehak patrick kenny r´eda dehak pierre dumouchel pierre ouellet front-end factor analysis speaker veriﬁcation ieee transactions audio speech language processing vol. ehsan variani erik mcdermott ignacio lopez moreno javier gonzalez-dominguez deep neural networks small footprint text-dependent speaker veriﬁcation acoustics speech signal processing ieee international conference ieee georg heigold ignacio moreno samy bengio noam shazeer end-to-end text-dependent speaker veriﬁcation acoustics speech signal processing ieee international conference ieee william campbell douglas sturim douglas reynolds support vector machines using supervectors speaker veriﬁcation ieee signal processing letters vol. patrick kenny vishwa gupta themos stafylakis ouellet alam deep neural networks extracting baum-welch statistics speaker recognition proc. odyssey", "year": "2017"}