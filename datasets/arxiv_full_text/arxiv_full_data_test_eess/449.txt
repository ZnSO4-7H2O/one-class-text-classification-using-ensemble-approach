{"title": "Linear Regression for Speaker Verification", "tag": "eess", "abstract": " This paper presents a linear regression based back-end for speaker verification. Linear regression is a simple linear model that minimizes the mean squared estimation error between the target and its estimate with a closed form solution, where the target is defined as the ground-truth indicator vectors of utterances. We use the linear regression model to learn speaker models from a front-end, and verify the similarity of two speaker models by a cosine similarity scoring classifier. To evaluate the effectiveness of the linear regression model, we construct three speaker verification systems that use the Gaussian mixture model and identity-vector (GMM/i-vector) front-end, deep neural network and i-vector (DNN/i-vector) front-end, and deep vector (d-vector) front-end as their front-ends, respectively. Our empirical comparison results on the NIST speaker recognition evaluation data sets show that the proposed method outperforms within-class covariance normalization, linear discriminant analysis, and probabilistic linear discriminant analysis, given any of the three front-ends. ", "text": "speaker channel variability many approaches proposed along gmm-ubm factor analysis among effective ones. ﬁrst extracts high-dimensional supervectors utterances ﬁrstsecondorder statistics produced gmm-ubm reduces supervectors low-dimensional identity vectors factor analysis. combination gmm-ubm i-vector gmm/i-vector front-end. recently deep neural network based front-ends received much attention sarkar used extract frame-level bottleneck features used input gmm-ubm. took trained different task e.g. speech recognition generate posterior probability speech frames supervised alternative gmm-ubm used factor analysis extract i-vectors based ubm. method denoted dnn/i-vector front-end. demonstrate advantages dnn/i-vector front-end acoustic model needs trained additional data variani trained classiﬁer frame-level features given context corresponding speaker identity target extracted feature vector referred deep vector d-vector speaker utterance averaging activations derived last hidden layer. method known d-vector front-end. feature extraction front-end speaker veriﬁcation back-end builds speaker models classiﬁcation. generally contains stages—a development stage test stage. development stage builds speaker space development data speaker acts like coordinate axis space. test stage gets enrollment test speaker models trial speaker space evaluates similarity models classiﬁer. summarize back-ends follows. reynolds ﬁrst built speaker space adapting gmmubm many speaker-dependent gmms maximum posteriori estimation development stage veriﬁes identity test speaker likelihood ratio test. later campbell trained support vector machine classiﬁer distinguish true speakers imposter speakers nuisance attribute projection compensating session variability. dehak proposed learn speaker space within class covariance normalization linear discriminant analysis applied cosine similarity scoring classiﬁer. kenny proposed extract speaker models i-vector based front-end used probabilistic classiﬁer. besides snyder proposed end-to-end training method train based front-end plda-like backend jointly. abstract—this paper presents linear regression based backend speaker veriﬁcation. linear regression simple linear model minimizes mean squared estimation error target estimate closed form solution target deﬁned ground-truth indicator vectors utterances. linear regression model learn speaker models front-end verify similarity speaker models cosine similarity scoring classiﬁer. evaluate effectiveness linear regression model construct three speaker veriﬁcation systems gaussian mixture model identity-vector front-end deep neural network i-vector front-end deep vector front-end front-ends respectively. empirical comparison results nist speaker recognition evaluation data sets show proposed method outperforms withinclass covariance normalization linear discriminant analysis probabilistic linear discriminant analysis given three front-ends. speech processing. speaker veriﬁcation system veriﬁes identity claim made test speaker decides accept reject claim. either text-dependent text-independent based input speech materials former constrains speaker pronounce prescribed text latter constrain speech contents. paper studies text-independent speaker veriﬁcation. textindepdent speaker veriﬁcation system generally contains components. ﬁrst component front-end extracts feature vector speaker utterance density estimator. second component back-end builds speaker models measures similarity speaker models classiﬁer. early speaker veriﬁcation front-end feature averaging learns feature vector speaker utterance averaging frame-level acoustic features method requires long speech utterances reach stable speech statistics. another class front-ends statistical models estimates density speech frames statistical models. early approaches kind build model e.g. vector quantization gaussian mixture model speaker. approaches inefﬁcient number speakers large. alleviate problem reynolds proposed gmm-based universal background model builds single pool training speakers. gmm-ubm fundamental method speaker veriﬁcation recent years. deal xiao-lei zhang center intelligent acoustics immersive communications school marine science technology northwestern polytechnical university xi’an china finally employ classiﬁer identify similarity speaker models menroll mtest. despite many classiﬁers could applied simple effective cosine similarity scoring example based experimental conclusion reference cosine similarity models calculated gmm/i-vector front-end gmm/i-vector front-end contains gmm-ubm speakerchannel-independent trained pool speech frames development data total variability matrix encompasses speakerchannel-variability. suppose contains gaussian mixture components suppose utterance frames {zl}l -dimensional acoustic feature. zero-th order centralized ﬁrst-order baum-welch statistics utterance extracted c-th component ack-end. traditional statistical regression model minimizes mean squared error target estimate closed-form solution. development stage back-end apply learn speaker space target model ground-truth indicator vectors speaker utterances. enrollment test stages ﬁrst extract enrollment test speaker models trial speaker space evaluate similarity models cosine similarity scoring. overall backend denoted lr+cosine back-end. evaluate effectiveness propose three speaker veriﬁcation systems combine lr+cosine back-end gmm/ivector dnn/i-vector d-vector front-ends respectively. conducted extensive experiment nist speaker recognition evaluation nist data sets. compared lr+cosine back-end cosine similarity scoring wccn cosine similarity scoring cosine similarity scoring plda scoring back-ends. experimental results show proposed method outperforms comparison methods experimental conclusion consistent different lengths enrollment speech. paper organized follows. section introduce lr-based back-end three lr-based speaker veriﬁcation systems. section present experiments. section summarize paper. procedure three speaker veriﬁcation systems follows. front-end extracts feature vector utterance {zk}s denotes number frames utterance. then lr-based back-end ﬁrst gets speaker model model veriﬁes identity cosine similarity scoring. suppose labeled development corpus processed front-end given {{}ui number speakers number utterances speaker feature vector speaker utterance produced front-end ground-truth label utterance representing identiﬁcation speaker suppose change s-dimensional indicator vector binary code k-th dimension dimensions result rewrite labeled corpus {{}ui model took conv condition nist speaker recognition evaluation database development conv condition nist enrollment test. conv condition nist contains female speakers male speakers. conv condition nist contains female speakers male speakers. speaker conversations. speaker utterance conversation minutes long removing silence segments took transcript label. split speech signals second segments. illustrate global performance proposed method terms detection error tradeoff curves built initial test condition follows. selected ﬁrst second speech ﬁrst conversation speaker enrollment data speaker split last second speech conversation speaker test segments segment individual test. took speaker claimant remaining speakers acting imposters rotated tests speakers. conducted experiment females males respectively. number claimant imposter trials summarized table closer curve approaches origin better performance investigate performance proposed method varies length enrollment speech conducted experiments test conditions described table speciﬁcally speaker conv condition nist ﬁrst randomly picked segments randomly selected conversation segment individual test; then randomly selected segments remaining conversations enrollment data speaker test conditions respectively. given test condition built claimant imposter trials initial test condition. therefore number trials table enrollment test speech trial selected randomly experiments test condition times reported average results prevent biased conclusions. used equal error rate minimum detection cost function sre’ parameters minimum sre’ parameters evaluation metrics. smaller better performance dnn/i-vector front-end difference dnn/i-vector front-end gmm/i-vector front-end gmm-ubm dnn/i-vector front-end estimated acoustic model trained automatic speech recognition. speciﬁcally acoustic model used estimate senone posteriors acoustic features senone used model tied states triphones close acoustic space. model posterior distribution senone gaussian mixture component gmm-ubm senone posteriors train gmm-ubm following way. u-th utterance frames gmm-ubm estimated acoustic model trained supervised mode speech frames ground-truth labels alignments produced hidden-markov-model-gmm speech recognition system. usually adopts contextual window window size e.g. expand input half-window length. d-vector front-end d-vector front-end averages frame-level features utterance produced hidden layer classiﬁer utterance-level d-vector trained minimize classiﬁcation error speech frames ground-truth label speech frame indicator vector speaker speech frame belongs adopts large contextual window window size expand input acoustic feature important acoustic features frame length frame shift extracted -dimensional mel-frequency cepstral coefﬁcients -dimensional relative spectral ﬁltered perceptual linear predictive cepstral coefﬁcients -dimensional energy well delta delta-delta coefﬁcients frame produced total -dimensional acoustic feature frame. front-ends gmm/i-vector front-end used gender-dependent ubms containing gaussian mixtures total factors deﬁned total variability matrix followed identity toolbox implementation gmm/i-vector front-end. dnn/i-vector front-end trained acoustic model switchboard- database. alignments frames training contained senones generated hmm-gmm speech recognition system implemented kaldi pipeline. half-window length expanded acoustic features dimensions. result acoustic model used -dimensional feature input corresponding dimensional alignment groundtruth label. hidden layers consists rectiﬁed linear units. output units softmax functions. optimized minimum cross-entropy criterion. number epoches backpropagation training batch size learning rate stochastic gradient descent momentum ﬁrst epoches epoches. dropout rate hidden units used posterior probability development data produced acoustic model train gender-dependent ubms. many senones small posterior probabilities truncated ubms gaussian mixtures gaussian mixtures discarding mixtures small zero-th order baum-welsh statistics. used total factors generate i-vectors. d-vector front-end trained gender-dependent dnns development data dnns parameter setting follows. half-window length expanded acoustic feature dimensions. hidden layers consists rectiﬁed linear units. output dimensions dnns females males respectively. learning rate stochastic gradient descent parameters values dnn/i-vector front-end. cosine similarity scoring cosine backend evaluates cosine similarity speaker models directly speaker model simply average utterance-level feature vectors speaker produced front-end wccn+cosine wccn helps compensate channel variability ﬁrst proposed based back-end applied cosine similarity scoring dehak compared wccn+cosine method lda+cosine supervised dimensionality reduction method. dehak applied cosine similarity scoring. output dimension evaluations common experimental setting literature. report comparison results initial test condition figs. respectively. ﬁgures observe proposed method outperforms comparison methods signiﬁcantly gmm/i-vector dnn/i-vector frontend used outperforms comparison methods slightly d-vector front-end used prevent biased conclusion proposed method happens advantage initial test condition comparison test conditions described table test condition independent implementations randomly generated nist database. report average results male female parts implementations tables respectively. tables observe proposed lr+cosine back-end outperforms comparison methods enrollment speech longer seconds comparable lda+plda enrollment speech seconds long given three front-ends. proposed method best comparison method respectively. ﬁgures observe following phenomena. relative improvement getting larger enrollment speech getting longer. exception that dnn/ivector used front-end relative improvement always increased females. caused fast performance improvement cosine similarity scoring enrollment speech getting longer. highest relative improvement happens gmm/i-vector frontend reaches females test condition males test condition. fig. normalized decision scores range mean values decision scores imposter true trials zero respectively. ﬁgure observe scores produced lr+cosine smaller with-in class variances smaller overlaps produced lda+plda. fusing decision scores produced multiple base methods effective improving performance base methods. subsection studies approach averaging soft decision scores produced systems gmm/i-vector dnn/i-vector front-ends respectively. figures show curves fusion systems different back-ends initial test condition. tables list comparison results fusion systems test conditions deﬁned table ﬁgures tables observe experimental phenomena section iii-c supports effectiveness lr+cosine back-end fusion systems. fig. histograms soft decision scores produced lr+cosine lda+plda female parts test conditions decision scores normalized mean values imposter true trials zero respectively. error target estimate closed form solution target speaker veriﬁcation problem deﬁned ground-truth indicator vectors utterances. proposed lr+cosine back-end ﬁrst learns speaker models model applies cosine similarity scoring evaluate similarity pair speaker models. proposed three lr-based speaker veriﬁcation systems combining lr+cosine back-end gmm/ivector dnn/i-vector d-vector front-ends respectively. conducted extensive experiment nist nist data sets used conv condition nist development conv condition nist enrollment test. prevent biased experimental conclusion particular evaluation environment experiment carried different lengths enrollment speech covering range seconds seconds repeated times. experimental results show proposed lr+cosine back-end outperforms several common back-ends including cosine wccn+cosine lda+cosine lda+plda back-ends cases terms curves dcf. variani mcdermott moreno gonzalezdominguez deep neural networks small footprint text-dependent speaker veriﬁcation proc. ieee int. conf. acoust. speech signal process. scheffer ferrer mclaren novel scheme speaker recognition using phonetically-aware deep neural network proc. ieee int. conf. acoust. speech signal process. campbell sturim reynolds solomonoff based speaker veriﬁcation using supervector kernel variability compensation proc. ieee int. conf. acoust. snyder ghahremani povey garcia-romero carmiel khudanpur deep neural network-based speaker embeddings end-to-end speaker veriﬁcation proc. ieee spoken lang. tech. workshop", "year": "2018"}