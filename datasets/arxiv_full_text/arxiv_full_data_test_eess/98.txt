{"title": "Direction of arrival estimation for multiple sound sources using  convolutional recurrent neural network", "tag": "eess", "abstract": " This paper proposes a deep neural network for estimating the directions of arrival (DOA) of multiple sound sources. The proposed stacked convolutional and recurrent neural network (DOAnet) generates a spatial pseudo-spectrum (SPS) along with the DOA estimates in both azimuth and elevation. We avoid any explicit feature extraction step by using the magnitudes and phases of the spectrograms of all the channels as input to the network. The proposed DOAnet is evaluated by estimating the DOAs of multiple concurrently present sources in anechoic, matched and unmatched reverberant conditions. The results show that the proposed DOAnet is capable of estimating the number of sources and their respective DOAs with good precision and generate SPS with high signal-to-noise ratio. ", "text": "also generates spatial acoustic activity similar music pseudo-spectrum intermediate output. numerous applications rely directional acoustic activity soundﬁeld visualizations room acoustics analysis comparison proposed doanet outputs doa’s multiple overlapping sources similar popular estimators like music esprit without requiring critical information number active sound sources. successful implementation enable integration methods higher-level learning based end-to-end sound analysis detection systems. recently several dnn-based approaches proposed estimation signiﬁcant differences proposed method aforementioned works focused azimuth estimation exception cartesian coordinates sound sources room predicted trained separate networks azimuth elevation estimation. contrast demonstrate estimation azimuth elevation sampling unit sphere uniformly predicting probability sound source direction. past works focused estimation single every time frame exception localization azimuth sources simultaneously proposed. hand proposed doanet algorithmically limit number directions estimated i.e. higher number audio channels input doanet potentially estimate larger number sound events. past works evaluated different array geometries making comparison difﬁcult. although doanet applied array geometry evaluate method using real spherical harmonic input signals emerging popular spatial audio format name ambisonics. microphone signals various arrays spherical circular planar volumetric transformed ambisonic signals appropriate transform resulting common representation sound recording. although doanet scalable higher-order ambisonics paper evaluate using compact four-channel ﬁrst-order ambisonics abstract—this paper proposes deep neural network estimating directions arrival multiple sound sources. proposed stacked convolutional recurrent neural network generates spatial pseudo-spectrum along estimates azimuth elevation. avoid explicit feature extraction step using magnitudes phases spectrograms channels input network. proposed doanet evaluated estimating doas multiple concurrently present sources anechoic matched unmatched reverberant conditions. results show proposed doanet capable estimating number sources respective doas good precision generate high signal-to-noise ratio. direction arrival estimation task identifying relative position sound sources respect microphone. estimation fundamental operation microphone array processing forms integral part speech enhancement multichannel sound source separation spatial audio coding popular approaches estimation based time-delay-of-arrival steered-response-power subspace methods multiple signal classiﬁcation estimation signal parameters rotational invariance technique aforementioned methods differ terms algorithmic complexity suitability various arrays sound scenarios. music speciﬁcally generic regards array geometry directional properties handle multiple simultaneously active narrowband sources. hand music subspace methods general require good estimate number active sources often unavailable difﬁcult obtain. furthermore music suffer signal noise ratio reverberant scenarios paper propose overcome shortcomings deep neural network method referred doanet learns number sources input data generates high precision estimates robust reverberation. proposed doanet *equally contributing authors paper. research leading results received funding european research council european unions framework programme grant agreement everysound. authors also wish acknowledge csc-it center science finland computational resources connected neural networks convolutional neural networks work along cnns recurrent neural network layers. usage allows network learn longterm temporal information. architecture referred convolutional recurrent neural network literature state-of-the-art method many single multichannel audio tasks. previous methods used inter-channel features generalized crosscorrelation phase transform eigen-decomposition spatial covariance matrix inter-channel time delay inter-channel level differences recently chakrabarty proposed phase component spectrogram avoiding explicit feature extraction. proposed method magnitude phase component. contrary employed omnidirectional sensors only general arrays directional microphones additionally encode information magnitude differences ambisonics format especially encode directional information mainly magnitude component. previous methods evaluated speech recordings synthetically spatialized spatially static. continue static sound sources present work extend larger variety sound events impulsive transient sounds. block diagram proposed doanet presented figure doanet takes multichannel audio input ﬁrst extracts spectrograms channels. phases magnitudes spectrograms mapped using crnn outputs sequentially. ﬁrst output spatial pseudo-spectrum generated regression task followed estimates classiﬁcation task. deﬁned azimuth elevation respect microphone intensity sound along given paper discrete uniformly sampling polar coordinate space resolution degrees azimuth elevation resulting sampled directions. computed sampled direction whereas subset directions used elevations limited degrees. spectrogram calculated audio channels whose sampling frequencies -point discrete fourier transform calculated hamming windows overlap. keep values corresponding positive frequencies without zeroth bin. frames features containing magnitude phase values extracted channels stacked tensor used input proposed neural network. dimension results ordering magnitude component local shift-invariant features extracted input spectrogram tensor using layers. every layer intra-channel time-frequency features processed using receptive ﬁeld rectiﬁed linear unit activation zeros resulting activation keep output dimension equal input. batch normalization max-pooling operation along frequency axis performed every layer reduce ﬁnal dimension number ﬁlters last layer. activations reshaped keeping time axis length unchanged layers order learn temporal structure. speciﬁcally bi-directional gated recurrent units tanh activation used. further output mapped ﬁrst output regression manner using layers linear activation. mapped estimates–the ﬁnal output proposed method–using similar crnn network minor architectural changes. layer introduced layers reduce dimension output. additionally output layer predicts uses sigmoid activation order estimate given time frame. node output layer represents direction polar space. testing probabilities nodes thresholded value anything greater suggests presence source direction otherwise absence source. refer combined architecture estimation work doanet. doanet trained using target computed sampled direction every time frame applying music represented using nonnegative real numbers. output doanet aims make discrete decision presence source certain direction; training doanet trained epochs using adam optimizer mean squared error loss output binary cross entropy loss output. losses used back propagation. dropout used every layer early stopping used metric improve epochs. doanet implemented using keras framework theano backend. order evaluate proposed doanet publicly available real synthetic datasets consist general sound events associated spatial coordinate. since dnn-based methods need sufﬁciently large datasets train dnn-based methods proposed studied performance synthetic datasets. similar fashion evaluate proposed doanet synthetic datasets size previous works. synthesize datasets consisting static point sources associated spatial coordinate space contexts anechoic reverberant. context three datasets generated temporally overlapping sources maximum overlapping sources maximum three overlapping sound sources refer anechoic context dataset reverberant denotes number overlapping sources. datasets three cross-validation splits recordings training testing. recordings sampled long. order generate datasets isolated real-life sound event recordings dcase task dataset consists sound event classes examples. classes dataset included speech coughing door slam page-turning phone ringing keyboard sounds. splits randomly chose disjoint sets examples training testing amounting examples training testing. order synthesize recording random subset sound examples chosen respective split. subset size varied recording based chosen sound examples. start synthesizing recording randomly choosing beginning time ﬁrst randomly chosen sound example within ﬁrst second recording. next randomly chosen sound example placed ﬁrst sound example. reaching maximum recording length process repeated many times number required overlapping sound events. sound examples assigned randomly using following conditions. sound events placed spatial grid degrees resolution along azimuth elevation. temporally overlapping sound events degrees spatial separation avoid spatial overlapping. elevation constrained within range degrees natural sound events occur range. finally anechoic dataset sound sources randomly placed distance range reverberant dataset sound events randomly placed inside room dimensions microphone center room. anechoic source following. converted signal vector multiplying real orthonormalized spherical harmonics ynm. complete anechoic sound scene multichannel recording gisiy gains modeling distance attenuation. entry reverberant case fast geometrical acoustics simulator used model natural reverberation based rectangular room image-source model point source dataset image sources generated modeling reﬂections predeﬁned time-limit. based room propagation properties image source associated propagation ﬁlter resulting spatial impulse response hiky. reverberant scene signal denotes convolution source signal spatial impulse responses. room absorption properties adjusted match reverberation times typical ofﬁce spaces. three sets testing data generated similar room size training data room size reverberation time room size reverberation time proposed method knowledge ﬁrst dnnbased implementation estimation multiple overlapping sound events. thus order evaluate complete features proposed doanet compare performance conventional high-resolution estimator based music. similar outputs estimated doanet music method also estimates thus allowing direct one-to-one comparison. music based measure orthogonality signal subspace spatial covariance matrix noise subspace spatial covariance matrix calculated frequency time dependent c-dimensional vector number channels conjugate transpose denotes expectation sound scene number sources music obtained ﬁrst performing eigenvalue decomposition eλeh. sorted eigenvectors partitioned aforementioned subspaces denotes signal subspace composed eigenvectors corresponding higher eigenvalues rest form noise subspace along direction given finally /unuh source doas found selecting directions corresponding largest peaks metric metric angle estimate ground truth used synthesize dataset degrees. calculated arccos)· ./π. further accommodate scenario unequal number estimated ground truth doas calculate report minimum distance using hungarian algorithm along percentage frames number doas estimated correct. ﬁnal metric entire dataset referred error calculated normalizing minimum distance total number estimated doa’s. test time metric output doanet calculated respect baseline music metric doas predicted doanet baseline music calculated respect ground truth used synthesize dataset. experiment baseline music algorithm uses knowledge number active sources. order fair evaluation test doanet similar scenario number sources known. knowledge choose probabilities prediction layer doanet instead thresholding value results evaluations presented table high snrs contexts overlapping sound events show generated doanet comparable baseline music figure shows respective active sources closely located. case three overlapping sound events baseline music already theoretical limit estimating sources n-dimensional signal space practice sources noise subspace vector used generate real signals weak stable estimation. present evaluation doanet trained four-channel audio features music case three overlapping sound sources used unstable estimate resulting poor training consequently results. four-channels input proposed doanet easily extend potentially localize sound sources simultaneously. error proposed doanet number active sources unknown presented table doanet error considerably better comparison baseline music uses active sources knowledge datasets. however number frames doanet produced correct number active sources few. example case anechoic recordings overlapping sound events estimated frames correct number predictions. prediction drops even drastically number sources three theoretical limit music explained previously consequently doanet music used training. finally confusion matrix number estimates frame datasets visualized knowledge number active sources doanet performs considerably better baseline music datasets music doa’s chosen using peak ﬁnder music whereas doa’s doanet chosen simply picking probabilities ﬁnal prediction layer. smarter peak picking method doanet using number sources additional input potentially result better scores across datasets. further doanet error unmatched reverberant data presented table performance doanet seen consistent comparison matched reverberant data table signiﬁcantly better performance music. paper since baseline chosen music fair comparison doanet also trained using music sps. ideal scenario considering doanet trained using datasets ground truth doas known generate accurate high-resolution ground truth doa’s required application training. alternatively doanet trained without directly generate doas used paper present complete potential method limited paper space. general results show proposed doanet potential learn direction information multiple overlapping sound sources directly spectrogram input audio without knowledge number active sound sources. exhaustive study detailed experiments including synthetic real datasets planned future work. convolutional recurrent neural network proposed multiple source localization. doanet shown learn number active sources directly input spectrogram estimate precise polar space. method evaluated anechoic matched unmatched reverberant dataset. proposed doanet performed considerably better baseline music scenarios. thereby showing potential doanet learning highly computational algorithm without prior knowledge number sources. nikunen virtanen direction arrival based spatial covariance model blind sound source separation ieee/acm transactions audio speech language processing vol. brandstein silverman high-accuracy low-latency technique talker localization reverberant environments using microphone arrays ieee international conference acoustics speech signal processing xiao learning-based approach direction arrival estimation noisy reverberant environments ieee international conference acoustics speech signal processing takeda komatani discriminative multiple sound source localization based deep neural networks using independent location model ieee spoken language technology workshop zermini deep neural network based audio source separation international conference mathematics signal processing vesperini neural network based algorithm speaker localization multi-room environment ieee international workshop machine learning signal processing chakrabarty habets broadband estimation using convolutional neural networks trained noise signals ieee workshop applications signal processing audio acoustics sainath convolutional long short-term memory fully connected deep neural networks ieee international conference acoustics speech signal processing adavanne sound event detection using spatial features convolutional recurrent neural network ieee international conference acoustics speech signal processing ottersten exact large sample maximum likelihood techniques parameter estimation detection array processing radar array processing. springer series information sciences", "year": "2017"}