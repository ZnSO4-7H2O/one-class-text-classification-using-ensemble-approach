{"title": "Modeling Singing F0 With Neural Network Driven Transition-Sustain Models", "tag": "eess", "abstract": " This study focuses on generating fundamental frequency (F0) curves of singing voice from musical scores stored in a midi-like notation. Current statistical parametric approaches to singing F0 modeling meet difficulties in reproducing vibratos and the temporal details at note boundaries due to the oversmoothing tendency of statistical models. This paper presents a neural network based solution that models a pair of neighboring notes at a time (the transition model) and uses a separate network for generating vibratos (the sustain model). Predictions from the two models are combined by summation after proper enveloping to enforce continuity. In the training phase, mild misalignment between the scores and the target F0 is addressed by back-propagating the gradients to the networks' inputs. Subjective listening tests on the NITech singing database show that transition-sustain models are able to generate F0 trajectories close to the original performance. ", "text": "also active development rule-based unit selection singing expression modeling systems shown generate realistic detail-rich trajectories methods similar decomposed weighted overlapping segments wherein segment either deﬁned b-spline basis expression database. present study inherits said segment-wise modeling strategy generates note-pair segments using feed-forward neural network similar inspired second network generate vibrato segments. rest paper overview proposed method ﬁrst given section note transition model sustain model respectively described section section training strategy results subjective listening test summarized section finally section concludes study additional notes future studies. proposed singing modeling system musical notes elementary units formulation. references ﬁgure facilitate following description deﬁne pair notes covering transition region note note dinote di−i similar notion diphone concatenative speech synthesis. contrast sustained region within note contain vibrato deﬁned mononote trajectory musical score containing notes thus decomposed weighted dinotes mononotes. study focuses generating fundamental frequency curves singing voice musical scores stored midilike notation. current statistical parametric approaches singing modeling meet difﬁculties reproducing vibratos temporal details note boundaries oversmoothing tendency statistical models. paper presents neural network based solution models pair neighboring notes time uses separate network generating vibratos predictions models combined summation proper enveloping enforce continuity. training phase mild misalignment scores target addressed back-propagating gradients networks’ inputs. subjective listening tests nitech singing database show transition-sustain models able generate trajectories close original performance. index terms singing voice synthesis modeling vibrato modeling deep neural network problem automatically modeling singing expressions received growing interests recent years. various parameters considered fundamental frequency trajectory carries melodic information details related perceived naturalness singing styles. comprehensive overview singing expression control umbert classiﬁed fully automatic modeling methods three categories rule-based statistical modeling unit selection. particular hmm-based statistical parametric systems extensively developed model singing timbre features. common setup hmm-based singing models derived speech synthesis systems wherein phoneme divided certain number states associated probability distributions feature vectors; alternatively states assigned subdividing different portions musical note generation continuous trajectories discrete statespace requires maximum-likelihood estimation continuity constraints process temporal details often lost moreover discrete assignment states sets smoothness assumption prohibits efﬁcient characterization periodic structures vibratos. deep neural network -based singing synthesis system thought drop-in enhancement hmm-based system statistics feature vectors predicted musical context vectors using feed-forward dnn. although enhanced system predicts feature vectors frame-by-frame basis maximum-likelihood parameter generation step still required reduce parameter discontinuities phoneme note boundaries. sophisticated architectures recurrent autoregressive convolutional average curve reduced level details. although mixture density network shown alleviate oversmoothing problem preliminary tests indicated simply realigning musical score recordings also highly effective solution. order automate realignment process network’s gradient input relative time position taken note onsets trained along transition model. maximum offset correction limited within milliseconds prevent build-up occasional realignment errors. figure shows results transition models trained without back-propagating gradients input offsets -second excerpt test data. seen offset-corrected training produces deﬁned pitch ornamentations near note boundaries. experiments suggested constant-frequency sinusoid proper amplitude fading ends gives perceptually accurate approximation singing vibrato; hence neural network sustain model needs predict vibrato depth mononote musical context. however without explicitly addressing phase frequency variation across time across different occurrences vibratos becomes hard equation training data underﬁt model produce damped vibrato depths. problem further complicated fact high degree randomness observed vibrato phase assumption vibrato phase small variations frequency perceptually irrelevant method similar addressing timing issues section supplements network note-dependent phaseadjusting input parameters. auxillary inputs receive backpropagated gradients training default values evaluating models unseen data. mononote trajectory expressed sinusoid modulated vibrato depth prediction duration i-th note; pre-determined angular frequency; trainable parameter phase shift; trainable warping function models time-varying frequency disturbance. essentially combination deﬁnes wide range time translation non-linear stretching operations ingly sustain model generates time-varying vibrato depth parameter mononote; vibrato depth converted deviation amplitude-modulating sinusoid signal. ensure continuity ﬁnal trajectory dinotes modulated linear cross-fading envelopes mononotes modulated duration-determined convex parabola prior summation onset note generation di−i depends musical context. note need extract dinote mononote segments prior training separation learned implicitly using multi-stage training method directly optimizing ﬁnal trajectory said process discussed detail following sections. transition model direct extension phoneme-level dinote units. details listed table given musical phonetic context pair neighboring notes relative time position within dinote model predicts speciﬁed position. complete trajectory covering dinote thus generated iterating model frames dinote. name duration ﬁrst note duration second note pitch interval transition ﬁrst note silent second note silent type second note’s onset position relative note boundary improve model’s generalization across pitch ranges dinote section pitch second note subtracted target training. alternatively implemented residual connection adding note-dependent offset network’s output thereby allowing direct gradient evaluation weighted equation another issue observed training process slight timing mismatches musical scores singing voice database imprecise nature human singing. statistical parametric systems naive attempts train model non-systematically time-offsetted data using unimodal cost function inevitably leads sine function whereas provides amplitude envelope. inspired phase interpolation technique sinusoidal models implement using cubic hermite spline function ﬁxed points slope parameters default value valid warping function derivative range deﬁnition positive sufﬁcient condition practice values restricted within prevent extreme stretching. training mononote trajectory relies predetermined vibrato frequency good initial value vibrato phase parameter estimate ﬁrst training transition model perform peak-picking spectra residual trajectory difference target re-synthesized transition model only. name duration mononote previous note silent next note silent pitch mononote pitch difference previous note pitch difference next note type mononote’s onset position mononote position mononote point topology composition singing models described great detail. remaining concept clariﬁed train transition sustain models dataset parallel musical scores recorded vocals. multi-stage gradient descent strategy ﬁrst trains transition model switches sustain model avoid unwanted interactions cause overﬁtting also experimentally found loss better vibrato loss. adam optimizer learning rate detailed procedure listed following. since offset phase corrections performed test data average test loss cannot used early stop criterion. procedure listed paper thus ﬁxes number epochs stage. objective measure test-set performance investigated. proposed transition-sustain models trained songs nitech song singing database evaluated rest songs. database consists japanese children’s songs female singer previously used evaluation dnnbased singing synthesis systems. neural networks transition sustain models hidden layers units trained according section subjective test following itu-r quality impairment evaluation method carried compare proposed method hmm-based sinsy system b-spline-based multi-layer model recommended paper parameters multi-layer model tuned hand training data overshoots undershoots vibratos original performance. towards goal measuring well models replicate singer’s style test data modiﬁed original vocals replacing synthesized version evaluated difference modiﬁed singing original version listening test. eliminate potential biases audio defects introduced vocoder original recordings also processed vocoder without parameter modiﬁcation. said purpose high-quality full-band harmonic-noise model vocoder used experiment. listening test conducted using online interface short excerpts randomly chosen test lasting seconds. prior test subjects advised headphone. music excerpts rendered using systems tested yielding total stimuli groups time listener presented known reference randomly chosen stimulus paired hidden reference identical known reference. listening known transition-sustain models multi-layer model able generate expressions resembling original performance extent makes comparison methods difﬁcult. advantage proposed method lies fully data-driven multi-layer model requires handtuning automation still investigation figure shows example trajectory generated purposed method overlaid input score original speciﬁc example transition-sustain models received lowest average rating. listening f-modiﬁed stimulus attribute problem timing error note transition starts milliseconds earlier original performance. early transition possibly caused realignment errors transition model training paper proposed singing modeling method using separate feed-forward neural networks note transitions vibratos. without relying parameter generation smoothing algorithm trajectories generated directly weighted neural network outputs. separate modeling baseline melodic component vibrato component allows intuitive control pitch ornamentations user. also shown oversmoothing problems addressed back-propagating gradients inputs transition vibrato depth prediction networks although occasional timing errors time ﬁxed. listening test nitech singing database showed proposed method scores similar state-ofart results ardaillon advantage data-driven. following study plan verify results reconducting listening test singers. next step incorporate expression-related parameters loudness vocal efforts transition-sustain framework. also interesting apply back-propagation based offset correction technique general task dnn-based textto-speech synthesis. figure plot listening test results comparing three modeling systems reference original singing. boxes cover lines placed medians. outliers marked reference subjects asked identify stimulus modiﬁed give comparative rating continuous scale based following criterion looping switching stimuli reference allowed. according post-test survey listening test participants experts speech music-related research; experience either vocal performance music production; native ﬂuent japanese speakers. breakdown analysis test results shows signiﬁcant difference different levels experience research music language education. data analysis data points subjects removed responses meet objective criteria listeners’ expertise speciﬁed differences hidden reference ratings fmodiﬁed stimuli ratings normalizing across listeners computed remaining data visualized figure plot seen proposed method performs signiﬁcantly better hmm-based system replicating singing style distribution ratings almost identical proposed method multilayer model systems median difference grade around corresponds perceptible annoying impairment grade. test results supplemented table lists median time rating made pair stimuli accuracy identifying hidden reference. listeners tend spend seconds telling apart transition-sustain models/multi-layer model original compared time spent hmm-based model. cases generated transition-sustain models/multilayer model successfully spoofed listener mistake hidden reference. results lead believe umbert bonada goto nakano sundberg expression control singing voice synthesis features approaches evaluation challenges ieee signal processing magazine vol. toda tokuda speech parameter generation algorithm considering global variance hmm-based speech synthesis ieice trans. information systems vol. jan.", "year": "2018"}