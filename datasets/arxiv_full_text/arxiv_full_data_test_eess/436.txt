{"title": "Predicting Audio Advertisement Quality", "tag": "eess", "abstract": " Online audio advertising is a particular form of advertising used abundantly in online music streaming services. In these platforms, which tend to host tens of thousands of unique audio advertisements (ads), providing high quality ads ensures a better user experience and results in longer user engagement. Therefore, the automatic assessment of these ads is an important step toward audio ads ranking and better audio ads creation. In this paper we propose one way to measure the quality of the audio ads using a proxy metric called Long Click Rate (LCR), which is defined by the amount of time a user engages with the follow-up display ad (that is shown while the audio ad is playing) divided by the impressions. We later focus on predicting the audio ad quality using only acoustic features such as harmony, rhythm, and timbre of the audio, extracted from the raw waveform. We discuss how the characteristics of the sound can be connected to concepts such as the clarity of the audio ad message, its trustworthiness, etc. Finally, we propose a new deep learning model for audio ad quality prediction, which outperforms the other discussed models trained on hand-crafted features. To the best of our knowledge, this is the first large-scale audio ad quality prediction study. ", "text": "introduction audio advertising abundantly used online music streaming services. users listening music different songs exposed audio messages advertisers. form called audio high impact user listening experience. given opportunity space typically retrieval bidding process. after eligible ordered based amount money advertisers willing times quality ads. challenge measure quality audio acoustic components sound composition create engaging audio ads. existing efforts toward discovering quality advertisements mainly focused visual perception display text therefore domain specific features considered context text image based features. furthermore case well accepted proxy metric quality clicks dwell-time conversion offensive rate however context audio clear kind metric consider proxy quality audio clicked. therefore existing approaches directly applicable. another challenge extracting features sound content order build prediction models understand create engaging high quality ads. best knowledge large scale audio quality studies address points. paper predict quality using acoustic signal. audio quality necessarily quality recording implicit within quality ad’s overall composition. composition includes speaker tone tempo speaker gender number speakers message music accompaniment production effects overall sources. fields digital signal processing music information retrieval acoustic features computed audio signal capture elements timbre rhythm harmony used model high-level subjective concepts sound audio understanding quality metric rely companion display presented time playing. users listening music audio usually using mobile device. listening audio decide click associated banner audio played. following click redirected landing page. user spend amount time landing page dwell-time higher threshold consider interaction engaging abstract online audio advertising particular form advertising used abundantly online music streaming services. platforms tend host tens thousands unique audio advertisements providing high quality ensures better user experience results longer user engagement. therefore automatic assessment important step toward audio ranking better audio creation. paper propose measure quality audio using proxy metric called long click rate defined amount time user engages follow-up display divided impressions. later focus predicting audio quality using acoustic features harmony rhythm timbre audio extracted waveform. discuss characteristics sound connected concepts clarity audio message trustworthiness etc. finally propose deep learning model audio quality prediction outperforms discussed models trained hand-crafted features. best knowledge first large-scale audio quality prediction study. concepts computing methodologies supervised learning; neural networks; information systems data mining; online advertising; applied computing sound music computing; reference format samaneh ebrahimi hossein vahabi matthew prockup oriol nieto. predicting audio advertisement quality. wsdm wsdm eleventh international conference search data mining february marina usa. york pages. https//doi.org/./. permission make digital hard copies part work personal classroom granted without provided copies made distributed profit commercial advantage copies bear notice full citation first page. copyrights components work owned others must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior specific permission and/or fee. request permissions permissionsacm.org. wsdm february marina association computing machinery. isbn ----//.... https//doi.org/./. call long click. quality metrics long click rate i.e. number long click divided number impressions. main reasons behind using simple click rate noisy listeners click banner mistake reflect short-term user engagements defining metric propose first acoustic based prediction model handcrafted features. main objective model prediction model interpretable tell create high quality audio improve interpretation also large scale user study. results case shows speech moderate-tempo articulate pronunciation moderate necessary vocal animation lead better quality ads. finally also propose deep learning model objective improving effectiveness prediction model reaching cold-start audio quality prediction using spectrogram audio. resume original contributions paper defined metric measure quality audio relying long click rate companion display appears time audio playing. conducted large crowd-sourcing study understand designed implemented acoustic features capture intuitive sonic attributes timbre rhythm harmonic organization build prediction model advertisement quality. gave interpretation level acoustic features connected concepts speech speed pronunciation foreground background sound proposed different audio prediction models using proposed deep learning model based directly audio spectrograms without using hand-crafted features„ reaching related work computational advertising address problem ranking based relevance quality. recently many different approaches arisen solve problem based visual perception display text native sponsored search much furthermore based well-known metrics clicks offensive rate dwell-time contributions proposing metric quality audio directly clickable prediction model based acoustic signals. next report related work classical quality prediction using visual perception machine deep learning algorithms audio signals music information retrieval. quality. many existing approaches related relevance within sponsored search trying optimize based dwell-time revenue conversion rate recently zhou focused explicitly taking user feedback account estimate quality. barbieri presented model predicting post-click user engagement using dwell-time mobile ads. chen proposed deep neural network based model directly predicts image based image pixels basic features step. combines deep neural networks factorization machine also brings improvement. previous predictive models quality based viewable features display native sponsored search best knowledge work using audio content directly predict user engagement listening audio signal understanding music-ir. many tasks music understanding work directly audio signals computation hand-crafted targeted features. features include descriptions timbre capture characteristics overquality sound rhythm capture relationships sound event timing harmony capture relationships patterns harmonic frequency organization rhythm features used model tempo beat locations meter. harmony melody features used model notes present mode chords song structure. timbre features used model instrumentation performer expression audio features many types used combination also proved useful modeling nebulous concepts well. audio feature similarity used derive music similarity drive automatic play-listing well song search retrieval supervised models using audio features also trained capture subjective concepts musical genre taxonomy organization assessing music performer expression sound quality even mood music finally oord proposed deep learning approach music recommendation work model subjective concept quality. audio recording/sound quality important aspect quality well studied aspect music-ir general however audio quality refers quality ad’s compositional elements music domain analog work would quality assessment song musical composition. seems difficult subjective task music feel composition quality tractable problem much shorter songs constructed communicate single focused message. defining good trivial task. spectrogram audio associated acoustic features objective learn function indicates quality order learn model audio quality prediction first need define measure audio quality nature clickable. solving measurement problem need define acoustic features order learn quality prediction model. final step need define learning model. user preferences develop user study understand audio quality users’ point view. study help gain insight factors affect user preferences audio inform feature engineering interpretation results. ensure good variety terms audio quality collect different quantiles. focus five categories retail/mass retail automotive education health care financial/insurance. design study similar user study provide evaluators different pairs audio time pick prefer. moreover exclude effect evaluators’ personal interests comparison ensure category. evaluators made comparison specify reason behind choice given probable reasons. define reasons several work literature however studies focus display native advertising. therefore define reasons specific audio ads. reasons clarity message clarity sound trustworthiness aesthetic brand ensure pair shown assessor once order audio played randomly chosen comparison. ensure quality assessments present pair three people collect three independent judgments. moreover employ gold standard check redundancy check. perform study collected audio category randomly sampled distinctive quantiles distribution. experiment consists pairwise comparison category resulting total pairs. ensuring assessments pair adding gold standard check redundancy check initially collect comparisons users. also ensure users’ demographics proper diversity. users female male groups among users yearly income less remaining income removing users failed quality checks users verified included analysis. table percentage reason selected presented. results show categories around time audio aesthetic selected reason high influence. message clarity sound quality next reasons users select good results show audio aesthetics sound quality important aspects determining quality audio suggest included models predict audio quality. motivates later work paper using acoustic features derived audio signal designed figure heat clicks display full screen size dimension shown. color indicates higher number clicks. clicks appear near close button likely noisy clicks. quality measurement important step predicting quality audio come useful quality metrics. major question measure quality audio unfortunately platforms access explicit feedback users. however gather different implicit feedback user performance. case rely companion display presented time audio playing. audio playing user decide click companion banner. however clicks noisy user might want close unintentionally click. figure depicts heat clicks mobile device. clicks around close button therefore likely noisy clicks. metric called long click rate i.e. amount times user clicks companion banner stay follow page threshold time case discovered clicks left corner clicked resulting user leaving less seconds following page. therefore fixed threshold seconds. effectiveness proposed metrics arguable validity ctr. however dwell-time higher threshold used successfully literature user engagement metric sponsored search native case might bias toward images shown. captures signals intensity perceived volume noisiness. melfrequency cepstral coefficients compact representation spectral shape motivated human auditory system perceives sound. frequency spectrum warped perceptually motivated filters. perceptual frequency warping linear logarithmic thereafter. given spectral frame mel-spaced filter-bank matrix mel-spectrum frame computed mel-frequency resulting mel-spectrum scaled discrete cosine transform performed create ceptstrum dct{log} cepstral frequencies mfcc feature first coefficients cepstrum starting second coefficient first coefficient often ignored represents scale rather shape. feature used capture timbre instrumentation intonation speaker/singer gender number speakers tone presence music sound effects. delta-mfcc frame-to-frame difference mfccs captures dynamics attributes mel-spectral patters capture consistency temporal stability energy mel-frequency bands. coarse band mel-spectrogram computed stft. sequential -frame blocks collected activations band block sorted. feature summarized percentile blocks bands rhythm features rhythm features capture relationships sound event timing. used model signal repetitiveness fast speaker talking pulse/pace presence background rhythms contains music backing tracks. rhythm features start computation accent-signal summarization stft shows emphasis sonic events occur time also computed along three distinct frequency ranges sonic accents low/bass middle/treble high pitch accent signals tempogram feature starts autocorrelation accent signal autocorrelation measure self-similarity product signals respect time shift tempogram transformation axis linearly-quantized frequency axis scaled represent beatsper-minute. captures absolute rates repetitiveness accent signal also used estimate primary secondary tempo estimate tg_lin feature made compact tempo-invariant looking weights tempogram simple fractional ratios estimated tempo creates tempogram ratio feature relative temporal self-similarity tgrr tempo estimate accent signal musical beattracking performed dynamic programming method capture positions fundamental pulse accent signal finance/insurance retail/mass retail table users’ selected reason preferring particular audio audio aesthetics selected reason preference time acoustic features section outline methods features motivated user study conducted related work digital signal processing music information retrieval obtain characteristics timbre rhythm harmony directly audio signal. summarized table many features high-dimensional designed capture intuitive auditory concepts dimensions. ad-quality nebulous problem chose start high-dimensional representations allow model choose important. affords ability gain intuition sonic attributes lead quality rating. acoustic features computed many sequential fixedlength windows audio samples resulting discrete fourier transform short-time fourier transform many sequential dfts computed sliding widows across signal. stft shows magnitude specific frequencies present time step audio signal starting point many hand-crafted acoustic features fundamental trade-offs computing stft. work audio start files. timbre rhythm features frame length samples sequential overlap overlap respectively. harmony features frame length overlap. parameter values quite common supporting literature timbre features timbre features capture characteristics overall quality sound. differences timbre distinguish male female voice multiple speakers music speech sound effects etc. many timbre features computed spectral frame order capture compact representation entire signal summarized block statistics. mean covariance feature dimensions computed fixedlength blocks frames. mean variance right covariance matrix vectorized vector block. blocks summarized mean variance vectors summarization performed mfcc dmfcc features. temporal features dynamics block summary frame’s amplitude block mfccs block summary compact snapshot spectral shape block delta mfccs block summary change spectral shape block mel-spectral patterns block summary patterns activation mel-frequency bands primary secondary estimate beats minute tempogram histogram-like feature shows emphasis rhythmic repetition multi-band ratios. compact version tempogram simple ratios tempo estimate multi-band beat profile captures snapshot emphasis within estimated beat/pulse positions mellin scale transform rhythmic self-similarity among multiple time scales shift-invariant chroma histogram histogram pitch classes present estimate major minor mode shift-invariant histogram chords present correlations hpcp chord templates modeling using acoustic features section focus predicting quality audio using acoustic features. denote feature vector dimension. goal predict probability audio high quality. curse dimensionality important step reduce number variables transform features smaller dimension. total number acoustic features extracted audio multi-collinearity redundancy also lead over-fitting. explore different dimension reduction feature extraction techniques including kernel feature selection based feature importance calculated tree classifiers penalty logistic regression linear svc. vector learn. logarithmic loss order learn previous function. moreover since many features regularized logistic regression often used feature selection model analogous lasso penalty term added loss criterion words minimize following function regularization parameter. furthermore implement reduced dimension obtained kernel apart mentioned methods explore support vector machines linear support harmony features harmony features seemingly tangential mostly nonmusic task still provide important information regarding frequency organization. speech dynamic harmonically rich signal. features capture person’s tone monotone animated clearly pitched raspy breathy. background music capture harmonic organization well. harmony features start constant-q transform performed stft frame spectral filtering/warping capture frequency emphasis locations musical notes based equal-tempered tuning. harmonic pitch class profile circular summarization constant-q transform captures emphasis pitch classes octaves ...k frame note bins frames summarized taking mean across frames. made shift-invariant taking fourier transform hpcp emphasize harmonic note relationships density harmony specific correlation features computed finding correlation hpcp contextual templates chordogram correlation coefficients hpcp frame major minor chords. chord correlations feature mean chordogram. chord histogram histogram chord estimates using chordogram frame. correlations feature correlation coefficients mean frames hpcp major minor templates made shift-invariant taking d-fourier transform resulting correlations/estimates. feature becomes fourier transform difference major minor correlations/estimates concatenated major minor correlations/estimates. concatenated major minor template activations vector classifier nonlinear kernel furthermore ensemble methods including random forest classifier boost decision trees bagging classifier logistic regression multilayer perceptron commonly used neural network methods classification. feedforward neural networks standard back-propagation algorithm training. classifier learns transform input data desired response supervise manner. consists input layer hidden layer output layer. implement audio ad’s acoustic features train model gain audio quality therefore architecture method neurons input layer neuron output layer hidden layers fully connected layers rectified linear units activation function max. relus ensure faster computation efficient gradient propagation sparse structure moreover prevent over-fitting ensure regularization dropout applied layer level dropout number hidden layers number neurons layer tuned using cross validation section output layer neuron sigmoid activation function representing likelihood good quality. training process minimize binary cross-entropy loss function uses adam optimizer default parameters architecture hidden layer shown figure presented network used predicting audio ad’s quality. also last hidden layer seen learned features audio acoustic features. features smaller dimension useful later representing clustering informative direction ads’ quality. estimate higher-level features directly spectrograms. representations typically contained rf×n matrices frequency bins time frames become input cnn. work propose deep learning model predict quality audio using spectrogram. model inspired music deep learning works compute frequency log-compressed constant-q transforms dataset using librosa parameters audio sampling rate length samples bins octave. furthermore log-amplitude scaling applied spectrograms power scaling even cnns allow variable sized inputs weight sharing nature convolutional filters need normalize sizes spectrograms train minibatches data points gradients become stable. inspired randomly sample three -seconds long patches resulting fixed-size input network used training. need patches need place valid tensor mini batch gradient training. inference network able make predictions full audio ads. network composed convolutional layers. convolutions operate time axis only thus convolutions instead common practice dealing music signals inspired importance relation frequency bins whose absolute placement spectrum matters. layers convolution maxpooling layer compute global pooling time placed. layer obtains different statistics mean l-norm standard deviation. aggregation network need operate fixed-sized spectrograms therefore audio different sizes able network. finally dense layers dropout relus added global pooling last layer scalars softmax activation represents likelihood classes good quality structure network shown figure training process minimizes binary cross-entropy loss function uses adam optimizer default parameters processor memory. implement network different dropout rate number hidden layers number neurons layer calculate average test auc. best configuration gained dropout rate layer hidden layer number neurons hidden layers respectively. explained section since sampling patches audio dataset total patches split training testing. make sure patches audio found different splits minibatches patches used training network converges epochs takes around minutes finish tesla gpu. network trained takes seconds average inference full spectrograms. trying different parameters best network gained using convolutional layers length time filters respectively. maxpool layers placed convolution aggregate time following shapes also dense layers neurons dropout. performance analysis section compare effectiveness proposed methods best configuration. comparison baseline methods machine learning approaches explained sec. results presented table results shows among baseline methods logistic regression regularization gives highest labels. moving network acoustic features increases r-lcr labels respectively. furthermore audio spectrograms gives highest accuracy test r-lcr labeled data. case comparison best baseline method accuracy increases r-lcr labels. results shows method spectrograms beats methods based acoustic features audio spectrograms used sufficient input obtain quality audio another comparison based runtime different methods. test training time method recorded table results show methods much higher training time comparison methods. therefore size data increases time hindering comparison methods. intuition discussion good property ml-based methods easy interpretation. among methods best accuracy obtained using lr-l method. method regularization used variable selection. list selected variables corresponding coefficients presented figure r-lcr data respectively. selected features value insight general characteristics favor better audio datasets sample audio pandora.com june collected information r-lcr audio following procedure described section labels applied filter least long clicks least users long clicked impressions. related dataset consists unique audio ads. r-lcr related dataset consists unique audio ads. audio format kbps. order insight audio datasets sampled audio asked human listeners provide information aesthetic data. listeners determined gender speaker speed speaker existence background music sound effect ad’s volume. figure show percentage aesthetic characteristics. audio dataset seems good diversity terms audio aesthetics. final dataset made audio acoustic features extracted audio spectrogram binary label. order binary label based r-lcr sort dataset based quality metric take upper percentile good lower percentile bad. define percentiles selected considered different scenarios chose percentiles highest prediction accuracy. scenarios tried percentile best result gained labeling good percentile lower percentile. implementation parameter tuning tune parameters method choose best parameters implement -fold stratified cross validation training data. fold fold train model remaining fold testing calculate average test auc. average test folds used select best parameters. network explained section batches size total number epochs used training training takes around seconds finish inter core acoustic feature intuition. timbre features quite important predicting ad-quality. correlations mel-frequency cepstral coefficients delta mfcc correspond spectral shape speech variance suggest clear pronunciation important. furthermore jarring sound effects music mask parts spectrum contain speech leading poor quality. correlations mel-spectral patterns dimensions suggest frequencies high frequencies active quality suggesting balance audio bad. furthermore high variance high frequencies leads quality well overall spectral range sound stable. speech sits middle frequencies overbalance variance frequencies surrounding speech distracting. rhythm features specifically tg_lin faster relative pulse repetition negatively correlated quality slower repetition relative pulse positively correlated quality. indicates speaking slowly moderate tempo music correlates better quality. harmony features also showed interesting correlations. major mode positively correlates quality suggesting choice music sounds major key. sikc sich little direct contextual meaning speech signals capture patterns transitions harmonic spacing sounds. animated speech pitch shifts down captured. correlations show moderately animated pitch shifts lead good quality ads. speech animated monotone leads poor quality. suggests speak slightly animated tone choose music little harmonic motion. qualitative listening analysis. intuition gained listening correctly predicted good versus poor quality. done clustering audio features well last layer neural-network model types listening clusters primarily true-positives true-negatives. neural-network based methods gives much better clusters terms separating high quality audio ads. listening clusters highest lowest quality gain insights differences clusters. qualitative analysis showed good clear midpaced solo voice. contain moderately varied non-monotone speaker expression moderate excitement. speech conversational speaker audience isolated speakers background music basic. good balance background foreground sounds almost sound effects. poor quality faster paced language long winded explanations products monotone expression. many loud backing music jarring sound effects sometimes obscure speech. finally many also lower quality recordings distortion compression effects. qualitative attributes shared among models clear interpret lr-l method neural network method. suggests acoustic attribute saliences exist echoed quantitative feature correlation analysis qualitative analysis. however neural network higher overall potentially picking subtleties leaves room exploration additional attributes capturing. conclusions future work work presented first audio quality prediction model. focus building prediction model using acoustic content. given fact direct feedback users regarding audio proposed quality metrics based long click rate audio ad’s companion display labeling audio files. conducted user study understand users’ reasons prefering particular audio results user study show cases prefer audio audio aesthetics. motivated this implemented several acoustic features. later used features learn prediction model audio quality. results show speaking slow less jarring sound effect simple music lead better audio quality. another finding conversational tone usually engaging instance future works plan study proposed quality metrics instance investigating bias toward images shown. furthremore want include model user profile features campaign information historical data quality. another interesting investigation transcription audio content perform text analysis. references giuseppe bandiera oriol romani picas hiroshi tokuda wataru hariya koji oishi xavier serra. good-sounds. framework explore goodness instrumental sounds.. proc. international society music information retrieval conference nicola barbieri fabrizio silvestri mounia lalmas. improving post-click user engagement native survival analysis. proceedings international conference world wide international world wide conferences steering committee republic canton geneva switzerland https//doi.org/./. breiman. random forests. machine learning junxuan chen baigui hongtao xian-sheng hua. deep prediction display advertising. proceedings multimedia conference. xavier glorot antoine bordes yoshua bengio. deep sparse rectifier neural networks. proceedings fourteenth international conference artificial intelligence statistics. dustin hillard stefan schroedl eren manavoglu hema raghavan chirs leggetter. improving relevance sponsored search. proceedings third international conference search data mining york https//doi.org/./. andré holzapfel yannis stylianou. scale transform rhythmic similarity music. ieee transactions audio speech language processing youngho ahmed hassan ryen white imed zitouni. modeling dwell time predict click-level satisfaction. proceedings international conference search data mining york https//doi.org/./. youngmoo erik schmidt raymond migneco brandon morton patrick richardson jeffrey scott jacquelin speck douglas turnbull. music emotion recognition state review. proc. international society music information retrieval conference mounia lalmas janette lehmann shaked fabrizio silvestri gabriele tolomei. promoting positive post-click experience in-stream yahoo gemini users. proceedings sigkdd international conference knowledge discovery data mining york https//doi.org/./. kuang-chih burkay orten dasdan wentong estimating conversion rate display advertising past erformance data. proceedings sigkdd international conference knowledge discovery data mining york https//doi.org/./. brian mcfee colin raffel dawen liang daniel ellis matt mcvicar eric battenberg oriol nieto. librosa audio music signal analysis python. proceedings python science conference. matthew prockup andreas ehmann fabien gouyon erik schmidt oscar celma youngmoo kim. modeling genre music genome project comparing human-labeled attributes audio features.. proc. international society music information retrieval conference matthew prockup andreas ehmann fabien gouyon erik schmidt youngmoo kim. modeling musical rhythmatscale music genome project. ieee workshop applications signal processing audio acoustics ieee intelligent systems mixing multichannel audio. digital signal processing international conference ieee rómer rosales haibin cheng eren manavoglu. post-click conversion modeling analysis non-guaranteed delivery display advertising. proceedings fifth international conference search data mining york https//doi.org/./ eric sodomka sébastien lahaie dustin hillard. predictive model advertiser value-per-click sponsored search. proceedings international conference world wide york https//doi.org/./. nitish srivastava geoffrey hinton alex krizhevsky ilya sutskever ruslan salakhutdinov. dropout simple prevent neural networks overfitting. journal machine learning research george tzanetakis perry cook. musical genre classification audio signals. ieee transactions speech audio processing aaron oord sander dieleman benjamin schrauwen. deep content-based music recommendation. advances neural information processing systems. martin wainwright john lafferty pradeep ravikumar. highdimensional graphical model selection using l-regularized logistic regression. advances neural information processing systems. chong wang achir kalra cristian borcea chen. viewability prediction online display ads. proceedings international conference information knowledge management york https//doi.org/./. alex wilson bruno fazenda. perception audio quality productions popular music. journal audio engineering society http//www.aes.org/e-lib/browse.cfm?elib= weinan zhang tianming wang. deep learning multi-field categorical data. european conference information retrieval. springer zhou miriam redi andrew haines mounia lalmas. predicting preclick quality native advertisements. proceedings international conference world wide international world wide conferences steering committee republic canton geneva switzerland https//doi.org/./. zhou miriam redi andrew haines mounia lalmas. predicting preclick quality native advertisements. proceedings international conference world wide web. international world wide conferences steering committee", "year": "2018"}