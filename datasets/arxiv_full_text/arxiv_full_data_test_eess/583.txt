{"title": "A General Pipeline for 3D Detection of Vehicles", "tag": "eess", "abstract": " Autonomous driving requires 3D perception of vehicles and other objects in the in environment. Much of the current methods support 2D vehicle detection. This paper proposes a flexible pipeline to adopt any 2D detection network and fuse it with a 3D point cloud to generate 3D information with minimum changes of the 2D detection networks. To identify the 3D box, an effective model fitting algorithm is developed based on generalised car models and score maps. A two-stage convolutional neural network (CNN) is proposed to refine the detected 3D box. This pipeline is tested on the KITTI dataset using two different 2D detection networks. The 3D detection results based on these two networks are similar, demonstrating the flexibility of the proposed pipeline. The results rank second among the 3D detection algorithms, indicating its competencies in 3D detection. ", "text": "lidar despite high cost able provide direct measurement object location. lacks color information always sparse poses difﬁculties classiﬁcation. order make full capabilities lidar camera fusion approaches proposed literature. make deep architecture point cloud needs transformed formats. process transformation information lost. prior approaches vehicle detection effective detection. little attention paid transfer advantages lessons learnt detection approaches detection approaches. moreover ﬁeld lacking effective detection approaches enable existing approaches provide information. state approaches applied autonomous vehicles require information. paper propose ﬂexible vehicle detection pipeline make detection network provide accurate detection results fusing network point cloud. general framework structure illustrated fig. image passed detection network provides boxes around vehicles image plane. subsequently points fall bounding projection selected. model ﬁtting algorithm detects location bounding vehicle. another network takes points bounding input carries ﬁnal regression classiﬁcation. requires minimum efforts modify existing networks pipeline adding additional regression term output layer estimate vehicle dimensions. main contributions paper pipeline tested using outstanding networks pc-cnn ms-cnn detection performances based networks evaluated using kitti dataset signiﬁcantly lead majority algorithms bird detection detection tasks. also achieved comparable results current state algorithm tasks. abstract— autonomous driving requires perception vehicles objects environment. much current methods support vehicle detection. paper proposes ﬂexible pipeline adopt detection network fuse point cloud generate information minimum changes detection networks. identify effective model ﬁtting algorithm developed based generalised models score maps. two-stage convolutional neural network proposed reﬁne detected box. pipeline tested kitti dataset using different detection networks. detection results based networks similar demonstrating ﬂexibility proposed pipeline. results rank second among detection algorithms indicating competencies detection. vision-based detection well developed widely implemented using deep learning technologies. kitti benchmark site reports state algorithms able achieve average precision however autonomous vehicles detection images sufﬁcient provide enough information vehicle perform planning decision making lack depth data. robust comprehensive perception system autonomous vehicle detection including dimensions locations orientations world essential. however state detection algorithms achieve gaps still exist compared detection performance problem remains challenging. mono images lack depth information recover therefore assumptions location detected obstacles approximations made. stereo image based approaches normally involve construction depth maps stereo correspondence matching. performance type approach depends heavily depth reconstruction accuracy drops distance vehicle increases. fig. general fusion pipeline. point clouds shown viewed height encoded color ground. subset points selected based detection. then model ﬁtting algorithm based generalised models score maps applied points subset two-stage reﬁnement designed tune detected re-assign objectiveness score mono image approaches network designed estimate dimensions orientations probabilities given detected existing network. using criterion perspective projection tightly image recovered using estimated information. similarly deepmanta vehicle orientation size estimated deep cnn. additionally network also estimated locations points image coordinates. shape matching algorithm applied estimate vehicle poses based part locations. stereo image approaches depth stereo correspondence normally appended image fourth channel. rgb-d image passed cnns order carry detection. pham proposed two-stream depth channel channel went separate branches fused fully connected layers. lidar approaches common framework involves three steps pre-processing segmentation classiﬁcation. detailed review lidar approaches found wang proposed different approach point cloud converted feature grids detection window slid feature grids identify vehicles. point cloud converted point designed identify vehicle bounding boxes point map. authors extended approach applied deep directly point cloud. however approach time consuming memory intensive convolutions involved. improve proposed voting mechanism able perform sparse convolution. fusion approaches sparse point cloud converted dense depth image similar stereo one. rgb-d image passed detection. point cloud converted three-channel contains horizontal disparity height ground angle channel. resulting six-channel image rgb-hha processed detection vehicles. however methods able output information directly network. oder address this detection network proposed chen included type input generated point cloud bird’s view feature input. input projective loss compared depth thus proposal boxes generated directly. approach achieved current state vehicle detection. generates boxes boxes generate boxes boxes. explores entire point cloud focus subsets point cloud efﬁcient saves computation power. detection proposed pipeline ﬂexible regards choice detection networks. slight change required last fully connected layer network able estimate dimensions cars. proposed ways encode dimensions network. better accuracy detection networks proposed incorporated since leading networks detection. faster computation approaches presented implemented. paper implement pc-cnn ms-cnn demonstrate ﬂexibility pipeline. model fitting xiang proposed voxel patterns model. dvps encode occlusion self-occlusion truncation information. boosting detector designed identify dvps image implemented sub-category awareness deformable part-based models found different classiﬁers trained detect dpm. fidler extended cuboid model order allow reasoning wireframe models used. similarly wire vertex encoded visibility. various vehicle types sizes occlusion patterns prior approaches require substantial number models order cover possible cases. approach three models used occlusion pattern assigned online model ﬁtting. input image. ﬁrst step generate bounding boxes candidate vehicles. secondly bounding boxes used select subsets point clouds using transformation camera lidar. perspective nature camera point subset spread across much larger area vehicle shown fig.. subset also contains substantial number non-vehicle points points neighbouring vehicles. artefacts challenges detection. proposals generated following principle ransac algorithm iteration point selected randomly. second point randomly selected points within cube centred ﬁrst point side length length dimension estimation compensates estimation error. vertical plane derived points. points distance plane less threshold considered inliers plane. maximum points randomly selected inliers. point second vertical plane passing point perpendicular ﬁrst vertical plane derived. along intersection line vertical planes eight boxes generated based estimated width length. since ﬁrst vertical plane visible based view direction four boxes eliminated. remaining locations range deﬁned expanding times along directions. lowest point within range found determines ground roof based height estimation. summary iteration maximum proposals generated. additional regression layer needed given detection network. regression method inspired first average dimensions cars vans kitti dataset obtained. denote height length width vehicle. ground truth regression vector weighting factor balance losses deﬁned original network e.g. classiﬁcation loss regression loss; otherwise; smooth loss function deﬁned regression vector network. train modiﬁed network reuse pre-trained weights original network initialisation. small part network needs re-trained rest kept ﬁxed training. example ms-cnn re-trained convolution layer fully connected layers pooling detection subnetwork pc-cnn re-trained googlenet layer convolution layer fully connected layers deconvolution layer detection sub-network. three generalised models used model ﬁtting. represent three categories cars suvs sedans vans. hatchback cars considered suvs. observe relative distances/positions different parts vary signiﬁcantly different cars category even different sizes. invariance indicates cars category normalised dimension shapes contours similar. veriﬁed generalised models normalising cars dataset used figure illustrates side view point cloud plots three categories. plot aggregation points generated models aligned direction normalised dimension. suv/hatchback plot consists points models sedan plot consists point sets plot consists points models. aggregation voxelized matrix along direction. element matrix assigned different scores based position. elements representing shell/surface assigned score indicating points model ﬁtting process fall surface counted towards overall score. elements inside outside shell assigned negative scores away shell smaller assigned values. indicates points detected outside inside lidar overall score penalised detections. elements bottom layer matrix assigned score points detected bottom layer could ground car’s tires difﬁcult distinguish other. penalised counted. given model ﬁtting process pipeline expands along directions times respectively include context. points inside expanded normalised voxelised matrix. matrix sparse occupied elements average. compared generalised model doubled resolution voxelisation order reserve spatial details patterns distribution points. note normalisation anisometric different scale ratios along different directions. self-occlusion easily determined view direction. encoded online model ﬁtting since view direction changes different proposals. negative scores assigned surface elements self-occluded. furthermore simplicity four vertical facets considered self-occlusion analysis roof bottom considered. slices score assignment category shown fig. left image depicting side facet right image illustrating center slice. exterior interior indicated orange blue bottom indicated white. yellow green refer shell/surface green indicates areas might self-occluded. points within proposals voxelised grids compared three potential vehicle models. orientation ambiguity grids rotated around vertical center axis degree compared three models. bounding proposals highest score selected next step. align detected point cloud designed two-stage cnn. literature cnns commonly used process point clouds e.g. however cnns extremely slow memory intensive. paper found cnns sufﬁcient. points given ﬁrst outputs box. points found within box. second outputs probability score based points indicate likely points represent actual car. however point sets cannot input directly. apply normalization voxelization strategies order formalize points matrix form order cnn. furthermore consistent image detection cases bounding context able provide additional information improve detection accuracy. also include context bounding input cnn. backbones cnns stages based vgg-net conﬁguration described convolution layer instead relu layer adopted stable training process. ﬁrst stage parallel outputs regression classiﬁcation second stage output classiﬁcation. classiﬁcation loss cnns tmax loss regression loss smoothl loss. ground truth regression vector deﬁned seven elements three left bottom corner width. sufﬁcient recover bounding seven elements. anisometric normalisation quartic polynomial needs solved. note across inputs xc/l yc/l zc/l constant boxes aligned normalised size. classiﬁcation classes background. classiﬁed positive bird’s view ground truth bird’s view greater speciﬁc threshold. threshold ﬁrst stage second. consistent criteria kitti benchmark. reason lower threshold ﬁrst stage train network able reﬁne boxes better position greater otherwise network take boxes negative trained reﬁne them. verify ﬂexibility approach pipeline tested using pc-cnn ms-cnn performance based networks evaluated using challenging kitti dataset contains images training/validation images testing. training/validation annotated ground truth bounding image plane bounding real world. following split training/validation training validation sub-sets. training sub-set purely used train dimension regression twostage validation sub-set evaluation only. kitti divides cars easy moderate hard groups based visibilities. follow convention evaluation. verify performance proposed pipeline also tested using autonomous vehicles. metrics primary focus paper detection evaluate performance pipeline detection tasks. following evaluation metrics proposed evaluate proposal based average precession bird’s view boxes boxes. bird’s view boxes generated projecting boxes ground plane. calculated based output boxes ground truth boxes distance boxes used. feel comprehensive index distance implicitly accounts distance also alignment size. bird’s view compare outputs pipeline algorithms output information including monod deepdbox image data only velofcn uses lidar data uses fusion. threshold true positive detection left part table shows results bird’s view. general point cloud based approaches signiﬁcantly lead image-based approaches ious. within point cloud based approaches pipeline outperforms velofcn signiﬁcantly underperforms marginally. performance pc-cnn worse average worse ms-cnn. performances pc-cnn ms-cnn close except performance pc-cnn hard group detection comparisons listed right part table similarly thresholds method signiﬁcantly outperforms approaches single exception mvd. average overall performance worse except performance ms-cnn moderate group less mvd. point clouds generate take color information image account. comparing velofcn also takes point clouds inputs shows effectiveness approach processing point cloud subsets instead whole. comparing image color information necessary boost performance pipeline. possible solution extract feature layer right pooling layer detection cnn. based model ﬁtting process could corresponding image plane carry pooling extracted feature layer order extract feature vector. fuse feature vector reﬁnement output ﬁnal probability. flexibility anlysis comparison approaches using proposed pipeline veriﬁes ﬂexibility pipeline. pc-cnn ms-cnn different network structures. approaches achieve comparable tasks thresholds. furthermore two-stage reﬁnement trained based pipeline pccnn re-used pipeline ms-cnn without tuning network. conﬁrms ﬂexibility adaptability proposed pipeline. dimension regression impact show impact dimension regression original detection table similarly populated detection task image plane. following kitti threshold left part shows performance original detection right part indicates results appending dimension regression term. impact signiﬁcant networks even improves performance marginally groups. ablation study analyse effectiveness steps involved generation calculated step bird’s view tasks. study threshold since results based ms-cnn pc-cnn quite comparable pccnn results presented table iii. ﬁrst detection performance improved signiﬁcantly bird’s view tasks. improvement respectively. shows although convolution used input matrix sparse network still powerful effective locate box. improvement second insigniﬁcant since designed regress box. designed reshufﬂe probability ﬁrst cnn. qualitative results ﬁrst fig. shows detection results applying pipeline pccnn kitti validation dataset. also tested using dataset collected boston usa. setup data collection vehicle similar kitti differences relative positions lidar camera car. applied pipeline trained based kitti training dataset directly boston data without ﬁne-tuning network weights. system still works shown second fig. shows generalisation capability proposed pipeline indicates potentials executing vehicle detection real situations beyond pre-designed dataset. interested readers refer link video illustrations paper propose ﬂexible vehicle detection pipeline able adopt advantages detection networks order provide information. effort adapt networks pipeline minimal. additional regression term needed network output estimate vehicle dimensions. pipeline also takes advantage point clouds measurements. effective model ﬁtting algorithm based generalised models score maps proposed bounding boxes point cloud. finally two-stage developed tune box. outstanding results based different networks indicate ﬂexibility pipeline capability vehicle detection. research supported national research foundation prime minister’s ofﬁce singapore create programme singapore-mit alliance research technology future urban mobility irg. grateful support. pepik stark gehler schiele teaching geometry deformable part models computer vision pattern recognition ieee conference ieee forsyth object detection discriminatively trained part-based l.-c. chen fidler yuille urtasun beat mturkers automatic image labeling weak supervision proceedings ieee conference computer vision pattern recognition bell lawrence zitnick bala girshick inside-outside detecting objects context skip pooling recurrent neural networks proceedings ieee conference computer vision pattern recognition chen kundu zhang fidler urtasun monocular object detection autonomous driving proceedings ieee conference computer vision pattern recognition xiang choi savarese subcategory-aware convolutional neural networks object proposals detection applications computer vision ieee winter conference ieee zeeshan stark schindler explicit occlusion modeling object class representations proceedings ieee conference computer vision pattern recognition pham jeon robust object proposals re-ranking object detection autonomous driving using convolutional neural networks signal processing image communication engelcke wang tong posner votedeep fast object detection point clouds using efﬁcient convolutional neural networks robotics automation ieee international conference ieee schoenberg nathan campbell segmentation dense range information complex urban scenes intelligent robots systems ieee/rsj international conference ieee eitel springenberg spinello riedmiller burgard multimodal deep learning robust rgb-d object recognition intelligent robots systems ieee/rsj international conference ieee schlosser chow kira fusing lidar images pedestrian detection using convolutional neural networks robotics automation ieee international conference ieee detection autonomous vehicle lidar vision fusion approach deep learning framework intelligent robots systems ieee/rsj international conference ieee yang choi exploit layers fast accurate object detector scale dependent pooling cascaded rejection classiﬁers proceedings ieee conference computer vision pattern recognition", "year": "2018"}