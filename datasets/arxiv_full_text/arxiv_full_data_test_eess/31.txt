{"title": "Restoring a smooth function from its noisy integrals", "tag": "eess", "abstract": " Numerical (and experimental) data analysis often requires the restoration of a smooth function from a set of sampled integrals over finite bins. We present the bin hierarchy method that efficiently computes the maximally smooth function from the sampled integrals using essentially all the information contained in the data. We perform extensive tests with different classes of functions and levels of data quality, including Monte Carlo data suffering from a severe sign problem and physical data for the Green's function of the Fr\\\"ohlich polaron. ", "text": "numerical data analysis often requires restoration smooth function sampled integrals ﬁnite bins. present hierarchy method eﬃciently computes maximally smooth function sampled integrals using essentially information contained data. perform extensive tests diﬀerent classes functions levels data quality including monte carlo data suﬀering severe sign problem physical data green’s function fr¨ohlich polaron. sampling heart many monte carlo computations experimental measurements. data points generated measured eventually want restore underlying smooth probability density distribution behind them. many density estimation protocols lists statistical data exist– large-scale monte carlo calculations storing individual data points would require pentabytes memory lead substantial slowing simulation. importantly individual data points needed provided know structureless certain scale. hence without losing essential information collect integrals ﬁnite-size bins. problem extract information integrals without systematic bias augmenting priori knowledge smoothness function. paper propose simple eﬃcient solution call hierarchy method note problem closely related problem numerical analytic continuation consistent constraints crucial simpliﬁcation. unlike numerical restoration spectral functions account possible sharp features δfunction peaks kinks cannot resolved within sampled error bars. assuming smooth allowed parametrize optimal approximation polynomial spline smoothing spline approach. however fundamental diﬀerence data structure. rather ﬁtting approximate function values given points spline directly sampled integrals. central requirement must consistent sampled integrals elementary histogram bins also integrals combination these. integrals large bins known higher precision smaller bins since former contain data points. hence accurately recovering large integral priority recovering smaller one. particular bins certain scale contain noise rather information thus safely omitted ﬁtting. formalize idea introducing hierarchy bins entire domain level doubling number bins subsequent level. goodness evaluated level separately n/˜n measure number bins given hierarchy level. possible approximations consistent sampled integrals select least features i.e. least ﬁtting parameters. achieved ﬁtting spline order minimal number knots yields acceptable number positions knots determined automatically ﬁtting algorithm. known boundary conditions also accounted for. desired additional optimization terms instance jump highest spline derivative included ﬁtting procedure iterative improvement spirit method consistent paper organized follows. sec. review alternative methods construct argue superior accuracy eﬃciency simplicity. details presented sec. iii. sec. present several tests bhm. conclude sec. unity. basis weight functions diﬀerent deﬁned also bins inﬁnite size. general basis functions chosen reﬂect properties known advance instance known divergences asymptotic behavior. otherwise majority cases shifted legendre polynomials reasonable choice. using basis projections collect information sampling step naive histogram since information position inside preserved. therefore fewer bins necessary resolve function. widths basis sizes chosen systematic error negligible compared statistical error without substantial increase statistical noise values. basis projection method signiﬁcant improvement naive histogram still several disadvantages. binning basis functions must chosen beginning sampling process cannot altered retrospectively. basis projections also computationally expensive especially large basis basis built complicated functions. moreover sampled projections generally exhibit large jumps boundaries basis functions unbounded. before eliminate jumps taking values several points inside straightforward approximate distribution histogram– divide domain several bins count many times sampled values generated probabilities given fall bins. generated lows refer method naive histogramming— emphasize contrast also involves histogramming part protocol. result naive histogram method staircase function smooth. drawback ameliorated taking value centers ﬁtting smoothing spline data statistical error bars. important issue naive histogram method suﬀers inherent compromise resolution features statistical noise. suﬃciently narrow bins necessary resolve without introducing signiﬁcant systematic bias reducing size bins increases noise sampled counters. generalization naive histogram method—the basis projection method—can signiﬁcantly reduce drawback. method based generalized fourier series expansion choose constructing smoothing spline. procedure however involves unnecessary loss information. rather reducing speciﬁc individual points suggestive spline sampled intereweighting monte carlo-speciﬁc technique allows convert statistics generated given variable statistics values variable. achieved following way. prior sampling choose ﬁxed points associate bins large overlapping. whenever random variable falls associated point update counter reweighted value vp/p. value would sampled without reweighting ratio probability weights probability distribution used sample physical function seen deterministic update generated point ﬁxed point suﬃciently large bins several counters updated simultaneously generated reweighting technique provides unbiased estimator value ﬁxed reweighting method eﬃcient case interested single special value certain continuous variable. characteristic example sampling single-particle density matrix statistics green’s function reweighting latter cases reweighting computationally expensive compared gain accuracy. also requires case-speciﬁc implementation assumes knowledge analytical form reweighting factors. maximally eﬃcient adjust size bini interest. size must optimized that hand large enough ensure suﬃciently large statistics hand small enough reweighting factors remain order unity bins large also result strong increase autocorrelation time since reweighting rare event frequent implies large ratio result occasional anomalously large contributions sampled counters. moreover produce smooth outcome reweighting protocol requires appropriately dense mesh points strongly overlapping bins computationally expensive since large number counters needs updated generated continuous function values smoothing spline needs ﬁtted used distribution accuracy essentially stored full list generated values achieved introducing hierarchy overlapping histogram bins diﬀerent size large bins give precise estimates broad features distribution small bins resolve structure enough data accumulated. note assume sampled distribution structureless certain scale hence always exists binning suﬃciently resolve features. human input control necessary limited choice initial parameters. particular method applicable reasonably occurring functions require adjustment diﬀerent classes functions. form combinations several bins elementary bins arbitrarily small. bins data points automatically excluded analysis. number sampled points increases bins smaller size become usable. number elemenlimit would formally correspond keeping full list generated values practice distributions interest structureless beyond certain scale sets natural limit required elementary width. generate values according probabilsample value sign] elementary contains also include additional weighting coeﬃcients sampled values. store number sampled values well average scaled variance sampled values bin. obtain sampled integral elementary ¯vini/n total number sampled points. variance sampled integral calculated still included ﬁtting procedure resolve potential structures distribution. example periodically oscillating function like sine zero average large parts domain nonzero ﬁner scale. structure function resolved integrals small bins contain enough data. weight factors small bins cannot overpower large contributions. note minimization levels decide whether accepted check goodness every level separately. accepted n/˜n approximately within tain suﬃcient data used ﬁtting). acceptance threshold external input parameter typically lower values threshold likely result failure produce acceptable instead ﬁxed value range also speciﬁed example four. acceptable lowest threshold value gradually increased either maximum reached acceptable found. large number hierarchy levels statistical probability level exceed threshold n/˜n becomes non-negligible even overall good. specifying threshold range allows attempt lower threshold values without risking failed sampled integrals ﬁtted spline. follows discuss polynomial splines generalization functions straightforward. brieﬂy review theory ﬁtting single polyk= akxk turn full exists standard software ﬁtting points function. want match polynomial integrals requires slight adjustment. derivation follows steps general linear least squares ﬁtting. best polynomial minimizes integral polynomial simplicity omit levels corresponding weighting factors section generalization straightforward. label boundaries ¯xi+. integral polynomial equals goodness considering bins level note construction hierarchy happens post processing. sampling stage values elementary bins need collected stored. tested several modiﬁcations setup produced consistent results. including bins level using overlapping bins equal size found bring signiﬁcant improvement. likewise using weights improve result. general ﬁner bins higher levels substantially contribute form error bars large shape distribution usually already determined lower-level integrals. used check goodness overall test cases polynomials individual intervals passed goodness-of-ﬁt test overall spline evaluated entire domain passed also. note before checks individual intervals performed hierarchy level separately. half level bins inside given interval contain enough data check interval terminates without proceeding subsequent levels. spline knots derivatives order greater zero. piecewise constant derivative proportional value parameter interval exhibits jumps knots. imposing additional constraint aims minimize jumps ensures continuous evolution ﬁtted spline function number sampled points number spline pieces best generally increases growing better statistics permits better resolution sampled function. additional interval divisions triggered certain discrete values namely values affected interval crosses goodness-of-ﬁt threshold. creates additional jump derivative position knot. jump closed small sacriﬁce since previous spline fewer knot almost acceptable. sense additional constraint jump acts compensation mechanism potentially vigorous interval splitting. cases constraining jump almost eﬀect polynomial parameters optimal without constraint weights control strength constraint. computing optimal spline minimization spline attempted interval division time minimizing constraint local weights determined goodness original next-to-adjacent respective knot. speciﬁcally determine diﬀerence maximally acceptable n/˜n. take minimum diﬀerences. ensures constraint aﬀect spline intervals order equal. gives constraints knot. since polynomial coeﬃcients total number free parameters number spline pieces. extra parameters arise since polynomial piece knots. known boundary conditions reduce number free parameters. algorithm determines positions knots using following procedure. begin attempting polynomial whole interval. acceptable split interval equal parts attempt ﬁtting two-piece spline. acceptable either check goodness interval separately. intervals acceptable split next iteration intervals remain unchanged. repeat procedure either acceptable found intervals longer split. require equations spline piece overdetermined i.e. number bins inside interval larger sets limit maximal number spline pieces. check goodness individual interval compute values evaluated bins level fully inside given interval number bins. larger bins reach several intervals cannot used check another error estimation protocol based analysis evolution function sample size this spline produced saved periodically intervals sampling steps. idea results approach exact duce eﬀect initial portion statistics strongly aﬀected transient processes. simple consistency criterion range essentially independent parameters. tests showed errors calculated method almost indistinguishable ones obtained bootstrap hence also agree robust error. method somewhat slower since full needs evaluated repeatedly requires suﬃciently large hand sequence provides explicit insight statistics data help identify statistical ﬂuctuations. monte carlo sampling often suﬀers sign problem positive negative terms occur almost equal frequency sampling process. suﬃcient amount data collected error thus substantially exceed absolute value sampled integrals. applies error ﬁtted spline. fits noise substantially exceeds signal unsuitable data analysis. identify problem algorithm checks—at levels— whether sampled data consistent zero start ﬁtting process. data deemed certainly inconsistent zero least following conditions individual level value n/˜n zero function exceeds already original barely acceptable. global weight iteratively adjusted maximal value still compatible imposed threshold n/˜n. additional iterations performed replacing values calculated constraint. estimate spline coeﬃcient errors obtained spline piece. equation accurate parametric statistically independent normally distributed data points. case overlapping bins unconventional χ-minimization protocol. this cannot attach gaussian standard deviation probabilities error bars. robust deﬁning error given point look histogram values large independent runs sample size smallest interval around histogram mean contains values corresponds robust estimate standard erperformed extensive tests several error estimation protocols comparing robust estimate diﬀerent types distribution tests conﬁrmed provides good error estimate cases. cases error found overestimated factor compared robust error. occurred particular domain boundaries splines large number knots. concrete example presented sec. error never observed small hence gives convenient eﬃcient obtain conservative error estimate tighter error estimate obtained using bootstrap following protocol. produce array histograms contains fraction sampled data points point sampled exactly histograms. generate linear combinations histograms. bootstrapped histograms contains sampled points possible repetitions. bootstrap histograms ﬁxing positions knots regular histogram without evaluating goodness error spline coeﬃcients determined statistics bootstrapped histogram usual way. bootstrap error found close robust error estimate tests. scheme uses resources especially memory since hisfig. cubic polynomial test function. comparison basis projection method left panel shows function right panel shows diﬀerence ﬁtted true function methods. present tests several types distribution. unless otherwise stated test random samples taken demonstrate ability restore smooth distribution moderate sample. always cubic splines. displayed error bands splines obtained comparison sampled data points also basis projection method using polynomial basis cubic order. binning basis projection sampling retrospectively chosen interval division spline determined hierarchy algorithm. strict test since practice optimal binning projection method known advance. tests observed accuracy hierarchy least good basis projection method proving superiority least eﬃciency smoothness display basis projection results ﬁrst example polynomial distribution omit following examples avoid overcrowding plots. since distribution cubic polynomial algorithm stop ﬁtting polynomial entire domain. indeed case. figure shows comparison result obtained using basis projection method. particular case basis projection method provides accurate estimate function deﬁnition since projecting function form thus cover whole interval without introducing systematic error. nevertheless produces result comparable accuracy. example demonstrates competes basis projection method even latter known optimal. generate sample sign]. provides accurate smooth function. result comparison basis projection method shown fig. four spline pieces needed resolve function example. previous example fig. quartic polynomial test function. comparison basis projection method left panel shows function right panel shows diﬀerence ﬁtted true function methods. exponentially decaying distribution typical many physical processes. example produced acceptable spline pieces intervals figure shows best agrees well original function. best spline obtained ﬁtting elementary bins figure compares ﬁts. using elementary bins deviates strongly ﬁrst interval particular apparent integrals interval entire domain properly captured. figure shows transformed back original domain. large domain sampling points used example. agrees well original distribution within error bars. example produced acceptable spline interval. order compensate divergence assumed location type known advance. often suﬃcient know approximate properties divergence. demonstrate this fig. shows data sampled weighting factor slightly overestimates underestimates power divergence despite wrong scaling still agree original distribution errors larger. better overestimate power since case divergence still fully compensated. values generated monte carlo markov chain process types updates switching between sectors corresponding varying value interval within sector. update acceptance probabilities given detailed balance equations challenge resolve periodic oscillations within accuracy sampled data. small sample expect reproducing average function. collect data oscillations resolved. show hierarchy small sample points larger sample points fig. reproduces original distribution well within error bars. many spline pieces needed resolve structure overestimates error spline coeﬃcients. fig. show error band obtained well obtained using bootstrap. domain roughly domain comparable gaussian case. error deviation almost never exceeds also present robust error analysis based independent samples points each. histogram values shown fig. several values reference indicate speciﬁc value example shown fig. illustrate values example statistical outliers typical. also show median errors representative bootstrap error indeed size bootstrap evolution errors close robust estimate error large. fig. oscillating test function using sampled points sampled points shown error estimates spline coeﬃcients errors calculated using errors calculated using bootstrap bootstrap provides tighter bound errors example. left panels show function right panels show diﬀerence ﬁtted true function. figure shows spline sampled points. former case data compatible zero correctly captured algorithm presented sec. case used despite acceptable data gathered algorithm begins correctly reproduce features function. examples shown spline piece suﬃcient acceptable basis retrospectively chosen interval division. clearly seen provides accurate smooth fr¨ohlich polaron green’s function agrees well reference. error bars basis projection comparable basis projection sampling sampling stage number basis functions used. particular example polynomial basis cubic order corresponds least times many operations needed sampling stage bhm. argued demonstrated yields eﬃcient ﬂexible fully automatized algorithm restore smooth functions noisy integrals using available information. resulting least accurate ones obtained using basis projection sampling guaranteed smoothness knots. sampling also computationally less expensive using basis projections require many operations sampling step. similar projection method onto polynomial basis spline piecewise polynomial function several large intervals. crucial technical advantage intervals need ﬁxed beforehand. suitable division intervals found automatically algorithm adjusted time data points collected. future plan extend hierarchy algorithm multivariate functions since many relevant physical observables depend several variables time momentum. three four dimensions relevant physical applications. thank chris amey helpful discussions. work supported simons collaboration many electron problem national science foundation grant dmr-. o.g. also acknowledges support us-israel binational science foundation green’s function central quantity diagrammatic technique properties system obtained appropriate analysis. reference long monte carlo reweighting. provides reliable estimate green’s function negligible errors fig. smoothed histogram values oscillating test function vertical lines histogram mean true function value particular value simulation shown bottom panel fig. latter shown reference. horizontal lines interval around histogram mean median standard error interval around histogram mean robust standard error interval around fig. sampling divergent function deﬁned semi-inﬁnite domain using appropriate transforms. left panel shows function right panel shows diﬀerence ﬁtted true function. fig. sampling severe sign problem using sampled points sampled points sampled integrals used left panel consistent zero correctly captured check presented sec. case displayed spline would used data analysis. fig. diagrammatic monte carlo sampling fr¨ohlich polaron green’s function. left panel shows precise numerical calculation function right panel shows diﬀerence ﬁtted reference function basis projection method.", "year": "2017"}