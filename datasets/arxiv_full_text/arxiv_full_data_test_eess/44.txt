{"title": "Efficient Convolutional Neural Network For Audio Event Detection", "tag": "eess", "abstract": " Wireless distributed systems as used in sensor networks, Internet-of-Things and cyber-physical systems, impose high requirements on resource efficiency. Advanced preprocessing and classification of data at the network edge can help to decrease the communication demand and to reduce the amount of data to be processed centrally. In the area of distributed acoustic sensing, the combination of algorithms with a high classification rate and resource-constraint embedded systems is essential. Unfortunately, algorithms for acoustic event detection have a high memory and computational demand and are not suited for execution at the network edge. This paper addresses these aspects by applying structural optimizations to a convolutional neural network for audio event detection to reduce the memory requirement by a factor of more than 500 and the computational effort by a factor of 2.1 while performing 9.2% better. ", "text": "recently convolutional neural network -based approach proposed acoustic event detection using network design adapted image classiﬁcation shown approach outperforms previous state-of-the-art approaches large margin. unfortunately cnns computationally expensive proposed algorithm also comes expense huge memory requirement huge number parameters. image classiﬁcation reduce complexity cnn-based classiﬁcation systems presented approaches joined paper build highly-accurate capable running embedded platforms limited resources. algorithm experimentally veriﬁed compared state-of-the-art convolutional neural networks acoustic event detection. experiment shows overall reduction memory requirement factor reduction operations factor affect performance accuracy even increases hardware platforms battery-operated devices stringent power requirements. low-power devices limited like cortex series overall on-chip storage typically limited less available digital signal processing performance limited millions multiply-accumulate operations second even advanced components wireless distributed systems used sensor networks internet-of-things cyber-physical systems impose high requirements resource efﬁciency. advanced preprocessing classiﬁcation data network edge help decrease communication demand reduce amount data processed centrally. area distributed acoustic sensing combination algorithms high classiﬁcation rate resource-constraint embedded systems essential. unfortunately algorithms acoustic event detection high memory computational demand suited execution network edge. paper addresses aspects applying structural optimizations convolutional neural network audio event detection reduce memory requirement factor computational effort factor performing better. many applications sensor networks cyber-physical system internet-of-things require power consumption long-term autonomous operation. local preprocessing classifying data edge nodes solution reduce data transmission therefore reduce energy consumption. addition approach avoid enormous amounts data need communicated processed centralized data analysis infrastructure. detection acoustic events typical example instead streaming audio network perform server-side event detection acoustic events interest pre-detected directly sensing device reducing network’s data throughput signiﬁcantly. accurate detection classiﬁcation individual acoustic events sound-emitting environment interest many application surveillance environmental monitoring low-power embedded devices used systems however come stringent memory throughput limitations. resource confront-end used transform audio signal time-frequency representation features both frequencytime-domain extracted. general transforms based short-time fourier transform efﬁciently implemented fast fourier transformation fact makes favorable compared novel techniques show good results learning ﬁlterbank coefﬁcients audio data major drawback employing large ﬁlterbanks. mel-scaling mirrors human auditory system often used addition stft order compensate linear frequency scale. additional processing steps also reduce amount data needs processed later stages processing pipeline important since number operations directly related size input ﬁeld. consequence work mel-spectrogram chosen front-end satisfy real-time constraint. calculated window size size using hamming window. number coefﬁcients spectrogram multiple frames consisting vectors extracted. frames input feature extractor thus network analyzes time span frame. considered. platforms provide speed-ups factor around improved energy efﬁciency system perform optimal comprises simple structured architecture. concept provide relief admissible computational effort strong limitations available memory remain external memory would deteriorate device’s energy efﬁciency substantially. removing memory-demanding non-convolutional layers architecture ideal maximize efﬁciency hardware convolution accelerators acoustic event detection different algorithms presented based non-negative matrix factorization hidden markov models recurrent neural networks like many machine learning applications cnns proven high classiﬁcation accuracy. advantage architecture acoustic event detection inherent inclusion temporal neighborhood since acoustic events strongly characterized temporal changes. besides mentioned acoustic event detection cnns used mainly speech recognition music classiﬁcation tasks. algorithms computationally expensive current state-of-the-art also comes expense huge number parameters implementing network mobile devices sensor nodes difﬁcult memory computational restrictions devices. reduce complexity cnn-based classiﬁcation systems presented image classiﬁcation similar structure used cnns default designed low-power embedded devices thus careful design terms structure learning algorithms must chosen. explain different steps necessary detect acoustic event detection system divided three major components illustrated figure first time-domain audio waveform transformed front-end time-frequency representation. systems extracts features representation. ﬁnal step features classiﬁed. feature extraction block uses learn features time-frequency representation. cnns built basic building blocks convolution activation pooling layers. concatenation blocks introduces higher depth network shown enhance accuracy higher depth results higher number required operations higher parameter count. work feature extraction block therefore limited sections consisting convolutional layers each provides enough parameters learn signiﬁcant features still moderate parameter count. moreover convolutional layer higher ﬁlter size reduced layers using ﬁlters reduces number parameters potentially even improves classiﬁcation performance cnns pooling used regularize network shown small scale datasets removal pooling layer affect performance consequence pooling removed network stride preceding layer increased divides required operations layer four maintaining network structure principle. table illustrates structure network fullyconnected dense layers classiﬁer network using convolutional layers classiﬁers networks number parameters number required operations listed. becomes obvious fully-connected layers biggest impact parameter count makes preceding convolutional layers almost negligible. shown fully-connected layer replaced convolutional layer reduces number parameters thus memory footprint reduction parameters also regularizes network advantage training network therefore improvement accuracy expected. last layer average pooling reduces output last convolutional layer design proposed paper denoted cnn-cnp illustrated table applying optimization step described parameter count decreased considerably factor parameters number operations factor mac. moreover optimization network consists convolutional layers. uniﬁed architecture beneﬁcial hardware implementation especially convolutional hardware accelerators. applying fundamental changes network substantially reducing number parameters arithmetic operations needs validated classiﬁcation performance maintained kept acceptable level. purpose networks implemented using keras networks compared best performing implementations referred network structure cnn-fc network table network complex network higher depth bigger fully-connected layers. table structure number parameters number required operations three cnns. ﬁrst uses fully-connected layers classiﬁer second uses convolutional layers classiﬁer third uses convolutional layers classiﬁer pooling layers. convolutional layers deﬁned conv ﬁlter size stride number ﬁlters. fully-connected layers output dimensions. pooling layers pool pool size bility might reached necessary real-time performance higher. therefore hardware accelerators suggested allowing ofﬂoad computation dedicated processor maintaining good energy efﬁciency. explained novel network structure matches communication memory access pattern expected current accelerators. paper acoustic event detection algorithm presented exploits advantages cnns implementable low-power microcontrollers. first convolutional neural network proposed able supersede state-of-the-art acoustic event detection algorithms. second network efﬁciently implemented resourcelimited low-power embedded devices. demonstrated possible reduce memory requirement factor number operations factor outperforming similar network fully-connected layers structured approach consisting mainly convolutional layers makes easily portable novel convolutional hardware accelerators increase energy efﬁciency. dataset contains various sound ﬁles collected freely available online sources. consists different event types variable length e.g. airplanes violins birds footsteps. total length audio ﬁles minutes. data split training test set. training contains original data subdivided training validation ratio although dataset strongly biased data augmentation performed following experiments since main focus comparison algorithm terms structure resources classiﬁcation performance augmentation technique. networks trained minimizing cross-entropy loss using gradient-based optimizer adam mini-batches size optimizers’ parameters left default values. testing done predicting probabilities class seconds window randomly extracted test set. class highest probability chosen correct class compared ground truth. experimental results listed table values accuracy network taken original publication values number parameters number macs calculated based information taken original publication. ﬁrst line table shows accuracy results networks data augmentation respectively. expected better corresponding accuracy results withcomplex data augmentation respectively. networks cnn-c cnn-cnp accuracy respectively. thus without sophisticated data augmentation proposed networks perform better reference network even better complex network analysis parameter count shows parameters assumed total memory consumption cnn-fc network’s weights feasible edge computing applications considering ﬁerce power memory constraints distributed sensing devices. contrast weight storage cnn-c cnn-cnp approx. even considering additional overhead implementation low-power devices stmf ﬂash memory still sufﬁcient store parameters presented acoustic event detection algorithm. considering devices mentioned processing capability higher mac/s processing input buffer required every seconds able handle macs cnn-cnp less seconds. thus classiﬁcation considered real-time. practical applications however claimed processing capa zhou zhuang tang hasegawajohnson hmm-based acoustic event detection adaboost feature selection multimodal technologies perception humans lecture notes computer science springer berlin heidelberg parascandolo huttunen virtanen recurrent neural networks polyphonic sound event detection real life recordings ieee international conference acoustics speech signal processing march abdel-hamid mohamed jiang deng penn convolutional neural networks speech recognition ieee/acm transactions audio speech language processing vol. oct. choi fazekas sandler automatic tagging using deep convolutional neural networks proceedings international society music information retrieval conference ismir york city united states august cakir heittola huttunen virtanen polyphonic sound event detection using multi label deep neural networks international joint conference neural networks july girard beutel gruber hunziker weber custom acoustic emission monitoring system harsh environments application freezinginduced damage alpine rock walls geoscientiﬁc instrumentation methods data systems vol. conti benini ultra-low-energy convolution engine fast brain-inspired vision multicore clusters proceedings design automation test europe conference exhibition consortium cavigelli gschwend mayer willi muheim benini origami convolutional network accelerator proceedings edition great lakes symposium vlsi glsvlsi rossi conti marongiu pullini gautschi tagliavini capotondi flatresse benini pulp parallel ultra power platform next generation applications ieee chips symposium aug. komatsu toizumi kondo senda acoustic event detection method using semisupervised non-negative matrix factorization mixture local dictionaries tech. rep. dcase challenge sept.", "year": "2017"}