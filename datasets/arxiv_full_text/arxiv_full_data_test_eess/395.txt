{"title": "Deep Neural Network-based Cooperative Visual Tracking through Multiple  Micro Aerial Vehicles", "tag": "eess", "abstract": " Multi-camera full-body pose capture of humans and animals in outdoor environments is a highly challenging problem. Our approach to it involves a team of cooperating micro aerial vehicles (MAVs) with on-board cameras only. The key enabling-aspect of our approach is the on-board person detection and tracking method. Recent state-of-the-art methods based on deep neural networks (DNN) are highly promising in this context. However, real time DNNs are severely constrained in input data dimensions, in contrast to available camera resolutions. Therefore, DNNs often fail at objects with small scale or far away from the camera, which are typical characteristics of a scenario with aerial robots. Thus, the core problem addressed in this paper is how to achieve on-board, real-time, continuous and accurate vision-based detections using DNNs for visual person tracking through MAVs. Our solution leverages cooperation among multiple MAVs. First, each MAV fuses its own detections with those obtained by other MAVs to perform cooperative visual tracking. This allows for predicting future poses of the tracked person, which are used to selectively process only the relevant regions of future images, even at high resolutions. Consequently, using our DNN-based detector we are able to continuously track even distant humans with high accuracy and speed. We demonstrate the efficiency of our approach through real robot experiments involving two aerial robots tracking a person, while maintaining an active perception-driven formation. Our solution runs fully on-board our MAV's CPU and GPU, with no remote processing. ROS-based source code is provided for the benefit of the community. ", "text": "component mcdt solution person detection method suitable outdoor environments marker/sensor-free subjects. deep convolutional neural network-based person detection methods unarguably state-of-the-art. recent past dnns consistently shown outperform traditional techniques object detection consequently gained immense popularity various robotics-related ﬁelds autonomous driving detection identiﬁcation pedestrians vehicles however works exploit power dnns visual object detection board mavs. main limiting factor using dnns mavs computational requirements networks. majority real-time capable. fastest dnnbased detector achieves approximately frames second pixel square area. however requires computing power dedicated high usually bulky impractical install onboard mav. moreover higher power consumption often requires bulkier power supply aggravating issue. alternative transmitting images ground-station order ofﬂoad processing. however approach also infeasible communication bandwith constraints multiple mavs used. using advanced light weight al.’s single shot multibox detector achieves sequential processing. hardware suitable airborne speed lower boundary real time applicability. abstract— multi-camera full-body pose capture humans animals outdoor environments highly challenging problem. approach involves team cooperating micro aerial vehicles on-board cameras only. enabling-aspect approach on-board person detection tracking method. recent state-of-the-art methods based deep neural networks highly promising context. however real time dnns severely constrained input data dimensions contrast available camera resolutions. therefore dnns often fail objects small scale away camera typical characteristics scenario aerial robots. thus core problem addressed paper achieve on-board real-time continuous accurate vision-based detections using dnns visual person tracking mavs. solution leverages cooperation among multiple mavs. first fuses detections obtained mavs perform cooperative visual tracking. allows predicting future poses tracked person used selectively process relevant regions future images even high resolutions. consequently using dnn-based detector able continuously track even distant humans high accuracy speed. demonstrate efﬁciency approach real robot experiments involving aerial robots tracking person maintaining active perception-driven formation. solution runs fully on-board mav’s remote processing. rosbased source code provided beneﬁt community. human/animal pose tracking full body pose estimation reconstruction outdoor unstructured environments highly relevant challenging problem. wide range applications includes managing large public gatherings search rescue coordinating outdoor sports events facilitating animal conservation efforts wild indoor settings similar applications usually make body-mounted sensors artiﬁcial markers static cameras. markers might still usable outdoor scenarios dynamic ambient lighting conditions impossibility static/ﬁxed cameras make overall problem difﬁcult. hand body-mounted sensors suitable kinds subjects therefore approach aforementioned problem involves team micro aerial vehicles tracking subjects using on-board monocular cameras computational units without subject-ﬁxed sensor marker. among several challenges involved developing system eric.priceguilherme.lawlesshhbblackaamir.ahmadtuebingen.mpg.de planck institute intelligent systems t¨ubingen germany. planck institute biological cybernetics t¨ubingen germany. hand performance resolution images. real-time on-board processing high resolution images still infeasible. thus unfortunately cannot exploit richness highresolution images provided modern cameras. na¨ıve approach high resolution images perform uninformed non-selective processing down-sampled resolution input image. always suboptimal reduced information content. also resolution image could wide ﬁeld view often lacks detail regarding distant subject thus limiting detection capability accuracy. alternatively un-informed region interest greatly limits chance tracked person fov. therefore dnns would often fail objects small scale away camera typical characteristics scenario aerial robots. achieve real-time continuous accurate vision-based detections using dnns mcdt solution leverages mutual world knowledge jointly acquired multirobot system cooperative person tracking. however imply sharing full resolution images high frame rates mavs. multirobot environment required communication bandwidth would increase least linearly additional robot rendering data sharing impractical. instead share compactly-representable detection measurements bandwidth requirements. using these perform cooperative person tracking predicted poses tracked person feed dnn-based detector wellinformed future images. consequently knows look next actively select relevant supplies highest information content. thus method minimizes information loss incurred downsampling high resolution image also maximizes chance person completely fov. fusion detection measurements within mcdt method takes account associated person detection uncertainties well self-localization uncertainties mavs. work multibox detector versatility detecting wide range object classes availability annotated training data speed accuracy. however important note approach tailored speciﬁc detector. treat black deﬁned interface. visual detector used long operate arbitrarily scaled subsets input space. core contributions paper follows. real-time continuous accurate dnn-based multirobot cooperative detection tracking method suitable mavs on-board camera computation. method allows increased sensitivity small away targets compared ﬁxed wide-angle low-resolution evaluate performance mcdt approach active cooperative perception experiments. team -rotor mavs actively detects tracks person outdoor environment. demonstrate using mcdt method mavs able consistently track follow person jointly maintaining high quality position estimate person remaining oriented towards person iii) satisfying formation constraints. formation controller based previous works involves combination model predicted controller potential ﬁeld algorithm. next section situate work within state-of-theart. followed description system design theoretical details proposed mcdt approach characterization detection measurement errors sec. iii. section presents experiments results followed conclusions sec. motivated several applications graphics computer vision e.g. virtual reality sports analysis pose monitoring health purposes crowd management full body pose motion estimation attracted widespread research attention state-of-the-art research ﬁeld focused indoor scenarios e.g. however recent works started address challenges performing full body motion capture unstructured everyday environments even unknown outdoor scenarios authors body-ﬁxed sensors estimate full body pose. although achieve high degree accuracy setup cumbersome even infeasible certain subjects avoid this well body-ﬁxed markers alternative approach perform motion capture using multiple cameras. authors presented method extract skeletal motion multiple closely-interacting people using multiple cameras without using body-ﬁxed markers sensors. however solution assumes scenario cameras ﬁxed environment ambient light controlled. unknown outdoor environments assumptions hold. hence approach motion capture outdoor scenarios involves multiple cameras board ﬂeet mavs. paper address issue multirobot cooperative detection tracking involved developing outdoor motion capture system. cooperative perception-driven formation ensure tracked subject almost always mavs also prevent mavs colliding other. multirobot cooperative tracking researched extensively last years focus methods improve tracked target’s pose estimate fusing information obtained teammate robots recent methods e.g. simultaneously improve localization estimates poorly localized robots addition tracked target’s pose within uniﬁed framework. however hardly cooperative target tracking method directly facilitates detections cooperation among robots. paper sharing independently obtained measurements among robots regarding mutually observed object world. using shared measurements mcdt method allows detector focus relevant informative rois future detections. cooperative tracking targets using multiple mavs also attracted attention recent past address problem on-board visual detection tracking using mavs still rely hand-crafted visual features traditional detection approaches. moreover cooperation among multiple mavs using on-board vision-based detections well addressed. paper address issues using dnn-based person detector runs board mavs sharing detection measurements among mavs perform mcdt. deep cnn-based detectors currently require power gpus. mavs light-weight gpus embedded solutions critical requirements. rallapalli present overview feasibility deep neural networkbased detectors embedded mobile devices. also several recent works concern airborne applications gpu-accelerated neural networks computer vision tasks. however mostly evaluate performance ofﬂine scenarios without ﬂight capable implementation hand networks suitable real time detection localization arbitrary objects arbitrary poses backgrounds. include networks yolo faster r-cnn outperformed speed detection accuracy multibox approach hence work latter. furthermore ensure real-time operation using camera given resolution. achieve cooperative approach involving active selection informative method novel best knowledge. fig. overall architecture multi-mav system designed cooperatively detect track person maintaining perception-driven formation satisfying certain formation constraints. focus work presented paper novelties correspond green blocks ﬁgure. although architecture also depend centralized communication network ﬁeld implementation done central access point. runs instance following software modules. lowlevel ﬂight-controller module self-localization module cooperative detection tracking module mpc-based formation controller module. figure details data among modules. data shared mavs consists self-pose estimates detection measurements tracked person. aforementioned software modules board realtime. following sections introducing notations focus detailed description module. therein describe proposed mcdt approach enables formation track seemingly-small far-away persons high accuracy without losing mav’s tracking. mavs ...rn tracking person pose world frame time obtained using self-localization given system. uncertainty covariance matrix associated pose given on-board monocular perspective camera rigidly attached position velocity tracked person assume world frame time given person represented position velocity centroid euclidean space. uncertainty covariance matrix associated given algorithm recursive loop outlines approach. runs instance algorithm real time. algorithm based inputs person’s tracked position estimate previous time step covariance matrix associated estimate roirk also computed input image steps correspond iteration algorithm step alg. performs person detection using dnn-based detector roirk provided previous time step image current time step using detection measurements image detection measurement world frame computed mean zprk noise covariance matrix qprk detection performed latest available image uses gpu. resource busy processing previous images detection skipped. detection measurements image consist rectangular bounding boxes associated conﬁdence scores noise covariance matrix. obtain noise performed characterization dnn-based detector explained sec. iii-d. detection measurements transformed ﬁrst camera coordinates ﬁnally world coordinates. transformation incorporates noise covariances detection measurements mav’s self-pose’s uncertainty covariance. note measurements image plane ﬁnal detection measurements computed world frame. this make assumption height person tracked. assume person’s height follows distribution assume person standing walking upright world frame model adapted consider varying pose instance increasing finally overall transformation detections image frame world frame measurements also takes account. mathematical details regarding transformation include propagating noise/uncertainty covariances refer world frame. step performs prediction step ekf. exponentially decelerating state transition model. algorithm continuously receives measurements allowing continuous update steps predictions behave similar constant velocity model. however detections measurements stop arriving exponential decrease velocity allows tracked person’s estimate become stationary. important property approach calculated tracked person’s position estimate case detection measurements uncertainty person’s position estimate would continuously grow resulting larger roi. clariﬁed explanation steps steps alg. lies novelty approach. actively selects ensuring future detections performed informative part image i.e. person keeping computational complexity independent camera image resolution. computational complexity dnn-based detectors grows fast image resolution using approach still able dnn-based method real-time high detection accuracy. calculated follows. first using prediction model similar prediction estimates current time step predict state person next time step t+}. then step using predicted position person calculate position associated uncertainty person’s head ˆxph t+}. assume ˆσph height distribution model person introduced previously person upright position. ˆxph back-projected onto image frame along uncertainties denoted ˆxph ˆxpf center-top pixel given ˆσpf ˆypf y-axis components ˆxph respectively. standard deviations y-axis computed directly ˆσph respectively. lastly left right borders calculated match desired aspect ratio. chose aspect ratio corresponds majority training images optimal detection performance. step alg. performs bias update self-pose. self-pose estimates obtained using sensors often time-varying bias self-pose biases cause mismatches fusing detection measurements world frame detrimental mcdt approach calculated person detection biased often include person person’s position estimate result fusing biased measurements. truly beneﬁt mcdt approach track compensate bias mav’s localization system track biases using approach based difference mav’s detection measurements tracked estimate used update bias estimate. approach simpliﬁed form track position biases sufﬁcient bias orientation negligible. mcdt approach depends realistic noise model person detector. perform noise quantiﬁcation. dependent speciﬁc detector used describe procedure followed pretrained multibox detector used work. multibox detect presence location object classes image people included. output detector detection bounding class label conﬁdence score. input image size deﬁned training time. used pre-trained network work. quantify detection noise respect size detections i.e. smaller distant larger closer camera. created extended test pascal dataset varying levels downscaling upscaling detected person. figure details example. selected images single non-truncated person avoid detection association problem. statistical analysis using person detector extended test performed. test images different sizes calculate measures relative image size. figure shows detection accuracy using jaccard index relative person height. evident even though detection accuracy given minimum conﬁdence threshold nearly constant w.r.t. analyzed absolute error decreases smaller roi. chance successful detection falls signiﬁcantly relative sizes goes zero thus forming upper boundary desired size. analysis clearly justiﬁes necessity mcdt approach active selection rois. analysis presented figure show relative error detected person’s position test images. error shown well described gaussian distribution. performed similar analysis errors detection bottom left rightpoints detection bounding different relative sizes. found noises similarly well described gaussian distributions without signiﬁcant correlations them. thus person detection noise well approximated constant variance model. evaluate approach conducted real robot experiments team -rotor mavs tracking person. equipped camera computer nvidia jetson embedded gpu. magnetic compass used self pose estimates ﬂight control. multi-master setup wiﬁ. continuously reads images camera runs ssd-multibox described sec. rois images down-sampled sent gpu. detection frame rate achieved .hz. detections persons projected shared mavs fused using kalman filter mav. self-pose estimates bias corrected based mismatches perceived fused position person within kalman filter. mavs formation using based controller formation constraints include maintaining preset distance tracked person’s position estimate preset altitude ground plane iii) orientation towards tracked person. inter-robot collision avoidance additional layer artiﬁcial potential-ﬁeld based avoidance algorithm mpc. state estimates sensor data updated achieved video frame rate resolution rgb. note experiments tracked person wearing orange helmet safety. helmet used detection. contrary dnn-based detector optimized persons helmets. using proposed approach mcdt on-board real-time computation ﬂights mavs perform estimation self-pose position tracked person. treat primary dataset refer ‘online dataset’ analysis section. experiment also record sensor camera data. using these generate additional ‘ofﬂine datasets’ disabling selected aspects mcdt approach. allows evaluate contribution component approach overall performance. following ofﬂine datasets generated. formation constraints mavs dper hmav person remains stationary absolute ground truth measurements person’s position. since person remains stationary instead calculate reference point mean position estimates dataset error position estimate calculated distance reference point. signiﬁcant overall effect person’s position estimate accuracy. occasional situations using bias-corrected self-pose produces slightly better results using however outweighed risk losing person partially completely zoomed wrong location disabling active selection leads roughly comparable tracking accuracy online estimates long person still successfully detected. however higher chances detection failure evident moving person experiment’s results consequently degrades overall performance results noticeably higher mean squared error. formation constraints mavs dper hmav since ground truth positions person time person walks along predeﬁned trajectory square edge length aligned towards true north. person keeps walking outline square considering known trajectory constraint horizontal north aligned reference square dataset error pose estimate calculated distance closest point reference square. fitting reference square done mean squared error pose estimates dataset minimized. table show results moving person experiment. similar stationary experiment self-pose bias correction occasionally introduces additional errors overall leads better performance. beneﬁt actively selecting cornerstone mcdt method signiﬁcant dynamic situation moving person active formation following stationary person experiment. reﬂected mean squared errors calculated whole experiment. similar stationary person experiment cooperative perception mavs outperforms single case factor mean squared error person’s position estimate. video attached paper illustrates work presented highlights clip footage moving person experiment bird’s view. high resolution version attached video found here. detailed video showing experimental setup full stationary moving person experiments well image streams cameras overlaid detections estimates found here. source code related work found project page here. paper presented novel method realtime continuous accurate dnn-based multi-robot cooperative detection tracking. leveraging cooperation robots team method able harness power deep convolutional neural network-based detectors realtime applications. real robot experiments involving on-board computation comparisons baseline approaches demonstrated effectiveness proposed method. also showed feasibility realtime person detection tracking high accuracy team mavs maintain perception-driven formation. additionally also performed noise quantiﬁcation dnn-based detector allowed within bayesian ﬁlter person tracking. work paper paves future goal performing full-body pose capture outdoor unstructured scenarios. developing perception-driven formation controller attempts minimize joint position uncertainty realtime also considers full-body pose reconstruction errors learned ofﬂine. future goals also include tracking animals developing heterogeneous team mavs different sensing maneuvering capabilities. andriluka schnitzspan meyer kohlbrecher petersen stryk roth schiele vision based victim detection unmanned aerial vehicles ieee/rsj international conference intelligent robots systems santos barnes ritoper nishizaki tejeda schurgers kastner small unmanned aerial vehicle system wildlife radio collar tracking ieee international conference mobile sensor systems http//aircap.is.tuebingen.mpg.de/icra/video/ http//aircap.is.tuebingen.mpg.de/icra/video_detailed/ http//aircap.is.tuebingen.mpg.de/ http//aircap.is.tuebingen.mpg.de/icra/code/ lima ahmad dias conceic¸˜ao moreira silva almeida oliveira nascimento formation control driven cooperative object tracking robotics autonomous systems vol. andriluka pishchulin gehler schiele human pose estimation benchmark state analysis proceedings ieee conf. computer vision pattern recognition ieee june bogo black loper romero detailed full-body reconstructions moving people monocular rgb-d sequences international conference computer vision dec. vlasic adelsberger vannucci barnwell gross matusik popovi´c practical motion capture everyday surroundings trans. graph. vol. july available http//doi.acm.org/./. marcard rosenhahn black pons-moll sparse inertial poser automatic human pose estimation sparse imus computer graphics forum proceedings annual conference european association computer graphics gall stoll h.-p. seidel theobalt markerless motion capture multiple characters using multi-view image segmentation transactions pattern analysis machine intelligence vol. zheng-jie solution cooperative area coverage surveillance swarm mavs international journal advanced robotic systems vol. available https//doi.org/./ oliveira wehrmeister towards real-time people recognition aerial imagery using convolutional neural networks real-time distributed computing ieee international symposium zhang deep convolutional neural networks forest detection international forum management education information technology application. atlantis press", "year": "2018"}