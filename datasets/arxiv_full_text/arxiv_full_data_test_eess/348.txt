{"title": "Identifying Corresponding Patches in SAR and Optical Images with a  Pseudo-Siamese CNN", "tag": "eess", "abstract": " In this letter, we propose a pseudo-siamese convolutional neural network (CNN) architecture that enables to solve the task of identifying corresponding patches in very-high-resolution (VHR) optical and synthetic aperture radar (SAR) remote sensing imagery. Using eight convolutional layers each in two parallel network streams, a fully connected layer for the fusion of the features learned in each stream, and a loss function based on binary cross-entropy, we achieve a one-hot indication if two patches correspond or not. The network is trained and tested on an automatically generated dataset that is based on a deterministic alignment of SAR and optical imagery via previously reconstructed and subsequently co-registered 3D point clouds. The satellite images, from which the patches comprising our dataset are extracted, show a complex urban scene containing many elevated objects (i.e. buildings), thus providing one of the most difficult experimental environments. The achieved results show that the network is able to predict corresponding patches with high accuracy, thus indicating great potential for further development towards a generalized multi-sensor key-point matching procedure. Index Terms-synthetic aperture radar (SAR), optical imagery, data fusion, deep learning, convolutional neural networks (CNN), image matching, deep matching ", "text": "follows range-based imaging geometry optical imagery reﬂects chemical characteristics scene follows perspective imaging geometry. hence structures elevated ground level buildings trees show strongly different appearances optical images particular dealing high resolution data. order deal problem multi-sensor keypoint matching several sophisticated approaches proposed e.g. exploiting phase congruency generalization gradient information however even sophisticated handcrafted descriptors reach limitations highly resolving data showing densely built-up urban scenes case often difﬁcult interpret even trained experts. therefore work aims learning multi-sensor correspondence predictor optical image patches state-of-the-art data. inspired promising results achieved context stereo matching optical imagery also make convolutional neural network major difference work purely optical approaches focus aforementioned distinctly complicated multi-sensor setup therefore design speciﬁc pseudo-siamese network architecture separate identical convolutional streams processing optical patches parallel instead weight-shared siamese network order deal heterogeneous nature input imagery. abstract—this pre-print version read ﬁnal version please ieee geoscience remote sensing letters ieee xplore. letter propose pseudo-siamese convolutional neural network architecture enables solve task identifying corresponding patches very-high-resolution optical synthetic aperture radar remote sensing imagery. using eight convolutional layers parallel network streams fully connected layer fusion features learned stream loss function based binary cross-entropy achieve one-hot indication patches correspond not. network trained tested automatically generated dataset based deterministic alignment optical imagery previously reconstructed subsequently co-registered point clouds. satellite images patches comprising dataset extracted show complex urban scene containing many elevated objects thus providing difﬁcult experimental environments. achieved results show network able predict corresponding patches high accuracy thus indicating great potential development towards generalized multi-sensor key-point matching procedure. used extensively computer vision remote sensingrelated image analysis especially framework stereo applications co-registration issues. many successful hand-crafted approaches speciﬁcally designed matching optical images exist date matching images acquired different sensors still remains widely unsolved challenge particularly holds joint exploitation optical imagery caused completely different sensing modalities imagery collects information physical properties scene work supported china scholarship council european research council european unions horizon research innovation programme helmholtz association framework young investigators group sipeo german research foundation grant schm designed matching optical patches. neither suitable conventional siamese architectures designed share weights layer input data processed feature extraction streams share similar properties. order cope strongly different geometric radiometric appearances optical imagery proposed pseudo-siamese network architecture separate identical convolutional streams process patch optical patch parallel fuse resulting information later decision stage. using architecture network constrained ﬁrst learn meaningful representations input patch optical patch separately combine higher level. work presented letter extension improving fusion part network architecture using different training strategy resorting non-locally preﬁltered patches instead temporal mean maps. addition evaluate network deterministically partitioned dataset instead randomly partitioned random partitioning always cause positively biased results overlapping regions patches. architecture proposed network shown fig. mainly inspired philosophy well-known nets optical image patches passed stack convolutional layers make convolutional ﬁlters small receptive ﬁeld rather using larger ones reason convolutional ﬁlters smallest kernels capture patterns different directions center up/down left/right still advantage small convolutional ﬁlters increase nonlinearities inside network thus make network discriminative convolution stride network ﬁxed pixel; spatial padding convolutional layer input spatial resolution preserved convolution i.e. padding pixel convolutional layers network. spatial pooling achieved carrying seven max-pooling layers follow convolutional layers. used reduce dimensionality feature maps. max-pooling performed pixel fusion stage proposed network made consecutive convolutional layers followed fully connected layers. convolutional layers consist ﬁlters operate concatenated feature maps optical streams order learn fusion rule minimizes ﬁnal loss function. max-pooling omitted ﬁrst convolutional layer fusion stage stride used order downsample feature maps preserving spatial information ﬁlters absence max-pooling ﬁrst convolution allows fusion layer learn fusion rule somewhat invariant spatial mismatches caused difference imaging modalities. fact fusion layer uses convolutions learn relationships features preserving nearby spatial information. lack pooling means learned spatial relationships preserved maximal response considered stride used reduce feature size. ﬁnal stage fusion network consists fully connected layers ﬁrst contains channels; second performs one-hot binary classiﬁcation contains channels. nutshell convolutional layers network apart fusion layer generally consist ﬁlters follow rules layers feature size number ﬁlters; number feature maps increases deeper layers roughly doubling max-pooling layer layers network equipped rectiﬁed linear unit activation function except last fully connected layer activated softmax function. figure shows schematic diagram conﬁguration network. figure depicts full conﬁguration network. apart previously discussed architecture also make batch normalization activation function convolutional layer. leads increase training speed reduces effects internal covariate shift. order reduce over-ﬁtting training made l-regularization convolution kernels optical streams dropout rate ﬁrst fully connected layer. training testing purposes large pool corresponding non-corresponding optical image patches needed. classical work deep matching optical imagery usually rely easy-to-achieve optical patch pools annotating corresponding patches optical imagery complex urban scenes highly nontrivial task even experienced human experts. thus contributions letter introduction fully automatic procedure sar-optical patch pool generation. order solve challenge automatic dataset generation resort so-called sarptical framework wang object-space-based matching procedure developed mapping textures optical images onto point clouds derived tomography. core algorithm match optical images space order deal inevitable differences caused different geometrical distortions. usually would require accurate digital surface model area link homologue image parts known object space. contrast approach creates separate point clouds tomography optical stereo matching registered space form joint point cloud serves necessary representation object space. ﬂowchart approach seen fig. order estimate positions individual pixels images algorithm requires interferometric stack images well least pair optical stereo images. matching point clouds guarantees matching optical images. finally project image geometry optical image sarptical point cloud vice versa. work presented letter made stack terrasar-x high resolution spotlight images city berlin acquired meter resolution ultracam optical images area ground spacing. reconstruction sarptical point cloud pixels high uniformly sampled non-locally ﬁltered master amplitude image projected individual optical images yielding total corresponding optical pixels. reason difference pixel numbers optical multi-view stereo images acquired different viewing angle making possible image pixel corresponding optical image pixels. actual number corresponding optical pixels dependent visibility pixel respective optical point view. patches centered corresponding image pixels. size ﬁxed pixels pixel spacing analogy optical patches centered corresponding optical pixels. resampling adjust pixel spacing patches rotated patches align ﬁrst approximation. order reduce bias training network randomly selected single correct optical correspondence image patch ﬁnal dataset preparation. addition randomly assign wrong optical correspondence patch order create negative examples. thus eventually sar-optical patch pairs order provide fair experimental design partition patch pool following manner patch-pairs used training dataset validation test dataset. noted partition patch pool purely randomized basis rather resort deterministic partitioning method order avoid positively biased test results. full extent optical images ﬁrst deterministically partitioned partition processed generate positive negative samples training validation testing respectively. network trained using adam optimization algorithm computationally efﬁcient exhibits faster convergence standard stochastic gradient descent methods. optimization hyper-parameters ﬁxed learning rate learning rate found grid search method training validation data β−parameters kept recommended values. prior training network weight vectors initialized using truncated uniform distribution described bias vectors initialized zero values. training conducted nvidia titanx gpus using class balanced mini-batches sar-optical patch pairs epochs; training took average minutes single forward pass taking around complete. trained versions proposed network different patch size order evaluate effect patch size classiﬁcation accuracy. patch cropping done onthe-ﬂy patch cropped center larger patch done center pixel point correspondence optical patch. furthermore seeded random number generator ﬁxed value start training patch size order prevent randomization effects networks. evaluate proposed network different input patch sizes using testing patch pool cropped around center pixel produce testing pools different patch sizes. accuracy false positive rate curves corresponding different patch sizes seen fig. table reports corresponding confusion matrix values proposed network evaluated patch size; noted confusion matrix reﬂective network point highest overall performance patch size. order evaluate proposed network’s performance real-world key-point matching scenario selected neighboring tomosar key-points image extracted corresponding optical patch pairs. selected key-points localized area within test reproduce conditions found real-world key-point matching application. compared every optical patch selected patch order determine fig. matrix depicting similarity scores various pair comparisons corresponding optical patches given index number. noted determining binary value correspondence threshold applied similarity scores. figure depicts sorted scores non-similar optical patches making easier number strength incorrect matches patch pool. fig. results key-point matching experiment. confusion matrix showing matching scores optical key-point patches. depicts spread incorrect matches ordered similarity score. generally results summarized section iv-b indicate promising discriminative power proposed network. however following major points must considered interpreting results. acquired range-based imaging geometry. thus patches cropped smaller regions likely crop deﬁning features used matching optical domain. intuitively understood referring fig. effects layover multi-path reﬂections building image near view building optical image. taking away explanatory context thus render matching difﬁcult. discussion reference results obtained using largest patch size pixels. summary approach obtains accuracy exceeding separate test dataset ﬁxing false positive rate falls order magnitude achieved using powerful handcrafted hopc descriptor combination l-norm cost function furthermore approach produced clear diagonal pattern fig. depicts ability accurately determine correct correspondence key-point matching scenario. upon investigation found network achieved top- matching accuracy top- accuracy points valid matches detected within key-point set. found large amounts layover extreme differences view point optical patches fig. false negatives. randomly chosen prediction examples displayed fig. observed many false positives false negatives erroneously matched extreme differences viewing angle optical patches. partially solvable resorting larger patch sizes providing valuable context might need exclude image parts strong distortions processing. ﬁrst evaluation shown promising potential respect multi-sensor key-point matching procedures. order ensure transferability applications based keypoints e.g. dense matching work generation additional training patches whose center pixel rely speciﬁc key-points. addition test approach data coming completely different sources. expect work help paving generalized sar-optical image matching procedures. wang zeisl pollefeys fusing meter-resolution insar point clouds optical images semantic urban infrastructure monitoring ieee trans. geosci. remote sens. vol.", "year": "2018"}