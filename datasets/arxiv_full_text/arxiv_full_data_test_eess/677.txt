{"title": "Nonlocality-Reinforced Convolutional Neural Networks for Image Denoising", "tag": "eess", "abstract": " We introduce a paradigm for nonlocal sparsity reinforced deep convolutional neural network denoising. It is a combination of a local multiscale denoising by a convolutional neural network (CNN) based denoiser and a nonlocal denoising based on a nonlocal filter (NLF) exploiting the mutual similarities between groups of patches. CNN models are leveraged with noise levels that progressively decrease at every iteration of our framework, while their output is regularized by a nonlocal prior implicit within the NLF. Unlike complicated neural networks that embed the nonlocality prior within the layers of the network, our framework is modular, it uses standard pre-trained CNNs together with standard nonlocal filters. An instance of the proposed framework, called NN3D, is evaluated over large grayscale image datasets showing state-of-the-art performance. ", "text": "fig. flowchart generic k-th iteration proposed framework. noisy image combined previous estimate ˆyk− clean image convex combination ˆyk−. first ﬁltered convolutional neural network ﬁlter cnnf output processed nonlocal ﬁlter whose output constitutes estimate ˆyk. method iterates drawback nlfs partly overcome external dictionaries multi-scale well multi-stage iterative approaches improve denoising quality reﬁning matching mutually similar blocks shrinkage. advantages cnnfs ability learn extract complex image features efﬁcient implementation graphics processing units drawbacks cnnfs learning time consuming hours days inferior performance regular textures high self-similarity. attempts overcome abovementioned drawbacks cnnfs. particular extends dncnn feature-space deep residual learning input image represented four subbands onelevel haar wavelet decomposition serve input dncnn. despite improved performance partial overcome drawback method still inferior recent nlfs especially regarding texture recent publications consider mixture nlfs cnns improve performance images containing self-similar patches. deep architecture combines explicit patch grouping learned potential function regularization operator. so-called block matching convolutional neural network method similar using groups similar patches inputs denoising cnn. structure approach resembles replaces wiener ﬁltering stage similar dncnn. abstract—we introduce paradigm nonlocal sparsity reinforced deep convolutional neural network denoising. combination local multiscale denoising convolutional neural network based denoiser nonlocal denoising based nonlocal ﬁlter exploiting mutual similarities groups patches. models leveraged noise levels progressively decrease every iteration framework output regularized nonlocal prior implicit within nlf. unlike complicated neural networks embed nonlocality prior within layers network framework modular uses standard pre-trained cnns together standard nonlocal ﬁlters. instance proposed framework called evaluated large grayscale image datasets showing state-of-the-art performance. index terms—image denoising convolutional neural network image processing computer vision aims estimating unknown image noisy observation. image denoising plays crucial role various stages image processing used replacement explicit image priors pre-processing enhance output quality performance subsequent image-processing computer-vision tasks demosaicing sharpening compression object segmentation classiﬁcation recognition post-processing suppress compression artifacts blocking ringing plug&play ﬁlter i.e. implicit regularization prior used various inverse-imaging applications end-to-end optimized computational imaging systems recently image denoising received boost interest application advanced machine-learning methods particularly deep convolutional neural networks current effective image denoising methods roughly categorized nonlocal ﬁlters block matching wnnm cnn-based ﬁlters dncnn respective advantages drawbacks advantages nlfs joint collaborative processing mutually similar image patches resulting superior noise removal image exhibits strong self-similarity edges regular texture. work supported academy finland european union’s framework programme grant agreement macsenet. authors tampere university technology finland noiseless imaging finland. e-mail cristovaonoiselessimaging.com advantages cnnf simple iterative modular framework unlike involve architectures leverage nonlocality plug-in approach uses generic generic cnnf without need retraining. furthermore present instance proposed framework called enables nonlocal self-similarity prior means group-wise ﬁltering. experiments carried several image datasets demonstrate nnd’s ability exceed results obtained respective cnnf components achieve state-of-the-art results image denoising. proposed framework summarized ﬂowchart fig. detailed algorithm noisy image iteratively ﬁltered cascaded cnnf awgn removal enforcing nonlocal self-similarity. rationale proposed iterative approach explained follows. cnnf biased learned mapping local features biased towards nonlocal self-similarity. operating high noise levels local nature coupled training external examples often leads hallucination i.e. introduction patterns exist original signal circumstances becomes especially important smooth hallucinations fail meet self-similarity prior show sect. hand attenuate severe localized artifacts hand might also introduce excessive spatial smoothing. proposed framework counteracts unwanted smoothing proceeding iteratively. speciﬁcally iteration input ﬁlter cascade convex combination λkz+ˆyk− original input previous estimate ˆyk−. hence fraction noise attenuated cnnf thus requires weaker regularization i.e. smaller step parameter controls rate progress iterative procedure. thus positive monotonically decreasing undeﬁned. introduce instance general framework. call cascaded neural network collaborative ﬁlter enforces nonlocal self-similarity prior following distinct phases block matching identify groups similar patches ﬁltering shrink spectra groups extracted ˜yk. block matching executed once ﬁltering executed every iteration. process groups similar blocks identiﬁed crucial step many nlfs noise negatively impacts therefore estimate particular convenience output cnnf result look-up table group coordinates sn}. contains coordinates mutually similar blocks size n×n; built pixel image covered least block. nonlocal self-similarity enforced group-wise processing based look-up table speciﬁcally iteration group array size n×n×n formed stacking blocks extracted coordinates speciﬁed could ﬁltered d-transform domain shrinkage cnnf already operated spatial smoothing therefore perform shrinkage along third dimension group respect transform length ﬁltered group threshold controls regularization strength respect nonlocal similarity; value depends magnitude deformations introduced cnnf well overall ﬁltering attenuates localised deformations fail meet self-similarity constraint. image estimate obtained returning block estimates ﬁltered group original locations aggregated group-wise weights reciprocal energy shrinkage factor noisy noiseless coefﬁcient zero-mean noise variance thus overall procedure similar wiener ﬁlter similarity domain uses pilot noisy coefﬁcient shrunk. evaluated several datasets ’set’ ’bsd’ ’urban’ chosen three state-of-the-art cnnf awgn removal dncnn wdncnn ffdnet comparison cnnf module used without modiﬁcation re-training. experiments implementation uses haar wavelet transform. cnnf able operate different noise levels. however cnnfs entail models trained speciﬁc noise standard deviation values σm}. three cnnfs analysis ffdnet trained noise arbitrary strength whereas trained speciﬁc noise levels dncnn wdncnn. thus ﬁlter upon scaling factor selected standard deviation i.e. αkλkσ matches standard-deviation levels trained for. practice deviate much otherwise dynamic range training images even exceed range adopted processing negatively impacting performance overall scheme. hence σ−ςk max{{ς λkσ} line algorithm becomes table reports peak signal noise ratio results evaluated methods. stronger noise noticeably outperforms state-of-the-art methods. maximal gain adopted cnnf modules achieved images strong self-similarity ’urban’. fig. outperforms wdncnn ’barbara’ wdncnn outperforms ’house’ ’starﬁsh’. however three instances approach outperforms wdncnn numerically visually. ’starﬁsh’ able produce sharper results wdncnn showing proposed ﬁlter cascade able signiﬁcantly exceed building blocks. results table also better obtained proposals combining nonlocal processing cnns reported processing ’bsd’ value tested combinations. processing ’house’ ’barbara’ results respectively values also signiﬁcantly best results reported fig. mentioned section iii-a effectiveness seriously compromised applied noisy image; particular applied directly instead average psnr loss experiments reported table ranges approximately nonetheless proposed framework generic enough performed estimate provided another ﬁlter. instance observed results obtained performing estimate provided equivalent ones presented section visually quantitatively experiments conducted computer running ubuntu equipped ryzen threadripper asus geforce turbo gpu. processing image observed following average execution times single call module. running single threaded running dncnn ffdnet wdncnn complete execution requires execution following modules cnnf cnnf nlf. code used experiments downloaded http //www.cs.tut.ﬁ/sgn/imaging/nnd. even though receptive ﬁelds analyzed cnns principle large enough capture nonlocal self-similarity distribution impact follows gaussian distribution meaning effective receptive ﬁeld type deep cnns signiﬁcantly narrower pixels center ﬁeld contribute much towards periphery. furthermore effective receptive ﬁeld grows square root depth network. factor alone explains networks strongly biased towards local features inclusion nonlocal element results dramatic performance improvement. cnnf especially dealing higher noise variance. type artifacts violate self-similarity prior therefore attenuated nlf. overall proposed approach yields cleaner images much sharper reconstruction details. finally zontak mosseri irani separating signal noise using patch recurrence across scales proceedings ieee conference computer vision pattern recognition urtasun zemel understanding effective receptive ﬁeld deep convolutional neural networks advances neural information processing systems sugiyama luxburg guyon garnett eds. curran associates inc. katkovnik egiazarian pointwise shape-adaptive high-quality denoising deblocking grayscale color images ieee transactions image processing vol. chan wang elgendy plug-and-play admm image restoration fixed-point convergence applications ieee transactions computational imaging vol. march heide steinberger y.-t. tsai rouf reddy gallo heidrich egiazarian kautz pulli flexisp ﬂexible camera image processing framework trans. graph. vol. nov. available http//doi.acm.org/./. zhang zhang learning deep denoiser prior image restoration ieee conference computer vision pattern recognition july katkovnik egiazarian astola from local kernel nonlocal multiple-model image denoising international journal computer vision vol. available https//doi.org/./s--- meng feng zhang weighted nuclear norm minimization applications level vision international journal computer vision vol. available https//doi.org/./ s--- chen pock trainable nonlinear reaction diffusion ﬂexible framework fast effective image restoration ieee transactions pattern analysis machine intelligence vol. june", "year": "2018"}