{"title": "Sentiment Analysis on Speaker Specific Speech Data", "tag": "eess", "abstract": " Sentiment analysis has evolved over past few decades, most of the work in it revolved around textual sentiment analysis with text mining techniques. But audio sentiment analysis is still in a nascent stage in the research community. In this proposed research, we perform sentiment analysis on speaker discriminated speech transcripts to detect the emotions of the individual speakers involved in the conversation. We analyzed different techniques to perform speaker discrimination and sentiment analysis to find efficient algorithms to perform this task. ", "text": "abstract— sentiment analysis evolved past decades work revolved around textual sentiment analysis text mining techniques. audio sentiment analysis still nascent stage research community. proposed research perform sentiment analysis speaker discriminated speech transcripts detect emotions individual speakers involved conversation. analyzed different techniques perform speaker discrimination sentiment analysis find efficient algorithms perform task. sentiment analysis study people’s emotion attitude towards event conversation topics general. sentiment analysis used various applications comprehend mindset humans based conversations other. machine understand mindset/mood humans conversation needs know interacting conversation spoken implement speaker speech recognition system first perform sentiment analysis data extracted prior processes. understanding mood humans useful many instances. example computers possess ability perceive respond human non-lexical communication emotions. case detecting humans’ emotions machine could customize settings according his/her needs preferences. research community worked transforming audio materials songs debates news political arguments text. community also worked audio analysis investigation study customer service phone conversations conversations involved speaker. since speaker involved conversation becomes clumsy analysis audio recordings paper propose system would aware speaker identity perform audio analysis individual speakers report emotion. recognition. speech recognition tools transcribe audio recordings proposed speaker discrimination method based certain hypothesis identify speakers involved conversation. further sentiment analysis performed speaker specific speech data enables machine understand humans talking feel. section-ii discusses theory behind speaker speech recognition sentiment analysis discussed. section-iii contains explanation proposed system. section-iv contains details experimental setup section-v presents result obtained detailed analysis. work concluded section-vi. sentiment analysis shortly referred identifies sentiment expressed text analyses find whether document expresses positive negative sentiment. majority work sentiment analysis focused methods naive bayesian decision tree support vector machine maximum entropy work done mostafa sentences document labelled subjective objective classical machine learning techniques applied subjective parts. polarity classifier ignores irrelevant misleading terms. since collecting labelling data time consuming sentence level approach easy test. perform sentiment analysis used following methods naive bayes linear support vector machines vader comparison made find efficient algorithm purpose. feature matching dynamic time wrapping— stan salvador describes algorithm dynamic programming techniques. algorithm measures similarity time series varies speed time. technique also used find optimal alignment times series time series warped non-linearly stretching shrinking along time axis. warping time series used find corresponding regions time series determine similarity time series. principle compare dynamic patterns measure similarity calculating minimum distance them. time series wrapped various distance/similarity computation methods euclidean distance canberra distance correlation used. comparison methods shown results section. paper propose model sentiment analysis utilizes features extracted speech signal detect emotions speakers involved conversation. process involves four steps pre-processing includes speech recognition system speaker recognition system sentiment analysis system. input signal passed voice activity detection system identifies segregates voices signal. voices stored chunks database chunks passed speech recognition speaker discrimination system recognizing content speaker speaker recognition system tags chunks speaker noted system works unsupervised fashion i.e. would find weather chunks speaker different ‘speaker ‘speaker speech recognition system transcribes chunks text. system matches speaker transcribed text. stored dialogue database. text output speech recognition system specific individual speaker serves potential feature estimate sentiment emphasized speech recognition ability given machine program identify words phrases language spoken humans convert machine-readable format used processing. paper used speech recognition tools sphinx bing speech google speech recognition. comparison made best suite proposed model chosen. speaker recognition identifying human based variations unique characteristics voice referred speaker recognition. acquired attention research community almost eight decades speech signal contains several features extract linguistic emotional speaker specific information speaker recognition harnesses speaker specific features speech signal. paper frequency cepstrum coefficient used designing speaker discriminant system. mfcc’s speech samples various speakers extracted compared find similarities speech samples. feature extraction extraction unique speaker discriminant feature important achieve better accuracy rate. accuracy phase important next phase acts input next phase. fcc— humans perceive audio nonlinear scale mfcc tries replicate human mathematical model. actual acoustic frequencies mapped frequencies typically range khz. scale linear logarithmic khz. mfcc constants signifies energy associated unique every speaker. uniqueness enables identify speakers based voice proposed system uses speech speaker recognition sentiment analysis. presented detailed analysis experiments performed various tools algorithms. tools used speech recognition sphinx bing speech google speech api. performance metric used wwr. speaker recognition used mfcc feature various distance computation methods euclidean correlation canberra feature matching. recognition rate used performance metric. sentiment analysis standard sentiment analysis datasets viz. twitter dataset product review dataset used commute accuracy system. first audio files dataset converted text files different speech recognition tools. table shows obtained various scripts spoken different speakers. refers male speaker similarly refers female speaker given percentage values. able tabulates obtained using google speech transcribe speech signals. dataset used i.e. scripts persons used compare results. done validate tools equal basis. dataset dataset comprises audio files recorded controlled environment three different scripts used conversation peoples. seven speakers totally involved recordings males females. conversations prelabelled depending upon scenario. audio sampled recorded mono tracks average seconds. work presents generalized model takes audio contains conversation people input studies content speakers’ identity automatically converting audio text performing speaker recognition. research proposed simple system above-mentioned task. system works well artificially generated dataset working collecting larger dataset increasing scalability system. though system accurate comprehending sentiment speakers conversational dialogue suffers flaws right system handle conversation speakers conversation speaker talk given time cannot understand people talk simultaneously. future work would address issues improve accuracy scalability system. pang sentimental education sentiment analysis using subjectivity summarization based minimum cuts. proceedings annual meeting association computational linguistics association computational linguistics. pang seeing stars exploiting class relationships sentiment categorization respect rating scales. proceedings annual meeting association computational linguistics association computational linguistics. pang vaithyanathan thumbs sentiment classification using machine learning techniques. proceedings acl- conference empirical methods natural language processing-volume association computational linguistics. shaikh prendinger mitsuru assessing sentiment text semantic dependency contextual valence analysis. affective computing intelligent interaction accuracy speaker identification respective number features illustrated figure number features varied dynamic time wrapping used feature mapping technique research. various distance commutation methods euclidean canberra compared. accuracy number features graph shown graph. noted system highly accurate used features hence took features process system salvador chan fastdtw toward accurate dynamic time warping linear time space. wkshp. mining temporal sequential data kdd'. seattle washington herbig gerl minker fast adaptation speech speaker characteristics enhanced speech recognition adverse intelligent environments. intelligent environments sixth international conference ieee. kinnunen overview text-independent speaker recognition features supervectors. speech communication ezzat gayar ghanem sentiment analysis call centre audio conversations using text classification. int. comput. inf. syst. ind. manag. appl", "year": "2018"}