{"title": "Building state-of-the-art distant speech recognition using the CHiME-4  challenge with a setup of speech enhancement baseline", "tag": "eess", "abstract": " This paper describes a new baseline system for automatic speech recognition (ASR) in the CHiME-4 challenge to promote the development of noisy ASR in speech processing communities by providing 1) state-of-the-art system with a simplified single system comparable to the complicated top systems in the challenge, 2) publicly available and reproducible recipe through the main repository in the Kaldi speech recognition toolkit. The proposed system adopts generalized eigenvalue beamforming with bidirectional long short-term memory (LSTM) mask estimation. We also propose to use a time delay neural network (TDNN) based on the lattice-free version of the maximum mutual information (LF-MMI) trained with augmented all six microphones plus the enhanced data after beamforming. Finally, we use a LSTM language model for lattice and n-best re-scoring. The final system achieved 2.74\\% WER for the real test set in the 6-channel track, which corresponds to the 2nd place in the challenge. In addition, the proposed baseline recipe includes four different speech enhancement measures, short-time objective intelligibility measure (STOI), extended STOI (eSTOI), perceptual evaluation of speech quality (PESQ) and speech distortion ratio (SDR) for the simulation test set. Thus, the recipe also provides an experimental platform for speech enhancement studies with these performance measures. ", "text": "propose single system push border challenge. important system reproducible since implemented kaldi toolkit opensource toolkits. scripts experiments downloaded ofﬁcial github website. original chime- baseline described uses delayand-sum beamformer deep neural network state-level minimum bayes risk criterion recurrent neural network-based language model contrary proposed system shown figure adopt bidirectional long short-term memory mask based beamformer shown effective beamformit. acoustic model used baseline limited represent long-term dependencies acoustic characteristics. hence sub-sampled time delay neural network lattice-free version maximum mutual information used acoustic model paper also shows great improvement word error rate combine data augmentation multichannel scenario using microphones plus enhanced data beamforming. then lstm language model uses training criterion importance sampling shown efﬁcient better performance re-score hypotheses. also incorporate computation four different speech enhancement measures recipe perceptual evaluation speech quality short-time objective intelligibility measure extended stoi speech distortion ratio include measurements part recipe reasons. first performance shows aspect speech enhancement algorithm. objective enhancement metrics give indication well enhancement different aspects second testing enhancement algorithm takes signiﬁcant amount computational time whereas obtaining scores quite fast. hence give initial indication good enhancement fusion system posterior domain proposed best result competition. also fusion systems decoding hypothesis domain multiple systems mainly using different front-end techniques. unlike highly complicated systems proposed system based single system without fusion systems achieves comparable performance systems challenge task. unique technical aspects proposed system fully utilize effectiveness tdnn paper describes baseline system automatic speech recognition chime- challenge promote development noisy speech processing communities providing state-of-the-art system simpliﬁed single system comparable complicated systems challenge publicly available reproducible recipe main repository kaldi speech recognition toolkit. proposed system adopts generalized eigenvalue beamforming bidirectional long short-term memory mask estimation. also propose time delay neural network based lattice-free version maximum mutual information trained augmented microphones plus enhanced data beamforming. finally lstm language model lattice n-best re-scoring. ﬁnal system achieved real test -channel track corresponds place challenge. addition proposed baseline recipe includes four different speech enhancement measures short-time objective intelligibility measure extended stoi perceptual evaluation speech quality speech distortion ratio simulation test set. thus recipe also provides experimental platform speech enhancement studies performance measures. index terms speech recognition noise robustness maskbased beamforming lattice-free lstm language modeling recent years multi-channel speech recognition applied devices used daily life amazon echo google home. recognition accuracy greatly improved exploiting microphone arrays compared single channel microphone devices however satisfactory performance still achieved noisy everyday environments. hence chime- challenge designed conquer scenario recognizing speech challenging noisy environments series challenge activities several speech enhancement recognition techniques established effective method scenario including mask-based beamforming multichannel data augmentation system combination various front-end techniques although many submitted systems chime- challenge yielded outcomes multi-channel automatic speech recognition scenario drawbacks systems highly complicated multiple systems fusion techniques easy research groups follow outcomes. paper aims deal drawback building baseline promote development noisy speech enhancement separation recognition communities. acoustic model tdnn lf-mmi training instead dnn+smbr architecture similar described lf-mmi objective function shown below different usual training sense phoneme sequence instead word sequence narrow search space denominator lstm based language model shown effective language modeling better ﬁnding longer period contextual information conventional rnn. property lstmlm predict next word accurate rnnlm. hence instead using vanilla rnnlm train lstmlm data combines subword features one-hot encoding. importance sampling method used speed training. important objective function used training behaves like cross-entropy objective trains output auto-normalize order speed test time computation system starts blstm mask based beamformer followed feature extraction. phoneme audio alignments generated acoustic model tdnn acoustic model training. finally lattices ﬁrst pass decoding tdnn re-scored -gram re-scored lstmlm. training multichannel data shown effective systems augmentation increase variety training data help generalization test set. work data channels also enhanced data generated beamformer training set. rd|t sequence d-dimensional feature vectors length single channel speech recognition case. case deal m-channel input represented rd|t then original training method uses particular channel input training data obtain acoustic model parameters follows blstm mask based generalized eigenvalue beamformer described beamforming procedure requires estimate cross-power spectral density matrix noise target speech. blstm model estimates masks ﬁrst mask indicates time frequency probably dominated speech indicates dominated noise. combined speech noise masks estimate matrices speech components φspeech cm×m frequency noise components φnoise cm×m follows input layer dimension hidden layer dimension output layer dimension l-regularize num-epochs initial-effective-lrate ﬁnal-effective-lrate shrink-value num-chunk-per-minibatch lstm language model first experiments describe speech enhancement performance blstm-based speech enhancement. single channel track used blstm masking technique trained channel data took speech mask forward propagation. took hadamard product single channel spectrogram speech mask used enhanced signal compare original signal without enhancement. channel channel tracks used blstm based beamformer described section compare beamformit. four different scores described section pesq stoi estoi computed. blstm architecture used experiments listed table impulse response used reference signal computing four metrics. channel track blstm mask gives signiﬁcantly better scores four metrics compared using noisy data without enhancement. however contrary results discussed next section. beamformit better scores compared blstm multi-channel tracks. also multi-channel track data estoi slightly better blstm gev. track experiments blstm signiﬁcantly better pesq score. overall blstm-based speech enhancement shows improvement conditions except case multichannel metric. system trained speech recognition toolkit kaldi tdnn acoustic model training backstitch optimization method used. decoding based -gram language models explicit pronunciation silence probability modeling described model re-scored -gram language model ﬁrst. kaldi-rnnlm used training lstmlm n-best re-scoring used improve performance. best result channel experiments averaging forward backward lstmlm. re-score weight means results -gram completely discarded. results section reported terms word error rate also provide parameters used system table table shows effectiveness data augmentation system using tdnn beamformit rnnlm described section channel track experiment. conﬁrmed improvement adding enhanced data alcases except simulation test data. also found channels experiment using tdnn tables show channel channel experiments. change experimental condition incrementally compare effectiveness method described section situations every method improved steadily. observed performance degraded paper describes single system chime- speech separation recognition challenge. system consists blstm masked beamformer tdnn lf-mmi acoustic model re-scoring using lstmlm trained channels data plus enhanced data generated beamformer system ﬁnally achieved outperforms place result challenge. system publicly available kaldi speech recognition toolkit. applied enhanced data system using dnn+smbr tdnn lf-mmi could make enhanced data discussed above. addition comparing speech enhancement results table shows better speech enhancement scores necessarily gives lower wer. especially always seems negative correlation performance scores. table illustrates results channel track experiment. found blstm masking effective used microphone although scores better terms four speech enhancement metrics table blstm masking degraded twice compared system without blstm masking. however also discovered adding enhanced data system blstm masking became closer best setup without masking seen thus adding enhanced data seems good strategy mitigate degradation speech enhancement. finally table presents comparison ofﬁcial baseline systems chime- challenge. systems fusion technique best wer. hand proposed single system achieved relative improvement ofﬁcial baseline achieved best performance. barker marxer vincent watanabe third chimespeech separation recognition challenge dataset task baselines ieee workshop automatic speech recognition understanding kinoshita delcroix gannot habets haebumbach kellermann leutnant maas nakatani summary reverb challenge state-ofthe-art remaining challenges reverberant speech processing research eurasip journal advances signal processing vol. vincent watanabe nugraha barker marxer analysis environment microphone data simulation mismatches robust speech recognition computer speech language vol. yoshioka delcroix ogawa kinoshita fujimoto fabian espi higuchi chime- system advances speech enhancement recognition mobile multi-microphone devices automatic speech recognition understanding ieee menne heymann alexandridis irie zeyer kitza golik kulikov drude schl¨uter rwth/upb/forth system combination chime challenge evaluation chime- workshop heymann drude haeb-umbach neural network based spectral mask estimation acoustic beamforming ieee international conference acoustics speech signal processing march waibel hanazawa hinton shikano lang phoneme recognition using time-delay neural networks readings speech recognition. elsevier povey peddinti galvez ghahremani manohar wang khudanpur purely sequence-trained neural networks based lattice-free interspeech beerends hollier hekstra perceptual evaluation speech quality method speech quality assessment telephone networks codecs proceedings acoustics speech signal processing ieee international conference volume ser. icassp taal hendriks heusdens jensen algorithm intelligibility prediction time-frequency weighted noisy speech ieee transactions audio speech language processing vol. sept jensen taal algorithm predicting intelligibility speech masked modulated noise maskers ieee/acm transactions audio speech language processing vol. hori chen erdogan hershey roux mitra watanabe multi-microphone speech recognition integrating beamforming robust feature extraction advanced dnn/rnn backend computer speech language vol. warsitz haeb-umbach blind acoustic beamforming based generalized eigenvalue decomposition ieee transactions audio speech language processing vol. povey discriminative training large vocabulary speech recognition ph.d. dissertation university cambridge sundermeyer schl¨uter lstm neural speech enhancement lstm recurrent neural networks application noise-robust author=weninger felix erdogan hakan watanabe shinji vincent emmanuel roux jonathan hershey john schuller bj¨orn booktitle=international conference latent variable analysis signal separation pages=– year= organization=springer. povey ghoshal boulianne burget glembek goel hannemann motlicek qian schwarz kaldi speech recognition toolkit ieee workshop automatic speech recognition understanding. ieee signal processing society mccowan carletta kraaij ashby bourban flynn guillemot hain kadlec karaiskos meeting corpus proceedings international conference methods techniques behavioral research vol.", "year": "2018"}