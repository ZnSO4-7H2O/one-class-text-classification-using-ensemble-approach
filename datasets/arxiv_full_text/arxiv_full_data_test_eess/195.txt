{"title": "A Data Driven Approach for Resting-state EEG signal Classification of  Schizophrenia with Control Participants using Random Matrix Theory", "tag": "eess", "abstract": " Resting state electroencephalogram (EEG) abnormalities in clinically high-risk individuals (CHR), clinically stable first-episode patients with schizophrenia (FES), healthy controls (HC) suggest alterations in neural oscillatory activity. However, few studies directly compare these anomalies among each types. Therefore, this study investigated whether these electrophysiological characteristics differentiate clinical populations from one another, and from non-psychiatric controls. To address this question, resting EEG power and coherence were assessed in 40 clinically high-risk individuals (CHR), 40 first-episode patients with schizophrenia (FES), and 40 healthy controls (HC). These findings suggest that resting EEG can be a sensitive measure for differentiating between clinical disorders.This paper proposes a novel data-driven supervised learning method to obtain identification of the patients mental status in schizophrenia research. According to Marchenko-Pastur Law, the distribution of the eigenvalues of EEG data is divided into signal subspace and noise subspace. A test statistic named LES that embodies the characteristics of all eigenvalues is adopted. different classifier and different feature(LES test function) are selected for experiments, we have shown that using von Neumann Entropy as LES test function combine with SVM classifier could obtain the best average classification accuracy during three classification among HC, FES and CHR of Schizophrenia group with EEG signal. It is worth noting that the result of LES feature extraction with the highest classification accuracy is around 90% in two classification(HC compare with FES) and around 70% in three classification. Where the classification accuracy higher than 70% could be used to assist clinical diagnosis. ", "text": "department automation shanghai jiaotong university shanghai china. shanghai mental health center shanghai jiaotong university school medicine resting state electroencephalogram abnormalities clinically high-risk individuals clinically stable ﬁrst-episode patients schizophrenia healthy controls suggest alterations neural oscillatory activity. however studies directly compare anomalies among types. therefore study investigated whether electrophysiological characteristics differentiate clinical populations another non-psychiatric controls. address question resting power coherence assessed clinically high-risk individuals ﬁrst-episode patients schizophrenia healthy controls ﬁndings suggest resting sensitive measure differentiating clinical disorders.this paper proposes novel data-driven supervised learning method obtain identiﬁcation patients mental status schizophrenia research. according marchenko-pastur distribution eigenvalues data divided signal subspace noise subspace. test statistic named embodies characteristics eigenvalues adopted. different classiﬁer different feature selected experiments shown using neumann entropy test function combine classiﬁer could obtain best average classiﬁcation accuracy three classiﬁcation among schizophrenia group signal. worth noting result feature extraction highest classiﬁcation accuracy around classiﬁcation around three classiﬁcation. classiﬁcation accuracy higher could used assist clinical diagnosis. used diagnostic tool nearly years still resists strict objective analysis interpretation remains mostly intuitive heuristic. particular cross channel relations signal reference sources hence certain morphological and/or functional brain structures understood sufﬁciently matter intense research. many methods developed helping understand meaning signal. range visual inspection record experienced physician sophisticated estimations attempt describe signal using phase space methods model sources oscillating electric dipoles. however none methods regarded fully satisfactory. reason signal electric activity brain measured electrodes placed scalp superposition electric signals produced synchronous activity numerous neurons. spatial propagation electric signal complex brain tissue straightforward. moreover various groups neurons participate various sometimes independent tasks. together makes resulting signal complex difﬁcult interpret. stressed morphological functional properties brain always same. contrary different different individuals. makes signal dependent measured subject. even different persons perform tasks measurement done identical conditions resulting signals could differ. possesses many special properties would make useful context high time resolution opens window dynamics brain. previous studies observed provides important information differences individuals pertains anatomical functional traits brains. individual persons furthermore stable speciﬁc. provides small intra-personal differentiation large inter-personal differentiation ideal biometrics. eeg-based biometric systems basically organized different states task-related state resting state. paper interested using resting state eeg. reasons this. first evidence indicates electrical activities resting state organizes coordinates neuronal functions second certain tasks cannot performed certain group people e.g. attention deﬁcit disorder handicapped patients. resting state includes resting-state open eyes resting-state closed eyes paper consider closed eyes conditions. common procedure eeg-based biometrics involves data collection preprocessing feature extraction pattern recognition. however resting state lacks task related feature thus making difﬁcult manually design best feature extract. paper analyze covariances using tools random matrix theory. necessary deﬁne matrix ensemble based data. fact brain nonstationary. means tasks performing change time. hence structure covariance matrix changes. typical measurement lasts mins. time interval divided roughly thousands overlapping stationary windows covariance matrix evaluated. thousands covariance matrices. matrices represent ensemble work with. known random matrix theory describes correctly spectral statistics certain complex systems. useful particular deals systems chaotic display time certain wave properties. signal multivariate time series. measured scalp activity particular cerebral area inﬂuences results several channels. hence activity given cortex area leads correlations signal measured different electrodes. object analyzed simplest describing covariance namely covariance matrix. random matrix theory based random variables elements matrix comparison random multidimensional time series statistical properties reﬂect correlation real data degree deviation random distribution properties reveal behaviour characteristic whole actual data. unique angle view different traditional methods widely applied ﬁelds ﬁnancial physical biological statistics computer science etc. based study large radar antenna array signal transmission found eigenvalue distribution uses antenna sensor nodes construct random matrix well describe correlation antenna nodes make rapid response emergence abnormal signals transmission process. ﬁnancial ﬁeld analysis researchers found trend america stock maximum eigenvalue correlation matrix years analysed american stock character market crashed paper proposes novel data-driven supervised learning method obtain identiﬁcation patient’s mental status schizophrenia research. first random matrix theories brieﬂy introduced solid mathematic foundations rmms. built rmms major data processing ingredients designs systematically studied. high dimensional statistical indicators; different test functions gain insight systems different perspectives. moreover theoretical values related less predictable reference points latest theorems. besides combined entropy entropy inequalities illustrate real data information. deep research; give brief mention. general based data applying architecture paper presents series work associated theorems brieﬂy discussion information entropy indicators derived visualization results. case studies real data validate proposed method related theories theorems. paper organized follows ﬁrst part consists introduction prodromal phase schizophrenia. second part gives general overview data source processing. third part materials methods describes subjects experiment well topology rmt. finally results discussion conclusion detailed sections data paper used provided metal health center hospital shanghai. continuous activity recorded subjects seated comfortably eyes closed. recordings took place participants monitored electroencephalographic signs somnolence whole duration recording recordings conducted ag/agcl electrodes arranged according modiﬁed system referenced fcz. electrode impedance kept signal contaminated noise artifacts external physiologic origin bandpass ﬁlter ocular correction applied ofﬂine. space position sensor shown fig. describe kind time series data form matrix dimension sample size means numbers sensor ag/agcl electrodes paper mean period time series data sample time mins sampling frequency participants subjects data form subject illustrated fig. modeling large dimensional data random matrix multivariate statistics describe random sample pdimensional random vectors form data matrix cn×t naturally random matrix need analysis high-dimensional data. remarkalbe fact large comparale. possibility arbitrary sample size classical limit theory free probability mathematical transform information theory. several theorems given important study based following theorem. corresponding eigenvectors. simplest property eigenvalues family related matrix ensemble eigenvalue density ρ.it counts mean number eigenvalues contained interval according distribution entries matrix ensemble random matrix mathematically studied marchenko pastur. particular density ensemble known given formula whose density given number channels number sampling points.this marchenko-pastur analogue wigner’s semicircle setting multiplicative rather addtive symmetrization assumption gaussian entries signiﬁcantly relaxed. deﬁnition spectral density needs independence data. consideration random signal contrary synchronous related corresponding brain activity. expect spectral density follow prediction marchenko-pastur related human activities. fortunately real data completely inconsistent spectral distribution. result plotted fig. keep result simple comprehend randomly choose data frame object three group data shows approximate result. blue fig. empirical spectral distribution eigenvalues n−xx random gaussian matrix curve marchenko-pastur density function. differences real simulated data. fig. head distribution certain number eigenvalues near zero tail distribution several large eigenvalues random matrix theories compared traditional probability theory random matrix deﬁned random variable elements matrix. random matrix dimension tends inﬁnity called large random matrix. rectangular matrix ﬁxed. large random matrix column tends inﬁnity rank ratio kept constant. then large random matrix empirical spectral distribution case many proven characteristics like semicircular marchenko-pastur latest circle law. random matrix theory according element distribution characteristics divided into gauss random matrices wishart random matrix haar-unitary random matrix. research method based variety mathematical theory mentioned previous subsection test statistic containing information eigenvalues. employ statistical test methods like analysis variance applied selected features examine pre-deﬁned hypothesis. results reported using values denote signiﬁcance difference signatures between/among factors testing hypothesis. pick form neumann entropy test statistic p-value table data plot shown table fig. p-value three states schizophrenia pairs three states small enough p-value smaller signiﬁcance level indicates least sample means signiﬁcantly different others. result analysis variancethere appropriate form test function could feature classiﬁcation among different kinds states schizophrenia. outliers. magnify eigenvalues empirical spectral distribution limit spectral distribution surprised distribution tempirial limit part coincides certain extent. according deﬁnition random matrix part shows data conforms characteristics random noise named noise subsapcebut theoretical value part also contains part information. parts including eigenvalues near zero outliers show information data named signal subspace. eigenvalues near zero means correlation data outliers affected actual activities. derive profound subject-independent information data test statistic embodies characteristics eigenvalues adopted. linear eigenvalue statistics deﬁnition since pioneer work wigner known consider linear eigenvalue statistic corresponding continuous test function presence universality property suggests highdimensional phenomenon robust precise details model ingredients. example perform various hypothesis tests assumption matrix entries gaussian distributed test statistic gaussian case. data real systems viewed spatial temporal sampling random graph. randomness introduced uncertainty spatial locations system uncertainty. real life applications cannot expect matrix entries follow i.i.d. distribution. numerous studies based simulations experiments however demonstrate ring universally followed. cases universality properties provide crucial tool reduce proofs general results tractable special case i.i.d. case paper. methods data experiments mentioned analyzed several procedures including signal preprocessing data blocking feature extraction state classiﬁcation shown fig. data blocking feature extraction important parts paper. signal preprocessing basic approach signal analysis proper information signal applying best suitable process. process method used study fourier transform. spectral analysis signal involves decomposition signal frequency components. words original signal could separated sub-spectral components using spectral analysis methods. among spectral analysis techniques fourier transform considered best transformation time frequency domains time shift invariant. fourier transform pairs expressed mentioned design test functions obtain diverse indicators real hard appropriate test function. might noticed standardization matrix eigenvalues matrix equal eigenvalues greater less kind probability. result natural think formula information entropy could test function les. consideration physically meaning information entropy kind description uncertainty source could linked actual. universality principle akin universality refers phenomenon asymptotic distributions various covariance matrices identical gaussian covariance matrices. results calculate exact asymptotic distributions various test statistics without restrictive distributional assumptions matrix entries. classiﬁer support vector machines commonly known svms considered best state classiﬁers lower complexity compared classiﬁers like neural networks fuzzy classiﬁers. based upon concept hyper plane able classify data separate classed possibility maximum margin. linear also classify nonlinear problems using kernel trick little amount complexity increase. top-down recursive construction method. internal node represents test attribute edge represents test result leaf node represents kind class class distribution node root node. typical classiﬁcation method approximate value discrete function. naive bayes based upon bayes theory makes assumption attribute given class independent values attributes. class conditional independence based upon assumption. oder perform reliable classiﬁcation process constructed training test data cross validation method presented study. training consists samples randomly selected data remaining part test ﬁrst used training train classiﬁer test validate trained model ﬁnally repeat process several data blocking turn data tiny data practical lately advanced data driven estimators could adopted obtain state evaluation without knowledge medical parameters connectivity. consideration characteristic data extremely long time series fig. illustrates conceptual representation structure massive streaming data. speciﬁcally original data form subject matrix. n×∆t window size sampling number respectively. time series data divided sequence random matrix feature extraction main task feature extraction derive salient features data different states. feature extraction related dimensionality reduction input data algorithm large processed suspected redundant. fundamental study spectral analysis large dimensional random matrix concerns central limit theory les. main reason many important statistics multivariate statistics analysis expressed functionals empirical spectral distribution random matrix. concerned mapping eigenvalue sample covariance matrix parts feature extraction. sample covariance matrix deals question approximate actual covariance matrix basis sample multivariate distribution.the sample covariance matrix unbiased efﬁcient estimator covariance matrix space covariance matrix viewed extrinsic convex cone rp×p. namely linear polynomial choose kernel result study. already make sample comparative experiment among kernels deﬁnitely proves robustness polynomial linear data sets kernel chosen basic kernel remaining paper. third state classiﬁer accuracies turn worse success rate around means feature extraction method distinguish three states well. result less reference value clinical applications. effect features section roughly represent data terms high-dimensional data vectors geometrically points high-dimensional vector space. random variables taken account simultaneously spatially temporally central idea treat vectors whole rather multiple samples random vectors. according procedure turning data many tiny data blocks block calculates feature basis test function. random matrix cn×n whose eigenvalues known strong correlated random variables. concept section show several popular test functions table different classiﬁer different feature selected experiments classiﬁcation results contrasted analyzed. result shown table worth noting result feature extraction better traditional statistical feature extraction highest classiﬁcation accuracy around classiﬁcation around three classiﬁcation encouraging. seen performance classiﬁers used satisfactory distinguish using neumann entropy test function combine classiﬁer could obtain average classiﬁcation accuracy three classiﬁcation among chr. comparing result table obvious classiﬁcation result could relatively easy good results classiﬁcation success rate higher could used assist clinical diagnosis. different statistical feature based feature training small high bias/low variance classiﬁers advantage bias/high variance classiﬁers since latter overﬁt. bias/high variance classiﬁers start training grows since high bias classiﬁers aren’t powerful enough provide accurate models. though better data often beats better algorithms designing good features goes long way. huge dataset choice classiﬁcation algorithm might really matter much terms classiﬁcation performance. data sets used study large large enough ignore differences various classiﬁcation methods words various classiﬁcation methods signiﬁcantly different differences cannot ignored. times statistical information observations. account performance index evaluation classiﬁer. mentioned above several classiﬁcation method adopted study includes naive bayes decision tree random forest. comparison various extracted features extraction feature extremely important since seeks reduce dimensionality data synthesized form feature vector preserving highlighting useful information data. quality feature selection directly affects success rate classiﬁcation computational effort required balance success efﬁciency taken account. characteristics electrode obtained statistical features sampling period. electrodes electrode could obtain seven statistical features could features. features trained variety machine learning methods table shows classiﬁcation performance obtained various classiﬁer serval statistical features distinguishing three kind states schizophrenia. observed two-category classiﬁcation problem good classiﬁcation effect accuracies classiﬁer particularly method closed point important aspect classiﬁer three kinds kernels classiﬁcation results shown table table observe length sampling size became longer different affect estimation accuracy sample covariance matrix maximum classiﬁcation accuracy located classical statistics sample size usually times dimension means suitably range results suggest sampling size subjects individualized around neumann entropy neumann entropy generalization classical entropy ﬁeld quantum mechanics. neumann entropy cornerstones quantum information theory. plays essential role expressions best achievable rates virtually every coding theorem. notation prefer using bold upper-case symbols represent random matrices. symmetric matrix bounded measurable function deﬁned matrix eigenvectors eigenvalues images namely eigenvector eigenvalues spectral decomposition orthogonal diag diagonal real advantages high accuracy nice theoretical guarantees regarding overﬁtting appropriate kernel work well even you’re data isn’t linearly separable base feature space especially popular classiﬁcation problems highdimensional spaces norm. random matrix eigenvalues various test function central importance theory random matrix.several popular statistical indicators used test function study test function physical meaning signiﬁcance selecting test function give physical explanation les. statistical signiﬁcance test function physical meaning combination engineering interpretation classiﬁcation results novel algorithm. neumann entropy performance best results compare functions discussion physical meaning entropy later study. effect different window size feature before used ﬁxed sampling period sampling base identiﬁcation obtained good classiﬁcation results. section would like frequency length signal still able preserve identiﬁcation information compare performance differences. divided signal sampling point various portions performed mentioned procedure. based results comparative experiments neumann entropy used test function selected classiﬁcation. ling massive streaming data modeling analytics smart grid state evaluation based multiple high-dimensional covariance tests ieee transactions data vol. borges fernandes silva silva feature extraction power quality disturbances classiﬁcation using smart meters signals ieee transactions industrial informatics vol. classiﬁer could obtain best average classiﬁcation accuracy three classiﬁcation among schizophrenia group signal. classiﬁcation performance would improved size training data database becomes larger proposed biometrics system tested larger group classes subjects providing identiﬁcation accuracy robustness applicability system. extensive research space data analysis human psychiatric disorders. current work focused spectral analysis. prospective work data analysis could data analysis based spatiotemporal representation information signal. introduce suitable model solve problem. appreciated department source imaging leaded professor jijun wang professor chunbo shjc data providing discussion. also grateful tianhong zhang shjc expert collaboration data analysis. cincotti mattia aloise bufalari astolﬁ fallani tocci bianchi marciani high-resolution techniques brain–computer interface applications journal neuroscience methods vol. fraschini hillebrand demuru didaci marcialis eeg-based biometric system using eigenvector centrality resting state brain networks ieee signal processing letters vol. vijayalakshmi dasari nandagopal subhiksha cocks dahal thilaga change detection visualization functional brain networks using data international conference computational science shcherbina central limit theorem linear eigenvalue statistics wigner sample covariance random matrices journal mathematical physics analysis geometry vol. p´ags.", "year": "2017"}