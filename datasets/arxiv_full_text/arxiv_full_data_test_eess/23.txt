{"title": "Neural Style Transfer: A Review", "tag": "eess", "abstract": " The seminal work of Gatys et al. demonstrated the power of Convolutional Neural Networks (CNNs) in creating artistic imagery by separating and recombining image content and style. This process of using CNNs to render a content image in different styles is referred to as Neural Style Transfer (NST). Since then, NST has become a trending topic both in academic literature and industrial applications. It is receiving increasing attention and a variety of approaches are proposed to either improve or extend the original NST algorithm. In this paper, we aim to provide a comprehensive overview of the current progress towards NST. We first propose a taxonomy of current algorithms in the field of NST. Then, we present several evaluation methods and compare different NST algorithms both qualitatively and quantitatively. The review concludes with a discussion of various applications of NST and open problems for future research. A list of papers discussed in this review, corresponding codes, pre-trained models and more comparison results are publicly available at https://github.com/ycjing/Neural-Style-Transfer-Papers. ", "text": "abstract—the seminal work gatys demonstrated power convolutional neural networks creating artistic imagery separating recombining image content style. process using cnns render content image different styles referred neural style transfer since then become trending topic academic literature industrial applications. receiving increasing attention variety approaches proposed either improve extend original algorithm. paper provide comprehensive overview current progress towards nst. ﬁrst propose taxonomy current algorithms ﬁeld nst. then present several evaluation methods compare different algorithms qualitatively quantitatively. review concludes discussion various applications open problems future research. list papers discussed review corresponding codes pre-trained models comparison results publicly available https//github.com/ycjing/neural-style-transfer-papers. years people attracted painting advent many appealing artworks e.g. gogh’s starry night. past re-drawing image particular style requires well-trained artist lots time. since mid-s theories behind appealing artworks attracting attention artists many computer science researchers. plenty studies techniques exploring automatically turn images synthetic artworks. among studies advances non-photorealistic rendering inspiring nowadays ﬁrmly established ﬁeld community computer graphics. however stylisation algorithms designed particular artistic styles cannot easily extended styles. community computer vision style transfer usually studied generalised problem texture synthesis extract transfer texture source target hertzmann propose framework named image analogies perform generalised style transfer learning analogous transformation provided example pairs unstylised stylised images. however common limitation methods low-level image features often fail capture image structures effectively. jing feng song microsoft visual perception laboratory college computer science technology zhejiang university hangzhou china. e-mails {ycjing zunleifeng yejingwen brooksong}zju.edu.cn. yang school computing informatics decision systems engineering arizona state university tempe usa. e-mail yz.yangasu.edu. department computer science university hong kong pokfulam road hong kong. e-mail yizhouyacm.org. recently inspired power convolutional neural networks gatys ﬁrst studied reproduce famous painting styles natural images. proposed model content photo feature responses pre-trained model style artwork summary feature statistics. experimental results demonstrated capable extracting content information arbitrary photograph style information wellknown artwork. based ﬁnding gatys ﬁrst proposed exploit feature activations recombine content given photo style famous artworks. idea behind algorithm iteratively optimise image objective matching desired feature distributions involves photo’s content information artwork’s style information. proposed algorithm successfully produces stylised images appearance given artwork. figure shows example transferring style chinese painting dwelling fuchun mountains onto photo great wall. since algorithm gatys explicit restrictions type style images also need ground truth results training breaks constraints previous approaches. work gatys opened ﬁeld called neural style transfer process using convolutional neural network render content image different styles. seminal work gatys attracted wide attention academia industry. academia lots follow-up studies conducted either improve extend algorithm. related researches also many successful industrial applications ostagram deep forger however comprehensive survey summarising discussing recent advances well challenges within ﬁeld neural style transfer. paper provide overview current advances neural style transfer contributions threefold. first investigate classify summarise recent advances ﬁeld nst. second present several evaluation methods experimentally compare different algorithms. third summarise current challenges ﬁeld propose possible directions deal future works. organisation paper follows. start discussion brief review previous artistic rendering methods without cnns section section explores derivations foundations nst. based discussions section categorise explain existing algorithms section improvement strategies methods extensions given section section presents several methodologies evaluating algorithms aims build standardised benchmark follow-up studies. demonstrate commercial applications section including current successful usages potential applications. section summarise current challenges ﬁeld well propose possible directions deal future works. finally section concludes paper delineates several promising directions future research. style transfer without neural networks artistic stylisation long-standing research topic. wide variety applications important research area decades. appearance related researches expanded area called non-photorealistic rendering section brieﬂy review artistic rendering algorithms without cnns. speciﬁcally focus artistic stylization images called image-based artistic rendering comprehensive overview ib-ar techniques recommend following ib-ar taxonomy deﬁned kyprianidis ﬁrst introduce category ib-ar techniques without cnns discuss strengths weaknesses. stroke-based rendering. stroke-based rendering refers process placing virtual strokes upon digital canvas render photograph particular style process generally starting source photo incrementally compositing strokes match photo ﬁnally producing non-photorealistic imagery looks like photo artistic style. process objective function designed guide greedy iterative placement strokes. goal algorithms faithfully depict prescribed style. therefore generally effective simulating certain types styles however algorithm carefully designed particular style capable simulating arbitrary style ﬂexible. region-based techniques. region-based rendering incorporate region segmentation enable adaption rendering based content regions. early regionbased ib-ar algorithms exploit shape regions guide stroke placement different stroke patterns produced different semantic regions image. song propose regionbased ib-ar algorithm manipulate geometry artistic styles. algorithm creates simpliﬁed shape rendering effects replacing regions several canonical shapes. considering regions rendering allows local control level details. however problem persists region-based rendering algorithm capable simulating arbitrary style. example-based rendering. goal example-based rendering learn mapping exemplar pair. category ib-ar techniques pioneered hertzmann propose framework named image analogies image analogies learn mapping pair source images target stylised images supervised manner. training image analogy comprises pairs unstylised source images corresponding stylised images particular style. image analogy algorithm learns analogous transformation example training pairs creates analogous stylised results given test input photograph. image analogy also extended various ways e.g. learn stroke placements portrait painting rendering general image analogies effective variety artistic styles. however pairs training data usually unavailable practice. another limitation image analogies exploit low-level image features. therefore image analogies typically fail effectively capture content style limits performance. image processing filtering. creating artistic image process aims image simpliﬁcation abstraction. therefore natural consider adopting combining related image processing ﬁlters render given photo. example winnem¨oller ﬁrst time exploit bilateral difference gaussians ﬁlters automatically produce cartoon-like effects. compared categories ib-ar techniques image-ﬁltering based rendering algorithms generally straightforward implement efﬁcient practice. expense limited style diversity. summary. based discussions although ib-ar algorithms without cnns capable faithfully depicting certain prescribed styles typically limitations ﬂexibility style diversity effective image structure extractions. therefore demand novel algorithms address limitations gives birth ﬁeld nst. derivations neural style transfer better understanding development start introducing derivations. automatically transfer artistic style ﬁrst important issue model extract style image. since style related texture straightforward relate visual style modelling back previously well-studied visual texture modelling methods. obtaining style representation next issue reconstruct image desired style information preserving content addressed image reconstruction techniques. visual texture modelling visual texture modelling previously studied heart texture synthesis throughout history distinct approaches model visual textures parametric texture modelling summary statistics non-parametric texture modelling markov random fields clarify style related texture limited texture. style also involves large degree simpliﬁcation shape abstraction effects falls back composition alignment texture features. statistical property model texture. idea ﬁrst proposed julesz models textures pixelbased n-th order statistics. later work exploits ﬁlter responses analyze textures instead direct pixelbased measurements. that portilla simoncelli introduce texture model based multiscale orientated ﬁlter responses gradient descent improve synthesised results. recent parametric texture modelling approach proposed gatys ﬁrst measure summary statistics domain cnn. design gram-based representation model textures correlations ﬁlter responses different layers pre-trained classiﬁcation network speciﬁcally grambased representation encodes second order statistics ﬁlter responses. next explain representation detail usage following sections. assume feature sample texture image layer pre-trained deep classiﬁcation network rc×h×w number channels represent height width feature gram-based representation obtained computing gram matrix rc×c feature gram-based texture representation effective modelling wide varieties natural non-natural textures. however gram-based representation designed capture global statistics tosses spatial arrangements leads unsatisfying results modelling regular textures long-range symmetric structures. address problem berger memisevic propose horizontally vertically translate feature maps pixels correlate feature position positions representation incorporates spatial arrangement information therefore effective modelling textures symmetric properties. non-parametric texture modelling mrfs. annotable texture modelling methodology nonparametric resampling. variety non-parametric methods based mrfs model assumes texture image pixel entirely characterised spatial neighbourhood. assumption efros leung propose synthesise pixel searching similar neighbourhoods source texture image assigning corresponding pixel. work earliest non-parametric algorithms mrfs. following work levoy speed neighbourhood matching process always using ﬁxed neighbourhood. image reconstruction general essential step many vision tasks extract abstract representation input image. image reconstruction reverse process reconstruct whole input image extracted image representation. previously studied analyse particular image representation discover information contained abstract representation. major focus representation based image reconstruction algorithms categorised image-optimisation-based online image reconstruction model-optimisationbased ofﬂine image reconstruction image-optimisation-based online image reconstruction. ﬁrst algorithm reverse representations proposed mahendran vedaldi given representation reversed algorithm iteratively optimises image similar desired representation. iterative optimisation process based gradient descent image space. therefore process time-consuming especially desired reconstructed image large. model-optimisation-based ofﬂine image reconstruction. address efﬁciency issue dosovitskiy brox propose train feed-forward network advance computational burden training stage. testing stage reverse process simply done network forward pass. algorithm signiﬁcantly speeds image reconstruction process. later work combine generative adversarial network improve results. taxonomy neural style transfer algorithms subset aforementioned example-based ib-ar techniques. section ﬁrst provide categorisation algorithms explain major image based non-photorealistic algorithms detail. speciﬁcally algorithm start introducing main idea discuss weaknesses strengths. since complex deﬁne notion style therefore subjective deﬁne criteria important make successful style transfer algorithm evaluate algorithms structural focusing details semantics depth variations brush strokes. discuss problem aesthetic evaluation criterion section also present evaluation results section proposed taxonomy techniques shown figure keep taxonomy ib-ar techniques proposed kyprianidis unaffected extend algorithms. current methods categories image-optimisation-based online neural methods model-optimisation-based ofﬂine neural methods ﬁrst category transfers style iteratively optimising image i.e. algorithms belong category built upon iob-ir techniques. second category optimises generative model ofﬂine produces stylised image single forward pass exploits idea mob-ir techniques. image-optimisation-based online neural methods deepdream ﬁrst attempt produce artistic images reversing representations iob-ir techniques. combining visual texture modelling techniques model style iob-nst algorithms subsequently proposed build early foundations ﬁeld nst. basic idea ﬁrst model extract style content information corresponding style content images recombine target representation iteratively reconstruct stylised result matches target representation. general different iobnst algorithms share iob-ir technique differ model visual style built aforementioned categories visual texture modelling techniques. common limitation iob-nst algorithms computationally expensive iterative image optimisation procedure. parametric neural methods summary statistics ﬁrst subset iob-nst methods based parametric texture modelling summary statistics. style characterised spatial summary statistics. start introducing ﬁrst algorithm proposed gatys reconstructing representations intermediate layers vgg- network gatys observe deep convolutional neural network capable extracting image content arbitrary photograph appearance information well-known artwork. according observation build content component newly stylised image penalising difference high-level representations derived content stylised images build style component matching gram-based summary statistics style stylised images derived proposed texture modelling technique details algorithm follows. type style images addresses limitations previous ib-ar algorithms without cnns however algorithm gatys perform well preserving coherence structures details stylisation since features inevitably lose low-level information. also generally fails photorealistic synthesis limitations gram-based style representation. moreover consider variations brush strokes semantics depth information contained content image important factors evaluating visual quality. addition gram-based style representation choice statistically encode style information. also effective statistical style representations derived gram-based representation. derive different style representations considering style transfer domain transfer learning speciﬁcally domain adaption given training testing data drawn different distributions goal domain adaption adapt model trained labelled training data source domain predict labels unlabelled testing data target domain. domain adaption match sample source domain target domain minimising distribution discrepancy maximum mean discrepancy popular choice measure discrepancy distributions. prove matching gram-based style representations pair style stylised images intrinsically minimising quadratic polynomial kernel. therefore expected kernel functions equally applied e.g. linear kernel polynomial kernel gaussian kernel. another related representation batch normalisation statistic representation mean variance feature maps layers model style main contribution al.’s algorithm theoretically demonstrate gram matrices matching process equivalent minimising second order polynomial kernel thus proposing timely interpretation making principle clearer. however algorithm resolve aforementioned limitations gatys al.’s algorithm. limitation gram-based algorithm instabilities optimisations. also requires manually tuning parameters tedious. risser feature activations quite different means variances still gram matrix main reason instabilities. inspired observation risser introduce extra histogram loss guides optimisation match entire histogram feature activations. also present preliminary solution automatic parameter tuning explicitly prevent gradients extreme values extreme gradient normalisation. compares content representation given content image stylised image compares gram-based style representation derived style image stylised image. used balance content component style component stylised result. content loss deﬁned squared euclidean distance feature representations content image layer stylised image initialised noise image {lc} denotes layers computing content loss. style loss exploits grambased visual texture modelling technique model style already explained section therefore style loss deﬁned squared euclidean distance gram-based style representations choice content style layers important factor process style transfer. different positions numbers layers result different visual experiences. given pre-trained vgg- loss network gatys al.’s choice {ls} {lc} {ls} {relu relu relu relu relu {lc} {relu {ls} idea combining multiple layers critical success gatys al.’s algorithm. matching multi-scale style representations leads smoother continuous stylisation gives visually appealing results content layer {lc} matching content representations lower layer preserves undesired structures original content image stylisation. contrast matching content higher layer network structures altered agree desired style preserving content information content image. also using vggbased loss networks style transfer option. similar performance achieved selecting pretrained classiﬁcation networks e.g. resnet equation differentiable. thus random noise initial equation minimised using gradient descent image space backpropagation. addition total variation denoising term usually added practice encourage smoothness stylised result. model-optimisation-based ofﬂine neural methods although iob-nst able yield impressive stylised images still limitations. concerned limitation efﬁciency issue. second category mobnst addresses speed computational cost issue exploiting mob-ir reconstruct stylised result i.e. feed-forward network optimised large images style images depending number artistic styles single produce mob-nst algorithms divided perstyle-per-model mob-nst methods multiple-styleper-model mob-nst methods arbitrary-styleper-model mob-nst methods. per-style-per-model neural methods parametric pspm summary statistics. ﬁrst mob-nst algorithms proposed johnson ulyanov respectively. methods share similar idea pre-train feed-forward style-speciﬁc network produce stylised result single forward pass testing stage. differ network architecture johnson design roughly follows network proposed radford residual blocks well fractionally strided convolutions ulyanov multi-scale architecture generator network. objective function similar algorithm gatys indicates also parametric methods summary statistics. algorithms johnson ulyanov achieve real-time style transfer. however algorithm design basically follows algorithm gatys makes suffer aforementioned issues gatys al.’s algorithm shortly ulyanov simply applying normalisation every single image rather batch images leads signiﬁcant improvement stylisation quality. single image normalisation called instance normalisation equivalent batch normalisation batch size style transfer network shown converge faster also achieves visually better results. interpretation form style normalisation directly normalise style content image desired style therefore objective easier learn rest network needs take care content loss. non-parametric pspm mrfs. another work wand inspired mrf-based algorithm section address efﬁciency issue training markovian feed-forward network using adversarial training. similar algorithm patch-based non-parametric method mrfs. method shown outperform algorithms johnson ulyanov preservation coherent textures complex images thanks patch-based design. however algorithm less satisfying performance non-texture styles since algorithm additionally matching histogram feature activations algorithm risser achieves stable style transfer fewer iterations parameter tuning efforts. however beneﬁt comes expense high computational complexity. also aforementioned weaknesses gatys al.’s algorithm still exist e.g. lack consideration depth coherence details. aforementioned neural methods compare content stylised images feature space make stylised image semantically similar content image. since features inevitably lose lowlevel information contained image usually unappealing distorted structures irregular artefacts stylised results. preserve coherence structures stylisation propose incorporate additional constraints upon low-level features pixel space. introduce additional laplacian loss deﬁned squared euclidean distance laplacian ﬁlter responses content image stylised result. laplacian ﬁlter computes second order derivatives pixels image widely used edge detection. algorithm good performance preserving structures details stylisation. still lacks considerations semantics depth variations brush strokes etc. non-parametric neural methods mrfs non-parametric iob-nst built basis nonparametric texture modelling mrfs. category considers local level i.e. operating patches match style. wand ﬁrst propose mrfbased algorithm. parametric method summary statistics captures perpixel feature correlations constrain spatial layout leads less visually plausible result photorealistic styles. solution model style non-parametric introduce style loss function includes patch-based prior local patches feature denotes local patch similar style patch i-th local patch stylised image best matching obtained calculating normalised cross-correlation style patches style image total number local patches. since algorithm matches style patch-level structure arrangement preserved much better. advantage algorithm wand performs especially well photorealistic styles speciﬁcally content photo style similar shape perspective patch-based loss. however generally fails content style images strong differences perspective structure since image patches could correctly matched. also limited preserving sharp details depth information. lacks consideration semantics. weaknesses algorithm include lack consideration depth information variations brush strokes important visual factors. multiple-style-per-model neural methods although pspm approaches produce stylised images orders magnitude faster previous iobnst methods separate generative networks trained particular style image quite timeconsuming inﬂexible. many paintings share similar paint strokes differ colour palettes. intuitively redundant train separate network them. mspm therefore proposed improves ﬂexibility pspm incorporating multiple styles single model. generally paths towards handling problem tying small number parameters network style still exploiting single network like pspm combining style content inputs tying small number parameters style. early work dumoulin built basis proposed layer pspm algorithm surprisingly using convolutional parameters scaling shifting parameters layers sufﬁcient model different styles. therefore propose algorithm train conditional multi-style transfer network based conditional instance normalisation deﬁned input feature activation index desired style style images. shown equation conditioning style done scaling shifting parameters normalising feature activation i.e. style achieved tuning parameters afﬁne transformation. interpretation similar section i.e. normalisation feature statistics different afﬁne parameters normalise input content image different styles. furthermore algorithm dumoulin also extended combine multiple styles single stylised result combining afﬁne parameters different styles. another algorithm follows ﬁrst path mspm proposed chen idea explicitly decouple style content i.e. using separate network components learn corresponding content style information. speciﬁcally mid-level convolutional ﬁlters individually learn different styles. style tied parameters stylebank layer. rest components network used learn content information shared different styles. algorithm also supports ﬂexible incremental training content components network train stylebank layer style. learn style ﬂexible control style fusion. however address common limitations algorithms e.g. lack details semantics depth variations brush strokes. combining style content inputs. disadvantage ﬁrst category model size generally becomes larger increase number learned styles. second path mspm addresses limitation fully exploring capability single network combining content style network style identiﬁcation. different mspm algorithms differ incorporate style network. given target styles design selection unit style selection n-dimensional one-hot vector. selection unit represents speciﬁc style target styles. selection unit ﬁrst sample corresponding noise uniform distribution feed style sub-network obtain corresponding style encoded features feeding concatenation style encoded features content encoded features decoder part style transfer network desired stylised result produced dec) another work zhang dana ﬁrst forwards style image style pre-trained network obtain multi-scale feature activations different layers. multi-scale combined multi-scale encoded features different layers encoder proposed inspiration layers. inspiration layers designed reshape match desired dimension also learnable weight matrix tune feature maps help minimise objective function. second type mspm addresses limitation increased model size ﬁrst type mspm. expense style scalability second type mspm much smaller since single network used multiple styles. quantitatively compare style scalability different mspm algorithms section addition aforementioned limitations ﬁrst type mspm still exist i.e. second type mspm algorithms still limited preserving coherence structures also depth information. arbitrary-style-per-model neural methods third category aspm-mob-nst aims one-modelfor-all i.e. single trainable model transfer arbitrary artistic styles. also types aspm built upon non-parametric texture modelling mrfs built upon parametric texture modelling summary statistics. non-parametric aspm mrfs. ﬁrst aspm algorithm proposed chen schmidt ﬁrst extract activation patches content style feature activations computed pre-trained network. match content patch similar style patch swap stylised result produced reconstructing resulting activation style swap either iob-ir mob-ir techniques. algorithm chen schmidt ﬂexible previous approaches characteristic one-model-for-all-style. stylised results less appealing since content patches typically swapped style patches representative desired style. result content well preserved style generally well reﬂected. parametric aspm summary statistics. considering section simplest approach arbitrary style transfer train separate parameter prediction network predict equation number training styles given test style image layers style transfer network take afﬁne parameters normalise input content image desired style forward pass. another similar approach based proposed huang belongie instead training parameter prediction network huang belongie propose modify conditional instance normalisation equation adaptive instance normalisation adain transfers channel-wise mean variance feature statistics content style feature activations also shares similar idea different encoder style transfer network ﬁxed comprises ﬁrst layers pre-trained network. therefore feature activation pre-trained network. decoder part needs trained large style content images decode resulting feature activations adain stylised result decf) algorithm huang belongie ﬁrst aspm algorithm achieves real-time stylisation. however algorithm huang belongie datadriven limited generalising unseen styles. also simply adjusting mean variance feature statistics makes hard synthesise complicated style patterns rich details local structures. recent work attempts exploit series feature transformations transfer arbitrary artistic style style learning free manner. similar ﬁrst layers pre-trained encoder train corresponding decoder. replace adain layer encoder decoder pair whitening colouring transformations decf) algorithm built observation whitening transformation remove style related information preserve structure content. therefore receiving content activations encoder whitening transformation ﬁlter original style input content image return ﬁltered representation content information. then applying colouring transformation style patterns contained incorporated ﬁltered content representation stylised result obtained decoding transformed features. also extend algorithm ﬁrst aspm algorithm transfer artistic styles learning-free manner. therefore compared limitation generalisation capabilities. algorithm still effective producing sharp details strokes. stylisation results shown section also lacks consideration preserving depth information variations brush strokes. improvements extensions since emergence algorithms also researches devoted improving current algorithms controlling perceptual factors also aforementioned methods designed general still images. appropriate specialised types images videos thus variety followstudies extend general algorithms particular types images even extend beyond artistic image style controlling perceptual factors neural style transfer. gatys propose several slight modiﬁcations improve previous algorithm demonstrate spatial style control strategy control style region content image. idea deﬁne guidance channels feature activations content style image. guidance channel values specifying style transferred content region i.e. content regions content guidance channel rendered style style guidance channel equal colour control original algorithm produces stylised images colour distribution style image. however sometimes people prefer colour-preserving style transfer i.e. preserving colour content image style transfer. corresponding solution ﬁrst transform style image’s colours match content image’s colours style transfer alternatively perform style transfer luminance channel. stroke size control problem much complex. show sample results stroke size control figure discussions stroke size control strategy need split several cases iob-nst non-high-resolution images since current style statistics scale-sensitive achieve different stroke sizes solution simply resizing given style image different scales. mob-nst non-high-resolution images possible solution resize input image different scales forward pass inevitably hurts stylisation quality. another possible solution train multiple models different scales style image space time consuming. also possible solution fails preserve stroke consistency among results different stroke sizes i.e. results vary stroke orientations stroke conﬁgurations etc. however users generally desire change stroke size others. address problem jing propose stroke controllable pspm algorithm. core component algorithm strokepyramid module learns different stroke sizes adaptive receptive ﬁelds. without trading quality speed algorithm ﬁrst exploit single model achieve ﬂexible continuous stroke size control preserving stroke consistency achieve spatial stroke size control produce artistic effects. although also aspm algorithm control stroke size aspm trades quality speed. result aspm effective producing strokes details compared iob-nst high-resolution images highresolution images large stroke size cannot achieved simply resizing style image large scale. since region content image receptive ﬁeld size affected neuron loss network almost visual difference large larger brush strokes small image region receptive ﬁeld size. gatys tackle problem proposing coarse-to-ﬁne iob-nst procedure several steps downsampling stylising upsampling ﬁnal stylising. mob-nst high-resolution images similar stroke size stylised result vary style image scale high-resolution images. solution also similar gatys algorithm coarseto-ﬁne stylisation procedure idea exploit multimodel comprises multiple subnetworks. subnetwork receives upsampled stylised result previous subnetwork input stylises ﬁner strokes. another limitation current algorithms consider depth information contained image. address limitation depth preserving algorithm proposed. approach depth loss function based measure depth difference content image stylised image. image depth acquired applying single-image depth estimation algorithm semantic style transfer. given pair style content images similar content goal semantic style transfer build semantic correspondence style content maps style region corresponding semantically similar content region. style style region transferred semantically similar content region. image-optimisation-based semantic style transfer. since patch matching scheme naturally meets requirements region-based correspondence champandard proposes build semantic style transfer algorithm based aforementioned patch-based algorithm although result produced algorithm wand close target semantic style transfer incorporate accurate segmentation mask sometimes leads wrong semantic match. therefore champandard augments additional semantic channel upon downsampled semantic segmentation map. segmentation either manually annotated semantic segmentation algorithm despite effectiveness mrfbased design choice. instead combining prior chen provide alternative semantic style transfer exploit masking process constrain spatial correspondence also higher order style feature statistic improve result. recently mechrez propose alternative contextual loss realise semantic style transfer segmentation-free manner. model-optimisation-based semantic style transfer. before efﬁciency issue always issue. based iob-nst algorithms therefore leave much room improvement. speed process optimising objective function feature space instead pixel space. speciﬁcally propose feature reconstruction instead image reconstruction previous algorithms optimisation strategy reduces computation burden since loss need propagate deep network. resulting reconstructed feature decoded ﬁnal result trained decoder. since speed reach real-time still room research. instance style transfer. instance style transfer built instance segmentation aims stylise single user-speciﬁed object within image. challenge mainly lies transition stylised object nonstylised background. castillo tackle problem adding extra mrf-based loss smooth anti-alias boundary pixels. doodle style transfer. interesting extension found exploit transform rough sketches artworks. method simply discarding content loss term using doodles segmentation semantic style transfer. stereoscopic style transfer. driven demand ar/vr chen propose stereoscopic algorithm stereoscopic images. propose disparity loss penalise bidirectional disparity. algorithm shown produce consistent strokes different views. portrait style transfer. current style transfer algorithms usually optimised head portraits. impose spatial constraints directly applying existing algorithms head portraits deform facial structures unacceptable human visual system. selim address problem extend head portrait painting transfer. propose notion gain maps constrain spatial conﬁgurations preserve facial structures transferring texture style image. video style transfer. algorithms video sequences substantially proposed shortly gatys al.’s ﬁrst algorithm still images different still image style transfer design video style transfer algorithm needs consider smooth transition adjacent video frames. like before divide related algorithms image-optimisation-based model-optimisation-based video style transfer. image-optimisation-based online video style transfer. ﬁrst video style transfer algorithm proposed ruder introduce temporal consistency loss based optical penalise deviations along point trajectories. optical calculated using novel optical estimation algorithms result algorithm eliminates temporal artefacts produces smooth stylised videos. however build algorithm upon need several minutes process single frame. model-optimisation-based ofﬂine video style transfer. several follow-up studies devoted stylising given video real-time. huang propose augment ruder al.’s temporal consistency loss upon current pspm algorithm. given consecutive frames temporal consistency loss directly computed using corresponding outputs style transfer network encourage pixel-wise consistency corresponding two-frame synergic training strategy introduced computation temporal consistency loss. another concurrent work shares similar idea additional exploration style instability problem found different chen propose subnetwork produce feature incorporate optical information feature space. algorithm built pre-trained style transfer network wraps feature activations pre-trained stylisation encoder using obtained feature ﬂow. character style transfer. given style image containing multiple characters goal character style transfer apply idea generate fonts text effects. atarsaikhan directly apply algorithm font style transfer achieve visually plausible results. yang propose ﬁrst characterise style elements exploit extracted characteristics guide generation text effects. recent work designs conditional model glyph shape prediction also ornamentation network colour texture prephotorealistic style transfer. photorealistic style transfer aims transfer style colour distributions. general idea build upon current semantic style transfer eliminate distortions preserve original structure content image. image-optimisation-based photorealistic style transfer. earliest photorealistic style transfer approach proposed luan propose two-stage optimisation procedure initialise optimisation stylising given photo non-photorealistic style transfer algorithm penalise image distortions adding photorealism regularization. since luan al.’s algorithm built image-optimisation-based semantic style transfer method algorithm computationally expensive. similar another algorithm proposed mechrez also adopts two-stage optimisation procedure. propose reﬁne nonphotorealistic stylised result matching gradients output image content photo. compared algorithm mechrez achieves faster photorealistic stylisation speed. model-optimisation-based photorealistic style transfer. address efﬁciency issue handling problem steps stylisation step smoothing step. stylisation step apply algorithm replace upsampling layers unpooling layers produce stylised result fewer distortions. smoothing step eliminates structural artefacts. aforementioned algorithms mainly designed natural images. another work proposes exploit transfer colour human-designed anime images sketches. algorithm demonstrates promising application photorealistic style transfer automatic image colourisation. attribute style transfer. image attributes generally referred image colours textures etc. previously image attribute transfer accomplished image analogy supervised manner derived idea patch-based liao propose deep image analogy study image analogy domain features. algorithm based patch matching technique realises weakly supervised image analogy i.e. algorithm needs single pair source target images instead large training set. fashion style transfer. fashion style transfer receives fashion style image target generates clothing images desired fashion styles. challenge fashion style transfer lies preservation similar design basic input clothing blending desired style patterns. idea ﬁrst proposed jiang tackle problem proposing pair fashion style generator discriminator. audio style transfer. addition transferring image styles extend domain image style audio style synthesise sounds transferring desired style target audio. study audio style transfer also follows route image style transfer i.e. audio-optimisation-based online audio style transfer claude monet georges rouault henri toulouse-lautrec divan japonais white zags wassily kandinsky trees lane john ruskin ritmo plastico luglio severini gino portrait pablo picasso juan gris landscape saint-r´emy vincent gogh tower babel pieter bruegel elder edith striped dress egon schiele model-optimisation-based ofﬂine audio style transfer. inspired image-based iob-nst verma smith propose audio-optimisation-based online audio style transfer algorithm based online audio optimisation. start noise signal optimise iteratively using backpropagation. improves efﬁciency transferring audio feed-forward manner produce result real-time. evaluation methodology evaluations algorithms remain open important problem ﬁeld. general major types evaluation methodologies employed ﬁeld i.e. qualitative evaluation quantitative evaluation. qualitative evaluation relies aesthetic judgements observers. evaluation results related lots factors quantitative evaluation focuses precise evaluation metrics include time complexity loss variation etc. section experimentally compare different algorithms qualitatively quantitatively. style images select artworks diversiﬁed styles shown figure example impressionism cubism abstract contemporary futurism surrealist expressionism art. regarding mediums artworks painted canvas others painted cardboard wool cotton polyester etc. addition also cover range image characteristics inspired works detailed information style images given table content images already carefully selected well-described benchmark datasets evaluating stylisation mould rosin proposed benchmark called nprgeneral consists images cover wide range characteristics satisfy lots criteria. therefore directly selected twenty images proposed nprgeneral benchmark content images. order cover every detail algorithm provided implementation published literatures. maximise fairness comparison especially speed comparison popular torchbased open source code also admitted authors. experiment except based tensorflow codes implemented based torch since visual effect inﬂuenced content style weight difﬁcult compare results different degrees stylisation. simply giving content style weight optimal solution different ways calculate losses algorithm therefore experiment best balance content style weight among different algorithms. default parameters suggested authors except aforementioned content style weight. although results algorithms improved careful hyperparameter tuning select authors’ default parameters since hold point sensitivity hyperparameters also important implicit criterion comparison. example cannot algorithm effective needs heavy work tune parameters style. also implementation details noted. instance normalisation strategy proposed covered published papers. also consider diversity loss term algorithms i.e. pair content style images corresponds stylised result experiment. chen schmidt’s algorithm feed-forward reconstruction reconstruct stylised results. figure example results iob-nst pspm-mob-nst qualitative evaluation. content images benchmark dataset proposed mould rosin style images public domain. detailed information style images found table figure saliency detection results iob-nst pspm-mob-nst corresponding figure results produced using discriminative regional feature integration approach proposed wang figure example results mspm-mob-nst qualitative evaluation. content images benchmark dataset proposed mould rosin style images public domain. detailed information style images found table figure saliency detection results mspm-mob-nst corresponding figure results produced using discriminative regional feature integration approach proposed wang figure example results aspm-mob-nst qualitative evaluation. content images benchmark dataset proposed mould rosin style images public domain. detailed information style images found table figure saliency detection results aspm-mob-nst corresponding figure results produced using discriminative regional feature integration approach proposed wang results iob-nst. following content style images figure contains results gatys al.’s iobnst algorithm based online image optimisation style transfer process computationally expensive contrast results appealing visual quality. therefore algorithm gatys usually regarded gold-standard method community nst. results pspm-mob-nst. figure shows results per-style-per-model mob-nst algorithms model style. noticed stylised results ulyanov johnson somewhat similar. surprising since share similar idea differ detailed network architectures. results wand results sightly less impressive. since based generative adversarial network extent training process stable. believe gan-based style transfer promising direction already gan-based works ﬁeld nst. results mspm-mob-nst. figure demonstrates results multiple-style-per-model mob-nst algorithms. multiple styles incorporated single model. idea dumoulin al.’s algorithm chen al.’s algorithm small number parameters style. also build algorithm upon architecture therefore surprising results visually similar. although results appealing model size become larger increase number learned styles. contrast zhang dana’s algorithm al.’s algorithm single network trainable network weights multiple styles. model size issue tackled seem interferences among different styles slightly inﬂuences stylisation quality. results aspm-mob-nst. figure presents last category mob-nst algorithms namely arbitrarystyle-per-model mob-nst algorithms. idea onemodel-for-all. globally results aspm slightly less impressive types algorithms. acceptable three-way trade-off speed ﬂexibility quality common research. chen schmidt’s patchbased algorithm seems combine enough style elements content image. algorithm based similar patch swap. lots content patches swapped style patches contain enough style elements target style reﬂected well. ghiasi al.’s algorithm data-driven stylisation quality dependent varieties training styles. algorithm huang belongie propose match global summary feature statistics successfully improve visual quality compared however algorithm seems good handling complex style patterns stylisation quality still related varieties training styles. algorithm replaces training process series transformations. saliency comparison. creation process. indicated deﬁnition style subjective also complex involves personal preferences texture compositions well used tools medium. result difﬁcult deﬁne aesthetic criterion stylised artwork. stylised result different people different even opposite views. nevertheless goal compare results different techniques objectively possible. here consider comparing saliency maps proposed corresponding results shown figure figure figure saliency maps demonstrate visually dominant locations images. intuitively successful style transfer could weaken enhance saliency maps content images change integrity coherence. figure noticed stylised results preserve structures content images well; however might harder observer recognise objects stylisation. using similar analytical method figure preserve similar saliency original content images since small number parameters style. also similar regarding ability retain integrity original saliency maps single network styles. shown figure saliency detection results aspmmob-nst perform better however data-driven methods quality depends diversity training styles. general seems results mspm-mob-nst preserve better saliency coherence aspm-mob-nst little inferior iob-nst pspm-mob-nst. quantitative evaluation regarding quantitative evaluation mainly focus evaluation metrics generating time single content image different sizes; training time single model; average loss content images measure well loss function minimised; loss variation training measure fast model converges; style scalability measure large learned style stylisation speed. issue efﬁciency focus mob-nst algorithms. subsection compare different algorithms quantitatively terms stylisation speed. table demonstrates average time stylise image three resolutions using different algorithms. experiment style images size content images. ﬁfth column table represents number styles model algorithm produce. denotes single model produce multiple styles corresponds mspm algorithms. means single model works style corresponds aspm algorithms. numbers reported table obtained averaging generating time images. note include speed table note ﬁfth column shows number styles single model produce. time excludes includes style encoding process shown since support storing encoded style statistics advance speed stylisation process style different content images. time producing images shown memory limitation. speed similar since share similar architecture. redundantly list table. note represent efﬁcient arbitrary style learning-free visual quality respectively. iob-nst denotes category image-optimisation-based neural style transfer mob-nst represents model-optimisation-based neural style transfer. algorithm scale shift parameters based algorithm johnson time required stylise image using close setting. chen al.’s algorithm since algorithm protected patent make public detailed architecture design attach speed information provided authors reference pascal titan chen schmidt’s algorithm time processing image reported limit video memory. swapping patches images needs video memory thus stylisation process practical. observe except mobnst algorithms capable stylising even high-resolution content images real-time. aspm algorithms generally slower pspm mspm demonstrates aforementioned three-way trade-off again. iterations capable producing enough visually appealing results. outline training time different algorithms reference follow-up studies. nvidia quadro training time single model hours algorithm johnson hours algorithm ulyanov hours algorithm wand hours zhang dana hours chen schmidt’s algorithm huang belongie’s algorithm take much longer acceptable since pretrained model work style. training time depends large training style mspm algorithms training time reduced incremental learning pre-trained model. example algorithm chen needs minutes incrementally learn style reported loss comparison. evaluate mobnst algorithms share loss function compare loss variation training i.e. training curve comparison. helps researchers justify figure training curves total loss style loss content loss different algorithms. solid curves represent loss variation algorithm ulyanov dashed curves represent algorithm johnson different colours correspond different randomly selected styles style set. choice architecture design measuring fast model converges well loss function minimised. compare training curves popular mob-nst algorithms figure since follow-up works based architecture designs. remove total variation term keep objective algorithms. settings also kept same. style images randomly select four styles style represent different colours figure observed algorithms similar terms convergence speed. also algorithms minimise content loss well training mainly differ speed learning style objective. algorithm minimises style loss better. another related criterion compare ﬁnal loss values different algorithms test images. metric demonstrates well loss function minimised using different algorithms. fair comparison loss function settings also required kept same. show results iob-nst algorithm mob-nst algorithms figure result consistent aforementioned trade-off speed quality. although mob-nst algorithms capable stylising images real-time good iob-nst algorithms terms minimising loss function. style scalability. scalability important criterion mspm algorithms. however hard measure since maximum capabilities single model highly related particular styles. styles somewhat similar patterns single model produce thousands styles even more since similar styles share somewhat similar distribution style feature statistics. contrast style patterns vary among different style images capability single model much smaller. hard measure much styles differ style patterns. therefore provide reader reference summarise authors’ attempt style scalability number visually plausible stylised results research many successful industrial applications begun deliver commercial beneﬁts. section summarise applications present potential usages. social communication reason catches eyes academia industry popularity social networking sites e.g. facebook twitter. recently emerged mobile application named prisma ﬁrst industrial applications provide algorithm service. high stylisation quality prisma achieved great success becoming popular around world. applications providing service appeared another began deliver commercial beneﬁts e.g. application ostagram requires users faster stylisation speed. help industrial applications people create paintings share artwork others twitter facebook form social communication. also related application papers introduces pictory combines style transfer techniques image ﬁltering; presents technical implementation details pictory; demonstrates design another gpu-based mobile prosumerfx. application social communication reinforces connections people also positive effects academia industry. academia people share masterpiece comments help researchers improve algorithm. moreover application social communication also drives advances techniques. instance inspired real-time requirements videos facebook research ﬁrst developed mobileembedded deep learning system caffego caffe deep neural networks mobile phones industry application brings commercial beneﬁts promotes economic development. user-assisted creation tools another make user-assisted creation tools. although popular applications applied technique creation tools believe promising potential usage future. creation tool painters designers make convenient painter create artwork particular style especially creating computer-made artworks. moreover algorithms trivial produce stylised fashion elements fashion designers stylised drawings architects variety styles costly creating hand. production tools entertainment applications entertainment applications movies animations games probably application forms nst. example creating animation usually requires painted frames second. production costs largely reduced applied automatically stylise live-action video animation style. similarly signiﬁcantly save time costs applied creation movies computer games. explore redrawing scenes movie named come swim indicates promising potential applications ﬁeld. fiˇser study illumination-guided style transfer algorithm stylisation renderings. demonstrate exploit algorithm rendering previews various geometries autocomplete shading transferring style without reference model. future challenges advances ﬁeld inspiring algorithms already found industrial applications. although current algorithms capable good performance still several challenges open issues. section summarise challenges within ﬁeld discuss possible strategies deal future works. since related critical problems also remain future challenges research nst. therefore ﬁrst review major challenges existing discuss research questions specialised ﬁeld nst. evaluation methodology aesthetic evaluation critical issue nst. ﬁeld necessity aesthetic evaluation explained many researchers e.g. rosin collomosse chapters explore issue. problem increasingly critical ﬁelds mature. pointed researchers need reliable criteria assess beneﬁts proposed approach prior also evaluate suitability particular approach particular scenario. however papers evaluate proposed approach side-by-side subjective visual comparisons measurements derived various user studies example evaluate proposed universal style transfer algorithm conduct user study participants vote favourite stylised results. argue optimal solution since results vary different observers. inspired conduct simple experiment user studies stylised results different algorithms. experiment stylised image rated different raters occupation age. depicted figure given stylised result different observers occupation still quite different ratings. nevertheless currently gold standard evaluation method assessing algorithms. challenge aesthetic evaluation continue open question communities solution might require collaboration professional artists efforts identiﬁcation underlying aesthetic principles. ﬁeld another important issue related aesthetic evaluation. currently standard benchmark image evaluating algorithms. different authors typically images evaluation. experiment carefully selected benchmark image named nprgeneral content images compare different techniques backed comprehensive study however admit selection style images standard benchmark style set. different algorithms explicit restrictions types style images. therefore compare style scalability different methods critical seek benchmark style collectively exhibits broad range possible properties accompanied detailed description adopted principles numerical measurements image characteristics well discussion limitations like works based discussion seeking benchmark image quite separate important research direction provides researchers demonstrate improvement proposed approach prior also tool measure suitability particular algorithm particular requirement. addition emergence several extensions remains another open problem study specialised benchmark data also corresponding evaluation criteria assessing extended works interpretable neural style transfer another challenging problem interpretability algorithms. like many cnn-based vision tasks process like black makes quite uncontrollable. part focus three critical issues related interpretability i.e. interpretable controllable disentangled representations normalisation methods associated adversarial examples nst. representation disentangling. goal representation disentangling learn dimension-wise interpretable representations changes speciﬁc dimensions correspond changes precisely single factor variation invariant factors representations useful variety machine learning tasks e.g. visual concepts learning transfer learning example style transfer could learn representation factors variation precisely disentangled factors could freely controlled stylisation. example could change stroke orientations stylised image simply changing corresponding dimension learned disentangled representation. towards goal disentangled representation current methods categories supervised approaches unsupervised ones. basic idea supervised disentangling methods exploit annotated data supervise mapping inputs attributes despite effectiveness supervised disentangling approaches typically require numbers training samples. however case quite complicated model capture aforementioned factors variation. example hard collect images different stroke orientations exactly colour distribution stroke size stroke composition. contrast unsupervised disentangling methods require annotations; however usually yield disentangled representations dimension-wise uncontrollable uninterpretable i.e. could control would encoded speciﬁc dimension. based discussion acquire disentangled representations ﬁrst issue addressed deﬁne model capture complicated factors variation nst. normalisation methods. advances ﬁeld closely related emergence novel normalisation methods shown table normalisation methods also inﬂuence larger vision community beyond style transfer video colour propagation part ﬁrst brieﬂy review normalisation methods discuss corresponding problem. ﬁrst emerged normalisation method instance normalisation proposed ulyanov instance normalisation equivalent batch normalisation batch size one. shown style transfer network instance normalisation layer converges faster produces visually better results compared network batch normalisation layer. ulyanov believe superior performance instance normalisation results fact instance normalisation enables network discard contrast information content images therefore makes learning simpler. another explanation proposed huang belongie instance normalisation performs kind style normalisation normalising feature statistics instance normalisation style individual image could directly normalised target style. result rest network needs take care content loss making objective easier learn. based instance normalisation dumoulin propose conditional instance normalisation scale shift parameters instance normalisation layers following interpretation proposed huang belongie using different afﬁne parameters feature statistics could normalised different values. correspondingly style individual sample could normalised different styles. furthermore huang belongie propose adaptive instance normalisation adaptively instance normalise content feature style feature statistics believe style individual image could normalised arbitrary styles. despite superior performance achieved instance normalisation conditional instance normalisation adaptive instance normalisation reason behind success still remains unclear. although ulyanov huang belongie propose hypothesis based pixel space feature space respectively lack theoretical proof proposed theories. addition proposed theories also built hypothesises e.g. huang belongie propose interpretation based observation channelwise feature statistics namely mean variance could represent styles. however remains uncertain feature statistics could represent style even whether feature statistics could represent styles relates back interpretability style representations. adversarial examples. several studies shown deep classiﬁcation networks easily fooled adversarial examples generated applying perturbations input images previous studies adversarial examples mainly focus deep classiﬁcation networks. however shown figure adversarial examples also exist generative style transfer networks. figure hardly recognise content originally contained figure reveals difference generative networks human vision system. perturbed image still recognisable humans leads different result generative style transfer networks. however remains unclear perturbations could make difference whether similar noised images uploaded user could still stylised desired style. interpreting understanding adversarial examples could help avoid failure cases stylisation. ﬁeld three-way trade-off speed ﬂexibility quality. iob-nst achieves superior performance quality computationally expensive. pspm-mob-nst achieves real-time stylisation; however pspm-mob-nst needs train separate network style ﬂexible. mspm-mob-nst improves ﬂexibility incorporating multiple styles single model still needs pre-train network target styles. although aspm-mob-nst algorithms successfully transfer arbitrary styles satisfying perceptual quality speed. quality datadriven aspm quite relies diversity training styles. however hardly cover every style great diversity artworks. image transformation based aspm algorithm transfers arbitrary styles learning-free manner behind others speed. another related issue problem hyperparameter tuning. produce visually appealing results remains uncertain value content style weights choose layers computing content style loss optimiser value learning rate. currently researchers empirically hyperparameters; however hyperparameters necessarily work style tedious manually tune parameters combination content style images. keys problem better understanding optimisation procedure nst. deep understanding optimisation procedure would help understand local minima lead high quality. discussions conclusions past several years continued become inspiring research area motivated scientiﬁc challenges industrial demands. considerable amount researches conducted ﬁeld nst. advances ﬁeld summarised figure summary corresponding style transfer loss functions found table quite fast-paced area looking forwarding exciting works devoted advancing development ﬁeld. period preparing review also delighted related researches also bring inspirations areas accelerate development wider vision community. area image reconstruction inspired ulyanov propose novel deep image prior replaces manually-designed total variation regulariser randomly initialised deep neural network. given task-dependent loss function image ﬁxed uniform noise inputs algorithm formulated description ﬁrst proposed style loss based gram-based style representations. widely adopted content loss based perceptual similarity. computing gram loss horizontally vertically translated feature representations. effective modelling style symmetric properties compared gram loss. subtracting mean feature representations computing gram loss. eliminating large discrepancy scale. effective multi-style transfer single network. computing gram loss multi-scale feature representations. eliminating artefacts. gram loss equivalent loss second order polynomial kernel. loss linear kernel capable comparable quality gram loss lower computational complexity. achieving comparable quality gram loss conceptually clearer theory. matching entire histogram feature representations. eliminating instability artefacts compared single gram loss. eliminating distorted structures irregular artefacts. effective content style similar shape perspective compared gram loss. incorporating segmentation mask loss. enabling accurate semantic match. computed based patchgan. utilising contextual correspondence between patches. effective preserving coherent textures complex images compared gram loss. achieving continuous stroke size control preserving stroke consistency. enabling coarse-to-ﬁne stylisation procedure. capable producing large also subtle strokes high-resolution content images. preserving depth maps content images. effective retaining spatial layout structure content images compared single gram loss. designed video style transfer. penalising deviations along point trajectories based optical ﬂow. capable maintaining temporal consistency among stylised video frames. designed stereoscopic style transfer. penalising bidirectional disparity. capable consistent strokes different views. training process mob-nst available image training replacing ltotal words trained overﬁt single sample. inspired upchurch propose deep feature interpolation technique provide baseline area image transformation upon procedure iob-nst algorithm extra step interpolating feature space. algorithm successfully changes image contents learning-free manner. another ﬁeld closely related face photo-sketch synthesis. example exploits style transfer generate shadings textures ﬁnal face sketches. similarly area face swapping idea mob-nst algorithm directly applied build feed-forward face-swap algorithm also provides domain adaption validated work atapour-abarghouei breckon apply style transfer technique translate images different domains improve generalisation capabilities monocular depth estimation model. reﬁne optimise recent algorithms aiming perfectly imitate varieties styles. stage involves technical directions. ﬁrst reduce failure cases improve stylised quality wider variety style content images. although explicit restriction type styles styles particularly good also certain styles weak example typically performs well producing irregular style elements demonstrated many papers however styles regular elements low-poly styles pixelator styles generally produces distorted irregular results property cnnbased image reconstruction. content images previous papers usually natural images content demonstrate proposed algorithms; however given abstract images input content typically combine enough style elements match content since pre-trained classiﬁcation network could extract proper image content abstract images. technical direction ﬁrst stage lies deriving extensions general algorithms. example emergence vision techniques promising study surface stylisation directly optimise produce objects photorealistic non-photorealistic stylisation. moving beyond ﬁrst stage trend imitate human-created techniques rather create form ai-created guidance underlying aesthetic principles. ﬁrst step towards direction taken i.e. using current methods combine different styles. example wang successfully utilise proposed algorithm produce style fuses coarse texture distortions style brush strokes another style image. gooch gooch non-photorealistic rendering. natick peters ltd. strothotte schlechtweg non-photorealistic computer graphics modeling rendering animation. morgan kaufmann rosin collomosse image video-based artistic stylisation. springer science business media vol. gatys ecker bethge image style transfer using convolutional neural networks proceedings ieee conference computer vision pattern recognition efros freeman image quilting texture synthesis transfer proceedings annual conference computer graphics interactive techniques. drori cohen-or yeshurun example-based style synthesis proceedings ieee conference computer vision pattern recognition vol. frigo sabater delon hellier split match example-based adaptive patch sampling unsupervised style transfer proceedings ieee conference computer vision pattern recognition elad milanfar style transfer texture synthesis ieee transactions image processing vol. hertzmann jacobs oliver curless salesin image analogies proceedings annual conference computer graphics interactive techniques. artistic style arxiv e-prints aug. prisma labs prisma turn memories using artiﬁcial intelligence available http//prisma-ai.com ostagram available http//ostagram.ru champandard deep forger paint photos style famous artists available http//deepforger.com kyprianidis collomosse wang isenberg state ‘art’ taxonomy artistic stylization techniques images video ieee transactions visualization computer graphics vol. semmo isenberg d¨ollner neural style transfer paradigm shift image-based artistic rendering? proceedings symposium non-photorealistic animation rendering. gooch coombe shirley artistic vision painterly rendering using computer vision techniques proceedings international symposium non-photorealistic animation rendering. –ff. y.-z. song rosin hall collomosse arty shapes proceedings fourth eurographics conference computational aesthetics graphics visualization imaging. eurographics association efros leung texture synthesis nonparametric sampling proceedings ieee international conference computer vision vol. ieee l.-y. levoy fast texture synthesis using treestructured vector quantization proceedings annual conference computer graphics interactive techniques. press/addison-wesley publishing heeger bergen pyramid-based texture analysis/synthesis proceedings annual conference computer graphics interactive techniques. portilla simoncelli parametric texture model based joint statistics complex wavelet coefﬁcients international journal computer vision vol. generating images perceptual similarity metrics based deep networks advances neural information processing systems goodfellow pouget-abadie mirza wardefarley ozair courville bengio generative adversarial nets advances neural information processing systems tian seah feature guided texture synthesis artistic style transfer proceedings international conference digital interactive media entertainment arts. wang demystifying neural style transfer proceedings twenty-sixth international joint conference artiﬁcial intelligence ijcai- available https//doi.org/./ijcai./ risser wilmot barnes stable controllable neural texture synthesis style transfer using histogram losses arxiv e-prints jan. t.-s. chua laplacian-steered neural style transfer proceedings multimedia conference. wand combining markov random ﬁelds convolutional neural networks image synthesis proceedings ieee conference computer vision pattern recognition johnson alahi fei-fei perceptual losses realtime style transfer super-resolution european conference computer vision ulyanov vedaldi lempitsky improved texture networks maximizing quality diversity feed-forward stylization texture synthesis proceedings ieee conference computer vision pattern recognition ghiasi kudlur dumoulin shlens exploring structure real-time arbitrary neural artistic stylization network proceedings british machine vision conference gatys ecker bethge hertzmann shechtman controlling perceptual factors neural style transfer proceedings ieee conference computer vision pattern recognition wang oxholm zhang y.-f. wang multimodal transfer hierarchical deep convolutional neural network fast artistic style transfer proceedings ieee conference computer vision pattern recognition doodles artworks arxiv e-prints mar. feng jing song finer-net cascaded human parsing hierarchical granularity proceedings ieee international conference multimedia expo. ieee zhang dana zhang wang tyagi agrawal context encoding semantic segmentation proceedings ieee international conference computer vision pattern recognition. zhao chen zhang decoder network lightweight reconstructed feature fast semantic style transfer proceedings ieee international conference computer vision castillo singh yadav goldstein zorn’s lemma targeted style transfer using instanceaware semantic segmentation ieee international conference acoustics speech signal processing. ieee weinzaepfel revaud harchaoui schmid deepﬂow large displacement optical deep matching proceedings ieee international conference computer vision. ieee revaud weinzaepfel harchaoui schmid epicﬂow edge-preserving interpolation correspondences optical proceedings ieee conference computer vision pattern recognition gupta johnson alahi fei-fei characterizing improving stability neural style transfer proceedings ieee international conference computer vision atarsaikhan iwana narusawa yanai uchida neural font style transfer proceedings iapr international conference document analysis recognition vol. yang lian awesome typography statistics-based text effects transfer proceedings ieee conference computer vision pattern recognition azadi fisher wang shechtman darrell multi-content few-shot font style transfer proceedings ieee conference computer vision pattern recognition zhang style transfer anime sketches enhanced residual u-net auxiliary classiﬁer proceedings asian conference pattern recognition liao yuan kang visual attribute transfer deep image analogy transactions graphics vol. jiang fashion style generator proceedings international joint conference artiﬁcial intelligence. aaai press mould rosin benchmark image evaluating stylization proceedings joint symposium computational aesthetics sketch based interfaces modeling nonphotorealistic animation rendering. eurographics association developing applying benchmark evaluating image stylization computers graphics vol. wang jiang yuan m.-m. cheng zheng salient object detection discriminative regional feature integration approach. international journal computer vision vol. rosin mould berger collomosse y.-k. shamir wand wang winnem¨oller benchmarking non-photorealistic rendering portraits proceedings symposium non-photorealistic animation rendering. t.-y. maire belongie hays perona ramanan doll´ar zitnick microsoft coco common objects context european conference computer vision. springer neural-style j.-y. park isola efros unpaired image-toimage translation using cycle-consistent adversarial networks proceedings ieee conference computer vision pattern recognition deepart available https//deepart.io/ ¨urschmid s¨ochting semmo trapp d¨ollner prosumerfx mobile design image stylization components siggraph asia mobile graphics interactive applications. gooch long estey gooch viewing progress non-photorealistic rendering heinlein’s lens proceedings international symposium nonphotorealistic animation rendering. hertzmann non-photorealistic rendering science proceedings international symposium nonphotorealistic animation rendering. mould authorial subjective evaluation non-photorealistic images proceedings workshop non-photorealistic animation rendering. isenberg neumann carpendale sousa jorge non-photorealistic rendering context observational study proceedings international symposium nonphotorealistic animation rendering. bengio courville vincent representation learning review perspectives ieee transactions pattern analysis machine intelligence vol. mnih disentangling factorising interna feng yang jing jiang song interpretable partitioned embedding customized multi-item fashion outﬁt composition proceedings international conference multimedia retrieval. higgins sonnerat matthey burgess botvinick hassabis lerchner scan learning abstract hierarchical compositional visual concepts international conference learning representations bouchacourt tomioka nowozin multi-level variational autoencoder learning disentangled representations grouped observations aaai conference artiﬁcial intelligence higgins matthey burgess glorot botvinick mohamed lerchner beta-vae learning basic visual concepts constrained variational framework international conference learning representations szegedy zaremba sutskever bruna erhan goodfellow fergus intriguing properties neural networks international conference learning representations upchurch gardner pleiss pless snavely bala weinberger deep feature interpolation image content changes proceedings ieee conference computer vision pattern recognition atapour-abarghouei breckon real-time monocular depth estimation using synthetic data domain adaptation image style transfer proceedings ieee conference computer vision pattern recognition chen k.-y. wong face sketch synthesis style transfer using pyramid column feature ieee winter conference applications computer vision. lake tahoe gerstner decarlo alexa finkelstein gingold nealen pixelated image abstraction proceedings symposium non-photorealistic animation rendering. eurographics association", "year": "2017"}