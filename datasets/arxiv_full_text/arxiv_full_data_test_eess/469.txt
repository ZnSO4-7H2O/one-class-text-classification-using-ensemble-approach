{"title": "BachProp: Learning to Compose Music in Multiple Styles", "tag": "eess", "abstract": " Hand in hand with deep learning advancements, algorithms of music composition increase in performance. However, most of the successful models are designed for specific musical structures. Here, we present BachProp, an algorithmic composer that can generate music scores in any style given sufficient training data. To adapt BachProp to a broad range of musical styles, we propose a novel normalized representation of music and train a deep network to predict the note transition probabilities of a given music corpus. In this paper, new music scores sampled by BachProp are compared with the original corpora via crowdsourcing. This evaluation indicates that the music scores generated by BachProp are not less preferred than the original music corpus the algorithm was provided with. ", "text": "hand hand deep learning advancements algorithms music composition increase performance. however successful models designed speciﬁc musical structures. here present bachprop algorithmic composer generate music scores style given sufﬁcient training data. adapt bachprop broad range musical styles propose novel normalized representation music train deep network predict note transition probabilities given music corpus. paper music scores sampled bachprop compared original corpora crowdsourcing. evaluation indicates music scores generated bachprop less preferred original music corpus algorithm provided with. search computational creativity frontier machine learning algorithms present creative domains painting music already lovelace predicted potential analytical engines algorithmic music composition current methods include rule based approaches genetic algorithms markov models recently artiﬁcial neural networks ﬁrst artiﬁcial neural networks applied music composition recurrent neural network trained generate monophonic melodies long short-term memory networks introduced ﬁrst applied music composition generate blues monophonic melodies constrained brain-mind institute school life sciences ´ecole polytechnique f´ed´erale lausanne lausanne switzerland school computer communication sciences ´ecole polytechnique f´ed´erale lausannee lausanne switzerland. correspondence florian colombo <ﬂorian.colomboepﬂ.ch>. chord progressions since then music composition algorithms employing lstm units used generate monophonic melodies folk music chorales harmonized style bach however algorithms make strong assumptions structure music modeled. example designed monophonic melodies only. generate monophonic melodies simple chords ﬁxed rhythm. works focused task harmonization style bach therefore designed algorithms exhibit inductive bias toward structure chorales. addition require preprocessing data cannot easily adapted music data automatized way. here present neural composer algorithm named bachprop designed generate music scores style. assume speciﬁc musical structure data except composed sequences notes musical instrument digital interface symbolic notation music designed record digital synthesizers. midi ﬁles potentially inﬁnitely many different ways representing music score especially rhythm developed novel normalized representation music applied midi sequences minimal distortion. bachprop generative model music scores learns musical structure midi sequences. normalized midi representation together architecture training generation methods presented paper bachprop able create music scores composition structures extracted relatively large data set. piece last arbitrary time exhibits well-deﬁned consistent features. example trained string quartets mozart haydn bachprop generate music scores mimicking composers’ style unique mood. thanks normalized representation midi sequences bachprop trained data sets previously unused deep learning algorithms recordings bach keyboard works john sankey digital keyboard. rare data sets bach chorales note duration multiple base duration cannot applied midi sequences without distorting rhythms. method described illustrated figure allows represent every midi term sequence notes controlled rhythmic environment. similar approaches taken monophonic melodies midi higher level music notation languages notation midi contains header possibly multiple tracks deﬁned sequence midi messages. bachprop interested midi messages deﬁning note pressed released midi precise timing event encoded relatively previous event consequence every midi message shares common attribute represents number ticks separates message previous. midi ticks natural numbers directly relate time. example midi sequence beats minute pulses quarter notes duration tick towards normalized representation music ﬁrst step involves parsing list messages extract note events. then merge consecutive events involving note pitch translate sequence midi messages sequence notes addition transform midi tick durations quarter note durations resulting sequence notes note represented midi designed record live performances digital keyboards many midi ﬁles exhibit expressive rhythmic freedom leads small variations around actual duration note standard music notation. addition midi sequences internet created many different softwares figure normalized midi representation. illustration steps involved proposed encoding midi sequences. using sets deﬁnes possible durations pitches midi sequence translated sequence notes three features timing duration pitch section present motivate normalized midi representation. section introduces bachprop’s neural network along training generation procedures. section analyze predictive generation performance bachprop data sets different levels heterogeneity musical structure. finally discuss present challenge designed compare music generated automated human composers section midi protocol designed digital synthesizers. standard music notation symbolic representation music. however designed record play back rather write scores standard music composition softwares musescore difﬁculties correctly consistently translate content midi ﬁles standard music notation. difﬁculty lies determining pitch note inferring correct sequence durations terms commonly used notation rhythm solve problem normalizing midi sequences shared dimensional representation. section normalized music score input deep lstm network. several approaches represent polyphonic midi sequences neural networks. encoding methods discretize time frames ﬁxed duration representation works figure neural network architecture. schematic bachprop network architecture. blocks lstm units connected feedforward structure block contains fully connected lstm units indicated. feedforward connections dropout probability output layer depicted softmax operator output units used represent probability possible realisation next note feature illustration input output vectors. list three input vectors order time step vectors one-hot encoding corresponding note feature. network trained approximate transition probabilities hidden state recurrent units. arrows depict linear transformation input neural network figure result operation output vectors note procedure cycles substeps predict timing duration pitch representing standard music durations. therefore perform ﬁnal normalization step towards low-dimensional encoding midi sequences. timings durations possible note lengths expressed fractions multiples quarter notes similar durations standard music notation softwares. mapping closest value removes temporal jittering around original note duration. result constrained discrete values. bachprop generative model midi sequences. combines normalized midi representation recurrent neural network architecture speciﬁc inputs outputs time step parameter optimization procedure ﬁnally method generate music scores trained model. used deep lstm network three consecutive layers schematized figure network’s task infer probability distribution next possible notes representation current note network’s internal state facilitate gradient propagation added skip connections. note employ units melody rhythm western music exists dependence note duration rhythm. reason unrolled time predictions timing duration pitch. particular prediction upcoming pitch conditioned current note also upcoming timing duration underlying probability distributions modeled artiﬁcial neural network bachprop detailed next section. recurrent neural network history events represented hidden state recurrent units. consequently output network time steps linear transform input representation note event hidden state. output used predict next note event. importantly probability event corresponds joint probability three features event timing duration pitch consider timing duration sets entries pitch containing piano keys joint distribution dimensions. reduce space account relationship note timing duration pitch features split joint probability three features event product conditional probabilities words predict pitch note choosing timing duration. network architecture implement idea splitting time step three substeps effectively timing distribution r|note) read ﬁrst substep input representation previous note. then probability distribution r|note read second substep upcoming timing provided timig input finally pitch probability distribution r|note read ﬁnal substep upcoming timing duration provided inputs. training timing duration upcoming notes known generation sample probability distributions proceed three substeps. artiﬁcial network bachprop trained approximate probability distributions shown figure achieve this perform consecutive rounds training epoch songs training corpus presented network. backpropagation time applied compute error signal. parameter updates performed batches songs adam optimizer loss function. prevent exploding gradients clip norm gradient evaluate backpropagation signal sequences consecutive notes. network hidden state reset beginning songs only. epoch evaluate predictive performance network remaining original music corpus. parameters maximized accuracy saved optimal parameters. using design conditional distributions read used different substep corresponding feature however network trained approximate distributions already time steps before. effectively learning representation hints toward desired output. taking pitch prediction example network trained predict upcoming pitch based ﬁrst last note event only additionally knowing relative timing ﬁnally based duration well. therefore network tracks temporal structure notes also relationship features constituting notes. order bachprop learn tonality transposition invariance music randomly transpose song beginning every training epoch within available bounds pitch set. words song compute possible shifts semitones sample applied offset pitches song. single midi sequence transposed offsets augmentation method allows bachprop learn temporal structure music examples. trained output probabilities neural network sampled select upcoming note generated bachprop. start randomly selecting ﬁrst note feed network iteratively sample network output probabilities corresponding time step substep generated note given input network next time step. resulting sequence notes representation easily translated back midi sequence reversing method schematized figure except jitter. sample probability distributions constrain possible realizations likely ones. nonetheless probability choosing likely outcomes weighted relative probabilities realizations. sampling method motivated ﬁnding human decisions likely based probable outcomes rather full probability distributions meta parameter tuned desired exploration/exploitation ratio. corresponds sampling temperatures leads generation periodic short motifs probably dynamics model entering limit cycle. then bigger explorative generated midi sequences. empirical parameter tuning authors believe good tradeoff exploitation exploration. applied bachprop midi sequences corpora different musical structures styles nottingham database contains british american folk tunes. musical structure songs similar melody simple chords. chorales corpus includes hundreds four-part chorales harmonized bach. every chorale shares common structures number voices rhythmical patterns. therefore figure accuracy prediction generation. accuracy predictions made bachprop unseen data three features data sets. accuracy fraction correct predictions entire song. mean standard deviation accuracy computed validation set. prediction generation pitch sequence bachprop. greyscale shown network output time step bachprop predicting upcoming pitch bach chorales. time step stars correspond pitches bachprop sampled network output distributions. selection active pitches shown. consider nottingham chorales corpora homogeneous data sets. john sankey data collection midi sequences recorded john sankey digital keyboard. sequences include works bach across corpus pieces rather different. addition data recorded live digital keyboard thus temporal information needs normalization efﬁcient learning. string quartets data includes string quartets haydn mozart. again large heterogeneity pieces across corpus. last bach corpus contains bach pieces present dave’s j.s. bach page. includes many different pieces solo organ works cello suites. artiﬁcial neural network trained using procedure described section corpus independently. model architecture number neurons hyper parameters identical data sets. bachprop tuned particular corpus considered universal algorithm music composition. observe saturation accuracies training validation sets less epochs datasets. accuracies epochs presented figure observe predictive performances bachprop scales structure complexity. homogeneous corpora many examples similar structures bachprop predict notes accuracies high timing duration pitch. heterogeneous data sets performances decrease respectively. illustrate prediction generation performed figure shows pitch output bachprop’s note transition model. however statistics inform quality music scores bachprop generates. following sections discuss results bachprop music scores generated trained networks. renderings note sequences generated bachprop available listening webpage containing media paper. results bachprop trained corpora. length song inﬁnite without losing coherence illustrated online examples media webpage. encourage readers listen examples convince ability bachprop generate unique heterogeneous music scores. better comparison examples rendered using digital instrument. addition also included examples original data sets. professional musicians reported music scores imagined bachprop pleasant listen. even predictive performance bachprop lower bach data bachprop able produce convincing coherent music pieces key. figure results crowdai challenge automated music composition. top-rated midi submission shown. score computed basis pairwise comparisons midi submissions using trueskill rating method. submissions music scores generated bachprop random selection midi ﬁles original corpora corpus bachprop trained written brackets. stands submissions coming algorithms bachprop. seven extracts submissions highlighted chosen performed live string quartet. audience asked select preferred extract. percentages boxes result individual votes. subject single vote indicate piece he/she liked best. music scores generated bachprop evaluated crowdai platform part ai-generated music challenge. challenge designed rate midi ﬁles generated different algorithms. human evaluators asked give preference seconds extracts hour long midi sequences generated music models. challenge included control submissions well midi generated participants. scores submissions computed using trueskill rating system trueskill computes score submission ensuring toprated submissions highly preferred high certainty. results evaluation presented figure controls apart top-rated submissions generated bachprop. surprisingly trueskill scores original music corpora undistinguishable music generated bachprop corpora. finally selection seven extracts top-rated submissions arranged string quartet performed live. performance audience asked select preferred music piece. video performance available readers media webpage. votes shown figure revealed strong preference music scores generated bachprop trained respectively nottingham string quartets data set. additional validation evaluation protocol observe votes live performance ratings challenge consistent across competitions. paper presented bachprop algorithm general automated music composition. generative model music scores able compose style provided examples style. conducted evaluation survey revealed music generated bachprop less preferred music coming original corpus bachprop trained. central method bachprop capacity represent midi sequences dimensional space. developed representation automatically applied midi sequences even ones recorded live performances. allows bachprop trained many data sets potentially every possible midi sequences. finally bachprop shown able learn many different musical structures heterogeneous corpora create music scores according extracted structures. directions authors propose explore repetitions feature inherent music better modeled algorithms. believe feature improving neural models music composition. thank johanni brea samuel muscinelli helpful discussions marcel salath´e sharada prasanna mohanty crowdai challenge. financial support provided ´ecole polytechnique f´ed´erale lausanne. references boulanger-lewandowski nicolas bengio yoshua vincent pascal. modeling temporal dependencies high-dimensional sequences application polyphonic music generation transcription. proceedings international conference machine learning fram. deep artiﬁcial composer creative neural network model automated melody generation. international conference evolutionary biologically inspired music springer douglas schmidhuber juergen. finding temporal structure music blues improvisation lstm recurrent networks. proceedings ieee workshop neural networks signal processing ieee gatys leon ecker alexander bethge matthias. image style transfer using convolutional neural networks. computer vision pattern recognition ieee conference ieee hadjeres ga¨etan pachet franc¸ois nielsen frank. deepbach steerable model bach chorales generation. proceedings international conference machine learning volume proceedings machine learning research pmlr sturm santos joao felipe ben-tal oded korshunova iryna. music transcription modelling composition using deep learning. conference computer simulation musical creativity", "year": "2018"}