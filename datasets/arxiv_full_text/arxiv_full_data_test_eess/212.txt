{"title": "Multiple Instance Deep Learning for Weakly Supervised Small-Footprint  Audio Event Detection", "tag": "eess", "abstract": " State-of-the-art audio event detection (AED) systems rely on supervised learning using strongly labeled data. However, this dependence severely limits scalability to large-scale datasets where fine resolution annotations are too expensive to obtain. In this paper, we propose a small-footprint multiple instance learning (MIL) framework for multi-class AED using weakly annotated labels. The proposed MIL framework uses audio embeddings extracted from a pre-trained convolutional neural network as input features. We show that by using audio embeddings the MIL framework can be implemented using a simple DNN with performance comparable to recurrent neural networks.  We evaluate our approach by training an audio tagging system using a subset of AudioSet, which is a large collection of weakly labeled YouTube video excerpts. Combined with a late-fusion approach, we improve the F1 score of a baseline audio tagging system by 17%. We show that audio embeddings extracted by the convolutional neural networks significantly boost the performance of all MIL models. This framework reduces the model complexity of the AED system and is suitable for applications where computational resources are limited. ", "text": "settings also usually sporadic corrupted noise. previous works relied training models using supervised learning paradigm requires strongly labeled data however given difﬁculty high resource requirement annotating large datasets datasets publicly available often limited size motivated this many recent works explored weakly labeled data training systems. successful approach transform audio time-frequency representations apply convolutional recurrent neural network classify entire clip methods however unsuitable real-time applications recurrent subsequent pooling layers require full clip parsed decision made. addition complexity computation time models quite high. another approach learning weak labels treat segments audio clip instances apply multiple instance learning model assumes independent labels instance accounts uncertainty weak labels assigning positive label least positive instance. evidently paradigm suitable portable applications classiﬁer applied individual instances ideal real-time operation. work propose enhance framework multi-class using convolutional audio embeddings. different prior works proposed architecture addresses issue building complexity models small footprint real-time applications. propose audio embeddings input features show using pre-trained embeddings model implemented simple architecture. audio embeddings also signiﬁcantly improves accuracy compared random initialization. proposed architecture removes need complex structures recurrent layers drastically reduces model complexity suitable portable applications computational resource real-time requirements. task detecting audio events using weakly labeled training data formulated multiple instance learning problem labels assigned bags instances without explicitly specifying relevance label individual instances. known instances within contribute label. applying framework task view audio clip instances {xij} instance audio segment shorter durastate-of-the-art audio event detection systems rely supervised learning using strongly labeled data. however dependence severely limits scalability large-scale datasets resolution annotations expensive obtain. paper propose small-footprint multiple instance learning framework multi-class using weakly annotated labels. proposed framework uses audio embeddings extracted pre-trained convolutional neural network input features. show using audio embeddings framework implemented using simple performance comparable recurrent neural networks. evaluate approach training audio tagging system using subset audioset large collection weakly labeled youtube video excerpts. combined latefusion approach improve score baseline audio tagging system show audio embeddings extracted convolutional neural networks signiﬁcantly boost performance models. framework reduces model complexity system suitable applications computational resources limited. index terms audio event detection weakly-supervised learning multiple instance learning increasingly devices various settings equipped auditory perception capabilities. inclusion acoustic signals extra modality brings robustness system offers improved performance many tasks. beneﬁt attributed omnidirectional nature acoustic signals provides valuable detecting events various applications. example analyzed audio signals monitor conditions industrial tools water leakage detection system using sound recordings water pipes proposed. systems able real-time lower cost capturing audio much less expensive distributing specialized physical sensors throughout environment. addition acoustic signals provide informational cues hard cannot captured modalities. common example detection alarms sirens driving scenario smart cars. often sources warning sounds visually occluded events detectable using auditory perception many applications also requirement real-time operation using computational resources. major challenge since unlike human speech environmental sounds much diverse span wider range frequencies. audio events occur tion. assign labels clip label {yin} indicates presence audio event goal problem classify labels unseen bags given label pairs training data. work implement framework using neural networks. implementation generate instances segmenting audio clip non-overlapping -second segments taking time-frequency representations. segment size chosen balance number total instances coverage audio events. frame size shift short-time fourier transform integrate power spectrogram mel-spaced frequency bins. log-transform applied spectrogram. also ﬁrst delta additional input channel. since spectrogram viewed image employ convolutional layers feature extraction. reference architectures proven good performance ﬁeld computer vision. speciﬁcally ﬁrst three conv groups vgg- fully-connected layers size batch normalization added convolutional layer. relu activation function used layers. goal multi-label system apply sigmoid activation function view outputs independent posterior probability estimates class. reduced version full model exploring compact models portable applications subset dataset contain enough samples train large models without overﬁtting. obtain prediction entire adopt na¨ıve approach assign label maximum scoring instance bag. motivation behind part fact since instances continuous audio clip i.i.d. many algorithms applicable however approach still beneﬁcial allows train instance classiﬁer applied real-time scenario. order address class imbalance apply weight loss proportional inverse frequency class. back-propagation gradient maximally scoring instance calculated used updating weights. interesting fact class pooling layer errors originate different instances classes. figure shows architecture proposed framework using cnn. identify important instances similar expectation maximization approach. however possible issues result model. ﬁrst methods system performance highly depends initialization point. initialization point model chooses wrong instance indicative class label optimizes irrelevant input. types errors would hard recover high variation individual audio event. second issue using pooling layer instances back-propagation propagate maximum scoring instance. result instances ignored training. focus relevant instances central idea greatly reduces robustness noise occurs intermittently audio. propose pre-trained audio embeddings alleviate issues. using audio embeddings features postulate audio events well noise conditions better represented improve performance framework. similar generate audio embeddings training give frame-wise predictions clip label. input features -bin log-mel spectrograms computed -second segments audio short-time fourier transform. clip label targets -second segments audio clip. outputs penultimate layer extracted used input framework. structure described previous section additional fully-connected layer size generate ﬁnal audio embedding. since frame-wise training instances results badly labeled data ﬁnal model selection embedding crucial generating meaningful embeddings. maximum frame-wise predictions predicted clip label select model best performance clip-level using held-out validation data. ﬁnal system similar architecture milcnn uses audio embeddings features instance. convolutional layers replaced fully-connected layers longer deal images. best performing system four hidden layers using relu activation function layer sizes ﬁnal architecevaluated models using subset google’s audioset audioset extensive collection -second youtube clips annotated large number audio events. dataset contains audio event classes million sound clips however proof concept refer subset released dcase challenge challenge subset contains audio event classes divided categories warning vehicle sounds. audio events highly focused transportation scenarios primed towards evaluating systems self-driving cars smart cities related areas. subset contains samples around hours audio. class names number samples class shown table main challenge dataset noisiness youtube data. clips user submitted mostly recorded using consumer devices real life environments audio events often far-ﬁeld corrupted variety noise including human speech music wind noise etc. another challenge variability audio events. even within class characteristic audio event vary drastically. example different types sirens different regions would make hard differentiate ambulance truck sirens. short possible label type encompasses possible global variations category. finally number samples class also highly imbalanced subset dataset. imbalance ratio least occurring occurring class issue alleviated machine learning techniques inherent shortage information minority classes result generalization classes. experiments used cross entropy loss function adam optimizer perform weight updates. handle class imbalance loss function weighted inversely proportional number samples class. model selection embedding adopted clip-level validation scheme. posterior class probabilities averaged instances clip model best clip tagging accuracy selected generate audio embeddings. compared framework baseline dcase challenge best f-score achieved system using architecture two-fold cross-validation setup using audio embeddings features classiﬁer performance improved absolute improvement dcase baseline. compared framework classiﬁer replaced -layer bi-lstm found results comparable dnns. also applied late-fusion models different hyper-parameters using weighted majority voting scheme improved f-score weights voting scheme based model validation accuracy. finally show performance framework improves using embeddings audioset. embeddings part audioset trained architecture using youtube-m dataset table shows performance parameter number different models. confusion matrix proposed system shown figure although high confusability class imbalance labels system still able distinguish classes relative accuracy. work proposed small-footprint multiple instance learning framework using deep neural networks audio event detection trained using large-scale weaklysupervised data. showed using pre-trained audio embeddings achieve good performance simple model framework. audio embeddings extracted trained give frame-wise predictions weakly labeled data. performance poor embeddings generated model used features drastically improve performance framework. improvements achieved using embeddings audioset trained data additional labels. postulate audio embeddings data acoustically meaningful high-dimensional space indicative audio events. using embeddings achieve good trade-off model size performance. future work hope apply model entire audioset truly large-scale weakly-supervised framework. introduction additional data well class labels expect audio embeddings contain richer representations improve performance smart cars. seyoum alfonso andel koole groenewegen giesen shazam-like household water leakage detection method proc. xviii int. conf. water distribution syst. vol. supplement schr¨oder goetze gr¨utzmacher anem¨uller automatic acoustic siren detection trafﬁc noise part-based models proc. ieee int. conf. acoustics speech signal process. dikmen mesaros sound event detection using nonnegative dictionaries learned annotated overlapping events proc. ieee workshop applications signal process. audio acoustics parascandolo heittola huttunen virtanen convolutional recurrent neural networks polyphonic sound event detection ieee/acm trans. audio speech language process. vol. achieves single-model f-score fair comparison would models without recurrent layers f-score even direct comparison limited value proposed method mainly aims address major issues deploying real-life scenarios model complexity real-time operation. proposed method reduces model complexity removing need recurrent layers suitable applications computational resources limited. similar performance conditions system using reduces number parameters factor almost compared -layer bi-lstm rnn. terms evaluation runtime model also times faster rnns. model able handle samples second compared samples using nvidia gtx- gpu. addition using independent instance classiﬁers system able real-time give running predictions audio events. property crucial applying smart cars events sirens horns detected soon occur. recurrent networks even cnns requiring full length inputs mode operation would possible. finally shown gain performance audioset embeddings system easily improved transfer learning sound events. interesting observation experiments joint optimization pre-trained embedding loss improve performance much random initialization. shows audio embeddings already contain rich acoustic information trained task-independent manner. separation embedding classiﬁer training means take advantage additional labels largescale weakly-supervised data learn embeddings independently. however also observed selection embedding model pivotal ﬁnal system performance embeddings useful. hershey chaudhuri ellis gemmeke jansen moore plakal platt saurous seybold slaney weiss wilson architectures large-scale audio classiﬁcation proc. ieee int. conf. acoustics speech signal process. gemmeke ellis freedman jansen lawrence moore plakal ritter audio ontology human-labeled dataset audio events proc. ieee int. conf. acoustics speech signal process. abu-el-haija kothari natsev toderici varadarajan vijayanarasimhan youtube-m large-scale video classiﬁcation benchmark arxiv preprint vol. abs/. s.-y. chou j.-s. jang y.-h. yang framecnn weaklysupervised learning framework frame-wise acoustic event detection classiﬁcation dcase challenge tech. rep. september", "year": "2017"}