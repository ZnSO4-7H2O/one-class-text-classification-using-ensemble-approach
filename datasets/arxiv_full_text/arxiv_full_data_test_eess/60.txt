{"title": "Finding phonemes: improving machine lip-reading", "tag": "eess", "abstract": " In machine lip-reading there is continued debate and research around the correct classes to be used for recognition. In this paper we use a structured approach for devising speaker-dependent viseme classes, which enables the creation of a set of phoneme-to-viseme maps where each has a different quantity of visemes ranging from two to 45. Viseme classes are based upon the mapping of articulated phonemes, which have been confused during phoneme recognition, into viseme groups. Using these maps, with the LiLIR dataset, we show the effect of changing the viseme map size in speaker-dependent machine lip-reading, measured by word recognition correctness and so demonstrate that word recognition with phoneme classifiers is not just possible, but often better than word recognition with viseme classifiers. Furthermore, there are intermediate units between visemes and phonemes which are better still. ", "text": "high level overview method shown figure described begin performing word recognition using classiﬁers based upon phoneme labels. provides baseline benchmark crucially confusion matrices speaker used cluster together potential monophones. however undertake different clustering process make mapping time phoneme re-classiﬁed viseme grouping thereby deriving maps speaker. classiﬁers used repeat word recognition task. word recognition performance measure normalises variance training samples classiﬁers. note performance relevant here rather improvement variance classes provide. reader also note suggesting clustering process deliver optimum visemes rather address need case method enable controlled comparison visemes. implement -fold cross-validation replacement sentences speaker randomly selected test samples included training folds. using toolkit hidden markov model classes ﬂat-start hmms re-estimate times forced alignment seventh eighth estimates. prototype based upon gaussian mixture components three state hmms. single-state tied shortpause ‘sp’ short silences words sentence utterances. also bigram word network support recognition. maximum phonemes within phoneme recognition results speakers used phonemes within speech utterances. cluster phonemes visemes classes follows; confusion matrices speaker summed together form confusion matrix representing confusions speaker. start phoneme confusion matrix paper structured approach devising speaker-dependent viseme classes enables creation phoneme-to-viseme maps different quantity visemes ranging viseme classes based upon mapping articulated phonemes confused phoneme recognition viseme groups. using maps lilir dataset show effect changing viseme size speaker-dependent machine lip-reading measured word recognition correctness demonstrate word recognition phoneme classiﬁers possible often better word recognition viseme classiﬁers. furthermore intermediate units visemes phonemes better still. index terms visual-only speech recognition computer lipreading visemes classiﬁcation pattern recognition although visemes formally deﬁned many possibilities found across literature deﬁnition viseme visual representative subset phonemes lips. therefore viseme classiﬁers inherently smaller phoneme classiﬁers. whilst means training samples class also introduces generalisation articulated sounds. optimal viseme classes need minimise generalisation order maximise recognition correct utterances also maximise data available. relationship phonemes visemes described phoneme-to-viseme maps. shown maps derived automatically phoneme confusions. by-product method control many visemes need. allows considerable precision answering questions optimal number nature visemes. selected dataset lilir data consists british speakers utterances speaker resource management context independent sentences totals around words. original videos recorded high deﬁnition full-frontal position. individual speakers tracked using active appearance models extract features concatenated shape appearance information. phonemes /ax/ /oy/ /zh/ /th/ /jh/ /ch/ /dh/ /sh/ /hh/ /ng/ /ea/ /ae/ /ao/ /uw/ /oh/ /ia/ /ey/ /ua/ /er/ /ay/ /aa/ /ah/ /aw/ /uh/ /ow/ /ih/ /iy/ /az/ /eh/ time around viseme classes recognizers. using sets classes shown step confusing lips perform recognition class set. total smallest classes largest classes phoneme repeat phoneme recognition task using phonemes know identiﬁable. probability that given classiﬁcation phoneme really subscript indicates elements merge phonemes looking confused phonemes hence create class confusions pm−. phonemes assigned classes vowels consonants. vowels consonants mixed. pair highest merged. equal scores broken randomly. process repeated intermittent step forms possible visual units. formal approach used incorporates conclusions vowel consonant phonemes clustered together devising phoneme-toviseme mappings. example mapping shown table similar step implement -fold cross-validation replacement sentences speaker randomly selected test samples included training folds. using toolkit hidden markov model classes ﬂat-start hmms re-estimate times forced alignment seventh eighth estimates. figure show correctness speakers. viseme sets containing fewer visemes produce viseme strings represent word homophones. example homophone data words ‘port’ ‘bass’. using speaker -viseme become i.e. single identiﬁer identifying words. thus distinguishing ‘port’ ‘bass’ becomes impossible. effect seen left side graphs figure although correctness scores signiﬁcantly chance. results speaker vary overall trend clear. superior performances found larger numbers visemes. note that reported viseme error effect visible imperative large numbers visemes would missed. also figure class sets highlighted labelled show particular combination previous viseme classes delivers signiﬁcant improvement recognition. combinations listed table whilst apparent pattern pairings reinforce knowledge speakers visually unique difﬁcult ﬁnding cross-talker viseme sets different phonemes require alternative grouping arrangements individual. assert better lip-reading achieved phonemes visemes. true that generally speaking larger numbers visemes out-perform smaller numbers curves figure monotonic. even figure mean performance speakers monotonic. number proposed phoneme-to-viseme maps literature typically generate visemes summary) well known consonant visemes vowels jeffers eight three looking figures certainly rapid drop-off performance fewer visemes region contains optimum viseme three speakers chance. words speaker optimal number visual units factors play graphs underlying accuracy visual units represent mouth shape appearances versus introduction homophones. large numbers visemes close phonetic recognition risk visual units visually distinctive several models match particular sub-sequence. latter problem creates decoding lattice several near equal probability paths which turn implies stateof-the-art language models would improve results still further. described method allows construct number visual units. remind reader proposing visemes best priority case method enabling comparison viseme sets controlled manner. presence optimum result competing effects. ﬁrst number visemes shrinks number homophones rises becomes difﬁcult recognise words second number visemes rises training data learn subtle differences lip-shapes again correctness drops. hazen saenko c.-h. glass segment-based audio-visual speech recognizer data collection development initial experiments proceedings international conference multimodal interfaces ser. icmi york available http//doi.acm.org/./. matthews baker active appearance models revisited international journal computer vision vol. available http//www.springerlink. com/openurl.asp? young evermann gales hain kershaw moore odell ollason povey valtchec woodland book cambridge university engineering department available http//htk.eng.cam.ac.uk/docs/docs.shtml", "year": "2017"}