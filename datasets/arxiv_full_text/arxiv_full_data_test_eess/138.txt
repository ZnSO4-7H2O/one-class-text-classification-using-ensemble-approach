{"title": "Weakly Supervised Audio Source Separation via Spectrum Energy Preserved  Wasserstein Learning", "tag": "eess", "abstract": " Separating audio mixtures into individual instrument tracks has been a long standing challenging task. We introduce a novel weakly supervised audio source separation approach based on deep adversarial learning. Specifically, our loss function adopts the Wasserstein distance which directly measures the distribution distance between the separated sources and the real sources for each individual source. Moreover, a global regularization term is added to fulfill the spectrum energy preservation property regardless separation. Unlike state-of-the-art weakly supervised models which often involve deliberately devised constraints or careful model selection, our approach need little prior model specification on the data, and can be straightforwardly learned in an end-to-end fashion. We show that the proposed method performs competitively on public benchmark against state-of-the-art weakly supervised methods. ", "text": "audio sources acoustic mixing process shown promising performance real-world practices. separation algorithms conducted spatial domain methods switched timefrequency domain means complex-valued short time fourier transform constant-q transform related work existing music source separation methods general categorized supervised approaches unsupervised ones. supervised setting separated sources assumed available labeled data together mixture data. direction recently dominated neural network based methods. powerful modeling capability deep neural networks models achieve improvement audio source separation ﬁelds. build deep neural network takes magnitude spectrograms mixture signal input tried extract individual instruments music. propose combine classical gaussian model perform multichannel audio source separation. explore different distance metrics training dnns including itakura-saito divergence kullback-leibler cauchy mean squared error phase-sensitive cost functions. demonstrate superiority convolutional neural network monoaural audio source separation. adopt deep recurrent neural networks separate monaural sources. employ data augmentation technique training blend ensemble four dnns lstm networks music audio source separation. blending model ranked ﬁrst place task signal separation evaluation campaign performance models largely depend assumption large amount labelled data training unrealistic many applications. restricts applicability real-world problems. unsupervised methods mostly trying solve ill-posed inverse problem different regularizations. independent component analysis sparse component analysis based methods assume source stft coefﬁcients stationary non-gaussian distribution loseparating audio mixtures individual instrument tracks standing challenge. introduce novel weakly supervised audio source separation approach based deep adversarial learning. speciﬁcally loss function adopts wasserstein distance directly measures distribution distance separated sources real sources individual source. moreover global regularization term added fulﬁll spectrum energy preservation property regardless separation. unlike state-of-the-art weakly supervised models often involve deliberately devised constraints careful model selection approach need little prior model speciﬁcation data straightforwardly learned end-to-end fashion. show proposed method performs competitively public benchmark state-of-the-art weakly supervised methods. introduction background audio source separation mixed sources long challenging problem music source separation domain considerable attentions attracted. music source separation demonstrated tremendous potential values various applications music upmixing audio restoration music edit music information retrieval among others fact music source separation challenging ill-posed inverse problem. typically signals estimate number signals observed. music tracks mono stereo recordings task recover sources constituent instruments. underdetermined problem regularization scheme enforced. researchers achieved successive breakthroughs music source separation techniques suited speciﬁc occasions. among techniques guided source separation means algorithms employ information ∗junchi correspondence author. work partially supported nsfc part work done ﬁrst author research china. mathematically converted wasserstein distance proven robust metric measure distance distributions contrast kl-divergence requires strict match probability distributions consider close samples relatively probability sensitive sample noise outliers wasserstein distance sensitive underlying geometry structure samples robust noise/outliers. addition ﬁrst assumption explicitly accounted analytical energy preservation term loss function. make wasserstein distance tractable paper turn generative adversarial nets technique. speciﬁcally wasserstein distance minimization problem solved minmax gaming procedure treat separation model generator introduce additional discriminator tries distinguish fake generated sources real ones. result efforts boil devising effective generator discriminator discriminator structure skip connection used paper improve capacity. importantly employ independent discriminators account corresponding sources respectively. global consistency synergically complemented energy preservation term. recent preprint works also based source separation networks. svsgan turns supervised approach whereby technique additionally used enhancement. another work turns unconditional unsupervised learning different separated tracks purpose directly learning different distributions using wasserstein distance. contrast model based conditional directly handle input source separation end-to-end learning algorithm totally different piece-by-piece ad-hoc method. better formulate problem assume number sources separation ﬁxed known assume training testing data associated separation. assumption realistic realworld applications widely adopted existing works music source separation explore paradigm weakly supervised source separation involves deep network learned general loss function rely less prior knowledge source data separation compared existing weakly supervised models direct beneﬁt end-to-end learning capability. present novel general loss involving wasserstein distance distributions separated source samples real-world source samples; spectrum energy preservation constraint complementary source’s wasserstein loss imposes global interlock consistency among separated sources compared mixed signal. explore joint gaussian modelling based methods assumed vectors stft coefﬁcients source spatial images zero-mean nonstationary gaussian distribution. compared totally unsupervised separation combining different level weakly supervised information sources leads improved performance practice. non-negative matrix factorization based methods employ global structure information sources demonstrated impressive performance. repet algorithm takes advantage prior musical background repetitive whereas vocal signal not. unsupervised weakly supervised methods built speciﬁc adhoc assumptions limit generalization capability. besides methods require expensive computation high processing time making difﬁcult real-world applications. last least state-of-the-art unsupervised models essence weakly supervised models e.g. kernel additive model heavily rely precise correct prior knowledge separated sources deliberate constraint design kernel selection prevent user-friendly. importantly many real-world applications prior knowledge either hard collect difﬁcult converted mathematical formula. approach overview paper aims explore weakly supervised methods seeing potential real-world applications. pursue general approach aiming relying less constraints assumptions prior knowledge source data done previous methods speciﬁcally model based mild assumptions making inherently general signal’s spectrum energy preserved separation well accepted concept literature separated sources distribution source data e.g. separated drum sources music shall distribution approximated real-world drum samples easier collect supervised case require one-to-one correspondence separated source mixture. fact constraints complementary ﬁrst enforces global consistency latter pays attention distribution interlock separated sources learning. figure overview proposed framework source separation. input mixture signal ﬁrst transformed spectrum domain separated sources ˆsfi. source discriminator devised using separated i.e. generated sources well real sources auxiliary source data. overall discriminative loss combination multiple sources. note existing audio separation models often additional regularization terms maximize independence estimated sources. paper independence regularization explicitly. independent restriction implied generative adversarial process estimated sources forced sampled real source distributions. helps simplify model. training stage randomly select mixture signals input generator estimated sources mixture output. estimates together randomly selected real sources feed discriminator note kind source input speciﬁc individual discriminator source. alternately optimize gradient decent losses them. training generator taken music source separator. learning paradigm loss function lead competitive performance music separation benchmark compared state-of-the-art weakly supervised methods. contrast needing careful kernel model selection calling deliberate constraint design model easy implement general. preliminaries explain energy preserved wasserstein learning separating mixture audio sources {sti}i=...n. denotes number sources. overall data shown figure firstly mixture audio segmented overlapped segments time context short time fourier transform computed. resulting magnitude spectrograms passed separator outputs estimate {ˆsfi}i=...n separated sources time indices. estimates along computed phase mixture transformed inverse stft recover audio signals corresponding separated sources. energy preserved wasserstein learning mentioned introduction loss function involves energy preservation term restrict separated sources’s total energy close mixed one; distribution distance term hoping separated sources similar real-world sources category. spectrum energy preservation constraint widely accepted used signal processing literature e.g. written model parameter generator discriminator respectively. sfn} denotes sources gradient penalty weight. points sampled uniformly along straight lines pairs points sampled data distribution estimated distribution refer detailed justiﬁcations. generator i.e. separator propose structure convolutional auto-encoder channel input channels output. network takes single channel mixture input outputs estimated signals {ˆsfi}i=...n channels. channel corresponds kind source signal. separator depicted figure fully convolutional auto-encoder. encoding stage input mixture spectrograms mapped dimensional features number strided convolutional layers followed rectiﬁed linear units decoding dimensional features projected back high dimensional outputs number fractional strided convolutional layers. dense layer used. devise architecture guidelines encoding part generator aims extract dimensional source-speciﬁc features input data. hence encoder devised extract source-common features several convolutional layers output sourcespeciﬁc features last layer. passing sourcespeciﬁc features decoders noise increase diversity output separator. note generator network consists skip connections connecting encoding layers corresponding decoding layers. skip connections pass level details directly higher layers help decoder reconstruct source signals. additionally gradients back propagation process deeper skip connections. discriminator another larger deeper generator. takes estimated source signals output similarity score distribution separated sources real sources modeling ﬂexibility devise separate discriminators source combined losses together corresponding weight. experiments discussion evaluation protocol dataset term method source separation convert stereo songs mono computing average channels songs sources demixing secrets dataset designed evaluate performances music audio source separation methods. dataset consists professionally produced full track songs mixing secrets free multitrack download library. song mixture sources length sampled divided test set. consist songs. train proposed model test trained model test set. magnitude spectrogram data computed stft. nonoverlapping hanning window points corresponds milliseconds. frame ﬁrst points taken magnitude values. figure structure generator decoders sources share similar structure decoder ‘convd/relu’ denotes convolutional layer followed rectiﬁed linear unit ‘deconvd/relu’ denotes convolutional layer followed rectiﬁed linear unit denotes time context denotes frequency bins. random noises added output encoder. algorithm source separation energy preserved wasserstein learning audio source separation. require sectrograms mixture audio require generator; discriminator; energy integrity penalty weight; gradient penalty coefﬁcient; batch size; icritic number discriminator iterations generator iteration. time indice. randomly select spectrograms mixture audios input generator estimated sources spectrogram {ˆsfi} update generator parameters optimizing equation adam d-steps icritic randomly select spectrograms real source {sfi} psfi randomly select spectrograms mixture data input update discriminator parameters gradient decent equation adam architecture generator/discriminator model generator aims separate mixed signal sources discriminator tries distinguish separated source real ones. neural networks model generator discriminator. table detailed structure generator output shape shown ‘convd’ denotes convolutional layer ﬁlter size stride time-context direction frequency direction. ‘leakyrelu’ denotes leaky rectiﬁed linear layer slide ’skip’ denotes skip connection corresponding encoder layer. input data size frames frequency bins. decoders share structure table detailed structure discriminator. output shape shown ‘convd’ denotes convolutional layer ﬁlter size stride time-context direction frequency direction. ‘leakyrelu’ denotes leaky rectiﬁed linear layer slide input data size denoting frames frequency bins. cent sisec published evaluation results submitted methods. facilitates comparison ssgan based method others. note published results cover songs test set. results songs published. make fair also compute results songs test set. compared weakly supervised methods choose three state-of-the-art weakly supervised methods kernel additive modellings comparison method also weakly supervised. note three peer methods based deep network. fact identiﬁed weakly supervised source separation deep network production paper concurrent work description time context frequency bins weight discriminator bass weight discriminator drum weight discriminator vocal weight discriminator others energy integrity penalty weight gradient penalty weight input output data ssgan aggregate magnitude vectors context window frames. hence ssgan input vector size input output instant spans around milliseconds. inputs scaled dataset also provides source tracks drums vocals bass instruments song set. generator four output channels discriminator four input channels. channels corresponds kind source. details generator discriminator networks found table table generator composed encoder four decoders. encoder consists convolutional layers followed rectiﬁed linear units. last layer encoder four output channels random noise added. four decoders structure. step decoder consists fractional strided convolutional layers followed rectiﬁed linear units concatenation correspondingly encoder layer. four discriminators share structure. discriminator contains convolutional layers followed leaky rectiﬁed linear units fully connected output layer indicating similarity estimated source real source. outputs four discriminators weighted summed together ﬁnal score. model settings parameters generator discriminator networks initialized randomly. used adam optimizer hyperparameters train generator discriminator using batch size parameters related model setup found table note source comprises many kind instruments varied across songs. besides segments source closed vocals source. indicates distribution source highly dispersed sometimes confounded vocals. learn distribution source well difﬁcult drums vocals bass. hence reduce weight discriminator raise weight vocals. metrics following widely used protocol measure performance proposed separation method source distortion ratio source interference ratio source artifacts ratio source image spatial among them usually considered overall performance source separation prove superiority proposed model. also test effect u-net structure. vocals nonvocals separation task test performance proposed model lacking u-net structure denoted lou-v. besides verify complementary effect energypreserving loss wasserstein loss test performance vocals non-vocals separation task energy-preserving loss removed denoted gan-v energy-preserving loss used denoted eng-v. experimental results shown figure model performs competitively peer methods. particular ssgan’s overall performance outperforms bass drums. average improvements proposed methods method approximately comparison test using non-parametric mann-whitney test conﬁdence interval level shows proposed method signiﬁcantly better method drumand bass channels shows difference vocals channel signiﬁcant. also note binary separation version ssgan-v slightly improves full version ssgan vocals non-vocals separation task terms overall performance sdr. vocals performance difference signiﬁcant. conjecture learning vocals’s real data’s distribution challenging learning wasserstein distance vocals contain diverse patterns. u-net connections removed performances lou-v dropped obviously compared ssgan-v. demonstrates effect u-net connections. performances gan-v eng-v signiﬁcantly lower ssgan-v. proves idea wasserstein loss energy-preserving loss complementary. energy-preserving loss constrain multiple sources whole wasserstein loss constrain source separately make look realistic. quite obviously synergy losses. important note method leverages auxiliary dataset contains large amount independent bass drums source data pretrain model. comparatively relatively small data cause difference performance. model also requires deliberate model selection source data need method. without ﬁne-tuning performance drop discussed paper conclusion paper endeavor explore weakly supervised neural network methods source separation relatively less studied compared dominant supervised learning based network models. source separation ill-posed problem resort adversarial learning well explored source separation literature. devise loss involving spectrum energy preservation term wasserstein loss separated sources real source data. model easy implement free deliberate design ad-hoc constraints assumptions sources thus promising practical applications. figure overall performance three individual metrics bass drums vocals separation task vocals non-vocals separation task test part dsd. ends vertical lines denote maximum minimum values denote mean values. upper lower edges boxes denote mean standard deviation. horizontal line denotes median values. results discussion performance peer methods sisec competition results. peer methods disclose performance vocals non-vocals separation task hence also test case denote ssgan-v method. full separation result binary vocals non-vocals separation shown figure approach full separation two-source separation models separately trained setting different number sources discriminators. pritish chandna marius miron jordi janer emilia g´omez. monoaural audio source separation using deep convolutional neural networks. international conference latent variable analysis signal separation pages springer derry fitzgerald rajesh jaiswal eugene coyle scott rickard. shifted using efﬁcient constantq transform monaural sound source separation. dublin institute technology goodfellow jean pouget-abadie mehdi mirza bing david warde-farley sherjil ozair aaron courville yoshua bengio. generative adversarial nets. nips pages masataka goto hiroki hashiguchi takuichi nishimura ryuichi oka. music database music genre database musical instrument sound database. ipsj notes ishaan gulrajani faruk ahmed martin arjovsky vincent dumoulin aaron courville. improved training wasserstein gans. arxiv preprint arxiv. po-sen huang minje mark hasegawajohnson paris smaragdis. joint optimization masks deep recurrent neural networks monaural source separation. ieee/acm transactions audio speech language processing diederik kingma jimmy adam method stochastic optimization. computer science antoine liutkus roland badeau richard. gaussian processes underdetermined source separation. ieee transactions signal processing antoine liutkus derry fitzgerald zafar raﬁi bryan pardo laurent daudet. kernel additive models ieee transactions signal processing source separation. antoine liutkus fabian-robert st¨oter zafar raﬁi daichi kitamura bertrand rivet nobutaka nobutaka julie fontecave. signal separation evaluation campaign. international conference latent variable analysis signal separation pages springer aditya arie nugraha antoine liutkus emmanuel vincent. multichannel audio source separation deep neural networks. ieee transactions audio speech language processing alexey ozerov cric fevotte. multichannel nonnegative matrix factorization convolutive mixtures audio source separation. ieee transactions audio speech language processing alexey ozerov emmanuel vincent fr´ed´eric bimbot. general ﬂexible framework handling prior information audio source separation. ieee transactions audio speech language processing prajoy podder tanvir zaman khan mamdudul haque khan muktadir rahman. comparative performance analysis hamming hanning blackman window. international journal computer applications alec radford luke metz soumith chintala. unsupervised representation learning deep convolutional generative adversarial networks. computer science zafar raﬁi bryan pardo. repeating pattern extraction technique simple method music/voice separation. ieee transactions audio speech language processing olaf ronneberger philipp fischer thomas brox. u-net convolutional networks biomedical international conference medical image segmentation. image computing computer-assisted intervention pages springer daniel stoller sebastian ewert simon dixon. adversarial semi-supervised audio source separation applied singing voice extraction. icassp. ieee stefan uhlich franck giron yuki mitsufuji. deep neural network based instrument extraction music. acoustics speech signal processing ieee international conference pages ieee stefan uhlich marcello porcu franck giron michael enenkl thomas kemp naoya takahashi yuki mitsufuji. improving music source separation based deep neural networks data augmentation network blending. icassp emmanuel vincent nancy bertin remi gribonval frederic bimbot. blind guided audio source separation models side information improve separation sound. ieee signal processing magazine emmanuel vincent. complex nonconvex norm minimization underdetermined source separation. international conference independent component analysis signal separation pages", "year": "2017"}