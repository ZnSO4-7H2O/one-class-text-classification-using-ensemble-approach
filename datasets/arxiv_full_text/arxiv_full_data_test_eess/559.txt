{"title": "Convolutional Neural Network Achieves Human-level Accuracy in Music  Genre Classification", "tag": "eess", "abstract": " Music genre classification is one example of content-based analysis of music signals. Traditionally, human-engineered features were used to automatize this task and 61% accuracy has been achieved in the 10-genre classification. However, it's still below the 70% accuracy that humans could achieve in the same task. Here, we propose a new method that combines knowledge of human perception study in music genre classification and the neurophysiology of the auditory system. The method works by training a simple convolutional neural network (CNN) to classify a short segment of the music signal. Then, the genre of a music is determined by splitting it into short segments and then combining CNN's predictions from all short segments. After training, this method achieves human-level (70%) accuracy and the filters learned in the CNN resemble the spectrotemporal receptive field (STRF) in the auditory system. ", "text": "music genre classiﬁcation example content-based analysis music signals. traditionally human engineered features used automatize task accuracy achieved -genre classiﬁcation. however it’s still accuracy humans could achieve task. here propose method combines knowledge human perception study music genre classiﬁcation neurophysiology auditory system. method works training simple convolutional neural network classify short segment music signal. then genre music determined splitting short segments combining cnn’s predictions short segments. training method achieves human-level accuracy ﬁlters learned resemble spectrotemporal receptive ﬁeld auditory system rapid development digital technology amount digital music content increases dramatically everyday. give better music recommendations users it’s essential algorithm could automatically characterize music. process called musical information retrieval speciﬁc example music genre classiﬁcation. however music genre classiﬁcation diﬃcult problem boundaries diﬀerent genres could fuzzy nature. example testing -way forced choices task college students could achieve classiﬁcation accuracy hearing seconds music accuracy doesn’t improve longer music also number labeled data often much smaller dimension data. example gtzan dataset used current work contains audio tracks audio track long sampling rate traditionally using human-engineered features like mfcc texture beat accuracy achieved -genre classiﬁcation task recently using pca-whitened spectrogram input convolutional deep belief network achieved accuracy -genre classiﬁcation task. results reasonable still good humans suggesting there’s still space improve. psychophysics physiology study show human auditory system works hierarchical first decomposes continuous sound waveform diﬀerent frequencies higher precision frequencies. then neurons lower higher auditory structures gradually extract complex spectro-temporal features complex spectro-temporal receptive ﬁeld features used human auditory system music genre classiﬁcation probably rely strfs. spectrogram input corresponding genre label learn ﬁlters extract features frequency time domain. learned ﬁlters mimic strfs human auditory system extract useful features music genre classiﬁcation. music signal often high-dimension time domain complete spectrogram music signal feasible. solve problem used divide-and-conquer method split spectrogram music signal figure convert waveform mel-spectrogram example -second segment. mel-spectrogram mimics human works high precision frequency band precision high frequency band. note mel-spectrogram shown ﬁgures already transformed. consecutive -second segments make predictions segment ﬁnally combine predictions together. main rational method humans’ classiﬁcation accuracy plateaus seconds good results obtained using -second segments train convolutional deep belief network also intuitively makes sense diﬀerent parts music probably belong genre. reduce dimension spectrogram used mel-spectrogram input cnn. mel-spectrogram approximates human auditory system works seen spectrogram smoothed frequency domain high precision frequencies precision high frequencies music signal ﬁrst converted waveform mel-spectrogram using librosa library time window overlap then mel-spectrogram transformed bring values diﬀerent mel-scale range ln). mel-spectrogram biological-inspired representation simpler interpretation pca-whitening method used layers/ﬁlters ﬁrst dimension corresponds mel-scale second dimension corresponds time. hidden layers relu activation functions output layer softmax function loss calculated using cross-entropy function. dropout regularization used prevent extreme weights. model implemented using keras tensorﬂow backend trained single gtx- using stochastic gradient descent. testing music split consecutive -second segments overlap. then segment trained neural network predicts probabilities genre. predicted genre music genre highest averaged probability. training musics split -second segments overlap. segments trained intermediate outputs calculated stored. then estimated learned ﬁlters using following method best knowledge current model ﬁrst achieve human-level accuracy -genre classiﬁcation task it’s higher obtained classiﬁes diﬀerent genres similar accuracy. confusion matrix could classiﬁcation accuracy varies across diﬀerent genres. especially accuracies country rock genre lower current average also lower important human-engineered features used long-term feature like beat rhythm suggests country rock music characteristic features require longer time capture segments used long enough. future direction explore extract long-term features classiﬁcation possibility another down-sampled mel-spectrogram whole audio input. another explanation country rock share features music genres diﬃcult classify nature. nonetheless expert advice probably required improve classiﬁcation accuracy country rock genre. figure shows ﬁlters learned cnn’s pooling layer they’re qualitatively similar strf obtained physiological experiments visualize ﬁlters help classify audios feed segments testing calculated activations last hidden layer. non-linear transformation testing data points become linearly separable contrast testing data points much less separable mel-spectrogram used. results together show learns ﬁlters similar spectro-temporal receptive ﬁeld observed brain. ﬁlters transform original mel-spectrogram representation data linearly separable. combining knowledge human psychophysics study neurophysiology used divide conquer classiﬁed audio waveforms diﬀerent genres human-level accuracy. technique used solve problems share similar characteristics example music tagging artist identiﬁcation using audio waveform. current model genre music extracted eﬃciently human-level accuracy used features recommending music users. figure comparison separability representation last layer representation testing data. axes ﬁrst three components data projected onto directions obtained linear discriminant analysis using training data.", "year": "2018"}