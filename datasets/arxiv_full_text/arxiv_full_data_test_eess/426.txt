{"title": "Completely Distributed Power Allocation using Deep Neural Network for  Device to Device communication Underlaying LTE", "tag": "eess", "abstract": " Device to device (D2D) communication underlaying LTE can be used to distribute traffic loads of eNBs. However, a conventional D2D link is controlled by an eNB, and it still remains burdens to the eNB. We propose a completely distributed power allocation method for D2D communication underlaying LTE using deep learning. In the proposed scheme, a D2D transmitter can decide the transmit power without any help from other nodes, such as an eNB or another D2D device. Also, the power set, which is delivered from each D2D node independently, can optimize the overall cell throughput. We suggest a distirbuted deep learning architecture in which the devices are trained as a group, but operate independently. The deep learning can optimize total cell throughput while keeping constraints such as interference to eNB. The proposed scheme, which is implemented model using Tensorflow, can provide same throughput with the conventional method even it operates completely on distributed manner. ", "text": "abstract—device device communication underlaying used distribute trafﬁc loads enbs. however conventional link controlled still remains burdens enb. propose completely distributed power allocation method communication underlaying using deep learning. proposed scheme transmitter decide transmit power without help nodes another device. also power delivered node independently optimize overall cell throughput. suggest distirbuted deep learning architecture devices trained group operate independently. deep learning optimize total cell throughput keeping constraints interference enb. proposed scheme implemented model using tensorﬂow provide throughput conventional method even operates completely distributed manner. conventional wireless communications. centralized architecture processes wireless communications supervised central node represented evolved node controls channels transmit powers schedules. architecture required various control signals devices enb. besides user data transferred enb. future highquality real-time video streaming services largecapacity virtual reality services dramatically increased mobile data trafﬁc demands future mobile data trafﬁc central architecture. therefore inevitable wireless communication system evolve distributed architecture. device device communication cellular system signiﬁcant techniques distributed wireless communication architecture communication applied directly transferring data devices merging data transmitted enb. types communication communication overlaying conventionally considered. system distinguished frequency resources allocated links. thus jeehyeong joohan park jaewon sunghyun department computer science engineering hanyang university ansan e-mail manjehanyang.ac.kr pjhhanyang.ac.kr wodnjshanyang.ac.kr choprohanyang.ac.kr interfere cellular system throughput gain would marginal limitation frequency resources. type communication underlaying lte. allows communication frequency resource cellular system. interfere other expected resource gains frequency reusing. thus minimizing co-channel interference important study topic improve overall performance cells. order reduce co-channel interference studies conducted three ways. firstly studies suggested efﬁcient spectral resource allocation methods reduce co-channel interference studies proposed efﬁcient transmit power allocation schemes reduce interference effects mode selection scheme devised determines devices communication cellular communication three approaches close other studies conducted mixture categories difﬁculties communication underlaying distributed architecture. although allows communication proposed schemes required central supervisor enb. nodes suffer lack information. difﬁcult nodes consider global cell environments. reason schemes mentioned cannot conducted without involvements enb. involves process much beneﬁts introducing communication cellular system lost. therefore focus distributed architecture communication underlaying lte. speciﬁcally distributed transmit power allocation scheme target paper. considerations resource allocation would next step paper. node decide transmit power considering throughput interference conventional cellular system. processes conducted without involvements possible. thus propose distributed architecture determine transmit powers using deep learning devices. proposed method transmitter determine transmit power without involvement either devices. uses location determine transmit power. furthermore powers determined devices maximize total throughput. device learns decide transmit power optimal cell throughput based locations considering interference conventional cellular infrastructure like enb. deep learning used learning process. also lagrange function deep learning cost function meet constraints interference enb. according study ﬁrst approach complete distributed power allocation decision maximize global cell throughput also ﬁrst methodology apply deep learning distributed decision problem maximize global performance wireless communications. additionally proposed scheme speciﬁc power allocation problem. applied minimizing problem designed cover customized objective function keeping several constraints. main contributions paper follows according proposed method device decide transmit power device device communication without supporting enb. simultaneously maximize overall cell throughput. rest paper organized follows. section introduce backgrounds related works communications deep learning. section proposed method described three aspects distributed architecture cost design learning deep learning process. section results actual implementation proposed scheme. show various expressions results including power distribution cells. finally signiﬁcance proposed method summarized conclusion section. communication standardized release ﬁrst time standardization many research conducted allocating resources determining transmit power dd-enabled underlaying environments. effective resource allocation studies important minimize co-channel interference maximize overall data rate cell. authors proposed framework dd-enabled cellular networks. framework used understand analyze inﬂuence communication performance cellular networks. authors proposed relaying-based scheme fullduplex. proposed idea used allocate transmitting power transmitter. goal idea optimize overall performance users meeting minimum performance requirements cellular users. authors proposed power allocation mechanism maximize energy efﬁcient users. used circuit powers consumption users maximize energyefﬁcient meeting minimum performance cellular users. proposed power allocation mechanism avoid interference satisfying delay constraint. research devices still dependent enb. author designed distributed power allocation underlaying lte. nevertheless devices supported recognize information others. section introduce schematic operations deep learning important research using deep learning wireless communication. deep learning emerging technique days also applied wireless communication deep learning regarded simple function assumed linear function appropriateness output must mathematically expressible. cost function mathematical expression determine appropriateness output also optimizer mathematical scheme adjust gradually according cost function. tries adjust various repeatedly. consequently optimizer ﬁnalize derive appropriate according cost function. deep neural network basic model deep learning regarded composite y=wx+b. deﬁned complex composite linear function. several layers. basic unit outputs would inputs next finally overall adjusted optimizer gradient decent adam optimizer optimizer changes repeatedly minimize cost function. composite linear function +...)wn approximate various functions. derives impressive results ﬁelds considered solve problems wireless communications too. concepts deep learning follows. network size various size. several layers layer depicted number vectors deﬁned width. addition number layers deﬁned depth. therefore network size means width depth. network size deep learning larger required approximate complex function. large network size capture features input data. always derive better results. case minor features ignored optimal results. features selected features speciﬁc given input data. means features represent overall data. case good performance given data data. called overﬁtting problem words overﬁtting problem caused lack input data. input data large enough represent overall data overﬁtting problem would reduced. fortunately actual data wireless communication. many mobile devices generating various data real time. reason overﬁtting problem need taken seriously deep learning wireless communication. xavier initiation xavier initiation method initiate weights generally weights initialized randomly. gaussian uniform random distributions considered ﬁrstly initiate weights. xavier initiation input size output size considered additionally reduce divergence neural network. neural network tends induce divergence variation would increase passing layer. describe assume basic calculation unit neural network follows inputs outputs assumed identically distributed. consequently variation output proportional number inputs. note outputs would input next layer neural networks. variation large situation cause divergence weights reduce divergence variation xavier initiation consider input size initiate weights. additionally backward considered optimizer uses back propagation algorithms update weights. finally xavier initiation described follows batch normalization batch normalization method normalize outputs layer deep learning prevents inputs layer divergent. firstly weights adopted input y=wx. note conventional bias added shifting conducted later. that normalized mean variance normalized would re-scaled shifted initiated respectively trained optimizer. thus regarded additional weights sets. normalization output controlled preventing divergence adjusted produce better results. adam optimization adam optimization algorithm. adam optimizer gradient descent optimization algorithm requiring less memory optimization algorithm process adam optimizer described follows. firstly method initializes timestamp momentum vector momentum vector zero. calculated momentum vector biased zero beginning learning since optimizer initialized momentum vectors zero. therefore optimizer adjusts momentum vector values make momentum vectors unbiased. process advantage adam optimizer. equations calculate bias-corrected momentum vectors described follow. tensorﬂow tensorﬂow major platforms deep learning implementation developed google. ﬂexible architecture implement customize deep learning model. also open-source models internet easy apply applications. explain dpadic three perspectives. ﬁrst feature dpadic distributed deep learning architecture. devices predict transmit power itself learn together maximize overall throughput. secondly objective function deep learning described. adopts shannon capacity equation spectral efﬁciency. also contains given constraints. finally deep learning process proposed method shown. distributed architecture fig. architecture proposed method described. device predict power respectively overall results merged update dnn. therefore described follows pair. weights bias contents dnn. determines output would derive given input. also shared given devices deep learning process optimal cases various cases locations regarded determined randomly. consider various deﬁne batch batch size batch. therefore optimal batch. described follows depends speciﬁc batch batch. batch hence batch re-deﬁned batch batch batch generally deep learning process conducted several input data once. input data processed once deﬁned batch. according design proposed method batch tweaked batchk learning. process described follows vectorization. described matrix hand consists values locations transmitter receiver pair devices also outputs deep learining values transmit power ofdma shared ofdma channel. training every transmitter trained dnn. focus maximizing total throughput keeping constraints maximum power transmitter interference enb. maximum power constraint means total transmit power user cannot limit. hand interference constraint means interference experienced cannot threshold. required focus underlaying cellular system. underlaying system cellular system mainly supported lte. guarantee performances cellular system allowed interference threshold. assume ofdma interface lte. orthogonal subcarriers non-overlapped spectrum regarded ﬂat. thus consider shared ofdma channels. also consider devices pair pair devices consists transmitter receiver assume perfect synchronization. likewise consider multi-cell environments cells. signal receiver link expressed follows hnki complex channel gain transmitter pair receiver pair channel snkk symbol transmission power e{|snkk|}. wnkk additive zeromean gaussian disturb variance also assume includes additional noise thermal noise interference cellular networks. therefore throughput receiver pair expressed follows transmit powers pair link pn}. purpose proposed scheme maximize throughput keeping constraints power constraint interference constraint. therefore objective function constraints derived sinr signal ratio quantitative unit. therefore constraints also designed shannon capacity ratio quantitative unit too. design shown work effectively section according interferences constraints channel. note additive zero-mean gaussian disturb adopted formula. purpose formula formulate impact transmitter enb. thus random noise factor ignored. therefore interference constraints ctif formulated follows constants control strength ctif respectively. constants adjusted deep learning process would described next section. although constraint formulas designed re-scale constraints strength constant would help accurate approximation power prediction. note several parameters deep learning learning rate network size batch size. also adjusted training process. strength constants constraints adjusted trials. furthermore throughput negative constraints positive deep learning process minimize cost function. maximize throughputs minimizing penalty. parallel operation another point proposed method. note deep learning process conducted batch input data. prediction costs including constraints derived parallel. parallel operation impossible batch size ﬁxed slow overall operation much. conventional deep learning parallel operation important cost function simple designs. however difﬁcult consider interference device since distance devices must taken cost function parallel. therefore describe detail process parallel operation cost function. cost function design section describe cost function design make possible maximize total cell throughput keeping constraints. propose practical mechanism apply constraints cost function transmitting power constraints interferences constraints. adopt lagrange function express constraints cost function. typically lagrange function function used minimize maximize target value constrained environment typical cost function deep learning regression problem mean square error average square difference predictions pre-deﬁned answers. intends give beneﬁt penalty update reducing differences. words cost function customized give beneﬁt penalty based purpose system. therefore throughput directly cost function proposed scheme shown equation thus answers required. throughput complex function problem deep learning. additionally proposed scheme constraints adopted cost function. firstly power constraint follows rectiﬁed linear unit function used. relu function deﬁned relu max. transmit power transmitter threshold would therefore delivers penalty transmit power transmitter constraint. remaining part designed re-scaling. appropriate re-scaling important estimate lagrange multipliers. proposed scheme difﬁcult determine lagrange multipliers cost function complex. difference scales objective function throughput proposed scheme constraints large would difﬁcult appropriate lagrange multipliers. thus objective function constraints designed simliar scales similar forms. note shannon capacity formed path loss model considers distance transmitter receiver. adopted interference too. transmitters interferers receiver pair following process determine interference transmitters parallel path loss required describe path loss transformed vector transmitters redundantly concatenated. deﬁne batchtx. number batchtx batchrx also deﬁned number vectors batch size. note process vector calculation once size vector enough processed memory time. that matter batch size cost designed derived times calculations. deriving element vector mapi re-transformed follows train predicts power input data then cost function deﬁned input data predicted power cost function main part train function. implemented equation including batch control. several data batch data trained once. cost function delivers equation input data respectively results averaged. also adam optimizer adjust deals cost function itself result cost function. adam optimizer differentiates cost function trace changes. consequently gradually changed optimizer minimize cost function. predict reshape function used change shape input data. ﬁrst shape input data means number batch size input data input data number pairs. pair four ﬁgures transmitter receiver respectively. changed pair data independent distributed learning. thus batch size× pairs. reshaping actually calculated repeatedly mentioned above. furthermore adopt batch normalization proposed method. sigmoid function used activation function layer. sigmoid function deﬁned adjusts output previous calculation layer iteration calculating neural network reshaped original form. then re-scaled unit output power dbm. results presented section. actually implement proposed scheme tensorﬂow consider environment assume hexagonal cells radius maximum distance pairs dmax uniformly distributed also consider multi-cell cases number pairs cell. thus number pairs number ofdma subchannels spectral efﬁciency would derived maximum transmit power constraint channel attenuation expressed path loss distance including shadowing fading. path loss exponent shadowing standard deviation normal distribution. additive zero-mean gaussian noise cellular network dbw. table shows default parameters dnn. width depth network size dnn. batch size number data training process. data batch number iterations thus cases drops learning duplicated data cases. interference constraint equation also changed similar described above. firstly experienced interference batch described path loss received power batch equation constants path loss could changed receiver thus interference constraint batch ctifbatch also deﬁned using experienced interference batch. ifbatch deep learning process process similar typical deep learning excepts include simulation training process labels required. operated pre-processed input data. means separated simulation generates overall input data data trained deep learning. however include simulation training process intuitive. thus simulation generates input data much required every iteration. data iteration deﬁned batch. batch size number input data processed iteration. detailed training process described algorithm deﬁned separately iteration means number training trials. epoch number iterations. simulation designed deliver batch input data. size batch given batch size. train function actual training part throughput constant value iterations. smaller qmax cases tend converged earlier initial transmit power near zero fig. range power dbm. initial powers near middle range. near zero powers growed better throughput optimizer. fig. shows gets converged throughput keeping interference constraint. also simulate dpadic -cell environment. tendency fig. similar case -cell environment. imply dpadic appropriate outputs regardless number shape cells. table comparison proposed scheme dpadic iadrmpic similar results throughput -cell environments. however dpadic node optimal transmit power pre-trained dnn. transmitter determine transmit powers without involvement peripheral nodes approve maximize cell throughput. proposed scheme signiﬁcant parameters adopting constraints determined manually difﬁcult. valid range parameters wide enough. fig. show effects interference constraint factor small used interference constraints ignored. case proﬁtable ignore minimizing cost though takes penalty thus spectral efﬁciency high valid interference limit qmax. high enough cannot ignore constraint. then keep constraints reducing transmit powers. uses high reduced falling meaningful. note includes relu function. turns constraint threshold. this effect high limited. however transmitters dropped randomly close enb. thus cases qmax though small transmit power. cases affect results. consequently reduced slightly larger fig. describes effects transmit power constraint factor less sensitive similar case ignore power constraint enough. small increased cannot keep constraint. adopts transmit power constraints appropriately unlike larger problem. even adopt batch normalization implementation proposed method. fig. shows comparisons adopted batch normalization cases optimized enough batch normalization adopted. likewise learning process regarded unstable. means applying batch normalization signiﬁcant impact learning performance. reason variation input data. coordinate input data. variation inputs wide adopt sigmoid function range sigmoid function large small data lose meaning. large numbers regarded close sigmoid function. reduces effects difference large numbers. inevitably sigmoid function information loss large numbers. makes difﬁcult learn differences large numbers. hand batch normalization moves distribution data including scales. would appropriate learning. intuitively batch normalization expected show performance improvement deep learning wireless communication treats wide coordinate values input data. fig. show time derive cost function affected batch size time generate data implemented regardless parallelism increased lineary. hand cost function affected batch size. means related parallel adopt deep learning wireless communication data essential preserved learning. implies scheme difﬁcult adopted without conventional well-operated scheme. thus deep learning based schemes wireless communication dependency simulations. however also difﬁcult simulation fully represent actual ﬁeld. adopt deep learning wireless communication freely operated simulation cannot represent actual ﬁeld. means deep learning method based speciﬁc simulation. work would future work paper. propose perfectly distributed power allocation link underlaying lte. major purpose communication underlaying relieve dense burden enb. thus important nodes operated distributed way. according study ﬁrst method transmitter decide transmit power without helps either nodes meet global optimum. deep learning module node memorize transmit power according locations global optimum. also maintains performance previous works. shown fig. furthermore results proposed method show underlaying appropriate cover edge users. poor performance edge users major concerns cellular networks. multihop communication using link main candidate solve cell edge user problems. finally method proposed used generally. features adopted wireless communication also optimization problems. first feature supports solve general minimizing problems keeping constraints using deep learning. deep learning best tool solve optimize problems show operated optimize problem keeping several constraints. another feature distributed architecture. solve distributed power allocation problem links distributed learning architecture. applied develop centralized system distributed system. fig. show visualized training results cell environments respectively. interference constraints power allocations distributed cell edge area. iterations almost converged results. results regarded divides compartments power allocation maximize throughput. allocates fractionaly transmit power slight subdividing. particular remarkable transmit power increases edge area cell. implies links proposed method helpful enhance poor performances cell edge users. signals cell edge users combined multi-hopped communication. furthermore dpadic derived distributed way. means performance enhancements cell edge users conducted without involvement enb. andrea abrardo marco moretti distributed power allocation communication underlaing/overlaying ofdma cellular networks ieee transaction wireless communication vol. mar. zhong zhang wong chen joint spectrum power allocation communication underlaying cellular networks. ieee transactions vehicular technology vol. azam ahmad naeem iqbal khwaja anpalagan qaisar joint admission control mode selection power allocation communication systems. ieee transactions vehicular technology vol. zhang yang qos-aware mode selection resource allocation scheme device-to-device communication cellular networks. ieee international conference communication workshops june sheng tang zhang guizani joint mode selection channel allocation power assignment green device-to-device communication ieee international conference communication june jeehyeong nzabanita abdoul karim sunghyun cho. interference mitigation scheme device-to-device communication sensor networks underlying lte-a. sensors vol. may. elsawy hossain alouini analytical modeling mode selection power control underlay communication cellular networks ieee transactions communication vol. zhang yang power allocation full-duplex relaying-based communication underlaying cellular networks ieee transactions vehicular technology vol. october xiao zhao zhou wang heterogeneous statistical qos-driven power control communication underlaying cellular networks international conference telecommunication fadlullah tang kato akashi inoue k.mizutani state-of-the-art deep learning evolving machine intelligence toward tomorrow’s intelligent network trafﬁc control systems ieee communication surveys tutorials vol. liang zhao optimization cache-enabled opportunistic interference alignment wireless networks data deep reinforcement learning approach ieee international conference communication paris france jun. k.s. deep learning–based realtime query processing wireless sensor network international journal distributed sensor networks vol. may. srivastava hinton krizhevsky sutskever salakhutdinov dropout simple prevent neural networks overﬁtting journal machine learning research vol. jun. xavier glorot yoshua bengio understanding difﬁculty training deep feedforward neural networks proceedings thirteenth international conference artiﬁcial intelligence statistics sardinia italy may. sergey loffe christian szegedy batch normalization accelerating deep network training reducing internal covariate shift proceedings thirteenth international conference artiﬁcial intelligence statistics deigo pp.- may. sunghyun received b.s. m.s. ph.d. computer science engineering hanyang university korea respectively. samsung advanced institute technology telecommunication center samsung electronics engaged design standardization network layers wibro/wimax g-lte systems. postdoctoral visiting scholar department electrical engineering stanford university. currently professor dept. computer science engineering hanyang university. primary research interests generation mobile communications software deﬁned networks vehicular communication systems. member board directors institute electronics information engineers korean institute communication sciences jeehyeong received b.e. degree computer science engineering hanyang university south korea currently pursuing m.s.-leading-to-ph.d. degree computer science engineering hanyang university south korea. since computer science engineering hanyang university engineering south korea. research interests include interference management cellular communications military communications using satellites security applied deep learning joohan park received b.e. degree computer science engineering hanyang university south korea currently pursuing m.s.-leading-to-ph.d. degree computer science engineering hanyang university south korea. since computer science engineering hanyang university engineering south korea. research interests include wireless power transfer energy harvesting network simultaneous wireless information power transfer", "year": "2018"}