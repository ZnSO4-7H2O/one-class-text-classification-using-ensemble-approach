{"title": "Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with  Tacotron", "tag": "eess", "abstract": " We present an extension to the Tacotron speech synthesis architecture that learns a latent embedding space of prosody, derived from a reference acoustic representation containing the desired prosody. We show that conditioning Tacotron on this learned embedding space results in synthesized audio that matches the prosody of the reference signal with fine time detail even when the reference and synthesis speakers are different. Additionally, we show that a reference prosody embedding can be used to synthesize text that is different from that of the reference utterance. We define several quantitative and subjective metrics for evaluating prosody transfer, and report results with accompanying audio samples from single-speaker and 44-speaker Tacotron models on a prosody transfer task. ", "text": "also spoken multiple ways indicating information objects exist. possible options intonation ﬁnal option declining pitch. variety options apple orange examples options typically intoned rising pitch. intonation sentences carries meaning environment context question unspeciﬁed text general number nuances present speech convey information beyond textual content. order avoid challenging problem schematizing labeling prosody seek methods modeling prosody require explicit annotations present architecture learning latent prosody representation extracting ground truth speech audio. accordingly subtractive deﬁnition prosody deﬁnition. prosody variation speech signals remains accounting variation phonetics speaker identity channel effects natural problem arises formulation sampling challenge generating diverse interesting prosody output speech even identical phonetics speaker identities channel effects. paper tackle basic problem constructing space represents prosody. propose possible construction prosody latent space show capture meaningful variation speech demonstrating transfer space roughly corresponds like this task. recently proposed tacotron speech synthesis system computes output directly graphemes phonemes prosody model implicit learned statistics training data alone. learns example english sentence ending question mark likely rising pitch question present extension tacotron speech synthesis architecture learns latent embedding space prosody derived reference acoustic representation containing desired prosody. show conditioning tacotron learned embedding space results synthesized audio matches prosody reference signal time detail even reference synthesis speakers different. additionally show reference prosody embedding used synthesize text different reference utterance. deﬁne several quantitative subjective metrics evaluating prosody transfer report results accompanying audio samples single-speaker -speaker tacotron models prosody transfer task. order produce realistic speech text-to-speech system must implicitly explicitly impute many factors given simple text input. factors include intonation stress rhythm style speech collectively referred prosody. speech synthesis text-to-speech challenging underdetermined problem since meaning expressed utterance inherently underspeciﬁed text. example simple statement mat. spoken many different ways. statement answer question where sit? speaker might stress word indicate answer question. express uncertainty knowledge speaker decide intone response rising pitch. question would like apple orange? yes-or-no answer. work augment tacotron explicit prosody controls. accomplish learning encoder architecture computes low-dimensional embedding speech signal embedding provides information provided text speaker identity. careful experiments demonstrate prosody embedding used reproduce desired prosody using tacotron. immediate implication acoustic encoder architecture prosody latent space control behavior system using different voice used training. resulting embedding ﬁxedlength often smaller transcript easily stored alongside text production system. longer-term implications build models predict prosody embeddings non-acoustic context prosody labels conversation state. main contribution encoder architecture extracts ﬁxed-length learned representation prosody acoustic input; demonstrate encoder allows transfer prosody utterances almost speaker-independent fashion. evaluate performance prosody transfer task propose number quantitative qualitative metrics. additionally strongly encourage reader listen audio samples demo page. prosody speaking style modeling studied since hmm-based research. example proposes system ﬁrst clusters training performs hmm-based cluster-adaptive training. proposes estimating transformation matrix predeﬁned style vectors. numerous works explored annotation schemes diagramming automatic labeling prosody tobi autobi tilt intsint slam describe methods annotation automatic extraction labels annotations correlate prosodic phenomena. challenges annotation often require domain expertshowever inter-rater annotations differ substantially works propose acoustic reference signals control prosody text-to-speech model. proposes signal driven features predict symbolic prosody representations using autobi labels improve hmm-based synthesis. propose prosody transplantation system called protran recording low-bit-rate enriched phonetic transcription used conjunction desired text prosody transfer related task voice conversion perform voice conversion model must synthesize utterance given acoustic signal utterance different speaker’s voice approach similar found complicated autoencoder used learn elements style unsupervised fashion. model based tacotron recently proposed state-of-the-art end-to-end speech synthesis model predicts spectrograms directly grapheme phoneme sequences. predicted spectrograms either synthesized directly timedomain wavenet vocoder ﬁrst learning linear spectrogram prediction network applying grifﬁn-lim spectrogram inversion work original encoder decoder architecture simpliﬁed architecture proposed additionally exclusively phoneme inputs produced text normalization front-end lexicon speciﬁcally interested addressing prosody model’s ability learn pronunciation graphemes. finally instead bahdanau attention used attention improves generalization long utterances. audio samples included demo page produced wavenet vocoder however original linear-spectrogram prediction network followed grifﬁn-lim spectrogram inversion works equally well prosody transfer. practice choice neural vocoder impacts audio ﬁdelity impact system’s resulting prosody. tacotron proposed include explicit modeling speaker identity; however ﬂexibility neural sequence-to-sequence models learning multi-speaker models conditioning speaker identity straightforward. follow scheme similar model multiple speakers. figure full tacotron architecture prosody control. autoregressive decoder conditioned result reference encoder transcript encoder speaker embedding attention module. coder -dimensional representation phoneme grapheme sequence produced transcript encoder architecture length encoded transcript representation embedding dimension produced transcript encoder. speaker dataset embedding vector initialized glorot initialization. example ds-dimensional speaker embedding corresponding true speaker example broadcast-concatenated -dimensional transcript encoder representation form -dimensional sequence encoder embeddings decoder attend additional changes loss metrics necessary. extend tacotron architecture adding reference encoder module takes length-lr drdimensional reference signal input computes dimensional embedding think ﬁxeddimensional embedding prosody space goal sampling space yield diverse plausible output speech manipulate elements speaker embedding prosody embedding combined text encoder representation combination broadcast-concatenation. speaker embeddings described section encoder embeddings form embedding matrix speaker prosody embeddings ﬁxed across timesteps. figure illustrates structure. training reference acoustic signal simply target audio sequence modeled. explicit supervision signal used train reference encoder; learned using tacotron’s reconstruction error loss. training think combined system encoder-decoder phonetic speaker information conditioning input. sufﬁciently high-capacity embedding representation could simply learn copy input output training. therefore autoencoder care must taken choose architecture sufﬁciently bottlenecks prosody embedding forced learn compact representation. figure prosody reference encoder module. -layer stack convolutions batch normalization followed recurrent pooling summarize variable length sequence followed optional fully connected layer activation. encode utterance constrained match either text input provided speaker embedding. particular enables possibility prosody transfer using utterance different speaker different text control output. study prosody transfer detail section reference encoder architecture simple -layer convolutional network. layer composed ﬁlters stride padding relu activation. batch normalization applied every layer. number ﬁlters layer doubles half rate downsampling reference signal downsampled architecture times dimensions. feature dimensions channels ﬁnal convolution layer unrolled inner dimension resulting lr/×dr/ matrix. compress lr/length sequence produced layers single ﬁxed-length vector recurrent neural network single -width gated recurrent unit layer. take ﬁnal -dimensional output pooled summarization sequence. compute ﬁnal -dimensional embedding -dimensional output apply fullyconnected layer project output desired dimensionality followed activation function choice activation function constrain information contained embedding make learning easier controlling magnitude. exploration reference signal feature representation choice feature representation used input reference encoder architecture naturally impacts aspects prosody expect learn. example pitch track representation allow model prominence languages since contain energy information. similarly mfcc representation somepitch-invariant preventing modeling intonation. work decided perceptually-relevant summarization spectrum does mel-warped spectrum choice representation enables interpretation resulting architecture encoder-decoder conditioned text speaker identity. must model bottleneck representation unexplained variation signal i.e. prosody recording environment. illustrate interpretation figure ﬁxed-length prosody embedding poses obvious scaling bottleneck preventing extension approach longer utterances. alternate implementation reference encoder section uses output pitch signals reference predicted audio voicing decisions reference predicted audio indicator function. measures percentage voiced frames deviate pitch compared reference. addition metrics propose subjective test structured discrimination test refer anchored prosody side-by-side. human rater presented three stimuli reference speech sample competing samples evaluate. rater asked rate whether prosody closer reference -point scale. scale ranges much closer both distance much closer naturally mapped integers prior collecting ratings provide raters examples prosodic attributes evaluate condition tacotron decoder sequence introduce second attention head attention-aggregator module proposed experiments variable-length prosody embeddings able generalize long utterances; however compared ﬁxed-length embeddings variable-length embeddings robust text speaker perturbations likely encode stronger timing signal. therefore paper focuses ﬁxed-length embeddings. single-speaker dataset single speaker high-quality english dataset audiobook recordings catherine byers dataset consists hours recordings books read animated emotive storytelling style. train models least steps minibatch size using adam optimizer start learning rate decay step respectively. baselines train models without reference encoder architecture generally-accepted metrics prosody transfer. measure performance adapt number metrics general audio processing reﬂects acoustic correlate prosody. comparisons predicted signals target signals extend shorter signal length longer signal using domain-appropriate padding pitch voicing metrics computed using table summary quantitative subjective metrics used evaluate prosody transfer. lower better mcdk ffe. higher subjective scores better indicate whether human raters believe voice closer prosody reference corresponding baseline model point scale about same. voice single-speaker single-speaker single-speaker single-speaker multi-speaker multi-speaker multi-speaker multi-speaker multi-speaker multi-speaker pauses) explicitly instruct raters ignore audio quality pronunciation differences. screenshot user interface included figure triplet evaluated collect independent ratings. rater used items single evaluation. analyze data subjective tests average scores compute conﬁdence intervals. figure shows three spectrograms utterance. note spectrogram model conditioned reference embedding bears much stronger resemblance reference signal generated unconditioned model. particular notice spectrogram baseline model reference signal exhibits noticeably different rhythm example long pause halves utterance utterance lasts much longer. contrast output prosody embedding length pause characteristics reference audio; also recognizably similar harmonic onset structure. figure shows pitch tracks triplet utterances. prosody embedding model closely follows pitch contours reference whereas unconditioned model something else entirely. evaluated synthesis singlemulti-speaker models using types reference utterance. same speaker indicates reference utterance speaker target unseen speaker refers reference utterance speaker unseen training. multi-speaker model also tested synthesis speaker seen training different target speaker present ﬁndings table results show augmenting tacotron reference encoder allows match reference prosody substantially accurately. true baseline/model pairs table independent whether reference speaker matches target speaker. objective metrics also support conclusion resulting substantially lower values reference encoder model baseline model. note target reference speakers different must careful demonstrate prosody transfer achieved. bottleneck allows much information reference encoder example overall model could simply copy reference output. instance listening even small number outputs sufﬁces verify output speaker matches target speaker fact achieved prosody transfer across speakers. however experiments explored section provide surprising results. figure spectrograms utterance snufﬂes happier. smells better. reference utterance unseen speaker. synthesized utterance conditioned reference embedding. synthesized utterance model without reference conditioning. figure pitch tracks utterance snufﬂes happier. smells better. pitch indicates unvoiced segment. reference utterance unseen speaker. synthesized utterance conditioned reference embedding. synthesized utterance model without reference conditioning. capture prosodic features time detail isn’t clear would mean transfer prosodic features radically different utterance. expected drastic changes sentence phrase structure result undesirable prosody transfer. case suited models capture less granular features prosody emotion style. example applies similar approach learning representations global style. nonetheless include number examples demo page demonstrating text transformations performed without compromising intelligibility desired prosody. highly useful building templated dialogue systems capable synthesizing template desired prosody. table results anchored prosody side-by-side subjective evaluation show reference-based synthesis matches reference audio signiﬁcantly better baseline model. however evaluation assess whether target speaker identity preserved synthesis. accidental pitch pacing prosodic characteristics factor speaker identity thus difﬁcult prescribe exactly aspects audio samples include demo page show model preserves many important aspects speaker identity prosody transfer. include grid audio examples representative typical performance system reference clips speakers distinct accents. utterance synthesized times different target speaker. notably prosody clip matches reference distinct accents vocal tract properties speaker preserved. however listening samples male voice controlling female voice reveals prosody representation encodes pitch absolute manner. controlled male reference signal female target speakers sound they’re imitating person deeper voice. similarly controlled female reference signal male speakers sound they’re imitating person higher voice. suggests prosody speaker representations somewhat entangled. universe speakers known training time. architecture uses strided convolutions gru-based aggregation reference encoder architecture section independently trained ground truth spectrograms using -speaker dataset used train multi-speaker model. architecture achieves accuracy held-out ground truth synthesized audio baseline -speaker model. tested prosody-enhanced tacotron using model. ﬁrst constructed pairs target speakers reference utterances test set. used prosody-enhanced tacotron generate spectrograms pairs output speaker identiﬁcation model. speaker identiﬁcation model identiﬁed spectrograms originating reference speaker test examples target speaker time refer reader audio samples understand surprising audio samples sound substantially like target speaker every sample we’ve listened since model seems transfer prosody pitchabsolute manner experiment trained speaker identiﬁcation model melfrequency cepstral coefﬁcients contain less pitch content. case speaker identiﬁcation model identiﬁed utterances originating reference speaker time target speaker time suggesting that indeed speaker-dependent pitch content transferred reference output. figure effect bottleneck size quantitative metrics. terms models prosody encoders beat baseline. bottleneck size increases performance metrics improve. softmax severe bottleneck tanh exhibits worse metrics. reference encoder output. experiment single speaker reference signal target plot metrics varying bottleneck size activation figure include series audio samples demo page. conclude increasing bottleneck size allows signiﬁcantly information reference output allowing better reproduction reference. interestingly using softmax activation leads degradation metrics comparison tanh probably exponential suppression non-maximal components softmax. quantitative metrics agreement audio samples provided demo page larger bottlenecks tanh activation improve audio similarity outputs faithful reference prosody. potential tradenarrower bottleneck would likely better preserve speaker identity target speaker. work demonstrated prosody transfer end-to-end learned representation prosody directly acoustic signals. system successfully transfers prosody speaker another pitchabsolute manner. future work focus encoding prosody pitch-relative manner speaker identity completely preserved transfer. substantial open question disentangle textual information implicit reference signal prosodic information. section showed possible extent especially transcripts relatively close. generally amounts transferring controlling prosody using utterances different corresponding text transcripts. noted earlier somewhat ill-deﬁned task careful formalization problem needed make real progress. also deﬁned objective subjective metrics evaluating prosody transfer evaluated architecture benchmarks. solidifying metrics quantify desired aspects prosody transfer important step long-term progression end-to-end prosody work. references arık sercan diamos gregory gibiansky andrew miller john peng kainan ping raiman jonathan zhou yanqi. deep voice multi-speaker neural text-to-speech. arxiv preprint arxiv. kyunghyun merrienboer gulcehre caglar bougares schwenk bengio yoshua. learning phrase representations using encoder-decoder statistical machine translation. kyunghyun merri¨enboer bart gulcehre caglar bahdanau dzmitry bougares fethi schwenk holger bengio yoshua. learning phrase representations using encoder-decoder statistical machine translation. arxiv preprint arxiv. https//arxiv.org/abs/.. ioffe sergey szegedy christian. batch normalization accelerating deep network training reducing internal covariate shift. international conference machine learning kinnunen tomi juvela lauri alku paavo yamagishi junichi. non-parallel voice conversion using i-vector plda towards unifying speaker veriﬁcation transformation. icassp alwan abeer. reducing frame error tracking algorithms noisy conditions unvoiced/voiced classiﬁcation frontend. acoustics speech signal processing icassp ieee international conference ieee coile bert tichelen vorstermans annemie jang staessen protran prosody transplantation tool text-to-speech applications. international conference spoken language processing icslp yokohama japan september http//www.isca-speech. org/archive/icslp_/i_.html. eyben florian buchholz sabine braunschweiler norbert. unsupervised clustering emotion voice styles expressive tts. acoustics speech signal processing ieee international conference ieee kubichek mel-cepstral distance measure objective speech quality assessment. communications computers signal processing ieee paciﬁc conference volume ieee nakashika toru takiguchi tetsuya minami yasuhiro nakashika toru takiguchi tetsuya minami yasuhiro. non-parallel training voice conversion using adaptive restricted boltzmann machine. ieee/acm trans. audio speech lang. proc. november nakatani tomohiro amano shigeaki irino toshio ishizuka kentaro kondo tadahisa. method fundamental frequency estimation voicing decision application infant utterances recorded real acoustical environments. speech communication nose takashi yamagishi junichi masuko takashi kobayashi takao. style control technique hmmieice transacbased expressive speech synthesis. tions information systems wang yuxuan stanton daisy zhang skerry-ryan battenberg eric shor joel xiao ying saurous style tokens unsupervised style modeling control transfer end-to-end speech synthesis. arxiv preprint shen jonathan pang ruoming weiss schuster mike jaitly navdeep yang zongheng chen zhifeng zhang wang yuxuan skerry-ryan saurous agiomyrgiannakis yannis yonghui. natural synthesis conditioning wavenet spectrogram predictions. arxiv preprint arxiv. https//arxiv.org/abs/. silverman beckman mary pitrelli john ostendorf mori wightman colin price patti pierrehumbert janet hirschberg julia. tobi standard labeling english prosody. second international conference spoken language processing tesser fabio sommavilla giacomo paci giulio cosi piero. experiments signal-driven symbolic prosody statistical parametric speech syntheeighth isca workshop speech synthesis sis. http//ssw.talp.cat/papers/ ssw_ps-_tesser.pdf. wang yuxuan skerry-ryan stanton daisy yonghui weiss jaitly navdeep yang zongheng xiao ying chen zhifeng bengio samy quoc agiomyrgiannakis yannis clark saurous tacotron towards end-to-end speech synthesis. proceedings interspeech august https//arxiv.org/abs/.. wang yuxuan skerry-ryan xiao ying stanton daisy shor joel battenberg eric clark saurous uncovering latent style factors expressive speech synthesis. mlaudio workshop nips figure subjective evaluation template described section human rater presented three stimuli reference speech sample competing samples evaluate. rater asked rate whether prosody closer reference -point scale. scale ranges much closer both distance much closer naturally mapped integers prior collecting ratings provide raters examples prosodic attributes evaluate explicitly instruct raters ignore audio quality pronunciation differences. triplet evaluated collect independent ratings. rater used items single evaluation. analyze data subjective tests average scores compute conﬁdence intervals.", "year": "2018"}