{"title": "A Deep Learning Approach for Privacy Preservation in Assisted Living", "tag": "eess", "abstract": " In the era of Internet of Things (IoT) technologies the potential for privacy invasion is becoming a major concern especially in regards to healthcare data and Ambient Assisted Living (AAL) environments. Systems that offer AAL technologies make extensive use of personal data in order to provide services that are context-aware and personalized. This makes privacy preservation a very important issue especially since the users are not always aware of the privacy risks they could face. A lot of progress has been made in the deep learning field, however, there has been lack of research on privacy preservation of sensitive personal data with the use of deep learning. In this paper we focus on a Long Short Term Memory (LSTM) Encoder-Decoder, which is a principal component of deep learning, and propose a new encoding technique that allows the creation of different AAL data views, depending on the access level of the end user and the information they require access to. The efficiency and effectiveness of the proposed method are demonstrated with experiments on a simulated AAL dataset. Qualitatively, we show that the proposed model learns privacy operations such as disclosure, deletion and generalization and can perform encoding and decoding of the data with almost perfect recovery. ", "text": "abstract—in internet things technologies potential privacy invasion becoming major concern especially regards healthcare data ambient assisted living environments. systems offer technologies make extensive personal data order provide services context-aware personalized. makes privacy preservation important issue especially since users always aware privacy risks could face. progress made deep learning ﬁeld however lack research privacy preservation sensitive personal data deep learning. paper focus long short term memory encoderdecoder principal component deep learning propose encoding technique allows creation different data views depending access level user information require access efﬁciency effectiveness proposed method demonstrated experiments simulated dataset. qualitatively show proposed model learns privacy operations disclosure deletion generalization perform encoding decoding data almost perfect recovery. dramatic demographic change western countries increase need development ambient intelligence technologies making artiﬁcial intelligence machine learning data protection regulations applying onwards make privacy aware machine learning necessary consequently issues privacy security safety data protection move focus thereby fostering integrated approach emphasizes importance human-in-the-loop. currently major threats privacy come personal data aggregation increasing power data mining pattern recognition techniques well healthcare data sharing analysis. number information sources increases potential combine sources proﬁle users learn sensitive information also increases makes great threat individual privacy. important issue especially ﬁeld address threats mentioned previously propose model encoding sharing combined healthcare data. model aims achieve privacy input data distributed various stakeholders. protect privacy long short-term memory encoder-decoder system designed allows creation different data views correspond access level receiver. remainder paper organized follows. section presents overview existing privacy techniques related work deep learning privacy. section introduces proposed privacy model. section describes case study explains performed experiments section presents results performance algorithm. lastly section includes conclusion suggestions future work. section divided three parts. ﬁrst part gives overview privacy deﬁnitions identiﬁers. second describes previous work done regards privacy preserving techniques third part gives introduction deep learning overview existing work privacy protection deep learning techniques. general data protection regulation deﬁnes personal data information relating identiﬁed identiﬁable natural person speciﬁcally acknowledges includes ‘direct’ ‘indirect’ identiﬁcation. identiﬁcation means identiﬁcation number factors speciﬁc physical physiological mental economic cultural social identity. privacy deﬁnition able encompass different aspects privacy privacy enhancing technologies protect users’ privacy based technology offer additional levels protection relying laws policies. order address privacy concerns users several approaches proposed research community. approaches include information manipulation privacy context awareness access control data anonymization. sections anonymization analyzed since methods commonly used privacy preservation. k-anonymity well-known method anonymize data releasing k-anonymity kanonymized dataset record indistinguishable least records regards speciﬁc identifying attributes k-anonymity achieved suppressing generalizing attributes data means attribute replaced less speciﬁc semantically consistent value utility privacy data connected. increase data privacy without also decreasing data utility objective problems maximize utility minimizing amount generalization suppression. achieving -anonymity generalization objective constraint nondeterministic polynomial-time hard problem cannot solved fully automatically cases -anonymity able prevent identity disclosure record k-anonymized data cannot connected corresponding record original data set. cases fail protect attribute disclosure. l-diversity method developed address weaknesses k-anonymity shown guarantee privacy adversaries background knowledge cases data lacking diversity. l-diversity anonymization conditions satisﬁed group records sharing combination attributes -well-represented values conﬁdential attribute disadvantage method depends range sensitive attributes. l-diversity applied sensitive attribute many different values artiﬁcial data inserted. artiﬁcial data improve privacy result problems analysis thus ruining utility data. also method vulnerable skewness similarity attack cannot always prevent attribute disclosure. t-closeness shown l-diversity might always sufﬁcient preventing attribute disclosure. since account semantic closeness sensitive values. method named tcloseness proposed address problems. method requires distribution sensitive attributes equivalent class close distribution attribute overall table turn means distance distributions speciﬁed threshold authors describe ways check t-closeness computational procedure enforce property given authors proposing t-closing method mention t-closeness limits amount useful information released. increase utility data increase threshold turn decreases privacy protection. seen overview strengths weaknesses technique k-anonymity anonymization methods always successful guarantying information leaked ensuring usable data levels. methods k-anonymity l-diversity always accomplish complete privacy method t-closeness provides sometimes expense correlations conﬁdential attributes attributes. also computational method speciﬁc dataset anonymized additional problem method. papers deﬁning k-anonymity l-diversity propose approaches based generalization suppression times cause numerical attributes become categorical. case t-closeness computational procedure reach described. thus issues ﬁeld still open conceptual computational level improved deﬁning better properties creating effective methods. deep learning promising area machine learning research signiﬁcant success recent years. applications deep learning used various systems image speech recognition data analysis social media bioinformatics medicine healthcare. usually deep learning architectures constructed multi-layer neural networks. several different neural network architectures recurrent neural network feed-forward neural network deep belief network deep learning ability transform original data higher level abstract expressions. means high-dimensional original data converted low-dimensional data training multiple neural networks reconstruct high-dimensional input data. however existing literature privacy protection mostly focuses traditional privacy preserving methods described previous section deep learning. differential privacy proposed dwork approaches privacy protection makes machine learning methods. applications differential privacy include boosting principal component analysis linear logistic regression support vector machines risk minimization continuous data processing however relevant work paper used encoder-decoder system protect private information videos extracting privacy region scrambling encoding. system allows users fully restore original video legitimate otherwise private regions video. long short term memory networks special kind capable learning long-term dependencies basic sequence-to-sequence model introduced consists recurrent neural networks ﬁrst encoder processes input second decoder generates output. recurrently connected blocks lstm layers known memory blocks. block contains memory cells composed three units input gate forget gate output gate. gates modulate interactions memory cell environment. figure shows single cell lstm memory block. lstm assist error minimization error back-propagated time layers. maintaining constant error recurrent network continue learn many time steps thus able link causes effects. model developed work uses multilayered long short-term memory encoder input sequence vector ﬁxed dimensionality another lstm used decode target sequence vector. encoder network part network takes input sequence maps encoded representation sequence. encoded representation used decoder network generate output sequence. makes framework lock analogy someone correct able access resources behind lock multiple hidden layers neural networks characteristics enable kind learning along mapping experiments conducted using basis lstm encoder-decoder model introduced previous section. following sections describe evaluation case scenario details simulated dataset used study followed modeling training methodology. john years lives ambient assisted living environment. widowed recently diagnosed alzheimer’s disease. currently lives alone likes stay touch family friends. environment lives gives independence allows control home automation system example remotely open close windows/doors control lighting heating alarm system. also allows monitoring vital signs offers reminders medication appointments. sensors deployed home send collected information cloud offering access family members care givers doctors researchers. case scenario four different views data created depending access level receiver preferences user user scenario close relationship family trusts caregiver selected almost information accessible them especially feels safer knowing able help case emergency. regards doctors allowed basic personal medical information visible different view created them. ﬁnally research purposes view created show explicit personal data sensitive attributes generalized. described previously proposed model makes lstm neural network architecture learns encode variable-length input sequence ﬁxed-length vector representation decode given ﬁxed-length vector representation back variable-length sequence. neural network three types operations applied encoder input decoder. three operations disclosure means keeping data deletion removing data generalization means replacing value less speciﬁc semantically consistent value. data entry fully disclosed receiver generalized deleted. value given attribute different range aligned real life values. four separate views created different receivers family member doctor caregiver researcher. receiver different decoder output privacy clearances patient information figure overall functionality encoder decoder lstm layers model depicted. figure show detail privacy operations work model reads input sentence john alzheimer produce dementia output sentence. instance operation deletion applied name attribute ‘john’ transformed operation generalization applied disease attribute changes ‘alzheimer’ ‘dementia’. model stops making predictions outputting end-of-string token ‘eos’. purposes work data related simulated. type data selected divided three categories personal medical smart home sensor attributes. entry simulated data includes three kinds attributes. personal attributes explicitly identify person name address phone number. second includes attributes could potentially identify person gender birth date. lastly third category includes sensitive medical information sensor data like blood pressure medical history presence sensors name gender height weight address phone number occupation marital status timestamp blood pressure glucose level disease wearable pedometer presence sensor temperature sensor light sensor window sensor external sensor energy consumption abbreviations fully disclosed generalized deleted simulation data based real world data collected environments included personal information health care data well smart home sensor data. data simulated users user entries. experiments models trained data entries tested unseen entries. user entry consisted different attribute shown table corresponding values entry characters most. different attributes separated order easily distinguish different attributes entry. character used dictionary. sequence maximum characters long ends special token ‘eos’. order handle different sequence lengths zero padded entry maximum number characters case encoder decoder comprise lstm network hidden units trained adam learning rate qualitatively analyzed trained model’s results comparing decoded outputs expected model output privacy operations. qualitative analysis shows lstm encoder decoder good learning privacy operations disclosure generalization deletion well capturing speciﬁed preferences access information table. example results model seen following ﬁgures. seen right encoder-decoder mechanism user’s information transferred almost perfectly researcher appropriate privacy rules applied researcher’s access level. since encoded vector shared possible user information without right decoder. figure showcases beneﬁcial parts model. case explore possibility caregiver tries access data meant researcher. encoded vector user information shared would possible decode unless right decoder used. encoder decoder match possible decode access user’s private information. receiver correct decoder almost impossible right decoder weights since high dimensional ﬂoating point vector. model average character error entry testing. characters error given length characters entry close perfect recovery. different decoders trained view close error testing. decoders shown capable deleting generalizing keeping information given encoder. qualitative analysis trained model results shows time character mistake attribute timestamp. attribute error incremental nature timestamp attribute investigated additional experiments. results show encoder-decoder model able learn operation rules privacy setting disclosing generalizing deleting speciﬁc attributes. thus model able learn users’ preferences regards privacy policy create subdatasets receiver appropriate information one. lstm encoder-decoder model able learn privacy operations disclosure generalization deletion data therefore generate different data views data receivers encrypted way. allows users train independently datasets selectively share small subsets attributes speciﬁc receivers creating different views one. offers attractive point regards utility privacy trade-off. goals achieved end-to-end manner using lstm based encoder decoder. encoded version user information second decode encoded information according privacy rules deﬁned user. encoded private information user decoded unless right decoder used. adversary tried using different decoder encoded information system would disclose information. without right decoder would possible train decoder encoded andreas holzinger randy goebel vasile palade massimo ferri. towards integrative machine learning knowledge extraction. lecture notes artiﬁcial intelligence lnai pages springer cham andreas holzinger markus plass katharina holzinger gloria cerasela crisan camelia-m. pintea vasile palade. glass-box interactive machine learning approach solving np-hard problems human-in-the-loop. arxiv. andreas holzinger klaus schaupp walter eder-halbedl. investigation acceptance ubiquitous devices elderly geriatric hospital environment using example person tracking. lecture notes computer science lncs pages springer heidelberg ninghui tiancheng suresh venkatasubramanian. t-closeness privacy beyond k-anonymity l-diversity. data engineering icde ieee international conference pages ieee ashwin machanavajjhala daniel kifer johannes gehrke muthuramakrishnan venkitasubramaniam. l-diversity privacy beyond kanonymity. transactions knowledge discovery data bernd malle peter kieseberg sebastian schrittwieser andreas holzinger. privacy aware machine learning right forgotten. ercim news paul ohm. broken promises privacy responding surprising benjamin rubinstein peter bartlett ling huang nina taft. learning large function space privacy-preserving mechanisms learning. arxiv preprint arxiv. anand sarwate kamalika chaudhuri. signal processing machine learning differential privacy algorithms challenges ieee signal processing magazine continuous data. deepika singh johannes kropf sten hanke andreas holzinger. ambient assisted living technologies perspectives older people professionals. lecture notes computer science lncs pages springer cham zhang zhenjie zhang xiaokui xiao yang marianne winslett. functional mechanism regression analysis differential privacy. proceedings vldb endowment zhang dequan zheng xinchen ming yang. bidirectional long short-term memory networks relation classiﬁcation. paclic martina zieﬂe carsten rcker andreas holzinger. medical technology smart homes exploring user’s perspective privacy intimacy trust. compsac pages ieee munich information high dimensionality lstm hidden state vector possible values lstm network parameter. users preserve privacy data receiving beneﬁts environment. moreover model handle data even text format beneﬁcial case medical records usually include doctors’ nurses’ notes. work preliminary experimental study preserving privacy lstm encoders-decoders. model’s limitations tokenization attributes improve performance. another limitation simulated data means contain missing abnormal values evaluate robustness method. future work also include expansion model real world data well complex data formats meta-data multimedia formats. kamalika chaudhuri anand sarwate kaushik sinha. nearoptimal algorithm differentially-private principal components. journal machine learning research kyunghyun bart merri¨enboer caglar gulcehre dzmitry bahdanau fethi bougares holger schwenk yoshua bengio. learning phrase representations using encoder-decoder statistical machine translation. arxiv preprint arxiv. josep domingo-ferrer vicenc¸ torra. critique k-anonymity enhancements. ares pages ieee cynthia dwork. differential privacy. encyclopedia cryptography christoph goller andreas kuchler. learning task-dependent distributed representations backpropagation structure. neural networks ieee international conference volume pages ieee", "year": "2018"}