{"title": "Inference of Spatio-Temporal Functions over Graphs via Multi-Kernel  Kriged Kalman Filtering", "tag": "eess", "abstract": " Inference of space-time varying signals on graphs emerges naturally in a plethora of network science related applications. A frequently encountered challenge pertains to reconstructing such dynamic processes, given their values over a subset of vertices and time instants. The present paper develops a graph-aware kernel-based kriged Kalman filter that accounts for the spatio-temporal variations, and offers efficient online reconstruction, even for dynamically evolving network topologies. The kernel-based learning framework bypasses the need for statistical information by capitalizing on the smoothness that graph signals exhibit with respect to the underlying graph. To address the challenge of selecting the appropriate kernel, the proposed filter is combined with a multi-kernel selection module. Such a data-driven method selects a kernel attuned to the signal dynamics on-the-fly within the linear span of a pre-selected dictionary. The novel multi-kernel learning algorithm exploits the eigenstructure of Laplacian kernel matrices to reduce computational complexity. Numerical tests with synthetic and real data demonstrate the superior reconstruction performance of the novel approach relative to state-of-the-art alternatives. ", "text": "dependencies among them interested predicting price stocks network knowing price some. paramount importance applications collecting attributes nodes prohibitive case sampling large-scale graphs attribute interest sensitive nature transmission social network. task ﬁrst formulated reconstructing time-invariant function graph follow-up reconstruction approaches leverage notions graph bandlimitedness sparsity overcomplete dictionaries smoothness graph uniﬁed approximations nonparametric graph functions drawn reproducing kernel hilbert space also semi-parametric alternatives. network connectivity node attributes change time. case e.g. ﬁnance network stock prices change time also interdependencies. hence maximizing reconstruction performance time-varying signals necessitates judicious modeling space-time dynamics especially samples scarce. inference time-varying graph functions pursued mainly slow variations temporal dynamics modeled assuming covariance function reconstructed available. hand spatiotemporal reconstruction generally dynamic graphs approached using extended graph kernel matrix model block tridiagonal structure lends computationally tractable iterative solver however neither relies dynamic model function variability provides tractable method learn best kernel data. furthermore adapt changes spatiotemporal dynamics graph function. abstract—inference space-time varying signals graphs emerges naturally plethora network science related applications. frequently encountered challenge pertains reconstructing dynamic processes given values subset vertices time instants. present paper develops graph-aware kernel-based kriged kalman ﬁlter accounts spatio-temporal variations offers efﬁcient online reconstruction even dynamically evolving network topologies. kernelbased learning framework bypasses need statistical information capitalizing smoothness graph signals exhibit respect underlying graph. address challenge selecting appropriate kernel proposed ﬁlter combined multi-kernel selection module. data-driven method selects kernel attuned signal dynamics on-the-ﬂy within linear span pre-selected dictionary. novel multi-kernel learning algorithm exploits eigenstructure laplacian kernel matrices reduce computational complexity. numerical tests synthetic real data demonstrate superior reconstruction performance novel approach relative state-of-the-art alternatives. number applications involve data admit natural representation terms node attributes social economic sensor communication biological networks name inference task emerges context predict extrapolate attributes nodes network given attributes subset them. ﬁnance network nodes correspond stocks edges capture deterministic model time-varying graph functions proposed spatial dynamics captured network connectivity temporal dynamics described graph-aware state-space model. based model algorithm termed kernel kriged kalman ﬁlter developed obtain function estimates minimizing kernel ridge regression criterion online fashion. proposed solver generalizes traditional network kriged kalman ﬁlter relies probabilistic model. novel estimator forgoes assumptions data distributions stationarity promoting space-time smoothness dynamic kernels graphs. appropriate kernel multikernel krikf developed based multikernel learning framework. algorithm adaptively selects kernel best data dynamics within linear span prespeciﬁed kernel dictionary. structure laplacian kernels exploited reduce complexity order kekrikf. complexity linear number time samples renders kekrikf mkrikf appealing online operation. rest paper structured follows. sec. contains preliminaries states problem. sec. introduces spatio-temporal model develops kekrikf. sec. endows kekrikf module obtain mkrikf. finally numerical experiments conclusions presented secs. respectively. notation scalars denoted lowercase column vectors bold lowercase matrices bold uppercase letters. superscripts respectively denote transpose pseudo-inverse; stands all-one vector; diag corresponds diagonal matrix entries diagonal diag vector holding diagonal entries gaussian distribution mean variance finally matrix vector problem statement preliminaries consider time-varying graph denotes vertex adjacency matrix whose entry nonnegative weight edge connecting vertices time edge vertices connected time graphs {gt}t paper undirected self-loops means laplacian matrix diag {atn} positive semideﬁnite provided sec. ii-a. time-varying graph function time indices. speciﬁcally represents value attribute interest node time e.g. closing price n-th stock t-th day. vector collects function values time suppose noisy observations available time nst} contains indices sampled vertices captures observation error. observation model promotes estimates certain structure. examso-called laplacian regularizer ann) promotes smooth function estimates similar values vertices connected strong links since small smooth. turns flf; e.g. scalar function general graph kernel family regularizers obtained fk†f uncorrelated reduces linear minimum mean-square error estimator thus generalizes lmmse interpreted lmmse estimator random signal covariance matrix section presents space-time varying model capable accommodating fairly general forms spatio-temporal dynamics. building model novel online estimator subsequently developed graph functions time-varying graphs. per-slot preselected kernel matrix superscript explained later. unfortunately approach account possible dynamics relating however leveraging dependencies across slots beneﬁt estimator observations {yτ}τ=t. captures arbitrary temporal dynamics across sampling intervals interpreted instantaneous component represents structured varying component. example consider stock price prediction accounts instantaneous changes caused e.g. political statements company announcements relative captures steady evolution stock market stock prices slot closely related prices stocks delving components modeled termed laplacian kernel. clearly subsumes special cases tested simulations collected table scalar functions plotted prior knowledge properties guides selection appropriate dataadaptive selection techniques sec. broadening scope generalized laplacian kernel regularizers arbitrary positive semideﬁnite matrix necessarily laplacian kernel. regularizers give rise family kernel ridge regression estimators scalars control trade-off smoothness data regularizers effect smoothness prescribed model. uncorrelated perturbations still captured setting laplacian kernel available prior ητ}t information steer selection suitable kernel matrices; available resort algorithm sec. directly solving would lead online algorithm since complexity approach grows sec. however develop next efﬁcient online algorithm obtain slot estimates notice overbar notation indicates matrices vectors recall without overbar counterparts sizes respectively. substituting arrive optimization problem depend rewrite next slot measurement error using smooth entries capvector tures instantaneous dependence among hand smooth also time models dependencies between time-lagged versions time slots adheres state equation graph transition matrix termed state noise. vector assumed smooth meaning expected similar recursion graph counterpart vector autoregressive model order lead computationally efﬁcient online estimators account temporal dynamics model thought graph counterpart model adopted derive kriged kalman ﬁlter. context here describes small-scale spatial ﬂuctuations within slot whereas captures so-called trend across slots. furthermore generalizes model used represents propagation transmission processing delays remark transition matrix interpreted adjacency generally directed transition graph relates simplicity estimating motivates graph version random walk model hand adherence graph prompts selection case amounts diffusion process time-invariant section develops online algorithm estimate given spatio-temporal model unfortuτ cannot obtained solving nately system equations comprising time even simply estimation replacing task involves unknowns namely criterion relies knowledge secondorder statistics here kekrikf derived deterministic kernel-based learning framework bypasses assumptions data distributions stationarity replaces knowledge second-order covariances knowledge moreover different novel kekrikf accommodate dynamic graph topologies provided remark complexity kekrikf slot. underlying graph large complexity managed splitting graph subgraphs n/ng nodes employing consensus-based decentralized schemes along lines performance estimators well known heavily depend choice kernel matrix unfortunately difﬁcult know kernel matrix appropriate given problem. address issue approach presented selects suitable kernel matrix within linear span prespeciﬁed dictionary using available data. since identical deterministic formulation kalman ﬁlter applied state-space model state noise covariance measurement noise covariance deduce algorithm e.g. applies readily obtain sequentially structured slot component substituting also slot instantaneous component t-th iteration so-termed kekrikf listed algorithm traditional krikf employed interpolate stationary processes deﬁned continuous spatial domains derivation follows probabilistic linear-minimum mean-square error theorem suggests online procedure approximate solution algorithm solver termed online kernel matching executed alternatingly. summarized algorithm termed multi-kernel krikf algorithm generally global optimum ﬁnding optimum critical practice since cannot computed polynomial time. rest section develops algorithm solving comprises laplacian kernels. ﬁrst step exploit fact laplacian kernel matrices associated given graph common eigenvectors. weighted norms namely nonτ separately convex convex. fortunately motivates alternating minimization strategies. algorithms minimize objective respect every block variables keeping variables ﬁxed conveniently ﬁxed reduces solved algorithm slot theorem conversely obtained ﬁxed theorem consider minimizing respect given necessarily global minimizers respect proposition establishes expressed kernels share eigenvectors case laplacian kernels; sec. ii-a. proposition function strongly convex differentiable gradient entails strongly convex differentiable objective projections feasible easy obtain motivate solve projected gradient descent besides simplicity converges linearly global minimum general iteration observe algorithm initialized output algorithm previous iterate namely θt−. warm start considerably speeds convergence algorithm since expected change slowly across iterations algorithm interesting byproduct algorithm ability adapt changes spatio-temporal dynamics graph functions adjusting coefﬁcients view proposition ﬁnding entry algorithm requires operations. computing gradient exploits common eigenvectors {k}m avoids inversion matrix required calculating gradient general formulation {k}m need share eigenvectors. complexity evaluating gradient therefore reduced prohibitive general kernels affordable laplacian kernels amounts considerable computational savings especially largescale networks. denoting number iterations convergence overall computational complexity therefore typically hence complexity algorithm learning appropriate linear combination kernels increase complexity order reduced suggested remark contains timestamped messages among students university california irvine exchanged social network days. sampling interval day. graph constructed edge weight counts number messages exchanged student k-th month hence changes across months. subset users corresponds connected graph selected. generated superimposing b-bandlimited graph function spatiotemporally correlated signal. speciﬁcally denote eigenvectors associated smallest eigenvalues generated according diffusion kernel function therefore smooth respect graph interpreted e.g. time n-th student spends speciﬁc social network t-th day. ﬁrst experiment justiﬁes proposed decomposition assessing impact dropping either right hand side krikf algorithm uses diffusion kernels parameters respectively. fig. depicts nmse kekrikf; kalman ﬁlter estimator results setting well kernel kriging kekrikf reduces observed kekrikf accounts summands outperforms algorithms account them. moreover nmse kekrikf reconstructing unavailable node values reveals algorithm capable efﬁciently capturing spatial well temporal dynamics time-varying topologies. next robustness kekrikf evaluated connectivity captured exhibits abrupt changes synthetic time-varying networks size generated using kronecker product model effectively captures properties real graphs prescribed seed matrix commodate scenario restart algorithm whenever topology changes time tc|tc well initialize replace laplacian kernels ones corresponding topology. section evaluates performance developed algorithms means numerical tests synthetic real data. proposed algorithms compared with least mean-square algorithm step size µlms; distributed least-squares reconstruction algorithm step sizes µdlsr βdlsr. dlsr track slowly time-varying b-bandlimited graph signals. performance aforementioned approaches quantiﬁed normalized mean-square error expectation taken sample locations matrix comprising rows whose indices tests chosen uniformly random without replacement kept constant time; parameters different algorithms selected using cross-validation minimize nmse. notice mkrikf learns kernel best data requires minimal parameter tuning. produces matrix denotes kronecker product. initial adjacency matrix constructed entries bernoulli) next following time-varying graph model generated entry changes probal |ξnn| choice based rich richer attribute real networks connections formed nodes high degree moreover edge deleted probability long graph remains connected. varying obtain different time-varying graphs. graph function generated time-varying graph follows graph-bandlimited component eigenvectors associated smallest eigenvalues algorithm employs bandlimited kernel diffusion kernel fig. plots nmse kekrikf algorithm function determines rapidly graph changes. observed kekrikf algorithm effectively cope different degrees time variation. consider dataset provided national climatic data center comprises hourly temperature measurements measuring stations across continental united states time-invariant graph constructed based geographical distances. value represents t-th temperature sample recorded n-th station. sampling interval hour ﬁrst experiment second. kekrikf employs diffusion kernels parameter transition matrix mkrikf conﬁgured follows contains diffusion kernels parameters contains diffusion kernels parameters identity kernel fig. depicts true temperature along estimates station sampled meaning clearly kekrikf accurately tracks temperature exploiting spatial temporal dynamics mkrikf outperforms kekrikf learning dynamics data. random sampling selection heavily affects performance algorithm; adaptive selection capita countries years time-invariant graph constructed using correlation different countries ﬁrst years. graph function denotes reported n-th country t-th year graph fourier transform ﬁrst years deﬁned denotes n-th eigenvector laplacian matrix; shows graph frequencies take small values large values otherwise. motivated aforementioned observation kekrikf conﬁgured band-reject kernel table mkrikf adopts band-reject fig. depicts actual well estimates greece contained sampled countries. clearly mkrikf kekrikf track evolution years greater accuracy considered alternatives. expected graph function adhere graph bandlimited model assumed dlsr lms. last dataset records measurements path delays internet backbone network comprises end-nodes directed links. delays available paths every minute. paths connect origin-destination nodes series links described path-link routing matrix whose entry path traverses link otherwise. graph constructed vertex corresponding paths timeinvariant adjacency matrix rn×n given expression selected assign greater weight edges connecting vertices whose associated paths share large number links. intuitively reasonable since paths common links usually experience similar delays function denotes delay milliseconds measured n-th path t-th minute. kekrikf algorithm employs diffusion kernel parameter mkrikf conﬁgured follows contains diffusion kernels parameters contains diffusion kernels parameters identity kernel randomly sampled path delays. delay maps traditionally employed depict network delay path time enable operators perform troubleshooting; also paths delay maps fig. sorted increasing order true delay clearly delay recovered mkrikf fig. visually resembles true delay fig. paper introduced online estimators reconstruct dynamic functions graphs. context function estimated decomposed parts capturing spatial dynamics jointly modeling spatio-temporal dynamics means state-space model. novel kernel kriged kalman ﬁlter developed using deterministic rkhs approach. accommodate scenarios limited prior information online multi-kernel learning technique also developed allow tracking spatio-temporal dynamics graph function. structure laplacian kernels exploited achieve computational complexity. numerical tests synthetic well real-data novel algorithms observed perform markedly better existing alternatives. future work includes distributed implemen romero leus wideband spectrum sensing compressed measurements using spectral prior information ieee trans. sig. process. vol. romero giannakis kernel-based reconstruction graph signals ieee trans. sig. process. vol. feb. shen baingana giannakis nonlinear structural vector autoregressive models inferring effective brain network connectivity arxiv preprint arxiv.v shuman narang frossard ortega vandergheynst emerging ﬁeld signal processing graphs extending high-dimensional data analysis networks irregular domains ieee sig. process. mag. vol. wikle cressie dimension-reduced approach space-time kalman ﬁltering biometrika zhou sch¨olkopf regularization framework learning graph data icml workshop statistical relational learning connections fields vol. banff", "year": "2017"}