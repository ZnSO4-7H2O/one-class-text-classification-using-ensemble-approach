{"title": "Nebula: F0 Estimation and Voicing Detection by Modeling the Statistical  Properties of Feature Extractors", "tag": "eess", "abstract": " A F0 and voicing status estimation algorithm for high quality speech analysis/synthesis is proposed. This problem is approached from a different perspective that models the behavior of feature extractors under noise, instead of directly modeling speech signals. Under time-frequency locality assumptions, the joint distribution of extracted features and target F0 can be characterized by training a bank of Gaussian mixture models (GMM) on artificial data generated from Monte-Carlo simulations. The trained GMMs can then be used to generate a set of conditional distributions on the predicted F0, which are then combined and post-processed by Viterbi algorithm to give a final F0 trajectory. Evaluation on CSTR and CMU Arctic speech databases shows that the proposed method, trained on fully synthetic data, achieves lower gross error rates than state-of-the-art methods. ", "text": "glottal source analysis framework) recent method ﬁnds balance heuristics probabilities datadependent parameters. yang ﬁrst divides input speech overlapping frequency channels. channel instantaneous frequency features extracted ﬁxed time interval. features channels converted mixture distribution heuristics smooth trajectory tracked using viterbi search. previous work successfully reduced error yang algorithm calibrating estimator synthetic speech data. study takes idea data-free modeling speech feature extractors step training gaussian mixture models entire feature extraction framework synthetic speech input. show good generalization achieved appropriate choice feature extractors meeting certain assumptions allowing relaxation synthetic data generator. paper organized follows section begins theoretical discussion sets ground algorithm design followed overview proposed method. estimation voicing detection stages explained section section respectively. section evaluates proposed method speech databases analyzes results. finally paper concluded section strategy training regression classiﬁcation models synthetic data received moderate attention image recognition knowledge idea rather underexplored area speech analysis possibly lack high-quality speech synthesizer matches distribution natural speech signals. circumvent chicken-andegg problem building near-perfect speech synthesizer studying speech analysis asking conditions requirements training data relaxed? question points general methodology problem reduction context speech signal analysis factorizing scope dimension variables modeled vicinity time-frequency point. time-frequency localized problem requires synthetic data generator reproduces fragments speech signals microscopic level example short sine waves noises without modeling formant structure variations. said locality condition easily using short analysis window band-pass ﬁltering; reduction timedomain waveforms small number variables done using feature extractors. found yang provides powerful feature extraction framework satisfying conditions mentioned. speciﬁcally frame instantaneous frequency estimated logarithmically spaced overlapping frequency channels coverf voicing status estimation algorithm high quality speech analysis/synthesis proposed. problem approached different perspective models behavior feature extractors noise instead directly modeling speech signals. time-frequency locality assumptions joint distribution extracted features target characterized training bank gaussian mixture models artiﬁcial data generated monte-carlo simulations. trained gmms used generate conditional distributions predicted combined post-processed viterbi algorithm give ﬁnal trajectory. evaluation cstr arctic speech databases shows proposed method trained fully synthetic data achieves lower gross error rates state-of-the-art methods. index terms fundamental frequency monte-carlo simulation gaussian mixture model feature extractor problem estimating fundamental frequency voicing status speech signals extensively explored using combination signal processing heuristic techniques. classical methods rely time-domain measurement auto-correlation normalized auto-correlation selection candidates spectral domain mixed domain also studied varying degrees consistency across databases noise levels. recent trend rise probabilistic estimation methods often attempt reduce heuristic elements algorithm ultimately achieve consistent performance without expert’s intervention. particular class data-driven methods indirectly perform estimation inference features extracted input signal. notably safe bears similarities method statistical framework employed signal-to-noise ratio features used discrimination harmonic noise. however method speciﬁcally designed information extraction peaks allow incorporating types signal features. another related approach sacc predicts distribution using feed-forward neural network trained frequency-dependent auto-correlation functions. modeling speech features instead formulating problem directly waveform makes model less prone inaccurate assumptions speech signals aside reducing mathematical complexity. downside characterization speech features often relies data-driven techniques distribution ﬁtting regression making performance data-dependent extent. yang algorithm channel second estimators added twice channel frequency third estimator added half channel frequency. although inclusion feature extractors different frequencies violates frequency locality condition preliminary test revealed reduction double half frequency errors leads lower overall error rate. rest inference algorithm focuses converting feature vectors posterior distributions performing tracking likelihood combining posterior distributions frames. k-th channel ﬁrst deﬁne feature vector interest lies recovering augmented vector truncated version essentially estimate last element estimates multiple channels combined give robust posterior distribution. given trained channel using synthetic data deﬁned section recovery done similar gmm-based voice conversion concretely joint density k-th channel deﬁned next conditional probabilities channels combined independence assumption. however correlation features neighboring channels simple summation conditionals would over-emphasize ﬁrst harmonics. thus distribution deﬁned every time-frequency point. outlined figure distributions found ﬁtting gaussian mixture models synthetic data generated monte-carlo simulations. models trained conditional distribution computed arbitrary input data long time-frequency local distributions unseen data covered priors monte-carlo simulations. seen discussion proposed system designed model statistical properties speech feature extractors instead complicated process speech itself. rationale choosing priors data fabrication rather mimicking speech signals becomes covering much assumption-deﬁned signal space possible fully characterize feature extractors. though less relevant expert knowledge speech phenomena speciﬁed implicitly choice feature extractors signal model data generator. study synthetic data generated harmonic-noise model deﬁned follows shown boldface random variables speciﬁed priors overall following log-uniform distribution amplitude k-th harmonic following log-uniform distribution fundamental frequency following log-uniform distribution covering speech singing. similar quadratically-interpolated method sinusoidal analysis finally estimation algorithm gives continuous log-f trajectory. voicing status determined explained following section. estimation stage outputs time-frequency likelihood map. regions exhibiting strong periodicity likelihood tends unimodal across frequency; noisy silent regions likelihood general exempliﬁed second plot figure thus comes naturally interpret peak likelihood indication voicing status. hard threshold peak likelihood separate voiced unvoiced regions reasonably-well vulnerable random likelihood ﬂuctuations unvoiced regions. direction improving robustness instead taking maxfl deﬁne peak likelihood voicing decision consistent estimate. addition peak likelihood sequence decoded two-state hidden markov model states mapped voiced/unvoiced status reduce spontaneous errors. two-state requires pair observation distributions characterizing peak likelihood voiced unvoiced frames. following strategy computing calibration function lcal another monte-carlo simulation performed white noise input signals peak likelihood extracted. empirically found follows normal distribution; grid-approximation log-spaced frequency bins mean variance note mean close slightly greater probability mass uniform distribution distribution peak likelihood voiced regions however cannot determined simulation voiced speech vary depending environment linguistic context. assuming distribution question also normal estimate mean variance peak likelihood run-time using baum-welch algorithm. training starts initial mean initial variance transition probability voiced unvoiced states ﬁxed thop/. thop time interval estimation. binary sequence voicing status efﬁciently estimated peak likelihood using viterbi algorithm. dithering. observed voicing detector prone picking small sinusoidal interferences silent unvoiced regions. simple dither input signal white noise maximal amplitude. smoothing likelihood map. current design estimators assumes quasi-stationary harmonic amplitude. manual inspection harmonic estimated speech signals show amplitude modulation vowel onsets endings causes underestimated causing voicing decision errors later stage algorithm. alleviate problem likelihood smoothed moving average ﬁlter prior voicing detection. order ﬁlter inversely proportional frequency important non-obvious issue regarding unnormalized likelihood that non-uniform spacing frequency channels log-uniform distributed priors monte-carlo simulation could biased towards certain frequency range. inspection results speech data tells exhibits systematic bias favoring lower frequencies. bias compensated subtracting expectation unnormalized likelihood computed white noise inputs inference. said expectation denoted calibration function lcal. normalization posterior density obtained frame procedure described above feature extraction computing posteriors repeated ﬁxed time interval yielding likelihood across time frequency robustly track peak frequency likelihood ﬁrst sampled log-spaced frequency grid passed viterbi path searcher observation probability. transition probability viterbi search constrains ﬁrst-order dynamics according zero-mean normal distribution standard deviation oct/s. resulting sequence frequency indices reﬁned using quadratic interpolation likelihood figure example estimated using nebula versus reference extracted signal taken highest-error sentence speaker bdl. nebula failed track rapid pitch rises drops. hand reference subjected half-pitch errors. vde-v observed male speaker large errors explained observation features less regular glottal pulse pattern compared speakers database causing errors nebula’s predictions reference finally large vde-u speaker also found caused errors reference noises present signals. concerning evaluation become systematically biased inaccurately extracted reference repeated analysis table speakers only. accuracy ranking however remained same. evaluation yields convincing evidences better accuracy proposed method least comparable state-of-the-art results estimation. rigorous evaluation requires expert-annotated reference attempted given limited time. paper presented nebula voicing status estimation algorithm. signiﬁcant contribution study novel methodology speech signal analysis characterizing statistical properties feature extractors using montecarlo simulation claim requirements speech prior relaxed timefrequency local feature extractors supported objective evaluation male female speakers nebula trained fully synthetic data outperformed state-of-the-art methods gross pitch error achieved overall best average performance. believe statistical feature extractor modeling technique also applications topics speech analysis example estimation spectral envelope decomposition speech periodic/aperiodic components. proposed algorithm evaluated clean speech samples cstr arctic databases. objective criteria drugman adopted assess accuracy voicing status estimation. speciﬁcally frame error indicates overall performance estimator breaks gross pitch error voicing decision error deﬁned percentage frames whose estimated deviates reference value among voiced frames correctly estimated voicing status. datasets ground truth. cstr database contains english sentences voiced male female speaker. annotations voicing labels provided database interpolated interval used reference study. arctic database ﬁrst sentences male speakers female speaker selected; reference extracted signals using praat default pitch tracking parameters also interval. methods evaluated test. following voicing estimation algorithms compared nebula yangsaf sacc rapt praat methods speakers search range parameters remain default values. results sacc available interval interpolated match rate reference. table summarizes results evaluation across databases including average worst-case error percentages algorithm. seen nebula clear advantage criteria terms average performance. worst-case scenario rapt outperforms nebula voicing decision margin nebula still holds second place. major source voicing decision errors found underestimated voiced/unvoiced boundaries even applying tricks section also worth noting nebula reduces gross error rate almost negligible level believe signiﬁcant improvement yangsaf attributed choice high-variance priors model training inclusion {snr snr} features under carefully designed statistical framework. breakdown analysis nebula’s performance speaker shown table voicing decision error divided mis-classiﬁcation rates voiced unvoiced frames. first seen algorithm performs better female voices fewer voicing decision errors voiced frames. next largest morise kawahara nishiura rapid estimation high-snr speech based fundamental component extraction trans. ieicej vol. drugman alwan joint robust voicing detection pitch estimation based residual harmonics interspeech florence kawahara agiomyrgiannakis using instantaneous frequency aperiodicity detection estimate highquality speech synthesis isca workshop speech synthesis sunnyvale varga bunke generation synthetic training data hmm-based handwriting recognition system intl. conference document analysis recognition proceedings.", "year": "2017"}