{"title": "Example-based super-resolution for point-cloud video", "tag": "eess", "abstract": " We propose a mixed-resolution point-cloud representation and an example-based super-resolution framework, from which several processing tools can be derived, such as compression, denoising and error concealment. By inferring the high-frequency content of low-resolution frames based on the similarities between adjacent full-resolution frames, the proposed framework achieves an average 1.18 dB gain over low-pass versions of the point-cloud, for a projection-based distortion metric[1-2]. ", "text": "mixed-resolution scenarios naturally emerge representation low-resolution error-protected base layer instance enhanced previously decoded full-resolution frame super-resolution technique already explored processing signals works trying increase data resolution depth maps usually explore geometric properties improve level detail depth map. contribution brought work infer high-frequency content point cloud exploring similarities time-adjacent frames already voxelized point-cloud signals illustrated fig. concise signal model derived section drives example-based super-resolution framework able enhance point-cloud level detail shown section conclusions presented section fig. super-resolution framework outputs superresolved frame ˆct} exploring high-frequency content similarities down-sampled point-cloud time-adjacent frame cr}. traditional super-resolution techniques generate high-resolution images either multiple low-resolution images databases lowhighresolution image pairs proposed method borrows ideas latter order increase propose mixed-resolution point-cloud representation example-based super-resolution framework several processing tools derived compression denoising error concealment. inferring high-frequency content low-resolution frames based similarities adjacent full-resolution frames proposed framework achieves average gain lowpass versions point-cloud projection-based distortion metric recent demand ar/vr applications accelerated interest electronic systems capture process render signals point clouds nonetheless established standards regarding capture representation compression quality assessment point clouds lack standards attracted attention research ﬁeld motivated sequence recent advances processing signals. signals captured using rgbd cameras represented voxelized point cloud. voxelized consists points constrained regular grid point considered address volumetric element voxel said occupied unoccupied occupied position surface color recorded. instead using dense volumetric signal possible samples frame point-cloud represented list occupied voxels color attributes referred point-cloud. efﬁcient geometry representation obtained using octree method space recursively divided ﬁxed-size cubes octants allowing data compression fast searching spatial scalability full resolution equivalent dilating reference point-cloud cube rendering figure illustrates concept scenario translations considered dilation performed square. super-resolution target frame requires df×df voxels estimated voxel order that motion estimation performed voxel basis using n×n×n neighborhood around voxel support. neighborhood deﬁned binary string indicating voxels occupied not. since different resolutions neighborhoods frames obtained skipping positions around voxels acts motion estimation downsampled versions figure illustrates concept scenario neighborhood. motion-estimation process search window around voxel chosen user creating tradeoff speed super-resolution accuracy. cost function i-th voxel j-th voxel fig. downsampling symbol factor considering -pixel translation directions posterior grouping seen dilation original symbol square. circles squares multiplication signs stars illustrate downsampled version position dilated version came from. hamming distance neighborr euclidean distance hoods inverse euclidean distance centers mass small euclidean distance centers mass indicates small motion reference target frames increasing value i.e. favors smaller motion vectors. performance metrics work uses measures evaluate achieved signal enhancements geometric quality metric referred gpsnr distortion metric referred projection peak signal noise ratio gpsnr uses point-toplane distances point-clouds calculate geometric ﬁdelity them. following steps performed evaluate ppsnr target frame expected represented three versions original low-pass {vdl super-resolved ˆct} point-clouds. version project signal faces surrounding cube signals pointcloud version. projection outputs color image. represent scene views orthographic projection cube face. sequence. table shows average ppsnr sequences gpsnr performance gains. method achieves superior performance inferring high-frequency. sequence beneﬁted inferred high-frequency phil achieved modest enhancement. observed trend complex geometry greater potential infer high-frequency. figures present ppsnr frame-byframe basis low-pass point-cloud version version sequences phil respectively. figure shows best high-frequency inference observed test set. relative lack motion sequence ﬁrst frames; side abrupt scene change around frame penalizes quality versions despite challenging scenario fig. framework yields better enhancement low-pass signal average. average gains loot considers ﬁrst frames. frames inserted geometric artifacts orthogonal normals perfectly recovering geometry point-to-plane sense resulted inﬁnite gpsnr. fig. neighborhood around downsampled version symbol factor upsampled version neighborhoods. note every position considered upsampled version indicated thicker lines around considered pixels. average psnrs quality assessments evaluating super-resolved another evaluating low-pass version. then subtracts ﬁrst value second quality enhancement. tests proposed method carried seven point-cloud sequences andrew david loot phil ricardo sarah test made upperbody scenes subjects captured recorded spatial resolution voxels -level resolution. loot full-body scenes recorded -level resolution respectively.the average ppsnr calculated according sec. fig. point-cloud projections sequences frames phil frame image left right columns correspond projections original signal super-resolved signal residue super-resolved signal low-pass signal residue low-pass signal. figure shows best performance test average ppsnr gain low-pass version mainly movement test subject. worst performance seen figs. average ppsnr losses low-pass versions respectively. table performance results. ppsnr-sr ppsnr-lp stand average projected psnr signal low-pass version respectively. values based already efﬁcient point-cloud representation beneﬁted inherent scalability resolution explore similarities point-cloud frames test sequences. experiments carried seven point-cloud sequences show proposed method able successfully infer high-frequency content test sequences yielding average improvement compared low-pass version test sequences. results beneﬁt point-cloud encoding framework efﬁcient hung queiroz brandi oliveira mukherjee video super-resolution using codebooks derived frames ieee trans. circuits systems video technology vol. september mesquita f.m. campos nascimento methodology obtaining super-resolution images depth maps rgb-d data proc. conference graphics patterns images august ganihar joshi setty mudenagudi object super resolution using metric tensor christoffel symbols proc indian conference computer vision graphics image processing december", "year": "2018"}