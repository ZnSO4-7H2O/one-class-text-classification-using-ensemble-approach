{"title": "Convolutional Neural Networks and Language Embeddings for End-to-End  Dialect Recognition", "tag": "eess", "abstract": " Dialect identification (DID) is a special case of general language identification (LID), but a more challenging problem due to the linguistic similarity between dialects. In this paper, we propose an end-to-end DID system and a Siamese neural network to extract language embeddings. We use both acoustic and linguistic features for the DID task on the Arabic dialectal speech dataset: Multi-Genre Broadcast 3 (MGB-3). The end-to-end DID system was trained using three kinds of acoustic features: Mel-Frequency Cepstral Coefficients (MFCCs), log Mel-scale Filter Bank energies (FBANK) and spectrogram energies. We also investigated a dataset augmentation approach to achieve robust performance with limited data resources. Our linguistic feature research focused on learning similarities and dissimilarities between dialects using the Siamese network, so that we can reduce feature dimensionality as well as improve DID performance. The best system using a single feature set achieves 73% accuracy, while a fusion system using multiple features yields 78% on the MGB-3 dialect test set consisting of 5 dialects. The experimental results indicate that FBANK features achieve slightly better results than MFCCs. Dataset augmentation via speed perturbation appears to add significant robustness to the system. Although the Siamese network with language embeddings did not achieve as good a result as the end-to-end DID system, the two approaches had good synergy when combined together in a fused system. ", "text": "belong language family. arabic dialects typically share common phonetic inventory linguistic feature like characters words phonemes utilized automatic speech recognition contrary general lid. natural language processing community tended partition arabic language broad categories egyptian levantine gulf north african msa. multi genre broadcast challenge committee established arabic dialect dataset holds challenge series attracts interest arabic researchers speech communities. mgb- dataset contains dialects hours training data hours test data. benchmark task attained using i-vector framework using bottleneck features using linguistic features words characters results similar performance obtained acoustic features convolutional neural network based backend since linguistic feature space different acoustic feature space fusion results feature representations shown beneﬁcial recent study achieves single system fused system. given dialects accuracies relatively afﬁrming difﬁculty task. recently many deep neural network -based endto-end speaker embedding approaches achieved impressive results text independent speaker recognition research indicates methods perform close slightly better traditional i-vectors though focused improving upon i-vectors room detailed analyses various task conditions. work propose different approaches using acoustic linguistic features. acoustic features explore end-to-end model based global average pooling. examine three representations based mel-frequency cepstral coefﬁcients mel-scale ﬁlter banks energies spectrogram energies. employ data augmentation speech volume perturbation analyze impact dataset size. finally analyze effectiveness training random utterance segmentation strategy cope short input utterances. language embeddings adopt siamese neural network model using cosine similarity metric learn dialect embedding space based text-based linguistic features. network trained learn similarities dialects dissimilarities different dialects. linguistic feature extracted automatic speech recognizer dialect identiﬁcation special case general language identiﬁcation challenging problem linguistic similarity dialects. paper propose end-to-end system siamese neural network extract language embeddings. acoustic linguistic features task arabic dialectal speech dataset multi-genre broadcast endto-end system trained using three kinds acoustic features mel-frequency cepstral coefﬁcients mel-scale filter bank energies spectrogram energies. also investigated dataset augmentation approach achieve robust performance limited data resources. linguistic feature research focused learning similarities dissimilarities dialects using siamese network reduce feature dimensionality well improve performance. best system using single feature achieves accuracy fusion system using multiple features yields mgb- dialect test consisting dialects. experimental results indicate fbank features achieve slightly better results mfccs. dataset augmentation speed perturbation appears signiﬁcant robustness system. although siamese network language embeddings achieve good result endto-end system approaches good synergy combined together fused system. signiﬁcant step forward speaker language identiﬁcation obtained combining i-vectors deep neural networks task dialect identiﬁcation relatively unexplored compared speaker language recognition. main reasons lack common datasets another reason often regarded special case researchers tend concentrate general problems language speaker recognition. however extremely challenging task since similarities among language dialects tends much higher used general task. arabic appropriate language explore uniqueness widespread use. countries arab world modern standard arabic ofﬁcial language citizens local dialect everyday life. arabic dialects historically related share arabic characters however mutually comprehensible. arabic therefore poses different challenges compared language dialects containing comprehensible vernacular. arabic dialects challenging distinguish state-of-the-art system time delayed neural network bidirectional long short-term memory recurrent neural network acoustic model rnn-based language model rescoring. extracted text sequence converted vector space model represents utterance ﬁxed length sequence level high-dimensional sparse vector number times word occurs utterance dictionary size. vector also consist n-gram histogram. figure illustrates linguistic feature extraction concept based acoustic features. mgb- arabic dataset tri-gram word dictionary size high dimensionality kernel trick method used support vector machine’s suitable approach classiﬁcation. another linguistic feature character phoneme feature also extracted system standalone phonetic recognizer. although phonetic recognizers start acoustic input linguistic feature space consists higher level features contain semantic information variable duration speech segments. system acoustic feature-based speaker recognition lid/did system vulnerable domain mismatched conditions affected results higherlevel linguistic spaces different. thus linguistic featurebased approaches could complement acoustic feature-based approaches produce superior fusion result. end-to-end acoustic features recently end-to-end approaches i-vector techniques showed impressive results speaker recognition start waveforms acoustic features ranging mfccs spectrograms. deep learning models consisted cnns rnns fully connected layers. recent studies report combinations global pooling layer obtains best result speaker representation textindependent variable length speech inputs. global pooling layer simple function averaging sequential inputs effectively convert frame level representations utterance level representations advantageous speaker recognition lid. size ﬁnal softmax layer determined task speciﬁc speaker language labels. identiﬁcation tasks softmax output used directly score class. veriﬁcation tasks usually activation last hidden layer extracted speaker language representation vector used calculate distance enrollment test data. end-to-end system based instead time delayed neural network used four -dimensional layers layers connected global average pooling layer averages outputs produce ﬁxed output size global average pooling ﬁxed length output layers softmax layer. structure end-to-end dialect identiﬁcation system represented figure four layers span total frames strides frames input. arabic softmax layer size based words characters phonemes. siamese neural networks usually applied veriﬁcation tasks end-to-end systems however previous study showed approach could also applied identiﬁcation task make original features robust applied approach linguistic features extract language embeddings improve performance reducing enormous feature dimensionality. python tensorﬂow code end-to-end system siamese network language embeddings available allow others reproduce results apply ideas similar speaker veriﬁcation tasks. i-vector regarded state-of-the-art general tasks recent studies show combinations dnn-based approaches produce competitive performance apart basic i-vector approach bottleneck features extracted acoustic model successfully applied although acoustic model usually trained single language performs reasonably well tasks mismatch appear matter speaker recognition tasks however stacked feature extracted second layer input output ﬁrst layer context expansion gaussian mixture model universal background model total variability matrix trained unsupervised manner features large dataset. although main purpose obtain phonetic characteristics languages suppressing individual speaker’s voice characteristics training scheme exactly training gmm-ubm total variability matrix speaker recognition. difference subsequent projection i-vector based measuring distances languages opposed speakers. inherent similarity dialects makes difﬁcult task take advantage linguistic features dialects tend share common phonetic inventory. word character sequences extracted using examined fbank mfcc spectrogram acoustic features. filter size ﬁrst layer changes spectrogram. softmax output used compute similarity scores dialect identiﬁcation. neural network-based deep learning models recent example age-old adage there’s data like data. models able absorb large quantities training data generally better data exposed given ﬁxed training data size researchers found augmenting corpus size artiﬁcial means also effective. paper explored internal dataset augmentation methods. augmentation approach segmentation training dataset small chunks segment dataset advance random segmentations mini-batches. random length selected uniform distribution seconds second intervals including original length. previous studies found random segmentation yields better performance short utterances however investigations show performance applying method difﬁcult judge much gains achieved approach. analyzed performances applying random segmentation various test lengths. technique augmentation perturbation original dataset term speed used asr. idea perturb audio play slightly faster slower. investigated effectiveness speed volume perturbation task using speed factors volume factors previous study explored back-end linguistic feature using cross-entropy objective function softmax output network. identiﬁcation task natural consider cross-entropy objective function class labels output network. however recent study shows using euclidean distance loss function label cosine distance output pair usually adopted binary classiﬁcation task still useful identiﬁcation task learning similarity dissimilarity classes. thus adopted siamese neural network approach extract language embeddings linguistic features. siamese neural network parallel neural networks shares weights biases shown figure network symmetric structure input pair network consists language representative vectors linguistic feature language/dialect index utterance index. language number utterances dialect segment level feature dialect thus pair network inputs combination language representative vectors linguistic features. label pair pair belongs language/dialect different language/dialect. optimize network euclidean distance loss function stochastic gradient descent label cosine similarity pair layers neurons. layers rectiﬁed linear unit activations. network language embeddings extracted language representative vectors linguistic features obtaining activations last hidden layer mgb- dataset partitions shown table partition consists ﬁves arabic dialects msa. detailed corpus statistics found although development relatively small compared training matches test channel conditions thus provides valuable information test domain. i-vector implementation features extracted system trained speech recognition similar conﬁguration extracted features trained hours manually transcribed aljazeera news recordings then gmm-ubm mixtures dimensional i-vector extractor trained based features. detailed conﬁguration described extracting i-vectors whitening transformation length normalization applied. similarity scores calculated cosine similarity gaussian backend linear discriminant analysis applied extracting i-vectors language labels. experiment reduces dimensional i-vector dimensions. phoneme features used four different phoneme recognizers czech hungarian russian using narrow-band models english using broadband model words character features word sequences extracted using arabic system built part mgb- challenge arabic broadcast speech word sequence character sequences also obtained splitting words characters. finally phoneme character word feature represented using sequence. unigrams word features trigrams character phoneme feature. word character feature dimensions respectively. phoneme feature dimensions used measure similarity between test utterance dialects used features mfcc fbank spectrogram. structure shown figure described fully section learning rate decay every mini-batches factor relus used activation nonlinearities. used training development dataset training excluded development dataset dialect validation set. acoustic input window length samples sample equivalent respectively audio. total coefﬁcients extracted mfccs fbanks spectrograms. features normalized zero-mean unit variance. train siamese network made utterance pairs training development sets. since number true pairs naturally lower false pairs adjust training batch ratio true false pairs. since test domain mismatched training development dataset important contains channel information target domain. thus expose development pairs training pairs factor scores normalized z-norm dialect fusion done logistic regression. performance measured accuracy equal error rate minimum decision cost function cavg. accuracy measured taking dialect showing maximum score test utterance dialects. minimum cavg computed hard decision errors ﬁxed costs priors utterance short seconds. seconds original length still shows performance improvement random segmentation provides diversity given limited training dataset. however impact great short utterances. figure table show performance data augmented speed volume perturbation. accuracy ﬂuctuated similarly observed original data figure numbers higher. volume perturbation shows slightly better results using original dataset maximum converged condition. however speed perturbation shows impressive gains performance particularly improvement eer. using volume speed seem advantages network converged need epochs converge larger data size compared volume speed perturbation. table shows performance comparison different features using volume speed data augmentation. performance gains dataset augmentation accuracy mfcc fbank spectrogram respectively. spectrograms still attain worst performance original dataset however somewhat surprising gain increasing dataset size much higher mfccs achieve relatively small increase. table shows performance comparisons i-vectors end-to-end approach. combination i-vectors shows better performance cavg original ivector. however end-to-end system table outperforms i-vector-lda features. table acoustic feature performance measurement arabic dialect mgb- dataset. end-to-end systems trained using random segmentation volume/speed data augmentation. exactly correlated loss three features show better performance network converged. measured performance conditions denoted maximum converged table maximum condition means network achieves best accuracy validation set. converged condition means average loss mini-batches goes under table difference maximum converged scenarios validation essential judge performance network always monitored stop training. mfcc fbank features achieve similar performance spectrogram worse. theoretically spectrograms information mfccs fbanks seems hard optimize network using limited dataset. obtain better performance spectrograms seems require using pre-trained network external large dataset like mentation volume/speed data augmentation training. since internal dataset augmentation approach gives diversity limited datasets end-to-end system could signiﬁcantly improved without additional dataset. interesting reﬁned feature mfcc shows less performance improvement dataset augmentation applied less reﬁned features i.e. fbank spectrogram show comparatively higher improvement finally spectrogram feature performs slightly better mfcc cavg. implies large dataset signals input features. time however difﬁcult determine much training data required training features. tables show performance evaluations language embeddings based phoneme character word features. features also compared baseline system. language embeddings show average improvement metrics. language embeddings based word features achieve best performance among three features. another beneﬁt linguistic feature dimension signiﬁcantly reduced. example dimension character feature reduced original dimensionality though improves table shows performance fusion systems various combinations. hungarian phonemes phoneticbased language embeddings attains best performance among phoneme features. end-to-end system used augmented data shown table result clear fusion acoustic language embeddings shows better efﬁciency fusion end-to-end systems mfcc fbank although performance language embeddings shows comparably lower performance acoustic end-to-end systems. finally scores feature fused fusion system using fbank features achieving better performance mfcc spectrogrambased fusion systems measurements. also spectrogram system performs slightly better mfcc counterpart. pared previous studies. table shows summary performance previous studies mgb- arabic dialect dataset. single fusion system show outstanding performance others. paper describe end-to-end dialect identiﬁcation system using acoustic features language embeddings based text-based linguistic features. investigated several acoustic linguistic features along various dataset augmentation techniques using limited dataset resource. veriﬁed end-to-end system based acoustic feature outperforms i-vectors also language embeddings derived siamese neural network boost performance learning similarities utterances dialect dissimilarities different dialects. experiments mgb- dialectical arabic corpus show best single system achieves accuracy best fusion system shows accuracy. experiments spectrograms could utilized acoustic feature training dataset large enough. also observe end-to-end dialect identiﬁcation system signiﬁcantly improved using random segmentation volume/speed perturbation increase diversity amount training data. end-to-end dialect identiﬁcation system simpliﬁed topology training methodology compared bottleneck feature based i-vector extraction scheme. finally using siamese network learn language embeddings reduces linguistic-feature dimensionality signiﬁcantly provide synergistic fusion acoustic features. najim dehak pedro torres-carrasquillo douglas reynolds reda dehak language recognition ivectors dimensionality reduction interspeech number august ahmed najim dehak patrick cardinal sameer khurana sree harsha yella james glass peter bell steve renals automatic dialect detection arabic broadcast speech interspeech vol. --sept maryam najaﬁan sameer khurana suwon shon ahmed james glass exploiting convolutional neural networks phonotactic based dialect identiﬁcation icassp maryam najaﬁan saeid safavi phil weber martin russell identiﬁcation british english regional accents using fusion i-vector multi-accent phonotactic systems proceedings odyssey speaker language recognition workshop suwon shon ahmed james glass mit-qcri arabic dialect identiﬁcation system multigenre broadcast challenge ieee workshop automatic speech recognition understanding ahmet bulut qian zhang chunlei zhang fahimeh bahmaninezhad john hansen utd-crss submission mgb- arabic dialect identiﬁcation front-end back-end advancements broadcast speech ieee workshop automatic speech recognition understanding trung trong ville hautamaki kong deep language comprehensive deep learning approach end-to-end language recognition proceedings odyssey speaker language recognition workshop david snyder pegah ghahremani daniel povey daniel garcia-romero yishay carmiel deep neural network embeddings text-independent speaker veriﬁcation interspeech jane bromley james bentz l´eon bottou isabelle guyon yann lecun cliff moore eduard s¨ackinger roopak shah signature veriﬁcation using siamese time delay neural network international journal pattern recognition artiﬁcial intelligence vol. vijayaditya peddinti daniel povey sanjeev khudanpur time delay neural network architecture efﬁcient modeling long temporal contexts interspeech daniel garcia-romero xiaohui zhang alan mccree daniel povey improving speaker recognition performance domain adaptation challenge using deep neural networks ieee spoken language technology workshop stephen shum douglas reynolds daniel garciaromero alan mccree unsupervised clustering approaches domain adaptation speaker recognition systems proceedings odyssey speaker language recognition workshop suwon shon seongkyu wooil hanseok autoencoder based domain adaptation speaker recognition insufﬁcient channel information interspeech sameer khurana ahmed qcri advanced transcription system arabic multi-dialect broadcast media recognition mgb- challenge ieee workshop spoken language technology ahmed yifan zhang patrick cardinal najim dahak stephan vogel james glass complete kaldi recipe building arabic speech recognition systems ieee spoken language technology workshop ieee. ahmed peter bell james glass yacine messaoui hamdy mubarak steve renals yifan zhang mgb- challenge arabic multi-dialect broadcast media recognition ieee spoken language technology workshop ieee.", "year": "2018"}