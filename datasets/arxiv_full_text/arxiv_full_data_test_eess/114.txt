{"title": "Reducing Model Complexity for DNN Based Large-Scale Audio Classification", "tag": "eess", "abstract": " Audio classification is the task of identifying the sound categories that are associated with a given audio signal. This paper presents an investigation on large-scale audio classification based on the recently released AudioSet database. AudioSet comprises 2 millions of audio samples from YouTube, which are human-annotated with 527 sound category labels. Audio classification experiments with the balanced training set and the evaluation set of AudioSet are carried out by applying different types of neural network models. The classification performance and the model complexity of these models are compared and analyzed. While the CNN models show better performance than MLP and RNN, its model complexity is relatively high and undesirable for practical use. We propose two different strategies that aim at constructing low-dimensional embedding feature extractors and hence reducing the number of model parameters. It is shown that the simplified CNN model has only 1/22 model parameters of the original model, with only a slight degradation of performance. ", "text": "ieee copyright notice ieee. personal material permitted. permission ieee must obtained uses current future media including reprinting/republishing material advertising promotional purposes creating collective works resale redistribution servers lists reuse copyrighted component work works. full citation reducing model complexity based large-scale audio classiﬁcation ieee international conference acoustics speech signal processing calgary audio classiﬁcation task identifying sound categories associated given audio signal. paper presents investigation large-scale audio classiﬁcation based recently released audioset database. audioset comprises millions audio samples youtube human-annotated sound category labels. audio classiﬁcation experiments balanced training evaluation audioset carried applying different types neural network models. classiﬁcation performance model complexity models compared analyzed. models show better performance model complexity relatively high undesirable practical use. propose different strategies constructing low-dimensional embedding feature extractors hence reducing number model parameters. shown simpliﬁed model model parameters original model slight degradation performance. rapid development technology made production rendering sharing transmission multimedia data easy low-cost hence become part daily life. growth online available audio visual data irreversible trend. effective efﬁcient tools classifying indexing managing multimedia data convenience enjoyment individuals also critical social economic development data era. audio inarguably important types multimedia resources reckoned. audio classiﬁcation generally deﬁned task identifying given audio signal predeﬁned categories sounds. depending applications sound categories could broad e.g. music voice noise highly speciﬁed e.g. children speech. existence diverse task deﬁnitions made difﬁcult compare methods results different research groups therefore hindered constructive exchange ideas. recent years organised efforts setting open evaluation competitions large-scale audio classiﬁcation. example ieee aasp challenge dcase includes acoustic scene classiﬁcation important part. task classify -second audio sample pre-deﬁned acoustic scenes. among participating teams dcase eghbal-zadeh proposed hybrid model using binaural i-vectors demonstrated best performance. shown log-mel ﬁlterbank features perform better mfcc models applied dcase popular among top- models. addressed problem data insufﬁciency proposed apply gan-based data augmentation method signiﬁcantly improve classiﬁcation accuracy. also trend using binaural audio features rather monaural features. dcase task provides annotated database contains hours audio recordings training. amount considered inadequate exploit full capability latest deep learning techniques. icassp sound video understanding team google research announced release audioset comprises large amount audio samples youtube. total duration data current release audioset exceeds hours. unlike dcase database audio samples audioset labeled large number sound categories organised loose hierarchy. availability audioset caught great attention research community published studies report referable classiﬁcation performance database. related database named youtube-m used investigate large-scale audio classiﬁcation problem. youtube-m dataset contains million youtube videos. experimental results show massive amount training data residual network layers produces best performance comparison alexnet inception network paper presents recent attempt large-scale audio classiﬁcation newly released audioset. knowledge except preliminary evaluation brieﬂy mentioned ofﬁcial published result complete audioset classiﬁcation task. apply variety commonly used models audioset task based models generally achieve better performance rnn. propose exploit low-dimension feature representation audio segments achieve signiﬁcant reduction model complexity. shown number model parameters could reduced times maintaining comparable performance classiﬁcation. addition effectiveness proposed methods validated dcase database. section audioset acoustic scenes database described. general framework classiﬁcation system proposed strategy model complexity reduction explained section experimental results different types neural network models given section video start time time audio clip sound category labels. audio clip second long. sound labels obtained human-annotation process human raters asked conﬁrm presence hypothesized sound categories. audio video components presented raters. hypothesized sound categories generated multiple sources including video-labeling system various meta-data information. multiple sound categories co-existing audio clip. totally sound categories used audioset. categories arranged following loose hierarchy. example speech male speech treated categories different hierarchical levels. however kind hierarchy taken account audio classiﬁcation experiments. entire audioset contains million audio samples correspond hours data. audio samples divided balanced training unbalanced training evaluation set. study balanced training evaluation used. number audio samples excluded various reasons e.g. deleted youtube links duration shorter seconds. result number audio samples used training evaluation respectively. validation created randomly selecting training data. acoustic scenes database used dcase challenge. deﬁned acoustic scenes covering various indoor outdoor environments. development dataset contains audio samples evaluation dataset contains samples. number samples representing different scene classes same. audio sample second long said scenes. total duration recordings hours. figure shows general framework segment-based audio classiﬁcation system. typical length segment second. segment divided short-time frames used spectral analysis. segment-based system make better temporal information audio signals frame-based system figure input audio signal divided non-overlapping segments. sound category labels segment inherited input audio signal. segment time-frequency representation derived classiﬁcation purpose. time-frequency features segment classiﬁer obtain classiﬁcation scores. sample-level classiﬁcation score calculated averaging segment-level scores. commonly used time-frequency representations audio classiﬁcations derived short-time fourier transforms. examples include log-mel ﬁlterbank features constant-q transform mfcc. based preliminary experiments dnn-based systems log-mel features give best performance among feature types thus used experiments. embedding features well-trained classiﬁer audio classiﬁcation area. example rakib uses trained model extract embedding feature plda improve classiﬁcation performance. embedding features trained classiﬁer also serve critical component proposed method. paper several ways obtain low-dimensional embedding feature studied section bottleneck layer applied speech recognition area extract embedding features. extracted feature called bottleneck feature generally better hand-crafted feature recently bottleneck layers investigated large-scale audio classiﬁcation shawn hershey introduction bottleneck layer leads faster training maintaining comparable classiﬁcation performance. bottleneck layer typically lies layers fully-connected neural network. middle layer designed relatively small number neurons compared hidden layers therefore called bottleneck. constructing bottleneck layer low-dimensional feature representation input data generated. figure shows example bottleneck layer. study make bottleneck layers achieve reduction model complexity low-dimensional embedding feature extractor constructed. different sizes bottleneck layer experimented reveal trade-off model cnn-based classiﬁcation model typically composed convolution layer fully connected layer. common making connection convolution layer layer ﬂattening feature maps convolutional layer using ﬂattened features input layer. since ﬂattened features large dimension number required model parameters would excessive. moreover increase chance over-ﬁtting layers. global average pooling strategy proposed solve problem over-ﬁtting layers effectiveness regularizer veriﬁed. average pooling operation applied feature obtained last convolutional layer size pooling window equal size feature map. pooling result used input layer classiﬁcation. figure illustrates conventional global average pooling transform feature maps feature vector. together form time-frequency matrix representation segment. dimension-wise normalization log-mel features performed using means variances calculated audio samples training set. area receiver operating characteristic curve abbreviated used performance metric experiments audioset. context binary classiﬁcation viewed probability classiﬁer ranks randomly chosen positive sample higher negative classiﬁcation model makes random guesses value perfect classiﬁcation model gives value found insensitive distribution positive negative samples compared evaluation metrics like precision accuracy score map. multi-class problem overall measure obtained weighted average values individual classes. weight speciﬁc class proportional prevalence dataset. experimented models study implemented using deep learning toolbox pytorch parameters used training empirically determined. initial learning rate mini-batch size model training done minimizing cross-entropy loss adam optimizer learning rate decay strategy. models dropout weight decay applied regularization purpose. sigmoid function used output layer models considering audio sample multiple sound labels. audio sample dataset divided non-overlapping -second segments. sound category labels assigned segment exactly source audio sample. short-time fourier transform applied audio segments window length length length subsequently -dimensional log-mel ﬁlterbank features derived short-time frame frame-level features table shows experimental results different models model hidden layers neurons layer. batch normalization relu activation function applied. lstm model contains lstm layers units. refers gated recurrent unit b-gru-att refers bi-directional output weighted attention network whose context vector size layers units. knowledge performance recurrent models reported audioset yet. models investigated large-scale audio classiﬁcation youtube-m database study models experimented alexnet residual network layers alexnet used experiments similar alexnet described designed image classiﬁcation input. make change ﬁrst convolutional layer kernel size stride obtain similar size feature ﬁrst convolutional layer. layers size alexnet mean batch normalization layer added layer overall calculated audio classes seen alexnet batch normalization performs best among tested models. even outperforms -layer deep residual network reported highest performance among models large-scale audio classiﬁcation alexnet model shown best performance among different models model complexity relatively large thus undesirable practical use. described section using bottleneck layer performing global average pooling effective techniques reducing number model parameters. experiment different arrangements layers bottleneck layer alexnet model. results compared table bneck-final- refers -dimension bottleneck layer inserted output layer last layer bneck-mid- means dimension bottleneck layer inserted layers. conﬁguration size layers reduced three different sizes embedding features tested lastly global-avg-pool means global average pooling layer used replace layers. resulting feature dimension pooling equal number feature maps last convolution layer. generally larger size bottleneck layer layers lead better classiﬁcation performance. reducing size existing layers without additional bottleneck layer would cause noticeable degradation performance despite signiﬁcantly reduced model complexity. size bottleneck layer beneﬁcial bottleneck inserted layers bneck-mid- could attain original alexnet less model parameters. applying global average pooling strategy model complexity reduced original alexnet resnet- model model. performance comparable resnet- model slightly worse alexnet. proposed models also evaluated acoustic scenes database. different nature scene classiﬁcation task softmax function used output layers neural networks. settings training stated section among audio samples training samples randomly selected validation data. alexnet model attains classiﬁcation accuracy evaluation -layer neurons layer accuracy well-tuned lstm model accuracy applying strategy global average pooling size-reduced alexnet accuracy conﬁrms effectiveness global average pooling strategy though viewed large-scale task compared audioset. audioset database provides useful resources enable advance research large-scale audio classiﬁcation. paper presents earliest batches experimental results database using latest neural network models. shown models effective rnn. model complexity best-performing signiﬁcantly reduced introducing bottleneck layer fully-connected layers applying global average pooling. must noted small portion audioset used present study though small portion already contains times audio samples existing dcase database. eghbal-zadeh lehner dorfer widmer cpjku submissions dcase- hybrid approach using binaural i-vectors deep convolutional neural networks tech. rep. dcase challenge september valenti diment parascandolo squartini virtanen dcase acoustic scene classiﬁcation using convolutional neural networks tech. rep. dcase challenge september park generative adversarial network based acoustic scene training augmentation selection using hyper-plane tech. rep. dcase challenge september hershey chaudhuri ellis gemmeke jansen moore plakal platt saurous seybold slaney weiss wilson architectures large-scale audio classiﬁcation proc. ieee icassp orleans hyder ghaffarzadegan feng hansen hasan acoustic scene classiﬁcation using cnnsupervector system trained auditory spectrogram image features proc. interspeech stockholm sweden gehring miao metze waibel extracting deep bottleneck features using stacked auto-encoders ieee international conference acoustics speech signal processing", "year": "2017"}