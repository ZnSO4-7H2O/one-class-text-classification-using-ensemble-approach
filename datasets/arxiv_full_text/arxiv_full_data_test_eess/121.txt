{"title": "Audio Set classification with attention model: A probabilistic  perspective", "tag": "eess", "abstract": " This paper investigates the classification of the Audio Set dataset. Audio Set is a large scale weakly labelled dataset of sound clips. Previous work used multiple instance learning (MIL) to classify weakly labelled data. In MIL, a bag consists of several instances, and a bag is labelled positive if at least one instances in the audio clip is positive. A bag is labelled negative if all the instances in the bag are negative. We propose an attention model to tackle the MIL problem and explain this attention model from a novel probabilistic perspective. We define a probability space on each bag, where each instance in the bag has a trainable probability measure for each class. Then the classification of a bag is the expectation of the classification output of the instances in the bag with respect to the learned probability measure. Experimental results show that our proposed attention model modeled by fully connected deep neural network obtains mAP of 0.327 on Audio Set dataset, outperforming the Google's baseline of 0.314 and recurrent neural network of 0.325. ", "text": "paper investigates classiﬁcation audio dataset. audio large scale weakly labelled dataset sound clips. previous work used multiple instance learning classify weakly labelled data. consists several instances labelled positive least instances audio clip positive. labelled negative instances negative. propose attention model tackle problem explain attention model novel probabilistic perspective. deﬁne probability space instance trainable probability measure class. classiﬁcation expectation classiﬁcation output instances respect learned probability measure. experimental results show proposed attention model modeled fully connected deep neural network obtains audio dataset outperforming google’s baseline recurrent neural network analysis environmental sounds popular topic potential used many applications public security surveillance smart homes smart cars health care monitoring. audio classiﬁcation also attracted signiﬁcant research effort detection classiﬁcation acoustic scenes events challenge several tasks deﬁned audio classiﬁcation including acoustic scene classiﬁcation sound event detection audio tagging however data sets used challenges relatively small. recently google released ontology human-labeled large scale data audio events namely audio audio consists expanding ontology sound event classes collection million human-labeled -second sound clips drawn youtube videos. audio deﬁned tasks audio tagging. objective audio tagging perform multi-label classiﬁcation ﬁxed-length audio chunks without predicting precise boundaries acoustic events. task ﬁrst proposed dcase challenge. deep neural networks convolutional recurrent neural networks used predicting occurring audio tags. neural networks attention scheme ﬁrstly proposed previous work audio tagging task provides ability localize related audio events. gated convolutional neural networks also applied large-scale weakly supervised sound event detection smart cars task dcase challenge system achieved place audio tagging sub-task. however audio tagging data used dcase challenge small sub-set google audio number audio event classes compared classes google audio set. paper propose attention model audio tagging google audio shows better performance google’s baseline. work main contributions conduct explore large-scale audio tagging google audio secondly explain attention model probability perspective. attention scheme also similar feature selection process ﬁgure related features suppressing unrelated background noise. achieved weighted frames attention values automatically learned neural network model. remainder paper related works presented section proposed attention method explanation probability perspective shown section section presents experimental setup results. conclusions drawn section weighted collective assumption asserts instance contributes independently necessarily equally label tag. achieved incorporating weight function collective assumption. equation form joint detection-classiﬁcation model attention model proposed audio tagging sound event detection. difference work model using neural network. although equation used many previous works explanation equation clearly presented. paper explain attention model equation probabilistic perspective helpful guide selection equation instances contribute differently classiﬁcation bag. labelled positive least instance positive. solve problem positive instances attended negative instances ignored. ﬁrst assign measure laid example euclidean space. assign measure instance introduce measure space probability theory. deﬁnition borel ﬁeld subsets measure numerically valued function domain satisfying following axioms instances. positive contains least positive instance. hand negative contains positive instances. audio clip audio contains several feature vectors. audio clip labelled positive class least feature vector belongs corresponding class. number training pairs. consists several instances xnl} instance number instances bag. denote label n-th bag. audio classiﬁcation collection features audio clip. instance feature dimension feature. label number audio classes represent negative positive label respectively. speciﬁc class label n-th ∃xnl positive. otherwise ∀xnl negative. assume classiﬁer instance want obtain classiﬁer bag. several ways obtain level classiﬁer instance level classiﬁer described follows. collective assumption states instances contribute equally independently bag’s label. assumption level classiﬁer obtained using aggregation rule collective assumption simple assumes instances contribute equally independently bag-level class labels. however collective assumption assumes instances inherit label corresponding assumption. maximum selection used audio tagging using convolutional neural networks audio event detection using weakly labelled data maximum selection corresponds global pooling layer convolutional neural network. maximum selection performs well audio tagging sometimes inefﬁcient training instance maximum value used training gradient computed instance highest classiﬁcation value. measure respectively. deﬁnition axiom calµk. constraint equation satisﬁed. modeling prediction k-th class obtained using equation framework attention model shown fig. audio dataset highly unbalanced. classes tens thousands samples classes contain hundreds samples. therefore propose mini batch balancing strategy occurrence frequency training samples different classes mini-batch kept same. experiment audio dataset audio contains million seconds audio clips extracted youtube videos. audio consists classes audio hierarchy structure. original waveform million audio clips published. instead published bottleneck feature vectors extracted embedding layer representation deep trained youtube-m dataset bottleneck feature vectors extracted feature second features seconds audio clip. bottleneck feature vectors post-processed principle component analysis remove correlations ﬁrst coefﬁcients kept. source code system available here. apply simple fully connected deep neural network verify effectiveness proposed attention model. ﬁrst apply fully connected layers input feature vectors extract high level representation. call mapping embedded mapping denote call embedded instance. embedded mapping modeled three fully connected layers hidden units layer followed relu non-linearity dropout rate fig. attention model probabilistic perspective classiﬁcation result instance probability measure instance given bag. prediction expectation respect probability measure pnk. assume k-th class classiﬁcation prediction probability measure instance respectively. obtain classiﬁcation result apply expectation classiﬁcation result respect probability measure random variable. equation represents instances contributes differently classiﬁcation probability measure controls much instance attended. large small represents instance attended ignored respectively. modeling attention dataset mapping used model presence probability k-th class instance hand modeling probability measure difﬁcult constraint probability instances equal table shows comparison different pooling strategies. average pooling pooling along time axis described equation respectively. google baseline uses simple fully connected table shows global average pooling performs better google baseline. using attention achieves better performance google baseline rnn. paper attention model audio classiﬁcation explained probability perspective. classiﬁer probability measure instance modeled neural network. apply fully connected neural network attention model audio achieves outperforming google baseline recurrent neural network. future explore modeling probability measure using different nonnegative functions. fig. model audio classiﬁcation. input space mapped embedded space followed classiﬁcation attention branch. final prediction expectation classiﬁcation output respect learned probability measure. sigmoid non-linearity sigmoid non-linearity ensures probability between non-linearity non-negative function investigate relu sigmoid softmax functions experiment. evaluate using mean average precision area curve d-prime used values computed classes averaged across classes obtain ﬁnal d-prime. higher d-prime lead better performance. table shows results without data balancing strategy using collective assumption equation data balancing strategy described section table shows using balancing strategy performs better without data balancing strategy d-prime. table shows results modeling measure function using different non-negative functions including relu sigmoid softmax functions. softmax non-negative srivastava hinton krizhevsky sutskever salakhutdinov dropout simple prevent neural networks overﬁtting journal machine learning research. ieee huang wang foster sigtia jackson plumbley unsupervised feature learning based deep models environmental audio tagging ieee/acm trans. audio speech language processing vol. kong huang wang mark plumbley attention localization based deep convolutional recurrent model weakly supervised audio tagging interspeech. ieee", "year": "2017"}