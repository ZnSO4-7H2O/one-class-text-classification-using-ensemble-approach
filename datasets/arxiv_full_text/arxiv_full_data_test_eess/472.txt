{"title": "Robust Target Localization Based on Squared Range Iterative Reweighted  Least Squares", "tag": "eess", "abstract": " In this paper, the problem of target localization in the presence of outlying sensors is tackled. This problem is important in practice because in many real-world applications the sensors might report irrelevant data unintentionally or maliciously. The problem is formulated by applying robust statistics techniques on squared range measurements and two different approaches to solve the problem are proposed. The first approach is computationally efficient; however, only the objective convergence is guaranteed theoretically. On the other hand, the whole-sequence convergence of the second approach is established. To enjoy the benefit of both approaches, they are integrated to develop a hybrid algorithm that offers computational efficiency and theoretical guarantees. The algorithms are evaluated for different simulated and real-world scenarios. The numerical results show that the proposed methods meet the Cr'amer-Rao lower bound (CRLB) for a sufficiently large number of measurements. When the number of the measurements is small, the proposed position estimator does not achieve CRLB though it still outperforms several existing localization methods. ", "text": "abstract—in paper problem target localization presence outlying sensors tackled. problem important practice many real-world applications sensors might report irrelevant data unintentionally maliciously. problem formulated applying robust statistics techniques squared range measurements different approaches solve problem proposed. ﬁrst approach computationally efﬁcient; however objective convergence guaranteed theoretically. hand whole-sequence convergence second approach established. enjoy beneﬁt approaches integrated develop hybrid algorithm offers computational efﬁciency theoretical guarantees. algorithms evaluated different simulated real-world scenarios. numerical results show proposed methods meet cr`amer-rao lower bound sufﬁciently large number measurements. number measurements small proposed position estimator achieve crlb though still outperforms several existing localization methods. index terms—target localization robust localization robust statistics iterative reweighted least squares generalized trust region subproblems problem localization arises different ﬁelds study wireless networks navigation surveillance acoustics many different approaches localization based various types measurements range squared-range time-of-arrival time-difference-of-arrival two-way time-of-ﬂight direction-of-arrival received-signalstrength localization range measurements rangedifference measurements considered least-squares estimators exploited. authors established methods exact approximate solution maximum likelihood framework. usually paper problem robust target localization considered. sensor networks nodes report faulty data processing node unintentionally maliciously. occur network failures battery physical obstruction scene attackers. thus processing node simply aggregate measurements sensors. efﬁcient disregard outlier measurements localize target based reliable measurements. different approaches toward robust localization. method obtained modeling estimation error cauchy-lorentz distribution. robust statistics speciﬁcally huber norm exploited localize sensors network distributed manner using location subset nodes. authors minimize worst-case likelihood function employ semideﬁnite relaxation attain estimate using tw-tof measurements. authors developed robust geolocation method estimating probability density function measurement error summation gaussian kernels. method works best measurement error drawn gaussian mixture pdf. paper goal localize single target presence outlier range measurements centralized manner. achieve outlier distributional robustness means estimator performs well different outlier probability distributions. least squares methodology applied squared range measurements. although formulation optimal sense provides opportunity estimate efﬁciently. contributions work summarized follows. first robust optimization problem formulated disregards unreliable measurements using squaredrange formulation. next different algorithms proposed solution optimization problem. ﬁrst algorithm based iteratively reweighted least squares proposed optimization problem transformed special class optimization problems namely generalized trust region subproblems numerical simulations show algorithm fast objective convergence. however whole-sequence convergence established theoretically. second algorithm based gradient descent. algorithm globally convergent needs iterations converge. using algorithms proposed hybrid method desirable theoretical practical features fast whole-sequence convergence. rest paper organized following order. section system model introduced. section describes robust localization problem methods tackle problem presented. section presents simulation results ﬁnally section draws conclusions. section localization method developed applying robust statistics squared range measurements. although formulation optimal sense unlike methods based range measurements solution attained easily. since problem source localization arises different ﬁelds wireless networks surveillance navigation acoustics general system model exploited. generalized model system comprised sensors known locations location target estimated using range measurements reported sensors. central processing node collects measurements computes location target. measurement errors assumed independent identically distributed random variables. model outlier measurements two-mode mixture assigned measurement errors written uniform distribution shifted gaussian distribution rayleigh distribution exponential distribution however worthwhile mention proposed method rely distribution here goal estimate using measurements disregarding measurements outlier sensors. processing node information number outlier sensors distribution outlier measurements. moreover assumed reported measurements including noisy irrelevant measurements positive. that exploit robust statistics propose methods obtain solution. worthwhile mention also outcome optimization procedure parameter set. formulation unreliable measurements outlier sensors affect accuracy localization signiﬁcantly. plan robust statistics decrease sensitivity estimator common assumptions. here robustness signiﬁes insensitivity small deviation common assumption gaussian distribution noise. parameter represents deviation assumption. goal deal unknown distribution described proposed statistical procedure following features. must efﬁcient sense must optimal near optimal performance assumed model i.e. gaussian distribution noise. must stable i.e. robust small deviations assumed model. also case breakdown large deviation model catastrophe occur. numerical experiments look features proposed methods. general recipe robustize statistical procedure decompose observations ﬁtted values residuals proposed methods residuals re-ﬁt iteratively convergence obtained. term summation corresponds residual single sensor. residuals exploited re-ﬁt observations iteratively. speciﬁcally residuals assign weights observation. observation ﬁtted model larger weight procedure decision making. inspired deﬁne objective function ﬁrst summation objective function weighted version objective terms added result commonly used class m-estimators known geman-mcclure function function reduce effect large errors interpolating norm minimizations m-estimatiors similar behavior geman-mcclure tukey welsch cauchy estimators. types m-estimators known robust large errors huber m-estimator desirable feature huber function convexity unlike mentioned estimators. however numerical results show proposed algorithms perform well different scenarios different values contamination ratio. different approaches solution introduced. ﬁrst approach show mapped special class optimization problems known generalized trust region subproblems iteration exact solution derived employing gtrs formulations. second approach method based gradient descent introduced solve problem. method computationally efﬁcient ﬁrst approach offers array desirable theoretical features. note quadratic objective function minimized subject quadratic equality constraint. special class optimization problems called generalized trust region subproblem equality constraint makes optimization problem non-convex. however shown global solution gtrs problems obtained efﬁciently speciﬁcally using theorem deﬁnitions easily verify holds proposed optimization problem thus optimization problem global minimizer iterations. also using theorem optimal solution exists that λd)y last expression means positive semideﬁnite. ﬁrst equalities exploited obtain solution i.e. ensure positive semideﬁnite easy show need seek interval largest generalized eigenvalue matrix pair shown holds moreover resulting characteristic function needed solved strictly decreasing interval thus iteration obtained using bisection algorithm. interval starting point bisection algorithm speciﬁed max{−a)ii then updated using estimated algorithm illustrates procedure calculate estimate using equations convergence algorithm analyzed theorem sr-irls method needs iterations solve problem. convergence objective also proven appendix however lack convexity standard convergence analysis tools cannot used show convergence whole-sequence iterates. problem becomes difﬁcult objective function linear quadratic function previous iterates. thus appendix convergence subsequence iterates critical point proved although wholesequence convergence almost always observed. motivates propose globally convergent algorithm. section algorithm referred sr-gd introduced solution based gradient descent. then integrate sr-irls sr-gd derive computationally efﬁcient globally convergent algorithm. section algorithm solving optimization problem proposed based gradient descent convergence whole-sequence iterates proven theoretically that lipschitz continuity gradient objective function well special form objective constraint employed. numerical experiments show algorithm needs iterations converge sr-irls. goal employ sr-gd srirls propose hybrid fast converging algorithm. intuitively ﬁrst term objective ﬁnds steepest descent second term prevents large changes magnitude gradient. lipschitz constant gradient function limits step size algorithm estimate enforced around prediction prediction constructed using previous iterates extrapolation factor update rule easy notice minimization problem stated gtrs problem. quadratic objective minimized subject quadratic equality constraint. exploiting deﬁnition show holds. thus optimization problem global minimizer iterations. also theorem states optimal solution exists that iteration ﬁnding predicted value iterate equality expressions used update values look solution interval satisﬁes positive semideﬁniteness constraint. since holds interval exists characteristic function strictly decreasing interval algorithm shows steps solution localization problem using sr-gd method. take advantage fast convergence srirls whole sequence convergence sr-gd propose hybrid method. speciﬁcally start sr-irls method update iterates steps stated algorithm convergence objective function proven appendix update rules algorithm employed ﬁnal solution. performance convergence rate computational cost hybrid method evaluated compared methods section simulation results evaluate performance proposed methods. seek main features robust estimator discussed section examine performance algorithms assumed model small deviations model large deviations model moreover check distributional robustness proposed algorithms means performance methods evaluated different different simulation scenarios investigated. scenario general system model considered outlier measurements obey uniform distribution models harsh environment. scenario localization target cellular radio network investigated. geometry sensors taken operating network measurement errors drawn gaussian mixture distribution model non-line-of-sight measurements. sensors trying localize target. sensors target distributed uniformly random range measurements corrupted additive white gaussian noise standard deviation moreover among sensors exist outlier sensors. noise outlier sensors uniformly distributed range best different values contamination ratio. ﬁgure shows proposed methods efﬁcient assumed method stable small deviations. also large deviations catastrophe occurred. estimate target location method approximates measurement error summation gaussian kernels. that needs considerable number measurements. hence unlike proposed methods cannot produce proper results measurements. further since method employs gaussian kernels works accurately measurement errors drawn gaussian mixture distribution using gaussian kernels decreases distributional robustness method signiﬁcantly. elaborate point figure illustrates impact number sensors performance different methods. experiment sensors reporting unreliable data processing node i.e. ﬁgure exhibits accuracy localization methods improves number sensors increases. expected rmse estimates produced method decreases signiﬁcantly number sensors increases. moreover clear proposed methods meet cr`amer-rao lower bound large number measurements. figure figure infer proposed methods efﬁcient simulation parameters meet crlb unbiased. crlb approximated using monte carlo integration techniques explained figure shows running times different number sensors. clearly iterative methods requires computation time least square method. also expected noticed figure running time hybrid method less sr-gd sr-irls. running time reﬂects time required execute steps algorithms including initialization preprocessing convergence postprocessing. simulations performed matlab environment equipped intel xeon processor ram. performances proposed methods sr-irls sr-gd hybrid version compared performance sr-ls least-square-based method well robust method namely robust iterative nonparametric performances compared according root mean square error ﬁrst numerical experiment convergence sr-irls sr-gd compared. figure depicts ky−yk different iterations. moreover labels show elapsed time iterations. although convergence sr-gd method theoretically provable figure shows needs iterations time converge. hybrid version algorithm uses update rules sr-irls convergence objective function employs update rules sr-gd. result needs less iterations srgd convergence still theoretically provable. study inﬂuence number outlier sensors figure exhibits rmse estimate different number outlier sensors equivalently different values study results based monte carlo trials. clear number outliers increases performance sr-ls method deteriorates signiﬁcantly. sr-irls sr-gd perform closely small values difference becomes noticeable increases. expected since sr-gd likely result local optimum solutions caused outliers smooth convergence iterates. however hybrid version uses small step size sufﬁciently close limit point performs outlier-free measurements result line-of-sight sensings. hand nlos sensings produce unreliable measurements. field trials indicated measurement errors harsh los/nlos environments modeled gaussian mixture distribution corrupted additive gaussian noise i.e. seen figure method outperform robust methods. expected since methods particularly tailored deal gaussian noise robust methods customized handle unreliable measurements. sacriﬁcing efﬁciency achieve stability deviation model. however easy notice rmse proposed robust methods close rmse sr-ls method implies near optimal performance gaussian noise. indicates measurement outlier residual greater threshold threshold function robustness noise improved increasing value expense losing robustness outlier measurements. hence variance noise increases assign larger value link proposed problem huber norm established. assuming additive measurement noise gaussian estimator would asymptotically efﬁcient meets cr`amer-rao bound setting parameter variance noise huber norm convex function. results robust statistics proposed problem convex version cost function employed. function surrogated closest convex approximation figure illustrates similarity huber norm convex approximation i.e. cost functions resemble least square estimator errors less cut-off parameter optimal cost function gaussian noise. hand large values error cost functions resemble norms known promote sparsity. ﬁgure shows sr-gd outperforms competitors. moreover hybrid version sr-irls perform conﬁguration able handle nlos measurements certain amount meet crlb certain large values sr-irls method breaks down still works better least square method. however scenario sr-gd able localize target even large contamination ratios. surement error mixture gaussian distribution. result method produce better estimate target location. measurements able approximate measurement error distribution. thus rmse change considerably different values fact vividly clear extreme case. method able approximate measurement error. result method outperforms competitors special case paper considered problem localizing single target presence unreliable measurements unknown probability distribution. that squared-range formulation exploited. disregard outlier measurements estimate using reliable measurements used robust statistics. problem converted known class optimization problems namely gtrs using concepts robust statistics. algorithms hybrid method proposed solve problem. convergence algorithms analyzed theoretically.", "year": "2018"}