{"title": "On Psychoacoustically Weighted Cost Functions Towards Resource-Efficient  Deep Neural Networks for Speech Denoising", "tag": "eess", "abstract": " We present a psychoacoustically enhanced cost function to balance network complexity and perceptual performance of deep neural networks for speech denoising. While training the network, we utilize perceptual weights added to the ordinary mean-squared error to emphasize contribution from frequency bins which are most audible while ignoring error from inaudible bins. To generate the weights, we employ psychoacoustic models to compute the global masking threshold from the clean speech spectra. We then evaluate the speech denoising performance of our perceptually guided neural network by using both objective and perceptual sound quality metrics, testing on various network structures ranging from shallow and narrow ones to deep and wide ones. The experimental results showcase our method as a valid approach for infusing perceptual significance to deep neural network operations. In particular, the more perceptually sensible enhancement in performance seen by simple neural network topologies proves that the proposed method can lead to resource-efficient speech denoising implementations in small devices without degrading the perceived signal fidelity. ", "text": "present psychoacoustically enhanced cost function balance network complexity perceptual performance deep neural networks speech denoising. training network utilize perceptual weights added ordinary mean-squared error emphasize contribution frequency bins audible ignoring error inaudible bins. generate weights employ psychoacoustic models compute global masking threshold clean speech spectra. evaluate speech denoising performance perceptually guided neural network using objective perceptual sound quality metrics testing various network structures ranging shallow narrow ones deep wide ones. experimental results showcase method valid approach infusing perceptual signiﬁcance deep neural network operations. particular perceptually sensible enhancement performance seen simple neural network topologies proves proposed method lead resource-efﬁcient speech denoising implementations small devices without degrading perceived signal ﬁdelity. deep neural networks seen exponentially greater usage regards audio signal processing improving state-ofthe-art source separation noise reduction speech enhancement. many studies improved performance terms quality recovery sources relies greatly enlarged model complexity. example network structure showed speech separation performance better traditional dictionary-based separation model advance) terms signal-to-distortion ratio another recent example would structure phase magnitudes source effectively predicted network represented weight matrix linear transformation required number ﬂoating-point operations would easily million. also shown standard feed-forward networks larger network structure outperforms smaller network expected network complexity predominantly increased favor improved performance. however enlarged structure become bottleneck comes implementing small device limited resources especially stringent requirement real-time speech enhancement. dnns increase size resource usage neural network compression grown lively research area. carefully pruning units reduce size network shown lowering quantization level network parameters reducing number bits represent parameter another compress network. example recent studies report binary ternary quantization schemes signiﬁcantly reduce accuracy famous benchmark classiﬁcation tasks however general-purpose compression techniques utilize audio-speciﬁc characteristics problem. example proposed perceptual evaluation methods audio source separation toolkit standard energybased objective metrics signal-to-noise ratio variants best judge perceptual quality audio signals paper claim neural network audio enhancement optimized exploits human perception. example legacy digital audio coding schemes leverage principles sound perception reduce coded signal’s data rate; refer perceptual coding schemes psychoacoustic models discarding inaudible tones allowing quantization noise least audible portions audio spectrum reduces rate minimizing degradation overall signal ﬁdelity psychoacoustic concepts relevant design perceptual audio coder phenomena hearing thresholds auditory masking. concepts empirically modeled used conjunction time-frequency analysis identify perceptually signiﬁcant components signal. identiﬁed auditory irrelevancies either masked unheard removed. psychoacoustics literature diverse ﬁndings different modern perceptual audio codecs adopted pam. incorporate pam- popularized iso/iec mpeg- standard without loss generality. although commonly used traditional audio coding used respect neural network compression. recent work proposed regarding perceptually weighted speech enhancement shows promising amount improvement signal quality intelligibility however network uses perceptual weight model based fig. plot pyschoacoustic model components. pam- identiﬁes tonal estimates global masking threshold absolute treshold hearing components determined using input signal’s power spectral density shaded area curve global masking threshold represents audible spectral energy. simpliﬁed version pam- considering tonal signal components ignoring non-tonal signal components. pam- computes global masking threshold frames input spectrogram. threshold computed ﬁrst performing sound pressure level normalization training spectrogram determine signal’s power spectral density log|s|. note ﬁxed then model identiﬁes tonal maskers ignoring fall absolute threshold hearing spreading function used generate masking curves tone. combination individual masking curves plus yields global masking threshold implementation pam- detailed fig. showcases various components pam- model example frame training data set. proposed method reformulate given ordinary cost function using perceptual weights derived masking curves computed pam-. using training clean speech signal’s power spectral density corresponding global masking threshold deﬁne perceptual weight matrix applied network cost function therefore ratio signal power masked threshold rescaled db-spl. division carried element-wise fashion. intuition behind weight matrix deﬁnition understood observing fig. signal energy frequency t-th time frame signal’s power greater masking threshold i.e. tone must audible. fig. audible regions blue line higher green dotted line. hand power source spectrum lower threshold region masked inaudible. understanding deﬁne weights bounded whose smaller extreme says masking threshold large sound reconstruction error time-frequency audible. conversely sigmoid function applied signal prioritizes highenergy components target speech’s spectral power. although assumption valid case speech unlike hold across types audio. regard work generalizes greatly expands upon ﬁndings found paper present perceptually weighted cost function train structurally simpler conducts perceptually comparable speech denoising. this generate meaningful weights based global masking threshold training data prescribed pam- harmonize weights mean-squared error. evaluate denoising results various network architectures show proposed method leads condensed network topology without losing perceptual quality recovered speech. input mask learning model magnitude spectra noisy utterances approximates mixture speech noise complex domain rectiﬁed linear units common activation function avoid gradient vanishing problem. hidden layer feed-forward process deﬁned follow indicates layers special case input layer stands input) weights bias respectively. denotes hadamard product. practice useful conduct smooth weight clipping applying hyperbolic tangent function weight bias bounded within range dropout applied output layer next layer; dropout masking matrix i-th layer whose elements binary values drawn bernoulli distribution parameter speech denoising networks trained predict ideal ratio mask mask input recover speech spectrogram hence employ logistic function ﬁnal layer activation modifying follows incorporation psychoacoustic model essential constructing weight matrix inﬂuences cost function focus signal components greatest perceptual signiﬁcance. utilize practice provide contextual information fully connected neural networks. smaller networks individual frames input. mini-batch size throughout training procedure. energy-based ideal ratio mask gives nonnegative real-valued masking matrix |s|+|n| source spectrogram recovered multiplying mask mixture spectrogram i.e. chose target signal proposed perceptual weighting used targets source magnitude spectra without loss generality. parameter settings seek condensed network structure limit maximum number hidden layers units totalling different network topologies assessed experiment. weights layer initialized truncated normal distribution divided square root size layer standard deviation cost function. learning rates given different model topologies. dropout rate input layer choose keep units active models concatenated input layer dropout rate wider hidden layers layers units units. limited space paper shows results best-ﬁt parameter conﬁguration found validation. choice model structure trained different error functions without perceptual weights. model training model trained tensorflow using adam optimizer number epochs training time varies range hours given different network structures parameter settings proposed perceptual weighting notably reduce training time. present eval toolbox evaluate objective sound quality well stoi peass toolkperceptual evaluation separation metrics used compare denoised speech results obtained proposed neural network using either conventional cost function perceptually weighted cost function eval toolbox objectively compare denoising quality groups models. particularly consider three measures ratio source remaining interference measure amount artifacts introduced separation process reﬂect overall source separation performance. measures calculated reconstructed utterance presented fig. weighted averages speech signals based lengths signals. weighted models overlook noise global masking threshold focusing instead audible noise affecting human speech perception. this model objectively denoise utterance resulting slightly lower unweighted model. however perceptual models barely artifacts comparison unweighted models similarly output networks utilizing weights still comparable conventional denoising networks irrespective cost function weighted unweighted large weight value means source spectral component large audible even considering masking threshold. therefore system create much error. weight matrix encodes perceptual importance time-frequency bins combine original function figure shows training signal’s power spectral density compared perceptual weight matrix short speech signal. note roughly follows spectral density suppressing weaker areas near-zero weights. expected beneﬁt using weighting scheme neural network prediction enjoy relaxed version error function underweights less audible output dimensions. result network focus narrower output dimensions–an easier optimization task smaller compressed network also solve similar perceptual quality. data preparation noisy dataset constructed mixing utterances timit corpus non-stationary noise types used this speakers randomly selected training equal gender probability. utterance mixed different noise types. thus noisy utterances used training. procedure used generate noisy utterances validation well another utterances create test set. noise signals used training overlap test mixtures. sources normalized mixture shorttime fourier transform used -point hann window %-overlap spectrogram computation. complex spectrogram clean signal background noise mixed create matrices dimensions training validation set. input mixture denoised acquired adding larger networks three consecutive spectra concatenated vectorized form input vector vectorizing consecutive input common yields higher highly contingent network complexity well-maintained even shallow networks. discussed section pam-weighted networks equally consider frequency bins. therefore reasonably lower non-pam models however artifacts introduced perceptual weighting also dampened leads higher overall conclude peass evaluation metrics says proposed perceptual weighting leads compressed network structures suffer much perceptual performance drop ones minimize unweighted cost function. additionally verify effect proposed weighted cost function short time objective intelligibility scores fig. average stoi score weighted models marginally higher reassures stability perceptual weighting scheme. however stay conservative asserting proposed method improves speech intelligibility claim researched performing subjective evaluation audio quality frameworks mushra trend–wider deeper neural networks guarantee better objective separation quality. trend justiﬁes popularity deep learning speech denoising tasks. however argue variation perceptual quality respect model complexity different pattern. peass measures perceptual quality denoised speech signals. case single-channel source separation three metrics overall interference-related artifact-related perceptual scores perceptual scores complement objective measures respectively. network topologies considered proposed perceptual weightpaper proposed psychoacoustically weighted cost function leads efﬁcient network structure speech denoising tasks. efﬁcient networks less number parameters implementations hardware-friendly especially resource-constrained environments maintain comparable perceptual quality. future plan investigate effect proposed perceptual weighting scheme qingju wenwu wang philip jackson tang perceptually-weighted deep neural network monaural speech enhancement various background noise conditions proceedings european signal processing conference narayanan wang ideal ratio mask estimation using deep neural networks robust speech recognition proceedings ieee international conference acoustics speech signal processing mart´ın abadi paul barham jianmin chen zhifeng chen andy davis jeffrey dean matthieu devin sanjay ghemawat geoffrey irving michael isard tensorﬂow system large-scale machine learning. osdi vol. cees taal richard hendriks richard heusdens jesper jensen short-time objective intelligibility measure time-frequency weighted noisy speech acoustics speech signal processing ieee international conference ieee huang hasegawa-johnson smaragdis joint optimization masks deep recurrent neural networks monaural source separation ieee/acm transactions audio speech language processing vol. florian mayer donald williamson pejman mowlaee deliang wang impact phase estimation single-channel speech separation based time-frequency masking journal acoustical society america vol. jonathan roux john hershey felix weninger proceedings deep speech separation ieee international conference acoustics speech signal processing apr. dally deep compression compressing deep neural networks pruning trained quantization huffman coding proceedings international conference learning representations valentin emiya emmanuel vincent niklas harlander volker hohmann subjective objective quality assessment audio source separation ieee transactions audio speech language processing vol.", "year": "2018"}