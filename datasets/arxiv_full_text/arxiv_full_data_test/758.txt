{"title": "TopP-S: Persistent homology based multi-task deep neural networks for  simultaneous predictions of partition coefficient and aqueous solubility", "tag": "q-bio", "abstract": " Aqueous solubility and partition coefficient are important physical properties of small molecules. Accurate theoretical prediction of aqueous solubility and partition coefficient plays an important role in drug design and discovery. The prediction accuracy depends crucially on molecular descriptors which are typically derived from theoretical understanding of the chemistry and physics of small molecules. The present work introduces an algebraic topology based method, called element specific persistent homology (ESPH), as a new representation of small molecules that is entirely different from conventional chemical and/or physical representations. ESPH describes molecular properties in terms of multiscale and multicomponent topological invariants. Such topological representation is systematical, comprehensive, and scalable with respect to molecular size and composition variations. However, it cannot be literally translated into a physical interpretation. Fortunately, it is readily suitable for machine learning methods, rendering topological learning algorithms. Due to the inherent correlation between solubility and partition coefficient, a uniform ESPH representation is developed for both properties, which facilitates multi-task deep neural networks for their simultaneous predictions. This strategy leads to more accurate prediction of relatively small data sets. A total of six data sets is considered in the present work to validate the proposed topological and multi-task deep learning approaches. It is demonstrate that the proposed approaches achieve some of the most accurate predictions of aqueous solubility and partition coefficient. Our software is available online at {\\url{http://weilab.math.msu.edu/TopP-S/}} ", "text": "aqueous solubility partition coefﬁcient important physical properties small molecules. accurate theoretical prediction aqueous solubility partition coefﬁcient plays important role drug design discovery. prediction accuracy depends crucially molecular descriptors typically derived theoretical understanding chemistry physics small molecules. present work introduces algebraic topology based method called element speciﬁc persistent homology representation small molecules entirely different conventional chemical and/or physical representations. esph describes molecular properties terms multiscale multicomponent topological invariants. topological representation systematical comprehensive scalable respect molecular size composition variations. however cannot literally translated physical interpretation. fortunately readily suitable machine learning methods rendering topological learning algorithms. inherent correlation solubility partition coefﬁcient uniform esph representation developed properties facilitates multi-task deep neural networks simultaneous predictions. strategy leads accurate prediction relatively small data sets. total data sets considered present work validate proposed topological multi-task deep learning approaches. demonstrate proposed approaches achieve accurate predictions aqueous solubility partition coefﬁcient. software available online http//weilab.math.msu.edu/topp-s/. ii.a overview data sets partition coefﬁcient data sets aqueous solubility data sets statistics datasets ii.b. persistent homology necessity esph example challenge primitive persistent homology ii.b. estd construction ii.c additional molecular descriptors ii.d topological learning algorithms ii.d. ensemble methods ii.d. multi-task learning deep neural networks multi-task learning multi-task deep neural network remark ii.e evaluation metrics iii.a partition coefﬁcient prediction training cross-validation star non-star iii.b aqueous solubility prediction iii.b. ref. leave-one-out -fold cross-validation partition coefﬁcient denoted deﬁned ratio concentrations solute mixture immiscible solvents equilibrium great importance pharmacology. measures drug-likeness compound well hydrophobic effect human body. logarithm coefﬁcient i.e. proved parameters drug design discovery. optimal along molecular weight polar surface area plays important role governing kinetic dynamic aspects drug action. particular hansch gave detailed description lipophilicity impacted pharmacodynamics. said surveys show approximately half drug candidates fail reach market unsatisfactory pharmacokinetic properties toxicity indeed makes predictions even important. extent existing reliable experimental data negligible compared tremendous compounds whose data practically needed. therefore computational prediction partition coefﬁcient indispensable approach modern drug design discovery. since pioneering work hansch al.– large variety octanol-water partition coefﬁcient predictors developed past decades. many methods generally called quantitative structure-activity relationship models. general models categorized atom-based additive methods fragment/compound-based methods property based methods. atom-based additive methods ﬁrst proposed crippen coworkers essentially purely additive effectively table look-up atom. later xlogp reﬁned version atom-based additive methods developed. approach considers various atom types contributions neighbors well correction factors help overcome known difﬁculties purely atomistic additive methods. however additivity fail cases unexpected contributions occur especially complicated structures. fragment/compound based predictors instead employing information single atom built compounds fragments level. compounds fragments added correction factors. popular fragment methods include kowwin clogp acd/logp klogp. major challenge fragment/compound based methods optimal classiﬁcation building blocks\". number fragments corrections involved current methods range hundreds thousands could even larger remote atoms also taken account. fact lead technical problems practice also cause overﬁtting modeling. third category property-based. basically property-based methods determine partition coefﬁcient using properties empirical approaches three dimensional structures methods) topological electrostatic indices. methods modeled using statistical tools associative neural network worthy mention property-based methods relatively computationally expensive depend largely choice descriptors accuracy computations. extent results preference methods ﬁrst categories third. another closely related chemical property aqueous solubility denoted logarithm value drug discovery related pharmaceutical ﬁelds great signiﬁcance identify molecules undesirable water solubility early stages solubility affects absorption distribution metabolism elimination processes qspr models along atom/group additive models developed predict solubility. example qspr models assume aqueous solubility correlates experimental properties aforementioned partition coefﬁcient melting point molecular descriptors solvent accessible area. however difﬁculty experimentally measuring solubility certain compounds experimental data contain errors units less units. high variability brings challenge solubility prediction. partition coefﬁcient aqueous solubility reveal solute dissolves solvent. therefore reasonable assume exists shared feature representation across related tasks. machine learning theory multitask learning designed take advantage shared feature representations correlated properties. learns so-called inductive bias related tasks improve accuracy using representation. words learning aims learning shared generalized feature representation multiple tasks brought insights study bioinformatics. successful applications include splice-site mhc-i binding prediction sequence biology gene expression analysis system biology. learning becomes efﬁcient incorporated deep learning strategies. successfully achieved state-of-the-art results signal information processing ﬁelds speech recognition natural language processing well toxicity prediction– aqueous solubility prediction. representation molecules particularly macromolecules often involves much structural detail thus become intractable large complex biomolecular data sets. contrast topology offers highest level abstraction truly metric free representations molecules. however traditional topology incurs much geometric reduction practically useful molecules. persistent homology bridges classical geometry topology offering multiscale representation molecular systems. creates family topologies ﬁltration parameter leads one-dimensional topological invariants i.e. barcodes betti numbers. physical interpretations betti- betti- betti- barcodes isolated components circles cavities respectively. persistent homology applied modeling prediction nano particles proteins biomolecules.– nonetheless found primitive persistent homology limited predictive power machine learning based classiﬁcation biomolecules motivate introduce element speciﬁc persistent homology retain crucial biological information topological simpliﬁcation geometric complexity.– esph found success predictions protein-ligand binding afﬁnities mutation induced protein stability changes. unfortunately representational predictive power persistent homology esph small molecules essentially unknown. unlike proteins small molecules involve wide range chemical elements properties sensitive chemical constitutions symmetry stereochemistry. therefore clear whether persistent homology esph suitable descriptors small molecules. objective work explore representationability predictive power esph small molecules. focus analysis prediction small molecular solubility partition coefﬁcient. relevance drug design discovery relatively large data sets collected literature problems give rise good data sets validation topological descriptors. overcome difﬁculty small available data sets certain problems construct topological learning integrating esph multitask deep learning partition coefﬁcient aqueous solubility predictions. show esph provides competitive description relatively small drug-like molecules. additionally inherent correlation partition coefﬁcient aqueous solubility makes multi-task strategy viable approach joint predictions. rest paper structured follow. section give introduction element speciﬁc persistent homology construction element speciﬁc topological descriptor deep neural network mt-dnn architecture carefully formulated illustrated section ii.d.. section ﬁrst give overview data sets. predictions mt-dnn models well methods partition coefﬁcients aqueous solubility presented. finally wrap paper discussions section datasets methods section devoted datasets topological methods machine learning algorithms evaluation metrics. ii.a overview data sets primary work paper explore proposed topology based multi-task methods learning partition coefﬁcient aqueous solubility simultaneously. data sets naturally divided parts partition coefﬁcient prediction aqueous solubility prediction. note partition coefﬁcient prediction multiple test sets training remains same. partition coefﬁcient data sets training used partition coefﬁcient prediction originally compiled cheng consists compounds based hansch al.’s compilation. compounds considered reliable experimental values hansch addition three sets chosen test sets. ﬁrst test completely independent training contains small-molecule organic drugs approved food drug administration united states represents variety organic compounds pharmaceutical interests. also compiled cheng remaining test sets star non-star publicly available originated monograph avdeef. star comprises compounds part biobyte star widely used develop prediction method. non-star contains compounds represent relatively chemical structures properties. compound list corresponding partition coefﬁcient available download http//ochem.eu/article/. also made attempt expand training searching database software packages large number molecules supervised learning. additional molecules added training set. aqueous solubility data sets order develop validate prediction models aqueous solubility several well-deﬁned aqueous solubility datasets used. firstly diverse data molecules proposed wang used verify predictive power descriptors. leave-one-out -fold crossvalidation carried set. furthermore also tested models relatively small independent test sets. suggested also removed molecules training ensure training test overlapping molecules. statistics datasets summary data sets used proposed models given table ii.b element speciﬁc topological descriptors brief introduction given persistent homology element speciﬁc persistent homology followed detailed example illustrate persistent homology characterization small molecules. reﬁned version esph corresponding estd construction also discussed. ii.b. persistent homology persistent homology branch algebraic topology deﬁnes topological spaces terms algebraic structures. main workhorse topological data analysis offers topological simpliﬁcation data complexity. unlike conventional physical chemical approaches persistent homology captures underlying topological connectivity small molecules directly atomic coordinates i.e. point cloud data mathematically isolated atoms molecule -simplices. connectivity among atoms deﬁnes high dimensional simplexes. example linked atoms gives rise -simplex mutually linked atoms triangular shape called -simplex. mutually linked four-atom tetrahedron -simplex forth. appropriate collection simplices forms simplicial complex topological space consisting vertices edges triangles high dimensional counterparts. simplicial homology deﬁned basis simplicial complex used analyze topological invariants i.e. betti numbers. physically betti- betti- betti- describe numbers independent components rings cavities respectively. however important note topological connectivity among atoms molecule follow physical relations i.e. covalent bonds hydrogen bonds waals bonds. instead deﬁned ﬁltration parameter artiﬁcial ball radius atom. therefore given ﬁltration radius obtains simplices thus betti numbers molecule. persistent homology ﬁltration radius varies continuously zero large number meaningful topological structure created further. therefore persistent homology computes topological invariants given molecule different spatial scales correspond different geometric shapes thus different topological connectivities. persistence topological invariants ﬁltration given molecule recorded barcodes persistent diagrams. barcode representation persistent homology utilized present work construct estds. readers referred ref. detailed still simple introduction persistent homology. necessity esph example primitive persistent homology treats atoms equal footing neglects chemical physical properties molecules. obtain accurate representation given molecule necessary least distinguish different element types construct element speciﬁc topological descriptors figure detailed example estds calculated reveal structure information cyclohexane. all-element representation cyclohexan given carbon atoms green hydrogen atoms white. barcode plot fig. betti- bars correspond atoms beginning disappear ﬁltration value gets indicates carbon atom merged closest hydrogen atoms ﬁltration value becomes larger length bond three atoms regarded single connected component. ﬁltration value increases betti- emerges means hexagonal carbon ring captured connected component left. ﬁltration value eventually exceeds radius hexagon ring structure disappears betti- bar. longest betti- corresponds existence connected component. carbon atoms selected relatively straightforward interpret barcode plot. cutoff betti- bars disappear corresponds bond length betti- represents existence hexagonal carbon ring. figure cyclohexane persistent homology barcode plots. carbon element selected respectively. subﬁgure bottom results betti- betti- respectively challenge primitive persistent homology aforementioned persistent homology although able capture information covalent bonds different atom types easily shown fig. necessarily reﬂect intramolecular interactions hydrogen bonds waals interaction ideal purpose small molecule modeling. words betti- atoms certain hydrogen bonding waals cannot captured since already exist shorter betti- bars thus important redeﬁne distance atom atom following atomic radius atoms respectively bond length deviation data set. large number greater maximal ﬁltration value euclidean distance atom atom equivalently setting distance close atoms sufﬁciently large number able capture intramolecular interactions since connection longer ﬁltration value automatically neglected persistent homology computation. ii.b. estd construction inspired classic atom-additive models partition coefﬁcient prediction utilize total basic element types calculated antechamber using general amber force ﬁeld atoms given atom type appropriate combinations selected construct vietoris-rips complex estds subsequently calculated. also important construct estds small size. example shows barcodes different cutoffs give rise variety information covalent non-covalent bonds. speciﬁcally divide barcodes several small bins extract features bin. complete list estds used study shown ref. group estds focuses different atom types group capture occurrences non-covalent bonding group mainly highlights strength non-covalent bonding waals interactions. note statistics birth death values group refer maximum minimum mean summation. essence estds offer insight small molecule modeling topological modeling topological learning. constructing topological feature vector i-th molecule task readily combine topological learning advanced machine learning algorithms details discussed section ii.d. ii.c additional molecular descriptors addition estds introduced previous subsection generate molecule descriptors cheompy molecule. feature pool contains feature groups e-state descriptors. total categories molecule descriptors molecular constitutional descriptors topological descriptors molecular connectivity indices kappa shape descriptors burden descriptors e-state indices basak information indices autocorrelation descriptors molecular property descriptors charge descriptors moe-type descriptors. detailed description features cheompy software available line https//code.google.com/archive/p/pychem/downloads. order improve overall performance also combine features estds create estd+. consistency reasons molecules whose features calculated estd software chemopy software used training purpose. worth mention estd approaches applicable molecules whereas chemopy difﬁculty dealing molecules. separate results discussions different sets descriptors also conducted later sections. ii.d topological learning algorithms section present methods algorithms topology based multi-task learning simultaneous predictions partition coefﬁcient aqueous solubility. ensemble methods including random forest gradient boosting decision tree neural network architectures discussed. detailed description multi-task neural network also provided. ii.d. ensemble methods ensemble methods widely used solve qsar problems achieved state-of-the-art results. naturally handle correlations descriptors generally insensitive parametrization feature selection bagging operations. work choose gradient boosting tree baseline method implement using scikit-learn package number estimators random forest increase number essentially improve accuracy. runs done average predictions taken ﬁnal prediction. ii.d. multi-task learning deep neural networks multi-task learning idea multi-task learning learn ‘inductive bias’ related tasks imwords aims learning shared generalized prove accuracy using representation. feature representation multiple tasks potentially gives better predictions. work assume underlying molecular mechanism partition coefﬁcient aqueous solubility shares commonalities differences learned jointly. multi-task deep neural network deep neural network wider deeper architecture compared traditional artiﬁcial neural network consists layers neurons layer reveals facets input features different levels. multitask framework different tasks share ﬁrst dense layers individual predictor attached speciﬁc task illustration multitask deep neural network shown fig. study total tasks logp prediction logs prediction. suppose molecules t-th task i-th molecule t-th task represented topological feature vector experimental value i-th molecule task objective topological learning minimize function different tasks functional topological feature vectors learned parametrized weight matrix bias term cross entropy loss classiﬁcation mean squared error regression. since logp logs measured quantitatively loss function minimized deﬁned training data normalized zero-mean unit variance. remark although units tasks different still train mt-dnn model simultaneously shared layers learn inherent commonalities individual layers deal differences. ii.e evaluation metrics several different evaluation metrics including root mean squared error pearson correlation coefﬁcient mean unsigned error used evaluate performances different models. methlog represents total number molecules test expl pred stand experimental predicted value molecule respectively pred expl average predicted experimental value entire test respectively. result metric along evaluate model performances star non-star described below. results section present results proposed esph methods conjugation random forest multi-task deep neural networks variety data sets including partition coefﬁcient solubility test sets. otherwise stated different tasks trained together network. besides would like introduce notations easier reference. estd- contains betti- bar-based estds estd- contains estds listed table iii.a partition coefﬁcient prediction training cross-validation order idea topological representation would work partition coefﬁcient -fold cross-validation performed using baseline method gbdt. note runs done achieve ﬁnal results randomness involved results summarized table seen descriptors better xlogp software given training data thus demonstrates great predictive power. compared xlogp gbdt. ﬁrst test would like apply model test set. molecule contains dropped difﬁculty computation. major challenge structures complex training partition coefﬁcient range spans nearly units. series prediction methods including multi-task neural networks applied results summarized table comparison ours. table multi-task model gives best prediction terms rmse mue. speciﬁcally small model indicates predictions less biased methods tested except outliers. also note training completely independent test shows applicability multi-task architecture. also build models architecture additional molecules gathered nih-database included guarantee alogps completely independent testset. turns accuracy greatly improved. table results different logp prediction methods fda-approved drugs ranked molecules dropped model evaluation feature generation failure chemopy star non-star star non-star proposed tetko benchmark sets evaluating partition coefﬁcient models. different models tested sets. emphasized sets different models trained different training sets overlap test sets unknown. thus makes sense merge training additional molecules database additional training data beneﬁt overall performances. results different models sets found table notice models trained additional data labeled superscript star achieve rmse units popular commercial software packages acd/logp clogp addition high acceptable prediction percentage well unacceptable rate non-star methods give accurate predictions structures relatively complex. acceptable rate ranks number among predictors though rmse relatively high large outliers results satisfactory commercial software packages generally much larger training ours. general exist overlapped molecules training test results signiﬁcantly improved. table indicates mt-dnn-estd+ models achieve substantial improvement xlop star maintaining level accuracy non-star set. performances mt-dnn-estd+ models suggest models able predict accurately. fact predictive power potentially improved molecules incorporated training set. thus also extend original training adding molecules star non-star set. extended training much higher accuracy achieved listed table observe mt-dnn outperforms features. iii.b aqueous solubility prediction evaluate performances solubility models several datasets used derived wang leave-one-out validation baseline method used. -fold cross-validation remaining folds trained together partition coefﬁcient training evaluating remaining fold mt-dnn architecture. iii.b. ref. dataset leave-one -fold cross validations carried order evaluate performance models. leave-one-out mt-dnn requires computational resources baseline method gbdt used leave-one-out prediction. trees learning rate training parameters develop models following results table achieved. -fold cross-validation mt-dnn baseline method gbdt involves randomness mt-dnn gbdt times report mean performances metrics. results summarized table observed models yield accurate robust predictions asms asms-logp models improving additionally also notice generally exists improvement mt-estd models gbdt models though signiﬁcant previous partition coefﬁcient prediction. table benchmark test results different logp prediction methods star molecules non-star molecules. superscript means star molecules non-star molecules included training. iii.b. data ref. test models data proposed training test sets predeﬁned cover variety molecules. test contains commonly used compounds pharmaceutical environmental interest trained original molecules. test contains molecules used develop klopman zhu’s group contribution model. suggested remove molecules overlap test training make prediction independent unbiased. reduces size training test test table shows performances different models test mt-estd models perform similarly drug-logs method achieving improvement klopman zhu’s method estds. test results test summarized table dataset mt-estd models gives satisfactory results high pearson correlation across estd combinations. results indicate methods applicable wide variety molecules. discussion section discuss outcome trained models several aspects. emphasis predictive power estds terms mt-dnn topology based multitask learning improve partition coefﬁcient aqueous solubility predictions. iv.a estds small molecules previous results indicated exists common feature representation partition coefﬁcient solubility prediction. features come different categories computed solely esph widely used development qsar models. although number estds small turns topological feature representation molecules strong predictive power compared baseline method. estds highlight atom type information keep track formation chemical bond well ring structures given molecule. indeed constructing topological space molecule estds able extract useful features esph computation. fact detailed topological representations precisely reﬂect covalent bond length hydrogen bond strength waals interaction constructed small size. iv.b multitask learning goal multitask learning learn commonalities different tasks simultaneously improve model performances. study partition coefﬁcient aqueous solubility trained jointly substantial improvements singletask models observed. results suggests exists shared information across tasks beneﬁt prediction accuracy. indeed original motivation predicting logp logs coefﬁcients closely relate extent compound dissolves solvent. comparing mt-dnn gradient boosting tree beneﬁcial learn partition coefﬁcient aqueous solubility models together. mt-estd models achieve satisfactory results various partition coefﬁcient aqueous solubility data sets state-of-the-art knowledge. estds alone give accurate predictions bringing insights element speciﬁc persistent homology computations. addition estds commonly-used descriptors also help improve overall accuracy. attempt learn related measurements together gives boost learning separately improvement validated data sets. conclusion partition coefﬁcient aqueous solubility among important physical properties small molecules signiﬁcant applications drug design discovery terms lipophilic efﬁciency. based chemical physical models wide variety computational methods developed literature theoretical predictions partition coefﬁcient aqueous solubility. present work introduces algebraic topology based method element speciﬁc persistent homology simultaneous partition coefﬁcient aqueous solubility predictions. esph offers unconventional representation small molecules terms multiscale multicomponent topological invariants. multiscale representation inherited persistent homology multicomponent formulation developed retain essential chemical information topological simpliﬁcation molecular geometric complexity. therefore present esph gives unique representation small molecules cannot obtained method. although esph representation molecules cannot literally translated physical interpretation systematically comprehensively encipher chemical physical information molecules scalable topological invariants thus ideally suited machine learning/deep learning algorithms decipher information. predict partition coefﬁcient aqueous solubility integrate esph advanced machine learning methods including gradient boosting tree random forest deep neural networks construct topological learning strategies. since partition coefﬁcient aqueous solubility highly correlated other develop common esph descriptors called element speciﬁc topological descriptors represent properties. approach enables perform simultaneous predictions partition coefﬁcient aqueous solubility using topology based multi-task deep learning strategy. test representational esph predictive power proposed topological multi-task deep learning strategy consider commonly used data sets including benchmark test sets partition coefﬁcient well additional solubility data sets. extensive cross validations benchmark tests indicate proposed topological multi-task strategy offers accurate predictions partition coefﬁcient aqueous solubility.", "year": "2017"}