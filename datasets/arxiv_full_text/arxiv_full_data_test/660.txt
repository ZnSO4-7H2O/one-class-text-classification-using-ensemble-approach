{"title": "Bayesian Best-Arm Identification for Selecting Influenza Mitigation  Strategies", "tag": "q-bio", "abstract": " Pandemic influenza has the epidemic potential to kill millions of people. While various preventive measures exist (i.a., vaccination and school closures), deciding on strategies that lead to their most effective and efficient use remains challenging. To this end, individual-based epidemiological models are essential to assist decision makers in determining the best strategy to curb epidemic spread. However, individual-based models are computationally intensive and it is therefore pivotal to identify the optimal strategy using a minimal amount of model evaluations. Additionally, as epidemiological modeling experiments need to be planned, a computational budget needs to be specified a priori. Consequently, we present a new sampling technique to optimize the evaluation of preventive strategies using fixed budget best-arm identification algorithms. We use epidemiological modeling theory to derive knowledge about the reward distribution which we exploit using Bayesian best-arm identification algorithms (i.e., Top-two Thompson sampling and BayesGap). We evaluate these algorithms in a realistic experimental setting and demonstrate that it is possible to identify the optimal strategy using only a limited number of model evaluations, i.e., 2-to-3 times faster compared to the uniform sampling method, the predominant technique used for epidemiological decision making in the literature. Finally, we contribute and evaluate a statistic for Top-two Thompson sampling to inform the decision makers about the confidence of an arm recommendation. ", "text": "pandemic inﬂuenza epidemic potential kill millions people. various preventive measures exist deciding strategies lead eﬀective efﬁcient remains challenging. individual-based epidemiological models essential assist decision makers determining best strategy curb epidemic spread. however individual-based models computationally intensive therefore pivotal identify optimal strategy using minimal amount model evaluations. additionally epidemiological modeling experiments need planned computational budget needs speciﬁed priori. consequently present sampling technique optimize evaluation preventive strategies using ﬁxed budget best-arm identiﬁcation algorithms. epidemiological modeling theory derive knowledge reward distribution exploit using bayesian best-arm identiﬁcation algorithms evaluate algorithms realistic experimental setting demonstrate possible identify optimal strategy using limited number model evaluations i.e. -to- times faster compared uniform sampling method predominant technique used epidemiological decision making literature. finally contribute evaluate statistic top-two thompson sampling inform decision makers conﬁdence recommendation. inﬂuenza virus responsible deaths half million people year. addition seasonal inﬂuenza epidemics cause signiﬁcant economic burden. transmission primarily local newly emerging variant spread pandemic proportions fully susceptible host population pandemic inﬂuenza occurs less frequently seasonal inﬂuenza outcome respect morbidity mortality much severe potentially killing millions people worldwide therefore essential study mitigation strategies control inﬂuenza pandemics. i.a. vaccination social measures antiviral drugs. however eﬃciency strategies greatly depends availability preventive compounds well characteristics targeted epidemic. furthermore governments typically limited resources implement measures. therefore remains challenging formulate public health strategies make eﬀective eﬃcient preventive measures within existing resource constraints. epidemiological models essential study eﬀects preventive measures silico individual-based models usually associated greater model complexity computational cost compartment models allow accurate evaluation preventive strategies capitalize advantages make feasible employ individual-based models essential available computational resources eﬃciently possible. literature possible preventive strategies typically evaluated simulating strategies equal number times however approach ineﬃcient identify optimal preventive strategy large proportion computational resources used explore suboptimal strategies. furthermore consensus required number model evaluations strategy currently lacking show number depends hardness evaluation problem. additionally recognize epidemiological modeling experiments need planned computational budget needs speciﬁed priori. therefore present novel approach formulate evaluation preventive strategies best-arm identiﬁcation problem using ﬁxed budget model evaluations. running individual-based model computationally intensive minimizing number required model evaluations reduces total time required evaluate given preventive strategies. renders individual-based models attainable studies would otherwise computationally feasible. additionally reducing number model evaluations free computational resources studies already individual-based models capacitating researchers explore larget model scenarios. important considering wider range scenarios increases conﬁdence overall utility preventive strategies paper contribute novel technique evaluate preventive strategies ﬁxed budget best-arm identiﬁcation problem. employ epidemiological modeling theory derive assumptions reward distribution exploit knowledge using bayesian algorithms. technique enables decision makers obtain recommendations reduced number model evaluations. evaluate technique experimental setting best vaccine allocation strategy realistic simulation environment models inﬂuenza pandemic large social network. finally contribute evaluate statistic inform decision makers conﬁdence particular recommendation. primary preventive strategy mitigate seasonal inﬂuenza produce vaccine prior epidemic anticipating virus strains expected circulate. vaccine pool used inoculate population start epidemic. possible stockpile vaccines prepare seasonal inﬂuenza case inﬂuenza pandemics vaccine speciﬁcally tailored virus source pandemic. therefore appropriate vaccine produced responsible virus needs identiﬁed. hence vaccines available limited supply beginning pandemic addition production problems result vaccine shortages number vaccine doses limited imperative identify optimal vaccine allocation strategy long tradition using individual-based models study inﬂuenza epidemics allow accurate evaluation preventive strategies. state-of-the-art individual-based model driver many high impact research eﬀorts flute flute implements contact model population divided communities households population organized hierarchy social mixing groups contact intensity inversely proportional size group additionally flute implements individual disease progression model associates diﬀerent disease stages diﬀerent levels infectiousness. flute supports evaluation preventive strategies simulation therapeutic interventions non-therapeutic interventions multi-armed bandit game involves k-armed bandit returns reward pulled common bandit game pull sequence arms cumulative regret minimized fulﬁll goal player needs carefully balance exploitation exploration. paper objective recommend best ﬁxed number pulls. referred ﬁxed budget best-arm identiﬁcation problem instance pure-exploration problem given budget objective established computational budget needs speciﬁed priori problem setting matches ﬁxed budget best-arm identiﬁcation setting. diﬀers settings attempt identify best predeﬁned conﬁdence i.e. racing strategies strategies exploit conﬁdence bound arms’ means recently ﬁxed conﬁdence best-arm identiﬁcation algorithms selected bayesian ﬁxed budget best-arm identiﬁcation algorithms incorporate prior knowledge arms’ reward distributions arms’ posteriors deﬁne statistic support policy makers decisions. refer broader overview state respect best-arm identiﬁcation algorithms. best-arm identiﬁcation algorithms used large application domains i.a. evaluation response surfaces initialization hyperparameters traﬃc congestion. preliminary work explored potential multi-armed bandits evaluate prevention strategies regret minimization setting using default strategies presented work ’adaptive learning agents’ workshop hosted aamas conference setting however inadequate evaluate prevention strategies silico minimizing cumulative regret sub-optimal identify best arm. additionally workshop paper experiments considered small less realistic population analyzed limited range values representative inﬂuenza pandemics. formulate evaluation preventive strategies multi-armed bandit game identifying best using ﬁxed budget model evaluations. presented method generic respect type epidemic modeled method evaluated context pandemic inﬂuenza next section. particular conﬁguration stochastic epidemiological model corresponds studied epidemic. consider multi-armed bandit pk}| arms. pulling corresponds evaluating running simulation epidemiological model bandit thus preventive strategies arms reward distributions corresponding outcome distribution stochastic epidemiological model parameters reward distribution known intractable determine optimal reward analytically. hence must learn outcome distribution interaction epidemiological model. work consider prevention strategies equal ﬁnancial cost realistic assumption governments typically operate within budget constraints. previously deﬁned reward distribution associated bandit’s corresponds outcome distribution epidemiological model evaluated pulling arm. therefore employing insights epidemiological modeling theory allows specify prior knowledge reward distribution. well known disease outbreak possible outcomes either able spread beyond local context becomes fully established epidemic fades stochastic epidemiological models reﬂect reality hence epidemic size distribution bimodal evaluating preventive strategies objective determine preventive strategy suitable mitigate established epidemic. practice observe established epidemics epidemics faded simulation would bias evaluation. consequently necessary focus mode distribution associated established epidemic. therefore censor epidemic sizes correspond faded epidemic. size distribution remains approximately gaussian study consider scaled epidemic size distribution i.e. proportion symptomatic infections. hence assume bimodality full size distribution approximately gaussian size distribution established epidemic. veriﬁed experimentally assumptions hold reward distributions observed experiments heterogeneous host populations number secondary infections accurately modeled using negative binomial oﬀspring distribution basic reproductive number dispersion parameter speciﬁes extent heterogeneity. probability epidemic extinction pext computed solving probability generating function oﬀspring distribution epidemic individuals targeted preventive measures obtain following successive rejects serves useful baseline however support incorporate prior knowledge. bayesian best-arm identiﬁcation algorithms hand able take account knowledge deﬁning appropriate prior posterior arms’ reward distribution. show prior knowledge increase best-arm identiﬁcation accuracy. additionally time recommended posteriors contain valuable information used formulate variety statistics helpful assist decision makers. consider state-of-the-art bayesian algorithms bayesgap top-two thompson sampling top-two thompson sampling derive statistic based posteriors inform decision makers conﬁdence recommendation probability success. established previous section bandit reward distribution approximately gaussian unknown mean variance. purpose genericity assume uninformative jeﬀreys leads following posterior prior bayesgap gap-based bayesian algorithm algorithm requires high-probability upper bound lower bound deﬁned posterior time step using bounds quantity deﬁned represents upper bound simple regret step algorithm minimizes quantity compared maximizes upper bound highest conﬁdence diameter pulled. reward results pull observed used update ak’s posterior. budget consumed amount exploration feasible given particular bandit game proportional available budget inversely proportional game’s complexity complexity modeled taking account game’s hardness variance rewards. hardness quantity deﬁned theorem supplementary information formally proves using bounds results probability simple regret asymptotically reaches exponential lower bound respective mean standard deviation posterior time step secondly need measure variance representative reward distribution arms. arms initialized observe sample variance compute average bounds depend standard deviation t-distributed posterior arm’s posterior needs initialized times ensure deﬁned initialization also ensures proper posteriors top-two thompson sampling reformulation thompson sampling algorithm used pure-exploration context thompson sampling operates directly arms’ posterior reward distribution’s mean time step thompson sampling obtains sample arm’s posterior. highest sample pulled reward subsequently used update arm’s posterior. approach proven highly successful minimize cumulative regret balances exploration-exploitation trade-oﬀ sub-optimal identify best adapt thompson sampling minimize simple regret top-two thompson sampling increases amount exploration. exploration probability needs speciﬁed. time step sample obtained arm’s posterior. atop highest sample pulled probability probability repeat sampling posteriors atop- highest posterior sample atop atop-. atop- found pulled observed reward used update posterior pulled arm. available budget consumed highest average reward recommended. top-two thompson sampling requires samples arms’ posteriors t-distributed posteriors equation avoid improper posteriors needs initialized times probability recommendation correct presents useful conﬁdence statistic support policy makers decisions. top-two thompson sampling recommends highest average reward assume arm’s reward distributions independent probability success random variable represents mean recommended arm’s reward distribution recommended arm’s posterior probability density function arms’ cumulative density function. integral cannot computed analytically estimate using gaussian quadrature. important note that aiming generality made conservative assumptions reward distributions approximated gaussian uninformative jeﬀreys prior used. assumptions imply derived probability success under-estimator actual recommendation success conﬁrmed experiments. composed performed experiment context pandemic inﬂuenza analyze mitigation strategy vaccinate population limited number vaccine doses available experiment accommodate realistic setting evaluate vaccine allocation consider large realistic social network wide range values. consider scenario pandemic emerging particular geographical region vaccines becomes available albeit limited number doses. number vaccine doses limited imperative identify optimal vaccine allocation strategy experiment explore allocation vaccines diﬀerent groups easily approached health policy oﬃcials pre-school children school-age children young adults older adults elderly proposed epidemiological model used experiments flute stochastic individual-based model. experiment consider population seattle includes individuals population realistic respect number individuals community structure provides adequate setting validation vaccine strategies ﬁrst simulated epidemic random individuals seeded infection. epidemic simulated days time infections seeded. thus infections established time simulation result mixing infectious susceptible individuals. assume pre-existing immunity towards circulating virus variant. choose number vaccine doses allocate approximately population size computational complexity flute simulations depends size susceptible population proportion population becomes infected. population seattle simulation time minutes standard deviation seconds) state-of-the-art hardware adults older adults elderly allocation scheme encoded boolean tuple position tuple corresponds respective group. boolean value particular position tuple denotes whether vaccines allocated respective group. vaccines allocated particular group done proportional size population part group decide best vaccine allocation strategy enumerate possible combinations tuple. presents interesting evaluation problem. demonstrate this visualize outcome distribution figure firstly observe diﬀerent values distances arms’ means diﬀer. additionally outcome distribution variances vary values diﬀerences produce distinct levels evaluation hardness demonstrate setting’s usefulness benchmark evaluate preventive strategies. discuss hardness experimental settings consideration important state best-arm identiﬁcation framework requires prior knowledge problem’s hardness. secondly expect outcome distribution bimodal. however probability sample mode outcome distribution represents non-established epidemic decreases increases expectation conﬁrmed inspect figure left panel shows bimodal distribution right panel shows unimodal outcome distribution samples established epidemic obtained. assess performance diﬀerent best-arm identiﬁcation algorithms algorithm budgets range evaluation performed inﬂuenza bandit game deﬁned earlier. budget algorithms times report recommendation success rate. previous section optimal vaccine allocation strategy identiﬁed evaluate algorithm’s performance respect respect uniform sampling current state-of-the evaluate preventive strategies. uniform sampling method pulls step given budget au’s index sampled uniform distribution consider diﬀerent levels hardness perform analysis value bayesian best-arm identiﬁcation algorithms prior speciﬁcations detailed section bayesgap requires upper lower bound deﬁned terms used posteriors. experiments upper bound lower bound established section toptwo thompson sampling requires parameter modulates amount exploration important best-arm identiﬁcation algorithms differentiate arms choose that limit top-two thompson sampling explore arms uniformly. censor reward distribution based threshold deﬁned section threshold depends basic reproductive number dispersion parameter deﬁned explicitly experimental settings. dispersion parameter choose conservative choice according literature deﬁne probability cutoﬀ figure shows recommendation success rate best-arm identiﬁcation algorithms results values visualized section supplementary information. results diﬀerent values clearly indicate selection best-arm identiﬁcation algorithms signiﬁcantly outperforms unifigure ﬁgure present results experiment curve represents rate successful recommendations range budgets curve shown considered algorithms bayesgap successive rejects top-two thompson sampling uniform sampling form sampling method. overall uniform sampling method requires double amount evaluations achieve similar recommendation performance. harder problems recommendation uncertainty remains considerable even consuming times budget required top-two thompson sampling. best-arm identiﬁcation algorithms require initialization phase order output well-deﬁned recommendation. successive rejects needs pull least once top-two thompson sampling bayesgap need pull respectively times reason algorithms’ performance evaluated initialization phase. bayesgap’s performance successive rejects except hardest setting studied comparison top-two thompson sampling consistently outperforms successive rejects pulls initialization phase. top-two thompson sampling needs initialize arm’s posterior pulls i.e. double amount uniform sampling successive rejects. however experiments clearly show none algorithms reach acceptable recommendation rate using less pulls. section derived statistic express probability success concerning recommendation made top-two thompson sampling. analyzed probability top-two thompson sampling recommendations obtained experiment described above. provide insights statistic used support policy makers show values top-two thompson sampling recommendations left panel figure figure indicates closely follows recommendation correctness uncertainty inversely proportional size figure top-two thompson sampling times budget experiment recommendations computed. left panel values shown scatter plot point’s color reﬂects correctness recommendation right panel values binned thus bernoulli trials show empirical success rate clopper-pearson conﬁdence interval orange reference line denotes perfect correlation empirical success rate estimated probability success. available budget. additionally right panel figure conﬁrm underestimates recommendation correctness. observations show potential serve conservative statistic inform policy makers conﬁdence particular recommendation thus used deﬁne meaningful cutoﬀs guide policy makers interpretation recommendation preventive strategies. formulate objective select best preventive strategy individualbased model ﬁxed budget best-arm identiﬁcation problem. experiment evaluate setting context realistic pandemic inﬂuenza. assess best recommendation performance preventive bandit report success rate independent bandit runs. demonstrate possible eﬃciently identify optimal preventive strategy using limited number model evaluations even large number preventive strategies consider. compared uniform sampling technique able recommend best preventive strategy reducing number required model evaluations -to- times using toptwo thompson sampling. additionally deﬁned statistic support policy makers decisions based posterior information obtained top-two thompson sampling. such present decision support tool assist policy makers mitigate epidemics. framework enable paper learn respect single model outcome however many pathogens interesting incorporate multiple objectives therefore future work multi-objective multi-armed bandits. pieter libin timothy verstraeten supported grant kristof theys jelena grujic diederik roijers supported postdoctoral grant fwo. computational resources provided ewi-fwo grant supplementary information provide proof bayesgap’s simple regret bound furthermore provide additional ﬁgures omitted main manuscript ﬁgures outcome distributions ﬁgures experimental success rates ﬁgures probabilities success budget ﬁgures binned distribution values finally section describe computational resources used execute simulations. theorem consider k-armed gaussian bandit problem budget unknown variance. generalization variance arms respectively upper lower bounds time ˆµk− ˆσk. simple problem setting presented intuitively result makes sense known variances gaussian used describe posterior means indeed number pulls approaches inﬁnity t-distributions converge gaussians. simulations high performance cluster used bridge nodes speciﬁcally nodes -core bridge xeon cpus ram. infrastructure allowed flute simulations node.", "year": "2017"}