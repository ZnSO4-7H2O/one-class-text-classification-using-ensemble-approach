{"title": "White matter hyperintensity and stroke lesion segmentation and  differentiation using convolutional neural networks", "tag": "q-bio", "abstract": " The accurate assessment of White matter hyperintensities (WMH) burden is of crucial importance for epidemiological studies to determine association between WMHs, cognitive and clinical data. The manual delineation of WMHs is tedious, costly and time consuming. This is further complicated by the fact that other pathological features (i.e. stroke lesions) often also appear as hyperintense. Several automated methods aiming to tackle the challenges of WMH segmentation have been proposed, however cannot differentiate between WMH and strokes. Other methods, capable of distinguishing between different pathologies in brain MRI, are not designed with simultaneous WMH and stroke segmentation in mind. In this work we propose to use a convolutional neural network (CNN) that is able to segment hyperintensities and differentiate between WMHs and stroke lesions. Specifically, we aim to distinguish between WMH pathologies from those caused by stroke lesions due to either cortical, large or small subcortical infarcts. As far as we know, this is the first time such differentiation task has explicitly been proposed. The proposed fully convolutional CNN architecture, is comprised of an analysis path, that gradually learns low and high level features, followed by a synthesis path, that gradually combines and up-samples the low and high level features into a class likelihood semantic segmentation. Quantitatively, the proposed CNN architecture is shown to outperform other well established and state-of-the-art algorithms in terms of overlap with manual expert annotations. Clinically, the extracted WMH volumes were found to correlate better with the Fazekas visual rating score. Additionally, a comparison of the associations found between clinical risk-factors and the WMH volumes generated by the proposed method, were found to be in line with the associations found with the expert-annotated volumes. ", "text": "white matter hyperintensities feature sporadic small vessel disease also frequently observed magnetic resonance images healthy elderly subjects. accurate assessment burden crucial importance epidemiological studies determine association between wmhs cognitive clinical data; causes eﬀects treatments randomized trials. manual delineation wmhs tedious costly time consuming process needs carried expert annotator problem delineation complicated fact pathological features often also appear hyperintense regions. recently several automated methods aiming tackle challenges segmentation proposed. methods speciﬁcally developed segment cannot diﬀerentiate wmhs strokes. methods capable distinguishing diﬀerent pathologies brain designed simultaneous stroke segmentation mind. therefore task speciﬁc reliable fully automated method segment diﬀerentiate pathological manifestations fully identiﬁed. work propose convolutional neural network able segment hyperintensities diﬀerentiate wmhs stroke lesions. speciﬁcally distinguish pathologies caused stroke lesions either cortical large small subcortical infarcts. proposed fully convolutional architecture called uresnet comprised analysis path gradually learns high level features followed synthesis path gradually combines up-samples high level features class likelihood semantic segmentation. quantitatively proposed architecture shown outperform well established state-of-the-art algorithms terms overlap manual expert annotations. clinically extracted volumes found correlate better fazekas visual rating score competing methods expert-annotated volumes. additionally comparison associations found clinical risk-factors volumes generated proposed method found line associations found expert-annotated volumes. white matter hyperintensities referred clinical literature leukoaraiosis white matter lesions white matter disease characteristic small vessel disease commonly observed elderly subjects ﬂuid-attenuated inversion recovery magnetic resonance images which name suggests appear hyperintense regions. moreover stroke lesions cortical large subcortical small subcortical infarct origin also often appear hyperintense regions flair images coexist coalesce wmhs. accurate assessment burden crucial importance epidemiological studies determine associations wmhs cognitive clinical data. similarly would help discover causes eﬀects treatments randomized trials. assessment burden important exclude stroke lesions diﬀerent underlying pathologies failure account important implications design sample size calculations observational studies randomized trials using quantitative measures progression brain atrophy outcome measures widely used metrics assess burden severity fazekas visual rating scale scale radiologist visually rates deep white matter peri-ventricular areas scan four possible categories depending size location conﬂuence lesions. combination deep white matter peri-ventricular ratings yields combined zero scale. vast majority clinical trials general clinical practice visual rating scores used wmhs variable size appearance location therefore categorical nature fazekas scale limitations studying progression relation clinical parameters. volume demonstrated correlate severity symptoms progression disability clinical outcome accordingly determining volume interest clinical research well clinical trials diseasemodifying drugs studies lesions traced manually slice slice. process easily become prohibitively expensive even moderately large datasets. therefore obvious accurate automatic quantiﬁcation volume would highly desirable undoubtedly lead savings time cost. recently several automated semi-automated methods forward address coarseness visual assessments well dependence highly qualiﬁed experts perform assessments. methods broadly classiﬁed supervised training goldstandard available i.e. human experts annotated data unsupervised gold-standard exists semi-supervised small portion available data expertly annotated however despite number proposed methods automated solution currently widely used clinical practice publicly available partly lesion load deﬁned previously proposed automatic segmentation algorithms take account contribution strokes lesion methods generally unable diﬀerentiate types lesions. sion segmentation imaging. additionally general segmentation approaches share architectural similarities method propose also reviewed section. last years increased amount research going areas although methods mentioned proposed segmenting diﬀerent pathologies rather ones explore work fact applied diﬀerent tasks. mentioned before methods broadly classiﬁed unsupervised semi-automatic semi-supervised supervised depending amount expertly annotated data available. unsupervised segmentation. unsupervised segmentation methods require labeled data perform segmentation. approaches employ clustering methods based intensity information anatomical knowledge group similar voxels clusters fuzzy c-means methods em-based algorithms gaussian mixture models probabilistic generative models lesion formation stroke lesion segmentation also designed forbes proposed bayesian multi-sequence markov model fusing multiple sequences robustly accurately segment brain lesions. derntl proposed combine standard atlas-based segmentation stroke lesion occurrence atlas patient-speciﬁc iterative procedure. authors also proposed model lesions outliers normal tissues. leemput employed weighted framework voxels model weighted less estimation considered potential lesions. weiss proposed dictionary learning learn sparse representation pathology free brain t-weighted scans applied dictionary sparsely reconstruct brain images contain pathologies lesions identiﬁed using reconstruction error. additionally several works also focused exploiting fact wmhs best observed flair images difﬁcult identify t-weighted images. methods rely generating synthetic flair image based observed t-weighted image using random forests generative mixture-models support vector regression convolutional neural networks synthetic real flair images compared detect abnormalities. method like lesiontoads combines atlas segmentation statistical intensity modeling simultaneously segments major brain structures well lesions. lesion growth algorithm proposed schmidt part spm’s toolbox constructs conservative lesion belief pre-chosen threshold followed initial grown along voxels appear hyperintense flair image. essence self-seeded algorithm tends diﬃculties detecting subtle wmhs. important drawback methods fact abnormality detection algorithms speciﬁcally segmentation methods hence principle detect pathology whether wmh-related pathology. semi-automatic semi-supervised segmentation. several semi-automatic algorithms proposed literature segmentation rely region growing techniques require initial seed points placed operator. kawata introduced region growing method adaptive selection segmentation using image features extracted initially identiﬁed candidates. itti proposed another region growing algorithm extracts wmhs propagating seed points neighboring voxels whose intensity optimized threshold. process iterates convergence i.e. voxels threshold connected initial seed point annotated. aside drawback requiring image expert inputs semi-automatic methods additional potential drawback seeds points could easily selected obvious regions biggest challenge segmentation arguably found confusing border regions. proposed semi-supervised algorithm optimizes kernel based maxmargin objective function aims maximize margin averaged inliers outliers exploiting limited amount available labeled data. although theoretically interesting well motivated problem transferring useful knowledge unlabeled data task deﬁned partially annotated data remains challenge open ﬁeld research right. hence practice semi-supervised segmentation methods even though still require expert input tend underperform compared supervised methods even later trained modest amount data. k-nearest neighbors bayesian models support vector machines random forests well studied segmentation. stroke lesion segmentation pattern classiﬁcation techniques learn segmentation function also employed lesion prediction algorithm implemented spm’s toolbox shown produce consistently good performance many cases considered robust gold standard problem. described logistic regression model binary lesion maps patients used response values. additionally covariates model lesion belief similar used combination spatial covariate takes account voxel speciﬁc changes lesion probability. recently ithapu proposed using svms random forests combination texture features engineered texton ﬁlter banks segmentation task. brain intensity abnormality classiﬁcation algorithm fully automated supervised method based algorithm also proposed segmentation. interesting work proposed dalca used generative probabilistic model diﬀerential segmentation leukoaraiosis stroke learning spatial distribution intensity proﬁle pathology shares application purpose work proposed here. recently cnns forward replace inference step many computer vision related tasks current stateof-the-art methods many ﬁelds dominated frameworks. cnns shown enough capacity model complex nonlinear functions capable performing multi-class classiﬁcation tasks required description understanding highly heterogeneous problems brain lesion segmentation instance brosch proposed deep convolutional encoder network combines feature extraction segmentation prediction lesions. work later extended deep encoder network shortcut connections consistently outperformed methods across wide range lesion sizes kamnitsas proposed network architecture parallel convolutional pathways processes patches diﬀerent scales followed densely connected conditional random ﬁeld although method originally proposed ischemic stroke tumor brain injury segmentation images easily adapted diﬀerent tasks using provided package deepmedic. similarly ghafoorian proposed architecture considered multi-scale patches explicit location features training later extended consider non-uniform patch sampling best performing architecture shares similar design architecture proposed kamnitsas trained independent paths convolutional layers scale. using multi-resolution inputs increase ﬁeld view smaller feature maps also allowing non-linearities used higher resolution desired properties. however down-sampling patches drawback valuable information discarded processing done since ﬁlters learned ﬁrst layers cnns tend basic feature detectors e.g. lines curves diﬀerent paths risk capturing redundant information. furthermore although convolutions performed intuitively make sense volumetric images flair image acquisitions actually often acquired images large slice thickness stacked volume. this gold standard annotations generated trained radiologists usually derived assessing images slice slice. thus pointed ghafoorian convolutions flair image segmentation fact less intuitive. works segmentation relevant work though brain lesion segmentation include long ronneberger proposed segment natural images using fully convolutional network supplemented output gradually contracting network features several levels contraction up-sampling. similar ronneberger used u-shaped architecture segment microscopical cell images. architecture symmetrically combined contracting expanding path feature concatenations up-sampling operations realized trainable kernels networks form foundation architecture later proposed work. challenges. several challenges held brain lesion segmentation recent years. instance lesion segmentation challenge goal direct comparison diﬀerent lesion segmentation techniques. data used challenge consisted brain images wide range patients pathology severity. longitudinal lesion segmentation challenge aimed apply automatic lesion segmentation algorithms neuroimaging data acquired multiple time points patients. ischemic stroke lesion segmentation challenge held since aims provide platform fair direct comparison methods ischemic stroke lesion segmentation multi-spectral image asked methods allow prediction lesion outcome based acute data. recently segmentation challenge held aiming directly compare methods automatic segmentation presumed vascular origin data used challenge acquired diﬀerent scanners three diﬀerent vendors three diﬀerent hospitals. work address short comings mentioned propose segment diﬀerentiate wmh-related pathology strokes. speciﬁcally task distinguishing pathologies pathologies originating stroke lesions result either cortical subcortical infarcts. this architecture inspired u-net originally used segment neuronal structures electron microscopic stacks proposed. architecture consists analysis path aims capture context symmetric synthesis path gradually combines analysis synthesis features ultimately enable precise localization. proposed architecture trained large high-resolution image patches able extract highlow-level features single path thus avoiding ﬁlter learning redundancy. diﬀerent work proposed replace convolutions residual elements concatenations used skip connections u-net architecture summations reduce model complexity. residual architectures shown ease gradient back-propagation hence improve optimization convergence speed allow deeper network training. important contribution work deals data sampling training. large class imbalance present segmentation data sampling training requires careful consideration issue received recent research focus inﬂuence precision segmentation here mitigate class imbalance training done using patches rather dense training whole images. this sample patches always contain randomly shift central location occur anywhere patch necessarily include center. argued before proposed architecture designed images trained image patches. furthermore experiment multi-channel inputs evaluate added beneﬁt adding scans white matter and/or cerebro-spinal track probability maps. proposed architecture refer uresnet visualized figure convolution non-linearity operations element sequence generally referred layer. layer produces features maps here convolutional kernel layer produces feature parametrized refers feature hl−. solution problem estimates conditional distribution minimizes loss function deﬁned estimate layer feature maps intermediate representations obtained. work non-linearities deﬁned rectiﬁed linear addition sequence convolution non-linearity operations mentioned work presented here residual units residual elements employed reformulate previous mapping function bottom-right shows form resele used work. furthermore decrease number parameters associated increase network ﬁeld-of-view max-pooling layers employed. maxpooling operates independently input feature maximum valued activation support region discarded repeated every strided location. support region stride work respectively eﬀectively down-sampling factor every max-pool layer. deﬁning cnn’s architecture requires careful consideration task achieve. important aspects must taken account network’s ﬁeld view receptive ﬁeld capacity complexity. architecture proposed follow suggestions simonyan zisserman small kernels. allows increased non-linearity capacity lower number parameters needed receptive ﬁeld. architecture proposed follows u-shaped architecture. furthermore fully connected layers used thus fully convolutional network hence even though trained image patches inference performed whole images single feed forward pass without need architectural changes. total architecture composed general terms loss function maps values variables onto real number represents cost associated event. loss functions deﬁned classiﬁcation tasks functions calculate penalty incurred every incorrect prediction. mentioned before casting semantic segmentation task voxel-wise classiﬁcation problem tends lead signiﬁcant class imbalances. loss functions deﬁned take class imbalance account. here detail classical loss function take account class imbalance well several recently proposed loss functions either directly indirectly take account class imbalance subject investigation. patches extracted in-plane flair axial slices treated independent samples training. here total number patches available total number voxels patch. additionally also deﬁne voxel level labels one-hot encoded one-hot encoded label space class voxel given c-length vector zeros except position indicates associated label. however simplify notation following loss equations re-indexing voxels corresponding label number voxels patches therefore problem estimating mapping function deﬁned minimization loss function works pseudo probabilities obtained equation popular loss function classiﬁcation tasks tackled here categorical cross-entropy aims maximize likelihood data equally minimize cross-entropy following classical cross-entropy take account class imbalances data might lead learning biased predictors. simple approach deal class imbalance proposed segmentation modify aggregation categorical cross-entropy given equation weighting voxels belong diﬀerent classes diﬀerently. modiﬁcation aims give weight under-represented classes weighting represented ones written recently proposed simple modiﬁcation categorical cross-entropy dropping ignoring loss contribution elements whose correct class prediction certain threshold eﬀect placing emphasis previous mistakes thus focusing learning process harder examples during training. dubbed online bootstrapped categorical cross-entropy loss function written dice coeﬃcient deﬁned binary space aims maximizing overlap regions class. makes popular natural choice metric comparing binary segmentation labels. however non-diﬀerentiable making optimization backpropagation algorithm possible. recently winning team second annual data science bowl proposed using pseudo dice coeﬃcient loss function written here predicted binary labels replaced continuous softmax outputs averaged across labels denotes softmax prediction class aggregating dice coeﬃcients diﬀerent classes average additional eﬀect normalizing per-class loss contribution. generally segmentation pathologies healthy tissue present larger quantities pathological. example segmentation number voxels labeled small compared labeled background/healthy tisdataset used work labeled background/healthy tissue training set). hence although dense training staple computer vision natural images less intuitive segmentation. therefore patch sampling used work order alleviate class imbalance problem. several techniques could used sample patches training. example half samples could extracted locations centered healthy tissue half centered tissue however strategy little class imbalance large patches considered individual patches tend still highly class imbalanced voxel level. another option sample patches centered locations only combination proposed architecture ﬁeld view comparable sample size would lead location bias wmhs always expected center patch. instead propose deﬁning random subset voxels extract training patches random shift half patch size applied axial plane patch extraction augment dataset. figure details procedure. important point location sensitivity mentioned here generally issue dense training natural images diﬀerent classes either appear anywhere scene class location gives meaningful description problem occurs sampling patches training images systematic proposed here. proposed methodology evaluated using subset images consecutive patients presented hospital stroke service ﬁrst clinically evident non-disabling lacunar mild cortical ischemic stroke diabetes hypertension vascular risk factors criteria exclusion. however patients unstable hypertension diabetes neurological disorders major medical conditions including renal failure contraindications unable give consent hemorrhagic stroke whose symptoms resolved within hours excluded. subset subjects considered work consisted stroke lesions delineated diﬀerent annotation classes i.e. contained strokes labeled excluded. work stroke lesions included recent lesions deﬁned turn either cortical sub-cortical nature. subset subjects used contained additional complete clinical demographic data. information included risk factors clinical assessments reported diabetes reported hypertension reported hyperlipidaemia reported smoking mini mental state examination systolic blood pressure diastolic blood pressure total cholesterol peri-ventricular fazekas score deep white matter fazekas score deep atrophy volume basal ganglia enlarged peri-vascular spaces score centrum semiovale enlarged peri-vascular spaces score stroke lesion present total number micro-bleeds image data acquired brain research imaging centre edinburgh signa horizon clinical scanner equipped selfshielding gradient manufacturer-supplied eight-channel phased-array head coil. details protocols used acquiring data given table rationale explained although several imaging sequences acquired flair images used study. subjects considered work acquired protocol protocol protocol image sequences co-registered using fslflirt mapped patient’s flair space. images acquired protocol delineated using multispectral coloring modulation variance identiﬁcation described mcmxxxvi based principle modulating mapping red/green/blue color space diﬀerent sequences display tissues/lesions brain diﬀerent intensity levels employing minimum variance quantization clustering technique segment diﬀerent tissue types. here mcmxxxvi considers hyperintense signals simultaneously appear t-weighted based sequences. images acquired protocols delineated human corrected histogram-based threshold flair sequence. stroke lesions separately extracted semi-automatically thresholding interactive region-growing guided radiological knowledge flair identiﬁcation procedure described table single stroke class created combining recent old. images re-sliced dimensions axial slices remaining dimension left unchanged. white matter probability maps obtained image segmentation using cerebro-spinal track probability maps obtained co-registering tract probability flair image space. additionally order consistent intensity voxel values model training images normalized zero mean standard deviation values three standard deviations mean clipped order guarantee consistent background values across images. random subset possible locations labeled locations labeled stroke. images included study contained lesions these also contained stroke lesions. data split separate sets used fold cross-validation fold contained half images half stroke represent data distribution folds. fold cross validation experiments fold used training setting parameters second fold reserved testing. optimization loss function input channel selection stopping criteria carried training set. appendix comparison proposed uresnet version used residual blocks convolutions observe added value center shifting training patch sampling experiments carried using theano lasagne frameworks adam optimization mini-batch size learning rate random weight initialization evaluation criteria used compare methods split mainly comparison well established state-of-the-art methods clinical analysis. comparison methods consisted evaluation labeling overlap segmented images using dice coeﬃcient analysis diﬀerences automatically calculated volumes expert terms intra-cranial volume comparison results calculated using dice coeﬃcient volume analyses reported class basis. clinical evaluations consisted correlation analysis clinically relevant variables general linear model analysis association known risk factors. important factor training deﬁnition loss function guide learning process here experimented several recently proposed loss functions used train proposed segmentation using flair images input. order directly compare eﬀect diﬀerent loss functions dice score results evaluating diﬀerent stages training calculated figure here horizontal axis indicates number training epochs vertical axis indicates dice score achieved either train test datasets. work epoch deﬁned transversing complete training patches once. must also noted dice results displayed calculated whole brain volumes extracted patches. figure shows results obtained using classical bootstrapped weighted cross-entropy loss functions well using pseudo dice similarity score figure observed weighted classical cross-entropy perform best little diﬀerence them. however weighted cross-entropy additional class weight parameter associated also need set. hence problem presented work considering experiments conducted classical cross-entropy considered best choice. important take notice using dice coeﬃcient loss function evaluation metric provides surprisingly poor results training here theorize that particular problem solution space optimize might mentioned before wmhs best observed flair images however suggested complementary information might found images. work contribution additional multi-modal information proposed segmentation framework explored. additional input channels proposed include images white matter probability maps cerebro-spinal tract atlas. segmentation accuracy evaluated using dice score. figure seen training converges epochs traversing whole extracted training patches times. therefore test dice scores automatic volumes presented obtained evaluating model epochs. given diﬀerent input channels training data testing results take account segmentation classes indicate little diﬀerence using four input channels compared using flair images. hence subsequent experiments made flair images input channels. additionally justiﬁed fact comparison methods flair images. furthermore acquisition additional modalities probability generation costly/time consuming render methodology less clinically viable. figures also observed training testing dice scores stroke segmentations much oscillatory segmentation. behavior explained fact simply less data stroke results sensitive variations network’s parameters epoch provides stochastic gradients associated class. furthermore stroke higher training accuracy combined lower test accuracy attributed class imbalance potentially point over-ﬁtting problem. experiments presented section proposed uresnet segmentation compared well established state-of-theart algorithms. lesion segmentation toolbox version frameworks used. used using flair images input required flair images. deepmedic recently published library segmentation medical images also used comparisons presented default settings. parameters frameworks according fold cross-validation using data splits described uresnet. parameter threshold used binarize lesion probability maps generated optimal value cross-validation authors recommend setting value however produced poor results hence excluded analysis. parameters cross-validation threshold deepmedic also validated using fold cross-validation strategy network trained fold tested other however meta-parameter tuning done. deepmedic trained using images re-sliced isotropic voxel size patch sampling internally handled deepmedic. default sampling option used randomly samples patches healthy tissue pathological tissue dice overlap scores automatically generated expertly annotated stroke lesions shown table here observed proposed uresnet outperforms compared methods comparisons dice scores obtained proposed every competing found statistically signiﬁcant according wilcoxon’s signed rank test. statistical signiﬁcance gives measure likelihood diﬀerence groups could attributed change eﬀect size quantiﬁes relative magnitude diﬀerence groups. cohen describes eﬀect size values small medium large respectively. eﬀect sizes related statistical signiﬁcance tests ysis expertly annotated volumes automatically generated. remove potential bias associated head size thus allow better comparison volumes converted ideally automatic algorithms produce values similar possible expert hence close dotted lines figure solid lines indicate general linear trend expert automatic comparison coeﬃcient determination indicates degree automatic values explain expert ones. figure bottom perform clearly worse approaches also evident outperforms value respectively. diﬀerences uresnet deepmedic less evident. however close inspection metric table uresnet deepmedic uresnet results slightly better correlated generated expert. hand deepmedic slope uresnet slope suggesting slightly better agreement. figure shows bland-altman plots compare expert automatic volumes. plots horizontal axis gives average expert automatic volumes subject vertical axis shows diﬀerence volumes. reproducibility coeﬃcient calculated here gives measure variability diﬀerences automatic manual volumes calculated dotted lines plots figure give range rpc. bland-altman plots also provide insight possible biases compared methods. displays statistically signiﬁcant tendency under-estimate volumes however methods tend under-estimate larger volumes over-estimate small ones eﬀect pronounced lga. main objectives work presented also diﬀerentiate stroke lesions. neither capable making distinction therefore suitable algorithms problem. figure shows correlation analysis automatic expert stroke volumes evident uresnet outperforms deepmedic terms rmse linear slope. analysis figure shows bland-altman plots conﬁrm ﬁndings uresnet obtains smaller deepmedic neither method average displaying statistically signiﬁcant tendency overunder-estimate volumes however worth noting methods tendency over-estimate small volumes under-estimate larger ones. summary figures also presented table diﬀerence algorithms terms dice scores observed. statistical signiﬁcance comparison uresnet deepmedic dice scores found according wilcoxon’s signed rank eﬀect size related statistical signiﬁcance uresnet deepmedic considerably closed additional inputs provided deepmedic however requires additional image acquisition tissue segmentation and/or co-registration cerebro-spinal track atlas. furthermore appendix results deepmedic experiments approximate sampling scheme used uresnet discussed. figure shows segmentation results three example subjects illustrate diﬀerences methods. here observed uresnet generally better diﬀerentiating stroke lesions compared deepmedic bottom figure example illustrated uresnet wrongly figure automated versus expertly generated stroke volumes. unable distinguish stroke hence cannot generate results. solid line indicates linear trend comparison dotted indicates ideal trend segments stroke. additionally methods shown clearly under-segment image compared expert shown. however inspecting flair image subject seen under-segmented regions would challenging even another expert annotator. experiments thus indicate better agreement volumes generated uresnet expert annotations however question clinical validity results remains open. regard table gives correlation coeﬃcient results volumes clinical variables fazekas scores split deep white matter peri-ventricular values ranging additional combined fazekas score created adding d-fazekas pv-fazekas also presented. table observe terms correlation fazekas score proposed uresnet outperforms competing methods additionally noting results pv-fazekas fazekas even higher obtained expert annotations. however terms mmse performed best. using clinical scores well known risk factors available analysis association volumes risk factors carried out. order explore associations results every algorithm risk factors generated. models risk factors clinical scores treated dependent variables volumes acted independent variable. careful consideration reported diabetes reported hypertension reported hyperlipidaemia reported smoking total cholesterol deep atrophy volume bgpvs score used analysis. table provides p-values indicate particular risk factor associated generated volumes glms corrected gender diﬀerences. results indicate bgpvs found associated expertly generated volumes however deep atrophy volume also found associated methods. additionally volumes also found associated diabetes. figure visual comparisons competing methods. yellow lines delineate green lines stroke white arrows point interesting result areas. best seen color. table p-values linear regression associations volumes calculated diﬀerent methods risk factors. bold numbers indicate statistical signiﬁcance table p-values linear regression associations volumes calculated diﬀerent methods risk factors residual outliers removed. bold numbers indicate statistical signiﬁcance analysis values well described model signiﬁcant impact subsequent analyses. outliers identiﬁed examining probability distribution residuals. order eliminate potential bias introduced outliers analysis outliers removed performed. results outlier-free association analysis presented table figure shows normal probability plot residuals methods outlier removal. table observe outliers removed expert volumes found associated deep atrophy volume bgpvs diabetes. associations found uresnet deepmedic addition also associated age. found associated bgpvs deep atrophy volume. variable) therefore excluded previous analysis. nonetheless included fazekas scores also composed sanity check correct associations would found. single fazekas score generated adding d-fazekas pv-fazekas scores volumes. eﬀect size association fazekas score expertly generated volumes indicates change fazekas scale translates change increase wmhs deepmedic obtained closest eﬀect size association fazekas scores volumes expert prediction increase fazekas point produces increase uresnet closely followed predictions. results produced eﬀect sizes respectively. expert stroke lesion volumes systolic blood pressure risk factor found associated incidentally also associated automatically generated volumes. uresnet values additionally found associated hypertension. however important note small size heterogeneous nature population used analysis might prove suﬃcient uncover associations. small sample analyzed outlier removal analysis performed stroke associations. work proposed framework uresnet segmentation wmhs capable distinguishing wmhs arising diﬀerent pathologies mainly wmhs presumed origin stroke lesions. comparison results indicate proposed uresnet architecture outperforms well established state-of-the-art algorithms. architecture used uresnet follows closely architecture u-net main diﬀerence residual elements generally lower complexity summation instead concatenation skip connections. preliminary experiments summation concatenation features maps found diﬀerence performance hence complexity favored. however also noted general solution given concatenation would allow network learn best combining feature maps training. course additional complexity comes expense higher risk over-ﬁtting higher memory consumption. mentioned residual units provide advantages training mainly improved convergence rates experiments. recently proposed pre-activated residual unit optimizes architecture unit making training easier improving generalization. future work involve updating architecture include residual elements evaluating merits context segmentation. large class imbalance medical image segmentation generally issue must considered. loss functions take account class imbalance drawback additional class weighting parameter tune. additional complication resulting large class imbalance computational eﬀort might spent optimizing perform well large relatively easy classify/segment sections image. bootstrapped cross-entropy attempts focus learning process hard classify parts image dropping loss function contribution voxels already classiﬁed good degree certainty. however technique also requires setting additional parameter threshold consider classiﬁcations already good moreover evaluation results indicated performance similar classical cross-entropy. important factor proposed framework training data sampling strategy described section training medical imaging using patches somewhat standard technique helps reduce large class imbalance usually aﬀects medical image segmentation. however careful consideration must given sampling strategy adopted certain architecture. mentioned class imbalance lesion location within samples need considered. proposed sampling strategy described section profound eﬀect proposed frequency class sampled. work sampled locations labeled locations labeled stroke balance classes. important note default sampling settings deepmedic used default sampling strategy deepmedic samples equally healthy diseased tissues furtherinclude central voxel oﬀset sampling strategy used here. believe factors signiﬁcant impact diﬀerences beimportant aspect note segmentation notoriously challenging example bartko anbeek consider similarity scores excellent landis koch consider scores moderate substantial near perfect respectively. mind consider average dice scores wmhs generated proposed uresnet well deepmedic substantial generating moderate results. important note heart unsupervised method data used tune parameter. uresnet deepmedic capable distinguishing diﬀerent types lesion regard uresnet produced average stroke dice score could considered moderate. research presented partially funded innovate grant framework programme european commission additionally data used preparation work obtained funding fogo charitable trust wellcome trust section present results comparing proposed architecture sampling scheme additional version residual block takes traditional form convolutional elements another proposed center shifting sampling scheme replaced standard centered patch sampling scheme table summarizes results. equivalent linear projection. experimented residuals blocks convolutions observed statistical diﬀerence them. however learning residual linear projections might still simpler thus leading observed faster convergence. observations need interpreted care. believe dice overlap scores method achieves close expected intra-rater variability hence lack observed diﬀerence performance convolutions residual blocks might come limitations data itself. training patches always contain diseased label center would bias towards labeling region patch diseased inference. patch center shifting alleviates problem distribution probability observe lesion across whole ﬁeld-of-view. example would estimate probability observing lesion particular location training patch would probability observe lesion center explicitly sampled manner. allowing patches shifted spreads probability locations single location preferential likelihood lesion fully convolutional neural network predictions made large area taking account context information large areas image however training driven pixel-wise prediction errors hence labeling occurs per-pixel basis. likelihood observing lesion particular location fact less uniform. uniformity removes bias towards particular location. results comparing uresnet center shifting sampling shown table approaches uresnet deepmedic easily trained using several inputs. table provides dice overlap results using diﬀerent input channels approaches provided. appreciated deepmedic narrow dice overlap uresnet several inputs provided. however discussed before obtaining generating extra inputs limits clinical applicability also adds additional computational costs whole segmentation framework. table mean dice scores stroke correlation analysis expert automatic volumes correlation clinical variables. statistical signiﬁcance uresnet uresnet observed statistically signiﬁcant diﬀerence patch oﬀ-center sampling regular oﬀ-center sampling tested deepmedic. direct comparison per-class patch sampling straight forward proposed method deepmedic furthermore misleading. instance work proposed sampling rate whm-stroke patches used patch size voxels uresnet makes prediction patch label space training means patch used uresnet table mean dice scores stroke diﬀerent inputs uresnet deepmedic. diﬀerence dice score methods given italics. flair image cerebro-spinal track atlas white matter probability weighted image. label size inevitably contains large amount healthy tissue. therefore sample speciﬁcally healthy regions. hand deepmedic trains segments label space voxels therefore less likely healthy tissue included nonhealthy samples thus healthy segments need sampled. nonetheless diﬀerent per-class sampling rates well hyper-parameter settings deepmedic explored. learning rate rmsprop optimizer sampling form foreground/background sampling rate diﬀerent sampling rates tested deepmedic experiments approximate uresnet setup healthy stroke tissue respectively. additionally learning rate values explored range rmsprop adam optimizer. changing sampling rates default generally produced unstable results either failing converge producing poorer overlap values default settings. total diﬀerent additional deepmedic train/test runs performed converged using sampling rate dice overlap results experiments stroke respectively instance other. unstable results might tuning additional meta parameters optimizer learning rate regularization. therefore presented deepmedic results obtained default", "year": "2017"}