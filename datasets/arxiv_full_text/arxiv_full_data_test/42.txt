{"title": "Fast event-based epidemiological simulations on national scales", "tag": "q-bio", "abstract": " We present a computational modeling framework for data-driven simulations and analysis of infectious disease spread in large populations. For the purpose of efficient simulations, we devise a parallel solution algorithm targeting multi-socket shared memory architectures. The model integrates infectious dynamics as continuous-time Markov chains and available data such as animal movements or aging are incorporated as externally defined events. To bring out parallelism and accelerate the computations, we decompose the spatial domain and optimize cross-boundary communication using dependency-aware task scheduling. Using registered livestock data at a high spatio-temporal resolution, we demonstrate that our approach not only is resilient to varying model configurations, but also scales on all physical cores at realistic work loads. Finally, we show that these very features enable the solution of inverse problems on national scales. ", "text": "present computational modeling framework data-driven simulations analysis infectious disease spread large populations. purpose eﬃcient simulations devise parallel solution algorithm targeting multi-socket shared memory architectures. model integrates infectious dynamics continuous-time markov chains available data animal movements aging incorporated externally deﬁned events. bring parallelism accelerate computations decompose spatial domain optimize cross-boundary communication using dependency-aware task scheduling. using registered livestock data high spatio-temporal resolution demonstrate approach resilient varying model conﬁgurations also scales physical cores realistic work loads. finally show features enable solution inverse problems national scales. important designing cost-eﬃcient surveillance control challenge disease dynamics transmission routes various pathogens fundamentally diﬀerent. indirect transmission pathogens environment fecal-oral diseases requires diﬀerent model compared diseases spread direct contact individuals another challenge incorporate increasing amount epidemiologically relevant data models therefore desirable simulation tools ﬂexible various disease spread models eﬃcient handle large amounts available livestock data. uncertainties exact details pathogen transmission inherent random nature animal interactions stochastic modeling natural often required. spatial models include proximity infected farms local clustering disease spread gained popularity foot-mouthdisease epidemic another important route disease spread animal trade creating temporal network contacts farms shown topology connectivity network great impact disease spread eﬀect control measures stochastic models discrete state-spaces typically simulated using discrete event simulation general approach evolve dynamical systems consisting discrete events including particular continuous-time markov chains realistic epidemiological models formulated large state-space and/or need studied comparably long periods time parallelization desirable. highest degree parallelism typically achieved decomposition spatial information often represented graph network sub-domains strategy event handling domain boundaries well concurrent execution scales overall degree parallelism extractable. hinder scalability constraint plays crucial role design parallel maintain sequential ordering events preserve underlying causality model. general types boundary events occur simulation hence ultimately decide optimal parallelization strategy. deterministic essentially fully predictable character stochastic predictable earlier simulation time parallelize events belong latter group sophisticated approaches optimistic parallel algorithms proposed approaches speculative execution enable scalability must implement rollback mechanisms case event causality violated alternatively simulations domain crossing events deterministic thus predictable conservative simulation used possible avoid causal violations altogether particular parallel scheduler used create execution order guarantees causality previously shown notably focus simulation telecommunication networks. continuous-time markov chains real livestock data deterministic events. allows create temporal network disease transmission shown aspect modeling simulation spatial disease spread previously agent-based simulations based synthetic data studied others model deﬁned allows predict future boundary events simulation time hence able create parallel execution traces respect causality. particular dependency-aware task computing used implement approach high eﬃciency necessary information maintain spatial temporal causality events speciﬁed dynamic creation tasks dependencies. contrast previous approaches scheduler implicit part parallel simulation algorithm chosen user wide selection openly available libraries starpu show selected library integrated simulation framework assigning parts sequential algorithm independent tasks scheduled using certain rules. evaluate approach using task-parallel run-time library superglue demonstrated eﬃcient scheduler ﬁne-grained tasks. using simulator models realistic work-loads demonstrate scalability multi-socket shared-memory system investigate approach preferable comparison traditional parallelization techniques. achievable scalability clearly depends properties individual model particular choose investigate inﬂuence model’s connectivity pattern. paper organized follows. introduce mathematical foundation framework. discuss sequential simulation algorithm strategy parallelization. present numerical experiments carconsider section highly general approach epidemiological modeling. proceeding stepwise start description single-node stochastic sir-type models form continuous-time markov chains using compact notation also encompasses externally deﬁned events. next couple ensemble single-node models network prescribed transitions nodes arrive global description. finally since realistic models multiple scales typically incorporate also quantities continuous description natural consider mixed approach continuous-time markov chains coupled ordinary diﬀerential equations sdes) follows. assume probability space ﬁltration contains poisson processes ﬁnite dimensionality. time depen+ counts time number dent state vector individuals diﬀerent categories compartments. since random process discrete character right continuous only; therefore denote value state events stoichiometric coeﬃcient small additional convention notation also encompasses events deﬁned externally. suppose example sirmodel susceptible individuals added known deterministic times accomplish replace evolves full dynamics coupled stochastic-deterministic model. note removing individuals using scheme care required able guarantee non-negative chain. although previous discussion completely general character makes sense handle collective dynamics possibly large collection nodes slightly streamlined fashion. assuming nodes total consider state matrix znc×nn evolve local dynamics previous description assumed essentially individuals counted discrete stochastic model needed accurately capture dynamics possibly small noisy population. multiscale model however makes sense allow also continuous state variables representing following section discuss implementation details computational framework. begin indicating numerical methods consistently designed approximate mathematical model arrived previously. description sequential solution algorithm presentation chosen parallelization strategy based domain decomposition follows. propose process events cross domain boundaries tasks thus conclude introduction dependency aware task computing associated scheduling scheme. freeze variable previous time-step integrate stochastic dynamics only. next insert average eﬀective value integrate deterministic part using suitable deterministic numerical method. describe concrete numerical method assumptions order. firstly assume events connecting nodes externally deﬁned. particular assumption satisﬁed important case domesticated herds animals move nodes human interventions only. secondly thus remove direct inﬂuence continuous variables connected nodes. reasonable macroscopic variables easily transported like bacterias soil could course violated media like groundwater air. stochastic part measure evolved time produce temporary variable next incorporates externally deﬁned deterministic events locally node according connectivity network. finally usual euler forward divide external events types; events type operate state single node events type operate states nodes. meaningful distinguish types events processed diﬀerently parallel algorithm discussed later. deﬁned attributes time event transition vector number individuals aﬀected indices aﬀected nodes. minimal attributes extended speciﬁc models. example within context model deﬁne birth sequential simulation algorithm divided three parts; processing stochastic events hereafter referred stochastic step processing external events deterministic step update continuous state variable steps processed repeatedly above-mentioned order simulation reaches end. stochastic step adaptation gillespie’s direct method algorithm generates trajectory continuous-time markov chain. ﬁrst rates stochastic events evaluated nodes then node next algorithm uses inverse transform sampling obtain exponentially distributed random variable representing next stochastic event time node found compute state update according transition simulation time finally matrix setting obtain next event time rate event occurred dependent events need re-computed fast execution dependencies stored dependency graph traversed stage. algorithm repeats deﬁned stopping time reached external events next processed. deterministic step works read incorporate algorithm. moves list external events processes deﬁned event time. particular event speciﬁes single compartment transition occurs directly applied step diﬀerent numerical methods applied. note thus updated continuous state generally aﬀects rate stochastic events thus simulation proceeds next iteration stochastic step event times need rescaled using parallelization starts decomposition spatial domain model understood graph target graph partitioning problem divide vertices size approximately equally sized sub-domains cutting edges follows straightforwardly consecutive assignment vertices sub-domains. partitioning strategy guarantee minimum amount edge cuts distribution edges predominantly homogeneous data believe partitioning beneﬁt sophisticated approaches. nonetheless edges distributed heterogeneously minimum bisection algorithm generate optimized contributes better performance parallel solver. partitions v..k deﬁned preprocessing algorithm continues rearrange external events structure convenient parallel processing. firstly external events type assigned lists events aﬀecting nodes stored list. second external events type divided categories; external events type source destination nodes within processed thread assigned sub-domain private. events type complexity data-rearrangement number external events. although large workload typically negligible real-scale models. example national scale model presented finally decomposed problem simulated parallel. simplicity assume sub-domain bound computing thread. every thread processes stochastic step update continuous variable private nodes well deterministic step external event lists since time discretized computations embarrassingly parallel communication neighboring threads necessary processing time window ∆tn. potential bottleneck simulation lies simulation cross-boundary events diﬀerent ways. ﬁrst possibility compute entirely serial. valid approach relation private events scaling private computations aﬀected. hand overall simulation events regarded serialized little concurrency extractable using approach. hence focus occur every deterministic time step lower frequency private events. also investigate scaling regime achievable increasing amount scientiﬁc computations parallelized using taskbased computing order apply pattern programmer typically divide larger chunk work group smaller tasks processed asynchronously. run-time library used create execution schedule tasks available parallel hardware. granularity tasks suﬃciently schedule denser idle time shorter. hand scheduler synchronizes larger number small tasks usually implies overhead. thorough discussion impact granularity. scheduler supports dependency-awareness programmer deﬁne number task dependencies. critical feature data shared tasks therefore processing order enforced. believe usage task-based computing beneﬁcial computational framework small granularity processes given underlying modeling. approach divide computations tasks deﬁne scheduling policy guarantees causality events although processed parallel. scheduling rules implemented dependency aware task scheduler requirement scheduling policies support dynamic addressing sub-set dependencies e.g. array pointers. example open support computational experiments make run-time library superglue superglue dependencies assigned data expressed data versioning chunk data processed task version counter representing data access increased. tasks dependent chunk spawned whenever version becomes available. superglue demonstrated eﬃcient shared-memory task-scheduler capable operating comparably synchronization overhead. processing dependencies spawning tasks dynamic superglue additionally supports load balancing work stealing over-utilized threads. based implementation parallel algorithm. task executes private pseudo-code stochastic step nodes processing private external events lists well update continuous variables counter indicates iteration time window ∆tn. list grained processing compute single task. thus task takes argument distinct task. denote task sub-domains subject e-event update nodes aﬀected. counter denotes total order events given model input. implies events exist window processed task order. following section present results computational experiments simulator. following measurements obtained sandy; dell power edge computer system equipped four intel xeon processors cores socket. restricted execution available physical cores timing results hyper-threads strongly ﬂuctuating. begin real-world simulation using animal movement data national scales followed synthetic benchmark scalability varying connectivity load conclude compute-intensive parameter estimation example. verotoxigenic escherichia coli zoonotic bacterial pathogen potential cause severe disease humans notably children cattle infected vtec important reservoir pute private work partitioned sub-domains. coarse-grained tasks control higher number dependencies blocking occur. fine-grained scheduling leads better interleaving higher overhead cost. bacteria shed bacteria feces without signs clinical disease reducing prevalence infected cattle population could potentially reduce number human cases. however epidemiology vtec cattle complex targeted interventions control bacteria require thorough understanding source transmission routes explore feasibility national scale simulations improve understanding underlying disease spread mechanisms created model vtec dynamics using presented framework. european union legislation requires member states keep register bovine animals including location date birth movements holdings date death slaughter records enable data-driven disease spread simulations include spatio-temporal dynamics cattle population regard structures births herd size slaughter trade patterns. present computational experiment based cattle reports swedish board agriculture period reports three types external events single type event condensed. total external events processed total runtime days. events window events events finally continuous variable represents environmental bacterial concentration asserts infectious pressure individual node. suitable model given again nodes refers number susceptible infected individuals compartment node respectively. constant average shedding rate bacteria environment infected individual captures decay removal bacteria. experiments used constant value varied according season ﬁrst parallelized simulation spreading tasks multiple cores events hereafter referred fork-join approach. next simulated model using taskbased approach scheduling tasks coarse-grained ﬁne-grained policies described chose number sub-domains multiple number threads note also number tasks scheduled vary inspect boundary regions parallel performance. figure performance measurements vtec model simulation sandy varying scheduling approaches task sizes scale factor number tasks chosen proportional number threads open parallelization cross-boundary events processed entirely serial. error bars represent standard error mean scaling diﬀerent approaches shown figure case task sizes small eﬃcient task-based approaches thus fork-join approach reaches higher eﬃciency. observe coarse-grained processing performs better fork-join parallelization optimally task sizes case ﬁne-grained task processing found choice strong impact performance scaling. task densities scale strongly lower thread count density reaches high eﬃciency full thread consumption. thus eﬃciency doubled comparison eﬃciency fork-join parallelization found dependency parallel eﬃciency factor detailed figure observe scheduling overhead small task sizes prohibit high eﬃciency task-based approaches full potential approaches extractable larger thread count. note thread aﬃnity tasks varied throughout performed experiments order investigate impact data locality. dependencies ﬁne-grained lower coarsegrained explained larger number dependencies associated coarse-grained growing partitioning ﬁne-grained tasks interleave densely tasks thus leading lower idle times higher parallel eﬃciency. percentage total work spent processing tasks synchronization worker threads well time spent waiting fulﬁlled dependencies shown figure conﬁguration. table maximum full-width-half-maximum his± standard deviation dependencies assigned tasks discrete time interval given partitioning computing cores. figure percentage total work spent processing tasks synchronization time spent waiting dependencies various scheduling policies measured cores. note relation work overhead agrees well figure local events eﬀective connectivity network. investigate synthetic benchmark ﬁxed load local events created. model consists compartments only residing nodes. transitions simply nodes arranged sub-domains total distinct events generated time window connecting randomly sampled nodes belonging diﬀerent sub-domains. hence means sub-domains communicate sub-domains synchronization point. number tasks coarsegrained ﬁne-grained approach number threads deduce problem memory bound. coarse-grained task-based implementation fork-join approach scale similarly increasing connectivity ﬁne-grained task-based approach attains highest parallel eﬃciency performance drops higher global connectivity. phenomenon arises -task creates dependencies subsequent ts-tasks every synchronization window thus creating higher usually compute intensive load case ﬁtting model parameters typically using numerical optimization kind. problem brieﬂy ideally described follows; unknown parameters observed time-series data parameters estimated repeatedly simulating whole family trajectories parameters modiﬁed input data simulations match suitable sense. framework’s feasibility ﬁtting epidemiological model course important since modeling process point involve calibration parameters respect reference data. obtain robust procedure kind smoothing statistics considered. chose aggregate counts animals neighboring nodes larger regions. precise overall domain divided areas goodness deﬁned practice make pattern search routine conceptually resembles golden section search narrowing searchspace. numerical optimization routine evaluates residual error reaches deﬁned threshold. tests varied initial guess parameters found results vary substantially. results below conveniently .k∗. optimization landscape goal function hence deﬁniteness setup itself visualized figure simple bisection search behavior numerical routine obtained parameters fact displayed cases although relative residuals diﬀer considerably. note obvious approach parallelization computing independent trajectories using separate threads sequential algorithm unfavorable here related reasons. firstly executable needs store rather large state space working memory. secondly simulation must also access complete database externally scheduled events. modeling simulation important designing surveillance control livestock diseases major economic importance. however various pathogens require diﬀerent models capture disease dynamics transmission routes. moreover increasing amount epidemiologically relevant data becoming available. adressesed challenges present ﬂexible eﬃcient computational framework modeling simulation disease spread national scale. simulation involves parts. firstly algorithm evolves stochastic dynamics disease process. secondly list processor incorporates database events entering exit movement individuals model state. framework highly ﬂexible conceivable epidemiological models either directly expressible framework straightforwardly extended encompass also non-standard models. concrete example would relatively easy include intervention strategies vaccination programs order simulate impact global dynamics. explored diﬀerent strategies parallelize simulator multisocket architectures. firstly decomposed spatial information list deterministic events. observed decomposed problem figure goal function form conﬁdence intervals visualized parameter parameters held target value vertical lines indicate target obtained estimates k.... parameter ranges simulated high parallel eﬃciency limited processing cross-boundary events. created three parallel implementations simulator core; used open parallelize private computations fork-join fashion cross-boundary events processed serial. implementations dependency-aware task scheduler create execution traces interleave cross-boundary events private computations respect dependencies. strategy allows exploit shared-memory parallelism higher degree fork-join approach task sizes suﬃciently large. benchmark approach using superglue task library present scheduling rules deﬁning parallel simulator general terms thus allowing implemented also dependency-aware task libraries. private work load fork-join approach performs best mainly scheduling overhead task-based approaches. higher private work loads simulation beneﬁts task-based computing doubling parallel eﬃciency cores comparison fork-join approach. inspect performance dependency network properties constructed synthetic benchmark cross-boundary events generated randomly. found performance fork-join approach coarse-grained task approach scales well growing amount crossboundary events. notably performance ﬁne-grained task processing depends strongly connectivity boundary crossing events thus favoring fragmented network. ﬁnal example used simulator carry experimental parameter ﬁtting within vtec bacteria spread model. emphasize high computational complexity task multiple unknown parameters need several full simulation runs evaluate parameter candidate. similar load case results diﬀerent intervention strategies evaluated. example even several interventions reduce infectious spread globally policy maker could interested ﬁnding cost-eﬃcient strategy. work provide powerful highly general freely available software contribute rapid eﬃcient development realistic large-scale epidemiological models. future research encompass studies larger inverse problems including realistic data input complex dynamics. another point future study scalability task-based approach distributed environment. thank martin tillenius providing assistance superglue. work ﬁnancially supported swedish research council within upmarc linnaeus center excellence", "year": "2015"}