{"title": "Exact heat kernel on a hypersphere and its applications in kernel SVM", "tag": "q-bio", "abstract": " Many contemporary statistical learning methods assume a Euclidean feature space. This paper presents a method for defining similarity based on hyperspherical geometry and shows that it often improves the performance of support vector machine compared to other competing similarity measures. Specifically, the idea of using heat diffusion on a hypersphere to measure similarity has been previously proposed, demonstrating promising results based on a heuristic heat kernel obtained from the zeroth order parametrix expansion; however, how well this heuristic kernel agrees with the exact hyperspherical heat kernel remains unknown. This paper presents a higher order parametrix expansion of the heat kernel on a unit hypersphere and discusses several problems associated with this expansion method. We then compare the heuristic kernel with an exact form of the heat kernel expressed in terms of a uniformly and absolutely convergent series in high-dimensional angular momentum eigenmodes. Being a natural measure of similarity between sample points dwelling on a hypersphere, the exact kernel often shows superior performance in kernel SVM classifications applied to text mining, tumor somatic mutation imputation, and stock market analysis. ", "text": "department physics university illinois urbana-champaign urbana carl woese institute genomic biology university illinois urbana-champaign urbana columns data matrix naturally interpreted points high-dimensional feature space traditional statistical modeling approaches often lose power feature dimension high. ameliorate problem laﬀerty lebanon proposed multinomial interpretation date sparse data clouds extensively analyzed euclidean space endowed l-norm using traditional statistical learning algorithms including kmeans hierarchical hypersphere parametrix expansion limit involves modiﬁed euclidean heat kernel euclidean distance replaced geodesic length computing parametrix euclidean l-norm great length sn−. unit vectors obtained non-negative feature vectors hyperspherical cosine similarity reduces product non-negativity guarantees case. again special dimensions dimensions singular note metric geodesic polar coordinate parametrix expansion coeﬃcients must vanish identically explicitly shown above. suﬀers numerous problems. zeroth order correction term diverges behavior major problem restricted range moreover gprx also unphysical condition dimension time obtained expanding e−θ/t noting leading order term product factors non-decreasing function distance corresponding unphysical situation nearby points hotter heat source itself. feature dimension typically large restriction work computed ﬁrst second order correction terms denoted equation equation respectively.in high dimensions divergence major problem expect expansion valid vicinity however divergence pathological thus truncate approximation since able correct unphysical behavior parametrix kernel near high dimensions conclude parametrix approximation fails high dimensions. hence remaining part gprx still applicable classiﬁcation perturbative expansion using euclidean heat kernel starting point suggests diﬀusion fundamentally diﬀerent exact hyperspherical heat kernel derived deﬁnition exact heat kernel gext fundamental solution heat equation ∂tu+ hyperspherical laplacian language operator theory gext integral kernel green’s function operator exp{− ˆlt} associated eigenfunction expansion. exp{− ˆlt} share eigenfunctions obtaining eigenfunction expansion gext amounts solving complete basis eigenfunctions spectral decomposition laplacian turn facilitated embedding utilizing global rotational symmetry euclidean space harmonic functions solutions laplace equation projected unit hypersphere usual separation radial angular variables formalism hyperspherical laplacian naturally arises angular part euclidean laplacian interpreted squared angular momentum operator resulting eigenfunctions known hyperspherical harmonics generalize usual spherical harmonics higher dimensions. hyperspherical harmonic equipped triplet parameters quantum numbers {mi} degree magnetic quantum numbers {mi} eigenfunction expansion exp{− ˆlt} addition theorem hyperspherical harmonics magnetic quantum number {mi} obtain figure color maps exact kernel kext rescaled time white paths simulated random walks monte carlo time approximately equal plots parametrix kernel kprx exact kernel kext figure illustrates diﬀusion process captured exact kernel kext three feature dimensions time figure systematically compared behavior dimension-independent parametrix kernel kprx time exact kernel kext symmetry slope kext vanished south pole time dimension sharp contrast kprx negative slope highlighting singular behavior parametrix kernel. relatedness measured kext sweet spot ﬁnite table webkb--university document classiﬁcation. performance test four-class classiﬁcation webkb--university word count data diﬀerent number representatives class entries show average optimal -fold cross-validation mean accuracy scores runs. exact kernel reduced error parametrix kernel gaussian cosine kernel also reduced error linear kernel table webkb--university document classiﬁcation. comparison kernel svms webkb--university data ﬁxed sample size varying feature dimension account randomness selecting representative samples using kmeans performed ﬁves runs representative selection performed using training test sets obtained run. finally averaged mean scores assess performance classiﬁer imbalanced webkb--university data set. exact cosine kernels outperformed gaussian linear kernels various feature dimensions ﬁxed balanced class size word selected feature total count greater times total number pages webkb--university data diﬀerent thresholds corresponding diﬀerent rows table. exact kernel reduced errors gaussian table tcga-gbm genotype imputation. performance test binary classiﬁcation mutant wild-type tcga-gbm mutation count data. rows diﬀerent genes mutation statuses imputed using samples mutant wild-type class. entries show average optimal -fold cross-validation mean accuracy scores runs. figure comparison classiﬁcation accuracy using linear cosine gaussian parametrix exact kernels tcga mutation count data. plots show ratio accuracy scores diﬀerent kernels. visualization purpose excluded gene ratios rbf/lin prx/cos ext/cos essentially constant class size greater words gaussian kernel outperformed linear kernel exact parametrix kernels outperformed cosine kernel uniformly values class size however negative slope linear cos/lin hints accuracy scores cosine linear kernels depend class size exact kernel also tended outperform gaussian kernel small. figure strong linear relation seen vc-bound cosine kernel class size dashed line marks vc-bound linear kernel however constant µ∗lin scatter plots accuracy scores cosine linear exact gaussian kernels eﬀective sample size mr/µ∗ accuracy scores exact cosine kernels increased eﬀective sample size whereas gaussian linear kernels tended decrease eﬀective sample size. ratio accuracy scores positively correlated ratio ˜mcos/ ˜mlin eﬀective sample sizes. table stock classiﬁcation. classiﬁcations performed stocks companies financial information technology. log-return instances january november used features. uniformly subsampled instances generate variations feature dimension here report mean -fold accuracy score kernel. although classes slightly imbalanced scores resentatives. webkb document classiﬁcations used min{mstudent mfaculty mcourse mproject} k-means clustering performed four classes separately; random initialization performed clustering times selected frequent representatives. five-fold stratiﬁed cross-validations performed resulting squared orbital angular momentum operator quantum mechanics. restricted laplacian reduces spherical laplacian exactly operator whose eigenfunctions spherical harmonics eigenvalue setting viewed angular component homogeneous harmonic polynomials perspective used subsequent discussion hyperspherical laplacian. convention spherical harmonics satisfy normalization condition homogeneous harmonic polynomials satisfy spherical coordinates decompose desired hyperspherical harmonic. using spherical coordinate laplacian shown equation propose choice self-similarity neither large small. large self-similarity roughly uniform similarity /asn− thereby losing contrast neighbors outliers. contrast approaches self-similarity becomes inﬁnite keep self-similarity ﬁnite larger uniform similarity suggests choice order self-similarity roughly e/asn−. thus search optimal value around n/n. prx/cos ext/cos greater class sizes interestingly ratio cos/lin showed dependence sample size exact kernel also tended outperform gaussian kernel small; general noted hyperspherical kernels tended outperform euclidean kernels small-sample-size classiﬁcation problems. pattern vc-dimension classiﬁer m/µvc eﬀective sample size. derivative respect proportional positive factor times µvc/η]. thus upper bound decreases increases otherwise; critical eﬀective sample size ˜mcrt typical values dimension linear kernel estimated using accuracy exact kernel also increased ˜mcos slightly higher accuracy additional tunable parameter adjust curvature nonlinear decision boundaries.", "year": "2017"}