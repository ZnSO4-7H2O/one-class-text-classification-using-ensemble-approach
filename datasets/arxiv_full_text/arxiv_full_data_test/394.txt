{"title": "A Linear Algebra Approach to Fast DNA Mixture Analysis Using GPUs", "tag": "q-bio", "abstract": " Analysis of DNA samples is an important step in forensics, and the speed of analysis can impact investigations. Comparison of DNA sequences is based on the analysis of short tandem repeats (STRs), which are short DNA sequences of 2-5 base pairs. Current forensics approaches use 20 STR loci for analysis. The use of single nucleotide polymorphisms (SNPs) has utility for analysis of complex DNA mixtures. The use of tens of thousands of SNPs loci for analysis poses significant computational challenges because the forensic analysis scales by the product of the loci count and number of DNA samples to be analyzed. In this paper, we discuss the implementation of a DNA sequence comparison algorithm by re-casting the algorithm in terms of linear algebra primitives. By developing an overloaded matrix multiplication approach to DNA comparisons, we can leverage advances in GPU hardware and algoithms for Dense Generalized Matrix-Multiply (DGEMM) to speed up DNA sample comparisons. We show that it is possible to compare 2048 unknown DNA samples with 20 million known samples in under 6 seconds using a NVIDIA K80 GPU. ", "text": "abstract—analysis samples important step forensics speed analysis impact investigations. comparison sequences based analysis short tandem repeats short sequences base pairs. current forensics approaches loci analysis. single nucleotide polymorphisms utility analysis complex mixtures. tens thousands snps loci analysis poses signiﬁcant computational challenges forensic analysis scales product loci count number samples analyzed. paper discuss implementation sequence comparison algorithm re-casting algorithm terms linear algebra primitives. developing overloaded matrix multiplication approach comparisons leverage advances hardware algoithms dense generalized matrix-multiply speed sample comparisons. show possible compare unknown samples million known samples seconds using nvidia gpu. forensics branch forensic science focuses genetic material criminal investigations short tandem repeats stretches containing short repeat units neucleotides used forensic human identity testing forensics currently uses strs chromosomal locations referred combined index system loci. comparing proﬁles samples individuals current standard justice systems. samples contributor difﬁcult impossible analyze using proﬁles. proﬁling single nucleotide polymorphisms advantages strs comparisons mixture samples united states federal bureau investigation database million proﬁles national index system comparing large number proﬁles large dataset known reference proﬁles currently computationally expensive process typically done large datacenter. fastid method developed enable rapid searching forensic panels large numbers loci runs processors. paper cast fastid method dense distribution statement approved public release distribution unlimited. material based upon work supported assistant secretary defense research engineering force contract fa--c- and/or fa--d-. opinions ﬁndings conclusions recommendations expressed material author necessarily reﬂect views assistant secretary defense research engineering. matrix multiplication operation graphics processing units enable fast comparisons proﬁles individuals individuals individuals mixtures mixtures mixtures. paper organized follows section describes process analysis forensics applications. section ii-a gives overview fastid method mixture comparisons section ii-b describe problem dense matrix multiplication algorithm. section details implementation fastid algorithm optimizations described. finally section present results approach used analyze large datasets summarize section composed series molecules called nucleotides encoded corresponding four types nucleotides. allele variant gene located speciﬁc position speciﬁc chromosome. single nucleotide polymorphism genetic variation individuals represents difference single nucleotide sample. average million snps human genome snps biological markers disease used identifying inheritance within families. context forensics comparing snps samples help identify individuals relatives. typically major allele common population people minor allele lower allele frequency major allele. snps typically alleles alleles possible. represent major allele respresent minor allele. alleles four possibilities individual compare snps size individuals comparisons needed compare alleles. fastid mixture comparison algorithm used paper ﬁrst developed ricke algorithm used compare samples individuals well mixtures samples. algorithm identiﬁes similarity samples ﬁrst performing bitwise exclusive-or operation reference sample query sample shown figure next step perform bitwise operation result reference sample. finally count number bits result operation gives measure similarity known unknown sample. practice samples compared mapping string alleles binary representations comparing proﬁles directly computer hardware instruction. -bits result represent positions difference minor alleles individuals. computer hardware population count instruction used -bits result identify minor allele differences proﬁles. compare individual sample mixture logical operation performed results individual proﬁle consider minor alleles individual. implementation fastid algorithm samples ﬁrst converted alleles array unsigned integers. sample snps mapped unsigned -bit integer numbers. sample thus represented length array unsigned integers. example let’s consider sample snps binary representation -bit unsigned integer decimal equivalent procedure used convert known unknown samples arrays -bit unsigned integers. algorithm proceeds performing operation equation integer arrays representing known unknown samples. length array depends number snps used comparison denoted rest paper. algorithm comparing single unknown mixture legnth known sample length shown algorithm algorithm viewed overloaded dot-product vectors length multiplication operation replaced practice enforcement agencies federal bureau investigation millions known proﬁles correspondingly large number unknown samples need identiﬁcation. number known samples number unknown samples length described previously. algorithm algorithm re-written shown algorithm operation equation must performed times. comparison matrix multiplication given known samples length unknown mixtures length goal compare every unknown sample every known sample. case view procedure overloaded product vectors representing unknown samples known samples shown figure cast proposed algorithm dense matrix multiplication operation organizing input data matrices size representing known unknown samples respectively. thus population counts given samples represented overloaded matrix multiplication operation dimension dimension dimension matrix multiplication overloaded figure shows execution program written using nvidia cuda programming platform language memory hierarchy nvidia gpus. serial code runs parallel section code implemented using cuda library launched kernel. cuda programming model enables programmers ﬁne-grained parallel code large number threads threads organized grid blocks shown figure block group threads runs single multiprocessor access shared memory collection threads concurrently called warp. detailed descriptions execution cuda program reader referred kirk also several types memory available individual thread global shared constant memory. constant memory read-only threads whereas global shared memories written read threads. amount shared constant memory signiﬁcantly smaller global memory accesses shared constant memory much faster global memory. optimization cuda programs involves management data transfers data layout device memory maximization computation global memory transfer ratio. optimizations discussed section iii-b. matrix multiplication widely researched topic signiﬁcant amount research towards optimizing dense matrix-matrix multiplication gpu. blas library provides routines basic vector matrix operations including matrix-matrix multiplication. optimized libraries atlas intel also available variety platforms. addition libraries magma nvidia cublas compute optimization addition tiled approach second optimization technique proposed volkov compute elements output matrix csub thread. allows fewer threads leading greater registers computations performed parallel. paper compute output elements thread. also employ loop unrolling unroll unrolled nvidia compiler default. c/c++ stored row-major format. result memory accesses matrix threads block coalesced; i.e. threads wrap access successive memory locations global memory. coalescing memory accesses number clock cycles required fetch data global memory shared memory minimized. memory accesses coalesced global memory access effectively serialized. transposing matrix memory transferring device memory access also coalesced. memory layout matrices adjusted appropriately reading data input ﬁles. gpus limited amount ram. experiments described paper conducted using nvidia tesla ram. limits size matrices created kernel. example comparing known proﬁles unknown proﬁles length represented using -bit unsigned integers generates result matrix size requires memory. compare large numbers mixtures break computation series smaller comparisons. moving data memory space memory space signiﬁcant bottleneck computing. technique hiding latency data transfers overlap compute data transfers. however case entire memory available used storing inputs results comparison algorithm order minimize number kernel launches number data transfers gpu. result possible overlap compute data transfers. typically number unknown proﬁles signiﬁcantly smaller number known reference proﬁles. case transfer query proﬁles block known reference proﬁles followed kernel launch perform comparisons. next batch known proﬁles compare transferred time results previous batch copied back cpu. also offer optimized implementations matrix-matrix multiplications leverage multi-core processors gpus. approaches optimizing dense matrix multiplication algorithm well researched utilized development algorithm described section. given matrices appropriate dimensions na¨ıve approach matrix multiplication ported shown algorithm single thread computes output element matrix order compute single output output matrix thread copy column matrices respectively global memory compute overloaded inner product equation copy result back global memory. data arrays type -bit unsigned integer result popcount described section ii-a blockidx.y blockdim.y threadidx.y blockidx.x blockdim.x threadidx.x tiling shared memory usage na¨ıve approach matrix multiplication described earlier bandwidth bound. number global memory transfers reduced improving data locality tiling shared memory. tiling approach involves computing output small block time reusing data already fetched global memory. threads load block data required compute sub-block csub output matrix shared memory. required sub-matrices asub bsub loaded shared memory given block threads used computing output matrix csub. approach illustrated figure paper block sizes used depending algorithm dominated time required transfer results back gpu. transfer times copying known unknown samples signiﬁcantly smaller fraction total time spent data transfers relatively small amount data copied. figure shows cummulative kernel time total time spent data transfers memory. seen ﬁgure time spent transferring data tends dominate. time reduced ofﬂoading additional computations performing additional reduction operation data memory. additionally pinned memory reduce time takes copy results back memory shown figure using pinned memory provides consistently faster data transfer time compared nonpinned memory comes cost small added overhead time memory allocated ﬁrst time. paper discuss formulation forensics dense linear algebra problem. based approach used speed computations involve comparing millions known proﬁles thousand unknown proﬁles. current approaches forensics employed forensics community require large computing systems take hours. using gpus overloaded matrix multiplication desribed paper possible reduce compute time required process large amounts data. paper single nvidia computations performance proposed algorithm comparing mixtures compared unknown proﬁles million known proﬁles. large mismatch number known unknown proﬁles unknown proﬁles transferred along block known proﬁles. depending total number comparisons performed number known reference proﬁles used given kernel launch changed memory utilized. also helped minimize number data transfers memory. result nearly full utilization memory kernel launch possible overlap data transfers computation. experiments also perfomed measure performance using pinned non-pinned memory kernel. figures show cumulative kernel time comparing mixtures snps respectively. total time spent kernel function total number comparisons known unknown samples total time blackford demmel dongarra duff hammarling henry heroux kaufman lumsdaine petitet pozo remington whaley updated basic linear algebra subprograms trans. math. softw. vol. jun. whaley dongarra automatically tuned linear algebra software ninth siam conference parallel processing scientiﬁc computing cd-rom proceedings. dongarra gates haidar kurzak luszczek tomov yamazaki accelerating numerical dense linear algebra calculations gpus numerical computations gpus authors would like thank adam michaleas michael jones support nvidia hardware software conﬁguration. would also like thank david martinez support. national library medicine national human genome institute national institutes health forensics geneed genetics education discovery https//geneed.nlm.nih.gov/topic subtopic.php? tid= isaacson schwoebel shcherbina ricke harper petrovick bobrow boettcher helfer zook wack robust detection individual forensic proﬁles mixtures forensic science international genetics vol.", "year": "2017"}