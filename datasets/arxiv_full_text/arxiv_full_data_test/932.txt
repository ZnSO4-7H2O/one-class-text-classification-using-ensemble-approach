{"title": "Onto2Vec: joint vector-based representation of biological entities and  their ontology-based annotations", "tag": "q-bio", "abstract": " We propose the Onto2Vec method, an approach to learn feature vectors for biological entities based on their annotations to biomedical ontologies. Our method can be applied to a wide range of bioinformatics research problems such as similarity-based prediction of interactions between proteins, classification of interaction types using supervised learning, or clustering. ", "text": "computer electrical mathematical sciences engineering division computational bioscience research center king abdullah university science technology thuwal saudi arabia. motivation biological knowledge widely represented form ontology-based annotations ontologies describe phenomena assumed exist within domain annotations associate biological entity phenomena within domain. structure information contained ontologies annotations makes valuable developing machine learning data analysis knowledge extraction algorithms; notably semantic similarity widely used identify relations biological entities ontology-based annotations frequently used features machine learning applications. results propose ontovec method approach learn feature vectors biological entities based annotations biomedical ontologies. method applied wide range bioinformatics research problems similarity-based prediction interactions proteins classification interaction types using supervised learning clustering. evaluate ontovec gene ontology jointly produce dense vector representations proteins classes annotated axioms constrain classes. first demonstrate ontovec-generated feature vectors significantly improve prediction protein-protein interactions human yeast. illustrate ontovec representations provide means constructing data-driven trainable semantic similarity measures used identify particular relations proteins. finally unsupervised clustering approach identify protein families based enzyme commission numbers. results demonstrate ontovec generate high quality feature vectors biological entities ontologies. ontovec potential significantly outperform state-of-the-art several predictive applications ontologies involved. availability https//github.com/bio-ontology-research-group/ontovec contact robert.hoehndorfkaust.edu.sa xin.gaokaust.edu.sa. biological knowledge available across large number resources several formats. resources capture different often complementary aspects biological phenomena. years researchers working representing knowledge structured formal creating biomedical ontologies ontologies provide means formally structure classes relations within domain employed wide range biological databases webservices file formats provide semantic metadata notably ontologies used annotation biological entities genomic variants genes gene products chemicals classify biological activities associations wide-spread ontologies several methods developed utilize information ontologies data analysis particular wide range semantic similarity measures developed applied similarity-based analysis ontologies entities annotated them. semantic similarity measure defined ontology used measure similarity ontology classes sets classes entities annotated sets ontology classes. semantic similarity measures classified different types depending annotations ontology classes incorporated weighted type information ontology used determine similarity similarity measures treat ontologies graphs nodes represent classes edges axiom involved connected classes however axioms ontology naturally represented graphs possible alternative consider axioms ontology computing semantic; challenge determine axiom contribute determine similarity beyond merely considering syntactic similarity. addition similarity-based analysis ontology-based annotations frequently used machine learning approaches. ontology-based annotations encoded binary vectors representing whether entity associated particular class semantic content ontologies used generate semantically closed feature vectors alternatively output semantic similarity measures widely used features machine learning applications example drug repurposing systems identification causative genomic variants approaches common features generated contain explicit information structure ontology therefore dependencies different features; dependencies therefore longer available features machine learning algorithm. case semantic similarity measures information ontology used define similarity information used define similarity subsequently reduced single point case binary feature vectors ontology structure used generate values feature vector subsequently longer present available machine learning algorithm. feature vectors explicitly encode ontology structure entity’s annotations would contain information either information alone perform significantly better machine learning applications alternative approaches. finally semantic similarity measures generally hand-crafted i.e. designed expert based assumptions ontology used constitute similarity. however depending application semantic similarity different features less relevant define notion similarity. previously observed different similarity measures perform well datasets tasks worse others without measure showing clear superiority across multiple tasks. possible define common similarity measure performs equally well multiple tasks establish train semantic similarity measure data-driven way. always possible absence training data desired outcomes available approach result better intuitive similarity measures hand-crafted ones. develop ontovec novel method jointly produce dense vector representations biological entities ontology-based annotations ontology structure used annotations. apply method gene ontology generate dense vector representations proteins annotations. demonstrate ontovec generates vectors outperform traditional semantic similarity measures task similarity-based prediction protein-protein interactions; also show ontovec train semantic similarity measure datadriven predict protein-protein interactions distinguish types interactions. apply ontovec-generated vectors clustering show generated clusters reproduce enzyme commission numbers proteins. ontovec method generic developed ontovec method learn dense vector-based representations classes ontologies biological entities annotated classes ontologies. generate vector representations combined symbolic inference statistical representation learning. first generated vector-based representations classes ontology extended result generate representations biological entities annotated classes. vector-based representations generated ontovec provide foundation machine learning data analytics applications including semantic similarity applications. main contribution ontovec method learn representation individual classes ontology taking account axioms ontology contribute semantics class either directly indirectly. ontovec uses ontology format applies hermit reasoner infer logical axioms call union axioms inferred axioms deductive closure designated contrast treating ontologies taxonomies graph-based structures assume every axiom constitutes sentence axiom corpus sentences. vocabulary corpus consists classes relations occur well keywords used formulate axioms ontovec uses skip-gram model learn representation word occurs corpus. representation word vocabulary vector predictive words occurring within context window ontovec also used learn vector-based representations biological entities ontologies annotation combine information entities’ annotations well semantics classes used annotation single representation. trivially since ontovec generate representations single classes ontology entity annotated classes represented combination vector representations classes. example entity annotated representations generated ontovec representation alternatively ontovec directly generate representation extending axioms additional axioms explicitly capture semantics annotation. ontology generated annotations adding axioms capturing semantics annotation relation class instance ontovec generate representation comprehensive case applied method joint knowledge base consisting proteins manual annotations obtained uniprot database. generate latter knowledge base added proteins entities connected using has-function relation functions. applied ontovec generate vector representations class generate joint representations proteins classes generated protein representations combining class vectors proteins’ annotations ontovec-vectors generated define representation total generated vectors representing proteins vectors representing classes. figure illustrates main ontovec workflow construct ontology-based vector representations classes entities. table values curves prediction. best value among methods shown bold. resnik semantic similarity measure; ontovec method protein ontology class representations learned jointly single knowledgebase deductively closed; ontovec noreasoner identical ontovec deductive closure knowledge base; binary represents protein’s annotations binary vector onto generates vector representations classes compares proteins comparing annotations individually using cosine similarity averaging individual values using best match average approach; onto addvec sums class vectors represent protein. methods suffix logistic regression support vector machine artificial neural network respectively either ontovec binary protein representations. applied vectors generated proteins classes prediction protein-protein interactions functional semantic similarity. first experiment evaluated accuracy ontovec predicting protein-protein interactions. purpose generated several representations proteins first used ontovec learn representations proteins jointly representations classes adding proteins annotations using has-function relations; second represented proteins vectors representing classes annotated; third represented proteins classes annotated. used cosine similarity determine similarity vectors. compare sets vectors other used best match average approach pairs vectors compared using cosine similarity. term approach compared vectors generated adding proteins knowledge base ontovec; onto addvec using cosine similarity protein vectors generated adding vectors classes annotated; onto using approach compare sets classes. compare different approaches using ontovec established baseline methods applied resnik’s semantic similarity measure approach generated sparse binary vector representations proteins’ annotations compared using cosine similarity furthermore evaluate contribution using automated reasoner infer axioms also included results using ontovec approach without applying reasoner. evaluated performance method using protein-protein interaction datasets species human baker’s yeast figure shows curves obtained approach human yeast datasets; area curve values shown table found resnik’s semantic similarity measure performs better methods evaluated ontovec representation based generating representations jointly proteins classes performs second best. results demonstrate resnik’s semantic similarity measure determines similarity based information content ontology classes well ontology structure better suited application ontovec representations using cosine similarity. proteins similar certain classes axioms contribute predicting protein-protein interactions others. test whether information ontovec representations used supervised machine learning train similarity measure predictive protein-protein interactions. used three different machine learning methods logistic regression support vector machines neural networks obtain baseline comparison also trained model using binary protein representations. model uses pair protein vectors inputs trained predict whether proteins provided input interact not. supervised model also outputs intermediate confidence values therefore considered output form similarity. curves trained models using ontovec binary representations proteins shown figure rocauc values reported table observed supervised models using ontovec protein representations outperform pre-defined similarity measures experiments; logistic regression performs comparable resnik semantic similarity svms artificial neural networks learn similarity measures predict protein-protein interactions significantly better pre-defined similarity measure. ontovec representations outperform sparse binary representations protein functions indicating combination annotations ontology axioms indeed results improved predictive performance. tested whether supervised models used similarity measures higher similarity values represent confidence existence interaction. used confidence scores associated protein-protein interactions string database determined correlation prediction score trained models confidence score string. table summarizes spearman correlation coefficients methods evaluated. found trained similarity measures correlate strongly confidence measures provided string methods thereby providing evidence ontovec representations encode useful information predictive protein-protein interactions. finally trained models separate protein-protein interactions different interaction types classified string table spearman correlation coefficients string confidence scores prediction scores different prediction methods. highest absolute correlation across methods highlighted bold. database reaction activation binding catalysis. comparison also reported results using sparse binary representations proteins supervised models reported resnik semantic similarity ontovec similarity results table summarizes results. resnik semantic similarity ontovec similarity cannot distinguish different types interaction find supervised models particular multiclass artificial neural network capable using ontovec vector representations distinguish different types interaction. addition ontovec representations perform better sparse binary vectors indicating encoding parts ontology structure improve predictive performance. ontovec representations used compute semantic similarity form part supervised models also provide foundation visualization unsupervised clustering. ability identify sets biological entities similar within dataset used clustering identifying groups related biological entities. visualized gobased vector representations proteins generated ontovec. since ontovec representations high dimensionality applied t-sne dimensionality reduction vectors represented randomly chosen enzyme proteins figure visual representation enzymes shows proteins separated form different functional groups. explore kind information groups represent identified number enzyme colored enzymes different groups depending top-level category. found groups visually separable represent mainly enzymes within single top-level category. quantify whether ontovec similarity representative categorization applied k-means clustering protein representations. evaluated cluster purity respect top-level classification found purity grouping enzymes based second-level classification cluster purity increases developed ontovec novel method learning feature vectors entities ontologies. several recent related efforts unsupervised learning generate dense feature vectors structured semantically represented data. notably large amount work knowledge graph embeddings i.e. feature learning methods applicable nodes heterogeneous graphs defined linked data methods applied predict relations entities knowledge graph perform similarity-based predictions reason analogy clustering however parts ontologies underlying taxonomy partonomy naturally expressed graphs edges represent well-defined axiom patterns challenging represent full semantic content ontologies possible materialize implicit inferred content formally represented knowledge bases automated reasoning long history applying machine learning methods deductive closure formalized knowledge base similar approaches also applied knowledge graphs contain references classes ontologies however approaches still limited representing axioms materialization graph-based format. ontovec best knowledge first approach applies feature learning arbitrary axioms biomedical ontologies includes incorporate ontology’s deductive closure feature learning process. ontovec used learn feature representations graph-structures opposite direction true; particular axioms involving complex class expressions axioms involving disjointness axioms involving object property restrictions naturally included ontovec mostly ignored feature learning methods rely graphs alone. another related area research semantic similarity measures biology. ontovec generates feature representations ontology classes entities annotated several ontology classes demonstrate vector similarity measure semantic similarity. experiments able almost match performance established semantic similarity measure using cosine similarity compare proteins. traditionally challenging evaluate semantic similarity measures performances differ biological problems datasets main advantage ontovec representations ability used trainable similarity measures i.e. problemdataset-specific similarity measures generated supervised available data. training overcomes limitation manually created semantic similarity measures inability judge priori class relation contribute determining similarity. example predicting protein-protein interactions relevant proteins active cellular component ability regulate proteins. trainable similarity measures based ontovec identify importance certain classes regard particular predictive task therefore improve predictive performance significantly. furthermore ontovec determine classes combinations weighted similarity computation. semantic similarity measures ontology background knowledge determine similarity classes; ontology used predetermined constitutes main distinguishing feature among semantic similarity measures since ontovec vectors represent entity’s annotations ontology structure structure used compute similarity also determined data-driven supervised learning; even different certain branches ontology. demonstrate supervised measures outperform binary representations shows combining ontology-based annotations ontology structure single representation clear advantages. ontovec method combines neural symbolic methods biology demonstrates significant improvement state-of-the-art methods. increasing interest integration neural symbolic approaches artificial intelligence biology biomedicine large amount symbolic structures many potential applications neural-symbolic systems current methods knowledge-driven analysis biology limited ontology enrichment analysis applications semantic similarity lesser degree network-based approaches ontovec introduce method semantic analysis toolbox specifically targeted computational biology analysis datasets ontologies used annotation. already demonstrate ontovec representations used improve predictive models protein-protein interactions additional experiments ontologies likely identify areas applications. expect future research neural-symbolic systems extend results enable comprehensive analysis symbolic representations biology biomedicine. downloaded gene ontology format gene ontology consortium website obtained protein annotations uniprot-goa website filtered automatically assigned annotations obtained protein-protein interaction networks yeast humans string database human protein dataset contains proteins interactions yeast dataset contains proteins interactions. extracted enzyme commission number annotations proteins expasy used version process format version contains logical axioms classes. used hermit reasoner infer logical axioms asserted ones. used hermit supports axioms optimized large ontologies optimizations make hermit relatively fast particularly helpful dealing ontologies size infer three types axioms subsumption equivalence disjointness resulting logical axioms implied go’s axioms materialized hermit. treated ontology axioms constitutes sentence. process axioms syntactically used wordvec methods. wordvec neural-network based tools generate vector representations words large corpora. vector representations obtained words similar contexts tend close vector space. wordvec distinct models continuous word uses context predict target word skip-gram model tries maximize classification word based another word sentence. main advantage cbow model smooths distributional information treating entire context observation skip-gram model treats context-target observation works better larger datasets. skip-gram model added advantage producing higher quality representation rare words corpus here chose skip-gram architecture since meets need produce high quality representations biological entities occurring large corpus including infrequent ones. formally given sequence training words skip-gram model aims maximize following average likelihood size training context size training words i-th training word sequence. identified optimal parameters skip-gram model limited gridsearch following parameters size output vectors interval using step size number iterations interval negative sampling interval using step size table shows parameter values used skip-gram work. used resnik’s semantic similarity measure baseline comparison. resnik’s semantic similarity measure widely used biology based notion information content quantifies specificity given class ontology. information content informative common ancestor ontology hierarchy defined common ancestor highest information content value. resnik’s similarity measure measures similarity ontology classes. applied best match average method compute similarity sets classes. biological entities defined ontology concepts annotated with concepts annotated with similarity value concept concept could calculated using resnik similarity semantic similarity measure used supervised learning train similarity measure entities predictive protein-protein interactions. applied method datasets protein–protein interactions yeast another human. filtered string database kept proteins experimental annotations total proteins human dataset proteins yeast dataset. randomly split dataset training testing respectively positive pairs reported string database negative pairs randomly sub-sampled among pairs occurring string cardinality positive negative equal testing training datasets. used logistic regression support vector machines artificial neural networks train classifier protein-protein interactions. trained methods providing pair proteins input predicting whether pair interacts not. output method varies used prediction output similarity measure inputs. logistic regression require selection parameters. used linear kernel sequential minimal optimization. structure feed-forward network four layers first layer contains input units; second third layers hidden layers contain neurons respectively; fourth layer contains output neuron. optimized parameters using limited manual search based best practice guidelines optimized using binary cross entropy loss function. addition binary classification also trained multi-class classifiers predict type interaction types proteins. used multi-class well anns; parameters used identical binary classification case except used architecture output neuron implemented supervised learning methods matlab. receiver operating characteristic curve widely used evaluation method assess performance prediction classification models. plots true-positive rate defined sensitivity) defined number true positives number false positives number true negatives used curves evaluate protein-protein interaction prediction method well baseline methods reported area curve quantitative measure classifier performance. evaluation value number protein pairs occurring string regardless string confidence score predicted interacting. value number protein pairs predicted interacting appear string. number protein pairs predicted non-interacting occur string database. visualizing ontology vectors generated used t-sne method reduce dimensionality vectors dimensions plotted vectors space. t-sne similar principal component analysis uses probability distributions capture non-linear structure data points linear dimensionality reduction methods cannot achieve used perplexity value applying t-sne. k-means algorithm used cluster protein vectors quantitatively measured quality clusters respect families using cluster purity. cluster purity defined total number data points clusters classes case families. since first-level categories number classes case number clusters used k-means also six. research reported publication supported king abdullah university science technology office sponsored research award urf//- urf//- urf//-- urf//--.", "year": "2018"}