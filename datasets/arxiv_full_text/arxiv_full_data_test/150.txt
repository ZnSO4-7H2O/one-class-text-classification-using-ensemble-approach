{"title": "The geometry of sloppiness", "tag": "q-bio", "abstract": " The use of mathematical models in the sciences often involves the estimation of unknown parameter values from data. Sloppiness provides information about the uncertainty of this task. In this paper, we develop a precise mathematical foundation for sloppiness and define rigorously its key concepts, such as `model manifold', in relation to concepts of structural identifiability. We redefine sloppiness conceptually as a comparison between the premetric on parameter space induced by measurement noise and a reference metric. This opens up the possibility of alternative quantification of sloppiness, beyond the standard use of the Fisher Information Matrix, which assumes that parameter space is equipped with the usual Euclidean metric and the measurement error is infinitesimal. Applications include parametric statistical models, explicit time dependent models, and ordinary differential equation models. ", "text": "abstract. mathematical models sciences often involves estimation unknown parameter values data. sloppiness provides information uncertainty task. paper develop precise mathematical foundation sloppiness deﬁne rigorously concepts ‘model manifold’ relation concepts structural identiﬁability. redeﬁne sloppiness conceptually comparison premetric parameter space induced measurement noise reference metric. opens possibility alternative quantiﬁcation sloppiness beyond standard fisher information matrix assumes parameter space equipped usual euclidean metric measurement error inﬁnitesimal. applications include parametric statistical models explicit time dependent models ordinary diﬀerential equation models. mathematical models describing physical biological real-life phenomena contain parameters whose values must estimated data. past decade powerful framework called sloppiness developed relies information geometry study uncertainty procedure although idea using fisher information quantify uncertainty study sloppiness gives rise particular observation uncertainty procedure potential implications beyond parameter estimation. speciﬁcally sloppiness enabled advances ﬁeld systems biology drawing connections sensitivity experimental design identiﬁability robustness reverse engineering sethna transtrum co-authors identiﬁed sloppiness universal property highly parameterised mathematical models however precise interpretation sloppiness remains matter active discussion literature paper’s main contribution provide uniﬁed mathematical framework sloppiness rooted algebra geometry. extend concept beyond time dependent models particular statistical models. rigorously deﬁne concepts building blocks theory sloppiness. approach requires techniques many ﬁelds including algebra geometry statistics. illustrate concept simple concrete example. mathematical foundation provide sloppiness limited current computational tools opens work. assume perfect data point second crucial step needed order deﬁne sloppiness parameter space data space giving perfect data function parameters known model manifold literature rename model prediction map. model prediction thus induces injective function next step assume mathematical model describes phenomenon studying perfectly real data corrupted measurement error ﬁnite sample size. assume noisy data arises random process whose probability distribution induces premetric parameter space kullback-leibler divergence premetric quantiﬁes proximity parameters parameter space discrepancy probability distributions noisy data associated parameters. aforementioned premetric tractable approximation limit decreasing measurement noise using fisher information matrix standard deﬁnition model sloppy condition number large several orders magnitude largest smallest eigenvalues. multiscale sloppiness extends concept regimes noninﬁnitesimal noise. conceptually extend notion sloppiness comparison premetric reference metric parameter space. demonstrate using condition number measure sloppiness parameter done sloppiness literature corresponds comparing approximation inﬁnitesimal neighborhood stansloppiness extend beyond original deﬁnition euclidean parameter space gaussian measurement noise avoids approximating better reﬂects sloppiness models beyond inﬁnitesimal scale. finally describe intimate relationship sloppiness practical identiﬁability whether generic noisy data allows bounded conﬁdence regions performing maximum likelihood estimation. section nature perfect data made clear examples discussed throughout section. think perfect data belonging wider data space encompasses possible real data. data space deﬁned rigorously section measurement noise comes play. example measurable output diﬀers xi’s measured perfect data extracted measurable output illustrated examples behavior variable also vary time time dependent case perfect data often consists values measurable output ﬁnitely many timepoints time series. alternative choice perfect data would stable steady states. also interested call continuous data value possible interval. statistical model measurable output outcome instance statistical experiment natural choice perfect data probability distribution belonging model function functions characterising probability distribution. finite discrete statistical models. straightforward case perfect data described explicitly function parameter finite discrete statistical models fall within group perfect data probability distribution possible outcomes depending choice parameter. model described additional times total four coin tosses. parameter probability picking ﬁrst coin probability obtaining heads tossing ﬁrst coin probability obtaining heads tossing second coin. here measurable output record single instance statistical experiment described perfect data probability distribution possible outcomes giving model coins always equivalence class contains furthermore equivalence class contain equivalence class contain ideal ideal cutting set-theoretic equivalence relation induced extending function indeed zero ideal pairs using symbolic computation software compute prime decomposition radical equivalence classes form dense open subset parameter space dimension equivalence class generically zero. note since zerodimensional equivalence classes size equivalence classes generically size two. continuous data. precisely suppose model real-analytic either explicit time-dependent model given real-analytic system real-analytic function. additionally assume variable parameter time variable belong real-analytic manifolds. suppose real-analytic manifold dimension important consequence result real-analytic timedependent models time series data model equivalence relation global structural property model need specify exact timepoints used. remark note many applications variable belongs real positive orthant indeed real-analytic manifold. condition time variable relaxed include closed partially closed time intervals. cases results like result hold global equivalence relation. therefore ﬁnite number measurements never induce equivalence relation parameter space continuous data. words taking measurements could obtain increasingly example example motivated examples found webpage sethna dedicated sloppiness consider explicit time dependent model variable changes linearly time hence result taking perfect data measurement suﬃciently general time points induces equivalence relation taking perfect data continuous function result time series generic induces equivalence relation parameter space continuous data. model clearly non-identiﬁable. indeed parameters yield continuous data since e−at e−bt e−bt e−at follows equivalence class parameter contain result implies that general time series data induces equivalence relation parameter space continuous data. previous example show achieved taking time series distinct nonzero time points. reduce case suppose general cannot easily exact solution system. nevertheless describing equivalence classes still possible. indeed various approaches building called literature exhaustive summary exhaustive ljung glad ollivier relies using exhaustive summaries. system time series data given rational functions derives input-output equation whose coeﬃcients provide exhaustive summary dense open subset parameter space. additional details exhaustive summaries given ollivier meshkat software available computing input-output equations exhaustive summaries useful determining identiﬁability ﬁnding identiﬁable parameter combinations. structural identiﬁability. formulate deﬁnition structural identiﬁability terms model-data equivalence relation deﬁned beginning section. base rigorous understanding various ﬂavors identiﬁability sullivant’s in-progress book algebraic statistics stefano iii’s book systems biology pair globally identiﬁable every equivalence classe consists pair generically identiﬁable almost equiv pair locally identiﬁable almost equivalence pair non-identiﬁable least equivalence class contains pair generically non-identiﬁable almost example consider model given system time series data describes behavior variable depending -dimensional parameter measurable output system given given induced function particular function bijective. follows function determines model-data equivalence relation. therefore equivalence class sidered given evaluated explicit time dependent model ﬁnitely many timepoints else used alternative method obtain exhaustive summary thus map. model-data equivalence relation made eﬀective diﬀerentiable determine local identiﬁability model looking jacobian model locally identiﬁable jacobian full rank generic values indeed immediate consequence inverse function theorem. method regularly employed algebraic statistics considering speciﬁc models model prediction meant making modeldata equivalence relation eﬀective want perform parameter estimation ﬁnding nearest model prediction given noisy data point remark sloppiness literature uses term model manifold image model prediction although general image manifold such using term manifold beneﬁt bringing focus geometric structure mathematical models. pair globally identiﬁable injective. pair generically identiﬁable generically injective. pair locally identiﬁable almost non-empty ﬁbers pair non-identiﬁable injective. pair generically non-identiﬁable almost non-empty ﬁbers deﬁnition generic model prediction model prediction deﬁned ∼mz-stable dense open subset parameter space. notation borrowed rational maps algebraic category denote generic model prediction exact domain deﬁnition unknown important. three notions identiﬁability rephrased terms generic model prediction maps pair generically identiﬁable injective domain pair locally identiﬁable almost non-empty ﬁbers pair generically non-identiﬁable almost non-empty ﬁbers deﬁnition mathematical model algebraic model prediction deﬁned rationally identiﬁable parameter written rational function φi’s equivalently ﬁelds rational functions equal consider model model prediction deﬁned parameter space p+p. first show globally identiﬁable. real numbers rewrite polynomial function real zeros since given polynomial degree discriminant follows model globally identiﬁable. rational function rationally identiﬁable. case ﬁnite discrete parametric statistical models simplest case since parameterization model prediction map. biased coin model studied examples model prediction map. possible non-isomorphic sets model predictions also following example model prediction maps belonging diﬀerent categories example consider mixture -dimensional gaussians model used describe behavior measurement make individuals belonging populations. model goes back pearson developed methods moments studying crabs naples. follow treatment am´endola faug`ere sturmfels paparameter gives proportion ﬁrst population remaining four coordinate parameters means variances gaussian distributions note model best locally identiﬁable. indeed since cannot tell population individual belongs parameters equivalence class parameter includes orbit aﬃne action symmetric group elements. follows generic equivalence classes size least non-generic special cases include case populations behavior case population actually present cases equivalence class parameter contains certain subsets follows well cumulative distribution function model probability density function moment generating function either characterizes model. probability density function also induce model-data equivalence relation. denote random sample distribution. moment generating function estimated sample etxi model prediction map. cumulative distribution estimated empirical distribution function also model prediction map. probability density function also principle indirectly estimated sample numerically deriving empirical distribution function estimates cumulative distribution function. thus also also considered model prediction map. determines implies polynomial functions also induce model-data equivalence relation. obtain algebraic model prediction suﬃce ﬁnite separating whenever points separated element separates treatment separating sets rings functions). ﬁnitely generated k-algebra ﬁnite separating sets exist large enough ﬁrst moments form separating set. fact careful algebraic manipulations possible show ﬁrst moments already form separating possible estimate moments data know exist model prediction maps capture time series information. explicit models simply matter choosing timepoints. systems would principle need exact solution. first examples explicit time dependent models example discussion example model-data equivalence relation coincides equivalence relation induced evaluating variable timepoints invertible linear transformation taking distinct timepoints choice timepoints give model prediction system time series data exact solution easily construct model prediction explicit time dependent case. absence solution still possible construct model prediction least dense open subset parameter space. example coefﬁcients input-output equations used diﬀerential algebra approach obtain exhaustive summary estimated data hence case construct rational model manifold. example parameter space rational model prediction map. general however best solve system numerically build numerical model prediction done sloppiness literature numerical model prediction provide information model equivalence relation induced exact model prediction map; quality information depend quality numerics. consider model ﬁxed choice model prediction similar analysis made model generic model prediction replacing domain deﬁnition needed. rest paper focus models model prediction maps. consider situation data model predictions corrupted measurement noise known probability distribution. hence according assumption noisy data result random process. deﬁne corruption perfect data; much extends beyond model predictions depend support probability distribution measurement noise. probability density function noisy data arise parameter kullback-leibler divergence used probability information theory quantiﬁes diﬀerence probability distributions deﬁne premetric parameter space kullback-leibler divergence denotes multivariate gaussian distribution mean covariance matrix positive semi-deﬁnite matrix. equivalent specifying measurement size sample. density multivariate gaussian gives symmetric satisﬁes triangle inequality hence pseudometric. particular identity matrix induced half square euclidean distance data space. pseudometric metric exactly often possible equip parameter space metric natural choice euclidean metric inherited ambient instance model might chemical reaction network coordinates parameter correspond positive real-valued rate constants associated particular chemical reactions. case reasonable choice reference metric euclidean distance diﬀerent points positive real quadrant. reference metric parameter space euclidean. example natural metric tree space arises phylogenetics metric noneuclidean inﬁnitesimal sloppiness. ﬁrst provide generally accepted original quantiﬁcation sloppiness found literature explain terms qualitative deﬁnition sloppiness sloppiness literature makes implicit assumption reference metric parameter space standard euclidean metric make assumption section. consider mapping suppose twice continuously diﬀerentiable neighborhood deﬁnition furthermore local minimum implying null jacobian. therefore approximation neighborhood given taylor expansion remark intimately linked structural identiﬁability. indeed result rothenberg shows locally identiﬁable full rank assume additive gaussian noise equation implies rank equal rank jacobian generic dimension connected component equivalence class compute rank computing singular value decomposition employing sound threshold used numerically determine dimension generic equivalence classes. approaches giving probabilistic sometimes guaranteed bounds identiﬁability using symbolic computation speciﬁc parameters developed applied taylor expansion shows that parameters near premetric approximately given pseudometric dfimp. therefore neighborhood giving model predictions maximally sensitive inﬁnitesimal perturbations direction eigenvector maximal eigenvalue referred stiﬀest direction direction eigenvector minimal eigenvalue gives perturbation direction minimally sensitive known sloppiest direction deﬁnition mathematical model choice model prediction speciﬁc assumption measurement noise euclidean metric reference metric inﬁnitesimally sloppy parameter several orders magnitude largest smallest eigenvalues deﬁne inﬁnitesimal sloppiness condition number ratio largest smallest eigenvalues. remark first note deﬁnition meaningful full rank. case condition number corresponds aspect ratio level curves dfimp quantify level curves euclidean spheres. thus using condition number quantiﬁcation sloppiness implies reference metric euclidean metric. possesses attractive statistical properties. suppose locally identiﬁable maximum likelihood estimates exist generically almost parameters minimizing negative log-likelihood unique maximum likelihood estimate. suppose true parameter corruption model prediction invertible cramer-rao inequality implies provides explicit link uncertainty associated parameter estimation geometry negative likelihood. meanwhile sensitivity related uncertainty associated parameter estimation asymptotic normality maximum likelihood estimates implies cramer-rao inequality tends equality tends inﬁnity formally remark suﬃcient condition dfimp good approximation premetric neighborhood large number replicates. practice however questions cost time mean number replicates often small. accordingly sloppiness literature generally assumes example revisit model ﬁrst considered example consider model prediction obtained evaluating timepoints example assume presence additive gaussian error covariance matrix equal identity matrix discussed examples example premetric induced half square euclidean distance data space explicitly determine weighted squares given positive deﬁnite matrix metric. positive deﬁnite matrix giving squares constant throughout parameter space follows sloppiness model also constant throughout parameter space. note phenomenon would happen model model manifold given injective linear particular situation would arise considering problem ﬁtting points polynomial curve corresponding model prediction linear. proposition mathematical model parameter space choice model prediction additive gaussian noise prediction linear dfimp proof. assumption linear implies matrix matrix polynomial dependence parameter known ﬁxed matrix real coeﬃcients measurable output. note depends initial condition consider extension parameter space. assume hurwitz considered. denote output system time given parameter measured system ﬁnite number time-points assuming gaussian noise-corruption distance function would euclidean distance model predictions chosen timepoints. multiscale sloppiness. present quantiﬁcation sloppiness holds non-euclidean reference metric better suited presence noninﬁnitesimal noise. section sometimes make assumption generic neighborhood reference metric strongly equivalent euclidean metric inherited subset metric mentioned beginning section satisﬁes property. section approximates premetric limit decreasing magnitude parameter perturbation realizable limit increasing experimental replicates sample size. practical context however limit increasing replicates valid. indeed examples provided models uncertainty parameter estimation poorly approximated fim. even approximation valid numerical errors sloppiness quantiﬁcation often signiﬁcant ill-conditioning describe second approach called multiscale sloppiness introduced models given systems time series data assumption additive gaussian noise standard euclidean metric reference metric. extend quantiﬁcation sloppiness general setting. remark computation δ-sloppiness would seem require solution optimization program however assuming reference metric parameter space euclidean distance presence additive gaussian noise ﬁnding pmin continuous ranges formulated solution optimal control problem relying solving hamiltonian dh/dp described method computation δ-sloppiness possible large nonlinear systems ode. note formulation optimal control problem fundamentally rely assumption euclidean metric parameter space principle likely applies general classes metric. λmax λmin denote maximal minimal eigenvalues argument. indeed taylor expansion implies approaches approaches dfimp level sets tend level sets dfimp goes zero. multiscale sloppiness precisely denominator closely theorem mathematical model choice model prediction speciﬁc assumption measurement noise choice reference metric assume strongly equivalent euclidean metric. equivalence class parameter size p∈p{d example highlight sloppiness local property depends point parameter space precise choice timepoints. spirit revisit example adding gaussian measurement noise identity covariance taking model prediction figure illustrates change model prediction case diﬀerent choices timepoints changes premetric suggests sloppiness taken consideration designing experiment choices timepoints allow better quality parameter estimation. figure hand illustrates premetric changes parameter space. particular ﬁgures illustrate unlike identiﬁability sloppiness global property model. sloppiness practical identiﬁability. determining practical identiﬁability model corresponds asking whether arrive estimate parameter noisy data whether based assumption measurement noise noisy data constrains parameter value bounded region parameter space. part literature uses manner inﬁnitesimal sloppiness deﬁne practical identiﬁability) consisting eigenvector corresponding largest eigenvalue plotted across grid. compare vector ﬁeld initialised delta-sloppy parameters respect range practical identiﬁability depends method used parameter estimation. focus practical identiﬁability maximum likelihood estimation widely used methods parameter estimation accordingly remaining section consider models choice model prediction speciﬁc assumption probability distribution measurement noise choice reference metric maximum likelihood estimates exist generic data. \u0001-conﬁdence region therefore denotes parameters data least well cutoﬀ quality predicated often known likelihood-based conﬁdence region intimately connected proposition mathematical model model prediction speciﬁc assumption measurement noise. suppose maximum likelihood estimates exist generic data. real-analytic almost maximum likelihood estimates consists exactly equivalence class ∼mφ. proof. generic data point. solving likelihood equation corresponds ﬁnding model prediction closest noisy data measured negative log-likelihood. assume without loss generality unique solution likelihood equations. indeed assumptions data points closest model prediction unique contained zero analytic functions. thus maximum likelihood estimates consist single equivalence class. assume equivalence class generic size. remark degree acronym stand maximum likelihood deﬁned number complex solutions likelihood equations degree upper bound number solutions maximum likelihood equation particular upper bound size equivalence classes maximum likelihood estimates exist. even generically identiﬁable models maximum likelihood estimate unique probability parameter identiﬁable practice meaning noisy data constrain parameter value bounded region parameter space signiﬁcant portion data space. precisely reﬁne deﬁnition raue deﬁnition mathematical model model prediction speciﬁc assumption measurement noise choice reference metric suppose maximum likelihood estimates exist generic data. practically identiﬁable signiﬁcance level generic unique maximum likelihood estimate conﬁdence region bounded respect reference metric satisﬁes model practically identiﬁable signiﬁcance level generic data imposes parameter estimate belongs bounded region parameter space conﬁdence region could large. hence practical identiﬁability sense necessarily completely satisfactory practitioner. quantify practical identiﬁability take account size conﬁdence regions example sloppiness practical identiﬁability complementary concepts. practically identiﬁable models sloppy example estimation component parameter much precise another example below. example models linear model prediction maps euclidean parameter space standard additive gaussian noise always practically identiﬁable according deﬁnition models arbitrarily sloppy. assumption additive gaussian noise implies conﬁdence interval oval whose boundary ellipse level centered maximum likelihood estimate thus conﬁdence intervals bounded model practically identiﬁable. following give example model almost everywhere sloppy inﬁnitesimal scale practically identiﬁable. model however exhibits sloppiness non-inﬁnitesimal scale. boundedness level curves almost every imply boundedness conﬁdence intervals almost everywhere. since conformal mapping preserves angles inﬁnitesimal circles sent inﬁnitesimal circles. assumptions measurement noise standard euclidean metric reference metric model sloppy inﬁnitesimal scale parameters belonging open half plane assumption measurement noise implies maximum likelihood estimate parameter whose image closest data point exist data point outside closed half line ×{}. conﬁdence region preimage euclidean open disc radius centered whenever closure open disc contains origin corresponding conﬁdence region unbounded. equipped usual euclidean metric. equivalence class model-data equivalence relation concentric circles model generically non-identiﬁable. proposition maximum likelihood estimates generic also circle centered origin model practically non-identiﬁable open neighborhood hand measurement noise assumed gaussian equivalence classes bounded conﬁdence region bounded well. indeed conﬁdence region either open disk open ring number interesting future directions theory application sloppiness. explained sloppiness identiﬁability beginning. important next step understanding sloppiness context existing inference uncertainty quantiﬁcation theory. terms applications models reference metric parameter space noneuclidean believe computation multiscale sloppiness adapted. beyond expertise authors would excited learn presented geometry sloppiness extends stochastic diﬀerential equations. highlighted sloppiness local property dependent parameter timepoints experiment. dependence reﬂected model selection studies diﬀerent model selected depending choice timepoints experimental stimulus dose believe quantifying shape δ-sloppiness relation identiﬁability direct impact parameter estimation. gratefully acknowledges late jaroslav stark posing problem. authors thank carlos am´endola murad banaji mariano beguerisse d´ıaz cohen dryden paul kirk terry lyons chris meyers sethna eduardo sontag bernd sturmfels jared tanner fruitful discussions. additionally thank anonymous referees helpful comments. paper arises research done postdoctoral research assistant mathematical institute oxford funded john fell oxford university press research fund supported epsrc systems biology doctoral training center. supported anne mclaren fellowship university nottingham. began discussions workshop model identiﬁcation funded kaust kuk-c--. supported epsrc fellowship ep/k/ royal society university research fellowship.", "year": "2016"}