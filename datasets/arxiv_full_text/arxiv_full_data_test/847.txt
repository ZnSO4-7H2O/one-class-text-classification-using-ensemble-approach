{"title": "Computational Protein Design with Deep Learning Neural Networks", "tag": "q-bio", "abstract": " Computational protein design has a wide variety of applications. Despite its remarkable success, designing a protein for a given structure and function is still a challenging task. On the other hand, the number of solved protein structures is rapidly increasing while the number of unique protein folds has reached a steady number, suggesting more structural information is being accumulated on each fold. Deep learning neural network is a powerful method to learn such big data set and has shown superior performance in many machine learning fields. In this study, we applied the deep learning neural network approach to computational protein design for predicting the probability of 20 natural amino acids on each residue in a protein. A large set of protein structures was collected and a multi-layer neural network was constructed. A number of structural properties were extracted as input features and the best network achieved an accuracy of 38.3%. Using the network output as residue type restraints was able to improve the average sequence identity in designing three natural proteins using Rosetta. Moreover, the predictions from our network show ~3% higher sequence identity than a previous method. Results from this study may benefit further development of computational protein design methods. ", "text": "computational protein design wide variety applications. despite remarkable success designing protein given structure function still challenging task. hand number solved protein structures rapidly increasing number unique protein folds reached steady number suggesting structural information accumulated fold. deep learning neural network powerful method learn data shown superior performance many machine learning fields. study applied deep learning neural network approach computational protein design predicting probability natural amino acids residue protein. large protein structures collected multi-layer neural network constructed. number structural properties extracted input features best network achieved accuracy using network output residue type restraints able improve average sequence identity designing three natural proteins using rosetta. moreover predictions network show higher sequence identity previous method. results study benefit development computational protein design methods. introduction proteins perform vast number functions cells including signal transduction replication catalyzing reactions etc. engineering designing proteins specific structure function deepen understanding protein sequencestructure relationship also wide applications chemistry biology medicine. past three decades remarkable successes achieved protein design designs guided computational methods. examples recent successful computational protein designs include novel folds novel enzymes vaccines antibodies novel protein assemblies- ligand-binding proteins membrane proteins.- comprehensive coverage protein designs provided samish recent ones reviewed elsewhere.- general input computational protein design backbone structure target protein computational sampling optimization sequences likely fold desired structure generated experimental verification. scoring function usually contains physics-based terms waals electrostatic energy well knowledge-based terms sidechain rotamer backbone dihedral preference obtained statistics protein structures. many cases sequences computational design subject filtering considering various factors shape complementarity silico folding free energy landscape human experience familiarity designed protein play important role indicating current design methods fully automatic designs. hand number known protein structures increasing rapidly number unique protein folds saturating. july structures protein data bank yearly increase number unique folds changed past years suggesting data accumulated fold therefore statistical learning utilizing existing structures likely able improve design methods. recently statistical potentials protein design developed abacus potential successfully used designing proteins. statistical potentials physical basis machine learning especially deep-learning neural network recently become popular method analyze data sets extract complex features make accurate predictions. eep-learning neural network machine learning technique becoming increasingly powerful development algorithms computer hardware applied learning massive data sets variety fields image recognition language processing computational biology/chemistry used protein-ligand scoring- protein-protein interaction prediction protein secondary structure prediction- protein contact prediction- compound toxicity liver injury prediction among others. many cases shows better performance machine learning methods. advantage using deep neural network learn high-order features simple input data atom coordinates types. technical details network architecture data representations vary application application fundamental requirement applying deep neural network availability large amount data. aforementioned rich protein structure data available promising apply deep neural network computational protein design. zhou coworkers used neural network approach tackle problem developed spin method predict sequence profile protein given backbone structure. input features spin include dihedrals target residue sequence profile -residue fragment derived similar structures rotamer-based energy profile target residue using dfire potential. spin trained non-redundant proteins reaches sequence identity test containing proteins. sequence identity lower boundary homologous protein sufficient improve protein design significantly. study applied deep-learning neural networks computational protein design using structural features network architecture larger protein structure data improving accuracy protein design. instead taking whole input structure account sliding widow method used protein secondary structure prediction predict residue identity position one. consider target residue neighboring residues threedimensional spaces assumption identity target residue compatible surrounding residues. collected large high-resolution protein structures extracted coordinates residue environment. performance neural network different input setups compared application network outputs protein design investigated. input computational protein design problem backbone structure protein instead predicting residue types positions input protein simultaneously consider target residue neighbor residues simplest case consider target position closest neighboring residue determined cα-cα distance feed input features neural network consists input layer several hidden layers softmax layer output. output dimension softmax layer output numbers interpreted probabilities residue types target residue. network named residue probability network hereinafter simple network considers neighbor residue obviously cannot make satisfactory predictions. study take account target residue neighbor residues repeatedly using residue probability network shares parameters. setup similar application convolution layer image recognition convolution network applied different regions input image. drawback setup output target-neighbor residue pair equally weighted. apparently neighbor residues larger impacts identity target residue others. overcome this construct another network takes input residue probability network outputs single number weight output residue probability network multiplied weight concatenated. several fully-connected layers constructed weighted residue probabilities -dimentional softmax layer used final output interpreted probabilities residue types target residue. input residue probability weight network consists features target residue neighbor residues features include basic geometric structural properties residues cα-cα distance values backbone dihedrals relative location neighbor residue target residue determined unit vector atom central residue atom neighbor residue three-type secondary structures number backbonebackbone hydrogen-bonds solvent accessible surface area backbone atoms train neural network collected high-resolution protein structures using filtering conditions including structure determination method resolution chain length sequence identity briefly three data sets prepared based three sequence identity cutoffs remove homologous proteins. data sets residue closest neighbor residues based cα-cα distance extracted cluster. clusters randomly split five sets five-fold crossvalidation. hereinafter refer dataset sequence identity cutoff neighbor residues. similar naming rules apply datasets well. number layers nodes fully-connected layer determined training test smallest data sin. neural network training performed epochs ensure convergence. figure architecture neural networks. residue probability network weight network full network. residue probability weight networks used subnetworks share network parameters different inputs. input consists features target residue neighbor residues. table shows overall accuracy standard deviations different datasets five-fold cross-validation. expected datasets higher protein identity cutoffs show better accuracy data samples higher similarities samples. however considering number data samples almost doubled dataset improvement accuracy significant. furthermore protein identity cutoff including neighbor residues show best accuracy. including fewer neighboring residues likely underrepresents environment target residue whereas including many neighbor residues generate noises inputs thus require data samples training. alternative extracting neighbor residues certain distance cutoff. however strategy requires input size neutral network flexible investigated future studies. *numbers parentheses standard deviations. next exam amino-acid specific accuracy using results dataset best overall accuracy. define recall precision amino acid. recall percent native residues correctly predicted precision percent predictions correct. higher recall precision residues achieves recall precision exceptional conformational rigidity highly flexible terms backbone dihedrals. neural network easily learn distinct structural properties. amino acids lower recall/precision generally lower abundance training example although already applied bias low-abundance amino acids training. characterize amino-acid specific accuracy calculated probability native amino acid predicted amino acids plot native predicted heat amino acids xy-axis ordered properties similarities other. diagonal grids show higher probabilities expected. interestingly several groups along diagonal including indicating neural network frequently predicts amino acid another within group. considering similarities amino acids within group replacing amino acid another group probably disrupt protein structure suggests neural network mispredict native amino acid still provide reasonable answer. figure recall precision different amino acids network trained dataset. recall percent native residues correctly predicted precision percent predictions correct. output neural network probabilities amino acids target position addition accuracy mentioned above also possible calculate top-k accuracy native amino acid within top-k predictions prediction considered correct. top- accuracy network trained dataset reaches respectively suggesting native amino acids enriched first half predictions simple application information restrain available amino acid types target position protein design. illustrative example applied top- predictions residue-type restraints designing three proteins including all-α protein all-β protein mixed protein none proteins included training set. crystal structures proteins used inputs neural network trained dataset. top- amino acids position used restraints fixed-backbone design program fixbb rosetta. control listed accuracy neural network proteins also performed fixed-backbone design without residue-type restraints fixbb uses stochastic design algorithm generated sequences protein calculated average sequence identity native proteins three proteins using information neural network predictions improves average sequence identity best value system dependent cases results worse restraints-free designs *sequence identities presented average standard deviation designs. numbers parentheses maximal possible identities given residue-type restraints. finally compare performance network spin developed zhou coworkers. spin trained non-redundant proteins reaches sequence identity test containing proteins. training test collected using sequence identity cutoff spin also evaluated proteins test proteins comparison rosetta. structure proteins known compare network spin proteins. fair comparison re-trained network dataset without proteins. table lists average sequence identity methods predictions considered. network shows higher identity spin. number data samples almost tripled study improvement accuracy significant indicating certain limitation learning sequence information protein structures. nonetheless networks trained larger data study could still beneficial computational protein design. real applications amino acid probability learned larger data could useful long biased. example tested methods novo designed protein prediction spin shows identity predictions network identities addition comparing sequence identities also compared predictions position-specific scoring matrix psi-blast. pssms test proteins obtained running psi-blast non-redundant protein sequences database available ftp//ftp.ncbi.nlm.nih.gov/blast/db/ converted pseudo probability matrixes amino acids residue. root mean square error matrixes predicted network spin calculated. network spin show similar rmse values noted spin trained pssms psiblast predicting sequence profiles whereas network trained protein sequences only. study developed deep-learning neural networks computational protein design. networks achieve accuracy dataset sequence identity cutoff neighboring residues included. accuracy limited neural network approach also nature protein structures. known proteins sequence identity fold similar structures. repair enzyme -methyladenine glycosylase probability random mutation inactivate protein found indicating large proportion mutations tolerated protein. moreover residues active sites subject functional restraints necessary stable ones. neural network approach similar structural comparison method extracts integrates similar local structures known structures. therefore accuracy limited average number tolerable amino acids residue training set. fortunately native amino acid concentrated predictions integration network output molecular-mechanics scoring functions possible identify correct amino acid predictions improve accuracy. particularly network preforms well ability learn distinct structural features less satisfying hydrophobic residues likely important correct folding protein. including solvation energy molecular mechanics scoring functions probably promising future development. approach environment target residue simply considered using closest residues based cα-cα distances. method exclude residues important interactions target residue. quantitatively characterize this calculated distance rank neighbor residues contacts target residue dataset found contacting residues contacting residues means contacting residues included environment respectively. moreover terminal residues highly exposed neighbors contain residues contacts target residue generate noises inputs. using distance cutoff instead residue number cutoff solve problem. however distance cutoff method requires input size highly flexible several residues tens residues carefully considered network construction. nowing possible amino acids good confidence designing positions reduce search space significantly increase chance make successful design. test rosetta design three proteins shows possible improve sequence identity using output neural network residue-type restraints. however optimal number amino acids used restraints system dependent. importantly neural network prediction residue independent other. real designs important simultaneously consider identities neighbor residues using molecular-mechanics-based statistical scoring functions like ones rosetta. regard predicted probability amino acid explicitly taken account. prediction trained neural network protein structure takes several seconds expect approach pave development computational protein design methods. datasets input features training collected using following criteria structure determined x-ray crystallography resolution better chain length longer structure dna/rna molecules. investigate effects sequence homology prediction accuracy structures satisfy conditions retrieved sequence identities. resulting entries cross-referenced database remove membrane proteins. structures d-amino acids also discarded. resulting structure dataset consists structures remove bias non-biological interface crystal asymmetric unit biological assembly provided used. multiple biological assemblies exist structure first assembly used. structures non-protein residues water ligand removed protein residue closest neighboring residues extracted structural cluster. clusters atoms occupancy missing backbone atoms discarded. protein oligomeric state also considered cluster extraction structure contains several identical subunits subunits used. cluster translated orientated atoms target residue located origin axis plane respectively. input features neural networks central residues values backbone dihedrals total solvent accessible surface area backbone atoms three-type secondary structure; neighbor residues values backbone dihedrals total sasa backbone atoms cα-cα distance central residue unit vector atom central residue atom neighbor residue cα-n unit vector neighbor residue cα-c unit vector neighbor residue three-type secondary structure number backbone-backbone hydrogen bonds central residue neighbor residue. cα-cα distance cα-cα cα-n cα-c unit vectors used define exact position orientation neighbor residue respect central residue. values dihedrals used dihedrals range continuous sasa value calculated using naccess program whole protein structure sidechain atom removed protein design identity residue thus sidechain atoms unknown. secondary structure assigned stride. features calculated in-house program. neural network constructed using keras library rectified linear unit activation function layers. training performed using categorical cross entropy loss function stochastic gradient descent method optimization learning rate nesterov momentum batch size account different abundance residue type training training samples weighted nmax/ni nmax maximal number samples residue types number samples residue type bias would force neural network learn residue types underrepresented training set. output neural-network probability amino acids central residue cluster. minimization. designs performed protein without residue-type restraints incorporated using -resfile option. acknowledgements work supported national natural science foundation china y.q. j.z. ministry science technology china global seed grant shanghai putuo district j.z.. thank supercomputer center east china normal university providing computer time. sandhya mudgal kumar sowdhamini srinivasan protein sequence design applications. curr opin struct biol kuhlman design novel globular protein fold atomic-level accuracy. science jiang novo computational design retro-aldol enzymes. science rothlisberger kemp elimination catalysts computational enzyme design. nature correia computational design epitope-scaffolds allows induction antibodies specific poorly immunogenic vaccine epitope. structure correia proof principle epitope-focused vaccine design. nature leaver-fay computationally designed bispecific antibodies using negative state repertoires. structure lewis generation bispecific antibodies structure-based design orthogonal interface. biotechnol bale accurate design megadalton-scale two-component icosahedral protein complexes. science gonen dimaio gonen baker design ordered two-dimensional arrays mediated noncovalent protein-protein interfaces. science hsia design hyperstable -subunit protein dodecahedron. nature king accurate design co-assembling multi-component protein nanomaterials. nature king computational design self-assembling protein nanomaterials atomic level accuracy. science tinberg computational design ligand-binding proteins high affinity selectivity. nature zhou protein engineered bind uranyl selectively femtomolar affinity. chem zhang computational design experimental characterization peptides intended ph-dependent membrane insertion pore formation. chem biol korendovych novo design molecular assembly transmembrane diporphyrin-binding protein complex. chem novo design transmembrane zn-transporting fourhelix bundle. science samish computational protein design huang boyken baker coming novo protein design. nature yang computational design ligand-binding proteins. curr opin struct biol norn andre computational design protein self-assembly. curr opin struct biol chen computational protein design given backbone recent progresses general method-related aspects. curr opin struct biol shapovalov dunbrack smoothed backbone-dependent rotamer library proteins derived adaptive kernel density estimates regressions. structure yang zhan zhou energy functions novo protein design current challenges future prospects. annu biophys boas harbury potential energy functions protein design. curr opin struct biol doyle rational design alpha-helical tandem repeat proteins closed architectures. nature bhardwaj accurate novo design hyperstable constrained peptides. nature berman protein data bank. nucleic acids broom trainor mackenzie meiering using natural sequences modularity design common novel protein topologies. curr opin struct biol khersonsky fleishman reinvent wheel? building proteins based ready-made parts. protein topham barbe andre atomistic statistically effective energy function computational protein design. chem theory comput xiong protein design comprehensive statistical energy function boosted experimental selection foldability. commun xiong chen computational protein design given backbone structure abacus statistical energy function. methods biol zhou proteins well-defined structures designed without backbone readjustment statistical model. struct biol lecun bengio hinton deep learning. nature simonyan zisserman deep convolutional networks largescale image recognition. arxiv e-prints collobert weston unified architecture natural language processing deep neural networks multitask learning. proceedings international conference machine learning silver mastering game deep neural networks tree search. nature ragoza hochuli idrobo sunseri koes protein-ligand scoring convolutional neural networks. chem model zhou sequence-based prediction protein protein interaction using deep-learning algorithm. bioinformatics heffernan improving prediction secondary structure local backbone angles solvent accessible surface area proteins iterative deep learning. protein secondary structure prediction using cascaded convolutional recurrent neural networks. arxiv e-prints deep convolutional neural fields. busia collins jaitly protein secondary structure prediction using deep multi-scale convolutional neural networks next-step conditioning. arxiv e-prints faraggi zhang yang kurgan zhou spine improving protein secondary structure prediction multistep learning coupled prediction solvent accessible surface area backbone torsion angles. comput chem protein contact ultra-deep learning model. plos comput biol lena nagata baldi deep architectures protein contact prediction. bioinformatics eickholt cheng predicting protein residue-residue contacts using deep networks boosting. bioinformatics mayr klambauer unterthiner hochreiter deeptox toxicity prediction using deep learning. frontiers environmental science unterthiner mayr klambauer hochreiter toxicity prediction using deep learning. arxiv e-prints hodas vishnu deep learning computational chemistry. comput chem yang faraggi zhan zhou direct prediction profiles sequences compatible protein structure neural networks fragmentbased local energy-based nonlocal profiles. proteins zhou zhou distance-scaled finite ideal-gas reference state improves structure-derived potentials mean force structure selection stability prediction. protein rost twilight zone protein sequence alignments. protein crystal structure functional studies reveal factor vibrio vulnificus novel member saposin-fold family. biol pflugrath wiegand huber vertesy crystal structure determination refinement molecular model alpha-amylase inhibitor hoe-a. biol leaver-fay rosetta object-oriented software suite simulation design macromolecules. methods enzymol altschul gapped blast psi-blast generation protein database search programs. nucleic acids choe loeb protein tolerance random amino acid change. proc natl acad tokuriki stricher serrano tawfik protein stability functions trade off. plos comput biol lomize lomize pogozheva mosberg orientations proteins membranes database. bioinformatics 'naccess' computer program frishman argos knowledge-based protein secondary structure assignment. proteins", "year": "2018"}