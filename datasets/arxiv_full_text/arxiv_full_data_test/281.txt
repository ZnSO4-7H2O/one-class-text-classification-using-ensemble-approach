{"title": "Interactive Natural Language Acquisition in a Multi-modal Recurrent  Neural Architecture", "tag": "q-bio", "abstract": " For the complex human brain that enables us to communicate in natural language, we gathered good understandings of principles underlying language acquisition and processing, knowledge about socio-cultural conditions, and insights about activity patterns in the brain. However, we were not yet able to understand the behavioural and mechanistic characteristics for natural language and how mechanisms in the brain allow to acquire and process language. In bridging the insights from behavioural psychology and neuroscience, the goal of this paper is to contribute a computational understanding of appropriate characteristics that favour language acquisition. Accordingly, we provide concepts and refinements in cognitive modelling regarding principles and mechanisms in the brain and propose a neurocognitively plausible model for embodied language acquisition from real world interaction of a humanoid robot with its environment. In particular, the architecture consists of a continuous time recurrent neural network, where parts have different leakage characteristics and thus operate on multiple timescales for every modality and the association of the higher level nodes of all modalities into cell assemblies. The model is capable of learning language production grounded in both, temporal dynamic somatosensation and vision, and features hierarchical concept abstraction, concept decomposition, multi-modal integration, and self-organisation of latent representations. ", "text": "abstract complex human brain enables communicate natural language gathered good understandings principles underlying language acquisition processing knowledge sociocultural conditions insights activity patterns brain. however able understand behavioural mechanistic characteristics natural language mechanisms brain allow acquire process language. bridging insights behavioural psychology neuroscience goal paper contribute computational understanding appropriate characteristics favour language acquisition. accordingly provide concepts refinements cognitive modelling regarding principles mechanisms brain propose neurocognitively plausible model embodied language acquisition real-world interaction humanoid robot environment. particular architecture consists continuous time recurrent neural network parts different leakage characteristics thus operate multiple timescales every modality association higher level nodes modalities cell assemblies. model capable learning language production grounded both temporal dynamic somatosensation vision features hierarchical concept abstraction concept decomposition multi-modal integration self-organisation latent representations. human brain seen complex sophisticated dynamic systems. humans build precise instruments write essays higher purpose life reached state specialisation knowledge externalising information interaction other. utter short sounds indicate intention also describe complex procedural activity share abstract declarative knowledge even completely think language extremely easy well important share information matter space time complex author. published informa limited trading taylor francis group. open access article distributed terms creative commons attribution-noncommercial-noderivatives license permits non-commercial re-use distribution reproduction medium provided original work properly cited altered transformed built upon way. however humans’ natural language processing perhaps least well understood cognitive capability. main reason complexity human language inability observe study capability less complex related species. another reason neural wiring human brain perhaps component necessary language develop. seems socio-cultural principles well important inclusion factors allow understand language processing. nevertheless brain enables humans acquire perception capabilities motor skills language social cognition. capability language acquisition thus result concurrence general mechanisms information processing brain’s architecture. particular recent studies neuroscience found brain indeed includes hemispheres modalities language processing embodied development representations might language acquisition furthermore hierarchical dependencies connectivity identified including different specific delays information processing. linguistic accounts behavioural studies number important principles compositional holistic properties entities body-rationality social interaction found might ease actually enable acquisition language competence light mechanistic conditions brain well enabling factors learn language higher cognitive functions objective understand characteristics brain-inspired appropriate neural architecture facilitates language acquisition. paper propose novel embodied multi-modal model language acquisition study important characteristics. significant innovation model grounds spoken language temporal dynamic processing somatosensory visual perception explores mechanism abstracts latent representations dynamics self-organising fashion. contribution knowledge adding understanding whether connectivity plasticity attributes human brain allow emergence development languages. results analytical well empirical studies computer simulations interactive humanoid robot reveal importance self-organisation well specific timing processing speech multi-modal sensory information. past researchers suggested valuable models explain grounding language embodied perception action based neuroscientific data hypotheses includes early work symbol grounding studies language evolution symbol emergence research sentence comprehension role filler assignment however tremendous complexity models rare consider dynamics full scale avoid assumptions predefined word representations static categorically predefined observations studies approach complexity adopt important insights. integrating dynamic vision models grounding dynamic vision supposed represent language alteration example perceived objects. objects example altered terms changing morphology motion self-induced manipulation. complexity models often based certain decoupling simplification visual stream achieve feasible level coherence visually perceived features. example developed model coupled lexical acquisition object categorisation. here learning processes visual categorisation lexical acquisition modelled close loop. emergence important associations also development links words categories thus linking similar fillers role. visual features reflect little morphology time since perception visual stream stemmed unchanging preprocessed shapes front plain background. changing morphology monner reggia modelled grounding language visual object properties. model designed micro-language stems small context-sensitive grammar includes input streams scene auditory information input-output stream related prompts responses. input input-output layer several layers long short-term memory blocks employed find statistical regularities data. includes overall meaning particular scene terms finding latent symbol system inherent used grammar dictionary. object properties principle present given prompts desired output responses. emerging symbols internal memory layers determined shaped prompt response data perhaps less latent. thus remains unclear relate emergence predefined latent symbols problem grounding natural language dynamic sensory information eventually understand noisy perceived information contributes. overall studies show dynamic vision integrated embodied sensation dynamics perception reasonably abstracted. novel model however crucial control complexity perception attempt explaining emerging internal representation. dynamic multi-modal integration integrating multiple modalities language acquisition particularly difficult linked processes brain extraordinary complex fact large parts understood. reason best authors’ knowledge model available describes language processing integrated multi-modal perception full spatial temporal resolution cortex without making difficult assumptions explicit limitations. however frameworks studied included temporally dynamic perception forms basis grounding. marocco cangelosi fischer belpaeme defined controller simulated cognitive universal body robot based recurrent neural networks icub’s neural architecture trained receive linguistic input robot started push object observe reaction sensorimotor way. experiments showed robot able distinguish objects correct linguistic tags could reproduce linguistic observing dynamics without receiving linguistic input correct object description. thus authors claimed meaning labels associated static representation object dynamical properties. farkaš malík rebrová modelled grounding words both object-directed actions visual object sensations. model motor sequences learned continuous actor-critic learning integrated joint positions linguistic input visually perceived position object specific strength approach model embedded simulated icub adapt well different motor constellations generalise permutations actions objects. however action shape colour descriptions already present input motor vision networks. thus information inherently included filtered representations model part linguistic description. addition linguistic network designed fixed-point classifier outputs active neurons input word object action. accordingly output assuming word representation omits sequential order. framework multi-modal integration noda arie suga ogata suggested integrating visual sensorimotor features deep auto-encoder. employed time delay neural network capture features varying timespan time-shifts hence abstract higher level features degree. study modalities features stem perception interactions toys form reasonable complex representations sequence frames. although language grounding pursued shared multi-modal representation central layer network formed abstraction perceived scenes certain internal structuring provided certain noise-robustness. nevertheless obtain insight forming representation language perhaps facilitated shared multi-modal representations combinations mechanisms brain filter features multiple levels. paper structured follows related work mind introduction section introduce important principles mechanisms found underlying language acquisition. section develop novel computational model integrating principles mechanisms general recurrent architecture aims neurocognitive plausibility respect representation temporal dynamic processing. include complete formalisation ease re-implementation introduce novel mechanism unsupervised learning based gradient descent. then section follow evaluation analysis. specify scenario language learning robot well complete description utilised neurocognition-inspired representations verbal utterances embodied multi-modal perception. addition report experiments generalisation selforganisation. finally section discuss findings conclusions future prospects. research language acquisition approached different disciplines complementary methods research questions. research linguistics investigates different aspects language general complexity formal languages particular. ongoing debates nature versus nurture symbol grounding valuable knowledge principles learning mechanisms information fusion brain facilitate language competence recent research suggests well-known principles statistical frequency compositionality language acquisition particularly important forming representation means structuring multi-sensory data. researchers different fields related behavioural psychology study top-down both development language competence growing humans reciprocal effects interaction environment identified important socio-cultural principles. computational neuroscience many researchers look bottom-up language processing refined activity across brain language comprehension production. imaging methods allow much detailed studies both temporal spatial level major paradigm shift understanding language acquisition underlying mechanisms. language acquisition first year birth human infant crucial. contrast mammals infant born mobile matured develops capabilities competencies postnatal development linguistic competence occurs parallel highly interwoven cognitive development capabilities multi-modal perception attention motion control reasoning brain matures wires various regions process individual learning infant undergoes several phases linguistic comprehension production competence ranging simple phonetic discrimination complex narrative skills sensorimotor-level environmental interactions accompanied goal-directed actions addition embodiment suggested necessary precondition building higher thoughts child caregiver provides digestible amounts spoken language particular mothers provide age-dependent simplification grammar focus common words first based imaging methods several hypotheses introduced stating many cortical areas involved language processing. particular claimed several pathways superior temporal gyrus inferior frontal gyrus involved language production comprehension pathways suggested include dorsal streams sensorimotor integration ventral streams processing syntax semantics. important mechanism found activation conceptual networks distributed sensory areas processing words related body parts object shapes seemingly important mechanisms found organised might distributed different cortical areas even across hemispheres activation large highly distributed form higher level concepts. exist represent specific semantics like morphemes lemmas language processing mediators different levels aforementioned conceptual networks seen word level. brain. example frontal lobe caudal–rostral axis processing information occurs much greater timescales pre-motor area mid-dorsolateral pre-frontal cortex suggesting timings might relevant processing plan motor movement sequentialisation execution motor primitives similar temporal hierarchies found lower auditory processing higher vision based aforementioned principles mechanistic characteristics build model neurocognitively plausible constraint general nonlinear neural architecture. starting point adopt continuous time recurrent neural network activity neuron derived time accumulation previous activity function presynaptic input plastic connections bias derivation governed time constant describes fast firing rate approaches steady-state value. although deduce ctrnn leaky integrate-and-fire model thus simplification hodgkin–huxley model network architecture suggested independently hopfield tank nonlinear graded-response neural network doya yoshizawa adaptive neural oscillator. ctrnn thus general computational network model allows define arbitrary input output recurrence characteristics within layer. recurrent connections network arbitrarily deep nonlinear based continuous information processed time. explore mechanism timescales constraint ctrnn tani replicated learning mammal body motions experimental setup along developmental robotic approach multiple timescale recurrent neural networks specified three layers layer context-fast layer contextslow layer) variable timescales trained gradient descent method sequences. analysis revealed trained network could reproduce sequences best patterns different layers self-organised towards decomposition body movements. researchers able interpret neural activity layer always coding short primitive layer patterns unique sequence consist slow changing values function triggering points primitives. mtrnn context bias original experiments researchers able train mtrnn reasonably diverse long sequences initialising network’s neural activity first time step specific values experimenter’s choice initial states kept training specific sequence represented association constant value dynamic pattern. later experiments nishide adapted integrated idea parametric bias units mtrnn therein bias units part layer parametrise motion sequence certain property another initial neural activity specified. however bias context-controlling units initialisation training necessary values units self-organise training. similar recurrent figure overall mtrnn architecture exemplary three horizontally parallel layers input-output context-fast context-slow increasing timescale layer includes context-controlling units. layer processes dynamic patterns time units neural network parametric bias initial states seen general context sequence. modulating internal states differing sequences generated. overall conducted experiments motor primitives slow context codes general concept certain body motion. combining characteristics various experiments ctrnns multiple timescales context bias properties arrive general description mtrnn illustrated figure certain contexts proneurons) network processing certain sequences time. constraints connectivity relative timescale setting inspired brain challenged developmental robotics studies confirm hierarchical compositionality e.g. body motion. models process dynamic sequences terms discretised time steps regard task continuous means absolute variability timescales. information processing mtrnn defining time constant neuronunit-dependent variable solving equation respect time step also describe special ctrnn detail mtrnn information processed continuously unit-specific firing rate sequence discrete time steps. sequence represented flow activations neurons layer input activation neuron iall time step calculated learning mtrnn learning mtrnn trained sequences self-organises weights also internal state values units. overall method variant backpropagation time sped appropriate measures based task characteristics. forward pass appropriate error function accumulating error activation values desired activation values neurons every time step based utilised activation function. second step partial derivatives calculated activation desired activation derived backward pass. case e.g. decisive normalisation function sigmoidal function fsig layers specify error internal states neurons follows partial derivatives respectively accumulated sums weight bias changes whole sequence denote learning rates weight bias changes. facilitate application different methods speeding training individual learning rates weights biases allow individual modifications weight bias updates respectively. adaptive learning rates speeding training employ adaptation resilient propagation algorithm makes different individual learning rates adapt learning rates update initial internal states well particular learning rates adapted proportionally average learning rates weights connected unit neurons adjacent layer mtrnn context bias found timescale characteristic crucial hierarchical compositionality temporal dynamic output sequences. increasingly slower information processing context generation sequence abstract concept. order design architecture abstract context temporal dynamic input sequences reverse notion context bias thus reverse processing context layer. structure novel mtrnn context abstraction visualised figure certain sequential input provided dynamic pattern fastest neurons network accumulating figure mtrnn context abstraction architecture providing exemplary three horizontally parallel layers context-slow context-fast input-output increasing timescale layer includes context-controlling units. layer processes dynamic patterns characteristics yield slow adaptation so-called units information units accumulate abstract pattern input sequence accumulation information characterised logarithmic skew near past reach-out long past depending timescale values supervised learning self-organisation mtrnn context abstraction trained supervised fashion capture certain concept temporal dynamic pattern. directly analogue fixed-point classification elmanrecurrent neural networks ctrnns determine error desired temporal static concept pattern activity error backwards time whole temporal dynamic pattern concept abstracted. however architecture supposed model processing certain cognitive function brain also interested removing necessity providing desired target concept priori. instead representation concept self-organise based regularities latent stimuli. units. thus internal states initial units self-organised space towards values suited best generating sequences data foster similar self-organisation units final time step mtrnn context abstraction semi-supervised mechanism developed allows modify desired concept pattern based derived error. particularly small self-organisation forcing constant allows final internal states units adapt upon data although actually serve target shaping weights network. accordingly final internal states units define abstraction input data also updated follows thus similarly units final internal states units self-organise training conjunction weights towards highest entropy. observe self-organisation forcing constant learning rate dependent since changing would also shift self-organisation arbitrary fixed however useful mechanism self-organise towards concepts appropriate respect structure data. preliminarily evaluating abstracted context test preliminary experiment abstracted concepts form different sequences using unsupervised learning mechanism architecture trained abstracting contrary cosine waves context patterns. particular sequence cosines waves presented input neurons discretised time step. differently phase-shifting cosines four different sequences prepared. aspect task learn abstract different phase-shifts otherwise identical sequences. particular ambiguous nature saddle points network cannot simply learn predict next time step must capture whole sequence. processing sequence mtrnn context abstraction supposed result specific pattern final units’ activity abstracted concept. randomly initialised patterns adapt training means varied selforganisation forcing parameter measure result self-organisation distance measures davg drel used describes number sequences ckti denotes final units sequence davg uses standard lebesgue euclidean distance estimate average distance patterns drel describe relative difference distances. example case distances patterns exactly same measure would yield best possible result drel comfigure eﬀect self-organisation forcing mechanism development distinct concept patterns diﬀerent sequences contrary cosine waves training eﬀort mean davg drel standard error bars varied runs; representative developed patterns diﬀerent sequences selected parameter settings small good large self-organisation forcing respectively. good value leads marginal self-organisation towards ideal distribution concepts space training weights. furthermore larger driving stronger adaptation patterns weights thus leading convergence similar patterns sequences. tation context allows convergence small error values. however larger numbers sequences potentially share primitives random distribution respective concept abstraction values unlikely provide good distribution thus self-organisation forcing mechanism drive learning. previous studies mtrnn context bias tested modelling language processing mechanism spatial temporal hierarchical compositionality. particular hinoshita utilised architecture model learn language continuous input sentences composed words graphemes stem small grammar. model implicit information provided word segmentation roles categories words. instead input modelled streams spikelike activities graphemic level. training architecture self-organises decomposition sentences hierarchically based explicit structure inputs specific characteristics layers. authors found characteristics information processing different timescales indeed leads hierarchical decomposition sentences certain character orders form words certain word orders form sentences. although model reproducing learned symbolic sentences quite well experiments generalisation possible test generation sentences initiated internal state units trained individually every sentence model. heinrich magg wermter extended model process language embodied visual input trigger model produce meaningful verbal utterance appropriately represents input. architecture called embmtrnn model consists similar mtrnn layers language network verbal utterance processed sequence phoneme level based initial activity overall concept level. overall concept associated feature input merged shape colour information visually perceived object. thereby model incorporates following hypotheses speech processed multiple-time resolution semantic circuits involved processing language. experiments revealed model generalise situations e.g. describe object novel combination shape colour correct corresponding utterance appropriate hierarchical component structure. model multi-modal complexity real-world scenarios tackled exhaustively. temporal dynamic nature visual observations sensations another modality included especially processed multiple-time resolution. previous models language processing provided insight architectural characteristics language production grounded perception. recent neuroscientific studies learned importance conceptual networks activated processing speech involved processes operate producing speech well central findings include sensorimotor system involved conceptual networks general action language comprehension particular. action comprehension phenomenon networks supposedly seem involve multiple senses. example actions perceived visual stimuli singer sheinberg found tight connection perceiving form motion action. sequence body poses perceived action frames integrated within additionally found visual sequence represented best action cues present case representation mostly based form information. since body-rational motion information hierarchically processed proprioception well integration visual form somatosensory motion seems important. multi-modal contributions visual somatosensory suggested strictly hierarchically organised structure integration conceptual network seems derive spatial conditions areas cortex identified higher abstraction sensory stimuli. areas example also connected densely compared sensory regions also show high interconnectivity areas higher abstraction. studies deduced particularly dense connectivity hand form general concepts hand invoke activation first model requirements recent findings hypotheses previous related work adopt computational neural model natural language production embedded architecture integrates multiple modalities contributing perceptual information. perceptual input also processed horizontally sensation encoding primitive identification conceptual level. highly interconnected neurons higher conceptual areas form thus share representations made experiences. importantly representations form based structure perceptual input without specific target. line developmental robotics approach multi-modal perception based real-world data. both perceptual sensation well auditory production represented neurocognitively plausible. employing approach embodied situated agent created acquires language interaction environment well verbally describing teacher. case interaction experienced terms temporal dynamic manipulation different shaped coloured objects. requirements model implements principles mechanistic characteristics described section properties model supposedly generalisation despite dynamic embodied perception disambiguation inherently focused limited uni-modal sensation multi-modal integration. goals model refine connectivity characteristics foster language acquisition investigate merged conceptual representation. multi-modal mtrnns model order meet requirements multi-modal model following hypotheses added previous embmtrnn model novel model named multimtrnns somatosensation visual sensation processed hierarchically means multiple-time resolution higher levels abstractions encoded distributed sensory motor areas. specific refinement previous model neural circuits processing perceptions modelled mtrnn context abstraction. first called mtrnns processes somatosensation specifically proprioceptive perception second named mtrnnv processes visual perception. units mtrnns linked fully connected associator neurons constitute representing concepts information. based abstract concepts mtrnn context bias called mtrnna processes verbal utterance sequence phoneme level. recurrent neural structures specifications ctrnn maintain neurocognitive plausibility. notation layers novel perception components multimtrnns model stand input fusion context modalities somatosensory vision respectively. overview architecture presented figure arising hypothesis computational model learning composition general feature emerges invariant length respective sensory input. second hypothesis features ambiguous uni-modal sensations ambiguous number overall different observations association provide distinct representation production verbal utterance. information processing training production every scene verbal utterances presented together sequences proprioceptive visual stimuli action sequence. training system somatosensory mtrnns visual mtrnnv self-organise weights also internal states units parallel processing incoming perception. production utterances auditory mtrnna self-organises weights also internal states units. important difference mtrnns mtrnnv self-organise towards final internal states mtrnna self-organises towards initial internal states finally activity units mtrnns gets associated cas. output layers mtrnna specified decisive normalisation neurons sigmoidal function figure architecture multi-modal mtrnn model consisting mtrnn context bias auditory mtrnns context abstraction somatosensory well visual information processing representing processing concepts. sequence phonemes produced time based sequences embodied multi-modal perception. training auditory mtrnna procedure mechanisms kept identical training previous models adaptive bptt variant utilised specifying respective error functions. training mtrnns mtrnnv conducted similarly includes suggested self-organisation forcing mechanism described equation mtrnn context abstraction error measured randomly initialised activities units final time step used self-organising both weights desired internal states. associations units mtrnns mtrnnv mtrnna trained rule activity units trained network generation novel verbal utterances proprioception visual input tested. final values mtrnns mtrnnv abstracted input sequences respectively associated initial values auditory mtrnna. values turn initiate generation phoneme sequence. generating novel utterances trained system presenting interactions depends calculation time needed preprocessing encoding done real time. additional training needed. order analyse proposed model’s characteristics first interested identifying parameter setting best generalisation capabilities. particularly enables analyse information patterns emerges different parts architecture. inspired infant learning analysis embedded real-world scenario robot learns language interaction teacher environment prelude analysis self-organisation forcing mechanisms need inspected impact developed internal representation abstracted proprioception. premised principle social cognition scenario also based interaction human teacher robotic learner acquire ground language embodied situated experience. testing refined model humanoid robot supposed learn describe manipulation objects various characteristics able describe novel manipulation actions correct novel verbal utterances. manipulations done nao’s effectors thus observed motor feedback visual perception overview). study developmental robotics approach particularly important include influence natural variances interaction originate varying affordances different objects also unforeseen natural noise. scenario controllable terms combinatorial complexity mechanical feasibility robot time allow analysing permutation handled. reason corpus limited verbal utterances generated small grammar summarised figure every single object four distinct shapes four colours four different manipulations feasible pull push show slide. grammar overall unambiguous meaning specific scene described specific utterance. nevertheless objects similar mass similar surface conditions proprioceptive sensation alone mostly ambiguous certain manipulation action objects differing colours also different shapes. order collect data study different possible interactions recorded times verbal utterance arm-starting position slightly varying movements object placements. done asking different subjects perform teaching interactions order minimise experimenter’s bias phoneme-based adaptation encoding scheme suggested hinoshita used verbal utterances descriptions taken symbolic grammar transformed phonetic utterances based phonemes arpabet four additional signs express pauses intonations propositions exclamations questions {sil qum} size occurrence phoneme represented spike-like neural activity specific neuron relative time step trel. addition activity spread backwards time forwards time represented gaußian function interval activities spike-like peaks normalised decisive normalisation function every absolute time step input neurons. absolute course time peaks mimic priming effects articulatory phonetic processing. example previous occurrence phoneme could related occurrence phoneme leading excitation respective neuron neuron activated. sketch utterance encoding shown figure filter width head margin noise start sequence interval phonemes scaling factor neuron’s activmaximal values possibly overlapping spikes. scaling factor depends number neurons scales activity normalisation function utterance encoding neurocognitively plausible reflects both neural priming mechanism well fluent activation spatially distinct phonetic although research neural spatial organisation phoneme coding infancy evidence early organisation primary auditory cortex superior temporal sulcus forming speech related speech unrelated sounds input representation also line ideal input normalisation mean activation function suggested lecun bottou müller gather encode proprioception corresponding manipulation action right guided human teacher. steered movement joint angles five joints directly measured sampling rate frames second resulting values scaled based minimal maximal joint positions example proprioceptive features fpro). data recording conducted scheme human teachers instructed four different movements listed figure encoding joint angle level neurocognitively plausible brain merges information joint receptors muscle spindles tendon organs similar proprioception representation area figure shows encoded proprioception exemplary manipulation action. visual perception capturing representation neurocognitively plausible level abstraction shapes colours make conventional visual perception methods shown figure first mean shift algorithm employed segmentation image taken robotic learner algorithm finds good segmentation parameters determining modes describe best clusters transformed feature space estimating best matching probability density functions. secondly canny edge detection well opencv contour finder applied object discrimination first algorithm basically applies number filters find strong edges direction second determines complete contour finding best match contour components. thirdly centre mass distances salient points around contour calculated. here salient means example largest shortest distance centre mass contour within intervals finally distances scaled square root object’s area ordered clockwise starting largest. resulting encoding values represents characteristic shape invariant scaling rotation. encoding perceived colour realised averaging three values area within shape. colour spaces e.g. based saturation could used well step mainly technical choice. additionally perceived relative position object encoded measuring values centroid coordinate field view allow tests interrelations multiple objects later. resulting encoding plausible brain representing visual information process recognising objects similarly primarily integrating shape colour features received visual cortex four area shape representation codes discrimination objects combining number contour fragments described curvature-angular position relative objects’ centre mass colour representation codes saturation information object invariant luminance changes overview figure provides prototypical example results perception process figure provides sketch visual shape perception encoding figure shows used objects. objects designed d-print possess similar masses despite different shapes comparable colour characteristics across shapes provide robustly controllably perceivable characteristics. capturing motion features also visual perception deliberately avoided several reasons. first conceptual perspective desired keep visual sensation ambiguous well study multi-model integration conceptual level. secondly agent could experience movement entity field view simply tracking said entity head eyes. would shift perception somatosensory level would introduce redundancy respect sensation could difficult preclude analysis. evaluation data divided training test sets used train randomly initialised systems. addition whole process repeated times well obtain runs analysis. acquired well work number neurons three mtrnns based representations utterances proprioception visual perception respectively. also based previous experience provide progressive abstraction scenario timescales somatosensory modality seem particularly crucial since manipulation actions strongly dependent shared motion primitives. preliminary parameter search confirmed suggestions based good parameters dimensions timescales learning variation selforganisation forcing parameter somatosensory mtrnns conducted test overall performance model. results experiment show system able generalise well high f-score edit distance training well test determined best network. average runs f-score edit distance training well test training challenging rarely perfect over-fitted systems obtained training data. nevertheless high precision lower medium recall observed test data. errors made production mostly minor substitution errors rarely word errors. using self-organisation mechanism final initial values somatosensory visual mtrnns caused good abstraction perception described scenario chosen values. scenario fact mechanism crucial. sensory modalities performance significantly worse using static random values final internal states units abstracting sensation particular proprioception forcing compared random patterns. based experience acquired preliminary test obvious hypothesis mtrnns self-organised better distribution patterns space. however measuring space using distance metrics revealed patterns spreading rather shrink towards small context values regardless large smaller shrinking develops similar less strong. find alternative hypothesis patterns inspected detail. showed regularity scenes including manipulation action. thus good performance might correlate self-organisation towards similar patterns similar manipulations. quantify effect additional measures used describe difference patterns scenes different manipulations inter-cluster distance dinter average unweighted pair distances patterns scenes include manipulation subsequently averaged manipulations. intra-cluster distance dintra provides mean distances centroids clusters contain patterns manipulation. measurements interintra-cluster distances varied presented figure plots compared absolute scale show inter-distance decreasing rapidly increased figure eﬀect self-organisation forcing mechanism development concept patterns multimtrnns model mean mixed -score mixed edit distance mixed measures indicate combination training test results equal weight mean average relative pattern distances intraintra-cluster distances interval standard error dimensions selected parameter settings good large self-organisation forcing respectively. diﬀerent words shapes colours shown diﬀerent coloured markers throughout tests model diverse patterns internal states units developed across modalities. nonetheless frequently similar patterns emerged respective modality similar utterances perceptions. particularly case units sensory modalities shown last experiment also units auditory production subsequently activation within cas. during training units auditory mtrnna also self-organised presented sequences however within formation means associations patterns emerged able cover whole space scenes training test data. inspect patterns self-organise look generated patterns whole model activated perception somatosensory visual modalities training test data. example activations presented figure well-converged architectures generalisation rate high generalisation rate visualisation provided reducing activity units dimensions using principle component analysis normalising values. results confirm patterns form dense sparse clusters visual somatosensory clusters reasonable distinct manipulations although notable mixing manipulations certain objects. auditory case high generalisation patterns also distinctly clustered. example presented figure discover clustering colour manipulation shape generalisation example figure shows clusters less clear patterns scattered across inspecting sensory data revealed visual shape colour sequences strikingly similar different manipulation objects proprioception sequences show differences objects. example slide manipulation banana-shaped objects notably different objects. apart that proprioception sensation mostly ambiguous respect specific scene intended scenario design. thus seems tendency restructuring characteristics overlapping single modalities representation characteristics distributed. perception overall concepts decomposition meaningful sequential actuation e.g. terms verbal description. results deduce self-organisation forcing indeed facilitating clustering concepts similar perceptions self-organising space internal states units upon structure data. self-organising patterns towards well-distributed clusters highly correlated ability generalise well. novel model good clustering self-organised abstracted context patterns visual perception also somatosensation. vision clustering occurs particularly dense clusters sparsely distributed space. models generalise well found associations emerged projected space multi-modal sensation well-distributed space auditory production. distribution self-organised towards sparselydistributed dense clusters. models able successfully describe training data cannot generalise showed less well-distributed auditory space. generalisation means well-distributed well-structured auditory space facilitates grounding language acquisition temporal dynamic features. space allows modulating motor sequence needs selected describe perception. good overall abstraction respective perceptual features thus fosters correct decomposition chain words phonemes. consequence fuse importantly disambiguate single modalities ambiguous overall coherent representation. since model happens temporally concurrent seems sufficient different aspects observation need co-occur form rich latent overall representation modalities. brain shown spatial characteristics neural connectivity temporal characteristics neural activation lead hierarchical processing sensation actuation previous studies researchers adopted natural conditions cortex order model similar hierarchical processing motor movements speech production aspects particular conditions utilised constrain ctrnns timescales integrate context bias. so-called mtrnn context bias model decompose initial context sequence primitives. paper concept developed reversed allow composing sequence primitives abstracted context. mechanism proposed force entropy-based self-organisation context supposedly serves component overall model grounding language embodied multi-modal sensation. self-organisation forcing mechanism provides development latent representation respective abstracted context sequential perception without need priori definition. model self-organisation forcing parameter quite sensitive small values hinder self-organisation large values lead fast premature convergence architecture. cause latter case both forward activity small weights well strong adaptation towards activity lead small errors. thus internal states final values self-organised match activity network network self-organised cover regularities data. issue could approached using regularisation self-organisation using weight initialisations based eigenvalue weight matrix. first option would important consider methods independent direction gradient. example simple normalisation internal states final units would skew distribution hence could lead convergence towards similar patterns. second option divergence could occur randomly initialised pattern could chance similarly small similarly large. utilising weight initialisation normalisation techniques used learning deep ffns might interesting lead additional instability training. model however means forming compositional representation perhaps sufficient data contain regularities well irregularities. seems compositional representation formed solely minimising differing activity similar temporal dynamic patterns thus entropy different versus similar patterns. concepts whole temporal dynamic sequences entropy-based descent inherent self-organisation forcing mechanism leads restructuring concept space represent similar sequences similar temporally static concept patterns. regularities data also rich natural environment also seem sufficient architecture different timescales. novel model density formed clusters certain observations observed closely related similarity abstracted sequences. observation logical since data somatosensory visual modalities compositional thus patterns formed compression temporal dynamic observations. consequence clustering sequences limited variability sequences since mapping required category within single modalities. associating multi-modal sensory representations auditory production representations form direct link active patterns. resulting mappings show close relation action-perception circuits measured brain space re-organised form specific conceptual webs co-occurring multi-modal patterns. since effect built emerged entropy-based learning seems conceptual webs obvious consequence self-organisation. regarding model means contexts single modalities indeed restructure towards clustering similar identical patterns similar perceptions. model self-organises towards capturing features different otherwise ambiguous sequences. associating abstracted temporally static context representations multiple perception modalities speech production modality concept-level emerge provide well-distributed unambiguous context space. thereby context space modulated produce novel correct speech productions. regard brain relates finding synchronous firing individual neurons react stimulus scaled-up cortex level again both uni-modal representations associations self-organise themselves driven regularities data. however structuring single modalities seems less complex easier re-organise. hence hierarchical abstractions seem operate like filter features rich perception. summarising means multi-modal context abstraction important aspects perception various pathways cope inherently varying temporal resolutions information densities different modalities. overall paper present neurocognitively plausible model embodied multimodal language grounding demonstrate natural interaction robotic agent environment. model extension previous model embodied grounding showed spatial temporal abstraction important characteristic language brain includes processing temporal dynamic somatosensory visual perception. characteristics neural architecture facilitating language acquisition obtained novel model shared representations abstracted multi-modal sensory stimuli motor actions integrate novel experience modulate novel production self-organisation might occur naturally structure sensorimotor data both spatial temporal nesting evolved human brain. future research must address demanding training scaling-up larger natural language corpora cover wider ranges sensorimotor contingencies. perhaps ease training fuzzy characteristics neurons e.g. stochastic variance neurons’ firing rate recruitment connections without changing architecture’s dimension conceptually similar tasks application namely sequence sequence mapping video annotation machine learning community made tremendous progress recently although many utilised architectures employ computational mechanisms neurocognitively plausible aspects like pooling drop-out normalisation utilised short-cut parts training conceptually crucial model preprocessing visual feature extraction. scaling-up complexity might reduced employing principle scaffolding learning language corpus words holo-phrases first complex utterances without altering weights word-layer phonetic output. respect modelling phenomena brain suggested conceptual networks involved speech processing motor action well somatosensation refinements embed hierarchical abstraction decomposition utterance comprehension motor outcome novel model refinements design novel neuroscientific experiments discovering multi-modal integration well hierarchical dependencies particularly language processing perhaps construct future robotic companions participate fascinating discourses. parts work presented icann compared non-recurrent ffns depth depending arbitrary length sequence. best network experiments shaped timescale values notation style follows original description mtrnn yamashita tani given dimensionality units ideal respect number sequences. however cases dimensionality lower value smaller example possible arrange four points d-plane equal distance case rep. arpabet general american english phone transcribed ascii symbols developed speech understanding project advanced research projects agency. transformation done using carnegie mellon university pronouncing dictionary. would like thank sascha griffiths sven magg wolfgang menzel cornelius weber fruitful discussions model characteristics experimental design well valuable comments earlier versions manuscript. also want thank erik strahl carolin mönter important support robotic hardware experimental data collections.", "year": "2017"}