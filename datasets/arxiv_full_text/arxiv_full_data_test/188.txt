{"title": "Three Perspectives on Complexity $-$ Entropy, Compression, Subsymmetry", "tag": "q-bio", "abstract": " There is no single universally accepted definition of \"Complexity\". There are several perspectives on complexity and what constitutes complex behaviour or complex systems, as opposed to regular, predictable behaviour and simple systems. In this paper, we explore the following perspectives on complexity: \"effort-to-describe\" (Shannon entropy $H$, Lempel-Ziv complexity $LZ$), \"effort-to-compress\" ($ETC$ complexity) and \"degree-of-order\" (Subsymmetry or $SubSym$). While Shannon entropy and $LZ$ are very popular and widely used, $ETC$ is a recently proposed measure for time series. In this paper, we also propose a novel normalized measure $SubSym$ based on the existing idea of counting the number of subsymmetries or palindromes within a sequence. We compare the performance of these complexity measures on the following tasks: a) characterizing complexity of short binary sequences of lengths 4 to 16, b) distinguishing periodic and chaotic time series from 1D logistic map and 2D H\\'{e}non map, and c) distinguishing between tonic and irregular spiking patterns generated from the \"Adaptive exponential integrate-and-fire\" neuron model. Our study reveals that each perspective has its own advantages and uniqueness while also having an overlap with each other. ", "text": "single universally accepted deﬁnition ‘complexity’. several perspectives complexity constitutes complex behaviour complex systems opposed regular predictable behaviour simple systems. paper explore following perspectives complexity eﬀort-to-describe eﬀort-to-compress degree-of-order shannon entropy popular widely used recently proposed measure time series. paper also propose novel normalized measure subsym based existing idea counting number subsymmetries palindromes within sequence. compare performance complexity measures following tasks characterizing complexity short binary sequences lengths distinguishing periodic chaotic time series logistic h´enon distinguishing tonic irregular spiking patterns generated ‘adaptive exponential integrate-and-ﬁre’ neuron model. study reveals perspective advantages uniqueness also overlap other. seemingly naive procedure ﬁnding decimal expansion real number synchronized beating heart cells irregular ﬁring neurons brain global economy society motion planets galaxies everyday weather examples complex systems. little agreement precise mathematical deﬁnition complexity doubt ubiquity complex systems nature society. ability model analyze understand complex systems invaluable since allows control predict exploit complex phenomena advantage. example characterizing complexity chaotic nature cardiovascular dynamics understand eﬀects aging understanding complexity unlocking mysteries brain since chaotic behaviour abound central nervous system complex behaviour neural signals even necessary multiplexing large number neural signals brain successful communication presence neural noise interference pseudorandom sequences high linear complexity easy generate hardware employed various cryptographic protocols complexity randomness increasingly playing important role psychology decipher behaviours mental processes pertaining memory references therein) cognitive eﬀects aging human judgments visual complexity list means exhaustive serves indicate widespread prevalence notion complexity. broadly categories complex systems deterministic non-deterministic chaotic systems examples deterministic complex systems capable producing rich complex behaviour ranging periodic quasi-periodic completely random-looking unpredictable outputs. stochastic systems inherently non-deterministic capable exhibiting complex dynamics predicted probabilistically. either case measuring complexity important step characterizing modeling system. paper concern all-important question complexity? single universally accepted deﬁnition ‘complexity’. several perspectives complexity constitutes complex behaviour complex systems opposed regular predictable behaviour simple systems. recent availability high speed cost computational tools disposal analysis complex systems become data-intensive. lloyd lists three questions researchers order quantify complexity thing study indicated questions corresponding italicized phrases parenthesis paper study three perspectives complexity namely eﬀort-to-describe eﬀort-to-compress degree-of-order. chosen perspective ‘eﬀort-to-compress’ instead ‘eﬀort-to-create’ interpretation degree-of-order diﬀerent lloyd’s means exhaustive several perspectives escape moment. table gives deﬁnitions examples three perspectives contrasting approaches characterize complexity object. rest paper goal compare evaluate speciﬁc measures representative three perspectives. section give in-depth deﬁnitions descriptions four measures together make three perspectives. among four measures measures well known widely used several applications third complexity measure known eﬀort-to-compress recently introduced measure characterize complexity time series beginning used several applications. fourth measure measure propose paper characterizing complexity time series though underlying idea counting subsymmetries new. claude shannon’s notion entropy quantitative measure information content popular widely used characterize complexity given time series. origins idea traced back thermodynamics statistical physics shannon entropy discrete random variable deﬁned takes possible events probability occurrence i-th event given maximum value concave function achieved uniform random variable events equally likely equal hmax bits. simple illuminating interpretation shannon entropy means yes/no questions entropy deﬁned minimum expected number yes/no questions needed remove uncertainty random experiment. thus entropy serves measure eﬀort-to-describe outcome random experiment. shannon entropy information theoretic measures widely used communication data compression error control coding cryptography biomedical applications ﬁnancial time series analysis non-linear dynamics various entropic forms physics references in). another important measure complexity goes name kolmogorov complexity deﬁned length shortest computer program produces given string/sequence output. also known descriptive complexity kolmogorov-chaitin complexity algorithmic entropy program-size complexity. please refer vitanyi details. shall always refer ﬁrst-order empirically estimated shannon entropy throughout paper. ‘ﬁrst-order’ refers fact entropy computed ﬁrst-order probability distribution treating symbols independent other. number bits needed describe object length shortest computer program describe object size dictionary captures minimum exhaustive history object. eﬀort losslessly compress object pre-determined lossless compression algorithm. remarks shannon entropy measured bits. popularly used place kolmogorovchaitin complexity diﬃcult compute. related universal lossless compression algorithm name complexity used extensively several applications. eﬀort-tocompress recently proposed measure based lossless compression algorithm known nonsequential recursive pair substitution subsymmetries subsym normalized complexity measure time series deﬁned ﬁrst time paper. subsym based alexander carey’s idea counting number subsymmetries measure visual complexity binary strings. owing uncomputability kolmogorov complexity lossless compression algorithms used approximate upper bound. lempel-ziv complexity measure closely related lempel-ziv universal lossless compression algorithm deﬁned size dictionary captures minimum exhaustive history input sequence entire sequence uniquely expressed example input string ‘aacgacga’ dictionary built words form minimum exhaustive history input sequence parsed left right. example dictionary acga}. thus value lempel-ziv complexity size dictionary order allow compare complexities strings diﬀerent length normalized measure proposed logα length input sequence number unique symbols input sequence. lempel-ziv complexity widely used variety applications estimation entropy spike trains biomedical applications ﬁnancial time series analysis bioinformatics applications analysis cardiovascular dynamics several others references in). recently proposed complexity measure diﬀerent perspective complexity. known eﬀort-to-compress measures eﬀort needed compress input sequence lossless compression algorithm. speciﬁcally employ non-sequential recursive pair substitution algorithm algorithm simple describe. proceeds identifying pair consecutive symbols input sequence frequently occurring replaces symbol. next pass repeated. fashion every iteration length sequence reduces algorithm stops sequence turns constant sequence complexity measure deﬁned number iterations needed reduce input sequence constant sequence. example transforms input sequence aacgacga agga value complexity measure instance normalized value measure given length input sequence note lower value measure lower complexity. originally proposed automatic identiﬁcation classiﬁcation short noisy sequences chaotic dynamical systems recently applied characterizing dynamical complexity time series chaotic ﬂows maps well two-state markov chains analyzing short tachograms healthy young subjects developing measure integrated information table subsym normalized complexity measure deﬁned using number subsymmetries example consider three binary strings length normalized measure deﬁned respect all-zero sequence value measure original taxonomy complexities lloyd degree organization divided aspects diﬃculty describing organizational structure amount information shared parts system result organizational structure. interpret perspective slightly diﬀerent way. interested degree-of-order intrinsic input sequence. best candidate notion symmetry. idea counting total number subsymmetries intrinsic binary string goes back alexander carey interested characterizing cognitive simplicity binary patterns. however largely forgotten recently revived toussaint context human judgment visual complexity. deﬁnition simple count total number substrings lengths palindromes. input sequence all-zero sequence function subsymmetries returns total number subsymmetries palindromes. matter simple counting easy all-zero sequence length total number subsymmetries palindromes idea behind deﬁnition all-zero sequence highest order number subsymmetries. hence number subsymmetries input sequence divided all-zero sequence. gives proportion order simplicity input sequence. order give measure complexity subtract quantity resulting normalized measure satisﬁes subsym example consider three binary strings length compute normalized measure subsym. measure string highest order followed string normalized complexity measure subsym three strings respectively. important point note measures work symbols need procedure convert real-valued time series symbolic sequence done ﬁrst deﬁning partition assigning unique symbols non-overlapping bins form partition. example consider real-valued time series takes values range deﬁne partition consisting bins in+m thus every value time series checked belongs. belonged coded belonged coded thus resulting symbolic sequence contain symbols made ready analysis using complexity measures. binary sequences strings arise several applications. example analyzing membrane potential waveforms obtained neurons signal ﬁrst converted symbolic sequence zeros ones indicating ‘no-spiking’ ‘spiking’ moving window pre-determined length resulting binary sequence analyzed order estimate entropy means lempel-ziv complexity several cases neuron study times window chosen study. thus vital consider performance complexity measures short binary sequences. example consider four binary strings table corresponding values four complexity measures. intuitively expect binary strings structure order lower value complexity less structure table above diﬀerent measures capture diﬀerent aspects order structure. shannon entropy blind arrangement sensitive relative counts. performs poorly issues short data-lengths previously noted subsym seem yield reasonable values example. subsym puts string highest complexity since least number palindromes/subsymmetries. number subsymmetries hence identical values subsym. slightly higher complexity since latter patterns frequency whereas former pattern highest frequency ﬁrst test perform characterize complexity possible binary strings lengths ranging metrics evaluate measures number distinct complexity values complexity measure takes across entire ensemble binary strings particular length. larger number distinct values desirable since allows distinguish complexities individual binary strings ﬁnely. figure number distinct complexity values binary strings lengths four measures seen subsym number distinct values followed larger number distinct values desirable since allows distinguish complexities diﬀerent individual binary strings ﬁnely. fig. shows graph number distinct complexity values binary strings lengths seen subsym number distinct values followed appears among measures considered subsym ideally suited characterizing complexity short binary strings. however alone insuﬃcient next test determine whether measures successfully distinguish periodic chaotic time series. several applications need distinguish periodic behaviour irregular chaotic behaviour. example well known heart rate healthy human hearts constant periodic shows irregular patterns typically associated chaotic dynamical system several studies suggest aging pathological physiological conditions result reduced complexity heart dynamics leading regular heart rate variability interested determining whether four complexity measures able distinguish chaotic periodic time series. order test this ﬁrst consider chaotic logistic given following equation bifurcation parameter. values chosen resulting time series periodic weakly chaotic strongly chaotic fully chaotic length time series generated varied lengths diﬀerent sets time series generated distinct initial conditions chosen randomly interval resulting ensemble time series converted symbolic sequence symbols corresponding interval corresponding interval symbolic sequences subsequently analyzed four complexity measures. length time series logistic randomly chosen initial conditions shannon entropy lempel-ziv complexity eﬀort-to-compress complexity subsym complexity. errorbars indicate standard deviation. show good separation four time series length increases. length time series. make following observations. mean shannon entropy values fairly constant length time series varied. though entropy able separate chaotic periodic time series poorly distinguish strong chaos full chaos mean mean values show good separation four cases especially increasing lengths. subsym able clearly separate periodic chaotic though unable distinguish weak chaos strong chaos full chaos next experiment interested determining minimum length time series needed measures classify periodic time series chaotic time series. consider non-linear chaotic maps logistic h´enon given experiment consider choices parameter logistic correspond periodic chaotic behaviour respectively. similarly h´enon parameter ﬁxed choices parameter corresponding periodic chaotic behaviour respectively. before take equal sized bins creating symbolic sequence trials. exercise determine length time series measure fails distinguish periodic chaotic cases. table shows minimum length time series required statistically distinguish periodic chaotic time series four measures. infer logistic measures succeed discriminating periodic chaotic time series though table minimum length time series required statistically distinguishing periodic chaotic time series chosen chaotic maps requires least length time series. billion neurons human central nervous system. cells basic information processing units form highly complex network. neurons respond stimulus ﬁring diﬀerent patterns short duration cell membrane potential spikes carry important information stimuli order investigate dynamics neuronal behaviour diﬀerent models ﬁring proposed. single spiking neuron model ‘adaptive exponential integrate-andfire’ model initially proposed brette gerstner simple realistic model used commonly equations reset condition. diﬀerent ﬁring patterns produced model described naud equations governing model equations membrane potential injection current adaptation current. model parameters total capacitance total leak conductance eﬀective rest potential threshold slope factor eﬀective threshold potential conductance time constant spike triggered adaptation reset potential current drives voltage beyond threshold value exponential term causes sharp increase action potential. rise stopped reset threshold ﬁxed decrease action potential represented reset condition varying parameters various ﬁring patterns obtained tonic spiking adaptation initial burst regular bursting delayed accelerating delayed regular bursting transient spiking irregular spiking. interested ﬁring patterns namely tonic spiking irregular spiking. shown fig. tonic spiking spikes produced regular intervals whereas interspike intervals irregular spiking aperiodic also highly sensitive initial conditions thus discriminating patterns akin distinguishing periodic signals chaotic ones. follow procedure converting waveforms symbolic sequences entire waveform partitioned non-overlapping time windows length window spikes present coded else coded four complexity measures estimated symbolic sequence moving time window results shown fig. make following observations based results across spike trains observed shows similar variations shows greater variation irregular spike train compared tonic case. further statistical evaluation shows mean values tonic irregular spike trains appreciable diﬀerence means measure. clear indicator periodic chaotic nature tonic irregular spike trains characterized measure fails cases shannon entropy subsym measures figure membrane potential time ‘adaptive exponential integrateand-fire’ neuron ﬁring model used study. tonic spiking waveform showing periodic spikes. bottom irregular spiking waveform showing chaotic behaviour. validate results complexity values windows used sample values statistical diﬀerence analyzed using conﬁdence interval plots. using sample values sample students t-test also done complement graphical analysis formal hypothesis test. based sample data signiﬁcance level statistical test suﬃcient evidence conclude mean mean shannon entropy mean subsym complexity measures irregular spiking patterns signiﬁcantly higher corresponding tonic patterns mean complexity measure irregular spiking pattern signiﬁcantly higher tonic pattern. thus assert figure complexity measures tonic irregular spiking using moving window overlap. mean tonic irregular spiking similar indicating inability complexity measure distinguish spike trains. complexity many facets perspectives chosen three speciﬁc viewpoints eﬀort-to-describe eﬀort-to-compress degree-of-order perspectives distinct unique also overlap amongst them. example entropy lossless compression deeply related compressible patterns typically symmetrical whereas random incompressible patterns asymmetrical. ‘subsymmetries’ relates intrinsic order arrangements symbols make string. relates perspective visual complexity figure complexity measures tonic irregular spiking using moving window overlap. clear diﬀerence spiking patterns. mean irregular spiking greater mean tonic spiking indicating able distinguish spike trains. rooted cognitive ability humans perceive structure/order distinguish lack normalized measure based subsymmetries proposed paper. subsym takes large number distinct values binary strings desirable since allows distinguish diﬀerent binary patterns ﬁnely. measure deserves tested various applications. recently proposed measure intuitive appeal easy compute also demonstrates superior performance discriminating periodic chaotic time series. conclude noting complexity remains multi-dimensional notion single measure capture entirety. several perspectives measures need work unison help arrive better understanding complexity.", "year": "2016"}