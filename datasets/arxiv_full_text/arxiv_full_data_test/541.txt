{"title": "Evaluating performance of neural codes in model neural communication  networks", "tag": "q-bio", "abstract": " Information needs to be appropriately encoded to be reliably transmitted over physical media. Similarly, neurons have their own codes to convey information in the brain. Even though it is well-known that neurons exchange information using a pool of several protocols of spatio-temporal encodings, the suitability of each code and their performance as a function of network parameters and external stimuli is still one of the great mysteries in neuroscience. This paper sheds light on this by modeling small-size networks of chemically and electrically coupled Hindmarsh-Rose spiking neurons. We focus on a class of temporal and firing-rate codes that result from neurons' membrane-potentials and phases, and quantify numerically their performance estimating the Mutual Information Rate, aka the rate of information exchange. Our results suggest that the firing-rate and interspike-intervals codes are more robust to additive Gaussian white noise. In a network of four interconnected neurons and in the absence of such noise, pairs of neurons that have the largest rate of information exchange using the interspike-intervals and firing-rate codes are not adjacent in the network, whereas spike-timings and phase codes (temporal) promote large rate of information exchange for adjacent neurons. If that result would have been possible to extend to larger neural networks, it would suggest that small microcircuits would preferably exchange information using temporal codes (spike-timings and phase codes), whereas on the macroscopic scale, where there would be typically pairs of neurons not directly connected due to the brain's sparsity, firing-rate and interspike-intervals codes would be the most efficient codes. ", "text": "information needs appropriately encoded reliably transmitted physical media. similarly neurons codes convey information brain. even though well-known neurons exchange information using pool several protocols spatio-temporal encodings suitability code performance function network parameters external stimuli still great mysteries neuroscience. paper sheds light modeling small-size networks chemically electrically coupled hindmarsh-rose spiking neurons. focus class temporal ﬁring-rate codes result neurons’ membrane-potentials phases quantify numerically performance estimating mutual information rate rate information exchange. results suggest ﬁring-rate interspike-intervals codes robust additive gaussian white noise. network four interconnected neurons absence noise pairs neurons largest rate information exchange using interspike-intervals ﬁring-rate codes adjacent network whereas spike-timings phase codes promote large rate information exchange adjacent neurons. result would possible extend larger neural networks would suggest small microcircuits would preferably exchange information using temporal codes whereas macroscopic scale would typically pairs neurons directly connected brain’s sparsity ﬁring-rate interspike-intervals codes would eﬃcient codes. main function brain process represent information mediate decisions behaviors cognitive functions. cerebral cortex responsible internal representations maintained used decision making memory motor control perception subjective experience. recent studies shown adult human brain neurons connected neurons many synaptic connections. neurophysiology shown single neurons make small understandable contributions behavior however behaviors involve large numbers neurons often organized brain regions nearby neurons similar response properties distributed number anatomically diﬀerent structures brain-stem cerebellum cortex. within regions diﬀerent types neurons diﬀerent connectivity-patterns typical responses inputs. coexistence segregation integration brain origin neural complexity connectivity essential integrating actions individual neurons enabling cognitive processes memory attention perception. neurons form network connections communicate mainly transmitting action potentials spikes. mechanism spike-generation well understood spikes generate change membrane potential target neuron potential surpasses threshold spike might generated brain regions show signiﬁcant specialization higher functions integration abstract reasoning consciousness emerging interactions across distributed functional neural networks. local level function individual neurons relatively well understood. however full understanding information processing networks spiking neurons so-called neural code still elusive. neural code system rules mechanisms signal carries information coding involving various brain structures. clear neurons communicate frequency spikes since part information also transmitted precise timing individual spikes also known parts brain rate codes timing codes. cases oscillations important others much still debate neural code used brain region much potential timing information actually used interactions diﬀerent timescales might related diﬀerent types processing thus understanding information processing requires examining temporal dynamics among neurons networks. precise spike-timing would allow neurons communicate information random spikes. diﬀerent types neural coding including temporal spatial coding also coexist diﬀerent time scales scientiﬁc evidence supports argument still lacking full understanding codes used neurons carry process information well neural code used brain region. emerges scientiﬁc evidence suggests fast systems responses fast spike-timings coding. example human visual system shown capable performing fast classiﬁcation participating neuron spike. speed auditory information decoded even generation speech also suggest crucial neural systems human brain operate quite fast. example human ﬁngertip sensory neurons found support demonstrating remarkable precision timeto-ﬁrst spikes primary sensory neurons thus investigating fundamental properties neural coding spiking neurons allow interpretation population activity understanding better limitations abilities neural computations. paper study neural coding introduce four neural codes. quantify compare rate information exchange code small-size networks chemically electrically coupled hindmarsh-rose spiking neurons deal spatial codes temporal ﬁring-rate codes. neuron network record temporal courses membrane-potential phase. construct suitable representation variables compute rate information exchange pair neurons mutual information rate function connectivity synaptic intensities. consider precise spike-timings neural activity maximum points phase neural activities considering oscillatory behaviors arbitrary amplitude including high-frequency spiking low-frequency bursting oscillations interspike intervals ﬁring-rate ﬁrst three codes assume measurements performed respect ticks local master clock meaning relative activity produced participating neurons network. choice arbitrary sense activity single neuron network used clock. allows estimated mutual information rates reﬂect measure synchronous events occur within reasonable short-time window. thus estimations provide strength information exchanged without signiﬁcant time-delay therefore reﬂecting non-directional non-causal estimation. relation estimations neural codes would possible reﬁne them considering ﬁner spatial partitions example ﬁner binary ones considered work. reﬁnements would correspond search generating higher-order markov partition however here study whether looking codes based interspike intervals would provide information instantaneous spike-timings code. motivated question time-series events carry information? code based times events code based precise times occurrence events? control estimations comparing theoretical upper bound verify plausibility analysis. main ﬁndings summarized follows simplest case single pair coupled spiking neurons exchange largest amount information unit time neural code based precise spike-timings. observable noise present ﬁring-rates able exchange larger rates information based temporal codes together interspike-intervals code robust noise. case four chemically electrically coupled neurons fig. largest rate information exchange attributed neural codes maximum points phases interspike intervals. surprisingly pairs neurons largest rate information exchange using interspike-intervals ﬁring-rate codes adjacent network spike-timings phase codes promoting large rate information exchange adjacent neurons network. latter also backed results fig. connectivity swapped. results provide evidence non-local character ﬁring-rate codes local character temporal codes models modular dynamical networks spiking neurons. neurons form multiplex network neurons arranged equal-size modules bottleneck conﬁguration communication pairs neurons modules mostly eﬃcient using either spike-timings maximum points phases codes. parameter modulates slow channels system external current iext enters neuron ﬁxed simplicity neurons submitted external current iext. values neuron exhibit chaotic behavior solution exhibits typical multi-scale chaos characterized spiking bursting activity consistent membrane potential observed experiments made single neurons vitro work intents study transmission information models small-size neural networks treating communication systems measure evaluate rates information exchanged among neurons. also interested considering realistic biological models function instead consider biologically inspired function chosen yield excitatory synaptic coupling behaves short deltafunction carries features required synaptic coupling. particularly vsyn tuned reproduce excitatory inhibitory behavior θsyn allow disconnection pre-synaptic neurons reached activation level. continuous sigmoid function behaves similarly binary process either fundamental property necessary analytical works networks neurons connected simultaneously electrical chemical means become synchronous naturally mimicking democratic fashion chemical synapses behave large community activated pre-synaptic neurons needs activated induce relevant response post-synaptic neuron. allows study system knowing domain parameters obtain oscillatory behavior. choices couplings network topologies work purely abstract guided realistic physiological reasons time eqs. parameters denote coupling strength chemical electrical synapses respectively. chemical coupling nonlinear functionality described sigmoid function acts continuous mechanism activation deactivation excitatory networks. neurons connected excitatory synapse presynaptic neuron spikes might trigger post-synaptic neuron spike. adopt excitatory chemical synapses here. accounts neurons electrically coupled represented laplacian matrix connection neurons entry matrix otherwise binary adjacency matrix describes neurons chemically connected degree i-th neuron. represents number chemical links neuron receives neurons network. positive oﬀ-diagonal value matrices column means neuron perturbs neuron intensity given glgij gnbij therefore adjacency matrices given neuron following initial conditions −.+ηr uniformly distributed random number details). initial conditions place trajectory attractor dynamics quickly reducing thus computational time simulations. integrated numerically eqs. using euler’s ﬁrst order method time-step reduce numerical complexity time feasible levels. preliminary comparison trajectories computed parameters using integration methods order produced similar results. numerical performed total integration time units integration eqs. computation various quantities computed transient time make sure shannon’s pioneering work information became clear useful important concept measure amount uncertainty observer random event thus provides measure unpredictable another concept related shannon entropy characterize random complex systems mutual information measure much uncertainty state variable observing another state variable system. authors derived upper bound nodes groups nodes complex dynamical network depends largest lyapunov exponents subspace formed dynamics pair nodes. particularly shown ﬁnite-time -size lyapunov exponents calculated -dimensional observation space dynamics pair nodes typically approach largest lyapunov exponents dynamics network connected time calculate suﬃciently small upper bound pair neurons network measured -dimensional observation space. estimated using mainly approaches expansion rates pair neurons taking maximal value among measurements tricky diﬃcult compute largest positive lyapunov exponents here second approach since equations motion dynamics available full spectrum lyapunov exponents calculated particularly estimate upper bound network. phase spaces dynamical systems associated multi-dimensional thus estimating upper bound using reduces considerably complexity calculations. besides parameter changes cause positive negative changes reﬂected upper bound proportion huge body work estimation dynamical systems neuroscience example work follow method introduced recently estimate pairs time-series methodology used estimate using reﬁnements generating markov partitions. below explain estimate using estimated values pairs represent mapping variables neural codes introduced work. particularly estimate considering binary symbolic dynamics encode time-series symbolic trajectory represented sequentially mapped points encoded symbolic sequences composed elements. encoding done ﬁrstly normalizing time-series unit interval. assume values either value smaller otherwise. joint probability symbolic sequences length observed simultaneously marginal probabilities symbolic sequences length sequences respectively. subindices vary number symbolic sequences diﬀerent lengths observed respectively. interval considers sequences starting bits. reason behaves linearly interval allowing calculation mir. particularly built-in correlations time-series fact chosen partition likely best possible suggests exclusion since correlations would start appearing larger symbolic sequences. also consider would numerical problems would introduce under-sampling eﬀects time-series length. example would assume analysis neurons would eﬀectively deal symbolic sequences length would diﬀerent sequences length signiﬁcant trajectory length would larger trajectory points. ergodic property chaotic systems probability observing given symbolic sequence length neuron another length another neuron equivalent probability ﬁnding trajectory points cell phase space. larger smaller cell thus contains information state pair neurons. mirii estimator subsec. interspike intervals similar work authors encode time-signal making time partition temporal bins deﬁned binary encoding done associating bins without spiking bins spikes. encodings sec. based partitions space created time-series approach sought maximize search generating markov partition however dealt biasing compare estimations neural codes estimated diﬀerence maximal lyapunov exponents estimations sec. bounded mathematical upper bound except three cases elaborate later. worth note parameters initial conditions eqs. give rise chaotic behavior positive lyapunov exponents. thus chaos responsible generating probabilities necessary estimation -dimensional spaces data encoding trajectories pairs neurons chaotic behavior turn gives rise uncertainty production information. information transmitted various nodes neural network electrical chemical connections ﬁrst uses spike-timings neural activity second maximum points phase neural activities third interspike intervals fourth ﬁring-rates ﬁrst three assume recordings done respect ticks local master clock relative activity produced single neuron. choice arbitrary sense activity single neuron used. purpose obtain values interpreted current rate information exchanged neurons time-delay mutual information. estimation neural codes integrate numerically system eqs. discussed subsec. obtain numerical solutions function time. solutions construct pairs time-series estimate particular neural code explained below. coupling topology choices abstract inspired current research multilayer networks seek study whether looking instantaneous spike-timings provides less information codes based interspike intervals. particularly study motivated question time-series events carry information? code based times events code based exact times occurrence events? here explain estimate amount information exchanged unit time neurons based spike-timings ﬁrst neuron mirst stands spike-timings. particularly assume ﬁrst neuron plays role clock record eqs. times ﬁrst neuron attains local maxima. allows construct time-series events transforming continuous dynamics variables time-series discrete-time spike events compute rate information exchanged neurons explained subsec. divide rate information exchanged mean interspike times spike activity ﬁrst neuron. call quantity mirst pair neurons next explain estimate amount information exchanged unit time neurons based maximum points time evolution phase variables denote mirmφ stands maximum phase assume ﬁrst neuron eqs. times ﬁrst neuron attains local maxima function time allows construct time-series events transforming continuous dynamics phase variables neurons time-series discrete time events estimate rate information exchanged neurons divide rate information exchanged mean time intervals ﬁrst neuron attain local maxima. call quantity mirmφ pair here show estimate amount information exchanged unit time neurons based interspike intervals variables denoted mirii stands interspike intervals. neuron produce series diﬀerent interspike intervals course time. measuring interacting systems need specify correlated relevant events occurring roughly time time-delays considered. events need match i.e. event happening neuron needs correlated event happening neuron. order relate time-series matched pairs events introduce notion relative clock. interspike interval neuron matched interspike interval neuron neuron spikes neuron notice this neglect several spikes happening neurons however produce discrete two-dimensional variable meaningfully correlated therefore producing meaningful another cumbersome approach would appropriate time-interval within neurons spike correlate spike-timings intervals method complicated calculate considering interspike intervals occurring diﬀerent time-delays. analysis would complicated adopted work would necessary. allows construct time-series interspike events continuous trajectories neurons. compute rate information exchanged neurons dividing mean time intervals constructed diﬀerence spike-timings neuron neuron given spike neuron occurred neuron call quantity mirii pair lastly show estimate amount information exchanged unit time neurons ﬁring-rates variables mirf stands ﬁring-rate. here divide time window ﬁrst last recorded spike-timing neuron equal-size time windows compute ﬁring-rates neurons time windows. ﬁring-rate mean ratio number spikes given time interval divided length time interval. allows construct time-series ﬁring-rate events time-series compute rate information exchanged link interspike-intervals ﬁring-rate codes goes back kac’s lemma relates return-time intervals ﬁrst poincar´e returns trajectory recurring region phase space probability measure trajectory returning region phase space. ﬁring rate calculated denotes number spikes represents ﬁrst poincar´e returns could also τi/n last equation relates ﬁring rates average spike times though study four neural codes introduced simplest case pair chemically bidirectionally connected neurons absence noise consider eﬀect next section. goal understand neural code maximize rate information exchange neurons considering communication system. also interested ﬁnding chemical coupling strengths happening. motivated question would neurons exchange information disconnected network acting single pair. note interested directionality information rate information exchanged pair-wise. particularly fig. calculate amount unit time exchanged neurons four neural codes diﬀerent chemical coupling strengths proceed detailed analysis summarize main results ﬁgure increase synaptic coupling strength time-series membrane potential synchronous becomes strongly synchronous weakly synchronous scenario similar amplitudes spikes panels localization panel total localization partial localization panel fact fig. interesting shows low-dimensional attractor associated membrane potential something usually observed coupled systems generalized-synchronous. scenario changes considerably observing behavior phases spike-timings even though weak phase-synchronization panel apparent synchronization panels respectively. figure shows membrane potentials mainly asynchronous time epochs synchronicity already visible small interval depicted panel. indeed happening full time-series numerical simulations depicted fig. phases deﬁned eqs. function derivatives. however interspike intervals become weakly synchronous panels respectively strongly synchronous diﬀerences intensity neurons exchange information explored following. ﬁrst fig. mirst mirmφ bigger mirii mirf certain regions intermediate large enough chemical coupling strengths almost quantities smaller upper bound except three chemical coupling strengths ranging smaller larger values. intriguing result fact calculating using lyapunov exponents discussed previously approximation real upper bound mir. consequently comparing upper bound lower bound estimations neural codes work might happen lower bounds larger estimated upper bounds. note values larger dynamics becomes quasi-periodic thus production information. reason cases largest lyapunov exponent dynamics negative consequently chaos quasi-periodic behavior gives rise predictability lack uncertainty thus production information. focus three characteristic cases ﬁrst corresponds case mirmφ >mirst chemical coupling strength second case mirii mirmφ mirst last case mirst >mirmφ ﬁrst case neurons communicate eﬃciently exchanging larger amounts information unit time using phases whereas third case exchanging information precise spike-timings. second case neurons communicate eﬃciently encoding information interspike activity. appreciate performance four codes ﬁrst focus case mirmφ >mirst. plot fig. time evolution data used compute mirst panel plane phase variables neurons panel computation mirmφ based panel data used compute mirii interspike intervals neurons. observe panel spike times neurons diﬀerent. fig. shows membrane potentials neurons mainly asynchronous time epochs synchronised activity already visible small interval depicted panel. characterized neurons phase shift displacement phases causes time shift spike trains thus making time-discrete variables spike-timings asynchronous. phase reﬂects continuous oscillatory behavior trajectory connected zero lyapunov exponent. spike trains reﬂect timely character connected positive lyapunov exponent. fact spike trains phases asynchronous. however discretization ﬁlters continuous oscillatory behavior trajectory producing spike-timings expected asynchronous behavior noticeable timing variables connection positive lyapunov exponents. behavior second neuron actually quiescent period ﬁrst spiking. contrast observing plane phases panel becomes apparent regions high phase-synchronicity rest region considerably smaller concentration phase points. behavior indicates neurons communicate chaotically adapting phases. panel indicates interspike activity neurons well spread plane high concentration points occurring close origin. moreover mirf seen attain smaller value respect quantities. panels study second case mirii note apparent violation comes estimate lyapunov exponents expansion rates. since estimated mesh grid ﬁnite resolution upper bound calculated grid would require calculation expansion rates using grid resolution. estimated lyapunov exponents smaller bound estimated expansion rates therefore case could true upper bound mir. here also observe mirst >mirmφ result shows neurons communicate mostly exchanging information precise spike-timings less phases. appreciated panel variables attain approximately similar amplitudes time evolution. becomes evident panel second neuron spikes ﬁrst neuron spikes attain approximately amplitudes time-evolution. behavior highly localized. contrast panel shows phases actually spread localization points happened neurons communicate exchanging largest amount information unit time phases. here panel indicates figure results neural communication channel code used chemically bidirectionally connected non-noisy neurons. panel pair chemically connected neurons strength chemical coupling. panel spike-timings mirst maxima phases mirmφ interspike intervals mirii ﬁring-rates mirf respectively. panels function time panel plane phase variables data used compute mirii interspike intervals neurons. panels similarly panels panel corresponds case mirmφ >mirst case mirii mirmφ mirst case corresponds mirst >mirmφ. interspike activity neurons well localized regions high concentration closer origin right upper part plot. moreover mirf seen attain smallest value particular chemical coupling strength. finally focus third characteristic case mirst >mirmφ situation quite diﬀerent. indeed panel reveals phenomenon spike times quiescent periods neurons actually similar. particularly panel reveals times either ﬁrst neuron spikes second spikes ﬁrst quiescent period second showing higher density points upper right corner plot smaller lower left corner contrast plane phases panel reveals phase synchronization activity dense regions ﬁrst case mirmφ >mirst. results show neurons communicate spike-timings i.e. temporal neural code time spike conveys information transmitted neurons. lastly panel exhibits interspike activity mostly concentrated lower left corner plot less three situation completely diﬀerent behavior panel second case. mirf seen attain smallest value similarly ﬁrst case. study problem presence noise. consider eﬀect additive gaussian white noise performance neural codes introduced subsec. want understand neural code robust increase noise strength case close realistic neural behavior particularly neural activity variable neuron white gaussian noise standard deviation obtain noisy signal noisy data estimate diﬀerent neural codes diﬀerent chemical coupling strengths noise strengths dynamics chaotic comes deterministic system eqs. demonstrate results fig. particularly plot neurons fig. diﬀerent chemical couplings three noise strengths. figure shows quantities fig. panel panel increases zero quantities start decreasing except mirf mirii remain practically unaﬀected increase noise strength. figure reveals even though small noise strengths mirst mirmφ larger mirf nevertheless considerably aﬀected increase noise strength. demonstrate panels mirf mirii prove consistently robust respect increase even values high underlines importance ﬁring-rate temporal codes spike-timings phase codes prove prone noise contamination transmission smaller amounts information unit time increase noise strength. comparing fig. fig. seen presence gaussian additive noise various quantities drop around also region mirst >mirmφ disappears. particularly noisy strength increasing mirf mirii became dominant larger mirmφ mirst respectively except singular values. ﬁndings suggest ﬁring-rate interspike-intervals codes robust readout noise. here extend study case four bidirectionally connected non-noisy neurons chemically electrically coupled shown fig. ﬁrst neuron chemically connected third whereas ﬁrst second third fourth electrically connected. strengths electrical chemical connections given respectively. four neurons fig. arranged typical conﬁguration wants infer topology information-theoretical quantities. open-ring topology oﬀers figure results neural code used chemically connected noisy neurons. panel values diﬀerent neural codes noise strength panel panel panels similar mirii mirf noise strengths ﬁrst three panels. also plot panels guide eye. notice mirii mirf panels remain unaﬀected increase noise strength. test whether adjacent neurons share higher rates information exchange. understand neural code best suited maximization rate information-exchange diﬀerent coupling strengths also pairs ﬁrst third neurons intermediates facilitate communication second fourth. consider setup fig. communication system which information transmitted connections reaches neurons. follows pair coupling strengths estimate neural codes them maximum value corresponding pair neurons produces then coupling pair plot maximum value corresponding pair neurons. figure topology parameter spaces neural codes four non-noisy neurons connected electrical chemical connection. panel network connections four neurons strengths chemical electrical couplings respectively. panels parameter spaces mirst nodes provide largest value links maximizes respectively. panels similarly mirmφ. panels similalry mirii. panels similarly mirf cases notation indicates bidirectional transfer information neurons links maximize respectively. orange spots panel correspond couplings produce largest amounts mirst whereas blue regions smallest mirst. former occurs relatively chemical electrical couplings whereas latter small electrical small large chemical couplings. panel reveals that depending couplings largest amounts mirst transmitted diﬀerent pairs neurons giving rise complicated pattern parameter space pattern mainly characterized pair neurons small chemical small large electrical coupling strengths pair comparatively small large chemical small large electrical coupling strengths many smaller-sized regions diﬀerent colors blue magenta green yellow correspond remaining pairs neurons. decided clock ﬁrst neuron mediators facilitate transmission information network choice however relative sense every pair neurons want estimate choose clock. sense universal clock several ones used. choice also intends maximize amount measured pairs neurons. parameter space mirmφ panel mainly dominated smaller blue region moderately values smaller orange region high chemical electrical couplings corresponds highest observed mirmφ values parameter space. similarly panel panel pairs neurons maximize mirmφ shows that depending coupling values largest amounts mirmφ transmitted diﬀerent pairs neurons giving rise complicated pattern parameter space dominated mainly pair neurons small chemical small large electrical coupling strengths pair comparatively small large chemical small large electrical coupling strengths many smaller-sized regions diﬀerent colors correspond remaining pairs neurons. situation changes slightly panel mirii almost parameter space dominated orange spots blue spots blue regions considerably smaller size blue region panel case mirii also diﬀerent respect pairs neurons maximal. parameter space panel reveals completely diﬀerent structural properties panels interestingly largest amounts mirii occur pairs except less implying ﬁrst third neurons play mainly role facilitators transmission information system. similar situation happening mirf parameter space panel looking uniformly covered moderately high mirf values quite small blue spots values. mirf less dependent coupling strengths. parameter space links maximize quantity looks quite similar mirii sense largest amounts mirf occur pairs except less implies ﬁrst third neurons play mainly role facilitators transmission information system. comparison parameter spaces fig. shows highest rate information exchange attributed neural codes maximum points phase mirmφ interspike intervals mirii. moreover mirf practically unaﬀected coupling strengths even though maximum values smaller maximum values neural codes based maximum points phase interspike intervals. result agreement performance case neurons sec. attained lowest values codes. interestingly pair nodes likely exchange largest amount information unit time using interspike-intervals ﬁring-rate codes adjacent network whereas spike-timings phase codes promote large exchange information adjacent nodes network. provides evidence non-local character ﬁring-rate codes local character precise spike-timings codes. latter result character codes also backed results fig. role chemical electrical connections swapped particular comparing panels fig. deduce temporal codes perform optimally adjacent neurons network whereas mirf figure topology parameter spaces neural codes four non-noisy neurons connected chemical electrical connection. panel network connections four neurons strengths chemical electrical couplings respectively. panels parameter spaces mirst nodes provide largest value links maximizes respectively. panels similarly mirmφ. panels similalry mirii. panels similarly mirf cases notation indicates bidirectional transfer information neurons finally study neural codes extended model identical clusters nonnoisy neurons each. simplicity clusters small-world structure neurons internally coupled electrical connections strength construction interesting resembles bottleneck clusters communicate link ﬁrst eleventh neuron clusters. bottleneck represented single chemical link strength connects clusters. used interconnection simplest case information travels cluster chemical link. moreover allows draw interesting conclusions regard neural codes diﬀerent coupling strengths. topology fig. example neural networks would interact connection implements bottleneck. again network undirected pair coupling strengths estimate four neural codes. code maximum corresponding pair neurons produces then coupling pair plot maximum value. network fig. motivated modular organization brain neurons linked together perform certain tasks cognitive functions pattern recognition data processing etc. modular processors suﬃciently isolated dynamically diﬀerentiated achieve independent computations also globally connected integrated coherent functions structure fig. helps understand neural code modular neural networks best suited transmission largest amount information unit time coupling strengths occurs. again treat model fig. communication system which information transmitted links reaches diﬀerent parts. figure topology bottleneck conﬁguration parameter spaces neural codes identical small-world chemically connected non-noisy clusters. panel identical clusters electrically connected neurons coupling strength chemical strength panel parameter space mirst panel similarly mirmφ panel similarly mirii panel mirf colors indicate maximal value nodes exchange using particular neural code. fig. study four neural codes. panels show parameter space mirst mirmφ respectively. orange corresponds couplings produce largest amounts values whereas blue black regions smallest values. intermediate values. panel mirst reveals highest values achieved large chemical intermediate electrical coupling strengths. example zero chemical coupling mirst considerably smaller around underlines importance chemical connections among clusters help system transmit larger rates information neurons exchange information precise spike-timings contrast mirmφ seems perform consistently sense parameter space panel uniformly orange spots large values. interestingly quantity becomes maximal large chemical moderate electrical coupling strengths similarly mirst. situation similar mirii becomes maximal large chemical moderate electrical coupling strengths. note maximum mirii values orange spots panel bigger order magnitude panels finally mirf still shows dependence coupling strengths achieve maximum even though maximum values smaller orders magnitude three neural codes. lastly mirf blue regions small values distributed evenly parameter space. comparing behavior various neural codes ﬁring-rate seems less advantageous respect maximum amounts transmitted information rest. results suggest prominent neurons temporal codes maximum points phases communicate maximal rate information modular neural networks chemical coupling strengths twice electrical coupling. paper sought study information encoded neural activity crucial understanding computations underlying brain functions. information encoded patterns activity within neural populations responsible similar functions interest studying related neural code read mainly understand brain processes information accomplish behavior cognitive functions. thus investigating fundamental properties neural coding networks spiking neurons allow interpretation population activity understanding better limitations abilities neural computations. studied numerically neural coding small-size networks chemically electrically coupled hindmarsh-rose spiking neurons. introduced four codes quantiﬁed rate information exchange code. quantity used measure level information exchanged mutual information rate. latter deﬁnition symmetric quantity cannot used infer directionality information ﬂow. therefore analysis cannot infer direction information exchange intensity. simplest case pairs spiking neurons found exchange largest amount information unit time opting temporal code time spike conveys information transmitted participating neuron. ﬁndings suggest ﬁring-rate interspike-intervals codes robust additive gaussian white noise. also studied four chemically electrically coupled neurons found largest rates information exchange attributed neural codes maximum points phases interspike intervals. network absence noise pairs nodes likely exchange largest amount information unit time using interspikeintervals ﬁring-rate codes adjacent network whereas spike-timings phase codes promote large rate information exchange adjacent neurons network. ﬁnding also backed similar results obtained network role chemical electrical connections swapped. results provide evidence non-local character ﬁringrate codes local character precise spike-timings temporal codes modular dynamical networks spiking neurons. becomes thus clear type neural code largest information transmission rate depends network adjacency. result possible extend larger neural networks would suggest small microcircuits fully connected neurons also known cliques would preferably exchange information using temporal codes whereas macroscopic scale typically pairs neurons directly connected brain’s sparsity eﬃcient codes would ﬁring-rate interspike-intervals codes. relatively larger network neurons arranged equal-size small-world modules form bottleneck work shows neurons choose temporal code maximum points phases transmit maximal rate information chemical coupling strengths twice electrical coupling. estimations mutual information rate based symbolic encoding trajectories thus depending encoding similar results obtained standard binary code particularly chosen time-window binary code close average interspike-intervals mirii would produce similar values binary code would encode spikes would typically encode relaxation neural activity. another possibility would reﬁnements estimation mutual information rate aiming obtaining true value each. reﬁnements would correspond search generating markov partition higher order since scope present paper leave future publication. fact sought study whether looking instantaneous spike-timings would provide less information codes based interspike intervals. decision driven question time-series events carry information? code based times events code based precise times occurrence events? here used chemical electrical synapses identical coupling strengths among model neurons. such limited study relatively simple dynamical model neurons small-size networks equal synaptic connectivity. choice made simpliﬁcation. similar study using unequal coupling strengths larger networks would allow general results would value neurophysiological perspective. lastly shown importance ﬁring-rate interspike-intervals codes spike-timings code based phases. latter codes prove prone noise contamination transmission smaller amounts information unit time increase noise intensity. work performed using maxwell high performance icsmb computer clusters university aberdeen. authors acknowledge ﬁnancial support provided epsrc ep/i/ grant. contributed work working university aberdeen then working university essex.", "year": "2017"}