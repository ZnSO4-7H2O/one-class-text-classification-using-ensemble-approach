{"title": "The geometry of learning", "tag": "q-bio", "abstract": " We establish a correspondence between Pavlovian conditioning processes and fractals. The association strength at a training trial corresponds to a point in a disconnected set at a given iteration level. In this way, one can represent a training process as a hopping on a fractal set, instead of the traditional learning curve as a function of the trial. The main advantage of this novel perspective is to provide an elegant classification of associative theories in terms of the geometric features of fractal sets. In particular, the dimension of fractals can measure the efficiency of conditioning models. We illustrate the correspondence with the examples of the Hull, Rescorla-Wagner, and Mackintosh models and show that they are equivalent to a Cantor set. More generally, conditioning programs are described by the geometry of their associated fractal, which gives much more information than just its dimension. We show this in several examples of random fractals and also comment on a possible relation between our formalism and other \"fractal\" findings in the cognitive literature. ", "text": "establish correspondence pavlovian conditioning processes fractals. association strength training trial corresponds point disconnected given iteration level. represent training process hopping fractal instead traditional learning curve function trial. main advantage novel perspective provide elegant classiﬁcation associative theories terms geometric features fractal sets. particular dimension fractals measure eﬃciency conditioning models. illustrate correspondence examples hull rescorla–wagner mackintosh models show equivalent cantor set. generally conditioning programs described geometry associated fractal gives much information dimension. show several examples random fractals also comment possible relation formalism fractal ﬁndings cognitive literature. making psychology quantitative diﬃcult feasible challenge since ﬁrst laboratory psychophysiology established wundt. making mathematical theory analytic control been possibly always utopia. nevertheless plethora analytic models able explain data coming observation subjects speciﬁc experiments. instance context behavioral theories pavlovian conditioning study interplay conditioned stimulus subsequent occurrence unconditioned stimulus typically high relevance subject food electric discharge. despite limited range applicability associative conditioning models useful several reasons. first express compact economic concepts took time many pages formulated. example fact prior activity inﬂuences value stimulus recognized since early stages functionalism translates eﬀectively description conditioning iterative process progressively modifying strength association salience stimulus. second oﬀer novel insights easily checked falsiﬁed quantitatively data experimental designs become available. question would like pose paper limited animal human behavior much expand toolbox mathematical models order extract valuable information learning processes? classic theoretical approaches simple cases conditioning cast language probability theory estes estes burke reviews bower mosteller models considers probability given conditioned response function trial number increment trial linear evaluating iteratively obtains learning curve. alternatively probability replaced strength association change variable useful phenomenological applications although mediated internal variables organism’s motivational state attention directly measured several performance indicators primis subject response. instance quality surprise function appearance ﬁrst suggested kamin relation competition single evolution novelty along learning curve made quantitative already hull salience salience magnitude intensity term indicates surprisingness decreases associative strength increases. association strength gained start trial found iteratively association made beginning ﬁrst trial ﬁxes unphysical constant −αβλ/. conditioning excitatory always occurs maximum learning achieved show conditioning inhibitory extinction. rescorla wagner extended linear model case presentation multiple discuss later. main contribution paper propose geometric interpretation learning processes carries several advantages. first useful time assessing efﬁciency processes quantitatively within given model comparing diﬀerent models. efﬁciency excitatory conditioning roughly deﬁned inverse number trials necessary increase associative strength concept subjectdependent used either compare learning diﬀerent individuals within program averaging individuals within experimental group compare diﬀerent learning programs. recognize similarity maps deﬁning cantor sets example peculiar totally disconnected sets known deterministic fractals. calculate hausdorﬀ dimension hull’s model show depends parameters smaller dimension eﬃcient conditioning. picture generalized conditioning described iterative equations giving explicit multidimensional examples include rescorla–wagner mackintosh pearce– hall models. application nonlinear sets approximate mackintosh theory model recursive equation describes slow learning intermediate trials; dimension conditioning process calculated shown greater hull model asymptotic value parameters agreement note that presence single learning rate already enough compare diﬀerent individuals programs. noting hausdorﬀ dimension depends product saliences smaller salience larger dimension. nevertheless goes beyond single-cue conﬁgurations considers complicated settings become progressively diﬃcult ambiguous deﬁne eﬀective learning rates. contrary hausdorﬀ dimension always well-deﬁned parameter provides quick compare diﬀerent individuals models. unfortunately practice calculating hausdorﬀ dimension complicated deterministic processes diﬃcult deciding eﬀective learning rates. however fractal paradigm limited deﬁnition parameter advantages here. rethinking learning processes geometric terms allow reinterpret conditioning mixture excitatory inhibitory processes rather black-or-white selection either. degree mixing determined value hausdorﬀ dimension also generalize construction random fractals essential describe experimental designs pavlovian conditioning characteristic stimuli determined random algorithms presented trials hausdorﬀ dimension cantor independent intensity fully capture eﬃciency process. obvious also give counterexample partialreinforcement program trial kept ﬁxed throughout. eﬃciency less important determination geometric shape fractal oﬀers global useful perspective number fact mappings generating fractal give prediction learning curve plateaux curve distribution determined random algorithm employed pick value parameters trial. diﬀerent randomizations hull’s model illustrate point. finally make preliminary connection results cognitive literature performance variability found follow multifractal pattern. caution comparing widely diﬀerent paradigms simulate performance variability internal origin pavlovian conditioning model salience stimuli slightly changes trial according random algorithm. since depends internal parameters determined type subject type stimuli presented cognitive-interactionist perspective hausdorﬀ dimension reinterpreted part eﬃciency process characteristics subject relation stimuli presented. again fractal geometry potential open door analysis. plan article follows. section recall basic aspects deterministic fractals. section apply formalism hull’s associative model pavlovian conditioning. section devoted generalization one-dimensional case realistic models many cues deterministically varying parameters rescorla–wagner mackintosh pearce–hall nonlinear model akin mackintosh random fractals subject section ﬂexible conditioning programs discussed section fractal construction extended important case random sets; digression cognitive experiments unveiling multifractal pattern task performance variability possible relation ﬁndings discussed section section brieﬂy explores applications fractal picture practical understanding conditioning processes experimental predictions response variability. conclusions future directions section presentation rather mathematical since borrows concepts fractal geometry considerably disorient part target readership paper namely psychologists limited mathematical background. reason summarize human language core message work. models learning looked upon uniﬁed way. change perspective respect traditional presentations inﬂuential models pavlovian conditioning hull’s rescorla–wagner’s mackintosh’s understood deterministic fractal sets. particular dimension fractal relates eﬃciency associated conditioning model. perspective links somewhat scientiﬁcally isolated elementary learning models robust framework fractal geometry illustrates potential cross-disciplinary fertilization psychological science. within framework deterministic conditioning models generalized random models learning rate consequently subject response ﬂuctuate trial trial make probabilistic predictions. construct several examples. point that regarded fractal learning processes random component generate possible values associative strength subset values. subset random fractal. eﬃcient fast conditioning characterized discontinuous process long hops point acquisition curve next. conditions inhibition completely separated process interfere acquisition. hand seems inhibition slow excitatory conditioning. statement made mathematically precise. fractals predictions. respect reordering thoughts terms fractal geometry interest theoretician epistemologist leave experimentalist skeptical practical usefulness. however fractal interpretation random models make characteristic prediction response variability must limited values associative strength included fractal set. concretely expect speciﬁc general trend response variability subject undergoing training program equivalent random fractal present trials variable salience. learning curve situations depicted respectively figs. features easily checked even qualitatively laboratory experiments present work lays theoretical ground test. similarity maps real constants point unit interval rationale behind term similarity explained shortly. image subset points cantor cantor dust given union image similarity maps instance ternary cantor deﬁnition implicit exists also explicit deﬁnition letting transformation interval being iterate shown definitions equivalent generalizable arbitrarily large ﬁnite number maps moreover generic iterated function system resulting always exists unique attractor. cantor shown fig. ﬁrst iteration interval rescaled duplicated copies copy leftmost side unit interval rightmost side. words removes middle third interval second iteration small copy contracted duplicated i.e. removes middle third copy thus producing four copies times smaller original; iterating inﬁnitely many times obtains dust points sprinkling line. figure ternary cantor iterations maps interpreted representation hull model pavlovian conditioning line range possible values associative strength developed subject trial number. thin curve learning curve connecting points corresponds excitatory conditioning process tends progressively. thin blue curve corresponds inhibition extinction tends text discuss also conditioned inhibition. self-similar inasmuch zoom multiple observe exactly structure. thus explained name similarity maps make smaller copies identical original except relative size. easy determine dimensionality cantor since dust cover whole line less dimension. naively might expect dimension zero since collection disconnected points however many points turns dimension real number particular given similarity maps ratio similarity dimension capacity formula valid exactly self-similar made copies itself size note n−/dc smaller size smaller copies iteration smaller dimensionality set. case middle-third cantor sets noninteger dimensionality called fractals term coined mandelbrot important geometric indicators used fractal geometry box-counting dimension hausdorﬀ dimension class fractals consider here embedded d-dimensional space box-counting dimension limδ→ minimum number n-balls radius centered points cover number increases decreases approaching behavior δ−db intuitively many irregularities requires balls covered number increases faster expected; example real world irregular porous surface hand surface many holes require less balls smooth one. equal capacity hausdorﬀ dimension popular among fractal dimensions calculated sets references therein] much general consider here. reason often refer together thanks equivalence cantor need deﬁnition follows thus avoiding delicate technicalities involved apply results quite standard fractal geometry simple cases hull rescorla– wagner models excitation extinction inhibition. consider conditioning experiments excitatory stimulus another stimulus inhibitory instance sound light food discharge. interpreting association strength point iteration comparing eqs. similarity ratio shift parameter hull model images correspond association strengths measured respectively excitatory inhibitory conditioning. pair hull rescorla–wagner models cantor parameters example fig. obtained actual excitatory conditioning process shown learning curve fig. branch initial condition extinction curve shown blue branch initial condition case extinction consider twophase experiment. ﬁrst phase excitatory given corresponding curve. then point measure geometry extend idea box-counting dimension case minimal covering covering sets diﬀerent size. sup{∆ diameter i.e. greatest distance points δ-cover countable ﬁnite collection sets {ui} diameter cover |ui| limδ→ |ui|s {ui} δ-cover limit exists measure s-dimensional hausdorﬀ measure hausdorﬀ measure obeys scaling property λs̺s scale factor dilation show nonincreasing exists critical value measure jumps hausdorﬀ dimension inf{s sup{s +∞}. hausdorﬀ measure diverges zero ﬁnite roughly speaking hausdorﬀ dimension scaling volume covering sets respect linear size. details found falconer blue curve corresponds ﬁrst trial second phase training association strength relates absence used phase decreases zero. case inhibitory conditioning process curve phase describes association strength pairing given conditioned stimulus phase pair second stimulus blue curve runs trials associative strength cs+cs combined conditioned stimuli decreases zero. standard inhibitory conditioning. alternatively consider backward pairing previously untrained stimulus cs−. then identify coordinate ﬁgure association strength shifted cs−. blue curve runs trace conditioning fol˜ lows similar rule. rest represents experiments trials excitatory pairing mixed trials follow learning curve change according session pattern inﬁnitely many possible experiments natural situations non-optimal learning. interpreting model pavlovian conditioning collection processes taking place fractal gain number insights described minimalistic eﬀective fashion. instance abstract notion excitation inhibition extremes opposite sign process translates precise mathematical statement. hull rescorla–wagner models excitation extinction correspond processes living respectively complementary branches cantor initial condition excit extin real world excitation inhibition symmetrical since inhibitory process must depend preceding excitation. however present case interested reformulation hull rescorla– wagner mathematical models. figure hausdorﬀ dimension measures eﬃciency conditioning. dashed line shown reference. region excluded fractal geometry acquires meaning context. fractal degenerate sense ﬁlls whole line. lower salience increases similarity ratio produces longer segments leading cantor larger dimension. strictly speaking although dimension equal since continuous line ﬁxes speak maximum occupation points canoverﬂown. however conditioning makes sense region good learning index even range values. latter consistent salience expectation that beginning training salient would actually compete rather neutral stimulus. typical salience closer value larger denominator move towards limit interpretation feature terms pavlovian conditioning straightforward. larger salience eﬃcient conditioning fewer trials needed achieve complete training. perfect training corresponds inﬁnitely many iterations eﬃcient training requires less iterations reach optimal learning. fewer trials fewer points means smaller dimension thus established capacity hausdorﬀ dimension fractal associated conditioning model decreases increase eﬃciency training. conjecture conclusion valid conditioning deﬁned iterative equations. course diﬀerent models correspond diﬀerent fractals necessarily cantor dusts. interestingly result depend magnitude another factor aﬀecting eﬃciency conditioning. must conclude capacity dimension insuﬃcient fully characterize eﬃciency λ-dependent concept. however ﬁrst step towards geometric classiﬁcation conditioning methods. purpose section illustrate without entering many details potential powerful techniques fractal geometry express context learning theory behavioral models. section considered treatments single conditioned stimulus associated strength parameter governed linear equation translated features mathematical concepts. allowed describe learning process terms completely embedded dimension i.e. line. linearity linear mappings mapping linear constant term mappings terms proportional entangled variables appearing mixed terms called nonlinear. however mathematics physics exist many one-dimensional fractals described nonlinear mappings thus breaking condition also majority fractals line need higher-dimensional embedding space thus breaking mathematically nonlinear mappings natural generalize cantor construction generic onedimensional deterministic fractals like cantor deterministic fractals deﬁned union image several maps functions contractions nonlinear called contraction exists constant inequality saturated similarity formulæ example many dynamical system studied chaos theory encoded nonlinear maps. here fractals arise rather subtle consider instance function real line constant. called logistic ﬁrst proposed model population growth certain animal species. system like called chaotic behavior strongly aﬀected value even tiny changes lead diﬀerent behaviors. values dynamics highly sensitive initial conditions acting points neighborhood quickly here following one-dimensional multidimensional refer topological dimension embedding space i.e. number independent variables entering iterative equations deﬁning fractal. embedding space ambient fractal imagined live. repeller dynamical system described invariant points outside mapped away nonlinear cantor invariant logistic diﬃcult show chaotic repeller example appreciate things deﬁned mappings nonlinear arises special points dynamical system described nonlinear logistic logistic one-dimensional nonlinear mappings used biology economics found falconer interpretative review early seminal papers chaos theory. examples multidimensional systems described mappings mixing coordinates nonlinearly fractals appear dynamical repellers baker’s transformation h´enon’s solenoid multidimensional chaotic systems applications biology economics also cryptographic systems correspondence learning models fractal geometry found section limited hull’s case. question wish extend further? fractals chaotic systems correspond learning models psychological literature mathematical complications practical interest? argue favor positive answer. section discuss precisely generalizations onedimensional condition linearity condition multidimensional models described many-variables recursive equations simpliﬁed learning scenario one-dimensional describable nonlinear equation presented section contribution limited recognize learning models multidimensional and/or nonlinear iterative systems. show associated fractals even chaos highly nontrivial form iterative equations explicit results nonlinear approximation section arguments advocate below strongly suggest fractal geometry waits beyond corner. complexity sketch future possibilities multidimensional models describe one-dimensional nonlinear generalization greater detail showing fractal. generalization fractals line multidimensional fractals captures situations learning described internal variable. simply instead having association strength related consider many association strength stimuli varying salience magnitude notice inclusion arbitrary number cues would change argument change would initial conditions would aﬀect constants similarity maps then easy multi-cue rescorla–wagner model experimental designs nonsimultaneous presentation cues trials cues large salience diﬀerent simpliﬁed model breaks analysis become considerably diﬃcult. general hausdorﬀ dimension product many sets cannot determined exactly thing bound certain combinations dimensions sets examples multidimensional systems. well-known rescorla–wagner model suﬀers several limitations among them recall predicts extinction conditioned inhibition regards extinction unlearning process thus cannot explain either spontaneous recovery eﬀects preconditioning exposure augmentation ﬁrst-trial unblocking unblocking surprising omission part compound moreover blocking eﬀect explained absence novelty pairing interpretation ruled experiment mackintosh turner latent inhibition accounted wagner ﬁrst-trial unblocking unblocking omission explained mackintosh model attention according blocking occurs because predictive redundant stimuli ignored. finally pearce hall proposed model could encompass cases explain latent inhibition well examine ﬁrst case many rescorla– wagner model proposed describe case compound stimuli case iterative evolution complicated. cues salience iterative processes replaced clearly extension single-cs case highly nontrivial presented together sessions. also diﬀerent phases might want couple diﬀerent diﬀerent uss. pair equations would augmented another identical pair diﬀerent salience asymptote possibly diﬀerent compound conditioned stimulus corresponds association strength parametrizes direction d-dimensional embedding space wherein rescorla–wagner fractal lives. much diﬃcult solve analytically stand-alone expressions depending variables mutually entangled. conceptually problem extending geometric interpretation still able construct fractal sets joining excitatory inhibitory branches. however proof involves either product one-dimensional fractals study ddimensional nondecomposable fractals cases require machinery sophisticated developed one-dimensional fractals nevertheless found simple result case presented simultaneously. begin observing twocue rescorla–wagner model solvable analytically simpliﬁed setting. consider phase experiment cues presented time trial starting generic value then exactly solve system therefore system coupled variables recast pair independent similarity maps. coupling extinction counterpart recalling obtain cantor dimension lnβ]. another copy dimension recalling hausdorﬀ dimension product proposals require quantitative modiﬁcation rescorla–wagner model replacing constant trial-dependent parameters change subject’s experience. case mackintosh model rate change assumed follow linear law. instance given cues analogous expression constant. recursive governing evolution inﬂuence stimuli encoded exclusively varies contrast rescorla–wagner prescription according size associative change depends strength stimuli according mackintosh model attention competitive based relative predictivity diﬀerent cues. illustrative purposes only interested simpler model less variables outcome unrealistic several reasons stress following simpliﬁed model regarded sketch possibility multidimensional iterative systems employed conditioning psychology admit fractal reinterpretation. moreover simpliﬁed mackintosh model prepare ground interesting generalization namely nonlinear systems. coupled constant. system two-dimensional embedding directions association strength salience although competition cannot thus apply actual mackintosh model main tenet mackintosh implemented namely varies subject’s experience depends correlation reinforcement particular case decreases associative strength increases towards asymptote contrary mackintosh two-cue model typically increases better predictor outcome presented cues. unable explicit solutions easy that compared hull learning curve model predicts slower learning intermediate trials model hybrid mackintosh pearce– hall. also pearce–hall model assumes eﬀectiveness changes predictive strength contrary mackintosh theory magnitude intensity varies experience figure learning progression excitatory conditioning light-gray circles hull’s model black squares mackintosh single-cue model gray diamonds nonlinear model αmin αmax |λn− vn−| magnitude bound range variant model ﬁxes issues original proposal expression replaced γ|λn− vn−| reﬂects idea stimuli always possibility gain access subject’s processing less surprising stimuli limited access. recursive combined βαnλn give threedimensional system three directions parametrized without speciﬁc iteration rule cannot solve system analytically. however approximately constant single-cue setting decreasing like model observed rescorla–wagner mackintosh pearce–hall models multidimensional iterative systems remains correspond fractals. said introduction section check lies range present investigation exploratory nature. however likely underlying fractal geometry exists three reasons. first visual inspection equations could revealing mathematician. second simpliﬁed core models hull’s model already neat example fractal. third model presented section approximates multidimensional models manifestly associated fractal. point generalizing one-dimensional model many dynamical variables and/or nonlinear mappings expected change geometry fractal smooth. somewhat easier still nontrivial possibility analyze learning processes one-dimensional described nonlinear recurrence equations. following example help reader appreciate abstract constructions direct applications psychology. present novelty here apart speciﬁc form geometric interpretation conditioning terms branches fractal. application show capacity larger hull’s model thus giving quantitative estimate uphill learning depicted fig. although always possible exact value dimension fractal powerful theorems make properties contractions. reader uninterested technicalities skip part directly ﬁrst step consists checking whether maps bi-lipschitz meaning exist positive ﬁnite constants bk|y ˜sk| ak|y case supx| prime denotes derivative respect system easy constants. since βαmax αmax αmin highest lowest value attained respectively then β/λ| βαmax β/λ| βαmax. assuming much diﬀerence initial ﬁnal value expressions reduce particular hull’s model αmin αmax coeﬃcients collapse next prove nonlinear model associated fractal. check important because underlying fractal approximation also mackintosh model corresponds fractal geometry yields support main claim section. show this must calculate hausdorﬀ dimension noninteger value. recalls hausdorﬀ dimension fractal bounded constants determined implicitly relations linear mappings relations suﬃcient determine nonlinear mappings least make estimate range instance consider bi-lipschitz maps excitatory conditioning salience default value αmax depends nature salience subject. excitatory training proceeds salience approaches asymptotic value αmin case extinction association strength decreases zero salience grows minimal value αmin αmax. therefore subject presented novel stimulus salience decrease αmax αmin case extinction converse happen. plugging obtain nonlinear excitatory conditioning small good approximation single-cue mackintosh model resume nonlinear model reduces hull/rescorla–wagner model lowest order approximation exactly constant. however linear dependence translates nonlinear term evolution equation association strength. figure clearly shows nonlinear model hand good approximation single-cue mackintosh’s slowly varying hand distinctly diﬀerent respect hull model conditioning described diﬀers nonlinear models described past particular pelley’s hybrid model extension rather approximation mackintosh theory. excitation branch associated fractal given contraction extinction branch given setting plugging therein αmin αmax then parameters fully determined ﬁnds taking extra iteration maps interval reﬁned third iteration maps yields fourth iteration gives diﬃcult convince oneself inequalities strict lower upper limit correspond hausdorﬀ dimension ternary cantor with respectively general saliences αmin αmax ﬁxed salience numerical iterative methods shrink range considerably. therefore nonlinear model describes less eﬃcient learning hull’s salience smaller hull’s models vice versa. conclusion obvious looking fig. made quantitative precise sense. main point however nontrivial consequence theorem cited above proves dimension noninteger. since deﬁned action contractions concludes deterministic fractal. easy generalize construction sections experiments. instance asymmetric cantor obtained nonlinear model proposed above also linear case choose diﬀerent saliences parameters also parameters vary randomly interval iteration would situation strength appearance rate governed random generator conditioning trial. therefore iteration four similarities language fractal geometry would random fractal. expect conditioning-to-fractal correspondence hold considering excitatory inhibitory branches time ideal excitatory conditioning controlled environment portion sequence iterations generating fractal point interpret whole fractal description varied pairings nature laboratory given stimuli. divide interval starting usual three equal parts remove randomly chosen then branch iteration eight options subinterval removed intervals removed central interval removed leftmost interval removed rightmost interval removed leftmost interval surviving central interval surviving rightmost interval surviving context one-dimensional conditioning constant saliences type randomization limited fact coeﬃcients completely independent ﬁxed priori change values among three possibilities diﬀerent saliences treated many diﬀerent css. randomizing algorithm pick values accommodating value i.e. either presented value cases summarized table clearly combination makes sense single-cue psychological experiment ﬁrst third line table cases excluded diﬀerent mappings all-or-no-subinterval case ruled represents conditioning all. resulting surviving procedure together excitatory extinction learning curves shown fig. corresponds controlled experimental design partial reinforcement randomized schedule either absent present either absent present figure random ternary cantor corresponding randomized hull model ﬁrst type iterations. thin solid curve learning curve excitatory conditioning partial reinforcement program. dashed curves learning curves deterministic model. value hadh deterministic case angular brackets removed eqs. recovered. similarity ratios eﬃciency conditioning increased decreasing hausdorﬀ dimension increasing towards average. already commented λ-independent capture aspects eﬃciency. instance program partial reinforcement determinist program continuous reinforcement known performance lower ﬁrst. phenomenon clearly shown fig. less fragmented fractal slower learning. thus examination detailed properties fractal said global indicator another possibility replace interval iteration subintervals iln+ irn+ random length length ratios |iln+|/|in| |irn+|/|in| independent identical probability distributions iln+ irn+ abut respectively leftright-hand obtains like depicted fig. condition optional. corresponds general situation trial change salience presented intensity salience vary presentation. could natural situation animal surrounded several dynamically evolving stimuli environment. tailoring algorithm reduce system controlled experimental design ﬂexible previous case example randomized cantor given fig. factors complicate fractal-based analysis conditioning processes random component fact independent extension multi-cue setting. factors taken account planning realistic simulation core theory. concerning ﬁrst considered case presented random schedule ﬁxed. since properties could vary depending presence absence stimulus general expects i.e. salient present. taking account modify simple partial-reinforcement model presented qualitatively later. model) trial-varying salience magnitude random-fractal construction becomes multidimensional much varied. experimental design draw unique random fractal hausdorﬀ dimension estimated usual given probability probability empty random fractals not-so-old acquaintance biological sciences found physiology neuroscience animal behavior cognitive sciences concerning latter wish comment whether formalism application connection with extant psychological literature subject. carefully order avoid hasty conclusions based apparent false analogies need make digression cognitive science. comparing random-fractal learning models theory results so-called literature acknowledgment sake record fractals already played role psychology. rather randomfractal learning models cognitive performance models variability subject response main characteristics studied experiments. understanding done found cognitive ﬁeld give orientation possible testable predictions fractal paradigm. variability human performance memory tasks reaction tasks mental rotation word naming become trend recent years review]. response subject sequence trials decomposed spectral analysis periodic components frequency experimentally found amplitude components scale frequency according power constant source phenomenon still debate. ﬁrst interpreted intrinsic uncertainty possibly estimation error formation representations mind reproduction spatial temporal intervals human memory different cognitive systems diﬀerent types idiosyncratic uncertainty combining give noise accidentally; interpretation noise general fundamental property human behavior alternative nomothetic perspective stochastic behavior speciﬁc cognitive systems mere noises fundamental mechanism cognition would happen emergence patterns self-organizing complex dynamical system. particular scaling might collective expression metastable coordination diﬀerent cognitive motor systems performance task typically variation response function trial plotted thousands trials highly rugged curve. curve graph mathematical properties certain stochastic processes found statistical mechanics anomalous transport theory processes self-similar probabilistic sense naturally associated random fractals. frequency distribution generalization number contraction maps deﬁning deterministic fractals. case random fractal spectrum values distributed integer ﬁeld. fractal dimension ambiguous concept here depends whether considering walk stochastic process trail path graph zeros path cognitive psychology usually refers trial series. precise stochastic processes interest closely describe typical trial series. fractional brownian motion fractal dimension hausdorﬀ dimension graph fractional brownian motions characterized parameter called hurst exponent produce spectrum hausdorﬀ dimension equal box-counting dimension stochastic processes reads almost surely i.e. probability different values associated various noises frequency distributions ranging ideal pink ﬂicker noise] antipersistent fbm] criticism nomothetic view found farrell wagenmakers early replies thornton gilden orden recent defense ihlen vereijken somewhat intermediate view idiosyncratic nomothetic proposed likens fine amazeen amazeen thoughts intrinsic uncertainty -scaling phenomenon role measurement psychological experiments related analogy quantum physics found holden choi amazeen orden orden kello holden special case wiener process correlation increments] persistent fbm]. process relevance triggers frequency distributions hfgn described fractional gaussian noise hurst exponent hfgn analytic continuation expression identify hfgn deﬁne fractal dimension hfgn apart case giving ideal pink noise three main regimes nonideal pink noise characterized small ﬂuctuations short time scales larger ﬂuctuations modulated longer time spans] white noise equally sized ﬂuctuations time correlation] nonideal blue noise]. value change according experimental conditions participants said above reproduces nonideal almost ideal pink noise. thus human variability performance task described random fractal dimension initial idea cognitive noise discovered internal biological clock cognitive systems involved reaction tasks generate noise motor system experimental design produce white-noise interference plane] subtle changes task demands introduce exogenous variation performance modify spectral distribution plane] representing interpreted endogenous variation. reproduce observed deviation straight line proposed look white noise data would ﬂatten noise line high frequencies however experiments carried humans failed conﬁrm layering hypothesis pointing instead towards multifractal noise diﬀerent exponents diﬀerent scales back associative models whether relation fractal structure found -scaling cognitive scenarios. conservative view connection several reasons. first associative models describe behavior pavlovian conditioning -noise eﬀect found diﬀerent cognitive tasks. second although paradigm behaviorsee holden classiﬁcation psychology falconer proof almost surely standard fractional brownian motion. still falconer also hausdorﬀ dimension trail d-dimensional brownian motion calculated almost surely psychologist-oriented review concepts multifractals multiplicative cascades special multifractal distributions points kelty-stephen palatinus saltzman dixon also nonaka bril example multifractal performance. states rules human behavior inferred animal behavior strictly speaking established range applicability associative models overlap experiments human response. third reason encompassing trying associate similar mathematical structures arising diﬀerent contexts dangerous principle guiding apart cursory resemblance. general regard associative models learning useful tools without making claim validity bits fundamental theory human mind. said that optimistic perspective cognitive behavioral psychology must agree extent approach topic albeit diﬀerent directions preliminary attempt make link without pretension rigorous notice random fractal structures found cognitive experiments compared randomized version proposal deterministic previous sections. consider random cantor obtained varying parameters randomly interval replicate much typical situation cognitive experiments cannot change intensity must remain trials. change combined cs–us salience call random cantor imagine random variation trial internal mechanisms noise superposition various cognitive systems emergence complex pattern. fig. plot random cantor desired features ﬁxed take random value interval central value corresponds deterministic ternary cantor maximal ﬂuctuation represents putative internal cognitive noise. useful make comparison mackintosh model changes trial deterministically. case random model cognitive process aﬀecting conditioning attention however mackintosh model deterministic gradient |αmax αmin| throughout duration experiment suﬀers small random variations internal ﬂickering attentional system global internal ﬂickering interaction attentional cognitive systems comparing geometric properties fractal stochastic graph discussed tricky issue since represent diﬀerent things diﬀerent types experiments. ﬁrst case fractal points corresponding possible values measured possible initial conditions i.e. suitably operationalized internal variable representing cs–us association strength subject pavlovian conditioning experiment. second case fractal actually measured statement recast terms dimension fractal associated model saliences correspond spilling line hausdorﬀ dimension high saliences correspond ordinary dust-like totally disconnected cantor reformulation gain deeper insight nature process model attempts describe. since faster learning associated sparsely populated totally disconnected points regarded process making large hops points support fractal. happens interval zeroth iteration depleted points faster iteration. another consequence dimensionality excitatory inhibitory branches mutual intersection point line uniquely associated similarity branch. sense excitatory conditioning uncontaminated inhibitory one. hand small inhibitory excitatory branches share points superposition otherwise separated processes gives rise sort contamination inhibitory branch slow learning. course acquisition rate intrinsic quality process subject-dependent feature. point theory might naturally open possibility existence cognitive interference internal workings slow-learning subject prefer leave speculations curious reader. experimental application belongs random version theory. deterministic version mathematically equivalent traditional associative models predictions deterministic-fractal picture’s predictions. however random version theory discussed section make forecast unreachable without interpreting associative models fractals pattern behavioral variations case randomly varying stimulus salience magnitude. consider case saliences magnitude take random value given distribution support seen happen diﬀerent situations controlled experimental design partial reinforcement randomized schedule natural environment subject everchanging stimuli according hypotheses forward cognitive literature random variations happen internal ﬂickering subject’s cognitive modules. distinguish general eﬀects variation parameters monotonic eﬀects ﬂuctuations subject response. takes values ﬁxed actual learning curve monotonic systematically absolute asymptote learning deterministic theoretical model simple consequence fact that subsequent copies equal smaller figure random cantor corresponding randomized hull model second type iterations picking values interval uniform probability distribution. example saliences vary trial. series responses subject cognitive task. however could interesting check would hand whether random model data better deterministic hand experiment uniting features pavlovian conditioning cognitive tasks whether application human subjects could capture modulation response could statistically related modulation found cognitive psychology. leave veriﬁcation possibility future studies. time being cannot help notice intriguing parallelism hausdorﬀ dimension fractals associated conditioning processes decreases eﬃciency conditioning hausdorﬀ fractal dimension stochastic response pattern cognitive tasks decreases improvement performance ﬁrst case better performance means faster conditioning dustlike second case better performance literally means smoother performance. quantitative theoretical description proposed yields cautious support found experimentally cognitive science notion measurable behavior characterized precise sense irregular geometry. describing geometric properties traditional conditioning models terms fractals worthwhile mathematical exercise real value discipline measured terms practical applications. mention theoretical experimental. theoretical application pertains deterministic random version theory alike diﬀerent understanding psychological process underlying conditioning. consider hull model learning rate determined product saliences intuitive salience stimuli subject takes longer acquire maximal association stimuli. seen previous iteration. smaller trials smaller scaling ratio becomes larger shift mapping becomes larger image shifted right effect smaller. probably eﬀect checked averaged data since could masked ﬂuctuations caused individual diﬀerences. carefully controlled partial reinforcement program achieve schedule presentation experimental subjects. ﬁxed salience varies randomly interval association strength either theoretical point deterministic model given iteration depending varies. creates pattern ﬂuctuations around deterministic theoretical curve course experimenter cannot control random variation salience depends variable internal subject. however formulate expectation general trend response variability. since support random fractal subset interval shifts smaller points within range points belong geometric construction process. therefore ﬂuctuations subject response predicted either large asymmetric symmetric around curve relatively small. cases ﬂuctuations progressively quickly damped curve approaches asymptote. contrary previous case features looked individual data since damped small response ﬂuctuations would easily ﬂattened averaged data. also varies randomly natural setting laboratory magnitude changed every trial also case learning curve individuals characterized certain variability. fluctuations deterministic theoretical curve follow pattern described tuned multiple products scaling ratios αnβn magnitude eventually single-variable linear nonlinear equations canaccount variety conditioning processes aware systems coupled iterative laws multiple entangled variables typical modern approaches model memory processing elements diﬀerent nodes neural graph interact nontrivially. sensitivity context complicates diﬀerent stimuli interact reﬂected later elemental theories random cantor sets corresponding randomized hull model iterations picking values interval panel bottom panel black segments portions cantor learning curve touches upon. dashed curve corresponds deterministic curve brandon crystal-clear reviews wagner wagner vogel also account conﬁgural theories]. nevertheless simple models rescorla–wagner pearce–hall exhausted usefulness. instance still topical ﬁeld research neuroscience actually coexist models error signal processing brain furthermore fractal approach resonates unfathomable intriguing ﬁndings task performance cognitive psychology discussed section extension multifractals natural direction look into since could connect analogous multiscale phenomena cognitive experiments. leads believe examples presented foundational prototypes involved paradigm. alternative toolbox fractal geometry examples hausdorﬀ dimension means rank eﬃciency conditioning subject-environment interaction random fractals descriptions variety programs even conditioning variable performance internal biological ﬂuctuations already lend promising applications.", "year": "2016"}