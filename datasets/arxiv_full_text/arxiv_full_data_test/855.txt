{"title": "Expectation Learning for Adaptive Crossmodal Stimuli Association", "tag": "q-bio", "abstract": " The human brain is able to learn, generalize, and predict crossmodal stimuli. Learning by expectation fine-tunes crossmodal processing at different levels, thus enhancing our power of generalization and adaptation in highly dynamic environments. In this paper, we propose a deep neural architecture trained by using expectation learning accounting for unsupervised learning tasks. Our learning model exhibits a self-adaptable behavior, setting the first steps towards the development of deep learning architectures for crossmodal stimuli association. ", "text": "singer sing opera. important effect learning realize incongruence expect really occurs e.g. singer suddenly starts sing death metal opera learn novel association learning process referred learning expectation makes experts associating concepts unsupervised using difference expected perceived modulatory effect learning concepts. paper introduce deep neural structure crossmodal associative learning based expectation. evaluate model crossmodal person identiﬁcation task using visual auditory information. proposed model composed channels process modality composed series convolution pooling layers able learn low-dimensional representation high-level abstract data. self-organizing network learn concurrent events modalities. additionally channel paired reconstruction channel reconstruct high-level input stimuli using low-dimensional speciﬁc representation. contrast conventional deep learning models model trained entirely unsupervised fashion continuous learning behavior. words rely large amount data learning also exhibit self-adaptive behavior application learning model real-world scenarios. proposed model composed modality channels learn facial features learn vocal characteristics. channels columns convolution pooling layers perception expectation. visual channel perception column composed three convolution layers followed pooling layer. fully connected layer representing low-dimensional visual perception. visual expectation column starts fully connected layer concept perception column. proceed similar structure visual perception column inverted. means instead pooling up-sampling operations expand dimensions information. extra convolution layer ﬁlters generate image. abstract—the human brain able learn generalize predict crossmodal stimuli. learning expectation ﬁne-tunes crossmodal processing different levels thus enhancing power generalization adaptation highly dynamic environments. paper propose deep neural architecture trained using expectation learning accounting unsupervised learning tasks. learning model exhibits self-adaptable behavior setting ﬁrst steps towards development deep learning architectures crossmodal stimuli association. crossmodal processing characteristics human brain necessary understanding world around meaningful processing crossmodal information allows enhance perceptual experience also unisensory stimuli solve associative incongruence conﬂicts learn concepts computational models crossmodal learning proposed past enhance tasks classiﬁcation regression prediction. models propose solutions crossmodal fusion early late stage e.g. using crossmodal representations increase level abstraction perception task. however models typically rely individual independent mechanisms processing unimodal representations modalities inﬂuence neurophysiological ﬁndings evidence different brain regions activated communicating also processing unisensory information development computational models brain-inspired principles crossmodal processing lead robust perception interaction mechanisms complex crossmodal environments. addition interaction modality-speciﬁc regions brain also ﬁne-tunes information using known expectation effect looking object also estimating thousands comparisons clustering similar different objects seen before. even stronger effect learning expectation occurs crossmodal information. looking woman already expects hear female voice speaks also causes overﬁtting behavior experienced examples lives grew near opera house never heard music style every time live show would expect finally train visual auditory channels adversarial learning approach. perform forward pass best-matching unit co-occurrence layer retrieve low-dimensional representations visual auditory. input expectation models. expectation model generate expected stimulus. proceed calculate training loss used train model using approach based generative adversarial network objective. generative adversarial network objective training explained generalization expectation learning. learning entities discriminator generator trained together learn distinguish fake original data generate indistinguishable fake data respectively. common problems models stabilization discriminator generator starts learn copy input data. autoencoders discriminative/generative models introduced achieved better stabilization traditional gans speciﬁcally auto-encoder loss train model instead categorical fake/not fake error. model uses concept generative auto-encoder. perception column explained encoding network expectation model decoding one. recent work generative auto-encoders propose wasserstein distance loss autoencoder reconstruction real generated data loss function approach uses similar concept instead using loss auto-encoder reconstruction wasserstein distance perceived stimuli expected one. process co-occurrence association expected stimuli reconstructed also modality present. allows train channels even channel perceived using unimodal expectation error. evaluated model using crossmodal person identiﬁcation task. enterface audio-visual challenge database contains recordings different subjects speaking phrases different emotion intonations. subject examples emotional intonations total videos frame rate frames second. feed network using always audio frame randomly chosen frames. trained model different strategies ﬁrst trained model data subject proceed evaluate model recognizes person using data. proceeded experiments unimodal multimodal stimuli. second strategy pre-trained model subjects. proceeded evaluate model learns association fig. proposed model crossmodal learning. model modalityspeciﬁc channels perception expectation columnn. self-organizing co-occurrence association model create prototype crossmodal neurons used generate expected stimuli. auditory channel similar structure also columns perception expectation. perception column three convolution layers. layers followed max-pooling operator. column fully connected layer represents low-dimensional auditory representation. audio pre-processed using hamming window stride produce spectrogram using log-fourier transform scale coefﬁcients producing spectrogram. expectation column follows structure inverted visual column. also make subsampling instead max-pooling expand dimensionality data. channels connected unsupervised layer trained self-organizing map. layer represents co-occurrence association trained using visual auditory low-dimensional representation input. concatenate representations train co-occurrence layer forward pass network. allows create prototype neurons encode crossmodal representation even modality present. max-pooling layers dimension figure shows proposed model architecture. train co-occurrence layer ﬁrst forward pass network generate low-dimensional stimuli representations. then train co-occurrence association using concatenated stimuli input. biasing layer towards representing latest stimuli make replay memory. memory stores last forward passes. helps maintain state self-organizing based previous stimuli helps forget outliers. association incongruent still present input data made fewer times congruent associations thus subject. done analyzing expectation error time behaves network learning association. purpose used -second video subject present training set. proper evaluation used person re-identiﬁcation architecture ahmed implementation uses multi-channel convolution layers identify persons used input not. slightly modiﬁed architecture using auditory channel topology make auditory identiﬁcation. baseline training network data distribution ﬁrst training strategy obtained accuracy vision audio. experiment calculated reconstructed prediction based crossmodal unimodal stimuli. results ﬁrst experiment listed table expectation error time subject exhibited figure possible error visual expectation decreases faster auditory although auditory expectation error lower ﬁrst second network. means network associated better auditory characteristics visual ones ﬁrst later visual channel learns faster. interesting behavior loss auditory stimulus grows third epoch could explained update co-occurrence layer adapting visual stimulus faster auditory one. paper shows ﬁrst steps towards development deep neural network learning crossmodal stimuli association expectation learning. network trained fully unsupervised adapts characteristics adversarial learning simulate expectation effect present human brain. stress importance self-adaptive learning model rely labeled training data. here showed preliminary experiments person identiﬁcation task unimodal crossmodal proposed model take consideration crossmodal expectation error training modulated unimodal stimuli. planning unimodal stimuli modulatory feedback crossmodal learning would improve stability model power generalization. also exploring plasticity strategies unsupervised co-occurrence layer improve learning capabilities network currently limited topology self-organizing layer. dorst cross creativity design process co-evolution problem–solution design studies vol. zhao multimodal fusion video search reranking ieee transactions knowledge data engineering vol. j.-c. c.-y. chiang chen image-based plant recognition fusion multimodal information innovative mobile internet services ubiquitous computing international conference boer schutte zhang y.-j. c.-w. kraaij blind late fusion multimedia event retrieval international journal multimedia information retrieval vol. ahmed jones marks improved deep learning architecture person re-identiﬁcation proceedings ieee conference computer vision pattern recognition", "year": "2018"}