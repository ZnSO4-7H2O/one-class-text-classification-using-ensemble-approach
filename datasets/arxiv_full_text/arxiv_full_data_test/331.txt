{"title": "Parallel replica dynamics method for bistable stochastic reaction  networks: simulation and sensitivity analysis", "tag": "q-bio", "abstract": " Stochastic reaction networks that exhibit bistability are common in many fields such as systems biology and materials science. Sampling of the stationary distribution is crucial for understanding and characterizing the long term dynamics of bistable stochastic dynamical systems. However, this is normally hindered by the insufficient sampling of the rare transitions between the two metastable regions. In this paper, we apply the parallel replica (ParRep) method for continuous time Markov chain to accelerate the stationary distribution sampling of bistable stochastic reaction networks. The proposed method uses parallel computing to accelerate the sampling of rare transitions and it is very easy to implement. We combine ParRep with the path space information bounds for parametric sensitivity analysis. We demonstrate the efficiency and accuracy of the method by studying the Schl\\\"{o}gl model and the genetic switches network. ", "text": "stochastic reaction networks exhibit bi-stable behavior common many ﬁelds systems biology materials science. sampling stationary distribution crucial understanding characterizing long term dynamics bistable stochastic dynamical systems. however normally hindered insuﬃcient sampling rare transitions metastable regions. paper apply parallel replica method continuous time markov chain accelerate stationary distribution sampling bistable stochastic reaction networks. proposed method uses parallel computing accelerate sampling rare transitions easy implement. combine parrep path space information bounds parametric sensitivity analysis. demonstrate eﬃciency accuracy method studying schl¨ogl model genetic switch network. paper apply version parrep algorithm developed continuous time markov chains accelerate simulation bistable reaction networks. furthermore algorithm allows eﬃciently sample stationary distribution starting transient regime. also investigate parametric sensitivity problem bistable reaction networks. basically study change bistable system outputs perturbations system parameters. enables quantify parametric uncertainty system robustness. point proposed version parrep easily combined path space information bounds provide useful information reductions parametric sensitivity analysis high dimensions. consider well-mixed chemical system species interacting reaction channels system size well-mixed assumption molecular population modeled dimensional ctmc numbers molecule species consumed produced reaction denoted respectively. call change caused reaction stoichiometric vector independent system size reaction channel associated propensity function probability reaction occurs inﬁnitesimal time interval vector rate constants paper suppress write propensity functions unless study parametric sensitivity respect propensity functions construct transition rate matrix markov chain stochastic reaction networks become increasingly important tool modeling complex biological chemical systems random noises. simulation real-world reaction networks using stochastic simulation algorithm computationally intractable multiscale feature systems. instance reaction networks biological cells often involve vastly diﬀerent numbers molecules different species rate constants diﬀerent reaction channels. therefore system metastable sense rarely samples reactions involving small rate constants population species. paper addresses another type metastable issue associated reaction networks. consider metastablity caused extremely rare transitions separate regions state space i.e. bistable reaction networks. discovered recently many biological physical systems exhibit bistability hence great interests understand bistable phenomenon. regarding accelerated stationary bistable distribution sampling parametric uncertainty quantiﬁcation using parallel replica dynamics method. know based sampling bistable reaction networks extremely expensive rare sampling transitions metastable regions. remedy issue parrep uses multiple parallel replicas explore transition path metastable regions controllable error. method originally designed sampling rare events molecular dynamics simulation langevin dynamics. mathematical framework parrep recently developed discrete time markov chains paper mainly interested accelerating simulation sensitivity analysis bistable reaction networks i.e. reaction networks whose pair asymptotically stable ﬁxed points separated saddle point denote neighborhood neighborhood neglect randomness network initial point placed approaches eventually. however random noise system subject rare large ﬂuctuations make concentration process away stable ﬁxed point enter neighborhood stable point. theoretical tool study type large ﬂuctuations large deviation principle ingredient rate function characterizes exponentially small probability remaining small neighborhood path i.e. small large. minimizing rate function path space called probable path. bistable reaction network sojourns long time exponentially small probability leave along probable path. sense call metastable sets since sojourn times sets exponentially long. metastability issue normally leads insuﬃcient sampling transition events consequently makes computationally prohibitive sample work stationary distribution speed sampling accelerating exit metastable sets using parallel computing. idea parrep ﬁrst introduced simulating rare events recently formalized several papers. goal section introduce parrep method accelerate simulation bistable stochastic reaction networks estimate stationary distribution. since considering ﬁxed volume section suppress superscript simplify notations. principle enables computation distribution however normally inﬁnite dimensional system cannot solved explicitly general. therefore monte carlo methods gillespie’s commonly used obtain numerical solution cme. holds suitable observables stationary distribution depends since process depends gradient respect parameter i.e. serves indicator system’s parametric uncertainty robustness. call estimation measurable ﬁrst exit time deﬁnition roughly says distribution supported initial distribution dtmc remains distributed exits existence uniqueness setting shown rigorously. consequence assuming starts ﬁrst exit time follows geometric distribution parameter i.e. moreover ﬁrst exit time exit state independent. suppose independent identically distributed replicas initial distribution denote ﬁrst exit time replica deﬁne smallest ﬁrst exit time among replicas ﬁrst result states ﬁrst exit state replicas independent total sojourn time replicas. furthermore second result guarantees joint distribution ﬁrst exit time ﬁrst exit state independent number replicas. facts suggest multiple replicas explore metastable region order accelerate sampling exit events without changing exit distribution. achieve acceleration using parallel computing. however gain eﬃciency procedure assumption replicas start case general. order sample launching parallel step preparation steps needed make process well quasi-stationary state. therefore complete cycle parrep roughly divided three steps adapt parrep procedure dtmc simulation ctmc simulating embedded chain. signiﬁcantly algorithm modiﬁed eﬀectively sample stationary distribution ctmc without detailed balance assumption. present parrep algorithm ctmc algorithm setup notations parrep algorithm follows. procedure decorrelation step summarized follows. metastable process would leave rapidly hence need launch following dephasing parallel steps. however metastable process would remain least transitions algorithm proceed dephasing step. since assume large enough process reach state obtain transitions asymptotically distributed according qsd. dynamics decorrelation step exact hence loss accuracy acceleration either step. dephasing step apply fleming-viot particle technique sample sequence initial states used subsequent parallel step. similar decorrelation step specify dephasing threshold replicas evolve transitions procedure replica leaves force restart current state anreplica similar large enough sample sequence distributed states note dephasing step contribute anything acceleration parrep comes parallel step. launch parallel replicas explore exit event sample r+k) ﬁrst exit state distribution sampling exit events replicas parallel step approximately times faster serial simulation moreover generated data replica parallel step collected order sample stationary distribution update clock time time integral note sampling reusing generated data parrep statistically correct comparing serial simulation. fact shown averaged contribution parrep cycle independent replica number provided independent distributed according qsd. accuracy parrep method relies choice decorrelation step dephasing step since parameters determine good sample parallel step. practice would never exact sampling parrep cycle hence error associated inexact sampling qsd. however large expect error suﬃciently small. fact justiﬁed following result. ﬁxed deﬁne distribution measurable i.e. distribution conditioned exit event occurred transition steps. assume dephasing step exact independent distributed qsd) averaged error sampling parrep cycle bounded constant times variation converges geometrically fast terms justiﬁes dynamics transition metastable another metastable asymptotically correct. analysis global error parrep cycles hard analyze. however numerical experiments sec. suggest parrep rather accurate algorithm long time simulation. brieﬂy discuss eﬃciency parrep ctmc. paper deﬁne speedup ratio between total computational time serial simulation parrep simulation. idealized scenario speedup factor parrep could number replica used simulation suggested properties. however practice preparation sequence initial states oﬀsets linear acceleration. heuristically eﬃciency parrep relies metastability set. strongly metastable time spent decorrelation dephasing steps negligible comparing acceleration achieved parallel step. however truly metastable parallel step would activated hence parrep equivalent ssa. fact argument formalized turns eﬃciency parrep determined focus bounding stationary sensitivity context stochastic reaction networks i.e. continuous time jump markov process. make bounds need reliable estimators sample average. note assumes dynamics starts stationary regime hence burn-in period necessary dynamics relax stationary state start sampling iaf. path space written stationary expectation special observable terms propensity functions i.e. k-th realization ergodic average. note great interests since reﬂects identiﬁability parameters cram´errao’s inequality. path space information bounds estimate stationary sensitivity bounds numerical experiments next section. section combine parrep method path-space information bounds accelerate parametric sensitivity analysis stochastic reaction networks. bounds derived using several concepts information theory. readability paper brieﬂy review concepts connections appendix recall deﬁne sensitivity analysis problem section exist several types sensitivity analysis methods ﬁnite diﬀerence likelihood ration inﬁnitesimal perturbation analysis pathwise derivative method. refer direct methods since estimate sensitivity directly. however direct estimation sensitivity extremely expensive large variances complexity applied large reactions networks. alternatively compute gradient-free upper bound sensitivity. computed sensitivity bounds used screening insensitive parameters direct methods applied remaining parameters. sensitivity analysis stochastic process stationary distribution often convenient interpret distribution path space distribution i.e. probability distribution paths time interval shown transient regime sensitivity index bounded section consider bistable examples arising chemistry systems biology. demonstrate parrep algorithm eﬃciently sample rare transitions stable equilibrium points outperforms standard signiﬁcant speedup factor. schl¨ogl model simplest example stochastic reaction networks exhibit bistability. auto-catalytic network involving three species whose population change according reaction network table following notational convention denote concentration species population concentration ﬁxed exchange chemicals material baths hence considered parameters network. therefore equivalent schl¨oglmodel species network fig. typical trajectory schl¨ogl model dashed line corresponds unstable equilibrium point multiplied system size i.e. crossing unstable state rare event. bistable nature long time simulation needed sample enough transition events system relaxes stationary distribution. apply parrep algorithm accelerate sampling long trajectories order estimate stationary distribution decompose state space metastable sets separated unstable equilibrium state state space note decomposition optimal parrep terms eﬃciency since strongly metastable. seen contradiction. fact decomposition deﬁned terms point left every time exits ¯x)) quickly pulled back left stable point dominating probability large deviation principle. hence subinterval metastable parrep ineﬃcient since parallel step activated process interval. therefore optimal choices separatrix point guarantees decomposed sets truly metastable. choose case stable equilibrium points separated unstable equilibrium point therefore schl¨ogl model exhibits time scales fast time scale corresponds relaxation stable equilibrium points slow time scale corresponds rare transitions stable equilibrium points. two-time scale feature illustrated figure standard performed figure shows estimates stationary average parrep algorithm diﬀerent choice decorrelation dephasing steps. number replicas parrep also plot numerical approximation benchmark accuracy figure seen parrep simulation approximates stationary average well decorrelation dephasing steps large consistent expectation metastable well approximated large simulation results obtained based sample trajectories. time standard simulation hours samples. demonstrate corresponding speedup factor replicas parrep outperforms standard signiﬁcant speedup factor. also study eﬃciency parrep terms number replicas. figure show estimation stationary average corresponding speedup factor. decorreation dephasing steps ﬁxed observe speedup factor increases number replicas changes however accuracy parrep independent number replicas. figure demonstrate application parrep estimate probability distribution estimated probability distribution compared probability distribution obtained approximation. plot suggests parrep rather accurate method suitable chosen. finally apply path space information bound obtain bound sensitivity index sfv. consider stationary sensitivity observable respect parameter note stochastic reaction networks simulate start transient regime i.e. initial distribution necessarily however path space information bounds assume starts stationary regime. therefore burn-in period needed process well stationary regime start sampling path space fim. computed path space conﬁdence intervals shown table note pfim useful obtaining ﬁnal sensitivity bounds also implies identiﬁability parameters cram´er-rao bound. computed .e+. resulting sensitivity bounds shown table iii. whether obtained sensitivity bounds tight enough compare approximated sensitivities. approximation obtained diﬀerentiating steady state truncating state space resulting equation linear system solved numerically. comparing sensitivity bounds approximated sensitivities observe bounds tight enough example. fact observed several examples path space information bounds always tight applied multi-scale problems. nevertheless bounds quite useful screening insensitive parameters large scale stochastic dynamical systems. demonstrate application bounds next example. table four reactions involved representation. note propensity functions functions switching variable population process mrna protein since depend volume process satisfy large volume limit however mean numbers mrna protein still satisfy following rescaled factor gives probability active state. choice parameters stable equilibrium points separated saddle point therefore genetic switching network bistable. ﬁnite noise induced rare transitions optimal decomposition state space metastable sets need analyze phase space determine separatrix metastable regions induced unlike schl¨ogl model nontrivial separatrix example since instead detect rare transitions ad-hoc. simply choose horizontal line passes saddle point boundary deﬁne metastable sets. provide heuristic explanation choice. large deviation perspective exists probable transition path transition occurs dominating probability transition would move along path. know another example study paper genetic switch network fundamental mechanism cells shift alternate gene-expression states. figure diagram network. genetic switch network on-oﬀ switch active inactive state. hence total population active inactive transition rates states depend number proteins positive feedback. following assaf roberts luthey-schulten explicitly take mrna noise account since shown presence mrna signiﬁcant impact dynamics network. list propensity function stochiometric vector reaction channel table true separatrix passes saddle point probable transition path crosses true separatrix along path suﬃciently close saddle point since points possible states suﬃciently close saddle point probable transition path cross separatrix moving depending true separatrix lies. accordingly suggests either boundary decompose state space metastable sets. readily seen choose horizontal since process much metastable direction direction. therefore decompose state space sets simulation results conﬁrm good choice decomposition. note though choice decomposition optimal since know true separatrix priori aﬀects eﬃciency accuracy parrep discuss section rigorous approach deﬁning optimal decomposition metastable sets subject ongoing work. throughout simulation genetic switch network simulation results obtained based sample trajectories. initial population molecule inactive molecule remaining species. terminal time taken suﬃciently large sampling ergodic average. ﬁrst study accuracy parrep terms decorrelation step dephasing step replicas. figure demonstrates simulation results regarding stationary means mrna protein increase. simulation results used accuracy comparison. corresponding speedup factor shown plot plot suggests number active inactive protein parameters arranged order kmin apply parrep estimate stationary sensitivity bounds observable respect parameters. order obtain bounds simestimated path space along conﬁdence interval shown table estimated observable shown table finally combine path space obtain stationary sensitivity bounds. illustrate observation sensitivity indices small visualize sensitivity bounds figure active inactive mrna insensitive parametric perturbation whereas protein tends sensitive. interested quantifying parametric uncertainty genetic switch model sensitivity bounds suggest screen insensitive combinations apply direct methods estimate remaining sensitivity number protein respect kmin note without bounds estimate sensitivities even take observables consideration. however sensitivity bounds screening need estimate much fewer sensitivities depending controlled conﬁdence level use. therefore two-step strategy signiﬁcantly reduces computational cost especially applied large scale networks. work p.p. partially supported u.s. department energy oﬃce science ofﬁce advanced scientiﬁc computing research applied mathematics program contract number desc. work t.w. partially supported darpa project wnf---. thank professor tiejun discussions genetic switches example. completeness paper give formal derivation path space information bounds transient regime stationary regime reference rigorous derivation. consider continuous time markov process stationary distribution path space measure assume absolutely continuous respect reference measure deﬁnition sensitivity indices cauchy-schwarz inequality stationary regime focus ergodic since stationary distribution also initial distribution stochastic process holds sfv. hence path space insfv sheppard rathinam khammash. pathwise derivative approach computation parameter sensitivities discrete stochastic chemical systems. journal chemical physics wang rathinam. eﬃciency girsanov transformation approach parametric sensitivity analysis stochastic chemical kinetics. siam/asa journal uncertainty quantiﬁcation angeli ferrell sontag. detection multistability bifurcations hysteresis large class biological positive-feedback systems. proceedings national academy sciences liang. adaptively biased sequential importance sampling rare events reaction networks comparison exact solutions ﬁnite buﬀer dcme method. phys. chem. dupuis ellis. weak convergence approach theory large deviations volume john wiley sons dupuis katsoulakis pantazis plech´ac. pathspace information bounds uncertainty quantiﬁcation sensitivity analysis stochastic dynamics. dykman mori ross hunt. large ﬂuctuations optimal paths chemical kinetics. journal chemical physics pantazis katsoulakis. relative entropy rate method path space sensitivity analysis stationary complex stochastic dynamics. journal chemical physics", "year": "2017"}