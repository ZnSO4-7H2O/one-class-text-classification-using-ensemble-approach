{"title": "Controlling false discoveries in Bayesian gene networks with lasso  regression p-values", "tag": "q-bio", "abstract": " Bayesian networks can represent directed gene regulations and therefore are favored over co-expression networks. However, hardly any Bayesian network study concerns the false discovery control (FDC) of network edges, leading to low accuracies due to systematic biases from inconsistent false discovery levels in the same study. We design four empirical tests to examine the FDC of Bayesian networks from three p-value based lasso regression variable selections --- two existing and one we originate. Our method, lassopv, computes p-values for the critical regularization strength at which a predictor starts to contribute to lasso regression. Using null and Geuvadis datasets, we find that lassopv obtains optimal FDC in Bayesian gene networks, whilst existing methods have defective p-values. The FDC concept and tests extend to most network inference scenarios and will guide the design and improvement of new and existing methods. Our novel variable selection method with lasso regression also allows FDC on other datasets and questions, even beyond network inference and computational biology. Lassopv is implemented in R and freely available at https://github.com/lingfeiwang/lassopv and https://cran.r-project.org/package=lassopv ", "text": "abstract motivation bayesian networks represent directed gene regulations therefore favored co-expression networks. however hardly bayesian network study concerns false discovery control network edges leading accuracies systematic biases inconsistent false discovery levels study. results design four empirical tests examine bayesian networks three p-value based lasso regression variable selections existing originate. method lassopv computes p-values critical regularization strength predictor starts contribute lasso regression. using null geuvadis datasets lassopv obtains optimal bayesian gene networks whilst existing methods defective p-values. concept tests extend network inference scenarios guide design improvement existing methods. novel variable selection method lasso regression also allows datasets questions even beyond network inference computational biology. availability lassopv implemented freely available https//github.com/ lingfeiwang/lassopv https//cran.r-project.org/package=lassopv. contact lingfei.wangroslin.ed.ac.uk supplementary information supplementary data available bioinformatics online. reconstruction gene regulation networks gene expression data major interests challenges computational systems biology opposed co-expression networks directed networks speciﬁc source target gene regulations consequently attracted increasing attention. among them bayesian networks model correlation structure among gene expression proﬁles conditional independencies them using directed acyclic graphs accurate bayesian network signiﬁcantly improve downstream analyses experimental validations predicting master regulators genes responding speciﬁc experimental conditions despite advantages bayesian networks co-expression networks false discovery control i.e. setting network sparsity threshold expected number false positive edges controlled left mostly untouched statistical hypothesis testing question. co-expression networks contain p-value every pair genes threshold chosen despite speciﬁcity. however bayesian network inference method knowledge provides spectrum continuous values fdc. instead bayesian network inference regarded either mathematical optimization problem multi-step multi-parametric test become difﬁcult. importance even itself mostly overlooked bayesian networks. consequences lacking obvious. without p-value-like variable control false discovery rate choice network sparsity hard justify statistically. even detrimental consequence sub-optimal inference accuracy group interactions favored rest statistical bias discussed detail section testing achieving would allow evaluate improve network inference methods. control false discovery paper consider bayesian network inference natural ordering genes given. case bayesian network inference reduces series individual variable selection problems unlike traditional likelihood optimization sampling algorithms approaches also easily scale large systems involving thousands genes. furthermore hampered fact dags form equivalence classes individual dags cannot distinguished observational data alone natural gene orderings prior dags typically obtained external information systems genetics context inferred using expression quantitative trait loci neighborhood gene’s transcription start site causal anchors applying regression methods particularly lasso favors sparse solutions perform variable selection candidate regulators gene obtain sparse genome-scale high-quality bayesian networks several attempts repurpose lasso regression statistical variable selection. cross-validation standard approach predictive lasso regression computationally intensive disregards variable selection scaling regularization strengths number candidate parental genes proposed offsets parents stronger selection provide upper bound false discovery. without lower bound however over-conservative still subject biases dependent number parental genes. none methods could demonstrate consistent network inference variable selection. recent developments sequential hypothesis testing regarded lasso regression hypothesis testing variable selection considering every candidate predictor separately null hypothesis assumes independent predictor p-value speciﬁc lasso statistics interest obtained. accurate p-values lasso regression variable selection would make possible bayesian networks like co-expression networks association studies. consistent fdcs across target genes would allow optimal inference accuracy self-justiﬁed network sparsity. paper develop software lassopv compute pvalue critical regularization strength every predictor starts contribute lasso regression ﬁrst time choice statistic based established criterion predictors nonzero contributions signiﬁcant stronger regularizations. also propose four statistical tests empirically evaluate reconstructed bayesian network. compare lassopv’s existing methods selectiveinference apply statistical tests reconstructed networks four low-dimensional high-dimensional simulated null real biological datasets also demonstrate bayesian networks’ advantage co-expression networks avoiding indirect regulations confounding. lassopv publicly available https //github.com/lingfeiwang/lassopv https//cran. r-project.org/package=lassopv. critical question bayesian network inference orienting regulations achieved three broad categories methods. ﬁrst known algorithm tries identify v-shaped interactions three genes propagates orientations co-expression network. second method treats every bayesian network regression model seeks best predictive network monte carlo simulations third method discussed before introduces external information order genes network inference becomes series regression problems regardless category however form products identical list gene regulations comprise bayesian network given signiﬁcance level regularization strength custom cutoff value. threshold determines network sparsity starting interaction threshold changes monotonically network gradually includes interactions ﬁnally reaches full network interactions genes). therefore every bayesian network inference method regardless category consists effectively separate sequential questions ﬁrst orient regulations answered full network value assign regulation rank signiﬁcance answered sequence and/or critical threshold become signiﬁcant network. paper focus latter question value assignment. understand lack undermine inference accuracy mentioned section consider example association study multiple diseases whose sample sizes differ. correlation coefﬁcient odds ratio used signiﬁcance measure study could account sample size differences therefore would bias towards associations diseases fewer samples. biases lead inconsistent levels different groups tests therefore reduce overall accuracy. proper signiﬁcance measure example would p-value observing correlation coefﬁcient odds ratio value ensure uniﬁed optimal accuracy across multiple tests. network inference statistical tests composite sequential much complicated simple pairwise correlations. therefore biases cannot assumed absent merely equal sample sizes tested. testing bias network inference equivalent testing random number generators cryptography. optimal prevents bias therefore non-existent candidate interactions would appear identical network inference method assign values rank randomly featurelessly. although possible feature space inﬁnite dimensions typical bias features network inference methods tend produce therefore tested random number generators example orienting interactions different numbers candidate incoming interactions different genes introduce bias especially regression based network inference. however bayesian network inferences produce list signiﬁcant interactions without specifying values rankings posing major difﬁculty empirical evaluations fdc. null hypothesis interaction equal probability signiﬁcant network sparsity. therefore target gene expected number signiﬁcant incoming interactions product potential ones false positive rate result given list signiﬁcant interactions consistent would yield testable linear relation numbers signiﬁcant possible incoming interactions. besides linearity test devise additional tests bayesian networks continuous values rankings potential interactions obtained lasso regression p-values. also account issues real data high dimensionality genomic data contamination unknown genuine interactions. used geuvadis consortium’s gene expression levels snps lymphoblastoid cell lines european individuals gene network reconstruction. limited analyses genes possess least signiﬁcant cis-eqtl expression levels every gene converted following standard normal distribution relative ranking prior subsequent analyses. used signiﬁcant cis-eqtl every gene causal anchor infer probability directed regulation pairs genes using function pij_gassist findr based inferred probability pairwise regulation constructed greedy maximal adding directed regulation time descending probability order using netr_one_greedy also findr edges create loop discarded. maximal edges represented natural prior ordering genes which together expression levels across individuals formed input lasso-based bayesian network learning. based full high-dimensional geuvadis dataset additionally derived three datasets evaluate lasso p-values bayesian network learning different conditions high-dimensional null dataset dimension constructed replacing every expression level random sample independent standard normal distribution. dataset examines performance variable selection methods high-dimensional null setting. low-dimensional null dataset similarly constructed low-dimensional geuvadis dataset replacing every expression level random sample independent standard normal distribution reﬂect low-dimensional null scenario. besides ‘spherical’ null hypothesis above section also considered ‘normal’ null hypothesis independent normal distributions variance developed package lassopv compute p-values null hypotheses. prune prior possible regulations genes need compute p-value every regulation separately target node variable selection. noting null p-values follow standard uniform distribution evaluated quality null p-values following tests kolmogorov-smirnov test evaluate null p-values separately variable selection performed test standard uniform distribution manhattan plot shows test p-values function number possible regulators p-values compared signiﬁcance threshold bonferroni correction. linearity test test whether p-values compared across different variable selections network inference choose signiﬁcance threshold pthres p-value. null hypothesis number signiﬁcant regulators every target gene would approximately follow normal distribution given threshold pthres visually examine linear relation numbers possible signiﬁcant regulators target scatter plot. test based linearity test computed goodness linear different signiﬁcance thresholds function total proportion signiﬁcant hypotheses. higher curve larger area curve indicates better fdc. since accuracy small p-values important distinguishing null non-null cases partial aurs small p-values also computed. although tests designed primarily p-values linearity tests also apply continuous statistics straightaway. histogram tests continuous statistic also compared null distribution available. tests also assume null dataset i.e. absence genuine interactions network. extend real datasets sparse real interactions lead enrichment small p-values statistics proper exclusion cutoff remove contaminations. speciﬁc treatments explained relevant results section. evaluated method dataset. given inferred maximal performed variable selection target gene computing lasso p-values potential regulators. using tests section evaluated p-values different packages different datasets. signalling pathways gene regulatory networks biological systems modeled sparse bayesian network inferred observational gene expression data superset natural ordering nodes given problem reduces series variable selections node regressed parents superset accurate p-value based would allow uniform signiﬁcance threshold across regressions therefore optimal overall accuracy network inference. evaluate different lasso p-value methods network inference ﬁrst looked baby problem low-dimensional null datasets used lassopv covtest selectiveinference prune maximal sparse dags. considering variable selections together histogram test figure lassopv produced uniformly distributed p-values null dataset. covtest highly over-conservative over-abundance p-values towards one. selectiveinference p-values over-abundantly small large high uniformly distributed agreement figures evaluated variable selections separately target gene using test lassopv maintained optimal lassopv p-values consistent standard uniform distribution low-dimensional null dataset. although selectiveinference obtained overall standard uniform distribution histogram test null p-value distributions revealed highly non-uniform many target genes. covtest accounted biased p-values performing test overall empirical p-value distribution. however null p-value distributions still differ across different target genes suggesting amount bias dependent number possible regulators. table lassopv outperformed covtest selectiveinference low-dimensional null dataset. partial aurs computed given bounds normalized unit constant function best performers shown bold. reafﬁrmed existing conclusions lassopv obtained highly linear relation numbers candidate signiﬁcant regulators especially small p-values opposed covtest selectiveinference. selectiveinference assigned many highly signiﬁcant regulators small number target genes could cause breakdown test. performances also summarized full partial aurs table evaluate different lasso p-value methods inference real gene regulation network ﬁrst looked low-dimensional geuvadis dataset section despite lack knowledge groundtruth gene regulation network sparse nature incoming regulations every gene still makes evaluation possible using tests applied null dataset. starting maximal low-dimensional geuvadis dataset ﬁrst performed overall histogram test results lassopv covtest selectiveinference compared low-dimensional null dataset three methods yielded excess small p-values reﬂecting existence genuine gene interactions. however selectiveinference excess scarce overlapped false positives high consequently selectiveinference speciﬁcity geuvadis data could resolved ﬁner choices also showed difﬁculty choosing correct selectiveinference. per-target evaluation test excluded genuine interactions discarding p-values smaller remaining interactions compared uniform distribution covtest removed bottom p-values account biased null distribution. results agreement null dataset conﬁrmed ideal lassopv remained stable higher exclusion thresholds existence genuine interactions violated null linearity lowered three methods leading method lassopv also shown methods expected violation appeared small localized fig. lassopv provided accurate covtest selectiveinference histogram tests low-dimensional null dataset. histogram histograms lasso p-values dashed lines perfectly uniform histogram size. manhattan plots test p-values lasso p-values standard uniform distribution function numbers potential regulators gene dashed lines represent test p-value bonferroni correction. high dots stars indicate p-values signiﬁcantly deviating desired distribution. goodness maximum number signiﬁcant regulators genes functions total proportion signiﬁcant regulations different signiﬁcance thresholds. higher blue linear curves indicate better across variable selection tasks. methods test methods. fig. covtest failed provide high-dimensional null dataset. layout figure test performed empirical distribution p-values covtest could provide network inference failing linearity test p-value signiﬁcance thresholds bottom covtest claimed gene regulations signiﬁcant bottom threshold ties. analysis. conﬁrmed lassopv figure highdimensional effect unavoidably biased large proportion insigniﬁcant regulations p-value= resulting p-value distribution differed notably standard uniform distribution insigniﬁcant regulations spite that remained accurate p-values<. still uniformly distributed. slight over-abundance p-values partly high-dimensional effect partly analytical approximation section simulation-based p-value computation without approximation shrank peak half lassopv also displayed accurate tests. test bottom p-values conﬁrmed lassopv’s accurate variable selection basis network inference lassopv attained highly linear relation numbers potential signiﬁcant regulators typical example conforming network reconstruction method yield linearity test. although high-dimensional effect resulted plateaus weak thresholds affect small p-values. proper network also demonstrated curve fig. lassopv provided accurate high-dimensional null dataset. histogram tests following layout figure account high dimensionality removed p-values= tested bottom p-values linearity test lassopv numbers predictors signiﬁcant predictors p-value signiﬁcance thresholds bottom potential regulations. every corresponds variable selection network inference. small p-values recall number genuine regulators every target gene. that method performances mostly agreed low-dimensional null dataset including selectiveinference continued assign highly signiﬁcant regulators small number targets. performances three methods lowdimensional geuvadis dataset agreed highly lowdimensional null dataset. several implications. first statistical tests section could also applied real gene regulation networks adjustments sparse interactions. second null dataset validated highly resemble null interactions geuvadis dataset. supported upcoming evaluations simulated high-dimensional null dataset. third continued lassopv best method fdc. high-dimensional problems lasso regression becomes underdetermined regularization strength approaches zero. machine precision prevents insigniﬁcant regulators role regression therefore biases p-values one. challenge overcome high-precision lasso solver. however would affect analysis identifying signiﬁcant regulations interested small p-values. fig. lassopv provided accurate covtest high-dimensional geuvadis dataset. layout figure besides remove effects high dimensionality geuine interactions bottom p-values evaluated tests. hand covtest could achieve highdimensional network inference. particularly nonlinear relation numbers potential signiﬁcant regulators indicated lack also manifested failed tests besides that high-dimensional effect biased covtest’s insigniﬁcant regulations towards p-value= even strongly lassopv’s conclusions hold lassopv covtest high-dimensional geuvadis dataset. accounting genuine interactions lassopv showed optimal although high dimensionality modern datasets introduces unavoidable distortions insigniﬁcant p-values groundtruth unavailable found lassopv could still provide ideal small p-values therefore unaffected high-dimensional effects. established principles tests evalute network inference lassopv’s symbolic linearity numbers candidate signiﬁcant regulators. lassopv remained optimal method high-dimensional network inference. hardly software package market capable highdimensional network reconstruction problem. knowledge available ones co-expression networks except covtest already shown highly biased. however co-expression networks well known high fprs indirectly regulated confounded genes pairwise nature. regression based methods reduce false positives accounting direct indirect effects together. tested reduction false positives lassopv comparing pearson co-expression network high-dimensional geuvadis dataset genes. using signiﬁcance threshold fig. lassopv reduced false positives co-expression networks. venn diagram regulation overlap. hypergeometric enrichment p-values total numbers signiﬁcant co-expressions lassopv networks indirect regulations indirect regulations confounding relations given step different signiﬁcance thresholds bonferroni adjusted p-value color legend b-e. colors represent different numbers direct steps indirect confounding relations step inferred network direct regulations. bonferroni corrections across interactions lassopv discovered regulations opposed co-expression network mostly overlap derived indirect regulations lassopv network connecting steps signiﬁcant direct regulations. indirect regulations -step enriched signiﬁcant co-expressions covered co-expressions adjusted p-value cutoff inclusion confounded genes much denser network enrichment co-expressions -step covering around co-expressions although high-quality gold standard available real data still found convincing evidence supporting reduction indirect confounding false positives bayesian networks particularly lassopv co-expression networks. article presented problem false discovery control bayesian network reconstruction impact inference accuracy network sparsity. designed four statistical tests evaluate reconstructed networks real genomic data. proposed method repurpose lasso regression variable selection computed p-value program lassopv consistent network inference. simulated real lowhigh-dimensional genomic datasets statistical tests revealed hidden defects covtest selectiveinference— existing variable selection methods also already known existing gwas’s consistent crucial optimal prediction accuracy. consequently evaluations advise guide application design network inference methods performed reconstructed bayesian networks continuous value merely list interactions although paper evaluated different p-values. hand hypothesis testing method variable selection lassopv potentially applicable example causal quantitative trait loci discovery supervised dimensional reduction also disciplines beyond computational biology. paper concerned obtain prior ordering gene nodes. used genotype gene expression data individuals population-based studies orient causal direction pair genes obtained dense prior dag. depending data availability prior ordering also obtained known regulatory gene function annotations regulatory interactions simply greedy maximumlikelihood optimization absence additional information similarly paper reconstructs structure bayesian network. since bayesian network reﬂects conditional dependency gene expression levels predictive model derived additional regression target gene parental genes reconstructed network. linear approximation sparse regulatory system unpenalized linear regression sufﬁce.", "year": "2017"}