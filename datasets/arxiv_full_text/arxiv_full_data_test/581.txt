{"title": "Blindfold learning of an accurate neural metric", "tag": "q-bio", "abstract": " The brain has no direct access to physical stimuli, but only to the spiking activity evoked in sensory organs. It is unclear how the brain can structure its representation of the world based on differences between those noisy, correlated responses alone. Here we show how to build a distance map of responses from the structure of the population activity of retinal ganglion cells, allowing for the accurate discrimination of distinct visual stimuli from the retinal response. We introduce the Temporal Restricted Boltzmann Machine to learn the spatiotemporal structure of the population activity, and use this model to define a distance between spike trains. We show that this metric outperforms existing neural distances at discriminating pairs of stimuli that are barely distinguishable. The proposed method provides a generic and biologically plausible way to learn to associate similar stimuli based on their spiking responses, without any other knowledge of these stimuli. ", "text": "brain direct access physical stimuli spiking activity evoked sensory organs. unclear brain structure representation world based diﬀerences noisy correlated responses alone. show build distance responses structure population activity retinal ganglion cells allowing accurate discrimination distinct visual stimuli retinal response. introduce temporal restricted boltzmann machine learn spatiotemporal structure population activity model deﬁne distance spike trains. show metric outperforms existing neural distances discriminating pairs stimuli barely distinguishable. proposed method provides generic biologically plausible learn associate similar stimuli based spiking responses without knowledge stimuli. major challenge neuroscience understand brain processes sensory stimuli. particular brain must learn group stimuli category discriminate others. strikingly feat achieved brain access noisy responses evoked sensory organs never stimulus itself. example brain receives retinal responses visual stimuli able associate together responses corresponding stimulus teasing apart ones coming distinguishable stimuli. nervous systems achieve discrimination still unclear. strategy solve problem could learn either decoding model reconstruct stimulus neural responses encoding model invert stimuli distinguished however cases requires access pairs stimuli evoked responses. clearly brain guaranteed access data access neural response without knowing corresponding stimulus. neural metrics deﬁne distance pairs spike trains proposed solve issue. general spike trains evoked stimulus close spike trains corresponding different stimuli away. using given metric associate together responses evoked similar stimuli without information stimuli themselves quality classiﬁcation relies metric well adapted task hand different metrics expected perform equally well. multiple metrics based diﬀerent features neural response proposed mostly single cells exceptionally populations metrics information correlative structure population response often require tune parameters optimize performance requires external knowledge stimulus. addition precise quantiﬁcation performance diﬀerent metrics discriminating barely distinguishable stimuli lacking. present approach learn spike train metric high discrimination capacity statistical structure population activity itself. applied method retina sensory system characterized noisy non-linear correlated responses. ﬁrst introduce statistical model retinal responses temporal restricted boltzmann machine allows learn accurate description spatio-temporal correlations population ganglion cells retina stimulated randomly moving bar. model derive metric neural responses. using closed-loop experiments stimuli tuned hardly distinguishable other show neural metric outperforms classical metrics stimulus discrimination tasks. high discrimination capacity achieved despite neural metric trained information stimulus. therefore suggest general biologically realistic method brain learn eﬃciently discriminate stimuli solely based output sensory organs. analyzed previously published vivo recordings retinal ganglion cells population cells stimulated moving recorded multielectrode array responses binarized time bins value neuron spiked given time otherwise ﬁrst aimed describe collective statistics spikes silences retinal population regard fig. experimental setup. retina stimulated moving bar. retinal ganglion cells recorded multielectrode array. model response spike trains binarized time bins. rbms direct interactions neurons. rather correlations explained interactions binary latent variables called hidden units hidden unit takes value induces collective changes excitability sub-populations cells. although tempting think hidden units non-visible neurons eﬀective variables usually correspond actual neurons; hidden units fact reﬂect multiple causes correlations direct input neighboring cells common input intermediate layers stimulus. number varied hidden units complex structures reproduced model parameters need estimated. learned hidden units model responses retinal population responding randomly moving bar. model inferred training using persistent contrastive divergence predictions compared testing predicted well neuron’s ﬁring rate well correlations pairs neurons addition predicted higher-order correlations accurately distribution total number spikes population contrast model independent neurons underestimated probability events many spikes order magnitude. model performance measured either fraction variance explained pairwise correlations model log-likelihood quickly saturated numfig. restricted boltzmann machine model predicts accurately response statistics within single time bins. models probability binarized responses single time bins. direct interactions neurons instead neurons interact hidden units single cell ﬁring rate. represents spiking frequency neuron testing versus model prediction. distribution total number spikes population time testing versus prediction model independent neurons shaded area shows standard error data. pairwise correlations. represents pearson correlation pair neurons testing versus prediction. fraction variance correlations explained models diﬀerent numbers hidden units training testing sets. mean model loglikelihood in-sample out-of-sample function number hidden units. small difference training testing sets suggests over-ﬁtting. modeled synchronous correlations neurons using restricted boltzmann machines previously applied retinal cortical populations. give probability same-time spikewords performs well modeling neural responses within time bins correlations neurons often span longer time scales. evaluate importance longer term correlations plotted distribution number spikes population time window compared prediction response population generated independently although performed better model independent neurons still underestimated probability large numbers spikes order magnitude indicating correlations longer scales play important role shaping collective response statistics. account temporal correlations introduced temporal restricted boltzmann machine model generalizes allowing interactions neurons hidden units across diﬀerent time bins want describe stationary distribution spike trains regardless stimulus absolute time irrelevant model invariant time translations connections hidden unit neuron trained trbm hidden units time connected neurons across consecutive time bins training using persistent contrastive divergence compared predictions testing set. like trbm could predict individual neuron ﬁring rates synchronous pairwise correlations addition trbm could also predict temporal correlations ignored rbm. particular reproduced accurately distribution total number spikes time window also tested trbm could predict correlations spiking activity pairs neurons time bins separated given delay. computed total variance pairwise correlations delay estimated fraction could explained trbm model predicts accurate response statistics across multiple time bins. trbm’s structure similar rbm’s neurons hidden units connected across multiple time bins. interaction neurons hidden units depends delay them schematic interactions color equal. simplicity model represented interactions delay time bins. general interactions larger time delays. single cell ﬁring rates. fig. trbm model. distribution number spikes population time window testing predicted model independent time bins independent neurons model independent rbms time trbm shaded area shows standard error data. pairwise correlation. fig. trbm model. cross-correlation. black line show variance cross-correlations neurons diﬀerent time delays. green lines show variance explained trbm respectively. fraction variance cross-correlations neurons delays explained trbm models function number hidden units training testing sets. varying maximum connection delay hidden visible units. response given stimulus intrinsically noisy. repetitions stimulus give rise distinct responses ref. response rpert perturbation reference stimulus thus hard tease apart methods). even though direct connections neurons hidden units limited trbm could explain substantial amount correlations even large delays correlations vanish. similarly found increasing number hidden units marginally improved performance beyond units time also varied maximum connection delay neurons hidden units performance quickly saturated connection delay around following consider trbm hidden units connection delay unless mentioned otherwise. hidden units trbm considered compress variability present neural activity extract relevant dimensions. asked whether hidden units could used deﬁne neural metric would follow structure population code allowing eﬃcient discrimination classiﬁcation properties. designed neural metrics derived trbm based diﬀerence hidden unit states. take responses retina deﬁne diﬀerence mean value hidden units conditioned responses covariance matrix response matrix couplings neurons hidden units. deﬁnition readily generalized trbm adding time indices note metric diﬀers euclidian distance space units modulates contribution hidden unit impact neural activity. later kernel improves discrimination capabilities. note metric deﬁned without information stimulus solely knowledge activity. next aimed test well metric discriminate pairs stimuli. evaluate capacity neural metric ﬁnely resolve stimuli based sensory response introduce measure discriminability responses distinct stimuli based neural metrics. fig. online adaptation perturbations. discriminating metrics. stimulus discrimination evaluted comparing distance responses within reference stimulus reference perturbation discrimability deﬁned probability within-stimulus distance lower across-stimuli distance closed-loop experiment. step retina stimulated perturbation reference stimulus. retinal ganglion cell responses recorded extracellularly multi-electrode array. electrode signals high-pass ﬁltered spikes detected threshold crossing. computed discriminability population response adapted amplitude next perturbation. stimulus consisted repetitions reference stimulus perturbations reference stimulus diﬀerent shapes amplitudes purple trajectories perturbations shape small large amplitude. example population response. spike represented dot. rectangle duration perturbation. shaded rectangle duration responses discriminability measured. another response reference stimulus noise given neural metric natural deﬁne discriminability perturbation probability response rpert apart response reference would responses reference rref perturbation perfectly discriminable distances reference perturbation well separated distances within responses reference discriminability approach conversely perturbations small discriminated distributions greatly overlap discriminability close corresponding chance. ﬁnely assess capacity neural metrics perform discrimination tasks need study perturbations extremes discrimination neither easy impossible. soft spot performed closed-loop experiments step discriminability perturbation analyzed order generate perturbation next step details). ﬁrst recorded multiple responses reference stimulus snippet trajectory described earlier recorded responses many perturbations stimulus given shape perturbation adapted perturbation size online searched smallest perturbations still discriminable perturbation high discriminability next step tested perturbation smaller amplitude. conversely perturbation discriminability tested larger perturbation. perturbations lasted responses analyzed delay thanks method could explore space possible perturbations eﬃciently exploring multiple directions perturbation space simultaneously obtained range responses pairs stimuli challenging impossible discriminate. method allowed benchmark diﬀerent metrics. expected discriminability increased perturbation amplitude small perturbations hardly discriminable reference stimulus large perturbations almost perfectly discriminable since metric based hidden states means hidden states informative stimulus. much better performance trbm especially small medium perturbations emphasizes importance temporal correlations shaping metric. comparison computed discriminability perturbation victor-purpura metric ﬁrst proposed neural metrics often used literature estimate sensitivity neural systems metric depends time scale parameter optimized maximize mean discriminability recorded responses. even optimization viktor-purpura metric discriminated perturbations less well either trbm metrics whose parameters optimized across perturbation amplitudes. better performance trbm metrics held stimuli compared discrimination capacity trbm metrics victorpurpura metric diﬀerent reference stimuli perturbation shapes reference stimulus perturbation shape separated responses batches medium high discriminability based linear discrimination task independent metric computed mean discriminability response batch trbm victor-purpura metrics responses discriminability batch poorly separated three metrics large majority responses medium high discriminability larger discriminability metric even larger trbm metric conﬁrming importance temporal correlations. compared trbm metrics neural metrics literature rossum angular inter-spike interval nearest neighbor event synchronization spike synchronization spike metrics well simple hamming distance binarized responses. metrics free parameters optimized maximize mean discriminability. metric computed mean discriminability batch across reference stimuli perturbation shapes responses low-discriminability batch hard distinguish metrics signiﬁcantly better chance spike synchronization spike angular trbm metrics. trbm metric discriminated responses best signiﬁcantly better second best spike metric medium high discriminability batches fig. trbm metrics outperform classical metrics discriminating responses. mean discriminability responses diﬀerent amplitudes example perturbation shape optimized victor purpura metric trbm metrics. error bars standard error. point represents mean discriminability responses medium high linear discriminability reference trajectory perturbation shape victor purpura metric. error standard error. trbm metrics. mean discriminability responses discriminability across reference stimuli perturbation shapes. error bars standard errors. stars bars show signiﬁcant diﬀerence mean discriminability stars next metric names indicate mean discriminability signiﬁcantly larger responses medium high discriminability. distance discriminability signiﬁcantly larger trbm metrics greatly outperformed metrics. strikingly medium discriminability group improvement discriminability chance level higher metric trbm metric angular metric discriminating metric literature. number hidden units indicating metric sensitive precise number provided large enough. contrast trbmbased metric using euclidian distance mean values hidden units degraded quickly number units worse performance explained fact hidden units little redundant impact activity counted equal weight euclidian disdesigned novel general method build metric neural responses sensory organs outperforms previously deﬁned metrics trying discriminate stimuli. metric called trbm metric based statistical model activity. importantly model trained unsupervised meaning knowledge stimulus required learning procedure. previous work considered possibility constructing ‘semantic’ metrics based relationship retinal response stimuli evoked them proposed clustering scheme based metric although metric clearly follows structure population code presents extreme case supervised learning building metric practice requires know probability response triggered possible stimuli brain cannot practice. contrast trbm metric discriminates stimuli well rather learned stimulus-response dictionary naturally emerges learning structure retinal code done reasonable amount data without information stimulus. constructing metric suggests realistic strategy brain learn discriminate stimuli. note many neural metrics require tune parameter values maximize performance—a supervised process uses knowledge stimulus evaluating discrimination posteriori. strikingly even optimization trbm metric outperforms metrics found literature. although motivated introducing trbm deﬁning metric statistical models population activity deserve attention right. regard trbm provides alternative existing approaches accurate tractable. spiking responses retinal ganglion cells given time strongly correlated various strategies proposed model collective synchronous activity. central eﬀort models based principle maximum entropy allow explicit mapping onto models ising spins statistical mechanics also known boltzmann machines however models often hard learn practice need additional terms non-linearities explain higherorder statistics distribution total number alternative ising models rbms applied correlated activity cortical micro-columns retina results conﬁrm ability describe synchronous collective activity retina including pairwise correlations distribution total numbers spikes. previous work also showed hidden units variant conveyed information stimulus although made possible small number used stimuli models ignore correlations spikes diﬀerent time bins play important role shown here. maximum entropy models generalized account correlations across time either practically intractable large populations focused total number spikes trbm reproduce pairwise higher-order correlations high accuracy across different time bins reasonable amount parameters relative computational ease. therefore expect trbm useful describing stimulus-independent activity neural populations variety contexts also using latent variables hidden markov model proposed describe retinal activity response controlled hidden categorical variable following markov chain however reﬂect diversity responses number categories encoded hidden variable grow exponentially population size impractical computationally biologically. contrast number conﬁgurations hidden state trbm grows exponentially number hidden units making easy application large populations. continuous latent variables also proposed account neural correlations cortical networks linear dynamical system could interesting apply models retina. however complex computational techniques needed infer them trbm relatively simple learn. work presents example unsupervised learning proves predictive supervised task reminiscent technique unsupervised ‘pre-training’ used machine learning examples available improve model performance. link machine learning suggests consider deep extensions several layers hidden variables general metrics could derived. shown deep neural networks achieve higher discrimination power rbms dealing complex stimuli natural scenes complex architectures could lead better metrics case well. fronted stimuli diﬀerent statistics possibility brain constantly re-learns metric depending visual stimulus alternatively learns universal metric performs well across wide random stimulus conditions. address question would need display several diﬀerent stimulus ensembles also design experimental procedure comparing responses pairs close enough stimuli ensemble. studying question interesting avenue future research. neural metrics explicitly estimated brain trbm metrics natural biological implementation suggests downstream population could discriminate responses diﬀerent stimuli. hidden units could implemented population downstream neurons simple response function weighted followed nonlinearity reminiscent neuron summing responses upstream cells weighted synapses’ strengths delays account time lags. shown networks spiking neurons learn synaptic weights approximate restricted boltzmann machines simplify trbm metric linearizing dependence hidden units function activity leads metric readily generalizes continuous times binning time disappears. metric simply given pairs spikes coeﬃcients depending identity spiking neurons delay them. showed simpliﬁed continuous trbm performs almost well full trbm metric continuous trbm metric could implemented simple summation spikes time delays. summary trbm provides insights biologically possible representations stimulus high discrimination capabilities without need supervised training. none properties trbm derived metric expected speciﬁc retina method could readily applied sensory neural circuits. analyzed previously published vivo recordings retinal ganglion cells male long evans brief animal killed according institutional animal care standards. retina extracted animal maintained oxygenated ames solution recorded ganglion cell side -electrode array. spike sorting performed custom software neurons selected stability spike waveforms ﬁring rates lack refractory period violation consistency fig. temporal trajectory ﬁrst second reference stimuli. perturbations diﬀerent shapes represented here added either reference stimuli varying amplitudes. fig. trbm performances aﬀected large numbers parameters. mean discriminability responses perturbations measured metric diﬀerent numbers hidden units. discriminability semantic metric increases number hidden units reaches maximum decays. contrary simpler euclidean metric discriminability responses decreases number hidden units. trbm maximum delay neurons hidden units. jectories. perturbations small changes aﬀecting reference trajectory middle portion perturbations varied shape amplitude used diﬀerent perturbation shapes presented diﬀerent amplitudes amplitude perturbations adapted online large enough could discriminated reference trajectories small enough would discriminated perfectly metric. used restricted boltzmann machines model probability responses within single time bin. statistical models direct interactions neurons. instead neurons interact binary latent variables termed hidden units. direct interactions hidden units either. call hidden unit joint probability neurons hidden units takes bold font stands vectors matrices stands transpose hidden variables necessarily correspond existing entities interacting neurons. instead eﬀective variables used capture correlations neurons. trajectory composed interleaved parts. ﬁrst part composed multiple s-long snipets random motion second part composed repetitions trajectories lasting each call reference trajectories parts generated random motion. parts alternated total learned trbm responses random trajectories hidden units inferred model using persistent contrastive divergence epochs minibatches responses length momentum coeﬃcient weight decay computation model statistics simulated order avoid model using block gibbs sampling. dependence times boundaries used cyclic boundary conditions. final model statistics computed simulations steps responses slightly diﬀerent model proposed later simpliﬁed also called temporal restricted boltzmann machine. contrary model presented here model also allows neuron-to-neuron hidden unit-to-hidden unit interactions across diﬀerent times. furthermore dependence past takes slightly diﬀerent form. time joint probability neurons hidden units ﬁeld vectors depending past values neurons hidden units. diﬀerence form consequences model computations. example possible compute exactly probability hidden states given neural responses used learning. learned responses random trajectories hidden units. inferred model maximizing likelihood using persistent contrastive divergence epochs minibatches size used momentum method known accelerate learning momentum coeﬃcient method updates parameters direction proportional likelihood gradient parameter update previous step. regularization used weight decay parameter meaning objective function maximized learning loglikelihood euclidean norm coupling parameters weighted factor computation model statistics simulated model using block gibbs sampling final model statistics computed simulations steps responses order model interactions neurons across multiple time bins complex allowing connections neurons hidden units diﬀerent time bins. call temporal restricted boltzmann machine order limit number parameters model convolutional meaning interaction neuron hidden unit depend absolute time delay them. deﬁne response neuron time probability neurons hidden units time bins takes parameters learned independently length responses considered used model responses diﬀerent lengths. visible units time boundaries depend hidden units outside boundaries. however given ﬁnitesize response still compute exactly probability order quantify well model predicted cross-correlations computed explained variance cross-correlations. ﬁrst computed variance cross-correlations diﬀerent time delays variid) varii variance across pairs neurons. ρdata computed testing fig. compute fraction explained variance across time bins. grouped crosscorrelations multiple time delays computation variance explained variance. empirical mean computed across responses training testing sets. computed likelihood responses length trbm computed likelihood responses length response population neurons consists series action potentials spike train. note population response time spike neuron neural metrics functions associate negative value pair responses such measure dissimilarity responses. following present multiple neural metrics found literature introduce metrics based trbm. metric literature deﬁned single neurons adapt population summing metric neuron. ﬁrst three metrics functional metrics responses ﬁrst mapped onto time dependent vectors metric deﬁned functional space. remaining metrics deﬁned directly spike trains. optimized maximize mean response discriminability across responses perturbations found here. constant might seem large compared time constants metrics presented below actually directly comparable scale. asymmetry rossum metric still takes spike times account limit inﬁnitely large. indeed large proportional number spikes happened opposite metrics presented depend time constant compare total number spike neuron time constant large information timing. similar equation exists trbm. temporal correlations probability responses across time bins also depends responses time bins order compute exactly distribution responses time bins needs marginalize possible responses time bins. intractable approximated probability response time bins using spike metric based spike dissimilarity proﬁle measuring diﬀerences timing spike events neuron time spike times weighted average times closest spikes response deﬁned nearest-neighbor metric victor-purpura metric edit-length metric distance spike trains minimal cost necessary transform spike train other. deleting adding spike costs whereas moving spike linear cost q∆t. optimized maximize mean response discriminability found nearest-neighbor metric measures similarity spike times given population responses in)in compute distance computing spike neuron time diﬀerence nearest spike show fig. semantic metric better discriminating responses euclidean less aﬀected redundancy parameters rbm. article always take semantic metric default unless explicitly stated. ﬁrst deﬁne metrics responses single time generalize longer responses. designed metrics distance binned responses depends diﬀerence probabilities hidden units conditioned neural responses multiple ways compute diﬀerence between distributions kullback-leibler divergence ﬁnding metric convenient computation. notice hidden units binary independent conditioned neural response semantic metric reasoned states hidden units similar trigger similar neural responses. ﬁrst deﬁne metric states hidden units takes consideration account apply measure diﬀerence mean hidden states small ﬂuctuations generated model similar inﬂuence neural responses. diﬀerent probabilities happen co-occur similar neural responses. thus chose measure distance responses σref multiple repetitions reference stimulus responses σsmax multiple repetitions largest amplitude perturbation shape computed mean response reference σref largest amplitude perturbation σsmax projected responses onto diﬀerence call xref σsmax σref) σref σsmax σref) projection response note although deﬁnition discriminability convenient doesn’t make assumption metric. supervised requires know mean response perturbation. conversely discriminability based metrics computed single response perturbation. experiment identify range perturbations neither easy hard discriminate adapted perturbation amplitudes online using accelerated stochastic approximation algorithm linear discriminability converged target value measures norm diﬀerence. order express trbm-based metric form convenient expression continuous time approximate diﬀerence using linear expansion sigmoid function dropped factor multiplying metric constant eﬀect discriminating properties. approximated continuous time euclidean metric corresponding following scalar product ackownledgements. thank david schwab insightful discussions rbms. work supported trajectory optima irreversible french state program investissements d’avenir managed agence nationale recherche european commission grant human brain project national institutes health grant uns. quiroga kreuz grassberger event synchronization simple fast method measure synchronicity time delay patterns. physical review statistical nonlinear soft matter physics schreiber fellous whitmer tiesinga sejnowski correlation-based measure spike timing reliability. neurocomputing hunter milton amplitude frequency implications dynamic gollisch meister smarter scientists believed neural computations circuits retina. arnett statistical dependence neighboring retinal ganglion cells goldﬁsh. exp. brain res. modeling higher-order correlations within cortical microcolumns. plos computational biology aronov reich mechler victor neural coding spatial phase macaque monkey. journal neurophysiology chase young spike-timing codes enhance representation multiple simultaneous sound-localization cues inferior colliculus. journal neuroscience tang maximum entropy model applied spatial temporal correlations cortical networks vitro. journal neuroscience shlens structure large-scale synchronized ﬁring primate retina. neurosci. nasser marre cessac spatio-temporal spike train analysis large scale networks using maximum entropy principle monte carlo method. stat. mech. theory exp. nakano otsuka yoshimoto doya spiking neural network model modelfree reinforcement learning highdimensional sensory input perceptual ambiguity. plos tieleman training restricted boltzmann machines using approximations likelihood gradient. proceedings international conference machine learning fischer igel introduction restricted boltzmann machines. lecture notes computer science progress pattern recognition image analysis computer vision applications mulansky bozanic sburlea kreuz guide time-resolved parameter-free measures spike train synchrony. proceedings international conference event-based control communication signal processing ebccsp", "year": "2017"}