{"title": "Pairwise maximum-entropy models and their Glauber dynamics: bimodality,  bistability, non-ergodicity problems, and their elimination via inhibition", "tag": "q-bio", "abstract": " Pairwise maximum-entropy models have been used in recent neuroscientific literature to predict the activity of neuronal populations, given only the time-averaged correlations of the neuron activities. This paper provides evidence that the pairwise model, applied to experimental recordings, predicts a bimodal distribution for the population-averaged activity, and for some population sizes the second mode peaks at high activities, with 90% of the neuron population active within time-windows of few milliseconds. This bimodality has several undesirable consequences: 1. The presence of two modes is unrealistic in view of observed neuronal activity. 2. The prediction of a high-activity mode is unrealistic on neurobiological grounds. 3. Boltzmann learning becomes non-ergodic, hence the pairwise model found by this method is not the maximum entropy distribution; similarly, solving the inverse problem by common variants of mean-field approximations has the same problem. 4. The Glauber dynamics associated with the model is either unrealistically bistable, or does not reflect the distribution of the pairwise model. This bimodality is first demonstrated for an experimental dataset comprising 159 neuron activities recorded from the motor cortex of macaque monkey. Using a reduced maximum-entropy model, evidence is then provided that this bimodality affects typical neural recordings of population sizes of a couple of hundreds or more neurons. As a way to eliminate the bimodality and its ensuing problems, a modified pairwise model is presented, which -- most important -- has an associated pairwise Glauber dynamics. This model avoids bimodality thanks to a minimal asymmetric inhibition. It can be interpreted as a minimum-relative-entropy model with a particular prior, or as a maximum-entropy model with an additional constraint. ", "text": "institute neuroscience medicine institute advanced simulation jara brain institute jülich research centre germany department physics faculty rwth aachen university germany v.rostamifz-juelich.de pairwise maximum-entropy models used recent neuroscientiﬁc literature predict activity neuronal populations given time-averaged correlations neuron activities. paper provides evidence pairwise model applied experimental recordings predicts bimodal distribution population-averaged activity population sizes second mode peaks high activities neuron population active within time-windows milliseconds. bimodality several undesirable consequences presence modes unrealistic view observed neuronal activity. prediction high-activity mode unrealistic neurobiological grounds. boltzmann learning becomes non-ergodic hence pairwise model found method maximum entropy distribution; similarly solving inverse problem common variants mean-ﬁeld approximations problem. glauber dynamics associated model either unrealistically bistable reﬂect distribution pairwise model. bimodality ﬁrst demonstrated experimental dataset comprising neuron activities recorded motor cortex macaque monkey. using reduced maximum-entropy model evidence provided bimodality aﬀects typical neural recordings population sizes couple hundreds neurons. eliminate bimodality ensuing problems modiﬁed pairwise model presented important associated pairwise glauber dynamics. model avoids bimodality thanks minimal asymmetric inhibition. interpreted minimum-relative-entropy model particular prior maximum-entropy model additional constraint. bimodality problem modiﬁed maximum-entropy model question relevance pairwise correlations presented discussed general perspective predicting activity given stimuli formalized simple mathematical terms. networks interacting units ubiquitous various ﬁelds biology limited observables accessible maximum entropy models provide unbiased construct statistical model. pairwise model uses ﬁrst moments among observables constraints therefore yields units interact pairwise manner. already level fundamental problem arises correlations average positive show maximum entropy distribution tends become bimodal. application neuronal activity bimodality artefact statistical model. explain conditions bimodality arises present solution problem introducing path collective negative feedback. result point existence homeostatic mechanism active system part observable units. understanding relation brain activity side could call state brain complex combination behaviour stimuli memory thought still partly escapes deﬁnition measurement side major goal study brain would like achieve understanding probabilistic level least. hand-waving terms could amounts assigning probabilities form given practically uncountable patterns activity brain even small region continuous spectrum even vagueness states assigning probabilities practically impossible likely stay next decades. bayesian theory deal vague large probabilities introducing statistical models simplify problem give welldeﬁned contours. example introduce models includes multi-dimensional parameter informationally screen every brain activity every state paraphrasing caves mutual information state brain activity ﬂows model parameters divide impera approach deal easily separately full probability provided parameter much fewer dimensions activity state spaces. parameter constitutes coarser suﬃcient description activity state both. example ﬁrst case could mean activities pairwise correlations neuronal population; example second could orientation light-intensity gradient retina ambient temperature. ﬁrst case model interpreted motivated neurobiologically neural code abstract viewpoint outlined useful understanding recent applications maximum-entropy method neuroscience main topic paper fact concrete example viewpoint model maximum-entropy model parameter empirical means pairwise empirical correlations activity neuronal population. choice model parameters give reasonable predictions question asked repeatedly neuroscientiﬁc literature past years. studies tested suitability maximum-entropy distribution perspective various experimental simulated activities states. studies tested suitability pairwise correlations higher-order moments parameter studies done time computing maximum-entropy distribution moment constraints usually called inverse problem simple principle amounts ﬁnding maximum convex function maximum searched variety methods convex function however involves terms. neurons roughly twice universe’s seconds modern technologies enable record hundreds neurons simultaneously convex function must therefore sampled rather calculated usually markov chain monte carlo techniques neuroscience glauber dynamics usually chosen markov chain whose stationary probability distribution maximum-entropy one. boltzmann learning iterative combination sampling maximum search still considered precise method computing maximum-entropy distribution least neurosciences knowledge methods conﬁned. diﬀerent approach approximate convex function analytic expression maximum directly study derivatives approximation. mean-ﬁeld thouless-andersonpalmer sessak-monasson approximations examples approach widely used neuroscience. approximations valid limited regions domain original convex function goodness usually checked boltzmann-learning calculation outside bayesian theory moment-constrained maximum-entropy models also used frequentist methods generators surrogate activity data glauber dynamics. surrogates pairwise maximum-entropy model used experimentally recorded activities populations couple hundreds neurons most far; success cannot automatically extrapolated larger population sizes. roudi gave evidence maximized shannon entropy comparative entropies model present qualitatively diﬀerent features particular population size. possibly also message tkačik mora terms criticality. present paper discuss feature pairwise maximum-entropy model problematic undesirable marginal distribution population-averaged activity becomes bimodal modes peak high activities. words maximum-entropy predicts population ﬂuctuate regime small fraction simultaneously active neurons another regime higher fraction simultaneously active neurons; fraction second regime high feature maximum-entropy model seems observed never remarked upon. first data reported neuroscientiﬁc literature coexistence regimes appears neurobiologically unrealistic second regime corresponds units active. second complementary problems appear glauber dynamics boltzmann-learning used model’s parameters. minimum probability maxima shallow activity alternately hovers either regime sustained periods unrealistic hence rules method generate meaningful surrogate data. minimum maxima deep glauber dynamics becomes practically non-ergodic pairwise model cannot calculated boltzmann learning approximations previously mentioned case particularly subtle undetected non-ergodic boltzmann learning still yields reasonable-looking distribution distribution gives back moments used constraints re-checked monte carlo sampling. however distribution sought pairwise maximum-entropy distribution diﬀer quantitatively also activities. subtle misleading self-consistency makes wonder whether papers apply model large populations aﬀected non-ergodicity actually pairwise maximum-entropy distribution. plan paper following mathematical methodological preliminaries show appearance bimodality problem experimental dataset activity neurons recorded macaque motor cortex. analytically tractable homogeneous pairwise maximum-entropy model give evidence bimodality aﬀects larger larger ranges datasets population size increases. example observed pearson correlations population-average larger bimodality bound appear population sizes neurons above. show experimental datasets neural-activity likely fall within bimodality ranges. also show bistability disappear inhomogeneous case become worse. analysing appearance bimodality conditions also propose eliminate using slightly modiﬁed pairwise maximumentropy distribution suﬀer bimodality problem. modiﬁed distribution interpreted arising principle minimum relative entropy respect neurobiologically motivated reference prior maximum-entropy distribution additional constraint. important property modiﬁed distribution stationarity modiﬁed glauber dynamics includes minimal asymmetric inhibition. eyes gives neurobiological justiﬁcation using modiﬁed distribution glauber dynamics. also show modiﬁed maximum-entropy distribution actual obtained boltzmann learning approximations non-ergodic case thus could distribution actually computed papers used techniques. ﬁnally bring close summary bimodality consequences justiﬁcation modiﬁed maximum-entropy model reference prior models pairwise correlations within modelling viewpoint outlined beginning section. study uses three main mathematical objects pairwise maximumentropy distribution reduced pairwise maximum-entropy distribution glauber dynamics associated them. review give additional remarks references seen elsewhere neuroscientiﬁc literature. towards paper introduce additional maximum-entropy distribution. pairwise maximum-entropy model first make mathematically clear mean activity sequences spikes neurons ﬁnite time interval spike sequences discretized divide time interval bins identical length equal indexed neuron existence spikes represented note covariance constraints mimj convex i.e. deﬁne convex subset probability simplex entropy maximized. lagrange-multiplier method guarantee uniqueness solution covariances constrained. uniqueness checked separately hand constraints separately convex thus conjunction convex bijective correspondence latter mimj guarantees latter constraints convex well. said covariances also holds correlations observer’s uncertainty quantiﬁed probability assignment physically measurable. therefore constraints trivial deﬁnitions equivalences fact particular situations make sense enforce constraints also depends uncertainty about. explain point. maximum-entropy distribution represents uncertainty population activity given time bins shown symmetry combinatorial arguments within probability calculus sometimes maximum-entropy distribution also used represent someone’s uncertainty observation time e.g. equal implies additional assumptions particular prior always justiﬁed example suppose time average coupled activity neurons vanishes enforce constraint maximum-entropy says impossible neurons spike together prediction makes sense speaking time bins fact means neurons never spiked together data prediction right. unreasonable prediction future past time part data neurons spiked simultaneously data bins cannot conclude impossible spike spiked simultaneously future past therefore constraints assume extreme values example meaningful maximum-entropy model predictions outside given dataset. case appropriate full probability calculus possibly maximum-entropy ideas abstract level contrary sometimes stated literature true maximum-entropy model used time sequence activities stationary. model represents guess activities sequence given time-average information. guess therefore time-invariant symmetry time-dependent information erased time averaging. words guess stationary physical data; still good guess given time-independent information provided. time-dependent constraints would obtain time-dependent maximum-entropy distribution application maximum-entropy principle called maximum-calibre reduced maximum-entropy model time-averaged activities homogeneous i.e. equal anpopulation average timeaveraged coupled activities also homogeneous population average pairwise maximum-entropy distribution homogeneous lagrange multipliers symmetry reduces simpler analytically tractable form simpler distribution could interpreted approximation pairwise maximum-entropy achieved disregarding inhomogeneities. also exact maximum-entropy distribution right obtained constraining expectations population sums single coupled activities reason call model reduced maximumentropy model. time-averages homogeneous reduced full pairwise model coincide. inhomogeneous case multipliers reduced model equal averages pairwise straightforward derive probability distribution population average model owing symmetry average ways possible equal probability given therefore reduced maximum-entropy model mathematically convenient lagrange multipliers easily found numerically symmetric couplings sometimes interpreted symmetric synaptic couplings biases sometimes interpreted either threshold external input controlling base activity individual neurons. reduced maximumentropy model parameters homogeneous full reduced maximum-entropy distributions give information particular dynamics like appearance metastable probable population-average states. assume uncertainty evolution population activity modelled glauber dynamics binary network choose parameters determined constraints thus generate surrogate data dynamics ergodic inﬁnite-time-average activities initial experimentally observed data. formulae pairwise maximum-entropy model similar even identical formulae lenz-ising sherrington-kirkpatrick spin model similarity useful allows borrow mathematical techniques approximations intuitive pictures developed model apply other. purposely emphasize probability-calculus viewpoint avoid explanation statistical-mechanical analogies related concepts jargon. whole analogies conceptually limitative pedagogically detrimental logical cart logical horse logical route statistical mechanics maximum-entropy probability calculus physics maximum-entropy statistical mechanics fact important diﬀerences models quantities. particular order first case lenz-ising model microscopic state unknown guess macroscopic properties; problem inference within model opposite holds pairwise maximum-entropy model microscopic state known macroscopic properties lead good guess problem inference model second lenz-ising model macroscopic quantity constraint total energy associated lagrange multiplier statistical temperature. pairwise maximum-entropy model constraints many associated lagrange multipliers. diﬀerence constraints models implies essential diﬀerences entropies; negligence diﬀerences leads variants gibbs paradox third couplings external ﬁelds appear energy lenz-ising model measurable physical quantities. mathematically similar lagrange multipliers pairwise maximum-entropy model statistical parameters cannot measured encode ignorance. λijsisj gibbs calls index probability energy. following exercise shows assume consider transition state state calculate many metres could lift weight energy diﬀerence could converted mechanical energy. diﬀerences stop using mathematical techniques problem bimodality bistability non-ergodicity ﬁrst show bistability problem subtly appears experimental data explore signiﬁcance larger population sizes. example experimental data data consists activity population neurons motor cortex macaque monkey recorded minutes using -electrode utah array. experimental setup. monkey so-called state ongoing activity i.e. sitting chair without performing task. figure shows two-second raster plot activity recorded neurons. time-varying population-summed activity shown underneath. time-averaged single coupled activities corresponding empirical covariances data shown panels population averages quantities boltzmann learning lagrange multipliers pairwise maximum-entropy model constrained single coupled activities plotted b–c. iteration sampling phase boltzmann learning timesteps; example shown note number timesteps exceeds ones used roudi factor broderick factor three. learning converges obtain lagrange multipliers whose distributions shown ﬁnal single coupled activities shown appear close experimental ones. sampling maximum-entropy distribution obtained lagrange multipliers obtain population-average probability distribution shown empirical one. tails distributions diﬀer concern now. figure experimental data empirical ﬁrstsecond-order statistics. display parallel spike recordings macaque monkey state ongoing activity. experimental data recorded -electrode utah array interelectrode distance covering area population-summed activity number active neurons within time time bins width population distribution time-averaged activities vertical line marks population average population distribution time-averaged coupled activities vertical line marks population average gij. population distribution covariances mimj. vertical line marks population average cij; positive average correlations data courtesy riehle brochier. sample distribution much longer time steps. shows happens real instance. roughly steps population jumps high-activity regime remains till sampling. discovered glauber dynamics additional metastable high-activity regime. many metastable regimes could starting dynamics states diﬀerent populationaverages metastable regimes; means actual distribution associated lagrange multipliers must bimodal. figure results boltzmann learning. population-summed activity neurons obtained glauber dynamics timesteps. couplings biases glauber dynamics lagrange multipliers shown panel found boltzmann learning experimental time-averages solid probability distribution population-summed activity sampled glauber dynamics panel blue dashed empirical distribution populationsummed activity dataset. time averages obtained boltzmann learning versus experimental ones. population distribution lagrange multipliers obtained boltzmann learning. boltzmann learning actually converged sample long enough allow exploration metastable regimes diﬀerent time-averages single coupled activities complete disagreement experimental ones. lagrange multipliers obtained therefore correct. hence probability distribution obtained initial boltzmann learning true pairwise maximum-entropy distribution. order sample probability distribution around modes estimate relative heights would need observe many jumps metastable regimes. time required observe figure longer sampling bistability. population-summed activity obtained glauber dynamics longer sampling timesteps. dashed grey line marks previous sampling population-summed activities obtained several instances glauber dynamics. instance starts diﬀerent initial population activity diﬀerent initial population represented diﬀerent shade jump seems larger timesteps impractically long. practical purposes glauber dynamics non-ergodic boltzmann learning cannot proceed cannot true pairwise distribution within reasonable times. sessak-monasson approximation correct either gives solution close erroneous boltzmannlearning one; lagrange multipliers sought-for maximumentropy distribution evidently outside radius convergence. reason initial result seemed self-consistent sampling phase brief compared time needed explore full distribution latter time long dynamics non-ergodic computational purposes. non-ergodicity eﬀectively truncates sampling states population-averaged activity trough metastable regimes. words lagrange multipliers found belong truncated distribution question whether correct sought-for maximum-entropy distribution also bimodal boltzmann learning simply encountered bimodal distribution search correct space probabilities. make educated guess examining analytically tractable reduced maximum-entropy model using population-averaged single coupled activities constraints numerically lagrange multipliers reduced model note case sampling involved distribution calculated analytically values correct within numerical precision maximization procedure values expected single couple activities re-obtained explicit summation corresponding reduced maximum-entropy distribution agree values seven signiﬁcant ﬁgures. resulting reduced maximum-entropy distribution populationsummed activity shown together experimental time-frequency distribution data. shows second maximum roughly activity. exact analysis small-population cases analysis large-population cases maximum-entropy model constrained population variance second moments corresponding constraining discussed here) show reduced maximum-entropy model bimodal full inhomogeneous model also bimodal heightened second mode shifted towards lower activities respect reduced model. shortly propose solution eliminate bimodality. basic idea behind solution easily grasped ﬁrst presenting intuitive picture bimodality arises. point view network couplings biases whose evolution described glauber dynamics bimodality associated bistability appear couplings positive average symmetric making network excitatory one. positivity couplings appears average correlation neurons positive symmetry couplings also essential factor. consider neuron average projects neuron inhibitory average activation average inhibit neurons coupled owing coupling symmetry inhibitory average neurons inhibited average excited. self-regulatory feedback loops possible networks asymmetric couplings impossible case excitation lead regimes higher activity. phenomenon agrees known role inhibitory neurons controlling irregular activity inhibition-dominated regimes naive mean-ﬁeld analysis also conﬁrms this. naive mean-ﬁeld approximation imagine neuron coupled ﬁeld representing mean activities neurons given couplings biases mean activities must satisfy homogeneous case reduce equation tanhλr ¯m+µr] correspond intersection functions line curve tanhλr depends parametrically lagrange multipliers data curves curves intersect diﬀerent values meaning solutions self-consistency equation corresponding diﬀerent mean activities. approximately correspond maxima probability distribution population average figure reduced maximum-entropy model mean-ﬁeld picture. solid probability distribution population-summed activity given reduced model dataset note probability maxima. blue dashed empirical distribution population-summed activity dataset. populationsummed activities obtained several instances glauber dynamics associated reduced model homogeneous couplings biases instance starts diﬀerent initial population activity diﬀerent initial population represented diﬀerent shade illustration selfcoupled symmetric network self-excitatory average. arrow-headed blue lines represent excitatory couplings; circle-headed lines represent inhibitory couplings. self-consistency solution naive mean-ﬁeld equation illustrated diﬀerent larger causes additional intersections corresponding additional unstable additional stable solution. curve corresponds calculated experimental data bistability ranges population size appearance bimodality peculiar experimental dataset expected experimental datasets neuronal activities? disappear larger neuronal populations become prominent? need answer questions whether general problem. make educated guess using reduced maximum-entropy model distribution elementary study convexity properties shows distribution minimum interior none depending values parameters distribution probability maxima minimum value conditions γ/dx gamma function express population-averaged single activity pearson correlation typically used literature terms using deﬁnitions probability finally obtain important shows maximum-entropy distribution bimodal larger ranges mean activities correlations population size increases. empirical population-averaged quantities hand change population size sampled biologically homogeneous neural population. means even maximum-entropy predict bimodal distribution measured activities correlations particular small sample predict bimodal distribution larger sample similar experimental setup. phenomenon shown keeping constraints ﬁxed distribution maximum activity bimodality inhibition maximum-entropy second probability maximum high activity appears. probability second maximum increases sharply thereafter maintains approximately stable value roughly times smaller low-activity maximum. minimum modes becomes deeper deeper increase mentioned previous section exact studies small samples studies large samples diﬀerent reduced model takes account population-variance second moments indicate high-activity maximum inhomogeneous case larger shifted towards lower activities also seen adding gaussian jitter multipliers reduced case making inhomogeneous. results shown c–d. basin attraction second metastable regime shifted lower activities transitions metastable regimes become likely larger jitters. means inhomogeneity makes minimum modes shallower. obtained distribution mathematically identical boltzmann distribution sherrington kirkpatrick inﬁnite-range spin-glass systematic analysis eﬀect inhomogeneity could therefore employ methods developed spin glasses population-averaged activity pearson correlation data fall within bimodality range expected. important question whether dataset typical representative bimodality problem outlier. easy question answer kind experimental data still rare take reference data summarized table cohen kohn reports ﬁring rates spike-count correlations rsc. reported ﬁring rates correspond population-averaged activities ranging time-bins. need estimate pearson correlation spike-count correlation rsc. particular cases crossi.e. number spikes neuron time window metric also equals area times crosscorrelogram neurons spike count correlation corresponds pearson correlation several studies report either measured values rccg diﬀerent windows measured cross-correlograms. analysis approximately rsc/ take rsc/ safest-case value figure bimodality ranges reduced model eﬀects inhomogeneity. reduced maximum-entropy model yields distribution either unimodal bimodal depending number neurons values curve) yielding bimodal curves symmetric respect shown). note range constraints yielding bimodality increases coloured dots show experimental constraints dataset diﬀerent time-binnings widths probability distributions reduced model population-summed activity obtained keeping constraints ﬁxed using diﬀerent population-summed activities several instances glauber dynamics normally-distributed couplings biases means standard deviations instance starts diﬀerent initial population activity diﬀerent initial population represented diﬀerent shade note basins attraction metastable regimes wider homogeneous case panel larger standard deviations jumps metastable regimes become frequent indicating minimum modes becomes shallow increasing inhomogeneity. data points indicative value suggest dataset outlier bimodality problem. data recorded population neurons would yielded bimodal pairwise maximum-entropy model. bimodality problem consequences need taken seriously. eliminate cohen kohn plotted upon curves separating bimodal unimodal maximum-entropy distributions plot suggests typical experimental neural recordings neurons likely lead bimodal maximum-entropy pairwise distributions. increases second mode becomes pronounced minimum modes shallower particular population size bimodality cannot dismissed small mathematical quirk. boltzmann-learning procedure based glauber dynamics becomes practically non-ergodic lagrange multipliers model diﬃcult impossible ﬁnd. finally fact position height second mode depend goes basic statistical expectations. consider neurons sample chosen unsystematic larger population maxima probability assignments population averages sample larger population roughly coincide mentioned intuitive understanding bimodality glauber dynamics mean-ﬁeld picture glauber-dynamical viewpoint jumps high activities happen couplings positive average symmetric making network excitatory one. positivity couplings inevitable corresponds experimentally observed positive average correlation. symmetry hand mathematical feature pairwise model made ungranted parallel synaptic couplings would realistic feature. answer simple connecting neurons single inhibitory neuron instantaneously activates whenever average activity exceeds threshold value upon activation inhibitory neuron sends inhibitory feedback neurons algorithm inhibited glauber dynamics explained materials methods section. results simulations inhibited glauber dynamics shown c–d; cases inhibitory coupling inhibition threshold reduced homogeneous case couplings biases bistability inhomogeneous case same normally distributed bistability c–d. either case additional inhibitory neuron eliminated bistability leaving stable low-activity regime. furthermore also case inhomogeneous couplings biases caused quasi-non-ergodic behaviour ﬁrst boltzmann learning results addition inhibitory neuron eliminates second metastable state summary asymmetric coupling additional inhibitory neuron clearly eliminates bistability glauber dynamics. works network size appropriate choice inhibitory coupling threshold figure asymmetric inhibition elimination bimodality nonergodicity. illustration self-coupled network additional asymmetric inhibitory feedback. neuron receives inhibitory input additional neuron whenever population-average becomes greater inhibition threshold populationsummed activities several instances inhibited glauber dynamics homogeneous used instance starts diﬀerent initial population activity diﬀerent initial population represented diﬀerent grey shade note disappearance thanks inhibition bistability evident unhinibited case analogous panel inhomogeneous normally distributed couplings biases unhinibited case note disappearance thanks inhibition bistability evident activities ﬁgure. comparison longer glauber sampling couplings biases obtained ﬁrst boltzmann learning inhibited-glauber sampling couplings biases comparison conﬁrms inhibition eliminates second metastable regime makes glauber dynamics ergodic. time averages obtained boltzmann learning inhibited model versus experimental ones. probability distribution population-summed activity given inhibited model dataset compared previously given reduced model asymmetric inhibition expressed reference prior eliminated second mode. pairwise maximum-entropy model stationary distribution glauber dynamics symmetric couplings. modiﬁed latter asymmetric way. stationary distribution inhibited glauber dynamics cannot therefore pairwise maximum-entropy model. turns however still maximum-entropy model following form coupling strength inhibitory neuron neurons activation threshold inhibitory neuron heaviside step function. call inhibited pairwise maximum-entropy model. distribution assigns decreasing probabilities states average activities probability interpreted arising detailed model know external inhibitory units make activities threshold increasingly improbable interpretation parameters chosen priori. constraint tail ﬁrst moment speak probability population-averaged activity determines whether right tail small heavy probability. also seen constraint higher moments owing interpretation parameter lagrange multiplier associated constraint hence determined data; parameter still chosen priori. note however experimental data likely give vanishing time average interpretation therefore used care reasons discussed inhibited model includes shimazaki’s model simultaneous silence constraint limit limit shimazaki’s model sharp jump probability gives whereas inhibited model presents kink discontinuity derivative proportional ﬁrst boltzmann-learning calculation results shown returned distribution reproduced desired constraints distribution turned true pairwise maximum-entropy truncated version owing bimodality true pairwise distribution resulting non-ergodicity. decided apply inhibited pairwise maximum-entropy model data instead pairwise sought lagrange multipliers boltzmann learning results would clear inhibitory neuron would allowed jumps higher activities unlike time would inﬂuenced dynamics sampling phase boltzmann learning would suﬃcient. conﬁrm applying boltzmann-learning procedure multipliers inhibited model resulting multipliers close constraints satisﬁed results obtained non-ergodic boltzmann learning therefore incorrect pairwise maximum-entropy model therefore reinterpreted correct results inhibited pairwise maximum entropy model appropriately chosen important work literature unknowingly aﬀected non-ergodicity. summary pairwise maximum-entropy model applied experimental neuronal data populations neurons likely give bimodal probability distribution population-averaged activity provided evidence claim starting experimental dataset looking summarized data literature. ﬁrst mode observed data. second mode appear high activities height increases population size. presence second mode problematic several reasons know second mode never observed experimental recordings surely high activity data neurons spike simultaneously unheard unrealistic prediction pairwise model. certain population sizes second mode cannot dismissed small recorded becomes pronounced increases minimum separates main mode becomes shallower. boltzmann-learning procedure based asynchronous glauber dynamics becomes practically non-ergodic already population sizes roughly neurons lagrange multipliers pairwise model diﬃcult impossible ﬁnd. approximate methods like mean-ﬁeld thouless-anderson-palmer sessak-monasson also seem break case. gave intuitive explanation second mode appears pairwise model given positive pairwise correlations corresponds network excitatory average symmetric. symmetric connectivity incompatible presence subset neurons inhibitory eﬀect receive excitatory input explanation also suggested eliminate second mode adding minimal asymmetric inhibition network guise additional asymmetrically coupled inhibitory neuron defence inhibited model already argued length bimodality problem application pairwise model dwell discussion. wish stress though presence bimodality non-ergodicity easily unnoticed. urge researchers boltzmann learning mentioned approximations check presence bimodality non-ergodicity starting sampling diﬀerent initial conditions high activities looking bistable regimes problem sampling techniques markov chains diﬀerent glauber diﬀerent readers draw diﬀerent conclusions presence bimodality. dismiss abandon whole pairwise model ﬂawed. still want bimodality notwithstanding. look maximum-entropy-inspired alternatives. presented alternative inhibited pairwise maximumentropy model interesting alternative least reasons. first inhibited distribution stationary glauber dynamics pairwise couplings. consider pairwise models additional constraints stationary gibbs samplers higher-order couplings thus lose analogies real neuronal networks. readers actually object usefulness inhibited distribution exactly derived particular prior minimum-relative-entropy thus appear less non-committal less unstructured bare maximum-entropy one. would like brieﬂy counter argument pointing bare maximum-entropy quite committal reference priors correct that. statement maximum-entropy method gives maximally noncommital probability distribution consistent given information variations thereof frequently repeated literature. many qualiﬁcations behind statement especially behind terms noncommittal information. term information mean experimental data also means knowledge assumptions underlying speciﬁed problem variables implied. maximum-entropy problem implies many underlying assumptions already experimental data taken account concrete assumption underlying bare maximum-entropy principle applied neuronal activity recorded neurons sample larger population neurobiologically similar neurons. easy expose assumption homogeneous case. assume neurons sample larger population maximum-entropy principle requires moment constraints applied average full population sample marginal distribution sample maximum-entropy distribution. assumption quite strong neurobiologically unrealistic seem bothered researchers applied maximum-entropy samples; maybe escaped attention. case shows bare maximum-entropy principle non-committal unstructured. committal nature bare maximum-entropy also appears derivation probability calculus. derivation requires particular prior could other quite natural priors probability assigned total activity therefore uniform apply maximum-entropy principle total activity directly instead gives uniform probability applications principle consistent diﬀerent assumptions structure biophysical problem. information implicit ﬁrst application speciﬁed second using minimum-relative-entropy method non-uniform prior distribution assigning probability implicit assumptions however like sampling assumption previously discussed cannot corrected reference priors. necessity reference priors reﬂecting deeper assumptions wellknown maximum-entropy image reconstruction example astronomical sources skilling remarked bare maximum-entropy surprised isolated stars astronomers analogous remark made case bare maximum-entropy surprised many inactive neurons tries make active ones creating second maximum break constraints. neuroscientists surprised inactive neurons. bare maximum-entropy assumes abstract units whose states symmetrically exchangeable. neuroscientists know units neurons whose individual collective properties asymmetric respect state exchanges biophysical reasons. prior inhibited model reﬂects asymmetry. fortunate partially correct symmetry assumption bare maximum-entropy using prior without overturn whole space variables. long argument shows hope inhibited model reference prior break non-committal nature maximumentropy principle; rather prevent maximum-entropy committing unrealistic assumptions. inhibited model therefore quite useful realistic hypothesis check measure prominence correlations simulated recorded neural activities. back picture conclude returning general modelling point view outlined introduction. original goal simplify intermediate models multi-dimensional parameter neurobiologically sound mathematically manageable. next step establish models probable given observed activities prior probabilities assign models. determining factor usually called evidence. last step adamantly explained discussed beautiful paper mackay pairwise maximum-entropy model inhibited pairwise maximum-entropy model presented paper examples consider higher-moment maximum-entropy models models deeper underlying assumptions even models based maximum-entropy all. last step question importance pairwise higher-order correlations maximumentropy models general acquires full meaning given precise answer. deﬁnition glauber dynamics show temporal process able sample distribution temporal dynamics called glauber dynamics. example markov chain space binary spins time step spin chosen randomly updated update rule pairwise maximum-entropy distribution stationary markov dynamics above. proof obtained case proof given below inhibited pairwise maximum-entropy model. inhibited glauber dynamics network neurons states additional neuron state dynamics determined following algorithm starting time step states step units chosen unit probability stationary distribution inhibited glauber dynamics. modiﬁed maximum-entropy distribution stationary distribution slightly modiﬁed version dynamics update rule simulation glauber dynamics nest neuron model ginzburg_neuron nest implements glauber dynamics parameters gain function chosen appropriately. grateful alexa riehle thomas brochier providing experimental data sonja grün fruitful discussions interpretation. work carried framework joint international associated laboratory marseilles inm- jülich. partially supported young investigator’s group vh-ng helmholtz portfolio theme smhb grant network simulations carried nest pglpm thanks forschungszentrum librarians always prompt eﬃcient help ﬁnding arcane scientiﬁc works miri mari encouragement aﬀection buster ﬁlling life inspiration developers maintainers latex emacs auctex miktex inkscape biorxiv arxiv philsci sci-hub making free unﬁltered science possible. roy. stat. soc. discussion lindley mclaren kadane dickey rizvi harding barnard bickel degroot fraser galbraith geisser godambe hinkley kud¯o mardia mouchart nimmo-smith novick donald rubin wijsman author; http//distancecovariance.googlecode.com/svn/trunk/ references/conditional%independence%in%statistical%theory.pdf. wolfgang spohn. stochastic independence causal independence shieldability. philos. logic http//www.uni-konstanz.de/philosophie/ files/_spohn_stochastic__cd.pdf. judea pearl. probabilistic reasoning intelligent systems networks plausible inference. morgan kaufmann series representation reasoning. morgan kaufmann francisco rev. second printing edition stefano panzeri simon schultz alessandro treves edmund rolls. correlations encoding information nervous system. proc. soc. lond. http//people.sissa.it/~ale/pan+ a.pdf. kenji doya shin ishii alexandre pouget rajesh rao. bayesian brain probabilistic approaches neural coding. computational neuroscience. press cambridge stefano panzeri jakob macke joachim gross christoph kayser. neural population coding combining insights microscopic mass signals. trends cognit. sci. steﬀen lauritzen. extreme point models statistics. scand. statist. discussion barndorﬀ-nielsen philip dawid persi diaconis søren johansen reply. larry bretthorst. maximum entropy method moments bayesian probability theory. inst. phys. conf. proc. http//bayes. wustl.edu/glb/bretthorsthistograms.pdf. claude elwood shannon. mathematical theory communication. bell syst. tech. http//cm.bell-labs.com/cm/ ms/what/shannonday/paper.html http//www.cparity.com/it/demo/external/ shannon.pdf. devinderjit singh sivia. bayesian inductive inference maximum entropy neutron scattering. alamos science http//www.fas.org/sgp/ othergov/doe/lanl/pubs/number.htm. probability theory logic scied. ence. larry bretthorst; http//omega.albany.edu/jaynesbook.html http// omega.albany.edu/jaynesbookpdf.html http//www-biba.inrialpes.fr/ jaynes/prob.html; ﬁrst publ. imre csiszár paul shields. information theory statistics tutorial. foundations trends communications information theory http//www.renyi.hu/~csiszar/. elad schneidman michael berry ronen segev william bialek. weak pairwise correlations imply strongly correlated network states neural population. nature arxivq-bio/ http//www.weizmann.ac.il/neurobiology/labs/schneidman/the_schneidman_ lab/publications.html. einat granot-atedgi gašper tkačik ronen segev elad schneidman. stimulusdependent maximum entropy models neural population codes. plos computational biology arxiv.. jonathon shlens greg field jeﬀrey gauthier matthew grivich dumitru petrusca alexander sher alan litke chichilnisky. structure multi-neuron ﬁring patterns primate retina. neurosci. also correction jakob macke manfred opper matthias bethge. eﬀect pairwise neural correlations global population statistics. technical report max-planckinstitut biologische kybernetik tübingen http//www.kyb.tuebingen. mpg.de/publications/attachments/mpik-tr-_%b%d.pdf. elad ganmor ronen segev elad schneidman. sparse low-order interaction network underlies highly correlated learnable neural population code. proc. natl. acad. sci. http//www.weizmann.ac.il/ neurobiology/labs/schneidman/the_schneidman_lab/publications.html. hideaki shimazaki kolia sadeghi tomoe ishikawa yuji ikegaya taro toyoizumi. simultaneous silence organizes structured higher-order interactions neural populations. sci. rep. yasser roudi joanna tyrcha john hertz. ising model neural data model quality approximate methods extracting functional connectivity. phys. rev. arxiv.. jakob macke lars buesing john cunningham byron krishna shenoy maneesh sahani. empirical models spiking neural populations. advances neural information processing systems jakob macke iain murray peter latham. estimation bias maximum entropy models. entropy http//www.gatsby.ucl.ac.uk/ ~pel/papers/maxentbias.pdf. shu-cherng fang rajasekera h.-s. tsao. entropy optimization mathematical programming volume international series operations research management science. springer york reprint edition william press saul teukolsky william vetterling brian flannery. numerical recipes scientiﬁc computing. cambridge university press cambridge edition first publ. antal berényi zoltán somogyvári anett nagy lisa roux john long shigeyoshi fujisawa eran stark anthony leonardo timothy harris györgy buzsáki. large-scale high-density recording local circuits behaving animals. neurophysiol. http//www.buzsakilab.com/content/pdfs/berenyi.pdf. david mackay. information theory inference learning algorithms. cambridge university press cambridge http//www.inference.phy.cam. ac.uk/mackay/itila/; ﬁrst publ. david landau kurt binder. guide monte carlo simulacambridge university press cambridge http//el.us.edu.pl/ekonofizyka/images//b/a_guide_to_ http//iop.vast.ac. christophe andrieu nando freitas arnaud doucet michael jordan. introduction mcmc machine learning. mach. learn. http//cis.temple.edu/~latecki/courses/robotfall/papersfall/ andrieuintroduction.pdf. werner krauth. statistical mechanics algorithms computations. oxford master series statistical computational theoretical physics. oxford university press oxford hinton sejnowski. learning relearning boltzmann chapter pages first publ. machines. https//papers.cnl.salk.edu/pdfs/learning%and%relearning%in% boltzmann%machines%-.pdf. douglas rayne hartree. wave mechanics atom non-coulomb central ﬁeld. part theory methods. proc. cambridge philos. soc. http//sci-prew.inf.ua/index.htm; also jakob macke philipp berens alexander ecker andreas tolias matthias bethge. generating spike trains speciﬁed correlation coeﬃcients. neural comp. shigeyoshi fujisawa asohan amarasingham matthew harrison györgy buzsáki. behavior-dependent short-term assembly dynamics medial prefrontal cortex. nat. neurosci. yasser roudi sheila nirenberg peter latham. pairwise maximum entropy models studying large biological systems work can’t. plos computational biology arxiv.. gašper tkačik thierry mora olivier marre dario amodei stephanie palmer michael berry william bialek. thermodynamics signatures criticality network neurons. proc. natl. acad. sci. arxiv.. jakob macke manfred opper matthias bethge. common input explains higher-order correlations entropy simple model neural population activity. phys. rev. lett. arxiv.. nikolaj nikolaević ćencov statistical decision rules optimal inference volume translations mathematical monographs. american mathematical society providence transl. leifman; ﬁrst publ. russian stephen gull john skilling. quantiﬁed maximum entropy memsys. users’ manual. technical report maximum entropy data consultants suﬀolk http//www.mpe.mpg.de/~aws/integral/issw/memsys.pdf; ﬁrst publ. joint committee guides metrology jcgm evaluation measurement data guide expression uncertainty measurement. bipm ifcc ilac iupac iupap oiml corr. version edition http//www.bipm.org/en/publications/guides/gum.html. first publ. also joint committee guides metrology jcgm evaluation measurement data supplement guide expression uncertainty measurement propagation distributions using monte carlo method. bipm ifcc ilac iupac iupap oiml http//www.bipm. org/en/publications/guides/gum.html. joint committee guides metrology jcgm international vocabulary metrology basic general concepts associated terms bipm ifcc ilac iupac iupap oiml edition http //www.bipm.org/en/publications/guides/vim.html. first publ. also nist. guidelines evaluating expressing uncertainty nist measurement results nist technical note edition. national institute standards technology washington d.c. http//physics.nist.gov/ cuu/uncertainty/bibliography.html. nist. guide international system units nist special publication edition. national institute standards technology washington d.c. http//physics.nist.gov/cuu/uncertainty/ bibliography.html. elad schneidman michael berry ronen segev william bialek. weak pairwise correlations imply strongly correlated network states neural population. nature april jonathon shlens greg field jeﬀrey gauthier matthew grivich dumitru petrusca alexander sher alan litke chichilnisky. structure multi-neuron ﬁring patterns primate retina. journal neuroscience piero giovanni luca porta mana. relation plausibility logic maximum-entropy principle numerical study arxiv.. also presented invited talk international workshop bayesian inference maximum entropy methods science engineering ‘maxent waterloo canada. andrew gelman john carlin stern donald rubin. bayesian data analysis. texts statistical science. chapman hall/crc boca raton edition first publ. steve pressé kingshuk ghosh julian dill. principles maximum entropy maximum caliber statistical physics. rev. mod. phys. http//statphysbio.physics.iupui.edu/presse_rmp.pdf. wilhelm lenz. beitrag verständnis magnetischen erscheinungen festen körpern. physik. zeitschr. xxi– http//www.physik.uni-rostock. de/fileadmin/physik/mahnke/geschichte/wilhelm_lenz/lenz_.pdf. josiah willard gibbs. elementary principles statistical mechanics developed especial reference rational foundation thermodynamics. charles scribner’s sons york http//gallica.bnf.fr/notice?n= frbnf; repr. roger balian. microphysics macrophysics methods applications statistical physics. vol. theoretical mathematical physics. springer berlin printing edition transl. haar gregg; ﬁrst publ. french roger balian. microphysics macrophysics methods applications statistical physics. vol. theoretical mathematical physics. springer berlin printing edition transl. haar; ﬁrst publ. french arthur hobson david loomis. exact classical nonequilibrium statisticalmechanical analysis ﬁnite ideal gas. phys. rev. http//ergodic.ugr.es/statphys_grado/bibliografia/hoobson.pdf. edwin thompson jaynes. gibbs paradox. smith erickson neudorfer editors maximum-entropy bayesian methods pages kluwer academic dordrecht http//bayes.wustl.edu/etj/node.html. alexa riehle sarah wirtssohn sonja grün thomas brochier. mapping spatio-temporal structure motor cortical spiking activities reach-tograsp movements. front. neural circuits ./fncir... milton abramowitz irene stegun editors. handbook mathematical functions formulas graphs mathematical tables volume national bureau standards applied mathematics series. u.s. department commerce washington d.c. tenth printing corrections edition first publ. wyeth bair ehud zohary william newsome. correlated ﬁring macaque visual area time scales relationship behavior. neurosci. http//invibe.net/biblio_database_dyva/woda/data/att/ fce.file.pdf. mark mazurek michael shadlen. limits temporal ﬁdelity cortical spike rate signals. nat. neurosci. https//www.shadlenlab. columbia.edu/publications/publications/mike/mazurek_shadlen.pdf. adam kohn matthew smith. stimulus dependence neuronal correlation primary visual cortex macaque. neurosci. http//www.smithlab.net/publications.html. matthew smith adam kohn. spatial temporal scales neuronal correlation primary visual cortex. neurosci. http//www.smithlab.net/publications.html. konstantin bakhurin victor peyman golshani sotiris masmanidis. temporal correlations among functionally specialized striatal neural ensembles reward-conditioned mice. neurophysiol. gašper tkačik olivier marre thierry mora dario amodei michael berry william bialek. simplest maximum entropy model collective behavior neural network. stat. mech. arxiv.. gašper tkačik olivier marre dario amodei elad schneidman william bialek michael berry searching collective behavior large network sensory neurons. plos computational biology arxiv.. william feller. introduction probability theory applications. vol. wiley series probability mathematical statistics. john wiley sons york edition first publ. david wolpert david wolf. estimating functions probability distributions ﬁnite samples part bayes estimators shannon entropy arxivcomp-gas/ also david wolpert david wolf. estimating functions distributions ﬁnite samples part bayes estimators mutual information chi-squared covariance statistics arxivcomp-gas/ also malay ghosh glen meeden. bayesian methods finite population sampling volume monographs statistics applied probability. springer dordrecht reprint edition kurt binder. applications monte carlo methods statistical physics. rep. prog. phys. http//fisica.ciencias.uchile.cl/~gonzalo/ cursos/simulacionii/rpphys_binder.pdf. thomas bayes. essay towards solving problem doctrine chances. phil. trans. soc. lond. http//www.stat.ucla.edu/history/ essay.pdf; introduction richard price. scholium reprinted analysed crispin gardiner. handbook stochastic methods physics chemistry natural sciences. springer series synergetics. springer berlin edition first publ. giorgio koch fabio spizzichino editors. exchangeability probability statistics proceedings international conference exchangeability probability statistics. north-holland amsterdam edwin thompson jaynes. jaynes papers probability statistics statistical physics. kluwer academic dordrecht reprint edition rosenkrantz. first publ. josé-miguel bernardo degroot lindley smith editors. bayesian statistics proceedings second valencia international meeting. elsevier valencia university press amsterdam valencia andreas greven gerhard keller gerald warnecke editors. entropy. princeton series applied mathematics. princeton university press princeton oxford jonathon shlens greg field jeﬀrey gauthier matthew grivich dumitru petrusca alexander sher alan litke chichilnisky. correction structure multi-neuron ﬁring patterns primate retina. neurosci. david rumelhart james mcclelland research group. parallel distributed processing explorations microstructure cognition. vol. foundations. computational models cognition perception. press cambridge printing edition first publ. douglas rayne hartree. wave mechanics atom non-coulomb central ﬁeld. part results discussion. proc. cambridge philos. soc. http//sci-prew.inf.ua/index.htm; jerzy neyman editor. proceedings fourth berkeley symposium mathematical statistics probability held statistical laboratory university california june –july vol. contributions theory statistics. university california press berkeley angeles joint committee guides metrology jcgm evaluation measurement data supplement guide expression uncertainty measurement extension number output quantities. bipm ifcc ilac iupac iupap oiml http //www.bipm.org/en/publications/guides/gum.html. joint committee guides metrology jcgm evaluation measurement data role measurement uncertainty conformity assessment. bipm ifcc ilac iupac iupap oiml http//www.bipm. org/en/publications/guides/gum.html. james justice editor. maximum entropy bayesian methods applied statistics proceedings fourth maximum entropy workshop university calgary cambridge university press cambridge first publ. hermann haken editor. complex systems operational approaches neurobiology physics computers. proceedings international symposium synergetics schloß elmau bavaria volume springer series synergetics. springer berlin james clerk maxwell. scientiﬁc papers james clerk maxwell. vol. two. dover york niven. volumes bound one. http //num-scd-ulp.u-strasbg.fr//. first publ. grosbøl warmels editors. third eso/st-efc data analysis workshop held garching april number conference workshop proceedings. european southern observatory garching albert einstein. collected papers albert einstein. vol. swiss years writings princeton university press princeton transl. anna beck peter havas; http//einsteinpapers.press. princeton.edu/. pierre simon laplace œuvres complètes laplace. tome septième théorie analytique probabilités. gauthier-villars paris ‘publiées sous auspices l’académie sciences secrétaires perpétuels’; http//gallica.bnf.fr/notice?n=frbnf.", "year": "2016"}