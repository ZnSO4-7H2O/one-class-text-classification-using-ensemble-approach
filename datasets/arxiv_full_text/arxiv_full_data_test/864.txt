{"title": "Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents", "tag": "q-bio", "abstract": " Psychlab is a simulated psychology laboratory inside the first-person 3D game world of DeepMind Lab (Beattie et al. 2016). Psychlab enables implementations of classical laboratory psychological experiments so that they work with both human and artificial agents. Psychlab has a simple and flexible API that enables users to easily create their own tasks. As examples, we are releasing Psychlab implementations of several classical experimental paradigms including visual search, change detection, random dot motion discrimination, and multiple object tracking. We also contribute a study of the visual psychophysics of a specific state-of-the-art deep reinforcement learning agent: UNREAL (Jaderberg et al. 2016). This study leads to the surprising conclusion that UNREAL learns more quickly about larger target stimuli than it does about smaller stimuli. In turn, this insight motivates a specific improvement in the form of a simple model of foveal vision that turns out to significantly boost UNREAL's performance, both on Psychlab tasks, and on standard DeepMind Lab tasks. By open-sourcing Psychlab we hope to facilitate a range of future such studies that simultaneously advance deep reinforcement learning and improve its links with cognitive science. ", "text": "psychlab simulated psychology laboratory inside ﬁrst-person game world deepmind psychlab enables implementations classical laboratory psychological experiments work human artiﬁcial agents. psychlab simple ﬂexible enables users easily create tasks. examples releasing psychlab implementations several classical experimental paradigms including visual search change detection random motion discrimination multiple object tracking. also contribute study visual psychophysics speciﬁc state-of-the-art deep reinforcement learning agent unreal study leads surprising conclusion unreal learns quickly larger target stimuli smaller stimuli. turn insight motivates speciﬁc improvement form simple model foveal vision turns signiﬁcantly boost unreal’s performance psychlab tasks standard deepmind tasks. open-sourcing psychlab hope facilitate range future studies simultaneously advance deep reinforcement learning improve links cognitive science. adaptive staircase procedures human behavioral paradigms unreal agent visual acuity contrast sensitivity global form perception glass patterns point target task foveal vision eﬀects input resolution foveal vision standard dm-lab laser tasks visual search motion discrimination change detection multiple object tracking state-of-the-art deep reinforcement learning agents navigate virtual worlds viewed egocentric perspective bind information shortterm memory play \"laser tag\" forage naturalistic outdoor environments trees shrubbery undulating hills valleys deep agents even demonstrated learn respond correctly natural language commands like blue balloon\" that stands reason could also cope experimental protocols developed ﬁelds psychophysics cognitive psychology. point contact could established psychology modern research. psychology stands gain mode empirically validating theories necessary aspects cognition research would gain wealth tasks well-understood controls analysis methods thought isolate core aspects cognition. work contribute research platform psychlab. framework allows deep agents humans directly compared another tasks lifted directly cognitive psychology visual psychophysics. psychlab built deepmind agent testing environment much state-of-the-art deep developed. means state-of-the-art agents directly plugged psychlab change setup. also contribute psychlab implementations several classical experimental paradigms including visual search multiple object tracking random motion discrimination. human results paradigms look similar standard results reported psychology literature thus validating implementations. psychlab used research compares deep agents human results enriches agent understanding thereby contributes back improve agent design. example research program unfold second half paper describe experiments probing visual psychophysics deep agent. result experiments motivate particular agent improvement simple model foveal vision improves performance range standard dm-lab tasks. figure screenshots various tasks releasing psychlab framework. proceeding clockwise starting upper left continuous recognition change detection arbitrary visuomotor mapping random motion discrimination visual search glass pattern detection landolt identiﬁcation multiple object tracking. motivation recently research driven forward availability complex naturalistic environments like deepmind lab. environments important pushing artiﬁcial agents learn increasingly complex behaviors. however properties make attractive perspective agent training also make harder assess agents fact ended learning. unambiguously tell cognitive abilities agents well developed. moreover human benchmarking experiments performed environments diﬃcult even humans particular cognitive abilities involved successful performance. tasks generally depend multiple abilities and/or admit multiple solution strategies. result analyzing understanding artiﬁcial agents relation concepts cognitive science challenging. ambiguities analysis natural behavior long known ﬁelds like psychology subject interest human. answer developed last years psychology design rigorously controlled laboratory-based experiments aimed isolating speciﬁc cognitive faculty time. deep advanced point productive apply research methodology tease apart agent cognitive abilities. course would huge undertaking come well-targeted rigorously controlled experiments cognitive functions would like agents learn. fortunately need reinvent wheel. testing environment right i.e. like typical psychology laboratory exactly tasks cognitive psychology already invented. tasks hand long history modeling cognitive faculties psychological phenomena neural networks rumelhart however models typically work sensory data interact laboratory equipment like computer monitor mouse humans thus cannot actually tested experimental procedures conceptual results based. moreover methods cannot actually applied advanced agents algorithms developed complex naturalistic approach deep psychlab enables direct comparisons agent human cognitive abilities making sure protocols used measure assess performance consistent both. moreover since psychlab tasks versions classical behavioral paradigms stood test time psychlab potential oﬀer better experimental controls greater focus probing speciﬁc cognitive perceptual faculties. psychlab environment psychlab psychophysics testing room embedded inside game world dm-lab. agent stands platform front large \"computer monitor\" stimuli displayed. agent able look around usual environment. decide look monitor around e.g. ground sky. change gaze direction transforms visual scene projected agent’s viewpoint usual game environment. changes gaze direction produce global transformation visual scene. common experiments nonhuman primates eye-tracking agent responds \"saccading\" target stimuli. humans psychlab control avatar’s direction gaze computer mouse. exact human control works many popular videogames ﬁrst-person shooter games like quake game dm-lab evolved. least subjects experience playing videogames controls feel quite natural intuitive. psychlab comes ﬂexible easy-to-use scripting language control stimuli placed simulated computer monitor program tasks. readers familiar software coding behavioral tasks psychlab thought analogous scripting environment like psychtoolbox specialized comparisons deep agents humans. reader encouraged take look attached videos examfor example hmax model object recognition ventral visual pathway feedforward neural network thus conventionally interpreted model object recognition performance brief presentation conditions. psychophysical experiments relating generally present stimuli less employ backwards masking techniques thought minimize eﬀects feedback visual processing model takes images outputs class labels. notion time. figure visualization visual search task looks psychlab. ﬁrst snapshot agent ﬁxating center. subsequent snapshots target searched ﬁnally found magenta example psychlab tasks keeping common behavioral testing methods psychlab tasks implemented divided discrete trials. trial also basic unit analysis. could number trials dm-lab episode numbers trials episode duration conﬁgured experimenter. example tasks trial initiated ﬁxating cross center psychlab screen. function _init -construct level around psychlab environment local psychlab_factory require factories.psychlab.factory return psychlab_factory.createlevelapi psychlab psychlab simple framework scripted lua. tasks created placing widgets psychlab monitor. widgets arbitrary visuals invoke callbacks events occur agent’s center gaze entering exiting widget area. framework also supports timers invoke callbacks complete. reinforcement learning psychlab supports reward scheme task developer code using api. experiments provided rewards follows agents receive reward whenever correctly complete trial reward steps. initial experiments tried several reward schemes providing negative rewards incorrect answers small positive rewards reaching basic trial events like foveating ﬁxation cross. however found slower less stable learning. relating protocols humans animals deep agents psychlab reaction times measured terms game steps. humans psychlab engine runs steps second. engine instead steps second human response times would diﬀerent. thus appropriate make qualitative comparisons human agent response times psychlab. psychlab experimental protocols deep agents seen directly comparable non-human primate experimental protocols. human psychophysics typically relies conveying task subject verbally. since deep agents study psychlab understand language tasks must conveyed reinforcement learning. non-human primate psychophysics protocols also conveyed reinforcement learning reason. analogy psychlab protocols testing deep agents nonhuman primate protocols deeper still. interpretational caveat aﬀecting many non-human primate experiments that relative human versions protocols monkey subjects \"overtrained\". since nonhuman primate training procedures take many months it’s possible slower learning mechanisms might inﬂuence results non-human primates could operate within much shorter timeframe equivalent human experiment. particular perceptual learning habitization processes known unfold longer timescales. thus expected play role non-human primate protocols human protocols. deep agents also typically train quite slowly furthermore deep training algorithms usually \"model-free\". resemble slower neural processes underlying habit learning perceptual learning opposed fast learning processes employed humans rapidly learn perform tasks hour. illustrate psychlab applied results interpreted oﬀer case study apply methods visual psychophysics probe visual behaviors state-of-the-art deep agent unreal beyond didactic value illustration psychlab used study basic visual behaviors deep agents interest several reasons. first convolutional neural network architectures like unreal motivated arguments resemble wiring neural networks visual cortex second convolutional neural network primate performance object recognition tasks studied extensively compared another well neural data recorded several regions along primate ventral stream third several recent studies also taken perspective probing convolutional neural networks along lines motivated psychology cognitive science unlike study mostly used networks trained supervised learning studies limited assumptions information read used behavior. hand psychlab works complete agents. makes possible study temporally extended visual behaviors. also allows direct comparison human behavior exact task. shall later turns unreal actually worse acuity human even tested spatial resolution. result motivates series experiments visually-guided pointing tasks leading surprising result that unlike humans state-of-the-art deep agent strongly aﬀected object size contrast ways humans not. learns quickly larger objects. motivates introduce model foveal vision. adding mechanism unreal turns improve performance another family labyrinth tasks didn’t create ourselves laser tag. figure visual acuity measurement snellen chart acuity determined ﬁnding smallest letters correctly read aloud. landolt chart acuity determined ﬁnding smallest subject correctly report orientation optotype’s opening. illustration psychometric curve visual acuity measurement. threshold scale indicated psychlab makes possible ways analyzing experimental data common psychology relatively unknown research. example describe methods measuring psychometric functions detection thresholds reaction times artiﬁcial agents directly compared humans. basic strategy psychophysical measurement analysis vary critical stimulus parameter like luminance contrast determine threshold value required observer perform simple reference task example measure visual acuity task requires identiﬁcation target stimulus presented range scales. example target stimulus landolt shape task identify orientation opening possibilities measuring thresholds provides principled compare task performances agents agents humans. better report performance allow meaningful magnitude comparison follows. thresholds naturally units stimulus task parameters. thus immediately interpretable actionable unlike mean reward values. example might application agent needs able discriminate visual stimuli speciﬁc small size knowing agent’s acuity greater immediately tells candidate task another agent acuity not. approach also makes sense tasks besides visual acuity. requirement task meaningful diﬃculty parameters. addition shapes psychometric functions diﬀerent task dimensions informative. psychometric curve tells particular task/stimulus dimension impact performance. psychometric functions usually sigmoid shape sequence probability distributions trials increasing order diﬃculty. example test visual acuity would distribution trials stimuli displayed largest easiest sized stimuli. would distribution smallest diﬃcult sized stimuli. distribution trials diﬃculty level trial following sample trial sample trial ﬁrst sample diﬃculty level sample speciﬁc trial trials sampled agent achieved score correct better increment base diﬃculty level agent achieved score worse correct trials sampled decrement diﬃculty level many tasks investigated two-dimensional adaptive staircase procedures. example visual acuity contrast sensitivity task simultaneously adjusted scale contrast parameters. work maintaining separate diﬃculty level task dimension equiprobably sampling advance type trials corresponding independently incrementing level other. episode—in sense—consists ﬁxed number steps thus depending response time agent complete variable number trials episode. adaptive staircase reset initial diﬃculty level start episode. humans procedure feels like adaptive staircase. task becomes easier harder adapt subject’s performance level. deep agents exact adaptive procedure induces kind curriculum. early learning agent complete many trials episode complete responds randomly. thus continues experience simplest version task. learned solve level gets level probe trials ensure trials easier diﬃculty levels remain interleaved. simultaneously prevents catastrophic forgetting smooths number trials available analysis diﬃculty level. human behavioral paradigms human experiments performed follows. experiments employed withinsubject design tested single expert observer also author widescreen per. psychlab game window used full-screen mode monitor subject seated approximately away monitor. version dm-lab psychlab platform used experiments report size game window scaled automatically resolution. thus experiments resolution game window signiﬁcantly larger experiments limitation removed version platform open sourced alongside report. possible vary resolution size independently future experiments open-source psychlab platform. unreal agent unreal agent combines framework self-supervised auxiliary control reward prediction tasks. base agent cnn-lstm agent trained on-policy loss. observations rewards actions stored small replay buﬀer. experience data used following self-supervised auxiliary learning tasks unreal algorithm optimizes loss function respect joint parameters combines loss together auxiliary control loss auxiliary reward prediction loss replayed value loss loss weightings real λrplrp note true objective function would like maximize score tasks loss function merely proxy this. particular consider discount parameter agent-side hyperparameter parameter environment. experiments note experiments section performed earlier version psychlab dm-lab codebase version open-source release. diﬀerences platform minor unlikely inﬂuence results. unlike resolution simply denotes number pixels image visual acuity refers agent’s ability detect discriminate small stimuli. greater acuity means greater ability perform reference task despite scaling stimuli smaller smaller sizes. input image resolution visual acuity related another simple way. primates visual acuity contrast sensitivity immature birth. acuity develops course ﬁrst year life primarily peripheral mechanisms including migration cones fovea figure comparison unreal human visual acuity. visual acuity measured landolt orientation discrimination accuracy. scale landolt stimulus displayed adapted according staircase procedure described section seen even input resolution humans agents visual acuity performance diﬀer. test visual acuity unreal agent trained identify landolt stimuli presented range scales. resulting psychometric function sigmoid shape qualitatively matched shape obtained measured human observer also measured unreal agent’s contrast sensitivity landolt identiﬁcation task presenting stimuli range contrasts. case psychometric function diﬀered qualitatively human. unreal less accurate human moderate contrasts outperformed human level lower contrast levels human observers performed visual acuity contrast sensitivity tasks psychlab running diﬀerent resolutions since standard implementation unreal runs i.e. downsamples size surprising acuity signiﬁcantly worse result obtained human observer however surprising ﬁnding unreal also worse acuity relative human observer similar result obtained contrast sensitivity. human contrast sensitivity greater unreal performed worse moderate contrast levels unreal worse visual acuity human observer even viewed stimuli fact humans perform better means must additional target-related information available observation stream unreal cannot take advantage possibility information aliased subsampling happens convolutional layers standard unreal network architecture. global form perception glass patterns video human performance psychlab implementation glass pattern detection task viewed https//youtu.be/xlqqgvqre. previous experiment measured well unreal coped small visual stimuli found impaired acuity relative human even tested resolution. next determine whether insensitivity small stimulus features implications extending larger object perception. speciﬁcally studied perception glass patterns class stimuli strong impression global form arises high spatial frequency cues glass pattern stimulus random pattern paired partner speciﬁc oﬀset pair together called dipole. concentric glass pattern dipoles oriented tangents concentric circles. glass patterns built local correspondences evoke percept global structure. perception must involve least stages. first local features must extracted resulting orientation information coming diﬀerent parts image must integrated order represent global form. glass patterns used numerous studies human form perception e.g. used neuroimaging well single-unit electrophysiology studies. perspective deep glass pattern stimuli particularly nice stimuli inﬁnite number diﬀerent ones easily produced. property useful excluding possibility agent might overﬁt speciﬁc stimuli. figure glass pattern example stimuli psychometric curves unreal human observer text details experimental setting. seen unreal humans perform similarly diﬀerent experimental settings. measured human unreal performance glass pattern detection task trial glass pattern stimulus paired distractor pattern created placing dots randomly preserving average inter-dot distances. measured psychometric function progressively degrading pattern injecting additional noise dots thereby progressively lowering pattern coherence. glass pattern detection psychometric function similar unreal human observer. unreal human observer sigmoid shaped psychometric functions detection white black glass patterns gray background. cases threshold deﬁned coherence level detection performance rose around interestingly unreal human observer unable reliably detect mixed polarity glass patterns glass patterns created dipoles consisting white black dot. eﬀect known human observers however likely ﬁrst time described artiﬁcial system created speciﬁc purpose. possible unreal human-like glass pattern detection thresholds despite worse human acuity? common conceptualize glass pattern perception depending two-stage process. first local orientation information must extracted dipole then second orientation information coming diﬀerent parts image integrated represent global form. unreal’s weak visual acuity expected speciﬁcally impact ﬁrst stages. recover normal human-level performance second stage information already lost ﬁrst stage? possibility acuity loss makes dipole detection less reliable integrating entire stimulus still possible obtain enough orientation information global percept represented despite accumulating errors individually misperceived dipole orientations. point target task particularly unbiological aspect modern artiﬁcial neural networks including unreal weight sharing. reasons computational eﬃciency convolutional neural networks incoming gradients entire visual ﬁeld resulting signal adjust weights cells matter part visual ﬁeld responsible for. section whether convolutional weight sharing structure leads abnormalities visual learning. figure point target task agent needs target either small large screen without presence lure unreal seems quite sensitive size target lure. seen learning much faster target large. additionally presence large lure hurts ﬁnal performance signiﬁcantly. trained unreal pointing task. trial initiated foveating ﬁxation target. upon initiation target stimulus appears distance away possible locations. pointing target trial ends reward delivered. versions task diﬀered size target. unreal learns large-target version task quickly learns small-target version requires less interactions environment achieve perfect performance. weight sharing. contrast biological neurons presumably tuned using signals local receptive ﬁeld. explain heterogenous spatial sensitivity patterns like described afraz weight sharing convolutional networks would able explain data. convolutional neural network gradient signal summed space thus larger region visual ﬁeld correlated loss signal gradient descent steps larger. case online reinforcement learning algorithms like unreal gradient descent steps time-locked environment steps implies larger region visual ﬁeld correlates reward bigger summed gradient becomes thus faster learning proceed. interpretation implies eﬀect peculiar unreal. deep agent time-locks network updates environment steps employs convolutional neural network process inputs show eﬀect. next studied variants pointing task objects appeared trial. cases pointing object left yielded reward pointing target right provided reward trial ends agent points either target lure. version task target lure size. version lure larger. since unreal learns quickly larger objects hypothesized presence larger lure stimulus would make likely become stuck suboptimal local optimum corresponding policy exclusively points lure rather target. indeed occurs. tends policy looking target target lure size tends policy pointing lure lure larger psychlab made easy detect subtle distortions learning process arising weight sharing convolutional neural networks underlying issues unlikely limited psychlab. likely unreal frequently gets stuck suboptimal local optima result learning ﬁrst larger objects smaller objects. complicated tasks could play countless subtle ways. foveal vision eﬀects input resolution input resolution deep agent rather critical hyperparameter. example aﬀects number units level network turn aﬀects speed whole system operated trained. optimal sizes convolutional ﬁlters also depend strongly input resolution. thus always simple matter change without also needing simultaneously change many aspects network design. could argue unfair limit human subject since could performed task higher resolutions thereby achieved higher scores least tasks require resolving small objects. chosen resolution unreal designed for. moreover can’t easily unreal higher resolution. minimum you’d change ﬁlter sizes convolutional network. could easily either make algorithm slow break altogether. emulate fovea subsample image keeping ﬁxed subset rows/columns pixels composing image discarding others. choose subset given image move away centre along vertical axis rows discarded. example consider original image size figure fovea illustration. cells pixels original image blue cells pixels kept processing fovea model. subﬁgures psychometric curves comparing fovea no-fovea human acuity contrast sensitivity glass patterns. model course crude approximation fovea human eye. first don’t distinction \"rods\" \"cones\" vastly diﬀerent distributions across retina diﬀerent response characteristics second sampling density retina changes quite rapidly move fovea sampling density decays someslower. nevertheless argue qualitatively model captures salient property fovea sampling central parts visual ﬁeld higher density thereby increasing acuity parts. foveal vision standard dm-lab laser tasks fovea model eﬀect expanding input representation objects located center visual ﬁeld. recall result point target task unreal learns quicker larger objects—in terms size input image—are correlated reward. suggests fovea model improve learning speed overall performance tasks agent typically centers gaze objects correlated reward. fortunately quite dm-lab tasks already exist property laser tasks. compared performance unreal running default resolution unreal inputs rendered foveally downsampled fovea model turned improve performance eight laser tasks human visual search behavior extremely well-characterized. thousands papers written topic considerable detail also known neural underpinnings detail phenomena related visual search behavior understood provides ideal setting productive psychlab experiments. psychlab makes easy test whether deep agents reproduce behavior patterns. original human experiments replicated psychlab results humans deep agents displayed side side. true visual behavior. unfolds time. fact reaction time typically dependent measure used human experiments. since time central visual search behavior natural discriminative modeling. progress made addressing \"bottom-up\" stimulus-driven aspect predicting ﬁrst ﬁxations models good predicting task-driven search behavior suspect accurate model require full rl-based agent integrating stimulus-driven information top-down feedback based recent search history task goals actually search display. major question area \"serial\" \"parallel\" processing appears reﬂect suboptimality human perceptual intelligence. know convolutional networks constructed capable localizing arbitrary features constant time assuming parallel computational ﬁlter responses gpu. evolution solution? especially puzzling since visual searches appear operate parallel manner said \"pop-out\" searches take longer longer items searched moreover subjective phenomenon serial processing appears suspiciously close essence thought. really suboptimality? apparently serial visual search eﬀects hint something fundamental neural computational processes understand? studying visual search behavior main accepted ways approach cognitive faculty call attention. supervised deep learning considerations \"attention\" methods restricting size hypothesis spaces proven essential scalability toward realistically sized images language corpuses deep developed point scaling seen important likely encounter issues. remember current state-of-the-art systems operate cannot easily scaled replicating classic human result show human reaction times orientation search color search independent size reaction times conjunction search scale linearly size validates psychlab implementation visual search paradigm showing produces pattern human results replicates achieved task implementations. unreal also able solve task. performs almost perfectly training. human performance also near perfect. however resemblance human visual search behavior ends. expected architecture processes visual inputs convolutional neural network unreal’s reaction time always independent size even conjunction search random motion discrimination tasks used investigate motion perception presence noise subjects must discriminate direction majority dots moving. fraction dots moving coherently versus randomly varied experimenter order determine motion perceptual thresholds. lesions cortical area impair performance increasing motion discrimination thresholds measured task going beyond speciﬁc study motion perception task also important study perceptual decision-making generally primate data typically threshold subject’s ability discriminate motion direction declines sharply. reaction time generally increases near perceptual threshold. systematic relationships reaction time there recent work using guide deployment attention model order improve supervised unsupervised learning much work models attention speciﬁcally speed deep attention opposed attention. figure visual search reaction times orientation search color search conjunction search. human reaction times orientation search color search independent size scale linearly size conjunction search. replicates well-known result literature validates psychlab implementation task. unlike human pattern results unreal’s reaction time independent size three cases. found unreal failed learn perform task level motion coherence it’s possible additional steps corresponding operant conditioning steps used animal training paradigms added protocol. example training macaques perform motion discrimination task britten employed curriculum increasingly diﬃcult learn subtasks ﬁxation saccade single target saccade single target presence random motion patterns choose saccade target based direction coherent motion. similar curriculum work deep agents. note version motion discrimination task used results reported diﬀered slightly version included psychlab open-source release. instead ﬂashing random incoherent dots diﬀerent locations described protocol britten incoherent dots moved random directions diﬀerent overall direction motion experiments reported here. diﬀerence unlikely qualitatively change results change detection task subject viewed sample array objects test array trial separated delay task indicate whether arrays identical whether diﬀered terms single feature. objects used squares letter-e shapes diﬀerent colors orientations. task used two-interval forced choice design i.e. sequential comparison design. task performance humans drops number objects increased performance also dependent retention period—longer delays sets hurt performance more. task regarded measuring capacity ﬁdelity visual working memory. inﬂuential debate whether human visual working memory discrete item limit whether ﬂexibly divisible interestingly humans individual diﬀerences change detection tests visual working memory highly correlated ﬂuid intelligence unreal fails perform change detection task regardless delay period size tells despite lstm ability learn manner akin human visual working memory quite limited. multiple object tracking task subjects presented display several indistinguishable objects moving. beginning trial objects brieﬂy identiﬁed target trial objects identiﬁed query object subject’s task report whether query object target set. experimenter vary number objects number target speed movement. task probes subject’s ability attend multiple objects simultaneously. human trials subjects able track four objects. also suggests—since objects indistinguishable—that indexical aspect human attention unreal also fails perform multiple object tracking task taken alongside results motion discrimination change detection tasks provides evidence that despite lstm unreal considerably diﬃculty learning integrate information time. report introduces psychlab dm-lab-based platform enabling psychologystyle behavioral experimentation deep agents. psychlab intended complement environments deep research like standard dm-lab levels vizdoom psychlab maintains figure psychometric functions comparing human unreal motion discrimination change detection multiple object tracking tasks. unreal able perform tasks performing chance levels settings. agent interface dm-lab making much easier perform experiments emulate behavioral paradigms cognitive psychology psychophysics. psychlab task deﬁnition easy-to-use highly ﬂexible demonstrated range paradigms making available along report. psychlab also makes easy directly compare humans artiﬁcial agents. human experiments psychlab replicate classical eﬀects literature like eﬃciency orientation search color search—reaction time independent size—versus ineﬃciency—linearly increasing reaction time size— corresponding conjunction search example psychlab applied deep undertook study visual psychophysics unreal deep agent comparison human. found unreal aﬀected target size contrast similar manner human observers similarly shaped psychometric functions. however found unreal’s visual acuity worse human-level even human comparison limited observing psychlab same quite input resolution unreal hand unreal’s global form perception measured glass pattern detection task similar human pattern results. particular unipolar glass pattern detection similarly shaped psychometric function human observers unreal mixed polarity glass patterns found diﬃcult detect both. visual search task unreal show classical reaction time eﬀects characterize human experiments paradigm. available github insert_url_here. current list visual acuity contrast sensitivity measurement glass pattern detection visual search sequential comparison random motion discrimination arbitrary visuomotor mapping continuous recognition multiobject tracking. case. also showed eﬀect sometimes cause learning become stuck suboptimal local optima corresponding larger objects despite presence smaller rewarding objects. likely eﬀects play numerous subtle ways deep tasks. psychlab makes easy measure them. another implication result input preprocessing step expands center observation—inspired foveal vision—should improve performance tasks important objects tend center gaze. tested hypothesis standard dm-lab laser tasks found adding \"foveal\" preprocessor unreal improved performance eight available laser levels. story demonstrates probing details agent behavior psychlab feed directly back deep research yield ideas improving agent performance. first would like thank gadi geiger najib majaj kindling interest psychophysics. also thank chris summerﬁeld dharshan kumaran koray kavukcuoglu thore graepel greg wayne vlad mnih sasha vezhnevets simon osindero karen simonyan eslami carl doersh jane wang jack many insightful inﬂuential conversations conceptualizing work. additionally would like thank stig petersen handley vicky langston helen king adrian bolton project management support marcus wainwright aliya ahmad comms.", "year": "2018"}