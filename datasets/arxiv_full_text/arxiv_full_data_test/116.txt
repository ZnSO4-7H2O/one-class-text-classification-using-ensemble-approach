{"title": "Network Modeling of Short Over-Dispersed Spike-Counts: A Hierarchical  Parametric Empirical Bayes Framework", "tag": "q-bio", "abstract": " Accurate statistical models of neural spike responses can characterize the information carried by neural populations. Yet, challenges in recording at the level of individual neurons commonly results in relatively limited samples of spike counts, which can lead to model overfitting. Moreover, current models assume spike counts to be Poisson-distributed, which ignores the fact that many neurons demonstrate over-dispersed spiking behavior. The Negative Binomial Generalized Linear Model (NB-GLM) provides a powerful tool for modeling over-dispersed spike counts. However, maximum likelihood based standard NB-GLM leads to unstable and inaccurate parameter estimations. Thus, we propose a hierarchical parametric empirical Bayes method for estimating the parameters of the NB-GLM. Our method integrates Generalized Linear Models (GLMs) and empirical Bayes theory to: (1) effectively capture over-dispersion nature of spike counts from retinal ganglion neural responses; (2) significantly reduce mean square error of parameter estimations when compared to maximum likelihood based method for NB-GLMs; (3) provide an efficient alternative to fully Bayesian inference with low computational cost for hierarchical models; and (4) give insightful findings on both neural interactions and spiking behaviors of real retina cells. We apply our approach to study both simulated data and experimental neural data from the retina. The simulation results indicate the new framework can efficiently and accurately retrieve the weights of functional connections among neural populations and predict mean spike counts. The results from the retinal datasets demonstrate the proposed method outperforms both standard Poisson and Negative Binomial GLMs in terms of the predictive log-likelihood of held-out data. ", "text": "commonly used models simultaneously recorded spiking activity generalized linear models latent variable models supervised setting glms used stimuli spiking histories covariates driving spiking neural population also glms closely related wellknown hawkes process model similarly used extensively network inference essentially introduces nonlinearity hawkes process ensures positive rates allows supersub-linear inﬂuences nodes. unsupervised setting lvms focus extracting low-dimensional smooth timeevolving latent structure capture variability recorded data temporally spatially. however settings spike counts time often assumed conditionally poisson given shared signal poisson assumption gives algorithmic conveniences implies conditional mean variance spike counts equal. ignores fact cases variance spike counts could much larger mean data over-dispersed. negative binomial model proposed solution handling over-dispersed spike counts intend extract functional dependences among neurons give insights neural interactions. thus nb-glm natural extension achieve goal simultaneously capturing over-dispersion neuron. despite ease implementation maximum likelihood estimation nb-glm recorded length spike-train data short large number neurons recorded simultaneously accuracy estimated coefﬁcients using glms responses unfortunately typical experimental settings cannot obtain long sequences high-quality neural data short lifetime neurons limited viable time recording materials micro-movement recording electrodes activity animal hence size dataset often small either length experiment even need real-time inference case maximum likelihood estimator parameters distribution leads large mean square error standard glm. alleviate problem employ regularization priors form hierarchical model means trade bias variance. challenges hierarchical modeling ﬂexibly abstract—accurate statistical models neural spike responses characterize information carried neural populations. challenges recording level individual neurons commonly results relatively limited samples spike counts lead model overﬁtting. moreover current models assume spike counts poisson-distributed ignores fact many neurons demonstrate over-dispersed spiking behavior. negative binomial generalized linear model provides powerful tool modeling over-dispersed spike counts. however maximum likelihood based standard nb-glm leads unstable inaccurate parameter estimations. thus propose hierarchical parametric empirical bayes method estimating parameters nb-glm. method integrates generalized linear models empirical bayes theory effectively capture over-dispersion nature spike counts retinal ganglion neural responses; signiﬁcantly reduce mean square error parameter estimations compared maximum likelihood based method nb-glms; provide efﬁcient alternative fully bayesian inference computational cost hierarchical models; give insightful ﬁndings neural interactions spiking behaviors real retina cells. apply approach study simulated data experimental neural data retina. simulation results indicate framework efﬁciently accurately retrieve weights functional connections among neural populations predict mean spike counts. results retinal datasets demonstrate proposed method outperforms standard poisson negative binomial glms terms predictive log-likelihood held-out data. rons vital deducing populations neurons process information. functional connectivity focuses statistical dependencies neural time series recent increase accessibility datasets containing spiking activities large-scale neural populations possible test effectiveness different methods extracting functional dependences neuronal level. here consider problem recovering connectivity neurons network merely observing simultaneous spiking activity paper propose hierarchical empirical bayes estimator probability parameters nb-glm helps model short over-dispersed spike-counts finally capture accurate spiking behavior neurons meanwhile recover functional connectivity framework. hierarchical framework places prior distribution parameters distribution estimated using empirical bayes. hyperparameters prior distribution estimated using maximum marginal likelihood methods. estimated value used obtain mean spike counts. summary main contributions four-fold present accurate prediction performance retinal ganglion cells compared state-of-the-art methods; give insightful ﬁndings neural interactions generally paper organized follows. section review properties negative binomial distribution differences full empirical bayes approaches. section introduce sods. section discusses parameter estimations sods numerical optimization maximum marginal likelihood roles parameters. results simulated experimental data presented section discussion contributions ﬁndings concluded section mean since figure shows relationship variance mean negative binomial poisson distributions. variance distribution larger mean shows super-poisson variability figure shows fig. relationship variance mean poisson negative binomial distributions. negative binomial shows super-poisson variability probability density function distribution different parameters functional connectivity modeled input-output system links negative binomial output spiking activities input neurons hierarchical model. hierarchical setting either fully bayesian inference empirical bayes estimate model parameters. fully bayesian inference assumes speciﬁc hyperprior hyperparameters need integrated out. often cannot obtain closed form marginalization fully bayesian inference requires sampling strategy approximate distribution. correspondingly comes high computational cost especially high-dimensional data hand empirical bayes inference sets parameters highest level hierarchical model likely value. setting hyperparameters maximizing marginal likelihood function incurs much lower computational cost. hence combining empirical bayes negative binomial produce estimator parameters negative binomial distribution efﬁciently handle over-dispersion smaller data-sets. establish network model framework still capture super-poisson spiking behavior. figure. illustrates demo simple network considered work. represent functional dependences graph connection strengths neurons. note input neurons’ spiking activities regressors predict output neuron’s spike counts figure. presents neuron excitatory inhibitory effects neuron ﬂexible link function distribution model respectively. accurate modeling link functions model help effectively retrieve intrinsic coupling strengths. mental trial time assume {yi}k normally link function predeﬁned using speciﬁc form logit probit identity however want constrain link function ﬁxed form. hence propose family link functions governed hyperparameter that design link family three considerations represent many widely used link functions. instance logit function complementary link function function constrain prior mean modeled mean value probability parameter inversed provide gradients hyperparameters easily. note hyperparameter ﬂexible parameter determines speciﬁc form link function therefore ensuring ﬂexibility nonlinear transformation regressors output. deﬁnition spike counts j-th trial i-th time vector regressors time step mean poisson distribution probability parameter negative binomial distribution failures negative binomial distribution parameters beta distribution degree freedom prior distribution vector weights family link functions parameter determining speciﬁc form link function mean prior distribution number trials i-th time mean spike counts across trials weight observation component estimator data length components gradients element number total number neurons vector lagrangian coefﬁcients variable number vector search direction step length iteration figure. shows graphical model proposed hierarchical structure. observation data xi−; latent variables; global parameters consistent across time steps. empirical bayes estimator sods fig. simple network model considered work excitatory inhibitory effects generates spiking behavior. illustration neuron effects ﬂexible link function distribution. observed data multiple spike-train data recorded simultaneously presented gray line signals indicates spike obtained. introduce hyperparameter interpreted precision parameter reﬂects degree prior belief ﬁxed across different time bins. prior mean thus determine beta distribution learning particular learn using generalized linear model mean counts input neurons previous time step vector functional weights capture directed effects input neurons output neuron. modeled θsods depends estimate empirical bayes approach. ﬁrst derive marginal likelihood function marginal distribution spike counts conditioned hyperparameters. optimize marginal likelihood using gradient-based broyden-f letcher-goldf arb-shanno algorithm. finally discuss roles model parameters model prior knowledge initial value give stable accurate optimization results. fig. graphical representation proposed model. prior mean formed input regressors weight vector link function parameterized mean beta prior probability parameter degree freedom prior beta distribution. finally together shape parameter distribution generate observed spike counts shaded nodes denote observed random variables; latent random variables. hyperparameters. rectangular plate notation denotes replication. convex combination data-driven estimate prior mean glm. consider parameter achieve trade-off bias variance. viewed precision parameter. thus results reﬂecting observed data. θsods thus estimator reduces standard negative binomial links probability parameter input regressors link function since using maximum marginal likelihood approach include assumptions hyperparameters beneﬁt relatively computational cost estimating high-dimensional parameters. derive marginal likelihood need integrated probability quadratic problems solved using active-set algorithm iteration step linear search direction line search procedure step length parameter achieves sufﬁcient decrease merit function fm). update group parameters converged parameters sods estimator play different roles explaining neural spike train dataset. section discuss turn present rules tune initial values used optimization procedure order improve estimation efﬁciently. shape parameter negative binomial response. physically controls underlying ﬁring rates neurons. real situations actual ﬁring rate underlying neural population high hippocampal areas. case reasonable mean spike counts make sure initial value small helps spike count observations match ﬁring rates. accordingly believe brain area high ﬁring rate motor cortex initialize higher value. figure. keep probability parameter show inﬂuence different values spike counts. results indicate negative binomial distribution larger values give larger spike counts. hierarchical modeling hard obtain closed-forms estimators. thus numerical maximization. here need approximate hessian matrix iteration achieved applying quasi-newton method approximation hessian matrix. speciﬁcally used approximate hessian matrix iteration. derive gradients w.r.t. however optimizations found sometimes negative value probability parameter within solve problem enforce constraint using sequential quadratic programming applying quasi-newton method updating step. form quadratic program line search direction minimizing quadratic subproblem form lagrangian function hyperparameters algorithm hierarchical parametric empirical bayes framework short over-dispersed spike-counts input output initialize based section iv-b. form linear regressors form link function based derive prior information construct beta negative binomial marginal likelidata length time series training dataset. spike counts output neuron sampled negative binomial model. depending combination parameters provide different types observed spike counts. basically conducted simulation tests interaction estimation. randomly assigned excitatory inhibitory weights neural population. goal identify whether could recover weights interactions accurately. performance sods estimator. simulation process underlying truth regarding mean spike counts based degrees freedom beta distribution. controls balance limited data sample prior knowledge. proposed estimator weighted combination standard estimation observed data θobs θglm nent nir+niyi nir+niyi+σ thus large proposed method close prior mean; small estimator approaching observed data. initial value determined number trials that trials have smaller means conﬁdence observed data. conveys nonlinear effects input neurons output neurons selects best link function dataset. commonly used logit function; becomes complementary link function; link function. regularly glms choose link function specifying parametric link work however determines unknown parameter automatically. learning dataset allows approach automatically select suitable link function. initial value determined result relatively ﬁring rate empirically shown give good performance spike count prediction. section test framework simulated experimental recordings. simulated data generated process outlined figure. general setting simulations listed table. experimental datasets retinal datasets taken visual experiments different numbers neurons validate stability ﬁtness model neural recordings. hyperparameters given different combinations comparison. range conﬁgurations parameters tested simulated data shown table number simulated trials number neurons simulation represents different parameter settings. example table model trained using training length tested computing mean spike counts true value testing trial data length. results averaged across randomly selected initializations unknown parameters. link function nb-glm selected probit function compared performance different link functions logit probit identity log− found cases probit gives best performance. simplicity demonstrate results standard nb-glm probit link function. however number samples decreases sods outperforms standard negative binomial glms. table shows neurons larger decrease estimation accuracy sods model still consistently outperforms nbglm. table expected increased larger since larger leads possible values spike counts larger leads degrees freedom. left panel figure. shows error bars sods different number training trials data lengths training trials data length already give relatively small mse. scatter plot right panel figure. provides clear view comparison true estimated mean spike counts. comparing conﬁgurations table would expected increasing gives better estimation. number training samples large models similarly good performances simulated data fig. goodness-of-ﬁt simulated data left panel mean square error across data lengths different numbers trials right panel scatter plot estimated mean spike counts true mean spike counts time bins. gray spike count value. next tested accuracy estimation weights describing directed effect input neurons output neuron. explored effect different data lengths method applied maximize marginal likelihood. results shown figure. taken several different combinations parameter conﬁgurations table relative standard error large actual weights close bins sufﬁcient provide accurate efﬁcient weight estimations consistent results shown figure. experimental data used taken multiunit recordings retinal ganglion cells database curated crcns.org. database single-unit neural responses recorded isolated retina mice using -electrode array response various visual stimuli. aims learn different visual stimuli inﬂuence spiking activity retina cells. population activity network models using framework quite fig. scatter plots estimated weights -neuron network different number data points trial different colors indicate different neurons. size ball shows relative standard error initial values weights optimized selected randomly simulated times. bins sufﬁcient achieve accurate stable estimations coupling weights inside neural network. popular test framework state-of-theart methods datasets containing neurons respectively. experimental data binned size trade-off ﬁnely time discretized computational costs. experimental dataset created random training testing splits experimental trials splits used training split used testing -fold cross validation performed. training dataset used estimate unknown parameters θsods used sods model compute log-likelihoods held-out test data versus standard poisson negative binomial glm. figures show percentage increase loglikelihood sods model poisson negative binomial datasets. denote sods poisson predictive log-likelihoods model. percentage log-likelihood increase calculated |poisson| figure sods−nb positive percentage value indicates improvement predictive log-likelihood held-out data sods compared comparative method conversely negative value indicates decrease predictive log-likelihood. majority results present higher prediction log-likelihoods test data using sods model. notably improvement offered sods model larger compared poisson compared negative binomial datasets analyzed indeed exhibit over-dispersion property. however compared negative binomial sods still offered increase performance similar number recorded neurons poisson glm. despite fig. sods compared negative binomial error percentage increase predictive likelihood neurons dataset neuron dataset sorted according improvements prediction performance. figure shows network weights estimated using sods experimental datasets. around total weights strength positive dataset total weights strength negative dataset. results give valuable insights neural kind coupling weights dominates whole neural connections recovered directed weighted neural network provides quantitative intuitively view information neural circuits. dataset show highly mutual excitations within functional neural network shown inhibitory-dominated underlying fig. estimated network weights experimental datasets using model. neurons laid circle black indicating neuron. red/blue lines highlight positive/negative weights thickness indicates strength weights. neural interactions recovered dataset show excitatory-dominated property; results dataset indicate underlying neural circuit inhibitory-dominated. cost. estimate unknown parameters model paninski used maximum likelihood estimation dataset small estimation becomes biased. sods estimator developed here model over-dispersed spiking behavior extract latent interactions among neural populations combines methods. beneﬁt providing bias-variance trade-off estimator negative binomial responses needing intensive computation fully bayesian inference. take advantage beneﬁcial properties glms empirical bayes inference propose sods estimator. used negative binomial distribution model spike counts neuron. negative binomial distribution selected allows over-dispersed spike counts using dispersion parameter superior standard poisson model. beta distribution employed prior information probability parameter negative binomial distribution allows closed-form posterior distribution. propose ﬂexible link function family order model prior mean using regressors. using recorded data neurons covariates infer functional weights among neural population. unlike fully bayesian inference utilizes hyperpriors instead estimate hyperparameters maximizing marginal likelihood. proposed sods estimator shrinkage estimator weights estimate viewed hidden functional dependences. taking neurons nodes functional neural network spike-train data observations empirical bayes inference method used identify neural including excitatory inhibitory behaviors. validated method using simulated data experimental retinal neuron data. using intensive simulations shown simulated system sods outperforms standard negative binomial glm. furthermore proposed approach implements ﬂexible link function unlike standard negative binomial allowing selecting best link dataset. simulation data found efﬁciently maximizing marginal likelihood accurately estimate model parameters. experimental data compared fig. sods compared poisson error percentage increase predictive likelihood neurons dataset neuron dataset sorted according improvements prediction performance. bio-signal processing community shown great interest multivariate regression methods methods provide clear view nature neuronal interactions. linderman developed fully bayesian inference method negative binomial responses yields regularized estimations hyperparameters. although uncertainties parameters applying fully bayesian approaches hierarchical models computationally intensive. alternative empirical bayes provide bias-variance trade-off achieve small mean square error lower computational widely used regression methods poisson negative binomial regressions substantial improvement predictive likelihood held-out data. results presented promising going forward interested extending model. instance incorporation hebbian learning rules could account time-varying weights. applying prior knowledge regarding network structure random small world scalefree networks could also promising avenue future research. finally ability model operate datalimited cases would open possibilities future applications real-time settings closed loop experiments improved brain-machine interface devices. implemented sods matlab plan release code github shortly. authors wish thank prof. james kwok department computer science engineering hong kong university science technology provided valuable comments insightful discussions derivations experiments manuscript. work described paper fully supported grant research grants council hong kong special administrative region china chen putrino ghosh barbieri brown statistical inference assessing functional connectivity neuronal ensembles sparse spiking data ieee transactions neural systems rehabilitation engineering vol. okatan wilson brown analyzing functional connectivity using network likelihood model ensemble neural spiking activity neural computation vol. song chan robinson marmarelis opris hampson deadwyler berger identiﬁcation functional synaptic plasticity spiking activities using nonlinear dynamical modeling journal neuroscience methods vol. truccolo eden fellows donoghue brown point process framework relating neural spiking activity spiking history neural ensemble extrinsic covariate effects journal neurophysiology vol. pillow shlens paninski sher litke chichilnisky simoncelli spatio-temporal correlations visual signalling complete neuronal population nature vol. a.-k. seghouane shah sparse estimation hemodynamic response functionin functional near infrared spectroscopy acoustics speech signal processing ieee international conference ieee kazemipour babadi robust estimation self-exciting generalized linear models application neuronal modeling ieee transactions signal processing vol. lawrence probabilistic non-linear principal component analysis gaussian process latent variable models journal machine learning research vol. lakshmanan sadtler tyler-kabara batista byron extracting low-dimensional latent structure time series presence delays neural computation vol. cichocki mandic lathauwer zhou zhao caiafa phan tensor decompositions signal processing applications two-way multiway component analysis ieee signal processing magazine vol. pillow paninski simoncelli maximum likelihood estimation stochastic integrate-and-ﬁre neural model. advances neural information processing systems churchland byron cunningham sugrue cohen corrado stimulus onset quenches neural variability widespread cortical phenomenon nature neuroscience vol. charles park weller horwitz pillow dethroning fano factor ﬂexible model-based approach partitioning neural variability biorxiv available http//www.biorxiv.org/content/early// taniai nishii optimality upper-arm reaching trajectories based expected value metabolic energy cost neural computation vol. gillis glineur accelerated multiplicative updates hierarchical algorithms nonnegative matrix factorization neural computation vol. giurc˘aneanu saip insights order selection information theoretic criteria based localized estimators digital signal processing vol. xiong wang cheng zheng generalized context modeling multi-directional structuring mdl-based model selection heterogeneous data compression ieee transactions signal processing vol. sheikhattar fritz shamma babadi recursive sparse point process regression application spectrotemporal receptive ﬁeld plasticity analysis ieee transactions signal processing vol. received b.e. degree nanjing university posts telecommunications within ranking currently ph.d. candidate department electronic engineering college science engineering city university hong kong. during visiting student research collaborator pillow princeton neuroscience institute princeton university. research focuses statistical signal processing methods extract hidden structure highdimensional spike-train data infer brain connectivity using bayesian framework. interested studying information encoded decoded brain especially using latent variable models modeling neural dynamics. beth jelfs currently recipient vicechancellors research fellowship rmit university australia. graduated university leicester meng electronic software engineering receiving british computer society prize graduate imperial college london ph.d. electrical electronic engineering previously held research positions department electronic engineering city university hong kong hong kong department medical physics bioengineering university college london departments chemistry physics university oxford current research interests include statistical adaptive signal processing machine learning signal modality characterization particular application biomedical data. adam charles received b.e. electrical computer engineering cooper union york city york. received ph.d. electrical computer engineering georgia institute technology research awarded sigma best doctoral thesis award well electrical computer engineering research excellence award. currently charles post-doctoral fellow princeton neuroscience institute princeton jersey studies theoretical computational neuroscience. research interests currently include neural imaging technologies inference sparse structured signals statistical models neural systems. rosa h.m. chan currently associate professor department electronic engineering city university hong kong. received eng. degree automation computer-aided engineering chinese university hong kong later awarded croucher scholarship edward youde memorial fellowship overseas studies received degree biomedical engineering university southern california also received degrees biomedical engineering electrical engineering aerospace engineering. research interests include computational neuroscience neural prosthesis brain-computer interface applications. co-recipient outstanding paper award ieee transactions neural systems rehabilitation engineering research breakthroughs mathematical modelling cognitive prosthesis. chan chair hong kong-macau joint chapter ieee engineering medicine biology society elected ieee embs adcom asia paciﬁc representative", "year": "2016"}