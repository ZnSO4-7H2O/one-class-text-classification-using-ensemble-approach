{"title": "The identity of information: how deterministic dependencies constrain  information synergy and redundancy", "tag": "q-bio", "abstract": " Understanding how different information sources together transmit information is crucial in many domains. For example, understanding the neural code requires characterizing how different neurons contribute unique, redundant, or synergistic pieces of information about sensory or behavioral variables. Williams and Beer (2010) proposed a partial information decomposition (PID) which separates the mutual information that a set of sources contains about a set of targets into nonnegative terms interpretable as these pieces. Quantifying redundancy requires assigning an identity to different information pieces, to assess when information is common across sources. Harder et al. (2013) proposed an identity axiom stating that there cannot be redundancy between two independent sources about a copy of themselves. However, Bertschinger et al. (2012) showed that with a deterministically related sources-target copy this axiom is incompatible with ensuring PID nonnegativity. Here we study systematically the effect of deterministic target-sources dependencies. We introduce two synergy stochasticity axioms that generalize the identity axiom, and we derive general expressions separating stochastic and deterministic PID components. Our analysis identifies how negative terms can originate from deterministic dependencies and shows how different assumptions on information identity, implicit in the stochasticity and identity axioms, determine the PID structure. The implications for studying neural coding are discussed. ", "text": "understanding different information sources together transmit information crucial many domains. example understanding neural code requires characterizing different neurons contribute unique redundant synergistic pieces information sensory behavioral variables. williams beer proposed partial information decomposition separates mutual information sources contains targets nonnegative terms interpretable pieces. quantifying redundancy requires assigning identity different information pieces assess information common across sources. harder proposed identity axiom stating cannot redundancy independent sources copy themselves. however bertschinger showed deterministically related sources-target copy axiom incompatible ensuring nonnegativity. study systematically effect deterministic target-sources dependencies. introduce synergy stochasticity axioms generalize identity axiom derive general expressions separating stochastic deterministic components. analysis identiﬁes negative terms originate deterministic dependencies shows different assumptions information identity implicit stochasticity identity axioms determine structure. implications studying neural coding discussed. characterization dependencies parts multivariate system helps understand function underlying mechanisms. within information-theoretic framework problem investigated breaking parts joint entropy variables mutual information sets variables approaches many applications study dependencies complex systems genes networks neural coding communication interactive agents important aspect information distributed across variables concerns whether different variables provide redundant unique synergistic information combined variables. intuitively variables share redundant information variable carries individually information carried variables. information carried certain variable unique carried variables combination group variables carries synergistic information information arises combined. presence different types information implications example determine information decoded robust disruptions system variables compressed without information loss characterizing distribution redundant unique synergistic information especially relevant systems neuroscience understand information distributed neural population responses. requires identifying features neural responses represent sensory stimuli behavioural actions information transmitted transformed across brain areas breakdown information different types components determine contribution different classes neurons different spatiotemporal components population activity moreover identiﬁcation synergistic redundant components information transfer help dynamic functional connectivity integration information across neurons networks despite notions redundant unique synergistic information seem ﬁrst intuitive rigorous quantiﬁcation within information-theoretic framework proven elusive. synergy redundancy traditionally quantiﬁed measure called interaction information coinformation measure quantify separately presence associated positive negative values respectively. synergy also quantiﬁed using maximum entropy models information retrieved joint distribution variables however recent seminal work williams beer introduced framework called partial information decomposition precisely simultaneously quantify redundant unique synergistic information variables target decomposition cornerstones. ﬁrst deﬁnition general measure redundancy following axioms impose desirable properties agreement corresponding abstract notion redundancy second construction redundancy lattice structured according axioms reﬂects partial ordering redundancies different sets variables framework adopted developed many others however concrete implementation properties terms continue debated harder argued original redundancy measure williams beer quantiﬁes quantitatively equal amounts information information qualitatively same. introduced axiom namely identity axiom states target copy sources redundancy correspond mutual information them cancel independent sources. several measures fulﬁll identity axiom subsequently proposed substitution original redundancy measure however bertschinger provided counterexample illustrating multivariate case identity axiom incompatible ensuring nonnegativity terms. like target-source copy example used motivate study general effect deterministic target-sources dependencies decomposition. counterexample bertschinger reveals inconsistency nonnegativity identity axiom provide general clue incompatible modiﬁed. furthermore identity axiom advocated based concrete example question generally determining identity different pieces information addressed independently proposing speciﬁc redundancy measures. show follows analysis addresses generally explicitly question assigning information identity cause negative terms. start work reviewing decompositions introduce alternative forms weak strong form stochasticity axiom imposes constraints existence synergistic information presence deterministic target-source dependencies using axioms derive general expressions separate term stochastic deterministic component bivariate trivariate case. show axioms lead alternative generalizations identity axiom check several previously proposed redundancy measures conform generalizations reconsider examples used bertschinger characterizing bivariate trivariate decompositions illustrating general negative terms occur finally comparing stochasticity identity axioms discuss implications assuming certain criterion identify pieces information target presence deterministic target-sources dependencies concretely assuming identity related speciﬁc sources seminal work williams beer introduced approach decompose mutual information nonnegative contributions. consider ﬁrst bivariate case. assume target formed variable variables variables information want characterize. williams beer argued mutual information variable expressed similarly term refers redundancy component variables obtained either knowing separately. terms quantify component unique respectively information obtained variables alone cannot obtained alone. furthermore joint information expressed term refers synergistic information variables unique joint source respect variables alone. therefore given standard information-theoretic chain rule equalities decomposition redundancy synergy component exist simultaneously. fact williams beer showed measure coinformation previously used quantify synergy redundancy deﬁned generally williams beer deﬁned decompositions mutual information target multivariate variables general formulation relies deﬁnition general measure redundancy construction redundancy lattice. detail decompose information williams beer deﬁned source subset variables collection sources. introduced measure redundancy quantify collection redundancy sources composing collection constructed redundancy lattice reﬂects relation redundancies different collections. generically refer redundancy collection furthermore following chicharro panzeri concise notation williams beer example instead writing {}{} collection composed source containing variable source containing variables write save curly brackets indicate source variables instead separate sources. also refer single variables primary sources want speciﬁcally distinguish general sources contain several variables. monotonicity property allows introducing partial ordering collections reﬂected redundancy lattice. self-redundancy links lattice joint mutual information collection formed single source including variables furthermore number collections included lattice limited fact adding superset source change redundancy. example redundancy source source information accordingly collections included lattice deﬁned figure redundancy lattices williams beer lattices reﬂect partial ordering deﬁned bivariate lattice corresponding decomposition trivariate lattice corresponding decomposition color label nodes indicate mapping terms trivariate bivariate lattice particular nodes color trivariate lattice accumulated corresponding node bivariate lattice. p\\{∅} nonempty subsets nonempty sources formed domain reﬂects symmetry axiom distinguish order sources. collections williams beer deﬁned partial ordering relation construct lattice collections source source subset source. partial ordering relation reﬂexive transitive antisymmetric. fact consistency redundancy measures partial ordering collections represents stronger form monotonicity axiom. beer implicitly deﬁning partial information measures associated node redundancy lattice redundancy measures obtained partial information measures refers collections lower equal partial ordering hence reachable descending lattice. partial information measures obtained inverting applying principle inclusion-exclusion terms lattice redundancy lattices bivariate trivariate shown figure studied chicharro panzeri mapping exists terms trivariate bivariate decompositions indicated colors labels. harder pointed original measure redundancy williams beer nonzero redundancy obtained independent variables target copy them measure quantifying amount qualitatively common information quantitatively equal amount information zero case. ince speciﬁcally differentiated identity axiom assumes form redundancy degree dependence primary sources target copy them concrete property namely independent identity property requires redundancy copy target cancels primary sources independent. several alternative measures proposed fulﬁll additional axiom properties terms characterized either based axioms structure redundancy lattice also considering properties speciﬁc measures however speciﬁc cases multivariate gaussian systems univariate targets shown several proposed measures actually equivalent start analysis deterministic relations target primary sources enunciating versions stochasticity axiom synergistic information. axioms impose different constraints synergy terms dependency target upon sources partly deterministic partly stochastic. consider ﬁrst weak axiom. axiom motivated idea subset variables comprised target completely determined source corresponding subset cannot synergistic information subset sources. already provide information without combining variable. accordingly weak axiom assumes that weak form stochasticity axiom implies sources cannot synergistic information part target deterministically related them. however axiom restrict variables determine provide information parts target synergistic way. conversely strong form stochasticity axiom imposes variables provide synergistic information degree deterministically related variables particular assumes that synergy equal synergy lattice associated decomposition mutual information s|x)) x\\x) conditioned logic strong axiom better appreciated when instead functional relation primary sources contained target case strong axiom states cannot synergistic contribution involving variables contrast weak axiom contributions cannot present even providing information x\\x). motivation primary sources cannot provide information target information themselves provided without combining variable. accordingly primary sources. simplify derivations focus case target contains primary sources themselves. general formulation considers target variables determined function sources leads main qualitative conclusions. derivations follow relations characteristic redundancy lattice need select speciﬁc measure redundant unique synergistic information. forms stochasticity axiom derive expressions unique redundant information presence target-sources overlap. derivations follow procedure first given unique synergistic information related conditional mutual information synergy stochasticity axioms determine form unique information terms. second unique information terms derived relation mutual information together redundancy term allows identifying redundancy. unique redundant information terms procedure separates stochastic deterministic components. however components combined depends order stochastic deterministic target-sources dependencies partitioned. particular using chain rule ﬁrst equality indicates unique information conditional information minus synergy. second equality uses chain rule separate conditional mutual information stochastic deterministic components applies stochasticity axiom remove overlapping part target synergy term. using relation conditional mutual information unique synergistic terms target also used equals entropy accordingly unique information separated stochastic component unique information target deterministic component entropy last term zero target contain source does quantiﬁes entropy source explain part target thus extra unique information contribution. identiﬁed unique information stochastic deterministic components relation unique redundant information mutual information characterize redundancy. that therefore sufﬁces primary sources overlaps target conditional mutual information given non-overlapping target variables contributes redundancy. follow procedure derive expressions unique redundant information terms applying mutual information partitioning order resulting terms compared table derived detail appendix also show consistency expressions obtained partitioning order. upper part table collect decompositions stochastic deterministic contributions term partitioning orders. simplify expressions form shown case alternative partitioning order expressions unique information redundancy contain cross-over component namely synergy instead expressed terms unique information redundancy respectively. furthermore separation deterministic stochastic components additive. indicates that chain rule holds mutual information guaranteed type separation holds separately term. certain partitioning order stochastic dependencies considered ﬁrst unique redundant information terms derived weak axiom separated additively stochastic deterministic component without cross-over terms. lower part table individuate deterministic components obtained partitioning order term separated additively stochastic deterministic component. table decompositions synergistic unique redundant information terms stochastic deterministic contributions obtained assuming weak stochasticity axiom. term show decompositions resulting alternative mutual information partitioning orders consistent partitioning order leading additive separation term stochastic deterministic component also individuate deterministic contributions synergy stochastic component according axiom expressions unique information come eqs. ones redundancy eqs. expressions simpliﬁed respect equations indicating form case terms analogous expressions symmetry exists zero otherwise. procedure derive unique redundant terms strong stochasticity axiom assumed determining synergy instead simplify expressions indicate advance term target deﬁnition equal target provide expressions derived target-sources overlap. contrast weak axiom strong axiom additive separation stochastic deterministic components obtained partitioning order appendix details partitioning order. unique information obtain before summarize decompositions table comparing table expressions obtained weak strong axiom differ cross-over contribution corresponding synergy transferred redundancy unique information. synergy constraints imposed axiom strong axiom assumes synergy hence part information transferred unique information synergy unique information constrained equal conditional mutual information. consequence redundancy reduced equivalent amount comply constraints relate unique informations redundancy mutual informations. furthermore like weak axiom chain rule property generally hold term separately. terms consistent mutual information decompositions obtained applying chain rule depending partitioning order version axiom assumed information contributions redistributed different terms stochastic deterministic components. agreement previous concrete counterexamples provided bertschinger rauh showed chain rule hold general term. table decompositions synergistic unique redundant information terms stochastic deterministic contributions obtained assuming strong stochasticity axiom. table analogous table synergy cancels according axiom expressions unique information come eqs. ones redundancy eqs. again expressions shown case corresponding symmetries holding terms equal zero otherwise. forms stochasticity axiom result different expressions redundancy term. examine expressions related redundancy identity axiom axiom determines redundancy speciﬁc deterministic target-sources relation namely primary sources target equal them straightforward redundancy identity axiom subsumed stochasticity axioms redundancy identity axiom first consider target copy primary sources target degree overlap functional dependence sources. second restricted bivariate case formulated number primary sources. redundancy terms derived axiom coincide particular case addressed identity axiom generally differ. strong axiom leads redundancy equal case addressed identity axiom general independently non-overlapping target variables. conversely weak axiom redundancy depends variables. discuss differences based concrete examples. check several proposed measures conform predictions stochasticity axioms. particular examine original redundancy measures williams beer based pointwise common change surprisal ince based maximum entropy bertschinger well-known redundancy measure williams beer comply identity axiom even redundancy obtained. excess redundancy leads less unique information turn produces nonzero synergistic contribution inconsistently weak strong stochasticity axioms. neither redundancy measure ince complies identity axiom thus conform stochasticity axioms. conversely redundancy measure bertschinger fulﬁlls identity axiom. broadly compares redundancies derived weak strong axioms consider following example target sources according weak axiom redundancy equal deterministic component stochastic component conversely according strong axiom redundancy equals redundancy measure bertschinger calculated minimizing mutual information sources target within family distributions preserves marginals target sources. particular redundancy calculated co-information distributions leading minimal information within family. example preserving marginal target source implies preserving whole joint distribution hence minimal information within family equal original information. accordingly given bertschinger measure redundancy measure coincides predicted strong axiom. holds general property co-information overlaps given matching redundancy straightforward check rest terms match well. derived predictions decompositions according version stochasticity axiom pointed relation identity axiom checked different previously proposed measures conform predictions. concrete examples examine decompositions. particular reconsider examples previously studied bertschinger rauh namely decompositions mutual information target jointly formed inputs output logical operation operation. ﬁrst describe decompositions obtained section discuss relation underlying assumptions assign identity different pieces information target. deterministic components examples derived without assuming speciﬁc measure redundancy unique synergistic information. stochastic components already previously studied terms depend measures selected. indicate previous work examining terms required. figure bivariate decomposition system. joint distribution inputs output operation. also collect value information-theoretic quantities used calculate bivariate decomposition trivariate decomposition section bivariate decomposition derived weak stochasticity axiom. stochastic deterministic components separated agreement table bivariate decomposition derived strong axiom. deterministic components present following table figure also indicate values information-theoretic measures needed calculate bivariate decompositions studied also serve trivariate decompositions addressed section want examine decomposition target composed three variables. version stochasticity axiom focus mutual information partitioning order allows separating additively stochastic deterministic component term. since weak axiom decomposition obtained implementing decomposition separately calculating deterministic components collected table decomposition operation characterized repeatedly showing terms zero except synergy contributes information. stochastic redundancy unique information regarding deterministic components redundancy deterministic unique information components zero according axiom deterministic synergy. case strong axiom since primary sources overlap target deterministic components appear decomposition selecting partitioning order additively separates stochastic deterministic contributions indicated table assumption synergy. since redundancy also zero information contained unique information terms. pointed generic expressions decompositions differ transfer stochastic component synergy unique information turns forces equivalent transfer redundancy unique information. compare decompositions previous analyses example studies terms derived using identity axiom. particular argued that since totally determines target reduced redundancy thus then using identity axiom zero. reasoning leads decomposition derived strong stochasticity axiom. position separately calculating deterministic components table using joint distribution inputs output displayed figure decomposition operation also already characterized term contributes half bit. unique contributions come exclusively deterministic components. unique information half output input determine input value redundancy also half comes part stochastic component part deterministic one. stochastic component previously determined harder indicating redundancy output appears intrinsically mechanism even inputs independent. deterministic component appears because although inputs independent conditioned output synergy also previously determined harder decomposition differs obtained weak axiom example. conversely strong axiom decomposition example completely determined latter decomposition agreement arguments bertschinger version stochasticity axiom implies different quantiﬁcation redundancy. since value unconditional conditional mutual informations depend decomposition bivariate case extra constraints synergy strong axiom imply assigning information unique information turns restricts amount redundancy compared constraints implied weak axiom. restriction imposes that target-sources overlap redundancy depends mutual information primary sources independent dependencies sources target variables. examine detail different quantiﬁcations related notion redundancy common information target obtained observing either source alone. point identity assigned different pieces information order assess information target carried sources qualitatively common. particular strong axiom logic source part target cannot provide information target information thus source contain information information unique. implicit argument assumption primary source part target still identify separate bits information source information rest target. idea regarding identity bits shared also motivated introduction identity axiom. although identity axiom formulated sources degree dependence motivation mainly based case sources independent case identify bits information related variable ones variable thus redundancy quantiﬁes qualitatively equal information shared common amounts information cancel. assigning identity pieces information target general less straightforward. example consider different combinations mutual information partitioning orders show assignment identity bits target based association sources interpretation redundant assume identify information carried primary source target decompositions would suggest redundant information since source carries information system. however keeping decomposition consider alternative decompositions redundancy unique information terms depend apply chain rule however contrast ﬁrst decomposition suggests identity bits target related overlapping variables sources redundancy sources particular variable part target associated source contribution interpreted redundant information source itself. second decomposition challenges interpretation redundancy unique information based assignment identity bits information target given association overlapping target variables. given source provides information amount information contained shared given conditional dependencies system. moreover conditioning variable target variable associated source would suggest contributes information combining sources. accordingly using target-sources correspondence identify pieces information different partitioning orders mutual information ambiguously suggest information obtained uniquely redundantly even synergistic way. problems arise because contrast case independent sources system bits cannot identiﬁed belonging certain variable distinguished ﬁrst variable provides alone second variable provides combined ﬁrst. lack correspondence pieces information individual variables incompatible identiﬁcation pieces information based association target-sources overlapping variables. differences quantiﬁcation redundancy stochasticity axiom related alternative interpretations identity discussed eqs. notion redundancy compatible weak axiom considers common information target obtained observing either source alone conditioned variables target. indeed deterministic component redundancy comprises conditional dependence sources given rest target target-sources overlap thus conversely strong axiom targetsource overlap redundancy equals independently agreement logic discuss implications axioms information identity section dealing trivariate case. extend analysis trivariate case. relevant because contrast bivariate case argued sources decompositions jointly comply monotonicity identity axiom guarantee nonnegativity terms particular bertschinger used example reconsidered counterexample show negative terms appear. therefore would like able extend general formulation section trivariate case thus apply examine examples identifying component trivariate decomposition decomposition bivariate decomposition single term involves synergistic information trivariate lattice figure nodes reached descending imply synergistic information nodes form i.jk too. weak strong axioms impose constraints terms given eqs. respectively. start weak stochasticity axiom. consider three primary sources part target synergy appear. example consider extra information obtained observing together instead separately. information distributed across nodes reached descending already reached descending axiom states contained target cannot synergistic information them. furthermore part target provides extra information given alone information redundant provides itself hence contained node still reachable descending accordingly weak stochasticity axiom implies proceed analogously bivariate case characterize remaining deterministic contributions terms. apply mutual information chain rule separate stochastic deterministic dependencies. focus partitioning order considers ﬁrst stochastic dependencies since order leads additive separation stochastic deterministic components term. partitioning order certain primary source overlap target nodes reached descending corresponding node deterministic component. understood intuitively. example suppose target includes entropy terms reached descending ﬁrst quantiﬁes information table deterministic components terms trivariate decomposition derived weak stochasticity axiom. terms included table deterministic component axiom. expressions correspond case primary source overlaps target. overlap zero terms depend characteristic symmetry variables cancel none variables corresponding symmetry overlaps target. main text appendix details. using condition procedure section derive expressions deterministic trivariate components. terms collected table leave detailed derivations discussion appendix expressions indicated case variable part target symmetric respect symmetry characteristic certain term cancel otherwise consistently ﬁrst terms nonnegative former entropy latter according axiom adding source reduce synergy. terms guaranteed nonnegative. examples negative values below. conditional co-information negative synergy primary sources conditioning non-overlapping target variables happen synergy target leading negative value. therefore following weak stochasticity axiom decomposition cannot ensure nonnegativity terms deterministic target-sources dependencies place. discuss limitation examining full trivariate decomposition examples. strong form axiom deterministic stochastic components synergy restricted. cannot synergistic contribution involves source overlapping target. applied furthermore since cancelation synergistic terms hold terms trivariate lattice also bivariate lattice associated given mapping terms lattices implies trivariate lattice also terms form i.jk constrained. fact case synergistic contributions nonzero target-sources overlap trivariate case variable overlaps. consider variable part target. since cannot synergy involving synergistic terms contained cancel also checked includes synergistic terms except former quantiﬁes synergy target variables latter synergy redundant information itself. primary source overlapping target synergistic terms cancel trivariate case. table deterministic components terms trivariate decomposition derived strong stochasticity axiom. terms included table deterministic component axiom. again expressions shown correspond case source overlaps target. consider neither overlap target otherwise term cancels. overlap zero terms depend characteristic symmetry variables cancel otherwise. main text appendix details. expressions respects symmetries term. example instead overlaps target note however that overlaps overlap appendix details. comparison deterministic components derived weak axiom differences first lack conditioning x\\ijk reversed partitioning order selected. like bivariate case deterministic components independent non-overlapping target variables adopting strong stochasticity axiom. second assuming strong axiom terms nonzero contained target source overlaps terms form cancel. case clear negative since co-information negative. therefore also decomposition derived strong axiom ensure nonnegativity. show examples negative terms decompositions. continue analysis examples decomposing since decompositions completely deterministic obtained calculating components described table table accordingly given deterministic joint terms equal instead refer them. start example decomposition derived weak stochasticity axiom show trivariate decomposition also decomposition indicating mapping nodes trivariate decomposition. trivariate lattice show nodes lower ones primary sources others corresponding terms zero terms calculated considering table information-theoretic quantities displayed figure trivariate terms zero variables determine third. also reﬂected terms bit. terms equal bit. terms quantify redundant information variables unique respect third interpretation impaired negative values. furthermore figure trivariate decompositions system. decomposition derived weak stochasticity axiom. trivariate redundancy lattice displayed nodes lower single source nodes because upper terms zero. bivariate decomposition shown indicating mapping terms colors labels figure decomposition derived strong axiom. redundancy monotonicity hold. however checked values obtained consistent point view constraints linking terms mutual informations. similarly calculated components consistent bivariate trivariate decompositions. particular nodes color label trivariate lattice equals corresponding node bivariate lattice. equality holds joint bivariate lattice deterministic lattice alone even trivariate case lattice uniquely deterministic. reﬂects transfer stochastic synergy bivariate case deterministic redundancy trivariate case consider decomposition derived strong axiom case also zero variables determine third also zero. axiom assumes synergy involving primary sources overlapping target. consistent lack synergy decomposition indicated mapping yellow nodes labeled also mapping terms consistent. particular corresponding unique informations bivariate decomposition contained terms trivariate one. comparison decomposition weak axiom terms negative instead negative value obtained therefore nonnegativity neither fulﬁlled decomposition. fact decomposition used bertschinger rauh counterexample show sources decomposition simultaneously comply redundancy monotonicity axiom identity axiom also lead global nonnegativity terms. section pointed bivariate decomposition derived strong stochasticity axiom coincides obtained arguments bertschinger based identity axiom. however trivariate decomposition obtain did. divergence occurs bertschinger arguing based identity axiom discussed section argued implies based redundancy monotonicity hence also terms negative value however trivariate decomposition figure respect monotonicity axiom necessarily imply indeed monotonicity respected already negative value assuming strong stochasticity axiom. accordingly recognising possibility results obtained strong axiom compatible arguments bertschinger showing decomposition counterexample global nonnegativity indicating negative value appears already present decomposition example. terms derived using information-theoretic quantities figure combination tables like case mapping trivariate bivariate decompositions consistent. again trivariate decompositions contain negative term. strong axiom bivariate decompositions example equal trivariate terms differ substantially reﬂecting different symmetries operation. particular case symmetry three variables case inputs. analysis trivariate decompositions derived weak strong versions stochasticity axiom shows explicitly nonnegative terms arise presence deterministic target-sources dependencies. form deterministic components indicated tables provides general understanding negative terms occur beyond concrete counterexample examined bertschinger particular axioms enforce certain pieces information attributed redundancy unique information terms identity associated sources hence deterministic components decomposition bounded part redundancy lattice leads negative terms order conform lattice structure relations terms mutual informations. furthermore argued rauh based continuity arguments mutual information problem obtaining negative terms expected occur deterministic target-sources dependencies exist also limit strong dependencies tending deterministic. avoiding negative terms would require changing assumptions deterministic target-sources dependencies constrain terms. common assumption weak strong axioms information overlapping variable redundant unique restrictive implies assuming assign identity pieces information target exclusively related overlapping variable. conversely cases identity assigned single variable case independent motivated identity axiom particular independent identity property requires case. general overall composition target affects identity piece information. example even independent target identify piece associated different variable incorporate third variable determined identity generally change depend speciﬁc operation generates case example system taken target. bits cannot identiﬁed belonging certain variable ﬁrst variable provides alone second variable provides combined ﬁrst. oppositely hand strong axiom assumes source alone uniquely provide corresponding identity reﬂected decomposition hand weak axiom second classiﬁed synergy consistently idea retrieving requires combination variables however weak axiom still assumes information overlapping variable redundant unique imposes synergy contained terms trivariate decomposition terms corresponding nodes upper ones single variables. means axiom still compatible identiﬁcation bits obtained single variable obtained combination variables. figure show trivariate decomposition consistent identiﬁcation bits example. ﬁrst obtained variable alone thus redundant three variables. none variables provide information alone remaining terms associated nodes lower zero. furthermore since second obtained combination variables information redundant pair thus contained node since total bits rest terms also zero. decomposition nonnegative conform version stochasticity axiom fact corresponds obtained using redundancy measure min{i} sources collection closely related measure williams beer measure also nonnegative decomposition example like case move target target qualitative argument associate bits target particular source variables. identity pieces information assigned quantitative criterion since maximum information redundant three sources target still provide alone reaching information. combination primary sources provides another half bit. total provides already information corresponding entropies half bits. remaining information unique synergystic term combining overall analysis highlights distinguishing redundant unique synergistic information requires criterion assign identity piece information target. measures fulﬁlling identity axiom generally complying stochasticity axioms implicit criterion assumes identity sources preserved within tarfigure nonnegative decompositions based identiﬁcation pieces information target without imposing constraints synergy deterministic target-sources dependencies. decomposition system. decomposition system. keep colors labels nodes facilitate comparison figures terms value indicated zero. get. criterion respects independent identity property leads negative terms. oppositely criterion quantitative redundancy measure used figure measure williams beer leads nonnegative decomposition respect intuition qualitative redundancy independent identity property. remains open question general criterion identity accommodates intuition associated independent identity property also compatible relations intrinsic redundancy lattice williams beer proposal williams beer decomposing mutual information nonnegative redundant unique synergistic components fruitful inﬂuential conceptual framework. however concrete implementation consistent axioms formalizing notions types information proven elusive. main difculty stems determining redundant sources contain qualitative information requires assigning identity pieces information target. harder pointed redundancy deﬁned williams beer captures quantitatively common amounts information shared sources. introduced identity axiom ensure independent variables cannot redundant information copy themselves. lack redundancy particular case enunciated independent identity property ince however bertschinger provided counterexample showing nonnegativity terms ensured identity axiom assumed. counterexample also involved target constituted copy primary sources particular inputs output variables logical operation. since cases deterministic relation exists target sources played important role motivating identity axiom raising caveats internal consistency axioms work examined systematically effect deterministic target-sources dependencies decomposition. target-sources dependencies. presence target-sources overlap weak form axiom states cannot synergistic information overlapping target variables. strong axiom constrains synergy assuming overlapping sources cannot provide information themselves thus neither contribute synergistic information nonoverlapping part target. derived general formulas terms bivariate case following version stochasticity axiom. showed terms separated stochastic deterministic component account information non-overlapping overlapping target variables respectively. indicated stochasticity axioms subsume identity axiom provide alternative generalizations characterize redundancy multivariate system degree target-sources overlap checked several previously proposed measures conform generalizations examined concrete examples based logical operations variables inputs variable output calculating decomposition mutual information based examples argued axioms imply different interpretations redundancy common information target obtained observing either source alone. weak axiom source combined target variables provide information target variables even presence target-sources overlap. conversely strong axiom assumes overlapping variable provides information itself thus redundant information cannot appear source combined target variables. leads redundancy always equal mutual information primary sources target-sources overlap independently non-overlapping target variables. however enforcing different constraints stochasticity axioms assume identity overlapping sources preserved within target pieces information identity associated corresponding sources independently variables composing target. section extended general derivations trivariate case. allowed understand originates negative terms found counterexample bertschinger general perspective. identiﬁed that following stochasticity axioms several terms deterministic component nonnegatively deﬁned. resumed examples section analyzing decomposition done counterexample bertschinger bertschinger fully characterize decomposition instead used identity axiom indicate least negative term appears. conﬁrmed results indicating arguments consistent strong axiom although pointed negative value already present redundancy three variables instead upper term involving synergy. analysis applying general derivations stochasticity axioms allowed expose relation assumptions information identity lack nonnegativity. particular imposing certain pieces information attributed redundancy unique information terms based premise identity associated sources enforces deterministic components mutual information bounded part redundancy lattice leads negative terms order conform lattice structure relations terms mutual informations. identity axiom motivated especial case independent which particularly enunciated independent identity property redundancy intuitively cancel pieces information target separately assigned source. however general overall composition target affects identity piece information. example even independent incorporating target third variable determined alters identiﬁcation target information. case example target formed jointly inputs output variables since bits cannot identiﬁed belonging three variables ﬁrst variable provides alone second variable provides combined ﬁrst. section examined alternative decomposition consistent alternative identiﬁcation bits system. showed that example nonnegative decompositions attained admitting nonzero synergistic contributions. however identity criterion used alternative decomposition purely quantitative williams beer thus respect desired independent identity property. although notion redundancy information shared pieces information intuitive plain language precise implementation within information-theoretic framework straightforward. measure mutual information applications many ﬁelds communication theory statistics accordingly certain decomposition terms redundant unique synergistic contributions compatible interpretations. indeed information understood context communication channel nonnegativity required operational interpretation number messages transmitted without errors. furthermore semantic content cannot attributed thus information identity rely statistical properties distribution target variables. example case target composed independent variables identity assigned based independence. alternatively mutual information used descriptor statistical dependencies nonnegativity required since locally negative information misinformation simply reﬂects certain change probability distribution variable conditioning another variable. interpretation information based local dependencies criterion information identity introduce semantic content association speciﬁc value variables common information sources associated dependencies induce coherent modiﬁcations probability distribution target variables local measures information interpreted operationally terms changes beliefs relation notion information associated ideal observer analysis communication theory work considered local versions mutual information adopted premise nonnegativity desirable property terms. determining proper criterion information identity evaluate information carried different sources qualitatively common essential interpret results decomposition practical applications analysis distribution redundant unique synergistic information neural population responses. example examining information multidimensional sensory stimulus represented across neurons decomposition identify information different features stimulus common amounts information. terms reﬂect functional properties neural population properly characterize neural code. hand nonnegativity terms facilitates interpretation description statistical dependencies breakinformation content neural responses example assess intersection information sensory behavioural choice representations underlying criterion information identity decomposition also important examining information ﬂows among brain areas because redundant unique information terms correctly separate qualitatively information interpret spatial temporal dynamics unique information transmitted across areas. common apply dynamic measures predictability granger causality characterize information ﬂows brain areas effect synergistic redundant information components characterization information ﬂows granger causality studied williams beer applied framework decompose information-theoretic measure granger causality namely transfer entropy terms separately accounting state-independent state-dependent components information transfer. furthermore also indicated terms decompositions associated information uniquely transmitted certain time information transfer speciﬁc variable certain sensory stimulus applications framework identify meaningful terms based redundancy lattice thus applied actual deﬁnition measures considerations highlight necessity properly determine information identity order fully exploit explanatory power. furthermore discussion interpretation information identity depends dependencies variables composing target indicates analysis redundant unique synergistic information components distributed across neural population responses particularly useful combination interventional approaches particular manipulation neural activity optogenetics techniques disentangle causal effects sources dependencies common factors. although work illustrates principled limitations current measures combination powerful experimental techniques help better probe functional meaning terms. overall studied effect deterministic target-sources dependencies decomposition enunciating variants stochasticity axiom comparing identity axiom discussing implications regarding information identity. analysis suggests that redundancy lattice williams beer remain backbone nonnegative decomposition mutual information criterion information identity established that conforming independent identity property less restrictive presence deterministic target-source dependencies ones underlying axioms. authors contribution authors contributed design research. research carried daniel chicharro. manuscript written daniel chicharro contribution stefano panzeri giuseppe pica. authors read approved ﬁnal manuscript. derive detail alternative expressions unique redundant information terms collected table obtained applying mutual information partitioning order using relation decomposing conditional mutual information unique information synergy also following strong axiom alternative partitioning order case considering ﬁrst stochastic dependencies non-overlapping target variables derived. overlap implies unique information derive detail trivariate deterministic components. start derivations following weak stochasticity axiom. consider unique information primary source respect example weak axiom imposes trivariate case synergy deterministic components upper single source nodes zero accordingly deterministic component contained decomposing conditional mutual information partitioning order considers ﬁrst dependencies non-overlapping target variables like expressions deterministic components tables sections simplicity indicate equalities hold primary source overlaps target. symmetries term indicate nonzero. example constrained equality form overlap target. finally consider also unconditional mutual information decomposed terms. example using partitioning order considers ﬁrst stochastic target-source dependencies altogether eqs. proceed obtain expressions terms function mutual informations entropies. rest terms remain function also terms terms understood comparing trivariate decomposition bivariate decomposition sources latter part target quantiﬁes stochastic synergistic contribution source. conversely trivariate decomposition source information redundant information provided variable itself. means identify comparing synergy decompositions. example bivariate decomposition source according weak axiom synergy provide information non-overlapping part target comprise moving trivariate case adding source synergy stochastic component becomes redundant information source itself thus strong stochasticity axiom instead repeating derivations proceed arguing change respect decomposition obtained weak axiom. changes originate difference constraints versions axiom impose existence synergistic components alternative mutual information partitioning order leads additive separation stochastic deterministic components depending axiom. strong axiom additive separation reached using partitioning order ﬁrst considers deterministic target-sources dependencies. means conditioning entropies mutual informations x\\ijk case present. moreover since strong axiom restricts also synergy non-overlapping target variables even stochastic component nonzero neither overlap target. since adding sources synergistic component zero expression terms reduced overlaps zero otherwise. implementing modiﬁcations expressions table obtained ones table", "year": "2017"}