{"title": "Development and evaluation of a deep learning model for protein-ligand  binding affinity prediction", "tag": "q-bio", "abstract": " Structure based ligand discovery is one of the most successful approaches for augmenting the drug discovery process. Currently, there is a notable shift towards machine learning (ML) methodologies to aid such procedures. Deep learning has recently gained considerable attention as it allows the model to \"learn\" to extract features that are relevant for the task at hand. We have developed a novel deep neural network estimating the binding affinity of ligand-receptor complexes. The complex is represented with a 3D grid, and the model utilizes a 3D convolution to produce a feature map of this representation, treating the atoms of both proteins and ligands in the same manner. Our network was tested on the CASF \"scoring power\" benchmark and Astex Diverse Set and outperformed classical scoring functions. The model, together with usage instructions and examples, is available as a git repository at http://gitlab.com/cheminfIBB/pafnucy ", "text": "structure based ligand discovery successful approaches augmenting drug discovery process. currently notable shift towards machine learning methodologies procedures. deep learning recently gained considerable attention allows model learn extract features relevant task hand. developed novel deep neural network estimating binding aﬃnity ligand-receptor complexes. complex represented grid model utilizes convolution produce feature representation treating atoms proteins ligands manner. network tested casf scoring power benchmark astex diverse outperformed classical scoring functions. model examples http//gitlab.com/cheminfibb/pafnucy structure-based virtual screening techniques successful methods augmenting drug discovery process structure-based screening tries predict binding aﬃnity target candidate molecule based structure complex. allows rank prioritize molecules processing subsequent testing. numerous scoring schemes developed process statistical and/or expert analysis available protein-ligand structures currently notable shift towards scoring functions using machine learning methodologies highlighted several reviews methods naturally capable capturing non-linear complex relationships available data. rather manually creating rules using expert knowledge statistical inference models arbitrary functions adjustable parameters capable transforming input output brieﬂy model presented examples input data paired desired outcome learns return predictions agreement values provided. typically process learning incremental; introducing small changes model parameters prediction moved closer target value. prime examples scoring functions rf-score uses random forest nnscore uses ensemble shallow neural networks. scoring functions proven useful virtual screening campaigns yielded active compounds classical counterparts however drawback approaches still rely feature engineering i.e. utilize expert knowledge deﬁne rules become basis input data preprocessing. hence argue sophisticated classical scoring functions complex rules. rule thumb says order establish good predictive model model needs data able distinguish general trends patterns noise. growing amount structural data aﬃnity measurements allowed researchers explore deep learning. brieﬂy deep neural network consists multiple layers non-linear transformations extract combine information data develop sophisticated relationships input output. main advantages deep learning allows reduction feature engineering model learns extract features natural consequence process ﬁtting model’s parameters available data. clear choosing representation input data profound impact predictive power model. currently eﬀort ﬁeld incorporate feature extraction directly model. approach learnable molecule representation replaces classical descriptors ﬁngerprints becomes ﬁrst part model. then representation trained together predictive part model extract features useful solving speciﬁc task. design therefore theoretically possible quantify relationships and/or mechanisms discovered unknown experts deep learning relatively widely used bioinformatics computational biology community several promising examples deep learning methods also shown computer-aided drug design although deep learning readily used ligand-based regimes currently couple interesting examples structure-based neural networks. atomnet input molecular complex discretized grid directly convolutional neural network. instead data preprocessing model uses learnable representation recognize diﬀerent groups interacting atoms. atomnet classiﬁcation method yields ligand active yields otherwise. another similar model created ragoza trained perform independent classiﬁcation tasks activity pose prediction. however classiﬁcation methods lose information since neural networks also suitable regression gomes created model predicting energy bounded protein-ligand complex unbounded state. work radial pooling ﬁlters learnable mean variance used process input. ﬁlters enabled production summary atom’s environment representation invariant atom ordering orientation complex. taking account current ﬁndings aforementioned approaches developed pafnucy novel deep neural network tailored many structure-based approaches including derivative prioritization virtual screening. similar ragoza input structure represented grid combination convolutional dense layers used; however model tries predict exact binding aﬃnity value. pafnucy utilizes natural approach atom description proteins ligands atom types. approach serves regularization technique forces network discover general properties interactions proteins ligands. additionally design pafnucy provides insight feature importance information extraction done learning ﬁnal prediction binding aﬃnity. network implemented tensorflow using python trained pdbbind database source code trained model usage instructions available repository http//gitlab.com/cheminfibb/pafnucy. three-dimensional structures protein-ligand complexes require speciﬁc transformations encoding order utilized neural network. approach cropped complex deﬁned size cubic focused geometric centre ligand. discretized positions heavy atoms using grid resolution approach allowed representation input tensor point deﬁned cartesian coordinates vector features smarts patterns deﬁned previous project partial charges scaled training set’s standard deviation order distribution unit standard deviation improves learning. case collisions rarely occur grid features colliding atoms added. network trained tested proteinligand complexes pdbbind database database consists structures molecular complexes corresponding binding aﬃnities expressed divided overlapping subsets. general includes available data. reﬁned comprises complexes higher quality subtracted. finally complexes reﬁned clustered protein similarity representative complexes selected cluster. fraction database called core designed high-quality benchmark structure-based cadd methods. properly employ pdbbind information prevent data leakage split data disjoint subsets i.e. reﬁned subtracted general core subtracted reﬁned overlaps three subsets. next discarded proteinprotein protein-nucleic acid nucleic acid-ligand complexes datasets. finally order evaluate model casf scoring power benchmark needed exclude data overlap complexes used casf. therefore excluded total overlapping complexes training validation sets. complexes used study protonated charged using ucsf chimera amber standard residues am-bcc non-standard residues ligands. additional improvements calibration performed complexes; default protocol chosen line able compare pafnucy methods tested casf scoring power benchmark. remaining complexes pdbbind dataset divided follows randomly selected complexes reﬁned used validation whole core used external test complexes used training set. summary general reﬁned sets used train model select hyperparameters core used external test unknown model training validation. scheme illustrating relationships between subsets available supplementary figure atomic features calculated using open complexes helper functions transformed grids. used prepare data jupyter notebook preprocessing steps available http//gitlab.com/cheminfibb/pafnucy. additional external test used complexes astex diverse complexes original database excluded without binding aﬃnity present pdbbind database remaining structures prepared pdbbind database. dataset used order test pafnucy structures diﬀerent source. predicting binding aﬃnity. model consists parts convolutional dense parts diﬀerent types connections layers convolution name convolutional stems mathematical operation mixes functions together. neural network libraries actually substitute convolution operation cross-correlation intuitive interpretation measures similarity functions. model discovers patterns encoded ﬁlters convolutional layer creates feature spatial occurrences pattern data. pafnucy’s input molecular complex represented tensor treated like image multiple colour channels. position input described vector properties analogous pixel image described vector intensities basic colours. first input processed block convolutional layers combined pooling layer. pafnucy uses convolutional layers ﬁlters. layer cubic ﬁlters followed pooling layer cubic patch. result last convolutional layer ﬂattened used input block dense layers. used dense layers neurons. order improve generalization dropout drop probability used dense layers. also experimented dropout dropout achieved worse results validation set. convolutional dense layers composed rectiﬁed linear units relu chosen speeds learning process compared types activations. also experimented tanh units achieved similar prediction accuracy learning much slower. initial values convolutional ﬁlter weights drawn truncated normal distribution mean standard deviation corresponding biases weights dense layers initialized truncated normal distribution mean standard deviation number incoming neurons given layer. corresponding biases relation scores experimentally measured binding constants assessed pearson’s correlation coeﬃcient standard deviation regression measure used casf deﬁned follows expected network achieves lowest error training used weights network. importantly pafnucy also returns accurate predictions test sets unknown model training validation. results core although substantially worse subsets still better scoring function tested best-performing x-score model achieved methods comparable errors obtained pdbbind data. expected pafnucy outperforms x-score astex diverse regardless measure used. observed correlation however lower methods. effect partially fact astex dataset adam optimizer used train network learning rate examples minibatch. larger batch sizes also tested resulted worse performance. training carried epochs model lowest error validation selected reduce overﬁtting used dropout approach mentioned earlier weight decay using higher value decreased model’s capacity much resulted higher training validation errors. addition providing regularization allows investigate feature importance. weight diﬀers considerably information transfers must important model make prediction important part approach develop model sensitive ligand-receptor complex orientation. therefore every structure presented network diﬀerent orientations yielding diﬀerent training examples protein-ligand complex. using systematic rotations complexes training anticipated network would learn general rules protein-ligand interactions lead better performance data. indeed experiments observed much worse performance models trained single orientations regardless hyperparameters used deﬁne particular network. error training validation sets monitored learning although model trained diﬀerent rotations complex calculated original orientation order speed computations. epochs training model started overﬁt error validation started slowly steadily increase. best weights network obtained epochs training saved used ﬁnal model. model performance evaluated subsets data complex dataset aﬃnity predicted compared real value. prediction error measured cortion molecular complex. model presented work rotation-invariant similar convolutional neural networks used image recognition; input looks diﬀerently object shown diﬀerent angle contains information underlying real object. therefore generalize well model needed learn extract information diﬀerently presented input. order achieve outcome augmented dataset systematic rotations input data. pafnucy trained correctly retest model’s stability selected pdea protein camp/cgmp phosphodiesterase important signal transduction recently linked neuropsychiatric disorders pdea complexed diﬀerent ligands pdbbind database complexes presented model diﬀerent rotations distribution returned predictions analyzed. anticipated variability predicted binding constants additionally variability depend value prediction subset molecule belongs. neural networks often deemed harder analyze interpret simpler models sometimes regarded black-boxes. worry model yield good predictions wrong reasons therefore generalize well datasets. order trust neural network predictions needs ensure model uses information relevant task hand. section analyze parts input important biggest impact predictions. case random forests example established calculate feature importance based impurity decrease neural networks consensus interpretation model’s parameters diﬀer considerably networks diﬀerent architectures. case pafnucy trained estimate feature importance looking distributions weights associated convolutional ﬁlters ﬁrst hidden layer. initial values close training weights tend spread form wider ranges weights higher absolute values pass information deeper layers network. pafnucy trained regularization crucial weights likely high absolute values. input represented using channels expected relevance model figure feature widest range moltype feature distinguishing protein ligand. result implies pafnucy learned binding aﬃnity depends relationship molecules recognizing crucial. additionally weights selenium boron atom types barely changed training close result interpreted ways either network found features protein-ligand complexes important binding aﬃnity infrequent occurrence atom types ligands network able general patterns inﬂuence binding aﬃnity. inspect network utilizes input analyzed impact missing data prediction. inspect this selected pdea complexes benzimidazole inhibitor experiment carried follows produced corrupted complexes missing data predicted binding aﬃnity each. missing data produced deleting cubic original data. slid step thus yielding corrupted inputs. next rotated complex x-axis followed procedure thus yielding another corrupted inputs. then orientations took corrupted inputs highest drop predicted aﬃnity wanted atoms’ absence caused highest drops predictions. additionally considered corrupted complexes highest drop predictions amino-acids interacting ligand forms hydrogen bond forms hydrophobic contacts ligand. methodology presented applied complexes order elucidate speciﬁc ligandreceptor interactions profound eﬀect prediction. going back uncorrupted input wanted investigate pafnucy managed give almost identical predictions diﬀerent orientations complex inquiry analyzed activations hidden layers inputs. figure ﬁrst hidden layer diﬀerent activation patterns orientations input. pafnucy gets diﬀerent data needs diﬀerent ﬁlters ﬁrst convolutional layer process them. however closer output layer similar activations become. clearly model learned extract information diﬀerently presented data. figure important parts input. regardless complex orientation region input highest impact prediction. note second plot rotated back x-axis ease comparison. figures orientations identiﬁed region containing ligand nearest neighbourhood. boxes contain amino-acids participating interactions ligand i.e. forms hydrogen work presented deep neural network pafnucy used structure based ligand discovery campaigns; scoring function virtual screening aﬃnity predictor novel molecules after complex generated. model tested casf scoring power benchmark outperformed state-of-the-art scoring functions tested casf authors. results obtained careful analysis network show pafnucy makes reliable predictions based relevant features. together jupyter notebooks used prepare data analyze results freely available http//gitlab.com/cheminfibb/pafnucy. usage examples scripts also available facilitate common use-cases preparing input data predicting binding aﬃnity training network. hope features make pafnucy easily applicable adaptable researchers. preparing environment needed dependencies using model data done minimum eﬀort", "year": "2017"}