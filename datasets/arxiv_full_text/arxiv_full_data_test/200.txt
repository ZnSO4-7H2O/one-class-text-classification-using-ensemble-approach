{"title": "EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer  Interfaces", "tag": "q-bio", "abstract": " Brain computer interfaces (BCI) enable direct communication with a computer, using neural activity as the control signal. This neural signal is generally chosen from a variety of well-studied electroencephalogram (EEG) signals. For a given BCI paradigm, feature extractors and classifiers are tailored to the distinct characteristics of its expected EEG control signal, limiting its application to that specific signal. Convolutional Neural Networks (CNNs), which have been used in computer vision and speech recognition, have successfully been applied to EEG-based BCIs; however, they have mainly been applied to single BCI paradigms and thus it remains unclear how these architectures generalize to other paradigms. Here, we ask if we can design a single CNN architecture to accurately classify EEG signals from different BCI paradigms, while simultaneously being as compact as possible. In this work we introduce EEGNet, a compact convolutional network for EEG-based BCIs. We introduce the use of depthwise and separable convolutions to construct an EEG-specific model which encapsulates well-known EEG feature extraction concepts for BCI. We compare EEGNet to current state-of-the-art approaches across four BCI paradigms: P300 visual-evoked potentials, error-related negativity responses (ERN), movement-related cortical potentials (MRCP), and sensory motor rhythms (SMR). We show that EEGNet generalizes across paradigms better than the reference algorithms when only limited training data is available. We demonstrate three different approaches to visualize the contents of a trained EEGNet model to enable interpretation of the learned features. Our results suggest that EEGNet is robust enough to learn a wide variety of interpretable features over a range of BCI tasks, suggesting that the observed performances were not due to artifact or noise sources in the data. ", "text": "objective brain computer interfaces enable direct communication computer using neural activity control signal. neural signal generally chosen variety well-studied electroencephalogram signals. given paradigm feature extractors classiﬁers tailored distinct characteristics expected control signal limiting application speciﬁc signal. convolutional neural networks used computer vision speech recognition perform automatic feature extraction classiﬁcation successfully applied eeg-based bcis; however mainly applied single paradigms thus remains unclear architectures generalize paradigms. here design single architecture accurately classify signals diﬀerent paradigms simultaneously compact possible approach work introduce eegnet compact convolutional neural network eeg-based bcis. introduce depthwise separable convolutions construct eeg-speciﬁc model encapsulates well-known feature extraction concepts bci. compare eegnet within-subject cross-subject classiﬁcation current state-of-the-art approaches across four paradigms visual-evoked potentials error-related negativity responses movement-related cortical potentials sensory motor rhythms results show eegnet generalizes across paradigms better than achieves comparably high performance reference algorithms limited training data available. also show eegnet eﬀectively generalizes oscillatory-based bcis. addition demonstrate three diﬀerent approaches visualize contents trained eegnet model enable interpretation learned features. signiﬁcance results suggest eegnet robust enough learn wide variety interpretable features range tasks suggesting observed performances artifact noise sources data. models found https//github.com/vlawhern/arl-eegmodels. brain-computer interface enables direct communication machine brain signals traditionally bcis used medical applications neural control prosthetic artiﬁcial limbs however recent research opened possibility novel bcis focused enhancing performance healthy users often noninvasive approaches based electroencephalography generally speaking consists main processing stages data collection stage neural data recorded; signal processing stage recorded data preprocessed cleaned; feature extraction stage meaningful information extracted neural data; classiﬁcation stage decision interpreted data; feedback stage result decision provided user. stages largely across paradigms paradigm relies manual speciﬁcation signal processing feature extraction classiﬁcation methods process often requires signiﬁcant subject-matter expertise and/or priori knowledge expected signal. also possible that signal preprocessing steps often speciﬁc feature interest potentially relevant features could excluded analysis need robust feature extraction techniques continue increase technologies evolve application domains deep learning largely alleviated need manual feature extraction achieving state-ofthe-art performance ﬁelds computer vision speech recognition speciﬁcally deep convolutional neural networks grown part success many challenging image classiﬁcation problems surpassing methods relying hand-crafted features recent reviews). although majority systems still rely handcrafted features many recent works explored application deep learning signals. example cnns used epilepsy prediction monitoring auditory music retrieval detection visual-evoked responses motor imagery classiﬁcation deep belief networks used sleep stage detection anomaly detection motion-onset visual-evoked potential classiﬁcation cnns using time-frequency transforms data used mental workload classiﬁcation motor imagery classiﬁcation restricted boltzman machines used motor imagery adaptive method based stacked denoising autoencoders proposed mental workload classiﬁcation studies focused primarily classiﬁcation single task often times using task-speciﬁc knowledge designing network architecture. addition amount data used train networks varied signiﬁcantly across studies part diﬃculty collecting data diﬀerent experimental designs. thus remains unclear previous deep learning approaches would generalize tasks well variable training data sizes. eeg-based bcis. introduce depthwise separable convolutions previously used computer vision construct eeg-speciﬁc network encapsulates several well-known feature extraction concepts optimal spatial ﬁltering ﬁlter-bank construction simultaneously reducing number trainable parameters compared existing approaches. evaluate generalizability eegnet datasets collected four diﬀerent paradigms visual-evoked potential error-related negativity movement-related cortical potential sensory motor rhythm representing spectrum paradigms based classiﬁcation event-related potentials well classiﬁcation oscillatory components addition data collections contained varying amounts data allowing explore eﬃcacy eegnet various training data sizes. results follows show eegnet achieves improved classiﬁcation performance existing paradigm-agnostic model across nearly tested paradigms limited training data available. addition show eegnet eﬀectively generalizes across tested paradigms. also show eegnet performs well paradigm-speciﬁc model orders magnitude fewer parameters representing eﬃcient model parameters finally feature visualization model ablation analysis show neurophysiologically interpretable features extracted eegnet model. important cnns despite ability robust automatic feature extraction often produce hard interpret features. neuroscience practitioners ability derive insights cnn-derived neurophysiological phenomena important achieving good classiﬁcation performance depending intended application. validate architecture’s ability extract neurophysiologically interpretable signals several well-studied paradigms show network performance driven noise artifact signals data. remainder manuscript structured follows. section gives brief description four datasets used validate model. section describes eegnet model well models used model comparison. section presents results within-subject cross-subject classiﬁcation performance well results feature explainability analysis. discuss ﬁndings detail discussion. bcis generally categorized types depending feature interest event-related oscillatory. event-related potential bcis designed detect high amplitude frequency response known time-locked external stimulus. generally robust across subjects contain well-stereotyped waveforms enabling time course modeled machine learning eﬃciently contrast erp-based bcis rely mainly detection waveform external event stimulus table summary data collections used study. class imbalance present given odds; i.e. odds means class imbalance data class data class datasets class imbalance subject-dependent; therefore odds given average class imbalance subjects. oscillatory bcis signal power speciﬁc frequency bands external control generally asynchronous oscillatory signals time-locked external stimulus represented event-related spectral perturbation analyses oscillatory bcis diﬃcult train generally lower signal-to-noise ratio well greater variation across subjects summary data used manuscript found table event-related potential stereotyped neural response novel visual stimuli commonly elicited visual oddball paradigm participants shown repetitive nontarget visual stimuli interspersed infrequent target stimuli ﬁxed presentation rate observed parietal cortex waveform large positive deﬂection electrical activity observed approximately post stimulus onset strength observed deﬂection inversely proportional frequency target stimuli. strongest neural signatures observable especially targets presented infrequently image presentation rate increases more commonly referred rapid serial visual presentation used develop bcis large image database triage data used previously described brief description given below. participants volunteered rsvp study. participants shown images natural scenery rate images either containing vehicle person vehicle person present participants instructed press button dominant hand target image shown. target/non-target ratio %/%. data participants excluded analysis excessive artifacts and/or noise within data. data remaining participants ranged years analyzed. recordings digitally sampled scalp electrodes arranged montage using biosemi active system continuous data referenced oﬄine average left right earlobes digitally bandpass ﬁltered using ﬁlter implemented eeglab downsampled trials target non-target conditions extracted post stimulus onset used two-class classiﬁcation. error-related negativity potentials perturbations following erroneous unusual event subject’s environment task. observed variety tasks including time interval production paradigms forced-choice paradigms focus feedback error-related negativity amplitude perturbation following perception erroneous feedback produced bci. feedback characterized negative error component approximately followed positive component approximately visual feedback illustration). detection feedback provides mechanism infer possibly correct real-time incorrect output bci. two-stage system proposed hybrid shown improve performance speller online applications challenge determine whether feedback speller correct incorrect. data originally recorded using passive ag/agcl sensors following extended system electrode placement. prior analysis data band-pass ﬁltered using ﬁlter implemented eeglab down-sampled trials correct incorrect feedback extracted post feedback presentation used features two-class classiﬁcation. neural activities contain well oscillatory components. particular example movement-related cortical potential elicited voluntary movements hands feet observable along central midline electrodes contralateral hand foot movement mrcp components seen movement onset early desynchronization frequency band) movement onset movement onset mrcp used previously develop motor control bcis healthy physically disabled patients data used previously described brief description given below. study subjects performed self-paced ﬁnger movements using left index left middle right index right middle ﬁngers. data recorded using channel biosemi active system extensive signal noise present data data ﬁrst processed prep pipeline data referenced linked mastoids bandpass ﬁltered using ﬁlter implemented eeglab downsampled downsampled channel space standard channel biosemi montage. index middle ﬁnger blocks hand combined common control signal oscillatory-based sensorimotor rhythm wherein beta bands desynchronize sensorimotor cortex contralateral actual imagined movement. similar oscillatory component mrcp. although smr-based bcis facilitate nuanced endogenous control tend weak highly variable across within subjects conventionally demanding user-training long calibration times order achieve reasonable performance data used comes competition dataset data consists four classes imagined movements left right hands feet tongue recorded subjects. data originally recorded using ag/agcl electrodes sampled bandpass ﬁltered resampled timeseries follow pre-processing procedure described using software provided authors. training test sets epoched data seconds post onset note make predictions time range test set. perform four-class classiﬁcation using accuracy summary measure. introduce eegnet compact architecture eeg-based bcis applied across several diﬀerent paradigms trained limited data produce neurophysiologically interpretable features. visualization full description eegnet model found figure table respectively trials collected sampling rate channels time samples. model using adam optimizer using default parameters described minimizing categorical cross-entropy loss function. training iterations perform validation stopping saving model weights produced lowest validation loss. models trained nvidia quadro cuda cudnn tensorﬂow using keras omit bias units convolutional layers. note that convolutions onedimensional two-dimensional convolution functions ease software implementation. software implementation found https//github.com/vlawhern/arl-eegmodels. figure overall visualization eegnet architecture. lines denote convolutional kernel connectivity inputs outputs network starts temporal convolution learn frequency ﬁlters uses depthwise convolution connected feature individually learn frequency-speciﬁc spatial ﬁlters. separable convolution combination depthwise convolution learns temporal summary feature individually followed pointwise convolution learns optimally feature maps together. full details network architecture found table outputting feature maps containing signal diﬀerent band-pass frequencies. setting length temporal kernel half sampling rate allows capturing frequency information above. depthwise convolution size learn spatial ﬁlter. applications computer vision main beneﬁt depthwise convolution reducing number trainable parameters convolutions fully-connected previous feature maps importantly used eeg-speciﬁc applications operation provides direct learn spatial ﬁlters temporal ﬁlter thus enabling eﬃcient extraction frequency-speciﬁc spatial ﬁlters depth parameter controls number spatial ﬁlters learn feature two-step convolutional sequence inspired part filter-bank common spatial pattern algorithm similar nature another decomposition technique bilinear discriminant component analysis keep convolutions linear found signiﬁcant gains performance using nonlinear activations. apply batch normalization along feature dimension applying exponential linear unit nonlinearity help regularize model dropout technique dropout probability withinsubject classiﬁcation help prevent over-ﬁtting training small sample sizes whereas dropout probability cross-subject classiﬁcation training sizes table eegnet architecture number channels number time points number temporal ﬁlters depth multiplier number pointwise ﬁlters number classes respectively. dropout layer within-subject classiﬁcation cross-subject classiﬁcation block separable convolution depthwise convolution representing activity followed pointwise convolutions main beneﬁts separable convolutions reducing number parameters explicitly decoupling relationship within across feature maps ﬁrst learning kernel summarizing feature individually optimally merging outputs afterwards. used eeg-speciﬁc applications operation separates learning summarize individual feature maps time optimally combine feature maps operation also particularly useful signals diﬀerent feature maps represent data diﬀerent time-scales information. case ﬁrst learn summary feature combine outputs afterwards. average pooling layer size used dimension reduction. classiﬁcation block features passed directly softmax classiﬁcation units number classes data. omit dense layer feature aggregation prior softmax classiﬁcation layer reduce number free parameters model inspired work table number trainable parameters model dataset cnn-based models. eegnet models orders magnitude smaller deepconvnet shallowconvnet across datasets. note temporal kernel length samples dataset data high-passed overcomplete representation learning feature maps inputs. notation eegnet-fd denote number temporal spatial ﬁlters learn; i.e. eegnet- denotes learning temporal ﬁlters spatial ﬁlters temporal ﬁlter. compare performance eegnet deepconvnet shallowconvnet models proposed full table descriptions models found appendix. implemented models tensorﬂow keras following descriptions found paper. architectures originally designed signals divided lengths temporal kernels pooling layers architectures correspond approximately sampling rate used models. train models train eegnet model deepconvnet architecture consists convolutional layers softmax layer classiﬁcation shallowconvnet architecture consists convolutional layers squaring nonlinearity average pooling layer nonlinearity log). would like emphasize shallowconvnet architecture designed speciﬁcally oscillatory signal classiﬁcation thus work well erp-based classiﬁcation tasks. however deepconvnet architecture designed general-purpose architecture restricted speciﬁc feature types thus serves valid comparison eegnet. table shows number trainable parameters model across models. also compare performance eegnet best performing traditional approach individual paradigm. erp-based data analyses traditional approach approach kaggle competition uses combination xdawn spatial filtering riemannian geometry channel subset selection feature regularization provide summary approach done steps perform feature normalization using ratio signifying equal weight penalties. penalty encourages absolute values parameters small whereas penalty encourages squares parameters small xdawn+rg model parameters across comparisons exception initial number channels mrcp. original solution used ensemble bagged classiﬁers analysis compared single model approach single eegnet model identical training test sets expect gains ensemble learning beneﬁt approaches equally. original solution also used meta features speciﬁc data collection. goal work investigate general-purpose model eeg-based bcis omitted features speciﬁc particular data collection. oscillatory-based classiﬁcation traditional approach implementation one-versus-rest ﬁlter-bank common spatial pattern algorithm described provide brief summary approach classiﬁcation problem multi-class classiﬁcation requires train classiﬁer pairs combinations train ﬁlter pairs ﬁlter bank training data using auto-covariance shrinkage method give find optimal value elastic-net logistic regression maximizes validation accuracy evaluating trained classiﬁers held-out validation set. multi-class label trial classiﬁer produces highest probability among classiﬁers. note approach diﬀers slightly original technique proposed naive bayes parzen window classiﬁer. opted elastic logistic regression ease implementation fact used existing software implementations fbcsp classiﬁcation results reported sets analyses within-subject cross-subject. withinsubject classiﬁcation uses portion subjects data train model speciﬁcally subject although cross-subject classiﬁcation uses data subjects train subject-agnostic model. within-subject models tend perform better cross-subject models variety tasks ongoing research investigating techniques minimize need subject-speciﬁc information train robust systems within-subject four-fold blockwise cross-validation four blocks chosen training block validation ﬁnal block testing. perform statistical testing using repeated-measures analysis variance modeling classiﬁcation results response variable subject number classiﬁer type factors. cross-subject analysis mrcp choose random subjects validation subject test remaining subjects training process repeated times producing diﬀerent folds. follow procedure dataset except test subjects original kaggle competition test fold. perform statistical testing using one-way analysis variance using classiﬁer type factor. dataset partitioned data follows subject select training data subjects random training training data remaining subjects validation set. test remains original test competition. note enforces fully cross-subject classiﬁcation analysis never test subjects’ training data. process repeated times subject creating diﬀerent folds. mean standard error classiﬁcation performance calculated folds. perform statistical testing analysis using testing procedure within-subject analysis. training within-subject cross-subject models apply class-weight loss function whenever data imbalanced class-weight apply inverse proportion training data majority class example dataset odds non-targets targets development methods enabling feature explainability deep neural networks become active research area past years proposed essential component robust model validation procedure ensure classiﬁcation performance driven relevant features opposed noise artifacts data present three diﬀerent approaches understanding features derived eegnet summarizing averaged outputs hidden unit activations approach focuses summarizing activations hidden units layers speciﬁed user. work choose summarize hidden unit activations representing data depthwise convolution spatial ﬁlters tied directly particular temporal ﬁlter provide additional insights spatial localization narrow-band frequency activity. summarize spatially-ﬁltered data calculating diﬀerence averaged time-frequency representations classes using morlet wavelets visualizing convolutional kernel weights approach focuses directly visualizing interpreting convolutional kernel weights model. generally speaking interpreting convolutional kernel weights diﬃcult cross-ﬁlter-map connectivity layers. however eegnet limits connectivity convolutional layers possible interpret temporal convolution narrow-band frequency ﬁlters depthwise convolution frequency-speciﬁc spatial ﬁlters. calculating single-trial feature relevance classiﬁcation decision approach focuses calculating single-trial basis relevance individual features resulting classiﬁcation decision. positive values relevance denote evidence supporting outcome negative values relevance denote evidence outcome. analysis used deeplift rescale rule implemented calculate single-trial feature relevance. deeplift gradient-based relevance attribution method calculates relevance values feature relative reference input technique similar layerwise relevance propagation used previously analysis analysis used elucidate feature relevance high-conﬁdence versus low-conﬁdence predictions figure -fold within-subject classiﬁcation performance mrcp datasets model averaged folds subjects. error bars denote standard errors mean. that minimal diﬀerence models dataset signiﬁcant diﬀerences mrcp dataset eegnet models outperforming models. dataset also eegnet models performing better others compare performance cnn-based reference algorithms traditional approach eegnet- eegnet-. within-subject four-fold cross-validation results across algorithms mrcp datasets shown figure observed across paradigms statistically signiﬁcant diﬀerence eegnet- eegnet- indicating increase model complexity statistically improve classiﬁcation performance. dataset cnn-based models signiﬁcantly outperform xdawn+rg performing signiﬁcantly diﬀerent amongst themselves. dataset eegnet- outperforms deepconvnet shallowconvnet xdawn+rg eegnet- outperforms deepconvnet shallowconvnet biggest diﬀerence observed among approaches mrcp dataset eegnet models statistically outperform others signiﬁcant margin four-fold cross-validation results dataset shown figure performances shallowconvnet fbcsp similar replicating previous results reported deepconvnet performance signiﬁcantly lower. also eegnetfigure -fold within-subject classiﬁcation performance dataset model averaged folds subjects. error bars denote standard errors mean. deepconvnet statistically performed worse models shallowconvnet eegnet- performed similarly fbcsp. cross-subject classiﬁcation results across algorithms mrcp datasets shown figure similar within-subject analysis observed statistical diﬀerence eegnet- eegnet- across datasets dataset cnn-based models signiﬁcantly outperform xdawn+rg performing sigfigure cross-subject classiﬁcation performance mrcp datasets model averaged folds. error bars denote standard errors mean. mrcp datasets minimal diﬀerence deepconvnet eegnet models models outperforming shallowconvnet. dataset reference algorithm signiﬁcantly outperforms models. figure cross-subject classiﬁcation performance model averaged folds subjects. error bars denote standard errors mean. cnn-based models perform similarly slightly outperforming fbcsp. niﬁcantly diﬀerent amongst themselves. mrcp dataset eegnet- deepconvnet signiﬁcantly outperform shallowconvnet also deepconvnet shallowconvnet performance better compared within-subject performance mrcp dataset. dataset xdawn outperforms models cross-subject classiﬁcation results dataset shown figure found signiﬁcant diﬀerence performance across cnn-based models illustrate three diﬀerent approaches characterize features learned eegnet summarizing averaged outputs hidden unit activations visualizing convolutional kernel weights calculating single-trial feature relevances classiﬁcation decision. illustrate approach dataset cross-subject trained eegnet- model. chose analyze ﬁlters dataset fact multiple neurophysiological events occur simultaneously participants told press button dominant hand whenever target image appeared screen. this target trials contain event-related potential well alpha/beta desynchronizations contralateral motor cortex button presses. interested whether eegnet architecture capable separating confounding events. also interested quantifying classiﬁcation performance architecture whenever speciﬁc ﬁlters removed model. figure shows spatial topographies four ﬁlters along average wavelet timefrequency diﬀerence calculated using morlet wavelets target trials nontarget trials. four distinct ﬁlters appear. time-frequency analysis filter shows increase low-frequency power approximately image presentation followed desynchronizations alpha frequency. nearly subjects dataset right-handed also signiﬁcant activity along left motor cortex. time-frequency analysis filter figure visualization features derived eegnet- model conﬁguration particular cross-subject fold dataset. spatial topoplots spatial ﬁlter. mean wavelet time-frequency diﬀerence target non-target trials individual ﬁlter. appears show signiﬁcant theta-beta relationship; increases theta activity previously noted literature response targets relationship theta beta previously noted. time-frequency diﬀerence filter appears correspond increase low-frequency power approximately image presentation. table performance cross-subject trained eegnet- model removing certain ﬁlters model using model predict test randomly chosen fold dataset. values bold denote best performing model removing ﬁlters time. number ﬁlters removed increases decreases classiﬁcation performance although magnitude decrease depends ﬁlters removed. figure visualization features derived within-subject trained eegnet- model subject dataset. columns shows learned temporal kernel second window associated spatial ﬁlters that many temporal ﬁlters isolating slower-wave activity network identiﬁes higher-frequency ﬁlter approximately also conducted feature ablation study iteratively removed ﬁlters re-applied model predict trials test set. combinations four ﬁlters. classiﬁcation results ablation study shown table test performance minimally impacted removal single ﬁlter largest decrease occurring removing filter expected removing pairs ﬁlters decrease performance pronounced largest decrease observed removing filters removing filters results practically change classiﬁcation performance compared full model suggesting important features task captured filters ﬁnding reinforced looking classiﬁcation performance three ﬁlters removed; model contains filter performs fairly well compared models contain filter filter figure shows ﬁlters learned eegnet- model within-subject classiﬁcation subject dataset. column ﬁgure denotes learned temporal kernel associated spatial ﬁlters note learning temporal ﬁlters length samples correspond seconds time; hence estimate frequency temporal ﬁlter four times number observed cycles. eegnet- learns slow-frequency activity approximately high-frequency activity approximately figure compares spatial ﬁlters associated frequency band learned eegnet- spatial ﬁlters learned fbcsp ﬁlter-bank four combinations. ease description notation denote row-column ﬁlter. many ﬁlters strongly positively correlated across models ﬁlter eegnet- ﬁlter fbcsp strongly negatively correlated figure comparison spatial ﬁlters learned fbcsp ﬁlter bank class combination spatial ﬁlters learned eegnet- temporal ﬁlters capture frequency activity subject dataset similar ﬁlters appear across fbcsp eegnet-. figure shows single-trial feature relevances eegnet- calculated using deeplift three three diﬀerent test trials cross-subject fold mrcp dataset. high-conﬁdence predictions correctly show contralateral motor cortex relevance expected whereas low-conﬁdence prediction feature relevance broadly distributed time space scalp. figure shows additional example using deeplift analyze feature relevance cross-subject trained eegnet- model test subject dataset. margaux previously noted average correct feedback trials earlier peak positive potential corresponding approximately whereas positive peak potential incorrect trials occurs slightly later approximately temporal diﬀerence timing peak positive potential incorrect feedback trials correct feedback trials also deeplift feature relevances align closely peak positive potential classes suggesting network focused peak positive potential relevant feature classiﬁcation. ﬁnding supports results previously reported showed strong positive correlation amplitude peak positive potential accuracy error detection. figure single-trial feature relevance cross-subject trained eegnet- model using deeplift three diﬀerent test trials mrcp dataset high-conﬁdence correct prediction left ﬁnger movement high-conﬁdence correct prediction right ﬁnger movement low-conﬁdence incorrect prediction left ﬁnger movement. titles include true class label predicted probability label. spatial topoplots relevances time points approximately button press. expected high-conﬁdence trials show correct relevances corresponding contralateral motor cortex left right button presses respectively. low-conﬁdence trial relevances mixed broadly distributed without clear spatial localization motor cortices. work proposed eegnet compact convolutional neural network eeg-based bcis generalize across diﬀerent paradigms presence limited data produce interpretable features. evaluated eegnet state-of-the-art approach oscillatory-based bcis across four datasets visual-evoked potentials error-related negativity movement-related cortical potentials sensory motor rhythms best knowledge represents ﬁrst work validated single network architecture across multiple datasets feature characteristics data sizes. work introduced depthwise separable convolutions signal classiﬁcation showed used construct eeg-speciﬁc model encapsulates well-known feature extraction concepts. finally feature visualization ablation analysis show neurophysiologically interpretable features extracted eegnet model providing validation evidence network performance driven noise artifact signals data. last ﬁnding particularly important critical component understanding validity robustness model architectures architectures general figure single-trial feature relevance cross-subject trained eegnet- model using deeplift test subject dataset. feature relevances three correctly predicted trials incorrect feedback along predicted probability three correctly predicted trials correct feedback. black line denotes average calculated channel incorrect feedback trials correct feedback trials thin vertical line denotes positive peak average waveform. feature relevances coincide strongly positive peak average waveform trial. also positive peak occurring slightly earlier correct feedback trials versus incorrect feedback trials consistent results human engineers understanding meaning features poses signiﬁcant challenge producing interpretable models especially true cnns used analysis data features neural signals often non-stationary corrupted noise artifacts study illustrated three diﬀerent approaches visualizing features learned eegnet analyzing spatial ﬁlter outputs averaged trials dataset visualizing convolutional kernel weights dataset comparing weights learned fbcsp performing single-trial relevance analysis mrcp datasets. dataset compared single-trial feature relevances averaged erps showed relevant features coincided peak positive potential correct incorrect feedback trials shown previous literature positively correlated classiﬁer performance addition conducted feature ablation study understand impact classiﬁcation decision presence absence particular feature dataset. analyses showed eegnet capable extracting interpretable features generally corresponded known neurophysiological phenomena. results suggest classiﬁcation performances observed artifact noise sources data. results showed spatial ﬁlters learned eegnet temporal kernels around signiﬁcantly correlated spatial ﬁlters learned fbcsp ﬁlter bank dataset. interesting note optimization criterion diﬀerent optimization criterion eegnet this guaranteed learned ﬁlters methods would comparable. encouraging many ﬁlters fact overlap suggesting eegnet learning similar feature representation fbcsp. analysis directly enabled eegnet’s depthwise convolutions spatial ﬁlters directly temporal ﬁlter aspect unique model. generally speaking classiﬁcation performance deepconvnet eegnet similar across cross-subject analyses whereas deepconvnet performance lower across nearly within-subject analyses possible explanation discrepancy amount training data used train model; cross-subject analyses training sizes times larger within-subject analyses. suggests deepconvnet data-intensive compared eegnet unsurprising result given model size deepconvnet orders magnitude larger eegnet believe intuition consistent ﬁndings originally reported developers deepconvnet state training data augmentation strategy needed obtain good classiﬁcation performance dataset. contrast work show eegnet performed well across tested datasets without need data augmentation making model simpler practice. general found that withincross-subject analyses shallowconvnet tended perform worse datasets oscillatory dataset opposite behavior observed deepconvnet. believe fact shallowconvnet architecture designed speciﬁcally extract bandpower features; situations dominant feature signal amplitude shallowconvnet performance tended suﬀer. opposite situation occurred deepconvnet; architecture designed extract frequency features performance lower situations frequency power dominant feature. contrast found eegnet performed well shallowconvnet classiﬁcation well deepconvnet classiﬁcation suggesting eegnet robust enough learn wide variety features range tasks. severe underperformance shallowconvnet within-subject mrcp classiﬁcation unexpected given similarity neural responses mrcp fact shallowconvnet performed well smr. discrepancy performance amount training data used within-subject mrcp classiﬁcation approximately training trials evenly split among left right ﬁnger movements whereas dataset training trials evenly split among four classes. addition observe large deviations shallowconvnet performance datasets fact shallowconvnet performed fairly well within-subject classiﬁcation even though dataset smallest among datasets used study determining underlying source phenomena explored future research. available channels transformed signal subset channels models fall generally signiﬁcant increase data dimensionality thus requiring either data model regularization learn eﬀective feature representation. introduces hyperparameters must learned increasing potential variability model performance hyperparameter misspeciﬁcation. models fall generally require priori knowledge channels select. example model proposed uses time-frequency decomposition channels inputs motor imagery classiﬁcation task. channel selection intentional given fact neural responses motor actions observed strongest channels easily observed time-frequency analysis. also working three channels authors reduce signiﬁcant increase dimensionality data. approach works well feature interest known beforehand approach guaranteed work well applications features observed channels limiting overall utility approach. believe models fall eegnet others oﬀer best tradeoﬀ input dimensionality ﬂexibility discover relevant features providing available channels. especially important technologies evolve novel application spaces features needed future bcis known beforehand project sponsored u.s. army research laboratory arl-h-hr arla-hrcyb cooperative agreement number wnf---. views conclusions contained document authors interpreted representing oﬃcial policies either expressed implied u.s. government. u.s. government authorized reproduce distribute reprints government purposes notwithstanding copyright notation herein. deepconvnet shallowconvnet architectures given tables respectively. deepconvnet designed general-purpose architecture restricted speciﬁc feature types whereas shallowconvnet designed speciﬁcally oscillatory signal classiﬁcation. table shallowconvnet architecture number channels number time points number classes respectively. here ’square’ ’log’ activation functions given respectively. note clip function minimum input value small number numerical stability.", "year": "2016"}