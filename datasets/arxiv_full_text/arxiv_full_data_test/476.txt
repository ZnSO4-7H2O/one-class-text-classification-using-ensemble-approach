{"title": "Representability of algebraic topology for biomolecules in machine  learning based scoring and virtual screening", "tag": "q-bio", "abstract": " This work introduces a number of algebraic topology approaches, such as multicomponent persistent homology, multi-level persistent homology and electrostatic persistence for the representation, characterization, and description of small molecules and biomolecular complexes. Multicomponent persistent homology retains critical chemical and biological information during the topological simplification of biomolecular geometric complexity. Multi-level persistent homology enables a tailored topological description of inter- and/or intra-molecular interactions of interest. Electrostatic persistence incorporates partial charge information into topological invariants. These topological methods are paired with Wasserstein distance to characterize similarities between molecules and are further integrated with a variety of machine learning algorithms, including k-nearest neighbors, ensemble of trees, and deep convolutional neural networks, to manifest their descriptive and predictive powers for chemical and biological problems. Extensive numerical experiments involving more than 4,000 protein-ligand complexes from the PDBBind database and near 100,000 ligands and decoys in the DUD database are performed to test respectively the scoring power and the virtual screening power of the proposed topological approaches. It is demonstrated that the present approaches outperform the modern machine learning based methods in protein-ligand binding affinity predictions and ligand-decoy discrimination. ", "text": "work introduces number algebraic topology approaches multicomponent persistent homology multi-level persistent homology electrostatic persistence representation characterization description small molecules biomolecular complexes. multicomponent persistent homology retains critical chemical biological information topological simpliﬁcation biomolecular geometric complexity. multi-level persistent homology enables tailored topological description interand/or intra-molecular interactions interest. electrostatic persistence incorporates partial charge information topological invariants. topological methods paired wasserstein distance characterize similarities molecules integrated variety machine learning algorithms including k-nearest neighbors ensemble trees deep convolutional neural networks manifest descriptive predictive powers chemical biological problems. extensive numerical experiments involving protein-ligand complexes pdbbind database near ligands decoys database performed test respectively scoring power virtual screening power proposed topological approaches. demonstrated present approaches outperform modern machine learning based methods proteinligand binding afﬁnity predictions ligand-decoy discrimination. ii.a persistent homology ii.a. simplicial complex simplex simplicial complex ii.a. homology chain boundary operator cycle group boundary group homology group ii.a. persistent homology filtration persistence ii.a. simplicial complexes ﬁltration vietoris-rips complex alpha complex covalent bonds non-covalent interactions multi-leveled protein structures protein-ligand protein-protein protein-nucleic acid complexes ii.c element speciﬁc persistent homology ii.d distance matrix induced persistent homology ii.d. multi-level persistent homology ii.d. interactive persistent homology ii.d. correlation function based persistent homology flexibility rigidity index based ﬁltration matrix ii.d. electrostatic persistence ii.d. multicomponent persistent homology ii.e feature generation topological invariants counts bins barcode statistics persistence diagram slice statistics representation ii.f. k-nearest neighbors algorithm barcode space metrics bottleneck distance metric wasserstein metric ii.f. gradient boosting trees ii.f. deep convolutional neural networks iii.a ligand based protein-ligand binding afﬁnity prediction data feature vectors gradient boosting trees barcode space metrics k-nearest neighbor regression performance multicomponent persistent homology robustness topological models iii.b complex based protein-ligand binding afﬁnity prediction data sets groups topological features performance association robustness algorithm redundant element combination features potential overﬁtting usefulness element types interactive betti- barcodes importance atomic charge information relevance elements rare respect data sets persistence deep convolutional neural networks iii.c structure-based virtual screening data data processing evaluation topology based machine learning models conclusion introduction arguably machine learning become important developments data science artiﬁcial intelligence. ability extract features various levels hierarchically deep convolutional neural networks made breakthroughs image processing video audio computer vision whereas recurrent neural networks found success analyzing sequential data text speech.– deep learning algorithms able automatically extract high-level features discover intricate patterns large data sets. general major advantages machine learning algorithms ability deal large data sets uncover complicated relationships. recently machine learning become indispensable tool biomoelcular data analysis structural bioinformatics. almost every computational problem molecular biophysics biology predictions solvation free energy solubility partition coefﬁcient protein-ligand binding afﬁnities mutation induced protein stability change molecular multipolar electrostatics virtual screening machine learning based approaches either parallel complementary physics based counterparts. success deep learning fueled rapid growth several areas biological science including bioactivity smallmolecule drugs– genetics large data sets available. despite success deep cnns dealing small molecules direct application deep cnns three-dimensional macromolecule structures extremely expensive prone accuracy reduction insufﬁcient grid resolution inadequate chemical labeling. result deep cnns competitive terms accuracy efﬁciency commonly used machine learning algorithms random forest gradient boosted trees predictions based biomolecular data. major obstacle development deep learning nets biomolecular data presence geometric biological complexities. biomolecules characterized geometric features electrostatic features high level features amino-acid sequence features based physical chemical biological understandings. geometric features coordinates distances angles surface areas– curvatures– important descriptors biomolecules.– however geometric features often involve much structural detail frequently computationally intractable large biomolecular data sets. electrostatic features include atomic partial charges coulomb potentials atomic electrostatic solvation energies polarizable multipolar electrostatics. descriptors become essential highly charged biomolecular systems nucleic acid polymers protein-ligand complexes. high level features refer values ionizable groups neighborhood amino acid compositions involvement hydrophobic polar positively charged negatively charged special case residues. sequence features consist secondary structures position-speciﬁc scoring matrix co-evolution information. sequence features annotations provide rich resource bioinformatics analysis biomolecular systems. topology offers unconventional representation biomolecules. topological features biomolecules generated variety ways. powerful topological features obtained multicomponent persistent homology element speciﬁc persistent homology recently carried comprehensive comparison performance geometric features electrostatic features high level features sequence features topological features prediction mutation induced protein folding free energy changes four mutation data sets. surprisingly topological features outperform features. unlike geometry topology well known power simpliﬁcation geometric complexity.– global description generated classical topology based concept neighborhood. space continuously deformed another considered present topological features. sense topology distinguish folded protein unfolded form. property prevents classical topology characterization biomolecular structures. instead using topology describe single conﬁguration connectivity persistent homology scans sequence conﬁgurations ordered ﬁltration parameter output sequence topological invariants partially captures part geometric features. persistent homology applied biomolecular systems earlier works. mathematics persistent homology relatively branch algebraic topology. dealing proteins small molecules conventionally consider atoms point clouds. given point cloud data type persistent homology turns point sphere radii systematically increasing. corresponding topological invariants persistence varying radius values computed. therefore method embeds multiscale geometric information topological invariants achieve interplay geometry topology. consequently persistent homology captures topological structures continuously range spatial scales. called persistent homology given radius topological invariants i.e. betti numbers practically calculated means homology groups. past decade much theoretical formulation– many computational algorithms– developed. onedimensional topological invariants generated persistent homology often visualized persistence barcodes persistence diagrams. recent years multidimensional persistence attracted much attention hope better characterize data shape multiple measurements interest. persistent homology applied various ﬁelds including image/signal analysis– chaotic dynamics veriﬁcation sensor networks complex networks data analysis– shape recognition– computational biology. compared traditional computational topology– and/or computational homology persistent homology inherently adds additional dimension i.e. ﬁltration parameter. ﬁltration parameter used embed important geometric quantitative information topological invariants. such importance retaining geometric information topological analysis recognized persistent homology advocated approach handling data sets. recently introduced persistent homology mathematical modeling prediction nano-particles unfolding proteins biomolecules. proposed molecular topological ﬁngerprint reveal topology-function relationships protein folding protein ﬂexibility. established ﬁrst quantitative topological analyses persistent homology based predictions curvature energy fullerene isomers. also shown correlation persistence barcodes energies computed physical models molecular dynamics experiments. moreover introduced ﬁrst differential geometry based persistent homology utilizes partial differential equations ﬁltration. recently developed topological representation address additional measurements interest stacking persistent homology outputs sequence frames molecular dynamics sequence different resolutions. also introduced ﬁrst topological ﬁngerprints resolving ill-posed inverse problems cryo-em structure determination. constructed ﬁrst topology based machine-learning algorithms protein classiﬁcation involving tens thousands proteins hundreds tasks. also developed persistent-homology based software automatic detection protein cavities binding pockets. despite much success found persistent homology limited characterization power proteins protein complexes applied directly single selection atoms. essentially biomolecules complex geometric constitution also intricate biological constitution. fact biological constitution essential biomolecular structure function. persistent homology designed reduce geometric complexity biomolecule easily miss biological information. overcome difﬁculty introduced multicomponent persistent homology element speciﬁc persistent homology recognize chemical constitution topological simpliﬁcation biomolecular geometric complexity. esph atoms speciﬁc element types biomolecule selected certain chemical information emphasized. esph able outperform geometric electrostatic representations large data sets also able shed light molecular mechanism protein-ligand binding relative importance hydrogen bond hydrophilicity hydrophobicity various spatial ranges. objective present work explore representabilityand reduction power multicomponent persistent homology biomolecules. take combinatorial approach scan variety element combinations examine characterization power components. additionally also propose multi-level persistence study topological properties non-covalent bond interactions. approach enables devise persistent homology describe interactions interest atoms connected series covalent bonds delivers richer representation especially small molecules. moreover enhance power topological representation introduce electrostatic persistence embeds charge information topological invariants class features multicomponent persistent homology. electrostatics paramount importance biomolecules. aforementioned approaches realized modiﬁcation distance matrix abstract setting example vietoris-rips complex. complexity reduction guaranteed topological representation biomolecular structures. obviously multicomponent persistent homology representation biomolecule leads higher machine learning dimensionality compared original single component persistent homology biomolecule. therefore subject overﬁtting overlearning problem machine learning theory. fortunately gradient boosting trees method relatively insensitive redundant high dimensional topological features. finally since components arranged dimension ordered feature importance multicomponent persistent homology barcodes naturally two-dimensional representation biomolecules. representation easily used image-like input data deep architecture different topological dimensions i.e. betti- betti- betti- treated multichannels. approach addresses nonlinear interactions among important element combinations keeping information less important ones. barcode space metrics bottleneck distance generally wasserstein metrics offer direct description similarity molecules readily used nearest neighbor regression kernel based methods. performance wasserstein distance protein-ligand binding afﬁnity predictions examined work. rest manuscript organized follows. section devoted introduce methods algorithms. present multicomponent persistent homology multi-level interactive persistent homology vectorized persistent homology representation electrostatic persistence. formulations crucial representability persistent homology biomolecules. machine learning algorithms associated present topological data analysis brieﬂy discussed. results presented section iii. ﬁrst consider characterization small molecules. precisely cross-validation protein-ligand binding afﬁnities prediction solely ligand topological ﬁngerprints studied. illustrate excellent representability multicomponent persistent homology comparison physics based descriptors. additionally investigate representational power proposed topological method sets benchmark protein-ligand binding data sets namely pdbbind pdbbind pdbbind bpdbind data sets contain thousands protein-ligand complexes extensively studied literature. results indicate multicomponent persistent homology offers powerful representations protein-ligand binding systems. aforementioned study characterization small molecules protein-ligand complexes leads optimal selection features models used virtual screening. finally consider directory useful decoys database examine representability multicomponent persistent homology virtual screening distinguish actives decoys. data used work total compounds containing active ligands bind targets families. large number state-of-the-art virtual screening methods applied data set. demonstrate present multicomponent persistent homology outperforms methods. paper ends conclusion. methods algorithms ii.a persistent homology concept persistent homology built mathematical concept homology associates sequence algebraic objects abelian groups topological spaces. discrete data atomic coordinates biomolecules algebraic groups deﬁned simplicial complexes constructed simplices generalizations geometric notion nodes edges triangles tetrahedrons arbitrarily high dimensions. homology characterizes topological connectivity geometric objects terms topological invariants i.e. betti numbers used distinguish topological spaces counting k-dimensional holes. betti- betti- betti- respectively represent independent components rings cavities physical sense. persistent homology betti numbers evaluated along ﬁltration parameter radius ball level hypersurface function continuously varies interval. therefore persistent homology induced ﬁltration. given biomolecule change persistence topological invariants ﬁltration offer unique characterization. concepts brieﬂy discussed below. ii.a. simplicial complex simplex k-simplex denoted convex hull afﬁnely independent points convex hull nonempty subset points forms subsimplex regarded face points also called vertices simplicial complex simplices simplicial complex faces simplex also intersection pair simplices either empty common face simplices. ii.a. homology chain k-chain simplicial complex denoted formal linear combination ksimplices here take ﬁeld coefﬁcients linear combination. rule ﬁelds k-chain group called chain group. boundary operator boundary operator denoted maps linear combination ksimplices linear combination boundaries k-simplices. k-simplex simplex face vertex absent. cycle group k-cycle k-chain whose image boundary operator empty set. collection k-cycles forms group denoted kernel ck−. boundary group image called boundary group denoted subgroup following property boundary operator homology group homology group quotient group deﬁned zk/bk. used compute betti numbers. betti number betti number deﬁned often computed rankhk rankzk rankbk. ii.a. persistent homology filtration ﬁltration simplicial complex nested sequence subcomplexes simplicial complex. persistence given simplicial complex ﬁltration p-persistent homology group deﬁned ii.a. simplicial complexes ﬁltration given ﬁnite points non-negative scale parameter vietoris-rips complex alpha complex constructed follows. vietoris-rips complex predeﬁned metric subset forms simplex collection simplices vietoris-rips complex ﬁnite metric space scale parameter denoted rips. obvious rips rips) alpha complex alpha alpha complex scale parameter given delaunay triangulation induced voronoi diagram simplex delaunay triangulation belongs alpha -faces length greater similar rips complex alpha complex also property alpha alpha) ii.b biological considerations development persistent homology motivated potential dimensionality reduction abstraction simpliﬁcation biomolcular complexity. early applications persistent homology biomolecules emphasis given major global features. short barcodes regarded noise. example persistent homology used identify tunnel gramicidin channel study membrane fusion. predictive modeling biomolecules features wide range scales might important target quantity. global scale biomolecular conformation captured. intermediate scale smaller intradomain cavities need identiﬁed. local scale important substructures addressed pyrrolidine side chain proline. features different scales reﬂected barcodes different centers persistences. therefore applications biomolecules make exhaustive persistent homology compared applications global features matter local features mapped noise. earlier persistent homology focused qualitative analysis. recently persistent homology devised quantitative tool. aforementioned applications descriptive regression based analysis also applied persistent homology predictive modeling biomolecules. however biomolecules structurally biologically complex. geometric biological complexities include covalent bonds non-covalent interactions effects chirality trans distinctions multi-leveled protein structures protein-ligand protein-nucleic acid complexes. covering large range spatial scales enough power model. biological details also explored. address underlying biology physics modifying distance function selecting various sets atoms according element types describe different interactions. biological considerations discussed section. covalent bonds covalent bonds formed shared electron pairs bonding pairs. lengths number covalent bonds easily detected betti- barcodes. macromolecules type covalent bonds similar bond lengths thus betti- barcode patterns. non-covalent interactions non-covalent interactions play critical role maintaining structure biomolecules mediating chemical biological processes solvation partition coefﬁcient binding protein-dna speciﬁcation molecular self-assembly etc. physically non-covalent interactions electrostatic waals forces hydrogen bonds π-effects hydrophobic effects etc. ability characterize non-covalent interactions essential task methodological development. betti- betti- barcodes suitable characterization arrangement interactions larger scale. additionally propose multi-level persistence electrostatic persistence reveal local pairwise non-covalent interactions betti- barcodes well. multi-leveled protein structures protein structures typically described terms primary secondary tertiary quaternary ones. protein primary structure linear sequence amino acids polypeptide chain. secondary structure mainly refers α-helix β-sheets highly regular easily detected distinct frenet-serret frames. tertiary structure refers structure single polypeptide chain. formation involves various non-covalent interactions salt bridges hydration effects often disulﬁde bonds. quaternary structure refers aggregation individual polypeptide chains multiprotein complex. protein structures complicated functional domains motifs particular folds. protein structural variability complexity result challenge opportunity methodological developments. various persistent homology techniques including multicomponent multi-level multidimensional multiresolution electrostatic interactive persistent homologies designed either earlier work paper protein structural variability complexity. protein-ligand protein-protein protein-nucleic acid complexes topological characterization proteins complicated protein interactions binding ligands proteins and/or molecules. although normal protein involves carbon hydrogen nitrogen oxygen sulfur atoms protein-ligand complexes bring variety elements play including phosphorus ﬂuorine chlorine bromine iodine many important biometals calcium potassium sodium iron copper cobalt zinc manganese chromium vanadium molybdenum biological element important biological functions presence biomolecules treated uniformly points point cloud data. interaction protein nucleic acids intricate. qualitatively multiscale multi-resolution persistent homology demonstrates interesting features structures. typically structures ﬂexible difﬁcult extract topological patterns. interactive persistent homology element speciﬁc persistent homology binned representation persistent homology outputs designed deal interactions protein-ligand protein-protein protein-nucleic acid complexes. approaches worked well protein-mutation site interactions. additionally multi-level persistent homology electrostatic persistence proposed work useful tools describe speciﬁc interactions. ii.c element speciﬁc persistent homology important issue protect chemical biological information topological simpliﬁcation. mentioned early treat different types atoms structureless points point cloud data. element speciﬁc persistent homology multi-component persistent homology proposed retain biological information topological analysis. element selection similar predeﬁned vertex color conﬁguration graphs. atoms passed persistent homology algorithms information extracted mainly reﬂects overall geometric arrangement biomoelcule different spatial scales. passing atoms certain element types certain roles persistent homology analysis different types interactions geometric arrangements revealed. protein-ligand binding modeling selection carbon atoms characterizes hydrophobic interaction network whilst selection nitrogen and/or oxygen atoms characterizes hydrophilic network network potential hydrogen bonds. protein structural analysis computation atoms identify geometric voids inside protein suggest structural instability computation atoms reveals overall structure amino acid backbones. addition combination various selections atoms based element types provides detailed description biomolecular system hidden relationships structure function learned machine learning algorithms. lead discovery important interactions realized prior. realized passing atoms selected element types persistent homology computation. concept used various deﬁnitions distance matrix discussed follows. ii.d distance matrix induced persistent homology biomolecular systems complex geometry also chemistry biology. effective describe complex biomolecular systems necessary modify ﬁltration process. three commonly used ﬁltrations namely radius ﬁltration distance matrix ﬁltration density ﬁltration biomolecules. distance matrix deﬁned smoothed cutoff functions proposed earlier work deal interactions within spatial scale interest biomolecules. present work introduce distance matrices enhance representational power persistent homology cover important interactions covered earlier works. distance matrices used abstract construction simplicial complexes vietoris-rips complex. ii.d. multi-level persistent homology small molecules ligands protein-ligand complexes usually contain fewer atoms large biomolecules proteins. bonded atoms stay closer non-bonded ones cases. result collection betti- bars mostly provide information length covalent bonds. difﬁcult capture covalent bond interactions among atoms especially hydrogen bonds waals pairwise interactions betti- barcodes. order describe covalent interactions propose multi-level persistent homology simply modifying distance matrix similar idea modifying distance matrix emphasize interactions protein ligand. given original distance matrix large number greater maximal ﬁltration value chosen persistent homology algorithm. note matrix fail satisfy triangle inequality whilst still satisﬁes construction principle rips complex. figure illustration representation ability reﬂecting structural perturbations among conformations molecule. betti- betti- results generated using rips complex conformations. present multi-level persistent homology able describe selected interactions interest delivers beneﬁts characterizing biomolecules. firstly pairwise non-covalent interactions reﬂected betti- barcodes. secondly treatment generates higher dimensional barcodes small structural ﬂuctuation among different conformations molecule captured. persistent barcode representation molecule signiﬁcantly enriched better distinguish different molecular structures isomers. illustration take ligand protein-ligand complex code bcd\" atoms. different conformation ligand generated using frog server. persistent barcodes generated using rips complex distance matrices identical betti- bars simple structure. case betti- bars reﬂect length bond therefore fail distinguish slightly different conformations molecule. however smallest number bonds travel atom atom number greater maximal ﬁltration value. ii.d. interactive persistent homology protein-ligand binding analysis and/or mutation analysis interested change topological invariants induced binding interactions and/or mutations. similar idea multi-level persistent homology design distance matrix focus interactions interest. atoms interactions atoms atoms interest. interactive original distance matrix induced euclidean metrics correlation function based distances atoms number greater maximal ﬁltration value. applications respectively sets atoms protein atoms ligand protein ligand complex. case characterization interactions ligand protein important task. modeling site speciﬁc mutation induced protein stability changes could atoms mutation site could atoms surrounding residues close mutation site. similar treatment used protein-protein protein-nucleic acid interactions. ii.d. correlation function based persistent homology biomolecules interaction strength pair atoms usually align linearly euclidean distances. example waals interaction often described lennard-jones potential. therefore kernel function ﬁltration used emphasize certain geometric scales. correlation function based ﬁltration matrix introduced earlier work additionally simultaneously correlation functions characterized different scales generate multiscale representation biomolecules. flexibility rigidity index based ﬁltration matrix form correlation function based ﬁltration matrix constructed ﬂexibility rigidity index. case lorentz function used euclidean distance point point parameter controlling scale related radius atoms. distance matrices based correlation functions used patterns different spatial scales addressed separately altering scale parameter ηij. note rigidity index given ii.d. electrostatic persistence electrostatic effects important effects biomolecular structure function dynamics. embedding electrostatics topological invariants particular interest useful describing highly charged biomolecules nucleic acids complexes. introduce electrostatics interaction induced distance functions address electrostatic interactions among charged atoms. abstract distance charged particles rescaled according charges geometric distance modeled distance atoms partial charges atoms nonzero tunable parameter. positive number opposite charge interactions addressed negative number like charge interactions interest. form function adopted sigmoid function widely used activation function neural networks. function regularizes input signal interval. functions similarly used. formulation extended systems dipole higher order multipole approximations electron density. weak interactions long distances neutral charges result correlation values close repulsive interaction attractive interaction deliver correlation values respectively. distances induced used characterize electrostatic effects. parameter rather physical chosen effectively spread computed values interval results used machine learning methods. another simple choice charge correlation functions qiqj exp. position vector euclidean distance atom position scale parameter. equation used electrostatic ﬁltration well. case ﬁltration parameter charge density value cubical complex based ﬁltration used. ii.d. multicomponent persistent homology multicomponent persistent homology refers construction multiple persistent homology components given object describe properties. obviously element speciﬁc persistent homology leads multicomponent persistent homology. nevertheless element speciﬁc persistent homology emphasis given appropriate selection important elements describing certain biological properties functions. example biological context electronegative atoms selected describing hydrogen bond interactions polar atoms selected describing hydrophilic interactions carbon atoms selected describing hydrophobic interactions. note chemical context atom many sharply different chemical physical properties depending oxidation states. whereas multicomponent persistent homology emphasis placed systematic generation topological invariants different combinatorial possibilities construction high-dimensional persistent maps deep convolutional neural networks. additionally multicomponent persistent homology also constructed combination persistences electrostatic persistent homology resolution induced persistent homology etc. ii.e feature generation topological invariants barcode representation topological invariants offers visualization persistent homology analysis. machine learning analysis needs convert barcode representation topological invariants machine learning feature vectors. introduce methods i.e. counts bins barcode statistics generate feature vectors sets barcodes. methods discussed below. counts bins given atoms denote barcodes {iα}α∈a characterize interval respectively birth death positions ﬁltration axis. length persistence topological invariant given locate position position bars persistences split barcodes ﬁltration axis predeﬁned bins {rmbini}n bini left right positions bin. figure illustration dividing barcodes subsets. barcodes plotted persistence diagrams horizontal axis birth vertical axis death. left right subsets generated according slicing death birth persistence values. number elements set. note discussion applied three topological dimensions i.e. barcodes betti- betti- betti- general approach enables description bond lengths including length non-covalent interactions biomolecules referred binned persistent homology earlier work barcode statistics another method feature vector generation barcodes extract important statistics barcode collections maximum values standard deviations. given bars {}α∈a deﬁne sets birth {bα}α∈a death {dα}α∈a persistence bα}α∈a. three generated sense statistics collection statistic feature vectors barcodes. example consists average value numbers standard deviation numbers maximum minimum values numbers summation elements numbers count elements set. generation examining death. contains information extra terms birth death values longest bar. statistic feature vectors collected barcodes three topological dimensions i.e. betti- betti- betti-. persistence diagram slice statistics thorough description sets barcodes ﬁrst divide sets subsets extract features analogously barcode statistics method. shown figure persistence diagram divided slices different directions. barcodes fall slice form subset. subset described terms feature vector using barcode statistics method. persistence diagram sliced horizontally members subset similar death values barcode statistics feature vector generated birth values. similarly members subset similar birth values persistence diagram sliced vertically barcode statistics feature vector generated death values. barcode statistics feature vectors generate birth values death values persistence diagram sliced diagonally members subset similar persistence. type feature vector generation describes barcodes detail produce long feature vectors. representation construction multi-dimensional persistence interesting topic persistent homology. general believed multi-dimensional persistent better representational power complex systems described multiple parameters. although multidimensional persistence hard compute compute persistence parameter ﬁxing rest parameters sequence ﬁxed values. case parameters biﬁltration done taking turns parameter sequence ﬁxed values computing persistence parameter. example take sequence resolutions compute persistence distance ﬁxed resolution. sequence outputs stacked form multidimensional representation. figure topological maps channels sample pdbbind. maps protein-ligand complex maps difference protein-ligand complex protein only. horizontal axis dimension spatial scale vertical axis element combinations ordered importance. computing persistence multiple times stacking results especially useful parameters chosen ﬁltration parameter naturally discrete underlying orders. example multicomponent element speciﬁc persistent homology result many persistent homology computations different selections atoms. results ordered percentage atoms used whole molecule importance classical machine learning methods. also multiple underlying dimensions exist element speciﬁc persistent homology characterization molecules. property enables topological representation molecules. based observation performance predictor degenerates many element combinations used order element combinations according individual performance task using methods ensemble trees. combining dimension spatial scale dimension element combinations topological representation obtained. representation expected work better case complex geometry protein-ligand complexes. {ej}ne denoting collection element combinations ordered individual performance task bdim betti-dim barcodes obtained atoms element combination eight representations deﬁned i=··· barcode counting rule deﬁned betti- since bars start zero need bi). eight representations regarded eight channels topological image. protein-ligand binding analysis topological features generated barcodes protein-ligand complex differences barcodes protein-ligand complex protein. therefore total channels image protein-ligand complex. -channel image training prediction convolutional neural networks. characterization protein-ligand complexes using alpha complexes features generated alpha complex based persistent homology computations protein protein-ligand complex. total element combinations considered. interval divided equal length bins deﬁnes resolution topological images. therefore input feature sample tensor. figure illustrates channels sample pdbbind database. images directly used deep convolutional neural networks training prediction. ii.f machine learning algorithms discuss three machine learning algorithms including k-nearest neighbors regression gradient boosting trees deep convolutional neural networks. ii.f. k-nearest neighbors algorithm barcode space metrics simplest machine learning algorithms k-nearest neighbors classiﬁcation regression. regression given object property values obtained average weighted average values nearest neighbors induced given metric. then problem becomes construct metric dataset. biomolecules simply derived distances sets barcodes generated different biomolecules. popular barcode space metrics include bottleneck distance induced metric generally wasserstein metrics. deﬁnition metrics summarized follows. bottleneck distance metric given bars regarded ordered pairs distance bars deﬁned max. single deﬁned helps reﬂect difference existence void. ﬁnite sets barcodes β}β∈b bijection penalty deﬁned intuitively bijection penalized linking bars large difference ignoring long bars either set. bottleneck distance deﬁned minimum taken possible bijections subsets subsets wasserstein metric wasserstein metric generalized analog bottleneck distance deﬁned penalty interesting consider distances metric spaces hausdorff distance gromov-hausdorff distance yau-hausdorff distance biomolecular analysis. however exhaustive study issue beyond scope present work. barcode space metrics directly used assess representation power various persistent homology methods biomolecules without potential overﬁtting effects induced manually generated feature vectors. show section results barcode space metrics induced similarity measurement signiﬁcantly correlated molecule functions. wasserstein metric measures biomolecules also directly implemented kernel based method nonlinear support vector machine algorithm classiﬁcation regression tasks. however aspect explored present work. ii.f. gradient boosting trees gradient boosting trees ensemble method ensembles individual decision trees achieve capability learning complex feature target maps effectively prevent overﬁtting using shrinkage technique. gradient boosting trees method implemented using gradientboostingregressor module scikit-learn software package. parameters found efﬁcient previous study protein-ligand binding afﬁnity prediction used uniformly unless speciﬁed. parameters used n_estimators= max_depth= learning_rate=. loss=’ls’ subsample=. max_features=’sqrt’. ii.f. deep convolutional neural networks widely used convolutional neural network architecture employed beginning convolution layers followed dense layers. limited computation resources parameter optimization performed parameters adopted earlier work. reasonable parameters assigned manually. detailed architecture shown figure adam optimizer learning rate used. loss function mean squared error function. network trained batch size epochs. training data figure architecture deep convolutional neural network. structured layers shown boxes unstructured layers shown rectangles. convolution layers drawn number ﬁlters ﬁlter size activation function. dense layers drawn number neurons activation function. pooling size pooling layers dropout rate dropout layers listed. layers repeated twice marked sign right side layer. shufﬂed epoch. deep convolutional neural network implemented using keras theano backend. results discussion rational drug design discovery rapidly evolved important exciting research ﬁelds medicine biology. approaches potentially profound impact human health. ultimate goal determine predict whether given drug candidate bind target activate inhibit function results therapeutic beneﬁt patient. virtual screening important process rational drug design discovery aims identify actives given target library small molecules. mainly types screening techniques ligand-based structure-based. ligandbased approach depends similarity among small molecule candidates. structure-based approach trys dock candidate molecule target protein judge candidate modeled binding afﬁnity based docking poses. structure-based screening knowledge based rescoring methods using machine learning deep learning approaches shown improvements applied docking algorithms.– also apply method rescoring machine rerank candidates based docking poses generated docking software. figure statistics ligands protein clusters average numbers heavy atoms ligand protein cluster shown standard deviations number heavy atoms across protein cluster shown blue. number ligands cluster given parentheses. section explores representational power proposed persistent homology methods prediction protein-ligand binding afﬁnities discrimination actives non-actives protein targets. present method investigate three types problems. first consider ligand based protein-ligand binding afﬁnity predictions. problem designed examine representability proposed topological methods small molecules. additionally study protein-ligand complex based binding afﬁnity prediction. problem enables understand capability proposed topological methods dealing protein-ligand complexes. finally examine complex based classiﬁcation active ligands non-active decoys i.e. structure-based virtual screening optimal selection features methods determined studying ﬁrst applications leads main application studied work topological structure-based virtual screening. computational algorithms used study illustrated fig. iii.a ligand based protein-ligand binding afﬁnity prediction consider protein-ligand binding afﬁnity prediction using ligand based approach. essential hypothesis that given binding site target protein similar ligands ligands similar decisive substructures similar binding free energies. data machine learning algorithms i.e. gradient boosting trees wasserstein metrics employed study analyze representational power proposed method. cross-validations within ligand protein target carried out. data assess representational ability present persistent homology algorithms small molecules high quality data protein-ligand complexes binding afﬁnity data involving protein clusters introduced earlier subset pdbbind reﬁned detail given supporting material ref. consider ligand based approach predict binding afﬁnities protein-ligand complexes various protein clusters. such ligand information used topological analysis. ligand structures taken pdbbind database without modiﬁcation. numbers ligands protein clusters range statistics data terms average number heavy atoms standard deviations given fig. dataset cluster relatively large binding site able accommodate large ligands cluster relatively small binding site. feature vectors gradient boosting trees test rips complex based alpha complex based persistent homology computations betti- performed variety atom collections different element types using euclidean metric multi-level distance deﬁned types features generated denoted combination computed. protein cluster -fold -fold cross figure illustration similarities ligands measured barcode space wasserstein distances. ligands ordered according binding afﬁnities represented dots semicircle. connected nearest neighbors based barcode space wasserstein distances. optimal prediction would achieved lines stay close semicircle. majority connections stay near boundary upper half sphere demonstrating barcode space metric based wasserstein distance measurement reﬂects similarity function i.e. binding afﬁnity case. protein clusters best worst performance shown. protein cluster protein cluster validation repeated times subset feature vectors depending selected element type. median pearson correlation coefﬁcients root-mean-square error kcal/mol reported. rips deﬁned performed. comparison results shown table results corresponding alpha complex shown table %reftabalpha. average performance alpha complex rips complex pearson correlation coefﬁcient barcode space metrics k-nearest neighbor regression barcodes generated using rips complex using wasserstein metric leave-one-out prediction every sample performed k-nearest neighbor regression within protein cluster based wasserstein metric. results shown table performance best performing worst performing protein clusters shown figure better performance closer lines semicircle. performance multicomponent persistent homology noticed table topological features generated barcode statistics typically outperform created counts bins. r-b-e-s-gbt r-b-m-s-gbt perform similarly majority protein clusters whilst r-b-m-s-gbt assess circumstances multi-level persistent homology improve original persistent homology characterization small molecules analyze statistics size ligands figure turns protein cluster smallest average number heavy atoms protein cluster smallest standard deviation number heavy atoms. observation partially answers question cases small molecules relatively simple relatively similar size multi-level persistent homology able enrich characterization small molecules improves robustness model. enrichment improvement original persistent homology approach mainly realized higher dimensional betti numbers i.e. betti- betti-. table results conﬁrm betti- features computation withm inferior results euclidean distance whilst betti- betti- features based outperforms best result euclidean distance cases. interesting note although wasserstein metric based methods accurate approaches consensus result obtained averaging various wasserstein metric predictions quite accurate. unlike approaches wasserstein metric utilizes type barcodes. fact r-b-e-knn r-b-m-knn r-b-m-knn work well. finally fft-bp -fold cross validation results obtained based multiple additive regression trees physical descriptors including geometry charge electrostatics waals interactions since multiple additive regression trees essentially used present work appropriate compare fft-bp results results work. current topological descriptors built ligands predictive power physical descriptors built protein-ligand complexes constructed earlier work. description barcodes generated using alpha complex different sets atoms based different element combinations. features constructed using betti- betti- betti- barcodes following counts bins method bins equally dividing interval different element combinations considered including cnos cnospfclbri cnoh cnsh cosh nosh cnosh cnospfclbrih gradient boosting trees structured feature matrix used computation. barcodes used a-b-e-c-gbt used. instead counts bins barcode statistics method used generate features. barcodes used a-b-e-c-gbt used. persistence diagram slice statistics method used generate features. uniform bins dividing interval equal length bins used slice birth death persistence values. barcodes generated using rips complex euclidean distances. features generated following barcode statistics method. element combinations considered i.e. cnos cnospfclbri cnoh cnsh cosh nosh cnosh cnospfclbrih cclh cbrh result obtained setup r-b-e-s-gbt except ﬁrst level enrichbetti-n barcodes rips complex computation euclidean distance used. knearest neighbor regression performed wasserstein metric leave-one-out validation performed individually element combination average prediction element combinations taken output result. element combinations considered cnos cnospfclbri cnospfclbrih}. combinations selected based performance gradient boosting trees experiments. experiments a-b-e-c-gbt a-b-e-s-gbt a-b-e-ss-gbt r-b-e-s-gbt r-b-m-s-gbt r-b-e-knn r-b-e-knn r-b-e-knn r-b-m-knn r-b-m-knn r-b-m-knn cons fft-bp table pearson correlation coefﬁcients rmse parentheses binding afﬁnity predictions protein clusters title numbers parentheses denote numbers ligands cluster. median results repeated runs reported ensemble trees based methods account randomness algorithm. experimental labels ﬁrst letter indicates complex deﬁnition used alpha complex rips complex. second part starting followed forth part shows feature construction counts bins barcode statistics. last part indicates regression technique used ‘gbt’ gradient boosting trees ’knn’ k-nearest neighbors. detailed descriptions experiments given table results using features consensus results taking average predictions except speciﬁed results obtained -fold cross validations. fft-bp -fold cross validation results adopted ref. pearson correlation coefﬁcients given. robustness topological models certain elements rare data sets studied work. considering elements high occurrence hurt performance validations performed. however omitting occurrence elements sacriﬁce capability model handle data elements play important role. therefore decide keep rare elements result large number features redundancy features. example element combinations cbrh probably deliver performance samples data sets studied figure model performance number element combinations involved feature construction protein clusters results related alpha complex marked rips complex blue. work. test whether redundancy causes degenerated results model features element combination added model step model validated accumulation added features step. performance model measured pearson correlation coefﬁcient plotted number element combinations involved fig. cases fig. model robust inclusion element combinations. iii.b complex based protein-ligand binding afﬁnity prediction demonstrated representational power present topological method characterizing small molecules apply proposed topological method characterize protein ligand protein-ligand complex. biologically consider task i.e. prediction protein-ligand binding afﬁnity different approach based structural information protein ligand protein-ligand complex. deep convolutional neural network algorithms used section. table number complexes number protein families pdbbind data sets used present binding afﬁnity prediction. training sets obtained corresponding reﬁned sets excluding complexes corresponding test sets. protein families refer corresponding tests. data sets pdbbind database provides comprehensive collection structures protein-ligand complexes binding afﬁnity data. original experimental data protein data bank selected pdbbind database based certain quality requirements curated applications. shown table database expanding yearly basis. become standard resource benchmarking computational methods algorithms protein-ligand binding analysis drug design. popular data sets include version among them core core identical. large number scoring functions tested data sets. latest version enlarged core contains protein-ligand complexes represent protein families. therefore test relatively easier core whose complexes involve protein families. groups topological features performance association experiments proteinligand-complex-based protein-ligand binding afﬁnity prediction pdbbind datasets summarized table description betti- barcodes rips complex computation interactive distance matrix based euclidean distance used. features generated following counts bins method bins element combinations used possible paired choices item protein another item cnos ligand result total combinations. persistent homology computation feature generation r-b-i-c. however element combinations used possible paired choices item protein another item ligand result total element combinations. computation interactive distance matrix based betti- barcodes parameter method bins element combinations used possible paired choices item protein another item ligand result total element combinations. barcodes element combinations r-b-ci-b-c. features generated following barcode statistics method. betti- betti- barcodes alpha complex computation euclidean distance used. element combinations considered heavy atoms carbon atoms. features generated following barcode statistics method. table pearson correlation coefﬁcients rmse parentheses predictions various groups features four pdbbind core sets. results ensemble trees based methods median values repeated runs account randomness algorithm. deep learning based methods independent models generated ﬁrst place. consensus model built randomly choosing models process repeated times median reported. ﬁrst letter indicates deﬁnition complex alpha complex rips complex. second part euclidean. last part shows feature construction counts bins barcode statistics ‘bp’ pair single elements. results reported obtained combining features rows corresponding numbers. authors specify number repeated experiments reported performance best median experiments. best results repeated runs randomness reported parameters feature generation optimized dataset. median reported median reported robustness algorithm redundant element combination features potential overﬁtting intuitive combinations element types able enrich representation especially case higher dimensional betti numbers. however consideration combination element types rapidly increases dimensional feature space. high dimensional feature space almost inevitable exists nonessential redundant features. additionally importance feature varies across figure performance model number included element combinations. betti- betti- barcodes computed alpha complex used. features generated following barcode statistics method. element combinations possible paired choices item cnos protein another item cnos cnospfclbri ligand result element combinations. horizontal straight lines represents performance representation deep convolutional neural network. blue colors correspond pearson correlation coefﬁcient rmse respectively. different problems data sets. therefore preferable keep potentially important features general model expected cover wide range situations. test robustness model unimportant features select total element combinations betti- betti- betti- barcodes computed combinations using alpha complex euclidean distance. features generated following barcode statistics method. general model features generated ﬁrst place. element combinations sorted according importance scores general model. starting important element combination element combination added feature vector time resulting feature vector passed machine learning training testing procedure. level adding element combinations based importance scores thus less important feature added step. figure depicts changes pearson correlation coefﬁcient rmse respect increase element combinations predicting four pdbbind core sets. cases inclusion combinations readily deliver good models. behavior present method pdbbind quite different data sets. performance present method improves almost monotonically element combination increases. however three cases improvement unsteady. nevertheless performance ﬂuctuates within small range indicates present method reasonably stable increase element combinations. different perspective increase element combinations might lead overﬁtting machine learning. since model parameters ﬁxed experiments shows algorithms sensitive redundant features robust overﬁtting. figure assessment performance model samples elements rare data sets. four data sets pdbbind element testing subset original core sets ligands contain atoms particular element type. features used features table reported rmse average taken four data sets. experiment training original training features used. experiment training original training features involve particular element used. experiment training original training excluding samples contain atoms particular element type features used. elements experiment achieves best result experiment yields worst performance. usefulness element types interactive betti- barcodes using element combinations element types higher dimensional betti numbers enriches characterization geometry remains assess whether interactive betti- characterization beneﬁt element combinations element types. example denote interactive betti- barcodes carbon nitrogen atoms protein oxygen atoms ligand bcn−o barcodes carbon atoms protein oxygen atoms ligand bc−o barcodes nitrogen atoms protein oxygen atoms ligand bn−o. case persistent homology barcode representation bcn−o strictly union bc−o bn−o. however bcn−o might redundant bc−o bn−o. address concern test features interactive betti- barcodes element combinations features selected element combinations listed feature group feature group table four cases features combinations slightly outperforms performs well features combinations suggesting element combinations element types redundant combinations element types case interactive betti- characterization. importance atomic charge information element speciﬁc persistent homology atoms different element types characterized separately offers rough implicit description electrostatics system. however implicit treatment electrostatics lose important information atoms behave differently different oxidation states. therefore explicitly embed atomic charges interactive betti- barcodes described resulting topological features given feature group table seen table combination feature group euclidean distance based interactive betti- barcodes generally outperforms results obtained euclidean distance based features. observation suggests electrostatics play important role taken care explicitly protein-ligand binding problem. relevance elements rare respect data sets since majority samples training testing sets contain atoms element types performance model samples rare occurring elements respect data sets hardly reﬂected overall performance statistics. simplicity refer rarely occurring elements respect data sets simply figure heat plot channels. mean value standard deviation digit pdbbind reﬁned shown. maps protein-ligand complex maps difference protein-ligand complex protein only. vertical axis element combinations ordered according importance horizontal axis dimension spatial scales. rarely occurring elements discussion follows. assess aspects model potentially affect performance samples containing rarely occurring elements picked samples containing rarely occurring element original testing testing set. three experiments carried address questions training samples containing rarely occurring element crucial?\" features addressing rarely occurring element important?\". short answer according results shown figure speciﬁcally rarely occurring element exclusion samples containing element training exclusion features addressing element cause degenerated results. also shown exclusion samples rarely occurring element leads much worse results. observation suggests interactions lead different binding properties molecules different compositions. since modiﬁcations model deliver worse results conclude including samples training similar compositions test sample crucial success model speciﬁc test sample. even inclusion features element types element combinations deliver better results general testing sets features still kept model case sample similar element composition comes test sample. persistence deep convolutional neural networks deep learning potentially powerful many machine learning algorithms data size sufﬁciently large. present work natural construct representation incorporating element combination additional dimension resulting channels deﬁned section ii.e. element combinations used analysis. advantage introducing extra dimension convolutional neural networks prevent unimportant features interacting important ones lower levels model whilst generally unimportant features still kept model case essential speciﬁc problems certain portion data set. figure illustrates mean value standard deviation pdbbind reﬁned set. existence signiﬁcant standard deviations relatively unimportant element combinations indicates features might still contribute overall prediction. shown figure data sets except pdbbind representation convolutional neural networks performs signiﬁcantly better. inferior performance convolutional neural networks might result small data size. note training protein-ligand complexes whereas training sets complexes. consequently deep convolutional neural networks able outperform algorithm predicting core sets. indeed deep convolutional neural networks advantages dealing large data sets. iii.c structure-based virtual screening section examine performance proposed method main application paper structure-based virtual screening. dataset much larger applications protein-ligand binding afﬁnity prediction. therefore best performing procedures ligand-based binding afﬁnity prediction protein-ligand-complex-based binding afﬁnity prediction applied virtual screening application since tuning parameters dataset time consuming. data directory useful decoys used benchmark topological approach virtual screening. data contains protein targets classes i.e. nuclear hormone receptors kinases serine proteases metalloenzymes folate enzymes enzymes. total active ligands identiﬁed literature. number ligands target ranges tens hundreds. decoys constructed ligand zinc database commercially available compounds. decoys selected possess similar physical properties ligands dissimilar molecular topology. physical properties include molecular weight value number hydrogen bonding groups. results total compounds. discrepancy calculated partial charges ligand decoy sets reported original release datasets makes trivial virtual screening methods distinguish sets using charges. work sets recalculated gasteiger charges ligand decoy sets. data processing structure-based virtual screening possible complex structures target protein small molecule candidate required. dataset structures protein targets ligands decoys given generate protein-ligand complexes protein-decoy complexes using docking software. ﬁrst missing atoms proteins using proﬁx utility jackal software package. receptors ligands decoys prepared using scripts prepare_receptor.py prepare_ligand.py provided autodocktools module mgltools package bounding binding site deﬁned cube edge size equal centered geometric center crystal ligand. autodock vina used dock ligand decoy receptor. option exhaustiveness parameters default values. docking experiment pose lowest binding free energy reported autodock vina used machine learning based model. table parameters used ensemble trees methods parameters default. gradient boosting trees. random forest. extra trees. n_estimators. subsample. class_weight. learning_rate. max_feature evaluation metrics enrichment factor area receiver operating characteristic curve used evaluate method’s ability discriminating ligands decoys. deﬁned number active ligands total number decoys number decoys higher ranked ligand. value expected value random selection whereas perfect prediction results denoted efx% evaluates quality ranked compounds comparing percentage actives ranked compounds percentage actives entire compound set. deﬁned table median results repeated runs different random seeds reported. best marked bold. second block autodock vina results acquired runs. number ligands target listed parenthesis next target name. topology based machine learning models unlike physical based models training sufﬁcient size needed machine learning base models. evaluate performance various methods data structure data obtained docking associated protein target used test time. selection training given protein target follow procedure given literature entries associated rest proteins excluding within class testing protein reported positive cross-enrichment testing protein method topvs-ml deepvs-adv icma nnscore-advb glide ddfa-all ddfa-rl nnscore-advb ddfa-adv deepvs-dock ddfa-ad glide htvsb surﬂexa glide htvs raw-all autodock vinab surﬂex rosetta ligand autodock vina flexx autodock. phdock dock. topology based machine learning model called topvs-ml relies manually constructed features utilizes ensemble trees methods. complex small molecules docked receptor features r-b-i-bp r-b-ci-s a-b-e-s used whereas features r-b-m-s a-b-e-s used small molecules. gradient boosting trees method random forest method extra trees method employed voters. averaged probabilities output three methods used classiﬁer decide class testing samples. modules gradientboostingclassiﬁer randomforestclassiﬁer extratreesclassiﬁer scikit-learn package used. parameters three modules listed table performance protein targets reported table also generated virtual screening results autodock vina based modeled binding free energy compared present topvs-ml terms enrichment factors areas receiver operating characteristic curve comprehensive comparison average large number methods given table ﬁnal model reported table topological descriptors protein-compound interactions compounds also tested models using either aforementioned descriptions. topological descriptor small molecules used falls category ligand-based virtual screening achieved. topological model using descriptions protein-ligand interactions achieved. obtained model combining sets descriptors better individual performance suggesting groups descriptors complementary important achieving satisfactory results. marginal improvement made protein-compound complexes maybe various docking quality. similar situation encountered deep learning method. targets high quality results autodock vina ligand-based features achieve complex-based features achieve hand targets quality results autodock vina ligand-based features achieve complex-based features achieve results cases listed table observation suggests performance features describing interactions geometry protein-compounds complexes highly depends quality docking results. model small molecular descriptors delivers comparably well performing methods. performance model also competitive regime protein-ligand binding afﬁnity prediction based experimentally solved complex structures shown section iii.a. results suggest topology based small molecule characterization proposed work potentially useful applications small molecules predictions toxicity solubility partition coefﬁcient. conclusion persistent homology relatively branch algebraic topology main workhorse topological data analysis. topological simpliﬁcation biomolecular systems major motivation earlier persistent homology development. persistent homology applied computational biology including efforts. however predictive power primitive persistent homology limited early applications. address challenge recently introduced element speciﬁc persistent homology retain chemical biological information topological abstraction biomolecules. approach offers competitive predictions protein-ligand binding afﬁnity mutation induced protein stability changes. however representability predictive power small molecules interaction macromolecules remain unknown. present work introduces multicomponent persistent homology multi-level persistent homology electrostatic persistence chemical biological characterization analysis modeling. multicomponent persistent homology takes combinatorial approach create possible element speciﬁc topological representations. multi-level persistent homology allows tailored topological descriptions desirable interaction biomolecules. electrostatic persistence incorporates partial charges essential biomolecules topological invariants. approaches implemented appropriate construction distance matrix ﬁltration. representation power reduction power multicomponent persistent homology multilevel persistent homology electrostatic persistence validated databases namely pdbbind dud. pdbbind involves protein-ligand complexes contains near small compounds. classes problems used test proposed topological methods including regression protein-ligand binding afﬁnities discrimination active ligands non-active decoys problems examine representability proposed topological methods small molecules somewhat difﬁcult describe persistent homology chemical diversity variability sensitivity. additionally methods tested ability handle full protein-ligand complexes. advanced machine learning methods including wasserstein metric based nearest neighbors gradient boosting trees random forest extra trees deep convolutional neural networks utilized present work facilitate proposed topological methods quantitative biomolecular predictions. thorough examination method prediction binding afﬁnity experimentally solved protein-ligand complexes leads structure-based virtual screening method topvs outperforms modern methods. feature sets introduced work small molecules protein-ligand complexes extended applications d-structure based prediction toxicity solubility partition coefﬁcient small molecules complex structure based prediction proteinnucleic acid binding protein-protein binding afﬁnities.", "year": "2017"}