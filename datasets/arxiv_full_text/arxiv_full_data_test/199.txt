{"title": "Deep neural networks can be improved using human-derived contextual  expectations", "tag": "q-bio", "abstract": " Real-world objects occur in specific contexts. Such context has been shown to facilitate detection by constraining the locations to search. But can context directly benefit object detection? To do so, context needs to be learned independently from target features. This is impossible in traditional object detection where classifiers are trained on images containing both target features and surrounding context. In contrast, humans can learn context and target features separately, such as when we see highways without cars. Here we show for the first time that human-derived scene expectations can be used to improve object detection performance in machines. To measure contextual expectations, we asked human subjects to indicate the scale, location and likelihood at which cars or people might occur in scenes without these objects. Humans showed highly systematic expectations that we could accurately predict using scene features. This allowed us to predict human expectations on novel scenes without requiring manual annotation. On augmenting deep neural networks with predicted human expectations, we obtained substantial gains in accuracy for detecting cars and people (1-3%) as well as on detecting associated objects (3-20%). In contrast, augmenting deep networks with other conventional features yielded far smaller gains. This improvement was due to relatively poor matches at highly likely locations being correctly labelled as target and conversely strong matches at unlikely locations being correctly rejected as false alarms. Taken together, our results show that augmenting deep neural networks with human-derived context features improves their performance, suggesting that humans learn scene context separately unlike deep networks. ", "text": "table model performance predicting car/person likelihood ratings humans. ceil refers data reliability upper bound model performance given inter-subject variability ratings best model predicting person likelihoods based nontarget coarse scene features calculated model performance average cross-validated correlation random splits scenes. asterisks represent statistical significance comparison model statistical significance calculated fraction random splits model correlation exceeded best model. note model performance sometimes reduces adding extra features overfitting. abbreviations targets nontargets coarse features. targets nontargets etc. table improvement car/person detection obtained augmenting state -of-the-art cnns predicted human-derived contextual expectations. entry shows crossvalidated accuracy detecting cars matched scenes adek people matched scenes adek details supplementary table matched scenes comprised scene categories similar rated humans. best models highlighted bold. columns indicate kind model used column marked indicates baseline accuracy deep neural network; columns form indicate accuracy augmented feature lklhd predicted likelihood target category object; xlocn predicted horizontal location target category object ylocn predicted vertical location target category object; scale overall bounding area marked subjects. table improvement accuracy object categories. types object detectors alexnet rcnn were augmented using human-derived car/person likelihood scores novel scenes. stephen mitchell. ching illustrated journey. girshick faster r-cnn towards real-time object detection region proposal networks. ieee trans. pattern anal. mach. intell. lapuschkin binder montavon m√ºller k.-r. samek analyzing classifiers fisher vectors deep neural networks. ieee conf. comput. vis. pattern recognit. doi./cvpr.. zhou semantic understanding scenes adek dataset. arxiv katti peelen arun targets nontargets scene context influence real-world object detection? attention perception psychophys. doi./s--- davenport potter scene consistency object background perception. psychol. sci. recognition independent ofattentional focus. front. psychol. castelhano henderson initial scene representations facilitate movement guidance visual search. exp. psychol. hum. percept. perform. visual objects context. nat. rev. neurosci. torralba oliva castelhano henderson contextual guidance movements attention real-world scenes role global features object search. psychol. rev. ieee comput. soc. conf. comput. vis. pattern recognition cvpr felzenszwalb girshick mcallester ramanan object detection discriminatively trained part based models. ieee trans. pattern anal. mach. intell. segmentation ppt. proc. ieee conf. comput. vis. pattern recognit. doi./cvpr.. felzenszwalb girshick mcallester ramanan object detection discriminative trained part based models. ieee trans. pattern anal. mach. intell. simonyan zisserman deep convolutional networks large-scale image recognition. imagenet chall. doi./j.infsof... work funded itpar collaborative grant department science technology government india province trento. supported postdoctoral fellowship cognitive science research initiative government india. supported funding european research table model performance predicting likely location scale aspect ratio. models based various combinations features trained separately predict horizont position vertical position area aspect ratio person likely occur scene. best model case indicated using bold face. conventions table", "year": "2016"}