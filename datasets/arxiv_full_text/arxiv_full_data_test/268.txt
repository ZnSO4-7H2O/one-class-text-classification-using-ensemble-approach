{"title": "Model selection and parameter inference in phylogenetics using Nested  Sampling", "tag": "q-bio", "abstract": " Bayesian inference methods rely on numerical algorithms for both model selection and parameter inference. In general, these algorithms require a high computational effort to yield reliable estimates. One of the major challenges in phylogenetics is the estimation of the marginal likelihood. This quantity is commonly used for comparing different evolutionary models, but its calculation, even for simple models, incurs high computational cost. Another interesting challenge relates to the estimation of the posterior distribution. Often, long Markov chains are required to get sufficient samples to carry out parameter inference, especially for tree distributions. In general, these problems are addressed separately by using different procedures. Nested sampling (NS) is a Bayesian computation algorithm which provides the means to estimate marginal likelihoods together with their uncertainties, and to sample from the posterior distribution at no extra cost. The methods currently used in phylogenetics for marginal likelihood estimation lack in practicality due to their dependence on many tuning parameters and the inability of most implementations to provide a direct way to calculate the uncertainties associated with the estimates. To address these issues, we introduce NS to phylogenetics. Its performance is assessed under different scenarios and compared to established methods. We conclude that NS is a competitive and attractive algorithm for phylogenetic inference. An implementation is available as a package for BEAST 2 under the LGPL licence, accessible at https://github.com/BEAST2-Dev/nested-sampling. ", "text": "bayesian inference methods rely numerical algorithms model selection parameter inference. general algorithms require high computational eﬀort yield reliable estimates. major challenges phylogenetics estimation marginal likelihood. quantity commonly used comparing diﬀerent evolutionary models calculation even simple models incurs high computational cost. another interesting challenge relates estimation posterior distribution. often long markov chains required suﬃcient samples carry parameter inference especially tree distributions. general problems addressed separately using diﬀerent procedures. nested sampling bayesian computation algorithm provides means estimate marginal likelihoods together uncertainties sample posterior distribution extra cost. methods currently used phylogenetics marginal likelihood estimation lack practicality dependence many tuning parameters inability implementations provide direct calculate uncertainties associated estimates. address issues introduce phylogenetics. performance assessed diﬀerent scenarios compared established methods. conclude competitive attractive algorithm phylogenetic inference. implementation available package beast lgpl licence accessible https//github.com/beast-dev/nested-sampling. bayesian methods provide comprehensive framework explore parameter space uncertainty model-to-data ﬁtness. concept introduced phylogenetics gained popularity ﬂexibility dealing complex models large data sets contrast maximum likelihood estimation. increase computational power rise bayesian methods markov chain monte carlo approaches became feasible. popularity increased state-of-the-art implementations models programs like mrbayes beast phylobayes ﬁelds model selection plays integral part phylogenetic inference. wide variety diﬀerent criteria available task popular likelihood ratio test akaike information criterion bayesian information criterion bayes factors ratios marginal likelihoods. latter particular interest provides many advantages methods direct consequence probability theory used theory reasoning; allows comparison nested non-nested models; iii) based point estimate parameter space since averages parameter space; embodies occam’s razor involving prior distribution ∗corresponding author. address correspondence department statistics university auckland private model selection process. marginal likelihoods penalise inclusion parameter value unknown possible values data well. however marginal likelihood diﬃcult integral depends complexity model. finding ways eﬃciently estimate integral major challenges ﬁeld. simple monte carlo method estimating marginal likelihood harmonic mean despite popularity well-known overestimate real value variance inﬁnite situations resulting unreliable estimates. among accurate methods currently used phylogenetics path sampling stepping-stone sampling much accurate high computational cost. latter gained popularity recent years implementation diﬀerent phylogenetic software packages mrbayes beast however methods relatively large number tuning parameters need prior analysis rigorous method determining values appropriate accurate estimation marginal likelihood. also methods problems dealing likelihood shapes eﬃciently deal issues generalised version stepping-stone sampling proposed generalisation also allows regard phylogeny unknown parameter incorporating uncertainty tree topology model selection. general technique estimation marginal likelihood nested sampling method requires less tuning deal partly convex likelihood functions main feature reduction multidimensional integral parameter space one-dimensional integral likelihood function enclosed prior probability. technique several variants successfully applied ﬁelds like astronomy systems biology shown great promise parameter inference model selection. paper assess merits nested sampling phylogenetic inference compare established methods. firstly method assessed small phylogenetic test case. secondly reasonably dataset contains several partitions many parameters analysed order show consistent marginal likelihood estimates parameter inferences yielded finally datasets become standard phylogenetic datasets analysis mcmc method performance analysed marginal likelihood estimation parameter inference. prior distribution represents previous knowledge parameters updated likelihood function represents probability data given parameters model. marginal likelihood probability data model plays role model selection. indeed quantity used select among models. this also called evidence understand role note posterior distribution model given marginal likelihood shown prior probability model probability data. marginal likelihood also denoted henceforth. bayesian comparison models carried comparing posterior probabilities. comparison often ratio probabilities represents plausibility model another deﬁned follows ratio marginal likelihoods ﬁrst ratio right side called bayes factor preference model i.e. model assigned prior probability priors cancel posterior odds given ratio marginal likelihoods. although marginal likelihood generally ignored parameter inference plays role model selection measure goodness indeed probability data given model i.e. deﬁnition measure model marginal likelihood acts normalisation constant posterior distribution making probability density function. thus quantity multidimensional integral prior distribution times likelihood function parameter space. mcmc methods used parameter estimation within model ratios posterior densities therefore unable measure normalisation general. unlike maximum likelihood represents model single point quantity stands average well model data. average likelihood function respect prior model greatest evidence might diﬀerent model highest likelihood prior could down-weight regions parameter space. also marginal likelihood sensitive size region likelihood high. result methods could favour diﬀerent models. despite important role model selection marginal likelihood usually analytically intractable approximated numerical methods. typically phylogenetic models involve high level complexity making diﬃcult calculate marginal likelihood. suchard proposed savage-dickey ratio estimate bayes factors nested models huelsenbeck used reversible jump markov chain monte carlo including possible time-reversible models. nevertheless methods restricted particular group models. alternatives proposed allow general comparison models. among them harmonic mean popular estimate marginal likelihood importance-sampling approach. popularity simplicity requires samples posterior distribution. however estimator often inﬁnite variance overestimates true value marginal likelihood work high dimensions usual case phylogenetics accurate method path sampling also known thermodynamic integration proposed phylogenetics lartillot philippe method requires several markov chains transition distributions form path prior posterior distribution. transition functions deﬁned power posterior expected value respect power posterior distribution uses series values deﬁne transition distributions. value markov chain required estimate expected values consequently integral clearly increase accuracy comes cost increased computational complexity. another importance sampling approach stepping-stone sampling proposed relies transition distributions like order deﬁne equivalence marginal likelihood telescope product ratios normalising constants given performance method similar however requires slightly less computational eﬀort need posterior samples general requires smaller number transition distributions reduce discretisation bias also allows estimate bayes factor directly deﬁning path posterior models extended version generalised stepping-stone sampling uses reference distribution shorten distance prior posterior distribution. strategy potentially lead eﬃcient estimation process. like predecessor geometric path often used connect densities deﬁned reference distribution. power posterior equivalent reference posterior distribution respectively. accurate original version reference distribution approximates posterior distribution reasonably well. method also extended allowing tree topology variable allows user accommodate phylogenetic uncertainty model selection. potential leading remarkable improvements comparison original less tuning parameters lower variance avoidance numerical instabilities reduction computational time accurate case diﬀusive priors cases ps/ss overestimate true marginal likelihood although yield accurate estimates marginal likelihood require several speciﬁcations depending problem. firstly annealing schedule required. common practice diﬀerent numbers estimate stable. commonly used procedure described drummond bouckaert follows path sampling analysis number steps ﬁrst increase number steps whether marginal likelihood estimates remain unchanged could impractical situations instance priors used would increase number steps datasets. actually priors often incorrectly used constitute improper priors challenging mcmc sampling secondly path described β-values deﬁned. lartillot philippe proposed spread β-values regularly spaced since often variability expected values concentrated near authors proposed concentrate computational eﬀort place. example lepage used sigmoidal function estimate bayes factor using friel pettitt proposed x-values equally spaced advocated spreading values according evenly spaced quantiles beta finally methods require number samples power posterior β-value. main problem optimal settings vary case case. popularity implementation popular software mrbayes beast either settings deﬁned user predetermined tuning parameters chosen unsuitable problem hand. context appropriate reference distribution requires potentially fewer tuning parameters. firstly requires annealing/melting scheme estimation start either prior posterior distribution. unlike β-values necessarily need follow particular distribution eﬀectively control uncertainty estimate similarity reference posterior distributions thus values equally spaced also need many transitional distributions original version robust prior speciﬁcations i.e. prior huge eﬀect method performance. finally method requires number samples transitional distribution. usually presented methods general applicability however methods work shape likelihood function cumulative prior probabilities concave. partly convex likelihood functions might make require impractical computational eﬀort make fail outright transition distributions unable diﬀerent phases likelihood function resulting poor estimate. eﬃcient alternative works well appropriate reference distribution used otherwise fail dramatically general method nested sampling algorithm measures relationship likelihood values prior distribution uses compute marginal likelihood. characteristic allows among things cope partly convex likelihood functions. importantly unlike requires less problem-speciﬁc tuning. explain nested sampling detail original paper give details application phylogenetic inference. marginal likelihood evidence simpliﬁed notation given deﬁnition applies continuous parameter space phylogeny assumed ﬁxed. tree topology unknown parameter space additionally composed discrete part. case marginal likelihood incorporates tree parameter space known total marginal likelihood. strictly speaking deﬁnition given represents area cumulative distribution function similarly likelihood function seen positive random variable follows prior distribution evidence expected value likelihood function. nested sampling takes advantage property transforming multi-dimensional integral deﬁned one-dimensional integral follows integral used nested sampling displayed figure general function concentrates mass near zero posterior located small area prior. overloaded notation letter represents likelihood function diﬀerent domains parameter vector argument prior mass argument. note monotonically decreasing function reaches highest point lowest point means draws prior distribution likelihoods greater points curve obtained integral approximated numerically basic standard quadrature method lowest likelihood value. then point discarded active points replaced point sampled prior constrained greater likelihood value point replaced i.e. procedure shrinks parameter space according likelihood restriction. process repeated given stopping rule satisﬁed thus sequence increasing likelihood values discarded points generated. discarded points ones contribute estimate marginal likelihood respective likelihoods. discarded points generate increasing sequence likelihoods known precisely. important insight skilling corresponding values cannot measured precisely figure association cumulative prior mass likelihood function. nested sampling estimates gray area marginal likelihood. general small area prior concentrates ξi/ξi− variable follows beta distribution. iteration takes points follows uniform values cumulative probabilities consequently uniform distribution. maximum value related minimum likelihood value non-increasing function). since distribution xi/ξi− uniform maximum value ξi/ξi− follows beta distribution. skilling deﬁned schemes estimating ξ-values stochastic deterministic. thus sequence values generated used geometric mean seems reasonable given prior mass deﬁned geometrically equation scheme considered examples recommended authors. however arithmetic mean allows nested sampling connected rare event simulation allows alternative version highest cost nested sampling sampling restricted prior distribution skilling suggested metropolis-hastings algorithm usual explore prior additional condition rejecting proposal points fulﬁl likelihood restriction. starting value point sequence active points randomly selected iteration meet likelihood condition deﬁnition. several eﬃcient methods also proposed skilling’s method generate restricted prior samples application. unlike proposal mechanisms used standard mcmc methods sample posterior static distribution mechanisms deal variable target distribution time. particular tree proposals scenario. nested sampling compresses prior iteration making vary constant rate. proposals explore wide area beginning becomes constrained time. tree proposal mechanisms able adapt sampling characteristic. frequently uniform prior distribution assigned tree parameter space quite huge even taxa. initially bold moves would allow good exploration using less steps conservative ones. however acceptance probability would decrease drastically time fact target distribution gets constrained. hand conservative moves would require steps explore prior distribution beginning later acceptance probability would higher bold moves. ideally proposal mechanism take account dynamical behaviour target distribution time. brewer foreman-mackey stated heavy-tailed proposals eﬃcient slice sampling least simple experiments. work operators implemented beast described drummond bouckaert switched auto-optimisation features since target distribution changes time. posterior prior distributions respectively. quantity represents amount information posterior respect prior acquiring data. deﬁnition seen expected value /π)]. approximated according property measure central tendency typical value value seen bulk posterior mass occupies prior. idea helps deﬁne termination condition nested sampling described later. note prior distribution consistent likelihood function namely supports parameter values lower information likelihood function contradiction prior i.e. mass concentrated diﬀerent places. words previous belief changes acquiring data information gained data. uncertainty numerical uncertainty associated estimation comes sources approximating prior volume error imposed integration rule. however total uncertainty usually dominated ﬁrst. actually second inferred. note represents marginal computational cost since spent generating likelihood sequence. strategy used similarly parameter inference. another criterion based concept information deﬁned before. typically likelihood values start dominating prior mass contribution increases beginning prior mass dominates quantity. reaching maximum values start decrease. peak function guarantee general termination conditions work perfectly. might start increasing greater rate future overwhelming points currently high weights. speciﬁc cases maximum likelihood value known roughly anticipated possible conﬁdent won’t happen. work relative error termination criterion. yields posterior samples extra cost assign appropriate weights discarded output points. iteration taken point active points generating sequence discarded points discarded points contributed estimate marginal likelihood respective weights proportional posterior distribution words prior multiplied likelihood. thus sequence discarded points sampled according weights order posterior sample. eﬀective sample size related entropy posterior weights algorithm assessed diﬀerent phylogenetic scenarios order show performance marginal likelihood estimation parameter inference. firstly assessed taxa case. secondly reasonably dataset alignment split several partitions site model used carry model selection addition used assess information provided posterior distribution comparison standard mcmc method. then datasets consisting sequences eukaryote species analysed. datasets form part group standard datasets evaluating mcmc methods possess interesting characteristics challenging standard mcmc methods. performed using deterministic approach generate ξ-sequence trapezoidal rule method numerical integration. relative error termination criterion error tolerance analyses performed beast plots produced want verify behaves well correctly implemented small example. since possible calculate marginal likelihoods analytically phylogenetic datasets even simple models simulated data study taxa case estimate marginal likelihood high degree conﬁdence thus evaluate dataset part bigger dataset available internet contains taxa nucleotides. strict clock model assumed. prior tree consider yule model normal birth rate. relative rate lognormal. distributions centred according posterior means tight order narrow parameter space. reliable estimate true value marginal likelihood followed analysis proposed baele integrate likelihood prior popularly known arithmetic mean. consists average likelihood values sample drawn prior. method produces unbiased estimate. comparative purposes also consider stepping-stone method. dataset contains taxa nucleotides. chloroplast sites used divided partitions. represents challenging case since involves many parameters consequently huge parameter space. evaluate performance model selection compare results. also assess ability sampling posterior distribution compare standard mcmc method. clock models compared strict clock model relaxed clock model clock models compared marginal likelihoods. first estimate values using steps samples transitional distribution. speciﬁcations tested yield reliable estimates analysis replicated using single active point mcmc steps iteration generate samples required. strict relaxed clock models took approximately hours respectively intel core .ghz. results displayed table estimates show better relaxed clock model comparison strict clock model; former marginal likelihood substantially higher latter. terms bayes factor strong evidence favour relaxed clock model consistent taking account uncertainty associated estimates. actually conﬁdence intervals contain estimates cases. model selection made based intervals since overlap. example shows eﬀectiveness carry model selection. hypothetical case intervals would overlapped analyses redone increasing number active points order decrease uncertainty consequently width intervals. table marginal likelihood estimates euphorbia dataset. includes conﬁdence intervals contain estimates make evident potential model selection even simplest speciﬁcations posterior likelihood prior treeheight yulemodel birthrate kappa.rbcl kappa.rpl kappa.rpl kappa.rplex ucldstdev rate.mean rate.variance rate.coeﬃcientofvariation table mcmc posterior means standard deviations estimated features euphorbia dataset figure remaining kappa relative substitution rate estimates. estimates also include corresponding conﬁdence intervals case contain mcmc statistics. generate posterior sample described above. mean standard deviation calculated sample. procedure replicated times registering statistics. note procedure computationally expensive since require likelihood evaluations addition mcmc analysis performed statistics registered. chain length burn-in period thinning factor results displayed table posterior sample size ﬂuctuated points mean around standard deviation statistics also include corresponding conﬁdence intervals. apparent intervals contain mcmc estimates means well standard deviations posterior distribution. include posterior likelihood prior values well parameters. figure shows conﬁdence intervals estimates parameters similar scales. points stand mcmc estimates within intervals. alignment h¨ohna drummond consists ribosomal sequences tetrapod nucleotides remarkable feature tree space contains separate regions form islands high posterior probabilities whidden matsen showed islands separated operations intermediate topology unlikely never visited mcmc analysis. general mcmc chains tend stuck tree islands common problem standard mcmc methods. characteristics make good case assess performance compare standard methods. evaluate attributes parameter inference marginal likelihood estimation. figure mcmc estimates mean standard deviation parameters euphorbia dataset. intervals inferred using dots stand statistics obtained mcmc analysis. intervals contain mcmc statistics suggesting eﬀectiveness parameter inference. assumed relaxed clock models suitable. prior tree topologies yule model assumed uniform birth rate; clock rate lognormal distribution; relative rates default gamma priors implemented beast independent mcmc analyses performed order sample posterior distribution. chain length million burn-in period samples taken every steps. furthermore independent performed order sample posterior. active points considered steps order generate independent points required iteration. posterior values mcmc chains displayed figure apparent converge diﬀerent distributions. highly probable markov chains stuck tree islands unable escape. figure shows posterior clade probabilities reﬂect diﬀerent samples are. note clades support sample whereas sample clades support. hand yields samples consistent clade probabilities values notably total agreement. tend diﬀer case problems sampling. posterior sample sizes example around analysis replicated multiple times obtaining similar posterior clade probabilities analyses potential exploring parameter space diﬀerent areas iteration granted active points. even case using single active point particle explores parameter space according prior likelihood restriction according posterior embodies diﬃculties. figure comparison mcmc posterior clade probabilities tetrapod dataset. graph left shows diﬃculty sampling parameter space contain tree islands mcmc chains tend stuck consequently converge diﬀerent distributions. graph right shows consistency yielding posterior samples independent runs unlike standard mcmc methods. table marginal likelihood estimates obtained diﬀerent speciﬁcations tetrapod dataset. values speciﬁcation stand independent estimates. yield estimates close ones possibly diﬃculty sampling near posterior distribution. marginal likelihood estimated means algorithm estimation carried using steps. general speciﬁcations enough yield reliable estimates. active points considered respectively. table displays results. diﬀerent speciﬁcations estimates quite similar could lead trust outcome. however values presumably problems sampling near posterior distribution observed mcmc analyses carried before could lead underestimation. also situation would fail estimating marginal likelihood incapacity mcmc methods approximating posterior consequently generating reference distribution alignment consists sequences chloridoideae nucleotides tree space rather requires sample size order correctly infer posterior probabilities context markov chain length burn-in period thinning factor compared posterior sample considering active points. particular interested well performs probability clades. results displayed figure mcmc analysis eﬀective sampling sizes least indicating reliable approximation posterior. posterior clade probabilities obtained quite similar obtained mcmc analysis. values located around straight line reﬂecting agreement tree posterior samples. principally probabilities highly correlated values tend diﬀer case disagreement samples. posterior sample sizes around nested sampling general bayesian algorithm provides means estimate marginal likelihoods carry parameter inference. introduced phylogenetic inference variable tree topology. performance compared established methods available many phylogenetic software packages. behaves well taxa case possible compare method found yields reliable estimates. secondly compared using dataset contain sequences partitions. particular compared strict clock model relaxed clock model showing single active point enough carry model selection. analysis relaxed clock model found data better. then showed single used estimate marginal likelihood model provides also means estimate means standard deviations posterior distribution. thirdly showed yields consistent posterior clade probabilities independent runs case tree topology space contain tree islands unlike standard mcmc methods. context also showed diﬀer marginal likelihood estimation potentially problems dealing scenario. finally evaluated performance tree parameter space showing posterior clade probabilities agreement obtained standard mcmc method. become popular high accuracy estimating marginal likelihood. speciﬁcally become popular implementation widely-used phylogenetic software packages. however rely several problem-speciﬁc tuning parameters need speciﬁed user namely number distribution values number samples transitional distribution burn-in periods. dispenses distribution values requires number posterior samples calibrate reference distribution. calibrations essential good estimates. hand requires number active points number mcmc steps used generate replacement points. latter chosen relation number parameters. number exceed dimension parameter space order guarantee generation independent point otherwise marginal likelihood estimate biased lower. experience least times number parameters recommended diﬀerent values. number steps lower number active points increased. another area remains open research ﬁnding eﬃcient transition kernels. length determined termination conditions described previously. overall practice user-friendly methods presented. provides measure uncertainty single run. even though power posterior methods least simple form approximation uncertainties quantities never reported practice. uncertainty inversely proportional square root number active points; higher number accurate estimate. similar computational conditions higher uncertainty though depends problem whether parameters well-tuned. however uncertainty calculated directly single whereas requires several replications estimate uncertainty carried reliability speciﬁcations tuning parameters tested. practice could estimate marginal likelihood intervals competitive models thus carry model selection based them. case intervals overlap could speciﬁc models using active points increase precision narrow intervals. nested sampling also provides means carry parameter inference. involve extra cost since points used estimate marginal likelihood recycled. assessed method study clade probabilities certain statistics posterior distribution. particular showed even case using single active point used generate conﬁdence intervals parameters. method possesses interesting attributes. instance unlike conventional mcmc methods require burn-in period. general period represents high computational cost mcmc methods. furthermore method explores parameter space quite diﬀerent allows deal well complex scenarios parameter spaces composed tree islands challenging scenario standard mcmc methods. possesses several positive characteristics make competitive algorithm comparison established methods used currently phylogenetics. applied successfully diﬀerent ﬁelds believe success replicated phylogenetics shown work. nested sampling algorithm implemented package beast available https// github.com/beast-dev/nested-sampling lgpl licence. adapting idea feroz fully parallel version implemented runs nested sampling analyses particles", "year": "2017"}