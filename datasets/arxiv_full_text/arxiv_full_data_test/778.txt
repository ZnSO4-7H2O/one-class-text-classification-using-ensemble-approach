{"title": "Personalizing deep learning models for automatic sleep staging", "tag": "q-bio", "abstract": " Despite continued advancement in machine learning algorithms and increasing availability of large data sets, there is still no universally acceptable solution for automatic sleep staging of human sleep recordings. One reason is that a skilled neurophysiologist scoring brain recordings of a sleeping person implicitly adapts his/her staging to the individual characteristics present in the brain recordings. Trying to incorporate this adaptation step in an automatic scoring algorithm, we introduce in this paper a method for personalizing a general sleep scoring model. Starting from a general convolutional neural network architecture, we allow the model to learn individual characteristics of the first night of sleep in order to quantify sleep stages of the second night. While the original neural network allows to sleep stage on a public database with a state of the art accuracy, personalizing the model further increases performance (on the order of two percentage points on average, but more for difficult subjects). This improvement is particularly present in subjects where the original algorithm did not perform well (typically subjects with accuracy less than $80\\%$). Looking deeper, we find that optimal classification can be achieved when broad knowledge of sleep staging in general (at least 20 separate nights) is combined with subject-specific knowledge. We hypothesize that this method will be very valuable for improving scoring of lower quality sleep recordings, such as those from wearable devices. ", "text": "despite continued advancement machine learning algorithms increasing availability large data sets still universally acceptable solution automatic sleep staging human sleep recordings. reason skilled neurophysiologist scoring brain recordings sleeping person implicitly adapts his/her staging individual characteristics present brain recordings. trying incorporate adaptation step automatic scoring algorithm introduce paper method personalizing general sleep scoring model. starting general convolutional neural network architecture allow model learn individual characteristics ﬁrst night sleep order quantify sleep stages second night. original neural network allows sleep stage public database state accuracy personalizing model increases performance improvement particularly present subjects original algorithm perform well looking deeper optimal classiﬁcation achieved broad knowledge sleep staging general combined subject-speciﬁc knowledge. hypothesize method valuable improving scoring lower quality sleep recordings wearable devices. good sleep fundamental healthy life sleep suggested important diagnosis treatment various illnesses traditional analysis sleep measurements sleep laboratory focuses differentiating different sleep stages according aasm guidelines labels assigned second epoch conventionally labeling done manually qualiﬁed electrophysiologists. however increased awareness sleep health total population continuing rise number personal sleep trackers including mobile devices used sleep monitoring renewed interest developing automated routines amount available sleep data becomes quickly large analyzed visual screening. long history automated methods sleep staging reaching exciting results using large data sets. noteworthy examples include investigating unsupervised approaches used impressively large subject cohort analysis using somewhat simpler approach combining -layer neural network hidden markow model. additionally recent developments using deep learning architectures allow skipping tedious approach carefully deﬁning characteristic sleep features offer potentially powerful tool data sets. despite promise machine learning approaches incorporated idea exploiting personspeciﬁc information order improve algorithmic performance despite fact intra-subject variation sleep features known much smaller inter-subject variation property easily taken account human scorers. approaches learning global method personalizing model individual already successfully investigated related problems instance mood recognition seizure detection general cross paradigm transfer challenge sleep tracking naturally involves access multiple nights data individual thus would ﬁtting extension explore potential personalizing deep learning models sleep staging. study investigate possibility using transfer learning deep convolutional neural networks transform population models subject-speciﬁc personal models training convolutional neural network data large subjects ﬁne-tuning model test subject data ﬁrst night evaluating following night. ﬁrst demonstrate convolutional network outperforms traditional feature-based approach enough data available subsequently quantify improvement performance ﬁne-tuning model. ease replication develop models publicly available ’sleep edf’ database physionet data contains nights sleep subjects together single night additional subject. home-tracking devices suitable collecting large numbers nights likely access channels select subject ’fpz-cz’ derivation data horizontal derivation. network design evaluate potential convolutional neural network started network presented added minor tweaks illustrated figure described following fig. network diagram. input streams data subjected different banks ﬁlters each. prior input network epoched data rescaled always standard deviation equal standard deviations passed separately system fully connected layer additional input stream created identical setup analyzing data passing layer. since data different streams separate instantiations convolutional layers. instead passing epoch seconds network receives epochs total seconds increases performance giving network access likely states surrounding epoch question. better facilitate reproduction work quantitative description including parameters also found table additionally python code made available github upon acceptance paper. implemented network using keras theano python everything nvidia geforce cudnn library version evaluating performance network compare traditional feature-based approach precisely random forest based method presented this calculate median accuracy across subjects function amount subjects included training set. keep things simple shall exclude single-night subject analysis. comparison also include single-subject models classiﬁer trained ﬁrst night fine tuning investigate improvement obtained updating network night subject-speciﬁc information started general population model subject speciﬁc model created ’ﬁne tuning’ general model recording speciﬁc subject. precisely tuning ﬁrst untrained network trained using least nights afterwards general model presented ﬁrstnight single subject times finally model tested second-night subject. figure diagram. result tuning might depend detailed performance base line model important test method wide range base line models. achieve this implemented resampling strategy exploited maximally amount data available follows training ﬁrst-nights subjects used together second-nights ranging fig. finetuning diagram. first untrained network trained using least nights afterwards general model subjected repeated training generations ﬁrst-night single subject. finally model tested second-night subject. drastically increases number possible population models investigate tuning reducing size training result reduced performance classiﬁer inspected network performance iterations conﬁrmed maximal drop accuracy acceptably small using resampling scheme generated different different baseline models. effects tuning tested different baseline networks different test data sets shown figure also made possible investigate details subject speciﬁc variations shown figure analysis effects tuning test hypothesis stochastic variable deﬁned change accuracy tuning mean value less equal i.e. tuning improve accuracy. tested standard one-sided t-test. base line performance figure shows comparison neural network classiﬁer feature based approach function amount training data. full data used good performance obtained even neural network outperforms individualized random forest classiﬁer. also clear purely subject-speciﬁc neural network classiﬁer performs poorly. figure shows frequency content eegbased ﬁlters. calculated extracting ﬁlter coefﬁcients layer training nights estimating power spectrum ﬁlter. plot ﬁlters reordered according fig. accuracy function number subjects neural network well different versions random forest network. ’random forest single subject’ classiﬁer training night test night subject. evaluate detail performance improvement relative baseline figure shows scatter plots. left shown results different tunings right shows average improvement average baseline performance subjects. ﬁrst case general trend towards slight increase performance well marked effect cases base line performance relatively poor. latter average improvement present great majority subjects large improvements primarily happen subjects. performing t-tests results presented left right plots p-values respectively meaning cases performance increase tuning statistically signiﬁcant. figure shows results tuning different distributions baseline tuned performance subject shown. note trend greater improvement happens room improve also variation tuning often quite small. latter fact likely always tuning towards ﬁrst night subject whereas resampling training data ensures much greater spread base line performance. comparing network parameters tuning possible study greater detail tuning takes place. figure shown absolute relative change parameter values tuning averaged across layer. line corresponds separate subject. simplicity changes layers averaged tuning happens multiple layers particularly input ’c’. starting general convolutional neural network architecture compare performance random forest classiﬁer demonstrate network able learn relevant frequency bands sleep staging perform high accuracy. comparison network performs similar accuracy neural network approaches furthermore best sleep staging achieved classiﬁer access large amounts general sleep data well weighting towards individual classiﬁer supposed analyze data from. note tuned network better individual random forest model showcased figure random forest neural network general models despite fact already quite good. also tested performance neural network individual data seen figure results signiﬁcantly worse alternatives presented here. somewhat surprising given conventional wisdom surrounding transfer learning dictates tuning primarily take place particular context makes good sense; algorithm likely looking features known exhibit inter-subject variation early portions neural network tweaked. commensurate ﬁndings also found tuning outside last layer data. study tuning classiﬁer generally improves performance especially base line accuracy less delving results presented here much baseline variation seen related inter-subject differences data set; particular subjects included subjects removed testing resulting base line performance worse tuning similarly advantageous. presumably means subjects sleep signatures common signature becomes less common training data tuning increases efﬁciency. important note ’rare’ sleep features already training tuning night represent information rather introduces weighting information already available fig. scatter plot accuracy tuning. note improvement particularly large base line accuracies line shows diagonal. avr. subject tuning. improvement much larger subjects. towards relevant task. basis quite possible tuning would retain effect larger training sets; knowing sleep characteristic individual advance likely always beneﬁcial scoring. beneﬁcial note interscorer agreement shown matches results particularly presented figure since seeing little improvement accuracies limit scoring likely essentially ’perfect’ tuning represent improvement. rather tuning ﬁxes subjects classiﬁer performing much worse interscorer agreement. short tuning work little room improve. still would interesting conﬁrm results presented would change much larger subject cohort. comparison found increase performance increasing cohort size reached subjects. would seem model presented here trained subjects still highly specialized. finally important point success tuning related differences scorers. data used here different trained scorers used. nine subjects person scored ﬁrst second nights. subjects comparing list figure subjects particularly prone improvement. indeed subjects median accuracy decreased tuning list. data used study data likely higher quality would available mobile sleep monitors despite fact used channels. anticipate case worse starting data room improvement larger many subjects fall ’sub category’ discussed above. similar additionally believe tuning would work well creating classiﬁers recordings people sleep disorders. case imagine scenario base line model trained large cohort healthy subjects subsequently tuned smaller cohort sick subjects. believe main drawback approach need labeled data subject. however envisage multiple scenarios serious ﬂaw. primarily many clinical cases would highly valuable monitor sleep extended period. cases would issue ﬁrst night manually scored even require additional hardware light weight wearable device. possible tuning improvement seen would also possible using scored hour tuning data. case could imagine scenario patient would come clinic wearable handed take day-time leave wearable. case manual scoring requires extra hardware compared automatic scoring short naps controlled setting would likely relatively cheap solution. also important remember network architecture used chosen tuning mind seems reasonable assume similar gains would achieved different architectures. paper investigated utility generating personal sleep staging models tuning existing population based models. found procedure generally increases model performance particularly difﬁcult subjects. theorize increase performance improved handling subject-speciﬁc quirks. fig. distributions accuracies tuning. subjects reordered achieve increasing tuning effect. note tuning variation accuracies generally quite low. likely reﬂects tuning always uses ﬁrst-night. research supported wellcome trust centre grant /z//z national institute health research oxford biomedical research centre authors grateful assistance orestis taheri link short sleep duration obesity recommend sleep prevent obesity archives disease childhood vol. nov. available http//dx.doi.org/./adc.. smaldone honig byrne sleepless america inadequate sleep relationships health well-being nation’s children pediatrics vol. supplement feb. available http//dx.doi.org/./ peds.-f carr saunders tsanas bilderbeck palmius geddes foster goodwin variability phase amplitude diurnal rhythms related variation mood bipolar borderline personality disorder scientiﬁc reports accepted berry brooks gamaldo harding lloyd quan troester vaughn aasm scoring manual updates journal clinical sleep medicine vol. available http//dx.doi.org/./jcsm. debener emkes bleichner unobtrusive ambulatory using smartphone ﬂexible printed electrodes around scientiﬁc reports vol. nov. available http//dx.doi.org/./srep rosenzweig morrell mandic wearable in-ear encephalography sensor monitoring sleep preliminary observations studies annals american thoracic society sep. available http//dx.doi.org/./annalsats.-bc larsen walter automatic methods sleep staging spectra electroencephalography clinical neurophysiology vol. available http//www.sciencedirect.com/science/article/pii/ review neural network applications sleep research journal neuroscience methods vol. available http//www.sciencedirect.com/science/article/pii/s l¨angkvist karlsson loutﬁ sleep stage classiﬁcation using unsupervised feature learning advances artiﬁcial neural systems vol. available http //dx.doi.org/.// tang kluge deep learning method sleep stage classiﬁcation neural information processing ser. lecture notes computer science springer international publishing vol. available http//dx.doi.org/./---- stephansen ambati leary moore carrillo hogl stefani hong pizza plazzi vandi antelmi perrin kuna schweitzer kushida peppard jennum sorensen mignot neural networks analysis sleep stages diagnosis narcolepsy oct. available http//arxiv.org/abs/. t.-h. tsai l.-j. k.-m. chao takagi-sugeno fuzzy neural network-based algorithm single-channel signal discrimination light deep sleep stages ieee biomedical circuits systems conference ieee oct. available http//dx.doi.org/./ biocas.. chang sleep stage classiﬁcation based multi-level feature learning recurrent neural networks wearable device nov. available http//arxiv.org/abs/. finelli achermann borb´ely individual ’ﬁngerprints’ human sleep topography. neuropsychopharmacology vol. suppl nov. available http//view.ncbi.nlm.nih. gov/pubmed/ buckelm¨uller h.-p. landolt stassen achermann trait-like individual differences human sleep electroencephalogram. neuroscience vol. available http//view.ncbi.nlm.nih.gov/pubmed/ w.-l. zheng b.-l. personalizing eeg-based affective models transfer learning proceedings twentyfifth international joint conference artiﬁcial intelligence ser. ijcai’. aaai press available http//dl.acm.org/citation.cfm?id=. improving eeg-based emotion classiﬁcation using conditional transfer learning frontiers human neuroscience available https//www.frontiersin.org/articles/./fnhum../full jiang deng qian wang wang f.-l. chung k.-s. choi wang seizure classiﬁcation signals using transfer learning semi-supervised learning fuzzy system. ieee transactions neural systems rehabilitation engineering publication ieee engineering medicine biology society sep. available http//view.ncbi.nlm.nih.gov/pubmed/ hajinoroozi y.-p. huang deep transfer learning cross-subject cross-experiment prediction image rapid serial visual presentation events data augmented cognition. neurocognition machine learning ser. lecture notes computer science schmorrow fidopiastis eds. springer international publishing vol. available http//dx.doi.org/./---- pratt discriminability-based transfer neural networks advances neural information processing systems francisco morgan kaufmann publishers inc. available http//portal.acm.org/ citation.cfm?id= kemp zwinderman kamphuisen oberye analysis sleep-dependent neuronal feedback loop slow-wave microcontinuity biomedical engineering ieee transactions vol. aug. available http//dx.doi.org/./. goldberger amaral glass hausdorff mark mietus moody c.-k. peng stanley physiobank physiotoolkit physionet circulation vol. jun. available http//dx.doi.org/./.cir...e tsinalis matthews zafeiriou automatic sleep stage scoring single-channel using convolutional neural networks oct. available http//arxiv.org/abs/ theano development team theano python framework fast computation mathematical expressions arxiv e-prints vol. abs/. available http//arxiv.org/abs/ rosenberg hout american academy sleep medicine inter-scorer reliability program sleep stage scoring. journal clinical sleep medicine jcsm vol. jan. available http//view.ncbi.nlm.nih.gov/pubmed/ mikkelsen kidmose hansen keyhole hypothesis high mutual information scalp neuroscience frontiers human neuroscience available http//journal.frontiersin.org/article/./fnhum../abstract", "year": "2018"}