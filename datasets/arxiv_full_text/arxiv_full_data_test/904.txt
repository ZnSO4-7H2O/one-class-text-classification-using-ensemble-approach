{"title": "Human Echolocation in Static Situations: Auditory Models of Detection  Thresholds for Distance, Pitch, Loudness and Timbre", "tag": "q-bio", "abstract": " We investigated, by using auditory models, how three perceptual parameters, loudness, pitch and sharpness, determine human echolocation. We used acoustic recordings from two previous studies, both from stationary situations, and their resulting perceptual data as input to our analysis. An initial analysis was on the room acoustics of the recordings. The parameters of interest were sound pressure level, autocorrelation and spectral centroid. The auditory models were used to analyze echolocation resulting from the perceptual variables, i.e. loudness, pitch and sharpness. Relevant auditory models were chosen to simulate each variable. Based on these results, we calculated psychophysical thresholds for detecting a reflecting object with constant physical size. A non-parametric method was used to determine thresholds for distance, loudness, pitch and sharpness. Difference thresholds were calculated for the psychophysical variables, since a 2-Alternative-Forced-Choice Paradigm had originally been used. We found that (1) blind persons could detect objects at lower loudness values, lower pitch strength, different sharpness values and at further distances than sighted persons, (2) detection thresholds based on repetition pitch, loudness and sharpness varied and depended on room acoustics and type of sound stimuli, (3) repetition pitch was useful for detection at shorter distances and was determined from the peaks in the temporal profile of the autocorrelation function, (4) loudness at shorter distances provides echolocation information, (5) at longer distances, timbre aspects, such as sharpness, might be used to detect objects. We also discuss binaural information, movements and the auditory model approach. Autocorrelation was assumed as a proper measure for pitch, but the question is raised whether a mechanism based on strobe integration is a viable possibility. ", "text": "centre speech technology department speech music hearing royal institute technology stockholm sweden. *corresponding author email boschkth.se blekinge institute technology karlskrona sweden. email vijaykirangidlaoutlook.com human echolocation describes people reflected sounds obtain information ambient world. investigated using auditory models three perceptual parameters loudness pitch sharpness determine echolocation. used acoustic recordings previous studies stationary situations resulting perceptual data input analysis. initial analysis room acoustics recordings. parameters interest sound pressure level autocorrelation spectral centroid. auditory models used analyze echolocation resulting perceptual variables i.e. loudness pitch sharpness. relevant auditory models chosen simulate variable. based results calculated psychophysical thresholds detecting reflecting object constant physical size. non-parametric method used determine thresholds distance loudness pitch sharpness. difference thresholds calculated psychophysical variables since -alternativeforced-choice paradigm originally used. found blind persons could detect objects lower loudness values lower pitch strength different sharpness values distances sighted persons detection thresholds based repetition pitch loudness sharpness varied depended room acoustics type sound stimuli repetition pitch useful detection shorter distances determined peaks temporal profile autocorrelation function loudness shorter distances provides echolocation information longer distances timbre aspects sharpness might used detect objects. also discuss binaural information movements auditory model approach. autocorrelation assumed proper measure pitch question raised whether mechanism based strobe integration viable possibility. lind people senses vision orient move around. hearing especially echolocation i.e. reflection echoes objects might used detect objects. sounds produced person mouth cane tapping also arise environment e.g. traffic. studying perceptual processes blind people echolocation reanalyzing results earlier studies. used models hearing understand sounds processed. blind people could detect objects difficult conditions longer distances sighted people. detection based pitch loudness timbre aspect sharpness. perception pitch useful shorter distances depended time properties sound loudness. longer distances timbre aspects sharpness might used detect objects. understanding echolocation important people manage move around surroundings senses process spatial information environment. issues involved interest physiologists psychologists biologists. importantly issues practical relevance blind people learning safely move around design mobility aids. ersons blindness echolocation obtain information surroundings. person source environment emits sound reflection perceived. static dynamic means used sensory information. cases person perceive object obstacle front him/her. perceptual decision determined threshold detection. threshold vary function number variables like character sound emitted rates sound position relative person motion involved experience expertise echolocation. review human echolocation stoffregen pittenger kolarik thaler goodale physical properties different effects psychoacoustic parameters used determine object front not. three psychoacoustic parameters particularly important sources human echolocation viz. pitch form repetition pitch loudness spectral information perceived timbre. describe information provided pitch loudness timbre result respective detection thresholds echolocation. limit stationary situations i.e. neither object person moving. movement involved potential information provided wallmeier wiegrebe also determine distance threshold person detect reflecting object. number auditory models applied physical stimuli related results models perceptual responses participants previous empirical studies schenkman nilsson schenkman nilsson grbic also referred respectively. psychoacoustic neuroimaging methods useful describing high echolocating ability blind underlying processes. however fully reveal information acoustic stimulus determines echolocation information encoded auditory system. wanted know information represented processed human auditory system. fruitful study information necessary human echolocation signal analysis acoustic stimulus. however analysis directed physical properties sound fully show information represented human auditory system. investigate this used auditory models mimic human hearing. analyzing acoustic stimulus using models provide insight processes human echolocation. also allow testing hypotheses comparing models loudness pitch timbre three perceptual attributes acoustic sound relevant human echolocation. backgrounds attributes modeling human echolocation discussed next. loudness perceptual attribute sound intensity defined attribute auditory sensation terms sounds ordered scale quiet loud dynamic range auditory system wide different mechanisms play role intensity discrimination. psychophysical experiments suggest neuron firing rates spread excitation phase locking play role intensity perception latter always essential. disadvantage neuron firing rates that although single neurons auditory nerve used explain intensity discrimination explain intensity discrimination better observed suggesting discrimination limited capacity higher levels auditory system also play role intensity discrimination several models proposed calculate average loudness would perceived listeners. basic structure models that initially outer middle transformations performed excitation pattern calculated. excitation pattern transformed specific loudness involves compressive non-linearity. total area calculated specific loudness pattern assumed proportional overall loudness. therefore independent mechanism underlying perception loudness excitation pattern essential information needed auditory model loudness thus also understanding human echolocation utilizing loudness. pitch that attribute auditory sensation terms sounds ordered musical scale view underlying mechanisms pitch that cochlea assumed perform spectrum analysis acoustic vibrations transformed spectrum coded profile discharge rate across auditory nerve. alternative view proposes cochlea transduces acoustic vibrations temporal patterns neural firing. views known place time hypotheses. according place hypothesis pitch determined position maximum excitation along basilar membrane within cochlea. explains pitch perceived pure tones levels fails explain perception pure tones higher levels. levels non-linearity basilar membrane peaks become broader tend shift towards lower frequency place. lead decrease pitch psychophysical experiments show pitch stable. another case place hypothesis fails inability explain pitch stimuli whose fundamental absent. according paradox missing fundamental pitch evoked pure tone remains additional tones frequencies integer multiples original pure tone i.e. harmonics. also change remove original pure tone fundamental since time hypothesis states pitch derived periodic pattern acoustic waveform overcomes problem missing fundamental. however main difficulty time hypothesis easy extract pulse period reliable fully general. psychoacoustic studies also show pitch exists sounds periodic. interest subject matter human echolocation instance sounds namely iterated ripple noise. sound models human echolocation signals order overcome limitations place time hypothesis theories proposed pattern matching cheveigné theory based autocorrelation cheveigné boer described pattern matching fundamental partial necessary correlate pitch absent parts pattern present. pattern matching supports place hypothesis. later goldstein wightman terhardt described models pattern matching. problem pattern matching theory fails account pitch whose stimuli resolved harmonics. autocorrelation hypothesis assumes temporal processing auditory system. states that instead detecting peaks regular intervals periodic neural pattern processed coincidence detector neurons calculate equivalent autocorrelation function cheveigné spike trains delayed within brain various time lags combined correlated original. equal time delay spikes correlation high outputs coincidence detectors tuned strong. spike trains frequency channel processed independently results combined aggregate pattern. however cheveigné argued autocorrelation hypothesis works well predicts that pitch equally salient stimuli resolved unresolved partials case. alternative theory based autocorrelation like function strobe temporal integration patterson allerhand giguere accordance auditory image underlying perception pitch obtained using triggered quantized temporal integration instead autocorrelation function. works finding strobes neural activity pattern integrating certain period. thus full understanding pitch perceived. irrespective temporal spectral multi mechanisms determine pitch perception underlying information auditory system uses detect pitch excitation pattern basilar membrane. hence excitation pattern crucial information simulated auditory model pitch perception thus also human echolocation. human echolocation signals consist original sound along reflected delayed signal. several studies presented explain pitch perception sounds. bassett eastmond examined physical variations sound field close reflecting wall. reported perceived pitch caused interference direct reflected sound different distances wall; pitch value equal inverse delay. similar small mcclellan bilsen delayed identical pulses found pitch perceived equal inverse delay naming time separation pitch repetition pitch respectively. sound repetition sound listened subjective tone perceived pitch corresponding reciprocal value delay time explained repetition pitch phenomenon autocorrelation peaks spectral peaks. yost performed experiments using iterated ripple noise stimuli concluded autocorrelation underlying mechanism used listeners detect repetition pitch. loudness pitch acoustic sound similar subjective attribute sound distinguish identify sound timbre. timbre defined attribute auditory sensation enables listener judge non-identical sounds similarly presented loudness pitch dissimilar example difference musical instruments playing tone e.g. guitar piano. timbre multidimensional percept single scale order timbre. quantify timbre approach consider overall distribution spectral energy. plomp co-workers showed perceptual differences different sounds closely related levels octave bands thus relating timbre relative level produced sound critical band. hence generally speech non-speech sounds timbre steady tones determined magnitude spectra although relative phases play small role consider time varying patterns several factors influence perception timbre periodicity; variation envelope waveform; spectrum changes time; preceding following sounds like. using auditory models timbre information assessed levels spectral envelope variations temporal envelope. another preserve fine grain time interval information necessary timbre perception strobe temporal integration method patterson allerhand giguere signal analysis auditory models enable understand processing sounds persons using echolocation since consider transmission acoustic sound source internal representation final percept person. acoustic sound travels undergoes transformation room acoustics. therefore first understand information received human ear. signal analysis useful purpose analyze characteristics sound transformed room conditions. second step analyze desired characteristics acoustic sound contains information represented auditory system. auditory models useful. desired information transformed analogous auditory system known process keeping track information outer central nervous system important part describing listeners perceive sounds explaining differences groups listeners different characteristics e.g. visually handicapped sighted persons. methodology used report. model auditory analysis performed human auditory system used auditory image model patterson allerhand giguere loudness models glasberg moore sharpness model fastl zwicker matlab used implementation environment. auditory image model implemented matlab bleeck ives patterson current version known aim-mat. loudness sharpness models implemented psysound guidriven matlab environment analysis audio recordings. aimmat https//code.soundsoftware.ac.uk/projects/aimmat http// www.psysound.org respectively. aims present study were study different components information acoustic stimulus determines echolocation. determine thresholds different components information acoustic stimulus important factors detection distance reflecting objects. find acoustic information determines high echolocation ability blind represented human auditory system. specifically hypotheses were detection thresholds based repetition pitch loudness sharpness vary depend room acoustics type sound stimuli used. repetition pitch useful detection shorter distances determined peaks temporal profile autocorrelation function computed neural activity pattern. detection shorter distances based loudness provides information listeners. longer distances timbre aspects sharpness information might used listeners detect objects. report hereafter structured follows next part method subtitled room acoustics basic acoustic analyses physical parameters describe recordings used studies schenkman nilsson schenkman nilsson grbic since form data present report. part present signal analysis conducted recordings. describe basic room acoustic parameters signals form basis physical information room persons whether objects present not. consideration done auditory models. next part models subtitled auditory analysis acoustic information describe auditory models designs implementation. loudness pitch sharpness recordings analyzed using auditory models presented results loudness analysis excitation patterns binaural loudness short long term loudness pitch analysis autocorrelation dual profiles sharpness analysis sections respectively. section thereafter threshold values absolute difference echolocation static situations based auditory model analysis thresholds object detection presented. followed discussion conclusions. sound recordings used describe briefly sound recordings made. detailed descriptions original articles. binaural sound recordings conducted ordinary conference room anechoic chamber using artificial manikin. object reflecting thick aluminum disk diameter recordings conducted distances microphones reflecting object. addition recordings made obstacle front artificial manikin. durations noise signal shortest corresponds perceptually click. electrical signal white noise. however emitted sound perfectly white non-linear frequency response loudspeaker system. loudspeaker generated sounds resting chest artificial manikin. recordings conducted ordinary lecture room. recordings conducted distances microphones reflecting object. emitted sounds either bursts each varying rates bursts white noise. contrast sounds generated loudspeaker placed straight behind center head artificial manikin. sound recording seen sound recordings used. anechoic room conference room loudspeaker chest artificial manikin schenkman nilsson lecture room loudspeaker behind artificial manikin schenkman nilsson grbic analyses performed determine basic room acoustical parameters relevant human echolocation sound pressure level autocorrelation spectral centroid. analyzing recordings recordings calibrated calibrating constants using equation based sound pressure level recording without object artificial manikin anechoic conference rooms lecture room cc’s calculated respectively. a-weighting included equation since difference using less could thus neglected. supporting information details. recordings binaural left right recordings analyzed. recordings versions duration distance. condition reflecting object sets recordings versions each condition recordings versions. versions object resulted similar values fullness presented separately report. noted recordings vary versions causing term equation vary thereby varying calibrated constants different versions. however variation small versions decided version first recording without object version recording without object establish calibrated constants. another reason choose version although versions exactly identical cc’s relatively calibrated respect recording version example suppose recording anechoic chamber version version calibration levels obtained calibrating recordings using version would version version words give level difference also calibration. detection objects echolocation certain extent based intensity information. hence calculated using equation root mean square amplitude signal analyzed. pointed various authors binaural information utilized echolocation purposes. therefore calculated values ears. mean values recordings study study shown tables respectively. values recordings reasons space shown here. mentioned above recordings object series conducted recordings. seen table values close other. tabulated values tables show effect room acoustics level differences ears rooms. level differences recording without object recordings object less differences experimental setup acoustics room. extent information affected listeners studies obvious loudness perceived human auditory system cannot related directly issue analyzed section loudness analysis excitation patterns binaural loudness short long term loudness. repetition pitch important aspect perceive complex sounds bilsen ritsma schenkman nilsson showed pitch rather loudness used listeners detect object echolocation. noted above pitch perception often explained peaks autocorrelation function therefore autocorrelation analysis performed present here. theoretical values repetition pitch recordings calculated using equation corresponding values recordings objects distances would approximately assuming sound velocity m/s. theory based autocorrelation uses temporal information repetition pitch perceived frequencies explained peaks inverse frequencies i.e. approximately respectively. autocorrelation analysis performed using frame would cover required pitch period. size used analyze next time instants etc. order compare peaks among recordings normalized limits study participants performed well longer duration signals. single short burst person chance perceive signal echo. visualized acfs figs recording peak present initial frame. recording peak also present frames time instants greater autocorrelation function signal recorded anechoic chamber reflecting object figures show autocorrelation function time instants signal respectively. recording duration autocorrelation function present first frame. autocorrelation function signal recorded anechoic chamber reflecting object figures show autocorrelation function time instants signal respectively. factor. even test person first attentive longer time interval available perceive signal. however schenkman nilsson grbic performance decreased distance longer duration noise although repetitions present frames time instant greater functions reasons space shown here. therefore longer duration signals always beneficial human echolocation cannot concluded available results. peak heights pitch period recordings object duration signal conference room greater lecture room duration signal object lecture room greater peak height signal conference room peak distinct enough compared duration signal conference room cause differences peak heights rooms conference room lecture room probably different room acoustics. depends spectrum signal acoustics room certainly influences peaks acf. reverberation time conference lecture room seconds respectively. fuller discussion information carried peaks represented auditory system discussed section pitch analysis autocorrelation dual profiles. detection object could provided timbre information available sound. timbre constituted number different characteristics e.g. roughness. another characteristic timbre perception spectral centroid gives time varying value characterizing subjective center timbre sound. mentioned introduction timbre section previously timbre steady tones mainly determined magnitude spectra. believe spectral centroid important feature human echolocation static situations. recordings static spectral centroid using magnitude spectra recordings computed depict timbre information. compute spectral centroid recordings analyzed using frame overlap. spectral centroid frame computed equation spectral centroid frame time varying function plotted function time. means spectral centroid versions condition left recordings shown figs recordings without object spectral centroid approximately recordings object spectral centroids approximately difference might provide information listeners distinguish conditions object without object. recordings object vary much compared recording without object. spectral centroid approximately recordings showing small changes. timbre information thus first sight seem useful echolocation. physical analysis indicates variation spectral centroid recordings object shorter distances longer distances difference spectral centroid almost negligible. conclusions based purely physical analysis fast fourier transform analysis sounds. however spectral analysis performed auditory system complex used compute spectral premises previous sections method part presented physical parameters studies determine human echolocation. models part take physical parameters study provide basis relevant auditory information person. results part thereafter connect auditory analysis behavioural results. auditory analysis used auditory image model originally developed patterson extensions added authors. timedomain functional model signal processing performed auditory pathway system converts sound wave perception experience presented sound. representation referred auditory image analogy visual image scene experience response optical stimulation. simplifies peripheral central auditory systems modules. summarily description modules implemented present analysis given below. detailed description module found http//www.acousticscale. org/wiki/index.php/aim_documentation. used modules described analyse recordings. processing modules written matlab. current version mentioned earlier referred aim-mat downloaded https//code.soundsoftware.ac.uk/projects/aimmat. autocorr module present version downloaded http//w.pdn.cam.ac. uk/groups/cnbh/aimmanual/download/downloadframeset.htm. outer middle transformation acoustic sound simulated cochlear processing module. module consists four different finite impulse response filters designed different applications. minimum audible field suitable signals presented free field. minimum audible pressure suitable systems produce flat frequency response. equal loudness contour filter almost identical include factors associated extra internal noise high frequencies. however uses recent data glasberg moore designed using parks-mcclellan optimal equi-ripple filter design algorithm designed using frequency sampling method. transmission acoustic sound filter modelled using equation signalinput input signalpcp filtered output corresponding filter. frequency response used design filter cochlear processing module aim. frequency response obtained frontal field cochlea correction data glasberg moore non-linear spectral response basilar membrane important feature peripheral auditory system. response implemented dynamic compressive gammachirp filter bank dcgc important properties basilar membrane motion asymmetry compression auditory filters made proportion intensity level. properties designed using compressive gammachirp filter generalized form gammatone filter derived operator techniques developments gammatone gammachirp filters described patterson unoki irino simulated cascading passive gammachirp filter high pass asymmetric function asymmetrical property simulated options available generating gammatone function pole zero filter cascade. since gammatone function depict nonlinearity basilar membrane used default filterbank dcgc simulate bmm. transformation modelled using equations signalpgc filtered output filterbank centre frequency filter high pass asymmetric compensation filters signalcgc final compressed output bmm. detailed description filterbanks irino patterson third step neural activity pattern basilar membrane motion transduced electrical potential inner hair cells. neural activity pattern implemented half wave rectification followed pass filtering. pass filtering executed phase locking feasible high frequencies human ear. three modules generate half wave rectification followed compression pass filtering half wave rectification followed pass filtering dimensional adaptive threshold choice module depends choice module. noted above used dcgc filter bank analyses compression basilar membrane simulated module therefore chosen generate nap. transformation modelled using equation abs) half wave rectified signal basilar membrane centre frequency filter pass filter signalnap modelled nap. fourth stage represents processing central nervous system. perceptual research suggests least fine grain time interval information needed preserve timbre information patterson auditory models often time average information unfortunately loses fine grain information. prevent this uses procedure called strobe temporal integration subdivided modules strobe finding temporal integration. strobe finding module used find strobes nap. uses adaptive strobe threshold issue strobe time strobe associated peak pulse. strobe initiated threshold initially rises along parabolic path returns linear decay avoid spurious strobes. duration parabola proportional centre frequency channel height height strobe. parabolic section adaptive threshold level decreases linearly zero additional feature inter channel interaction i.e. strobe channel reduces threshold neighbouring channels. example threshold varies strobes calculated shown temporal integration temporal integration implemented module called stabilized auditory image turn uses module accomplish this. module changes time dimension time interval dimension. works follows initially temporal integration initiated strobe detected. strobes detected process continues stops. strobes detected within interval strobe initiates temporal integration process. preserve shape uses weighting. strobes initially weighted high making older strobes contribute relatively less sai. mentioned above offers module autocorr analyze autocorrelation processes. corresponding physiological processes presumed take place central nervous system bilsen using autocorr module implement models hearing based autocorrelation processes. autocorr module takes input computes center frequency channel using duration time maximum delay long term loudness room acoustics part earlier sound pressure level analysis described physical intensity sound affect human echolocation. description necessary understanding echolocation sufficient. intensity related perception loudness psychological attribute loudness also depends number parameters primarily only frequency selectivity bandwidth duration sound. section consider perceptual aspects loudness echolocating sounds using loudness model glasberg moore chose model instead following reason. loudness model glasberg moore computes frequency selectivity compression basilar membrane stages computing excitation pattern specific loudness input signal. physiologically interlinked time domain filter bank simulates selectivity compression might appropriate. although different time domain models level dependent auditory filters available give sufficiently good equal loudness contours since consider important aspect instead choosing model model loudness used model glasberg moore loudness model consider outer middle filtering non-linearity basilar membrane temporal integration auditory system. loudness model glasberg moore estimates loudness steady sounds time varying sounds accounting features human auditory system. stage model described briefly below. outer middle transformation modelled using finite impulse response filter coefficients. response inner represented using equation yomt signals transformation impulse response filter. excitation pattern excitation pattern defined magnitude output auditory filter function filter center frequency. compute excitation pattern time domain signal glasberg moore used ffts parallel based hanningwindowed segments durations aligned temporal centers. windowed segments zero padded ffts based sample points. ffts updated intervals used calculate spectral magnitudes specific frequency ranges. values outside range discarded. running spectrum input auditory filters output calculated center frequency equivalent rectangular bandwidth intervals taking account known variation auditory filter shape regarding center frequency level. excitation pattern defined output auditory filter function center frequency represented equation magnitude output auditory filter center frequency yomt power spectrum yomt calculated using parallel fft’s mentioned above interval frequency response auditory filter center frequency model non-linearity basilar membrane excitation pattern converted specific loudness. specific loudness loudness critical band. conversion done model glasberg moore using three conditions threshold excitation frequency dependent. represents level gain cochlear amplifier relative gain above frequency dependent. parameter used bring input-output function close linear around absolute threshold. compressive exponent varies constant scales loudness conform sone scale loudness tone corresponds sone equal loudness depends intensity bandwidth sound among factors also duration. duration signals relevance human echolocation therefore briefly describe models duration loudness. effect duration loudness modeled glasberg moore using three concepts duration sounds viz. instantaneous loudness short term loudness long term loudness. depict temporal integration loudness auditory system described next. instantaneous loudness specific loudness critical band pattern specific loudness critical bands called specific loudness pattern. usually area specific loudness pattern summed give instantaneous loudness. sound binaural area specific loudness patterns ears summed together give instantaneous loudness. instantaneous loudness intervening variable used calculations perceptual variable. short term loudness short term loudness determined averaging instantaneous loudness using attack constant decay constant values chosen model give reasonable predictions variations loudness duration amplitude modulated sounds long term loudness long term loudness parameter calculated averaging instantaneous loudness using attack constant decay constant values chosen model give reasonable predictions overall loudness sounds amplitude modulated rates noted above loudness also affected binaural hearing. model binaural loudness number psychoacoustic facts considered early results suggested level difference required equal loudness monaurally diotically presented sounds subjective loudness sound doubles every increase physical intensity therefore assumed early loudness model glasberg moore loudness sums across ears. however later results suggested level difference required equal loudness rather glasberg moore therefore presented model account lower values based concept inhibition. inhibition occurs strong input lowers even stops i.e. inhibits internal response evoked weaker input glasberg moore implemented inhibition binaural hearing gain function. initially specific loudness pattern smoothed gaussian weighting function relative values smoothed function ears used compute gain functions ears. gains applied specific loudness patterns ears. loudness calculated summing specific loudness center frequencies binaural loudness obtained summing loudness values across ears used procedure calculate binaural loudness values report. binaural loudness model glasberg moore implemented psysound gui-driven matlab environment analysis audio recordings glasberg moore assumed loudness brief sound determined maximum short term loudness long term loudness correspond memory loudness event last several seconds. time varying sound appropriate consider long time loudness function time calculate time varying loudness. however report stimuli presented participants noise bursts considered steady brief follow assumption glasberg moore using maximum short time loudness measure loudness recordings. means maxima values short term loudness sones versions recordings rooms presented tables respectively. tables sees loudness difference recordings without object object less case lecture room anechoic conference room explain performance participants lecture room loudness values follow pattern sound pressure level analysis room acoustics chapter however values tables psychophysical depict acoustics rooms also account aspects human hearing important human echolocation. comparison loudness results echolocation persons made section threshold values absolute difference echolocation static situations based auditory model analysis relate psychophysical values echolocation performances. table means maxima short term loudness sones versions recordings anechoic conference room lecture room duration signal. blank cells indicate recordings made distances. series recordings reflecting object. able means maxima short term loudness sones versions recordings anechoic conference room duration signal. series recordings reflecting object. able means maxima short term loudness sones versions recordings anechoic conference room lecture room duration signal. blank cells indicate recordings made distances. series recordings reflecting object. pitch analysis autocorrelation dual profiles repetition pitch percept underlies human echolocation detecting objects. usually experienced coloration sound perceived frequency equal inverse delay time sound reflection bilsen ritsma also bassett eastmond mentioned section method room acoustics reflecting objects distances resulting delays repetition pitches would correspond respectively. however actual delays might vary factors like recording speed sound etc. therefore actual repetition pitch would different. test presence repetition pitch frequencies together information would represented auditory system used modules summarily presented above analyze recordings perception repetition pitch created presenting iterated rippled noise stimuli. peaks autocorrelation function sounds seen basis repetition pith patterson hence instead strobe finding temporal integration modules used autocorr module final stage analysis quantify repetition pitch information. analysis autocorrelation provides feasible quantify repetition pitch need explain echolocation. chose strobe temporal integration final stage exclude might pitch information echolocation represented auditory system. determine whether autocorrelation strobe temporal integration better explains repetition pitch perception possibly also physiological processes involved auditory system experiments analysis needed. interested reader present example results obtained using strobe temporal integration module signal supporting information. generating autocorr module dual profile development module sums along temporal spectral domain. features relevant human hearing depicting temporal spectral information might represented useful analyzing repetition pitch. therefore used module analyze temporal spectral results. dual profile module plots single plot temporal spectral frequency axis. temporal profile spectral profile scaled this inverse relation time versus frequency used plot time frequency frequency scale. example dual plot pure tone shown recordings analyzed way. recordings object study clicks study provide additional information module therefore included autocorrelation analysis. autocorrelation function autcorr module pure tone temporal axis frequency axis seen. peak temporal profile peak spectral profile approximately high pass asymmetric function used dynamic compressive gammachirp filter whose centre frequency shifts stimulus level increases. temporal profile calculated summing output along critical bands time delay. spectral profile calculated summing output critical band along time delay. therefore temporal profile consists critical bands every sample time delay spectral profile consists delay samples every critical band. studies analyze recordings presented participants durations plus additional silence. therefore presentation duration i.e. whole signal analyzed. example recording duration plus silence. however presenting figures graphically first time interval recordings. dual profiles presented recordings three signal durations rooms study signal study important note amplitude scale y-axis different figure figure. investigated attribute pitch figure reflecting object compared figure object condition. distinct peak figure absent figure object indicates potential occurrence perception pitch. remember visual impression peak figure object misleadingly indicate auditory peak unless observes different scales different y-axis different figures. next section deal select peaks based peak strength. mentioned above theoretical frequency repetition pitch recordings object analysis recordings show peaks approximately frequencies. example peaks approximately figd peaks approximately figc peak approximately reason peaks exactly theoretical values probably experimental setups room acoustics. figb peaks corresponding theoretical frequencies. however wider range axis scale spectral profiles hand peaks closer theoretical frequencies small spectral differences provide timbre information pitch information. signal recordings distinct peaks could account pitch perception absent spectral profiles conclude spectral profiles provide information pitch perception. temporal profiles figs might peaks approximately theoretical frequencies repetition pitch clearly visible figures scaling figures. therefore premature conclude temporal profile necessary detecting objects based repetition pitch. analysis therefore needed quantified peaks temporal profile. determine role temporal information detecting objects based repetition pitch pitch strength development module used. measures pitch perceived based peak strength. elaborate next section. temporal profiles shown peaks theoretical frequencies repetition pitch which believe explains perception repetition pitch thus also major cause detection echolocation reflecting objects studies. dual profile signal recorded anechoic room solid line along spectral axis dashed line along time delay axis time interval. temporal spectral profiles scaled compared other. axis changed temporal profile using inverse relationship time frequency f=/t. figure object recording figures recordings object respectively. dual profile signal recorded conference room solid line along spectral axis dashed line along time delay axis time interval. temporal spectral profiles scaled compared other. axis changed temporal profile using inverse relationship time frequency f=/t. figure object recording figures recordings object respectively. dual profile signal recorded lecture room solid line along spectral axis dashed line along time delay axis time interval. temporal spectral profiles scaled compared other. axis changed temporal profile using dual profile signal recorded anechoic room solid line along spectral axis dashed line along time delay axis time interval. temporal spectral profiles scaled compared other. axis changed temporal profile using inverse relationship time frequency f=/t. figure object recording figures recordings object respectively. dual profile signal recorded conference room solid line along spectral axis dashed line along time delay axis time interval. temporal spectral profiles scaled compared other. axis changed temporal profile using inverse relationship time frequency f=/t. figure object recording figures recordings object respectively. dual profile signal recorded anechoic room solid line along spectral axis dashed line along time delay axis time interval. temporal spectral profiles scaled compared other. axis changed temporal profile using inverse relationship time frequency f=/t. figure object recording figures recordings object respectively. dual profile signal recorded conference room solid line along spectral axis dashed line along time delay axis time interval. temporal spectral profiles scaled compared other. axis changed temporal profile using inverse relationship time frequency f=/t. figure object recording figures recordings object respectively. dual profile signal recorded lecture room solid line along spectral axis dashed line along time delay axis time interval. temporal spectral profiles scaled compared other. axis changed temporal profile using inverse relationship time frequency f=/t. figure object recording figures recordings object respectively. pitch strength peaks temporal profile autocorrelation function computed dual profile module distributed without apparent order meaning. obvious peak corresponds pitch. solution model pitch strength module calculates pitch strength determine particular peak random not. module first calculates local maxima corresponding local minima. ratio peak height peak width peak subtracted mean peak height adjacent local minima obtain pitch strength particular peak. modifications made pitch strength algorithm improve performance analysis. pass filtering removed smooths peaks pitch strength measured equation figure illustrates pitch strength algorithm used. peak greatest peak height greatest pitch strength would perceived frequency repetition pitch. illustration pitch strength measure computed using pitch strength module aim. indicates local maxima stars corresponding local minima. vertical dashed line pitch strength calculated using equation frequency computed inverting time delay results calculated pitch strength recordings studies presented tables seen peaks misleadingly identified recordings without object would caused pitch perception. happens pitch strength algorithm identifies local maxima minima duration signals pitch strength greater object distances anechoic conference rooms duration signal strength greater distances anechoic room distances conference room. lecture room also pitch strength greater condition computed pitch strength consistent single frequency lasted time frames. case anechoic conference rooms high pitch strengths particular frequency lasted time frames intervals time additionally lecture room reflecting object present pitch strength much different object. illustrates echolocating difficulties test persons study. perceptual results showed participants able detect objects high percentage correct object distances anechoic room conference room presented previous paragraph pitch strength greater conditions. pitch seems important information listeners detect objects distances therefore results imply might perceptual threshold approximately equal pitch strength echolocating situations. peak pitch strength must exist certain time frames person perceive repetition pitch. also dependent acoustics room. relating pitch strength results performance participants studies made following section threshold values. shall analyze results terms timbre property namely sharpness. method part analysis room acoustics described spectral centroid used measure timbre perception. spectral centroid computed time varying fourier transform. address specifically human hearing perceives timbre fastl zwicker computed weighted centroid specific loudness rather fourier transform. psychophysical measure called sharpness indicates sound extends perceived vary dull sharp. conducted sharpness analysis recordings using code available psysound sharpness varies time therefore median used representative measure perceived sharpness. results mean medians perceived sharpness versions anechoic conference lecture room duration signals presented tables unit sharpness called acum. knowledge studies thresholds sharpness. pedrielli carletti casazza found participants noticeable difference sharpness acum. jeon found study refrigerator noise participants noticeable difference sharpness acum. assuming acum threshold value sharpness results tables show difference median sharpness greater threshold object compared recordings without object. differences recordings without object smaller although greater acum. possible shorter distances study reflecting object distances signal durations recordings differences mean median sharpness less acum compared recordings without object. however anechoic room signal duration recordings object differences sharpness approximately greater acum compared recordings without object information blind persons might detect identify reflecting object longer distances than discuss issue next section. threshold values absolute difference echolocation static situations based auditory model analysis background stimuli studies presented participants two-alternative-forcedchoice manner. participants compare sounds detect sound echo. perceptual decision based information attributes stimuli. person detect attribute object percentage correct response limit usually termed absolute threshold. judgments commonly based source information. experiments sources information used. sounds presented manner participants compared information sounds without object made decision. difference threshold threshold participant make discrimination percentage correct response. regards echolocation define absolute threshold value perceptual attribute recording reflecting object person percentage correct response. difference threshold thus difference responses recordings without object respectively person percentage correct response. experimental procedure used experiments therefore difference threshold relevant measure echolocation ability persons. however difference threshold calculated absolute thresholds clarity shown here. procedure finding difference thresholds corresponding results presented below. threshold analysis psychometric functions relate perceptual results physical parameters stimulus. commonly psychometric function estimated parametric fitting i.e. assumed underlying relationship described specific parametric model. parameters model estimated maximizing likelihood. however correct parametric model underlying description psychometric function unknown. therefore estimating psychometric function based assumptions parametric model lead incorrect interpretations address problem zychaluk foster implemented non-parametric model estimate psychometric function require assumptions empirical state underlying phenomenon. psychometric function thus modeled locally without assuming true underlying function. since true relationship variables determine human echolocation unknown chose method proposed zychaluk foster analysis perceptual data. next brief description nonparametric model estimating underlying psychometric function. thereafter analysis perceptual results presented. generalized linear model usually used fitting psychometric function. consists three components random component exponential family systematic component monotonic differentiable link function relates two. hence psychometric function modeled using equation parameters estimated maximizing appropriate likelihood function efficiency relies much chosen link function approximates true underlying function. however mentioned true function never know certain. nonparametric modelling instead fitting link function function fitted using local linear method. given point value point neighborhood approximated equation first derivative actual estimate value obtained fitting approximation data prescribed neighborhood features important purpose kernel bandwidth gaussian kernel preferred unbounded support best widely spaced levels. optimal bandwidth chosen using plugin bootstrap cross validation methods method guaranteed always work find optimal bandwidth analysis chose bootstrap method replications. bootstrap method failed find optimal bandwidth cross validation used establish optimal bandwidth. psychometric function initially fitted mean proportion correct responses respect distance reflecting object. figures show nonparametric modeling parametric modeling perceptual results blind participants study mean percentage correct plotted function distance recordings signals anechoic conference rooms. link function used parametric modeling weibull function. visual inspection shows link function appropriate since correspond well perceptual results. mentioned knows underlying link function psychophysical data parametric better local non-linear data analyzing cannot assume particular link function. however local linear correlates well perceptual results. demonstrates used means proportion correct responses participants psychometric fitting. used individual responses individual thresholds would vary local linear would probably still believe well correlated perceptual results. therefore results remaining part present section based psychometric function using local linear mean proportion correct answers. used implementation non-parametric model fitting matlab zychaluk foster local linear needs least three stimulus values make mathematically valid fit. recordings lecture room stimulus values possible make psychometric recordings. parametric non-parametric modeling mean proportion correct responses recordings blind participants function distance anechoic chamber. conference room. parametric non-parametric modeling mean proportion correct responses recordings blind participants function distance anechoic chamber. conference room. parametric non-parametric modeling mean proportion correct responses recordings blind participants function distance anechoic chamber. conference room. distance perception object perceptual attribute presented directly participants studies therefore distance threshold obtained psychometric derived quantitative threshold. distance threshold distance person detect object probability fitted psychometric function discrete always possible exact value therefore threshold values proportion correct responses within range initially calculated mean threshold values determined actual threshold. distance threshold study blind sighted could detect object using echolocation proportion correct responses shown table distances blind participants could detect reflecting object farther away sighted rooms three sound signals. threshold positively related signal duration groups i.e. longer durations give longer range detection. also blind persons could detect objects farther away conference room signals sighted case signal. original study calculations distance blind sighted person might detect reflecting object based parametric approach yielding general lower distance values thresholds nonparametric approach. words reanalysis data show higher sensitivity blind sighted values table distance thresholds duration room listener groups study threshold values calculated psychometric function blind sighted participants’ responses mean percentage correct responses values loudness thresholds absolute difference object detection loudness also source information detecting reflecting objects echolocation kolarik common psycho-acoustical measure express loudness unit sones gescheider therefore used values sones local linear fitting determine absolute difference threshold loudness blind sighted could detect reflecting object. elsewhere criterion detection percentage correct mean loudness values mean percentage correct responses calculated study used inputs psychometric fit. resulting absolute threshold values loudness detecting object presented table data show thresholds loudness blind participants lower compared sighted roughly sone less anechoic chamber sones less conference room. able absolute threshold values loudness duration room listener groups study threshold values calculated psychometric function blind sighted participants’ responses mean percentage correct responses value values table misleadingly lead reader infer shortest sounds lowest threshold. case. look tables recording without object signal loudness approximately sones signal approximately sones. considering values appropriate difference rather absolute threshold since detection based loudness consequence method used based relative judgment comparison absolute judgment. difference threshold values calculated subtracting absolute threshold values table corresponding loudness values recording without object table table difference threshold values loudness duration room listener groups study threshold values calculated psychometric function blind sighted participants’ responses mean percentage correct responses value data table give different realistic picture data table blind detect objects lower loudness values sounds groups could detect lower relative loudness levels duration signals conference room. loudness model used compute mean loudness test groups therefore conclude absolute difference threshold values pitch strength calculated autocorrelation index blind sighted test persons study could detect reflecting object presented tables respectively. first discuss results terms absolute thresholds appropriate conclusions based difference thresholds. absolute threshold varies blind sighted persons depending signal durations room conditions. blind conditions lower thresholds pitch strength increased signal duration thresholds lower anechoic room. possible shorter duration signals person inattentive miss signal thus also pitch information. performance participants signals thus based pitch strength also cognitive factors attention. schenkman nilsson showed pitch loudness information presented together distances object participants’ performance almost percentage correct. recordings object study almost percent correct response blind sighted. therefore signal condition likely likelihood miss signal pitch information non-attention lower perceptual results participants likely based mostly pitch information. possible theoretical ways regard hearing system treats values. focus analysis signal since noted above signals cognitive aspects could bias auditory model analysis. based reasoning assume auditory system analyses pitch information absolutely i.e. compare peak heights recordings results indicate absolute threshold detecting pitch based autocorrelation process greater blind sighted respectively shown table hand assume auditory system analyses pitch information relatively i.e. compares peak heights recordings results indicate difference threshold detecting pitch based autocorrelation greater blind sighted respectively shown table cases values show blind persons could detect echo reflections objects lower peak heights sighted could. able absolute threshold values pitch strength duration room listener groups study threshold values calculated psychometric function blind sighted participants’ responses mean percentage correct response values sound duration table difference threshold values pitch strength duration room listener groups study threshold values calculated psychometric function blind sighted participants’ responses mean percentage correct response values sound duration discussed previously timbre indicates experience various qualities sounds. chose study aspect timbre sharpness potential information source object detection echolocation. analog previous psycho-acoustical parameters calculated absolute difference threshold values sharpness blind sighted test persons study could detect reflecting object using echolocation correct response value quantitative values sharpness used psychophysical unit acum tables show blind sighted participants absolute difference thresholds sharpness values same. however unlike loudness pitch strength sharpness information need greater value participants detect object. sharpness listener must distinguish timbres. include cognition involving e.g. memory processes. participant presented stimuli method distinguished recording object recording without object identifying higher loudness level stronger pitch strength both. however person uses sharpness echolocation e.g. method necessary recording reflecting object higher sharpness value. recording reflecting object might sound duller i.e. lower value sharpness recording without object. person might information detect identify object. table absolute threshold values mean median sharpness duration room listener groups study threshold values calculated psychometric function blind sighted participants’ responses mean percentage correct response values able difference threshold values mean median sharpness duration room listener groups study threshold values calculated psychometric function blind sighted participants’ responses mean percentage correct response values table showed sharpness values duration recordings reflecting object anechoic room smaller sharpness values recording without object. interestingly blind participants performed better conditions remaining participants i.e. proportion correct approximately even looked deeper performance high-performing echolocators making local linear proportion correct persons sharpness values recordings anechoic chamber calculated shown table cross validation used find bandwidth local linear kernel. figs show corresponding local linear fits. clearly proportion correct approximately equal absolute threshold values sharpness higher lower. consider mean sharpness object recordings condition hence difference threshold blind participant would acum acum. similarly difference threshold blind participant would acum acum. perceptually means high-performing blind participants could detect object even recording object duller recording without object. detailed discussion importance sharpness information human echolocation presented discussion part below. non-parametric modeling proportion correct response recordings blind participant function mean median sharpness. function discrete values proportion correct responses approximately equal considered. non-parametric modeling proportion correct response recordings blind participant function mean median sharpness. function discrete values proportion correct responses approximately equal considered. wanted elucidate factors determine echolocation differences echolocation ability blind sighted persons. neuroimaging psychoacoustic methods give insight high echolocating ability blind persons methods necessarily reveal information acoustic stimulus determines echolocation also fully information represented processed human auditory system. implementation auditory models human echolocation intended establish information determines echolocation ability variability information represented processed human auditory system. signal analysis conducted physical signals presented method part room acoustics. find physical information used echolocation analyze effects room acoustics human echolocation. studied particular sound pressure levels auto correlations spectral centroids. analyses performed recordings studies results demonstrate expected acoustics room affect sounds thereby physical attributes associated however information represented auditory system complex uses physical information processing auditory neural system. understand better takes place auditory system person using echolocation used consider relevant auditory models human echolocation today available literature. thus studied corresponding perceptual attributes sound pressure level auto correlation spectral centroid encoded human auditory system. results auditory models suggest repetition pitch loudness sharpness provide potential information people echolocate distances results also indicate longer distances sharpness information used human echolocation. detailed discussion loudness pitch sharpness essential human echolocation might represented auditory system presented sections echolocation loudness echolocation pitch echolocation timbre. discussion room acoustics binaural information well movement affect human echolocation presented section echolocation room acoustics echolocation binaural information movement. finally conclude comments using auditory models understanding human echolocation together theoretical implications. existing loudness models chose glasberg moore since good equal loudness contours results model related proportion correct responses listeners studies calculating estimates threshold values based loudness. loudness values tabulated tables resulting threshold values detecting reflecting object based percentage correct shown tables difference loudness level loudness threshold loudness level recordings without object duration signals anechoic room approximately sones sighted persons. example signal anechoic room table threshold sones sighted persons mean loudness object room sones shown table difference values sones. conference room differences sones respectively differences loudness level make possible persons echolocate making loudness potential information source echolocation kolarik comparing loudness thresholds sighted blind persons thresholds blind persons lower sighted test persons loudness information encoded manner groups test persons believe reasonable assumption analysis shows blind persons echolocate lower loudness levels sighted persons. repetition pitch important information sources blind people detect reflecting object shorter distances studied information represented auditory system. purpose dual profile analysis performed presented section pitch analysis autocorrelation dual profiles. results suggest repetition pitch explained peaks temporal profile rather peaks spectral profile autocorrelation function. agreement study yost peaks temporal domain autocorrelation function form basis explaining perception repetition pitch. however dual profile analysis sufficient determine strength perceived pitch peaks random temporal profile autocorrelation function. measure pitch strength therefore used showed peaks random thereafter computed pitch strength means resulting pitch strengths shown tables thresholds detecting objects tables pitch strength values obtained duration recordings table considered recordings likely influenced cognitive factors. pitch strength threshold lower blind persons sighted. reasonable assumption pitch information encoded manner blind sighted persons. appears blind persons echolocate lower pitch strength sighted persons. auditory models used without changing parameters determine extent sharpness useful echolocation computed weighted centroid sounds studies specific loudness using code psysound. pedrielli carletti casazza showed analysis noticeable difference sharpness study acum. used value criterion sharpness detecting reflecting objects. results analysis show difference sharpness greater acum recordings object distances however distances loudness pitch information prominent. hence distances shorter sharpness might major information source echolocation. note that study recording anechoic chamber reflecting object sharpness difference approximately equal acum compared mean recordings without object blind test persons able detect objects noticeable difference sharpness acum found pedrielli carletti casazza also difference threshold sharpness echolocating sounds longer distances sharpness used vital information blind people detect objects point tables present linear relationship sharpness percentage correct i.e. higher value sharpness higher probability detection result. however discussed previously distinction loudness pitch sharpness need larger indicate detection since indicated either perceived dull sharp. psychometric function cannot depict this. experiment controlling sharpness information sound could clarify role echolocation. echolocation room acoustics loudness pitch sharpness provide people information useful echolocation efficiency also depend acoustics room character sounds. results many studies human echolocation evidence tonelli brayda gori vercillo conference room increased pitch strength hence enabled participants echolocate farther distances lecture room decreased pitch strength listeners presumably rely kinds information like loudness resulting deterioration object detection. physical cause deterioration probably loudspeaker chest artificial head behind artificial head. another physical cause deterioration might reverberation time conference room lecture room .s.too little reverberation seem beneficial human echolocation much cannot neither useful. hypothesize might optimal amount reverberation successful echolocation. careful design room acoustics improve possibilities echolocation blind persons. effects room acoustics echolocation also provided recordings anechoic room study recordings object distances room including reflections reflecting object. slight sharpness differences resulted might used skilled listeners detect object. echolocation binaural information movement binaural information provide additional information echolocation. inter-aural level differences time differences provide information echolocation. papadopoulos argued information obstacle discrimination found frequency dependent inter aural level differences especially range khz. nilsson schenkman found blind people study used interaural level differences efficiently sighted. evidence self-generated sounds rice well binaural information beneficial echolocation. recordings analyzed studies report reflecting object directly front recording microphones dummy head little binaural information therefore provided test persons. thus considered source information report although calculate values ear. seen tables values ears similar. static nature recordings might resulted poorer echolocation test persons. real situation movement gives additional information. blind persons move heads body object might moving. additionally would also sounds. reasonable conclude sounds together motion offer information blind persons static sounds provided external source experimenter present article based studies using stationary objects stationary listeners. already wilson showed theoretical reasons benefits echolocation could achieved motion. conclusions obtained findings bassett eastmond pitch changes depending distance reflecting object. recent findings rosenblum showed advantages walking echolocating. furthermore self-motion found beneficial echolocation study blind children walking along path ashmead hill talor found children could avoid utilizing nonvisual information. authors stated congenitally blind children could utilize auditory information could coordinate information functionally important behavior goal-directed locomotion. arias echolocation combination action perception thaler goodale review stressed echolocation active process. present analysis extended also include studies motion objects persons well self-generated sounds. kinds auditory models possibly modification could used test processes hypothesis pertaining additional benefits motion self-generated sounds echolocation. echolocation psychoacoustic experiments sound usually presented participants controlled manner perceptual behavioral responses measured. makes possible identify cause-effect relationships stimuli response. however although stimuli presented controlled manner e.g. echolocation studies underlying cause echolocation obvious e.g. whether biological perceptual psychological. example study blind participants able perform better sighted main cause high performance evident except cause related blindness. volder maybe first describe different brain activities blind sighted persons distance tasks using positron emission tomography. advanced scanning techniques like functional magnetic resonance imaging brain locate areas brain activated persons echolocation. techniques describe physiological processes relating underlying echolocation abilities thaler analyses fully reveal information used blind persons echolocation processed represented auditory system cognitively perceived analyzed. recently also serious criticism studies results inflated false-positive rates address issues representation processing implemented number auditory models; binaural loudness model moore glasberg auditory image model patterson allerhand giguere sharpness model fastl zwicker chose loudness model moore glasberg since agrees well equal loudness contours also gives accurate representation binaural loudness chose auditory image model since instead using different modules depict frequency selectivity compression; uses dynamic compressive gammachirp filterbank module depict frequency selectivity compression performed basilar membrane. model bleeck ives patterson thus used analyze information provided repetition pitch. model also physiologically inspired. finally used loudness model glasberg moore analyze sharpness. sharpness information obtained weighted centroid specific loudness general review auditory processing models given signal analysis performed physical stimuli showed sound pressure level autocorrelation spectral centroid varied recordings. results showed peaks temporal information likely source echolocation shorter distances explanation thus line analysis bilsen yost perception repetition pitch represented people i.e. information necessary pitch perception represented temporally auditory system. analysis performed sharpness model showed blind participants analyzed studies could used sharpness detect objects longer distances temporal spectral information required encode attribute. analysis similarities rowan utilizing models analyze perception level information. similar analysis cross channel cues spectral spread information relevant object detection used quantification sharpness. analyses auditory models used fully explain information necessary high echolocation ability blind persons represented auditory system. order investigate auditory models neural physiological causes different echolocation abilities blind sighted people parameters models could varied participants´ perceptual results. however assumed high echolocation ability mainly perceptual ability common groups. therefore thresholds blind sighted persons obtained comparing results auditory models perceptual results test groups mentioned blind participants consistently better sighted echolocating lower thresholds detection sighted parameters studied. analysis auditory models confirmed repetition pitch loudness important information sources people echolocating shorter distances agreement earlier results kolarik cirstea pardhan moore sharpness candidate important source echolocation short long distance. psychoacoustic experiments could determine usefulness sharpness timbre qualities echolocation. highest ecological validity probably reached experiments real objects actual environments laboratory studies viable alternative. today simulations rooms objects provide another option study human echolocation e.g. pelegrin-garcia rychtáriková glorieux used auditory models analyze information human echolocation static situations represented processed auditory system i.e. movement involved. focused three perceptual attributes. these loudness pitch known important human echolocation. third attribute sharpness aspect timbre considered important echolocation therefore also studied. used number auditory models binaural loudness model moore glasberg model bleeck ives patterson loudness model glasberg moore sharpness information used weighted centroid specific loudness formulated fastl zwicker main results analysis following. shorter distances person reflecting object repetition pitch loudness also sharpness provide information detect objects echolocation. longer distances sharpness information might used purpose. tentative conclusion justified experimentally varying particular sharpness characteristics echolocation sounds. analysis confirmed repetition pitch best represented auditory system peaks temporal profile rather spectral profile median sharpness information computed using centroid specific loudness varying time represented spectral temporal information. analysis assumed auditory information blind sighted persons represented processed way. however assumption true. high echolocation ability blind outcome physiological changes neural system studies indicated thaler investigate detail change parameters auditory models analyze results together data neuroimaging psychoacoustic experiments. established underlying ability blind persons certain physiological conditions parameters auditory models varied results auditory models agree psychoacoustic results. used different auditory models analyze loudness pitch sharpness attributes. assumed high echolocation ability many blind persons result general perceptual ability therefore computed perceptual thresholds blind sighted persons using models groups. analysis showed blind lower thresholds sighted could echolocate lower loudness lower pitch strength levels. noted above recordings form basis analysis recorded static positions i.e. movement person object. real life blind person would likely moving object would addition person often using his/her sounds advantageous echolocation rice movement provided self-produced sounds used believe thresholds blind persons would even lower. ideas alignment concept surplus information schenkman nilsson information makes perceptual tasks easier perform lack information makes perception ambiguous difficult. concept follows gibsons´s theory ecological perception. summary shown importance pitch loudness timbre human echolocation. three characteristics studied especially role timbre attributes like sharpness needs deeper understanding. neuroimaging psychoacoustic experiments signal analysis including auditory models help understand information necessary high ability many blind persons visual impairments represented perceived. original data collected together mats nilsson. work partially supported swedish council working life social research https//www.promobilia.se/ funders role study design data collection analysis decision publish preparation manuscript. onceived controlled study performed simulations analysed data wrote paper funding acquisition contributed analysis tools developed theory wrote paper wilson psychoacoustics obstacle detection using ambient selfgenerated noise. busnel editor animal sonar systems. biology bionics jouy.en-josas france laboratoire physiologie acoustique inra-cnrz. boer residue hearing. academic thesis amsterdam. boer residue auditory pitch perception. keidel neff editors handbook sensory physiology berlin springer patterson allerhand giguere time-domain modeling peripheral auditory processing modular architecture software platform. journal acoustical society america plomp timbre multidimensional attribute complex tones. plomp smoorenburg editors frequency analysis periodicity detection hearing leiden w.j.sitjthoff cabrera ferguson schubert 'psysound' software acoustical psychoacoustical analysis sound recordings. proceedings international conference auditory display montréal canada june rowan papadopoulos edwards holmes hollingdale evans allen identification lateral position virtual object based echoes humans. hearing research papadopoulos edwards rowan allen identification auditory cues utilized human echolocation objective measurement results. biomedical signal processing control doi./j.bspc.... nilsson schenkman blind people sensitive sighted people binaural sound-location cues particularly inter-aural level differences. hearing research volder catalan-ahumada robert labar coppens michel veraart changes occipital cortex activity early blind humans using sensory substitution device. brain research rowan papadopoulos archer goodhew cozens guzman lopez edwards holmes allen detection ‘virtual’ objects using echoes humans spectral cues. hearing research pelegrin-garcia rychtáriková glorieux single simulated reflection audibility thresholds oral sounds untrained sighted people. acta acustica united acustica reference sound pressure level calibration constants anechoic conference lecture rooms documented respectively. calibration constant recordings should principle weighted. results table show calibrated levels calculated using calibration constants equations respectively. weighted signal gives increase calibrated levels approximately less negligible human hearing. therefore used equation equation calculating calibration constants recordings report. results equations calibrated levels without weighting calculated recordings version left signal object first recording anechoic conference rooms version left object recording lecture room table able calibrated levels without weighting version left sound reflecting object first recording anechoic conference rooms version left sound reflecting object lecture room. temporal profile stabilized auditory image recording conference room shown stated section auditory analysis acoustic information stabilized auditory image implemented modules brief description implementation given below. temporal profiles stabilized auditory image signal recorded conference room time frame. indicates highest peak corresponding values indicate pitch strength frequency .the figure object recording figures recordings object respectively. initially module uses adaptive strobe threshold issue strobe nap. strobe initiated threshold initially rises along parabolic path returns linear decay avoid spurious strobes strobes computed frequency channel module uses strobes initiate temporal integration. time interval strobe value determines position value entered sai. example strobe identified channel time instant level sample time instant added position channel sai. next sample added position sai. process adding levels samples continues terminates strobes identified. case strobes detected within interval strobe initiates temporal integration process. preserve shape uses weighting viz. strobes initially weighted high older strobes contribute relatively less sai. time axis converted time interval axis sai. temporal profile figures generated summing along center frequencies. shows recording reflecting object previous researchers patterson analyzed perception repetition pitch autocorrelation function. followed approach since autocorrelation appears good description repetition pitch processed auditory system. determine whether autocorrelation strobe temporal integration best accounts human echolocation repetition pitch relevant physiological processes auditory system analysis needed concepts studied compared number different conditions.", "year": "2018"}