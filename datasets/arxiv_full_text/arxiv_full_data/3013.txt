{"title": "Look into Person: Self-supervised Structure-sensitive Learning and A New  Benchmark for Human Parsing", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Human parsing has recently attracted a lot of research interests due to its huge application potentials. However existing datasets have limited number of images and annotations, and lack the variety of human appearances and the coverage of challenging cases in unconstrained environment. In this paper, we introduce a new benchmark \"Look into Person (LIP)\" that makes a significant advance in terms of scalability, diversity and difficulty, a contribution that we feel is crucial for future developments in human-centric analysis. This comprehensive dataset contains over 50,000 elaborately annotated images with 19 semantic part labels, which are captured from a wider range of viewpoints, occlusions and background complexity. Given these rich annotations we perform detailed analyses of the leading human parsing approaches, gaining insights into the success and failures of these methods. Furthermore, in contrast to the existing efforts on improving the feature discriminative capability, we solve human parsing by exploring a novel self-supervised structure-sensitive learning approach, which imposes human pose structures into parsing results without resorting to extra supervision (i.e., no need for specifically labeling human joints in model training). Our self-supervised learning framework can be injected into any advanced neural networks to help incorporate rich high-level knowledge regarding human joints from a global perspective and improve the parsing results. Extensive evaluations on our LIP and the public PASCAL-Person-Part dataset demonstrate the superiority of our method.", "text": "recently convolutional neural networks achieved exciting success human parsing nevertheless demonstrated many problems object detection semantic segmentation performance cnn-based approaches heavily rely availability annotated images training. order train human parsing network potentially practical value real-word applications highly desired large-scale dataset composed representative instances varied clothing appearances strong articulation partial occlusions truncation image borders diverse viewpoints background clutters. although exist training sets special scenarios fashion pictures people constrained situations datasets limited coverage scalability shown fig. largest public human parsing dataset contains fashion images others include thousands images. moreover best knowledge attempt made establish standard representative benchmark aiming cover wide pallet challenges human parsing task. existing datasets provide evaluation server secret test avoid potential dataset over-ﬁtting hinders development topic. therefore propose benchmark look person public server automatically reporting evaluation results. benchmark signiﬁcantly advances state-of-the-arts terms appearance variability complexity includes human images pixel-wise annotations semantic parts. recent progress human parsing achieved improving feature representations using convolutional neural networks recurrent neural networks. capture rich structure information combine cnns graphical models similar general object segmentation approaches however evaluated human parsing recently attracted research interests huge application potentials. however existing datasets limited number images annotations lack variety human appearances coverage challenging cases unconstrained environment. paper introduce benchmark look person makes signiﬁcant advance terms scalability diversity difﬁculty contribution feel crucial future developments humancentric analysis. comprehensive dataset contains elaborately annotated images semantic part labels captured wider range viewpoints occlusions background complexity. given rich annotations perform detailed analyses leading human parsing approaches gaining insights success failures methods. furthermore contrast existing efforts improving feature discriminative capability solve human parsing exploring novel self-supervised structure-sensitive learning approach imposes human pose structures parsing results without resorting extra supervision self-supervised learning framework injected advanced neural networks help incorporate rich high-level knowledge regarding human joints global perspective improve parsing results. extensive evaluations public pascal-personpart dataset demonstrate superiority method. human parsing aims segment human image multiple parts ﬁne-grained semantics provide detailed understanding image contents. stimulate ∗the ﬁrst authors contribute equally paper. corresponding author dongyu zhang. work supported national natural science foundation china grant table overview publicly available datasets human parsing. dataset report number annotated persons training validation test sets well number categories including background. sensitive learning figure annotation examples look person dataset existing datasets. images dataset ﬁxed size contain stand-up person instances outdoors. images pascal-person-part dataset also lower scalability contain coarse labels. images dataset high appearance variability complexity. dataset results existing methods unsatisfactory. without imposing human body structure priors general approaches based bottom-up appearance information sometimes tend produce unreasonable results shown fig. human body structural information previously well-explored human pose estimation dense joint annotations provided. however since human parsing requires extensive detailed prediction pose estimation difﬁcult directly utilize joint-based pose estimation models pixel-wise prediction incorporate complex structure constraints. order explicitly enforce produced parsing results semantically consistent human pose joint structures propose novel structure-sensitive learning approach human parsing. addition using traditional pixel-wise part annotations supervision introduce structure-sensitive loss evaluate quality predicted parsing results joint structure perspective. means satisfactory parsing result able preserve reasonable joint structure note annotating pixel-wise labeling pose joints expensive cause ambiguities. therefore work generate approximated human joints directly parsing annotations supervision signal structure-sensitive loss hence called selfsupervised strategy noted self-supervised structurecontributions summarized following three aspects. propose large-scale benchmark evaluation server advance human parsing research images pixel-wise annotations semantic part labels provided. experimenting benchmark present detailed analyses existing human parsing approaches gain insights success failures approaches. propose novel self-supervised structure-sensitive learning framework human parsing capable explicitly enforcing consistency parsing results human joint structures. proposed framework signiﬁcantly surpasses previous methods existing pascal-person-part dataset dataset. related work figure example shows self-supervied structuresensitive learning helpful human parsing. original image. parsing results attention-toscale left-arm wrongly labeled right-arm. parsing results successfully incorporate structure information generate reasonable outputs. number images categories. containing images annotated categories dataset largest comprehensive human parsing dataset date. datasets vision community dedicated tasks clothes recognition retrieval human pose estimation dataset focuses human parsing. human parsing approaches recently many research efforts devoted human parsing example liang proposed novel co-cnn architecture integrates multiple levels image contexts uniﬁed nerwork. besides human parsing also increasing research interest part segmentation objects animals cars capture rich structure information based advanced architecture common solutions inlcude combination cnns crfs adoptions multi-scale feature representations chen proposed attention mechanism learns weight multi-scale features pixel location. previous works explored human pose information guide human parsing generating pose-guided part segment proposals. leverage human joint structure effortlessly efﬁciently focus approach nevertheless self-supervised structure-sensitive learning approach actually embedded networks. section introduce look person large-scale dataset focusing semantic understanding human bodies several appealing properties. first annotated images order magnitude larger challenging previous similar attempts. second annotated elaborated pixel-wise annotations semantic human part labels background label. third images collected real-world scenarios contain people appearing challenging poses viewpoints heavy occlusions various appearances wide range resolutions. furthermore background images dataset also complex diverse previous datasets. examples showed fig. dataset propose benchmark suite human parsing together standard evaluation server test kept secret avoid overﬁtting. images dataset cropped person instances microsoft coco training validation sets. deﬁned human parts clothes labels annotation hair sunglasses upper-clothes dress coat socks pants gloves scarf skirt jumpsuits face right left right left right shoe left shoe addition background label. implemented annotation tool generated multi-scale superpixels images based speed annotation. total images dataset including full-body images upper-body images lower-body images head-missed images back-view images images occlusions. split images separate training validation test sets. following random selection arrive unique split consisting training validation images publicly available annotations well test images annotations withheld benchmarking purpose. mentations different ways completely available codes. fair comparison train method training epochs evaluate validation test set. deeplabv vgg- model without dense crfs. following standard intersection union criterion pixelwise accuracy evaluation. begin analysis reporting overall human parsing performance approach summarize results table. table. validation among four approaches attention achieves best result mean accuracy beneﬁted attention model softly weights multi-scale features. mean attention performs best fcn-s segnet perform signiﬁcantly worse. similar performance observed test set. interesting outcome comparison achieved performance substantially lower current best results segmentation benchmark pascal suggests detailed human parsing small parts diverse ﬁnegrained labels challenging object-level segmentation deserves attention future. analyse performance approach respect following challenging factors occlusion full-body upper-body head-missed back-view evaluate four approaches validation contains images occlusions full-body images upper-body images head-missed images back-view images. expected performance varies affected different factors. back-view clearly challenging case. example attention drops figure performance comparison evaluated validation different appearance including occlusion full-body upper-body head-missed back-view. remarkable parts human body. however human parsing aims analyse every detailed regions person including different body parts well different categories clothes. therefore deﬁne body parts clothes categories. among body parts divide arms legs left side right side precise analysis also increases difﬁculty task. clothes classes common clothes like upper clothes pants shoes also infrequent categories skirts jumpsuits. furthermore small scale accessories like sunglasses gloves socks also taken account. numbers images semantic part label presented fig. images dataset contain diverse human appearances viewpoints occlusions. additionally half images suffer occlusions different degrees. occlusion considered occurred semantic parts appears image occluded invisible. challenging cases images contain person instances back-view gives rise ambiguity left right spatial layouts. numbers images different appearance summarized fig. section analyse performance leading human parsing semantic object segmentation approaches benchmark. take advantage rich annotations conduct detailed analysis various factors inﬂuencing results appearance foreshortening viewpoints. goal analysis evaluate robustness current approaches various challenges human parsing identify existing limitations stimulate research advances. analysis consider fully convolutional networks deep convolutional encoderdecoder architecture deep convolutional nets atrous convolution multi-scale attention mechanism achieved excellent performance semantic image segface l-arm r-arm l-leg r-leg l-shoe r-shoe deeplabv deeplabv attention table performance comparison terms per-class four state-of-the-art methods validation set. second inﬂuential factor appearance head. scores approaches much lower head-missed images average score whole set. performance also suffers occlusion. results full-body images closest average level. contrast upper-body relatively easiest case fewer semantic parts present part regions usually larger. results draw conclusion head important existing human parsing approaches. probability ambiguous results increase head part disappears images back-view. moreover parts clothes lower-body difﬁcult ones upper-body existence small labels shoes socks. case body joint structure play effective role guiding human parsing. per-class performance evaluation order discuss analyse labels dataset detail report performance per-class validation shown table. observe results respect labels larger regions like face upperclothes coats pants much better ones small-region labels sunglasses scarf skirt. attention deeplabv perform better small labels thanks utilization multi-scale features. visualization comparison qualitative comparisons four approaches validation visualized fig. display example parsing results challenging factors scenarios. upper-body image slight occlusion four approaches perform well fewer errors. back-view image four methods mistakenly label right left arm. worst results appear comes head-missed image. segnet fcn-s fail recognize arms legs deeplabv attention errors right left arms legs shoes. furthermore severe occlusion also affects performance lot. full-body less challenging small objects full-body image like shoes also hard predicted precisely. moreover observed results unreasonable perspective human body conﬁguration existing approaches lack consideration body structures. summary human parsing difﬁcult general object segmentation. particularly human body structures paid attention strengthen ability predict human parts clothes reasonable conﬁgurations. result consider connecting human parsing results body joint structure better approach human parsing. previously mentioned major limitation existing human parsing approaches lack consideration human body conﬁguration mainly investigated human pose estimation problem. human parsing pose estimation label image different granularities pixel-wise semantic labeling versus joint-wise structure prediction. pixel-wise labeling address detailed information joint-wise structure provides high-level structure. however results state-of-the-art pose estimation models still many errors. predicted joints high enough quality guide human parsing compared joints extracted parsing annotations. moreover joints pose estimation aligned parsing annotations. example arms labeled arms parsing annotations covered clothes pose annotations independent clothes. address issues work investigate leverage informative high-level structure cues guide pixel-wise prediction. propose novel self-supervised structure-sensitive learning human parsing introduces self-supervised structure-sensitive loss evaluate quality predicted parsing results joint structure perspective illustrated fig. speciﬁcally addition using traditional pixelwise annotations supervision generate approximated human joints directly parsing annotations also guide human parsing training. order explicitly enforce produced parsing results semantically consistent human joint structures treat joint structure loss weight segmentation loss becomes structure-sensitive loss. self-supervised structure-sensitive loss figure illustration self-supervised structure-sensitive learning human parsing. input image goes parsing networks including several convolutional layers generate parsing results. generated joints joints ground truth represented heatmaps obtained computing center points corresponding regions parsing maps including head upper body lower body right left right left right shoe left shoe structure-sensitive loss generated weighting segmentation loss joint structure loss. clear observation combine nine heatmaps map. structure-sensitive supervision parsing annotations. human parsing results semantic parts pixel-level labels explore pose information contained human parsing results. deﬁne joints construct pose structure centers regions head upper body lower body left right left right left shoe right shoe. region head generated merging parsing labels hair sunglasses face. similarly upper-clothes coat scarf merged upper body pants skirt lower body. rest regions also obtained corresponding labels. examples generated human joints different humans shown fig. following parsing result corresponding ground truth compute center points regions obtain joints represented heatmaps training smoothly. euclidean metric evaluate quality generated joint structures also reﬂect structure consistency predicted parsing results ground truth. finally pixel-wise segmentation loss weighted joint structure loss becomes structure-sensitive loss. consequently overall human parsing networks become self-supervised structure-sensitive loss. phrase learning framework self-supervised structure-sensitive loss generated existing parsing results without extra information. self-supervised learning framework thus excellent adaptability extensibility injected advanced networks help incorporate rich high-level knowledge human joints global perspective. formally given image deﬁne list joints con|i ﬁgurations heatmap i-th joint computed according parsing result map. obtained similarly corresponding parsing ground truth. variate decided human bodies input images equals full-body image. joints missed image simply replace heatmaps maps ﬁlled zeros. joint structure loss euclidean loss dataset evaluate performance selfsupervised structure-sensitive learning method human parsing task challenging datasets. public pascal-person-part dataset images training testing pays attention human part segmentation annotated following annotations merge person part classes background class head torse upper lower arms upper lower legs. large-scale dataset highly challenging severe pose table performance comparison terms mean iou. left different test sets. middle different sizes objects. right different single input sizes. results comparisons pascal-person-part dataset table. shows performance models comparisons four state-of-the-art methods standard intersection union criterion. method signiﬁcantly outperform four baselines particularly. example best model achieves better deeplablargefov better attention large improvement demonstrates self-supervised strategy signiﬁcantly helpful human parsing task. dataset report results comparisons four state-of-the-art methods validation test table. table. validation proposed architecture give huge boost average better deeplabv better attention test method also outperforms baselines. superior performance achieved method demonstrates effectiveness selfsupervised structure-sensitive learning incorporates body joint structure pixel-wise prediction. fig. show results respect different challenging factors validation set. structure-sensitive loss performance kinds types improved demonstrates human joint structure helpful human parsing task selfsupervised learning reasonable efﬁcient. report per-class validation verify detailed effectiveness structure-sensitive loss presented table. structure-sensitive loss achieved best performance almost classes. observed reported results structure-sensitive loss signiﬁcantly improves performance labels like arms legs shoes demonstrates ability reﬁne ambiguous left right. furthermore labels covering small regions sunglasses socks gloves predicted better higher iou. improvement also demonstrates effectiveness structure-sensitive loss especially small labels. head torso u-arms l-arms u-legs l-legs deeplab-largefov table comparison person part segmentation performance four state-of-the-art methods pascalperson-part dataset network architecture utilize publicly available model attention basic architecture leading accuracy competitive efﬁciency. also train network based deeplabv employs re-purposed vgg- atrous convolution multi-scale inputs atrous spatial pyramid pooling. training pre-trained models networks settings provided deeplabv scale input images ﬁexed training networks based attention training steps employed train networks. first train basic network dataset epochs takes days. perform self-supervised strategy ﬁne-tune model structure-sensitive loss. ﬁne-tune networks roughly epochs takes half days. train models using stochastic gradient descent batch size images momentum weight decay testing stage images takes second average. reproducibility proposed method implemented extending caffe framework. networks trained single nvidia geforce titan memory. code models available https//github.com/ engineering-course/lip_ssl. figure visualized comparison human parsing results validation set. upper-body images. back-view images. head-missed images. images occlusion. full-body images. visualized comparisons self-learning structure outputs semantically meaningful precise predictions four methods despite existence large appearance position variations. example observed full-body image small regions successfully segmented method structure-sensitive loss. taking example approach also successfully handle confusing labels left versus right left versus right leg. regions similar appearances recognized separated guidance joint structure information. difﬁcult head-missed image left shoe right shoe part left excellently corrected approach. general effectively exploiting self-supervised structure-sensitive loss approach outputs reasonable results confusing labels human parsing task. pirical analysis different object sizes i.e. small medium large results four baselines proposed reported table observed shows substantial superior performance different sizes objects. demonstrates advantage incorporating structure-sensitive loss parsing model. research inﬂuence input size perform experiment scale single input. detailed analyses different input sizes methods attention mechanism scales) presented table shows structure-sensitive learning robust input size. better understanding dataset evaluate models trained test common categories reported table general performance better dataset contains instances diverse poses appearance patterns occlusions resolution issues consistent real-world situations. following mscoco dataset done emwork presented look person large-scale human parsing dataset carefully designed benchmark spark progress human parsing. contains images richly labeled semantic part labels. taking advantage rich annotations performed detailed experimental analyses identify success limitations leading human parsing approaches. furthermore design novel learning strategy namely self-supervised structure-sensitive learning explicitly enforce produced parsing results semantically consistent human joint structures.", "year": 2017}