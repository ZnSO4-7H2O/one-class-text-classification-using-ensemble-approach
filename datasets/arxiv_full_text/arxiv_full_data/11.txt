{"title": "A Unified Deep Neural Network for Speaker and Language Recognition", "tag": ["cs.CL", "cs.CV", "cs.LG", "cs.NE", "stat.ML"], "abstract": "Learned feature representations and sub-phoneme posteriors from Deep Neural Networks (DNNs) have been used separately to produce significant performance gains for speaker and language recognition tasks. In this work we show how these gains are possible using a single DNN for both speaker and language recognition. The unified DNN approach is shown to yield substantial performance improvements on the the 2013 Domain Adaptation Challenge speaker recognition task (55% reduction in EER for the out-of-domain condition) and on the NIST 2011 Language Recognition Evaluation (48% reduction in EER for the 30s test condition).", "text": "learned feature representations sub-phoneme posteriors deep neural networks used separately produce signiﬁcant performance gains speaker language recognition tasks. work show gains possible using single speaker language recognition. uniﬁed approach shown yield substantial performance improvements domain adaptation challenge speaker recognition task nist language recognition evaluation index terms recognition language recognition impressive gains performance obtained using deep neural networks automatic speech recognition motivated application dnns speech technologies speaker recognition language recognition general methods applying dnn’s tasks shown effective. ﬁrst direct method uses trained classiﬁer intended recognition task. direct method trained discriminate speakers languages second indirect method uses trained different purpose extract data used train secondary classiﬁer intended recognition task. applications indirect method used trained extract frame-level features accumulate multinomial vector accumulate multi-modal statistics used train i-vector system uniﬁed approach described work uses indirect methods described above. ﬁrst indirect method uses frame-level features extracted work sponsored department defense force contract fa--c-. opinions interpretations conclusions recommendations authors necessarily endorsed united states government. special bottleneck layer second indirect method uses posteriors extracted accumulate multi-modal statistics features statistics indirect methods used train four different i-vector systems task method point uniﬁed approach single used four i-vector systems. additionally examine feasibility using single i-vector extractor past years state-of-the-art performance achieved using i-vector based systems addition using i-vector classiﬁer baseline approach experiments also show phonetic-knowledge rich feature representations posteriors incorporated i-vector classiﬁer framework providing signiﬁcant performance improvements. section provide high-level description i-vector approach figure show simpliﬁed block diagram ivector extraction scoring. audio segment ﬁrst processed locations speech audio extract acoustic features convey speaker/language information. typically dimensional melfrequency cepstral coefﬁcients derivatives used dimensional static cepstra plus shifteddelta cepstra used analyzed feature vectors/second. using universal background model essentially speaker/language-independent gaussian mixture model per-mixture posterior probability feature vector computed used along feature vectors segment accumulate zeroth ﬁrst second order sufﬁcient statistics transformed dimensional i-vector representation using total variability matrix i-vector whitened subtracting global mean scaled inverse square root global covariance matrix normalized unit length finally score model test i-vector computed. simplest scoring function cosine distance i-vector representing speaker/language model i-vector representing test segment. current state-of-the-art scoring function called probabilistic linear discriminant analysis requires within-class matrix characterizing ivectors single speaker/language vary across class matrix characterizing i-vectors different speakers/languages vary. collectively known system’s hyper-parameters must estimated system enroll and/or score data. represent general feature distributions total variance statistics i-vectors unlabeled data desired audio domain used estimate them. matrices however require large collection labeled data training. typically require thousands speakers contributes tens samples data set. enrollment samples desired languages typically hundreds samples many different speakers used estimate σac. computationally expensive part ivector system extracting i-vectors themselves. efﬁcient approach performing data i-vectors. possible systems feature extraction matrices. tradeoff performance however since matrix signal processing specialized like multi-layer preceptron consists input layer several hidden layers output layer. layer ﬁxed number nodes sequential pair layers fully connected weight matrix. activations nodes given layer computed transforming output previous layer weight matrix output given layer computed applying activation function commonly used activation function include sigmoid hyperbolic tangent rectiﬁed linear units even simple linear transformation. note activation functions network linear stacked matrices reduce single matrix multiply. type activation function used output layer depends used for. trained regression output activation function linear objective function mean squared error output target data. trained classiﬁer output activation function soft-max objective function cross entropy output true class labels. classiﬁer output node classiﬁer correspond class output estimate posterior probability class given input data. training classiﬁers used acoustic models systems compute posterior probability sub-phonetic unit given acoustic observation. observations feature vectors extracted speech data ﬁxed sample rate using spectral technique ﬁlterbank analysis mfcc perceptual linear prediction coefﬁcients. decoding preformed using hidden markov model likely sequence senones given feature vectors training requires signiﬁcant amount manually transcribed speech data senones labels derived transcriptions using phonetic dictionary state-ofthe-art gmm/hmm system. generally speaking reﬁned phonotactic units aligned using high performing system required train high performing system training essentially traditional training. common approach uses stochastic gradient descent mini-batch updating parameters throughout training pass epoch. backpropegation algorithm used estimate gradient parameters mini-batch. initializing critical shown random initialization adequate speech applications substantial amount data held validation data used estimate error rate training epoch. algorithm uses heuristic learning rate parameter adjusted accordance scheduling algorithm monitors validation error rate epoch. training ceases error rate longer reduced. past training neural networks hidden layers proved problematic. recent advances fast affordable computing hardware optimization software initialization techniques made possible train much deeper networks. typical hidden layers number nodes typically number output senones varies hundred tens thousands also used means extracting features secondary classiﬁer including another accomplished sampling activation dnn’s hidden layers using feature vector. classiﬁers dimensionality hidden layer high sort feature reduction necessary like pca. dimension reducing linear transformation optimized part training using special bottleneck hidden layer fewer nodes bottleneck layer uses linear activation behaves much like transformation activation previous layer. bottleneck used work system described theory layer used bottleneck layer work chosen second last layer hope output posterior prediction adversely affected loss information bottleneck. typical i-vector system uses zeroth ﬁrst second order statistics generated using gmm. statistics accumulated ﬁrst estimating posterior component density frame using posteriors weights accumulating statistics component mixture distribution. zeroth order statistics total occupancies utterance across components ﬁrst order statistics weighted means component. i-vector computed using dimension reducing transformation non-linear respect zeroth order statistics. alternate approach extracting statistics proposed statistics accumulated class posteriors used place component posteriors. statistics accumulated i-vector extraction performed based statistics. apthree different corpora used experiments. trained using hours subset switchboard hour switchboard subset deﬁned example system distributed kaldi systems trained evaluated using domain adaptation challenge data systems evaluated nist language recognition evaluation data details training development data found systems speech activity segmentation generated using based speech activity detector i-vector system uses ppca estimate matrix. scoring performed using plda exception input features multi-modal statistics i-vector systems identical component dimensional i-vector subspace. systems discriminative backend described front-end feature extraction baseline system uses static cepstra appended sdc. unlike front-end described vocal track length normalization feature domain nuisance attribute projection used. front-end baseline system uses mfccs including ﬁrst derivatives total features. trained using state cluster target labels generated using kaldi switchboard tria example system front-end uses gaussianized coefﬁcients ﬁrst second order derivatives stacked frame window total input features. segmentation applied stacked features. hidden layers nodes exception bottleneck layer nodes. hidden layers sigmoid activation function exception layer linear. training preformed nvidia tesla using custom software developed mit/csail. sets experiments corpora indomain out-of-domain. sets experiments hyper-parameters trained switchboard data. hyper-parameters trained speaker recognition evaluation data in-domain experiments data out-of-domain experiments details). tables summarize results in-domain out-of-domain experiments ﬁrst table corresponding baseline system. dnnposterior technique mfccs gives signiﬁcant gain baseline system sets experiments also reported even greater gain realized using bottleneck features gmm. unfortunately using bottleneck features dnn-posteriors degrades performance. experiments task summarized table ﬁrst corresponding baseline system last corresponding fusion postevaluation systems details). bottleneck features posteriors performs systems conﬁgurations including system fusion. interestingly bottleneck features dnn-posteriors show improvement baseline system speaker recognition experiments. table shows performance tasks extracting i-vectors using parameters systems. expected degradation performance mis-matched task degradation less task using hyper-parameters. result motivate research developing uniﬁed i-vector extraction system careful ubm/t training data selection. paper presented bottleneck feature extractor effective speaker language recognition produces signiﬁcant performance gains stateof-the-art mfcc/sdc i-vector approaches well recent dnn-posterior approaches. speaker recognition task bottleneck features decreased in-domain out-of-domain out-of-domain results particularly interesting since in-domain data used training hyper-parameter adaptation. bottleneck features decreased eers test durations respectively even performed system fusion acoustic phonetic based recognizers. ﬁnal experiments demonstrated possible common i-vector extractor uniﬁed speaker language recognition system. although presented here also observed recognizers using bottleneck features produced much better calibrated scores measured cllr metrics. bottleneck features essence learned feature representation posteriors derived. experimentally appears using learned feature representation better using output posteriors features combining bottleneck features posteriors degrades performance. able train better suited posterior estimator data matched task data. since working features future research examine whether effective classiﬁers apply i-vectors. future research explore sensitivity bottleneck features dnn’s conﬁguration training data quality quantity. garcia-romero zhang mccree povey improving speaker recognition performance domain adaptation challenge using deep neural networks proc. ieee workshop povey ghoshal boulianne burget glembek goel hannemann motlicek qian schwarz silovsky stemmer vesel kaldi speech recognition toolkit proc. ieee asru geoffrey hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath kingsbury deep neural networks acoustic modeling speech recognition ieee signal processing magazine november lopez-moreno gonzalez-dominguez plchot martinez gonzalez-rodriguez moreno automatic language identiﬁcation using deep neural networks proc. icassp sarkar c.-t. v.-b. barras combination cepstral phonetically discriminative features speaker veriﬁcation ieee signal processing letters vol. sept.", "year": 2015}