{"title": "A new look at reweighted message passing", "tag": ["cs.AI", "cs.CV", "cs.LG"], "abstract": "We propose a new family of message passing techniques for MAP estimation in graphical models which we call {\\em Sequential Reweighted Message Passing} (SRMP). Special cases include well-known techniques such as {\\em Min-Sum Diffusion} (MSD) and a faster {\\em Sequential Tree-Reweighted Message Passing} (TRW-S). Importantly, our derivation is simpler than the original derivation of TRW-S, and does not involve a decomposition into trees. This allows easy generalizations. We present such a generalization for the case of higher-order graphical models, and test it on several real-world problems with promising results.", "text": "note generalized trw-s recently presented however argue generalization complicated introduces notation definitions related decomposition graphical model monotonic junction chains imposes weak assumptions tion) uses restriction order processing factors proposes special treatment nested factors improve eﬃciency. makes generalized trw-s diﬃcult understand implement. believe derivation beneﬁts even pairwise graphical models. family srmp algorithms ﬂexible compared trw-s; discussed conclusions prove useful certain scenarios. related work besides closest related works probably ﬁrst presented generalization pairwise higher-order graphical models also described family relaxations speciﬁed pairs nested factors marginalization constraint needs enforced. framework paper. work presented family convex message passing algorithms building blocks. research also went developing algorithms guaranteed converge optimal solution examples include subgradient techniques smoothing objective temperature parameter gradually goes zero proximal projections nesterov schemes augmented lagrangian method proximal gradient method bundle method mirror descent method smoothed version trw-s propose family message passing techniques estimation graphical models call sequential reweighted message passing special cases include well-known techniques min-sum diﬀusion faster sequential tree-reweighted message passing importantly derivation simpler original derivation trw-s involve decomposition trees. allows easy generalizations. family algorithms viewed generalization trw-s pairwise higher-order graphical models. test srmp several real-world problems promising results. paper devoted problem minimizing function discrete variables represented factors factor term depending certain subset variables. problem also known map-mrf inference graphical model. generality deﬁnition applications many areas. probably well-studied case factor depends variables many inference algorithms proposed. prominent approach solve natural linear programming relaxation problem sometimes called schlesinger research went developing eﬃcient solvers special detailed below. proposed techniques min-sum diﬀusion short derivation price simplicity eﬃciency signiﬁcantly slower advanced techniques sequential tree-reweighted message passing derivation trw-s uses additionally decomposition graph trees namely monotonic chains. makes generalizing trw-s cases harder consider simple modiﬁcation call anisotropic msd; equivalent special case convex max-product algorithm show particular choice weights order processing nodes anisotropic becomes equivalent trw-s gives alternative derivation trw-s involve decomposition chains allows almost immediate generalization trw-s higher-order graphical mostly focus case take incoming outgoing edges generality also allow proper subsets. procedures described special cases convex max-product algorithm formulated diﬀerent presentation notion reparameterization. case anisotropic consider factor simnon-empty incoming edges algorithm maximizing messages min-sum diﬀusion pairwise models discovered kovalevsky koval independently flach werner generalized higher-order relaxations. consider generalization algorithm call anisotropic given fig. ﬁrst step computes marginals parents moves factor call collection step. propagates obtained vector back parents weights ωαβ. probability distribution known factor graph resulting relaxation sometimes called basic relaxation known relaxation tight term submodular function larger classes functions solved recently identiﬁed fact completely characterized classes valued constraint satisfaction problems relaxation always tight. contains single edge uniform procedure becomes equivalent msd. procedure becomes equivalent version described factor graph; need take cα/ˆcβ). work used ﬁxed distribution factor. show however allowing non-ﬁxed distributions lead signiﬁcant gains performance. section particular scheme together particular order processing factors correspond trw-s algorithm often faster msd/cmp. case anisotropic mplp algorithm given updates single message edge corresponds amsd uniform distribution equivalent performing single-edge updates convergence. version pairwise energies mentioned although without explicit formula. correspond amplp uniform probability distribution analogy case conjecture diﬀerent weighting could lead faster convergence. however leave question future research focus case instead. completeness appendix give implementation amplp messages; slightly diﬀerent implementations since store explicitly vectors factors least incoming edge remove factor aﬀect relaxation.) factors least incoming edge. select total order srmp order backward pass next discuss select distributions diﬀerent distributions forward backward passes; denoted respectively. cial case srmp. particular f|α| setting would give gtrw-s uniform distribution junction chains resulting weight smaller weight remark tried choice namely setting case pairwise models. gives larger weights compared somewhat surprisingly preliminary tests appeared perform slightly worse choice possible informal explanation follows operation amsd sends mass away never come back. thus desirable keep mass especially original vectors factors messages edges deﬁne current reparameterization leads algorithm fig. updates done possible usual numerical stability mesminxβ aﬀect backward pass update edge therefore processed updates similarly also processed. therefore vector never modiﬁed updates immediately update vector xα∼xβ pairwise graphical models skipping unnecessary updates reduces amount computation approximately factor note argument proposition apply ﬁrst forward pass algorithm therefore pass equivalent amsd updates lower bound potentially decrease ﬁrst pass. alternative implementation ﬁrst glance algorithm appear diﬀerent trw-s algorithm example graph chain ﬁrst iteration messages trw-s converge srmp keep changing show connection trw-s describe alternative implementation srmp update rules weights used last update update rules interpretation given appendix weights chosen updates equivalent extracting primal solution used following scheme extracting primal solution beginning forward pass mark nodes unlabeled. consider procedure amsd assign labels nodes follows compute restricted messages using following modiﬁcation instead minimizing labelings minimize labelings consistent currently labeled nodes compute labelings consistent currently labeled nodes choose labeling smallest cost shown pairwise graphical models procedure equivalent given procedure backward pass. observed forward pass usually produces labeling previous forward pass forward backward passes often given diﬀerent results. accordingly extraction procedure every third iteration passes keep track best solution found far. fig. order processing factors important question thus parameter srmp order nodes. choice order important issue addressed paper. note however many applications natural order nodes often works well. tests processed nodes order given. remark note sequence least limit point example vectors bounded. conjecture vectors always stay bounded leave open question. remark message passing algorithms conjectured messages converge ﬁxed point would like emhpasize case srmp algorithm discussed previous section; general messages would diﬀerent backward forward passes. respect srmp diﬀers proposed message passing techniques trw-s mplp. however weaker convergence property given theorem still holds. except prove vectors stay bounded.) remainder section devoted proof theorem proof applicable srmp sequences updates amsd satisfy certain conditions. ﬁrst condition updates consist iteration repeatedly applied inﬁnitely many times iteration visits statement special case following well-known fact j-consistent applying number treestructured block-coordinate ascent steps increase lower bound. completeness proof fact given below. support probability distribution vector constructed follows. first connected component pick arbitrary factor component choose distribution supp repeatedly choose edge excomplementary slackness conditions vectors therefore optimal dual vector means applying block-coordinate ascent step results vector optimal well complementary slackness conditions must hold consider sequence amsd updates fig. diﬃculty analysis components distributions zeros. need impose restrictions components. speciﬁcally require following ﬁrst equality holds since sequence monotonic second equality continuity function denoted space vectors form need show j-consistent. suppose case. deﬁne mapping follows take vector apply iterations srmp theorem clearly thus continuous mappings therefore remains prove theorem remark note theorem holds sequence amsd updates satisfying conditions believe case theorem example updates factors used varying distributions whose components would tend zero increase lower bound could become exponentially smaller iteration might converge j-consistent vector argument essential sequence updates repeating weights used algorithm kept constant. assume applying iterations vector increase lower bound; need show j-consistent. deﬁne relations using following procedure. beginning calling amsd update checking properties hold iniproof. tialization straightforward. show call procedure amsd preserves them. notation lemma similarly denote rγrαβ corresponding quantities monotonicity rαβ. show section compare srmp uniform distributions mplp. note many inference algorithms e.g. recent comprehensive comparison. goal replicate comparison instead focus techniques family since represent important branch optimization algorithms. implemented three methods framework trying amount eﬀort optimizing technique. mplp used equations given appendix protein second-order stereo instances discussed implementation times faster code three techniques factors processed order described section unless noted otherwise graph constructed follows possible intersections existing factors; edges intermediate factor problems also experimented relaxation although weaker general message passing operations potentially implemented faster certain factors. instances used data cited subset data energies order note energies order srmp equivalent trw-s; included case completeness. instances summarized below. potts stereo vision. took instances node possible labels. stereo second order smoothness prior used version described energy unary terms ternary terms horizontal vertical directions. scaled-down stereo pairs tsukuba venus constraint-based curvature described nodes correspond faces dual graph possible labels. used cameraman lena images size code appears message update routines factors. instead implemented separate routines diﬀerent factors virtual functions c++. addition precompute necessary tables excluded instances specialized high-order factors used require customized message passing routines implemented. discussed energies mplp advantage; srmp could competitive mplp factor allows eﬃcient incremental updates exploiting figure average lower bound energy time. axis srmp iterations scale. notation /a/b means iteration srmp takes time iterations iterations mplp. note srmp iteration passes mplp iterations forward passes. however pass srmp updates subset messages axis lower bound/energy stances also tried reparameterized energies given three methods performed similarly summary results plots fig. make following conclusions. problems highly regular graph structure srmp clearly outperforms mplp. protein-related problems srmp perform similarly outperform mplp. remaining problem three techniques roughly comparable although srmp converges worse solution. subset problems also gtrwcode found behaviour similar srmp fig. claim speed improvement gtrw-s; instead advantage srmp simpler general formulation presented family algorithms includes trw-s special cases. derivation srmp shorter trw-s; facilitate generalizations cases. developed generalization higher-order graphical models also envisage directions. interesting possibility treat edges pairwise graphical model diﬀerent weights depending strengths; srmp provides natural this. certain scenarios desirable perform updates certain parts graphical model again srmp suitable that. presented smoothed version trw-s pairwise models; framework allow easy generalization higher-order graphical models. thus hope paper lead research directions area approximate map-mrf inference. seen updates given equivalent note order operations slightly diﬀerent step forward pass send messages node higher-ordered nodes messages sent lower-ordered nodes however checked result cases same. thank thomas schoenemann help experimental section providing data. work parts funded european research council under european unions seventh framework programme /erc grant agreement implementation amplp given below; updates done labelings step essentially messages zero update accordingly. explicitly would eﬀect.) step move factor again could step would eﬀect. avoid accumulation numerical errors recompute stored values current messages", "year": 2013}