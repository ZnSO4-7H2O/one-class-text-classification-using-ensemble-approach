{"title": "Linear Disentangled Representation Learning for Facial Actions", "tag": ["cs.CV", "cs.AI", "cs.LG", "stat.ML"], "abstract": "Limited annotated data available for the recognition of facial expression and action units embarrasses the training of deep networks, which can learn disentangled invariant features. However, a linear model with just several parameters normally is not demanding in terms of training data. In this paper, we propose an elegant linear model to untangle confounding factors in challenging realistic multichannel signals such as 2D face videos. The simple yet powerful model does not rely on huge training data and is natural for recognizing facial actions without explicitly disentangling the identity. Base on well-understood intuitive linear models such as Sparse Representation based Classification (SRC), previous attempts require a prepossessing of explicit decoupling which is practically inexact. Instead, we exploit the low-rank property across frames to subtract the underlying neutral faces which are modeled jointly with sparse representation on the action components with group sparsity enforced. On the extended Cohn-Kanade dataset (CK+), our one-shot automatic method on raw face videos performs as competitive as SRC applied on manually prepared action components and performs even better than SRC in terms of true positive rate. We apply the model to the even more challenging task of facial action unit recognition, verified on the MPI Face Video Database (MPI-VDB) achieving a decent performance. All the programs and data have been made publicly available.", "text": "limited annotated data available recognition facial expression action units embarrasses training deep networks learn disentangled invariant features. however linear model several parameters normally demanding terms training data. paper propose elegant linear model untangle confounding factors challenging realistic multichannel signals face videos. simple powerful model rely huge training data natural recognizing facial actions without explicitly disentangling identity. base well-understood intuitive linear models sparse representation based classiﬁcation previous attempts require prepossessing explicit decoupling practically inexact. instead exploit low-rank property across frames subtract underlying neutral faces modeled jointly sparse representation action components group sparsity enforced. extended cohn-kanade dataset one-shot automatic method face videos performs competitive applied manually prepared action components performs even better terms true positive rate. apply model even challenging task facial action unit recognition veriﬁed face video database achieving decent performance. programs data made publicly available. units widely-used basic emotions deﬁned paul ekman include surprise sadness disgust anger fear happiness. also deﬁnes facial action coding system using code almost expression. recently feature learning using auto-encoder adversarial training shown able disentangle facial expression identity pose. unlike face recognition limited labelled training data available facial expressions particular. shown fig. expressive face separated principal component neutral face encoding identity cues action component encoding motion cues highlighted brow cheek nose relate facs. recognition always broken measuring similarity similar identity confuse similar action. decouple them ﬁrst rules neural face explicitly discriminate different action components instead faces ﬁrst step based observation underlying neutral face stays same. stack vectors neutral faces time action matrix low-rank ideally rank theoretically low-rank principal component pursuit exact certain conditions approximate nature practice. second step based idea describing action component sparse representation over-complete dictionary formed action components categories. thing implicitly neutral face. another equally-spaced sampled frames since frames collaboratively redundantly represent expression neutral face. then sparse coefﬁcient vectors form joint-sparse coefﬁcient matrix. drives induce joint sparse representation implicit lowrank approximation model also induces consistent classiﬁcations across frames. furthermore ideally non-zero coefﬁcients drop ground-truth category. therefore class-level sparsity coefﬁcient matrix exhibits group sparsity. however coefﬁcient vectors share class-wise necessarily atomwise sparsity thus prefer enforcing group sparsity atom-wise sparsity. name extended model collaborative-hierarchical sparse low-rank model following naming c-hilasso sec. review classic idea learning sparse representation classiﬁcation related application expression recognition. remainder ﬁrst elaborate model sec. discuss solving model joint optimization sec. ﬁnally quantitatively evaluate model sec. conclusion followed sec. among non-linear models line work kernel-based methods another deep learning similar ideas disentangling factors presented introducing extra cues line works models another multi-modal models linear world observing random signal recognition hope send classiﬁer discriminative compact representation dictionary normally computed pursuing best reconstruction. example under-complete closedform approximate solution obtained least-squares alternatively seek sparse usage sparse representation based classiﬁcation expresses test sample weighted linear combination training samples simply stacked columnwise dictionary presumably non-zero weight coefﬁcients drop ground-truth class induces sparse coefﬁcient vector so-called sparse representation. practice non-zero coefﬁcients also drop classes noises correlations among classes. adding error term particularly facial actions treat videos multichannel signals different image-based methods explicitly separates neutral face action component exploits class-wise sparsity separately recognition identity neutral faces expression action components. differently focus facial actions exploit low-rank property disentangling identity well structured sparsity interchannel observation. furthermore tradeoff simplicity performance. videos sequential signals appearance-based methods including cannot model dynamics given temporal model spatiotemporal models linear models include ordinal regression boosting section explain model using training data contains types actions. would like classify test video classes. joint sparse representation low-rankness first need explicit representation expressive face. matrix rd×τ arrangement d-dimensional feature vectors emphasize model’s power simply using pixel intensities. seek implicit latent representation rn×τ input test face’s emotion rd×τ sparse linear combination prepared ﬁxed training emotions rd×n dictionary matrix dd×n arrangement training sub-matrices training emotions neutral faces subtracted. constraint characterizes afﬁne transformation latent representation observation ideal case rank neutral face pre-obtained trival solve normally unknown rank noises. supposed sparse rank expected small possible intuitively objective c-hislr degenerates slr. back collaborative sparse group lasso. classiﬁcation following class denote sub-matrix consists columns correspond emotion class similarly classify assigning class minimal residual minc l||f shrinkage thresholding operator. lasso problem solve using illinois fast solver. follows chislr computing needs approximation based taylor expansion refer reader convergence analysis recovery guarantee. evaluate model expressions action units images cropped using viola-jones face detector. category accuracies averaged runs. holistic facial expression recognition experiments conducted dataset consisting videos labels. c-hislr assume prior knowledge neutral face. testing unit contains last frames together ﬁrst frame explicitly known priori neutral face. contempt discarded confusion anger disgust choose keep completeness experiment ck+. https//github.com/eglxiang/icassp_emotion cropped face data programs c-hislr eigenface. optimization problem reduces src. terms relaxed convex norms alternatively solve entry-wise matrix norm whereas schatten matrix norm seen applying norm vector singular values. proposed joint model expressed c-hislr collaborative-hierarchical model low-rank term becomes problem multi-channel lasso single-channel signal group lasso explored group structure lasso enforce sparsity within group sparse group lasso yields atom-wise sparsity well group sparsity. then extends sparse group lasso multichannel resulting collaborative-hierarchical lasso model. problem need induces collaborativehierarchical sparse low-rank model sub-matrix formed rows indexed elements group ...n}. shown fig. given group indices sub-dictionary columns indexed denoted non-overlapping partition denotes frobenius norm entry-wise norm well testing dataset divided training disjoint testing sub-videos category. slr’s performance shown fig. average recognition rate c-hislr’s performance shown fig. average recognition rate perform poorly confuse lips. paper propose identity-decoupled linear model learn facial action representation unlike requiring neutral faces inputs generating labels identity facial action mutual by-products extra efforts. fig. confusion matrix chi-slr mpi-vdb. achieves recognition rate optimizer runs iters lasso iters. chi-slr achieves recognition rate optimizer runs iters. case fig. effect group sparsity. τtrn test input recovered given c-hislr correctly classiﬁes contempt. recovery results given mis-classiﬁes sadness. denote results frame respectively whereas displays recovered given c-hislr group-sparse expected. forming dictionary subtract ﬁrst frame last τtrn frames video. parameters τtrn τtst randomly choose videos training testing class. fig. visualizes recovery results given c-hislr. table present confusion matrix respectively. columns predictions rows ground truths. table summarizes true positive rate anticipated performs worse since equipped neutral faces. however c-hislr’s result comparable src’s. c-hislr performs even better terms sensitivity veriﬁes group sparsity indeed boosts performance. comparsion replicate image-based used assume neutral face provided. represent action component subtracting neutral face ﬁrst frame last frame video. choose half training half testing class. sparsity level achieves recognition rate shown table accuracies fear confuse other. facial action unit recognition pose-independant following experiments conducted proﬁle view mpi-vdb containing long video frames video sample disjoint sub-videos contains equally-spaced sampled frames. different sec. frames directly used without subtracting ﬁrst frame sub-videos start neutral states. however implicitly exist underlying neural states presumably proposed model still valid. randomly sample sub-videos training first recover contribution two-fold. action component explicitly. instead video-based sparse representation jointly modelled low-rank property across frames neutral face underneath automatically subtracted. second preserve label consistency enforcing atom-wise well group sparsity. dataset c-hislr’s performance faces comparable given neutral faces veriﬁes action components automatically separable faces well sparsely representable training data. also apply model recognizing actions units limited training data embarrass deep learning techniques. salah rifai yoshua bengio aaron courville pascal vincent mehdi mirza disentangling factors variation facial expression recognition eccv. springer ping joey tianyi zhou ivor wai-hung tsang zibo meng shizhong tong feature disentangling machine-a novel approach feature selection disentangling facial expression analysis eccv. springer raymond ptucha grigorios tsagkatakis andreas savakis manifold based sparse representation robust expression recognition without neutral subtraction ieee iccv workshops pablo sprechmann ignacio ramrez guillermo sapiro yonina c-hilasso collaborative hierarchical sparse modeling eldar framework ieee trans. sig. proc. vol. fabian benitez-quiroz ramprakash srinivasan aleix martinez emotionet accurate real-time algorithm automatic annotation million facial expressions wild cvpr june chen jiangdong fengjun zhang yang hongan wang model-based continuous emotion recognition cvpr zheng zhang jeff girard xing zhang peng umur ciftci shaun canavan michael reale andy horowitz huiyuan yang jeffrey cohn qiang lijun multimodal spontaneous emotion corpus human behavior analysis cvpr june kaili zhao wen-sheng fernando torre jeffrey cohn honggang zhang joint patch multi-label learning facial action unit detection cvpr june zhao quan shangfei wang qiang facial expression intensity estimation using ordinal information cvpr june ognjen rudovic vladimir pavlovic maja pantic multi-output laplacian dynamic ordinal regression facial expression recognition intensity estimation cvpr. ieee patrick lucey jeffrey cohn takeo kanade jason saragih zara ambadar extended cohn-kanade dataset complete ieee dataset action unit emotion-speciﬁed expression cvpr", "year": 2017}