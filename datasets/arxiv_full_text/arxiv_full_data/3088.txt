{"title": "Robust Nonnegative Matrix Factorization via $L_1$ Norm Regularization", "tag": ["cs.LG", "cs.CV", "stat.ML"], "abstract": "Nonnegative Matrix Factorization (NMF) is a widely used technique in many applications such as face recognition, motion segmentation, etc. It approximates the nonnegative data in an original high dimensional space with a linear representation in a low dimensional space by using the product of two nonnegative matrices. In many applications data are often partially corrupted with large additive noise. When the positions of noise are known, some existing variants of NMF can be applied by treating these corrupted entries as missing values. However, the positions are often unknown in many real world applications, which prevents the usage of traditional NMF or other existing variants of NMF. This paper proposes a Robust Nonnegative Matrix Factorization (RobustNMF) algorithm that explicitly models the partial corruption as large additive noise without requiring the information of positions of noise. In practice, large additive noise can be used to model outliers. In particular, the proposed method jointly approximates the clean data matrix with the product of two nonnegative matrices and estimates the positions and values of outliers/noise. An efficient iterative optimization algorithm with a solid theoretical justification has been proposed to learn the desired matrix factorization. Experimental results demonstrate the advantages of the proposed algorithm.", "text": "nonnegative matrix factorization widely used technique many applications face recognition motion segmentation etc. approximates nonnegative data original high dimensional space linear representation dimensional space using product nonnegative matrices. many applications data often partially corrupted large additive noise. positions noise known existing variants applied treating corrupted entries missing values. however positions often unknown many real world applications prevents usage traditional existing variants nmf. paper proposes robust nonnegative matrix factorization algorithm explicitly models partial corruption large additive noise without requiring information positions noise. practice large additive noise used model outliers. particular proposed method jointly approximates clean data matrix product nonnegative matrices estimates positions values outliers/noise. efﬁcient iterative optimization algorithm solid theoretical justiﬁcation proposed learn desired matrix factorization. experimental results demonstrate advantages proposed algorithm. several variants proposed recently improve performance. sparseness constraints incorporated obtain sparse solutions algorithms proposed preserve local struc proposes ture dimensional manifold. robust outliers rsnmf based outlier resistant objective function. maintains outlier list robust performance. real applications data samples often partially corrupted. figure shows examples kind partial corruption. intuitively partial corruption treated large additive noise. unfortunately traditional methods based least square estimation sensitive kind noise since underlying assumption gaussian noise distribution valid. recent work tries deal partial corruption. usually assume positions corruption given ahead ignore corresponding data entries. however unrealistic assume positions corruption known many real world applications. proposes robust recover noise value position. paper proposes robust nonnegative matrix factorization approach able simultaneously learn basis matrix coefﬁcient matrix estimate positions values noise. underlying observation clean data allow nonnegative factorization noise sparse. efﬁcient iterative optimization algorithm solid theoretical justiﬁcation proposed obtain desired solution robustnmf approach. best knowledge work ﬁrst technique generates robust results data large additive noise without requiring information positions noise. rest part paper organized follows. section reviews traditional algorithm. section proposes robustnmf algorithm followed iterative optimization method section section provides theoretical review nonnegative matrix factorization given nonnegative matrix rm×n column represents data sample algorithm aims learn nonnegative matrices rm×k rk×n approximating product them i.e. learn following objective function minimized proposed robust nonnegative matrix factorization algorithm explicitly models partial corruption treated large additive noise. nonnegative matrix rm×n denote observed corrupted data column data sample. rm×n denote clean data without pollution. rm×n large additive noise. note large additive noise gaussian noise zero mean well handled least square error minimization. moreover concerned partial corruption partial means noise distribution sparse. words small portion entries nonzero. example face recognition occlusion glasses instance kind noise covers small portion entire face. ﬁrst term approximate clean data; second term obtained sparseness constraint parameter controls tradeoff terms thus dependent large portion entries corrupted. however norm second term makes objective function difﬁcult optimize norm employed approximate popular strategy prior research substituting norm objective function squared norm penalty sparseness proved effective computationally convenient note sparse large additive noise could either negative nonnegative. need decompose nonnegative matrices described gain nonnegativity results convenience optimization. also constraint since clean data nonnegative. finally objective function minimized respect subject constraints updatevt+ minv zvvt) lemma auxiliary function nonincreasing long asvt+ zvt+vt) zvtvt) vt+) zvt+vt) zvtvt) problem contains negative value. thus updating rules auxiliary function kvt) diagonal matrix. thus second order terms involve formv lemma ifvt+ minv zvvt) andvt ≥vt+ ≥vt+ zvt+vt) zvtvt). according lemma lemma vt+) vt). ensure nonnegativity simply thresholdvt+ opfromvt thresholdedvt+. thus updating rule described several algorithms proposed deal data partial corruption. however usually assume positions noise known advance. fortunately proposed robustnmf able locate positions. missing values located existing algorithms also applied. subsection presents experiments detecting positions large noise face images image patches. reported results averaged runs. experiments based face dataset. face image size thus represented dimensional vector. face randomly selected subset pixels randomly selected replaced values simulate large additive noise. polluted faces make data matrix column corresponds polluted face image. then apply robustnmf algorithm estimate furthermore scan entries nonzero claim corresponding pixel polluted. procedure able detect positions noise analyzing performance evaluated precision recall recision detectedp ollutedp ixels recall detectedp ollutedp ixels algorithm since algorithm best knowledge designed handle task. tried compare proposed algorithm nmf. ﬁrst applied noisy data gain reconstruction tried detect positions noise analyzing difference however difﬁcult appropriate threshold difference performance sensitive this. tried several thresholds gave poor results probably partial corruption signiﬁcantly skews solution nmf. ﬁgure left subﬁgure presents precision recall versus different numbers face images. algorithm gains precision recall performance increases increase number image faces. reasonable since samples means information robustnmf explore. number large enough increasing number help improve performance longer. middle right subﬁgures ﬁgure investigate relationship performance parameter still number face images ﬁxed middle subﬁgure right subﬁgure. generally speaking algorithm gains precision recall. larger values precision become little higher recall little lower. consistent expectation since larger indicates detected noise sparse often leads higher precision lower recall. discussed before algorithms wnmf able handle large noise positions given. thus robustnmf locate noise employ wnmf recover images. reason combining methods approximation norm robustnmf cause absolute value estimation smaller truth. robustnmf+wnmf denote combined method. section original data samples form matrix mean squared reconstruction. compared original noise free matrix msre polluted not. taking mask wnmf learns matrix experiments conducted varying number pixels polluted faces. ﬁrst experimentswe number faces vary number pixels polluted step means percent percent pixels corrupted face. results shown ﬁgure second experiments number pixels polluted ﬁxed means percent pixels face corrupted. experiments conducted various numbers faces step results shown bottom ﬁgure consistently outperform traditional varying number data samples. increasing amount noise advantages proposed algorithms become even larger. robustnmf able detect positions large value noises i.e. partial corruption enables application wnmf. considering approximation norm norm large noise underestimated prefer robust+wnmf pure robustnmf even though methods outperform traditional nmf. subsection presents experiment results image denoising using robustnmf. pepper salt noise added natural images. noise density means pixels affected. noisy image converted patches robustnmf applied. used reconstruct original image. denoising results shown ﬁgure ﬁrst shows generated polluted images second shows denoised results traditional third results robustnmf. seen robustnmf outperforms traditional nmf. space limit ground truth image results robustnmf+wnmf experiments images given supplemental materials. data many real world applications often partially corrupted without explicit information positions noise prevents usage existing variants.this paper proposes robustnmf algorithm large additive noise handle partial corruption without requiring position information noise advance. proposed algorithm able simultaneously locate estimate large additive noise learn basis matrix coefﬁcient matrix framework nmf. proposed algorithm also paves apply variants data missing values estimating positions noise. efﬁcient optimization algorithm solid theoretical justiﬁcation proposed robustnmf. experimental results three different sets applications demonstrate advantages algorithm. future research plan explore rank version robustnmf automatically adequate rank decomposed matrices. similar robustpca applications robustnmf investigated since widely used various areas including computer vision text mining speech analysis etc.", "year": 2012}