{"title": "Learning to detect chest radiographs containing lung nodules using  visual attention networks", "tag": ["stat.ML", "cs.CV"], "abstract": "Machine learning approaches hold great potential for the automated detection of lung nodules in chest radiographs, but training the algorithms requires vary large amounts of manually annotated images, which are difficult to obtain. Weak labels indicating whether a radiograph is likely to contain pulmonary nodules are typically easier to obtain at scale by parsing historical free-text radiological reports associated to the radiographs. Using a repositotory of over 700,000 chest radiographs, in this study we demonstrate that promising nodule detection performance can be achieved using weak labels through convolutional neural networks for radiograph classification. We propose two network architectures for the classification of images likely to contain pulmonary nodules using both weak labels and manually-delineated bounding boxes, when these are available. Annotated nodules are used at training time to deliver a visual attention mechanism informing the model about its localisation performance. The first architecture extracts saliency maps from high-level convolutional layers and compares the estimated position of a nodule against the ground truth, when this is available. A corresponding localisation error is then back-propagated along with the softmax classification error. The second approach consists of a recurrent attention model that learns to observe a short sequence of smaller image portions through reinforcement learning. When a nodule annotation is available at training time, the reward function is modified accordingly so that exploring portions of the radiographs away from a nodule incurs a larger penalty. Our empirical results demonstrate the potential advantages of these architectures in comparison to competing methodologies.", "text": "machine learning approaches hold great potential automated detection lung nodules chest radiographs training algorithms requires vary large amounts manually annotated images diﬃcult obtain. weak labels indicating whether radiograph likely contain pulmonary nodules typically easier obtain scale parsing historical free-text radiological reports associated radiographs. using repositotory chest radiographs study demonstrate promising nodule detection performance achieved using weak labels convolutional neural networks radiograph classiﬁcation. propose network architectures classiﬁcation images likely contain pulmonary nodules using weak labels manually-delineated bounding boxes available. annotated nodules used training time deliver visual attention mechanism informing model localisation performance. ﬁrst architecture extracts saliency maps high-level convolutional layers compares estimated position nodule ground truth available. corresponding localisation error back-propagated along softmax classiﬁcation error. second approach consists recurrent attention model learns observe short sequence smaller image portions reinforcement learning. nodule annotation available training time reward function modiﬁed accordingly exploring portions radiographs away nodule incurs larger penalty. empirical results demonstrate potential advantages architectures comparison competing methodologies. lung cancer common cancer worldwide second common cancer europe estimated leading cause cancer death typically advanced stage diagnosis survival rate delay diagnosis chest radiograph commonly performed radiological investigation quick inexpensive associated radiation doses. chest radiograph nodule rounded opacity less wellpoorly-deﬁned. pulmonary mass similar larger usually conspicuous detecting pulmonary lesions plain challenging because despite high spatial resolution limited contrast resolution. planar nature means heart diaphragm mediastinum obscure large part lungs ∗petros-pavlos ypsilantis emanuele pesce giovanni montana department biomedical engineering king’s college london london united kingdom samuel withey department radiology guy’s thomas’ foundation trust london robert bakewell department medicine imperial college healthcare trust london vicky department cancer imaging king’s college london london united kingdom ﬁrst authors contributed equally work. asterisk indicates corresponding author. patients often several co-existing pathologies visible chest radiograph. furthermore many benign ﬁndings mimic nodule e.g. opacity composite shadowing skin lesions. studies shown lung cancer diagnoses lesion seen plain computer-aided detection systems using machine learning techniques facilitate automated detection lung nodules provide cost-eﬀective double-reporting mechanism. performance systems varies substantially depending size nature samples used compute performance metrics. instance sensitivity detect nodules larger ranges using system combined bone suppression algorithm using commercially available system alone whereas imaging modalities cancer detection mammograms routinely double-read associated improvement sensitivity feasible chest x-rays lack resources. hence hoped machine-learning systems provide cost-eﬀective alternative double-reporting assisting radiologists improving sensitivity lung cancer detection. order trained systems typically require large number images nodules manually annotated. expensive time-consuming obtain. recent years widespread adoption digital archiving reporting systems pacs hospitals facilitated access large amounts historical studies used train machine learning systems access large-scale clinical datasets started enable joint modelling images radiological reports diagnostic purposes automated detection pulmonary nodules challenging task nodules small ill-deﬁned margins. typically natural images problem framed automated object detection state-of-art results currently obtained deep convolutional neural networks large majority methods regression models predict coordinates bounding boxes likely contain object interest alternatively make sliding windows approaches capitalize excellent representation learning capability provided dcnns. documented studies rely large annotated datasets natural images objects detected typically well-deﬁned suﬃciently large compared entire image. medical imaging manual annotation daunting task scale well size currently available historical datasets. moreover nodule typically covers tiny fraction chest radiograph obscured ribs structures diaphragm heart mediastinum thus making detection task signiﬁcantly challenging. moreovercan wide range abnormalities x-ray. study cast nodule detection task image classiﬁcation task. objective detect chest radiographs appearances indicating presence pulmonary nodule keeping number images nodules potentially abnormalities manageble level. ﬁrst hypothesis image classiﬁer based deep convolutional networks trained accomplish task using weak possibly noisy image labels. moderate proportion labels extracted historical radiological reports expected noisy human errors estimated least interreader variability automated label extraction methods used natural language processing algorithms noise level expected even higher errors interpreting radiological language. several recent studies using natural images shown dcnns image classiﬁcation suﬃciently robust noisy labels ﬁndings provide reassurance that large majority radiological labels accurate dcnn able learn those provided suﬃciently large data repository. order address hypothesis collected historical chest radiographs large teaching hospitals london guy’s thomas’ million patient encounters year natural language processing system developed parse free-text radiological reports used identify exams containing mention pulmonary nodules masses. ideally training dataset contain large number manually annotated nodules either countours bounding boxes indicating exact location within image obtained. however manual annotation process time consuming number annotated nodules often substantially smaller total number available exams. second hypothesis classiﬁcation improvements obtained augmenting image labels nodule’s bounding whenever information obtained even small subset exams. investigate hypothesis approximately radiographs dataset identiﬁed presenting least nodule randomly selected subsequently inspected radiologist manually delineated bounding boxes. annotation process resulted pulmonary nodules precisely highlighted images. rationale that position nodule known training exploited provide network additional visual feedback quality features learned convolutional ﬁlters. present diﬀerent learning strategies leverage weak labels nodule annotations. strategies introduce attention mechanisms within classiﬁer attempt learn improved imaging representations. idea attention deep neural networks inspired human visual attention system. spatial attention allows humans selectively process visual information prioritization area within visual ﬁeld signiﬁcantly improve recognition detection performance especially images cluttered background following principle neural networks trained focus speciﬁc portions input signal appear strongly related task hand. ﬁrst approach uses soft attention mechanism. convolutional network used learn imaging features minimise classiﬁcation error saliency maps inferred weakly-supervised fashion part training process. saliency highlights parts image likely associated class predicted network. several methodologies recently proposed literature proved generate suﬃciently accurate maps propose hybrid learning approach using loss function that addition penalising classiﬁcation error also penalises discrepancy measure network’s implied position nodule represented saliency extracted training real position nodule known. large loss indicates network’s current representation accurately describe nodule’s visual patterns provides additional mechanism self-improvement back-propagation. resulting architecture convolutional neural network attention feedback ensures image representation learned network optimises classiﬁcation localisation performance. second approach implements hard attention mechanism radiograph processed ﬁnite number consecutive steps. contrast previous method step portion image used input. present extention reinforcement learning approach recurrent attention model every time step algorithm samples next location attend probability distribution calculated based information acquired model previous steps. information cumulated random path across image eventually used classify image. classiﬁcation score used reward signal update probability distribution controlling sequence image locations visited attention eventually given relevant parts images lungs. proposed architecture ramaf assigns higher rewards every time path visited algorithm training time overlaps correct location nodule available. reward strategy forces model review image regions likely contain nodules areas higher speed resulting faster convergence rate increased classiﬁcation performance. article structured follows. section introduce dataset used experiments explain chest radiographs automatically labelled using natural language processing system. conaf ramaf algorithms presented section respectively. performance assessed compared number alternative architectures either weak labels annotated images. section describe experimental results indicate leveraging relatively small portion manually fig. three examples successfully detected lung nodules chest radiographs using proposed conaf model. ﬁrst contains original x-ray images second contains heatmaps generated conaf along ground truth annotation bounding boxes drawn white radiologists. heatmaps indicate predicted position nodule conaf; colors indicate regions high probabilities blue colors indicate regions probability. study obtained dataset consisting chest x-rays exams collected historical archives guy’s thomas foundation trust london period january march exam free-text radiologist report extracted ris. subset exams also extracted corresponding radiographs form dicom ﬁles pacs. sensitive information patient’s name date birth address removed dicom headers reports. ethics committee radiological reports used determinate whether chest radiograph deemed contain evidence suspected lung lesions label generated image. study used three mutually exclusive labels normal i.e. exams presenting radiological abnormalities; nodules i.e. exams reported presenting least nodule others i.e. exams normal contain pulmonary nodule mass. parenchymal lesions represent broad spectrum disease. common appearances small rounded opacity within lung parenchyma. however x-ray lung lesions solid semi-solid groundglass wellill-deﬁned single multiple occur anywhere lung parenchyma meaning x-ray projected behind ribs mediastinum diaphragm heart. according accepted nomenclature nodule labelling task automated using extension system originally developed detection clinical ﬁndings radiological reports overview system along validation study results found supplementary material. paediatric exams removed dataset resulting total exams labels images available. system identiﬁed normal exams exams containing least nodule exams radiological abnormalities nodules. amongst examples containing least lung lesion manually annotated experienced radiologist. bounding drawn around suspected location within image. examples manually annotated nodules seen fig. size nodule measured taking longest side bounding millimeters therefore provides upper bound real nodule’s size. fig. shows distribution nodule sizes. noticed majority nodules smaller millimeters many millimeters ﬁnally tiny proportion lung masses greater millimeters. section propose image classiﬁer based deep convolutional neural networks. detect chest radiographs likely contain nodules. although localisation nodules within image primary interest information extracted trained network. number methodologies proposed inferring saliency maps feature maps learned convolutional network without need provide network annotated images. proposed architecture exploits saliency maps introduce soft attention mechanism. radiographs containing annotations saliency maps compared ground truth derive localisation error. although additional error term valued subset training images provides feedback likely inferred position nodule given time training process. fig. illustration conaf model. classiﬁer localizer receive input output feature extraction cnn. localization loss function classiﬁcation loss function linearly combined form hybrid loss function proposed architecture presented fig. relies upon three building blocks convolutional neural network feature extraction separate components used classiﬁcation localisation. feature extraction component used similar architecture found reliable literature well studies. feature extraction block takes input consists sequence convolutional layers maxpooling layers. last layer contains high-level feature representation image used input classiﬁcation localisation components. predicted class. furthermore images contribute towards second performing convolutions. output passed sigmoid function produce scoremap used infer position nodules within image. values away zero closer indicate corresponding pixels likely contain nodule. rationale consists comparing scoremap associated ground-truth binary mask order quantify current localization error. adjustment step required stage since manually delineated masks rectangular squared shape whilst true nodules generally round-shaped. since manually annotated nodules typically centered middle bounding apply gaussian smoothing operator trace elliptical area high probability middle fig. illustration ramaf model. green colour frame represents bounding annotation colour frames represent proposed glimpses time step time step core samples location attend next. time steps model samples location belongs bounding annotation receives extra reward. θθθl denotes network’s weights images containing bounding box. given lung lesions cover small part image expect minority pixels contribute error. loss term places importance high-value section propose extension original model call recurrent attention model annotation feedback original learns follow optimal path within image whereby speciﬁc portions image glimpses sequentially processes time. subsequent glimpse incrementally contributes overall classiﬁcation error. follows represents glimpse seen model time overall sequence glimpses seen model image deﬁned git}. formulation glimpse consists image patches diﬀerent size sharing central location capturing diﬀerent context around region. largest patch scaled match size smallest available reward signal generated depending whether image correctly classiﬁed. ramaf addition classiﬁcation reward additional reward signal introduced take account number central coordinates fig. provides overview model. glimpse layer encoder introduced compress information contained glimpse extract representation robust noise. encoder implemented diﬀers used originally application complex visual environment featuring high variability luminance object complexity. large variability patient’s anatomy well technical variability since x-ray scans dataset acquired diﬀerent x-ray devices. stage glimpse passed stack convolutional layers followed maxpooling operations. convolutional layer stack pre-trained oﬄine using convolutional auto-encoders max-pooling ﬁne-tuned part end-to-end training ramaf model. training concatenated location representation mation summary formed hidden representation recurrent neural network previous hidden representation passed input current passes fully connected layer resulting vector locator decides position next glimpse sampling i.e. normal distribution mean diagonal covariance matrix ﬁrst step initiate algorithm center image always ﬁxed covariance matrix consisting components. first image classiﬁcation correct otherwise second. glimpse’s central pixel time step lies within annotation bounding otherwise latter term represents spatial reward signal needs minimised. model trained learn policy maximizes conditional probability true label given partial interaction radiographs. optimize cross entropy loss train network correctly classify radiographs. also train part model proposes observation locations using reinforce algorithm. details found supplementary material. section provide additional implementation details. conaf loss function fully speciﬁed using parameters yielded optimal performance. training done using back-propagation adadelta mini-batches. within minibatch images weak labels selected probability otherwise images bounding boxes selected. approach followed avoid overﬁtting localization part model since number images signiﬁcantly less compared images weak labels. parameter controlling gaussian smoothing gives suﬃcient importance values centre bounding nodule likely located. resolution path pixels resolution size pixels. convolutional layers within encoder consisted feature maps ﬁlters dimension followed max-pooling layers non-overlapping receptive ﬁeld dimension training model back-propagation time optimization algorithm called adam mini-batches size learning rate number annotated images within mini-batch varied weights core neural network architectures tested comparison algorithms. assess degree localisation performance achieved using weak labels only used stateof-the-art weakly-supervised methods performing classiﬁcation localisation tasks. ﬁrst method uses convolutional adaptation layers feature extraction layer order scoremap class. second method uses global average pooling layer last layer feature maps encourage network identify complete extent object; passes output features inputs fully connected layer order compute desired output. saliency maps obtained projecting back weights fully connected layer last layer convolutional feature maps. furthermore considered state-of-the-art fully supervised methods proposed object detection. algorithm proposed also known overfeat able perform classiﬁcation localisation detection. algorithm scans image sliding window fashion several scales training tasks classiﬁcation bounding prediction performed simultaneously. ﬁnal stage predicted bounding boxes merged according proposed scheme. module used encode image high-level feature representation passed input lstm module learns decode representation predicted bounding boxes. comparison state-of-the-art methods classiﬁcation localisation conducted separate experiments. ﬁrst experiment tested capacity proposed models diﬀerentiate chest radiographs normal radiological appearance chest radiographs nodules second experiment tested whether models able diﬀerentiate chest radiographs nodules chest radiographs including normals radiological ﬁndings split dataset training validation test sets performance metrics reported image classiﬁcation task report sensitivity speciﬁcity average accuracy negative predicted value measure precision observe conaf outperforms others methods terms average accuracy f-measure sensitivity highest precision detection images nodules achieved method noted that application achieving highest possible sensitivity rate critical main minimise percentage nodules missed algorithm. accuracy conaf respect nodule size illustrated fig. supplementary material. expected accuracy conaf increases linearly nodule size. also noticed ramaf achieves better performance compared simpler model trained without bounding boxes. models general comparable competing architectures terms overall performance. results also demonstrate deep learning algorithms trained suﬃciently large dataset robust moderate level label noise previously reported literature estimation localisation performance test ﬁrst used thresholding technique segment localisation saliency maps generated conaf. experiment tried diﬀerent threshold values ranging increments pixels saliency chosen threshold ﬁltered clusters spatially contiguous pixels values threshold formed. clusters considered nodule candidates bounding boxes cover clusters automatically drawn predicted bounding boxes greatest overlap ground truth considered true positives remaining bounding boxes considered false positives. number true positive false negative bounding boxes used calculate precision sensitivity measures. table summarizes localization results. table shows that terms sensitivity average overlap conaf achieves superior performance overfeat achieves best precision. furthermore fig. provides examples comparing localisation results obtained conaf fig. illustrates relationship fig. examples nodule localisation performance using diﬀerent neural networks. white boxes manually drawn radiologists. boxes found likely contain nodule architecture described zhou conaf. ramaf display trajectories followed algorithms taking classiﬁcation decision path starts point indicated square ends point indicated triangle. precise localization metrics obtained using ram/ramaf. instead measure percentage regions contained within bounding boxes overlap least glimpses taken models. experiments ramaf attends overall bounding boxes test model attends result indicates ramaf leverages additional spatial information accessible subset images. additional noticeable advantages also observed terms convergence rate. fig. supplementary material shows ramaf learns approximately times faster compared ram. paper explores diﬀerent computer vision algorithms detect x-ray images likely contain lung nodules. number approaches weakly supervised learning fully supervised object detection compared purpose image classiﬁcation nodule localization. proposed novel methods relying principle large quantities weakly labelled images combined small subset manually annotated images order boost classiﬁcation performance. conaf localisation loss function derived inferred saliency maps combined traditional classiﬁcation error improve overall performance. implements supervised attention feedback mechanism since error signal localization component used reﬁne saliency maps generated convolutional layers weakly supervised way. conaf interpreted type feedback neural network recurrent neural networks iteratively high level features back reﬁne level features focus salient image regions. feedback neural networks without recurrent connections used recently human pose estimation self-correcting model progressively changes initial prediction iteratively feeding back error predictions. stacked hourglass network proposed introduce bottom-up top-down inference across multiple scales. domains also shown network feedbacks improve task locating human models implemening soft attention mechanisms typically learn processing entire input images using dcnns. learning models focus certain parts input image directly associated demands task. idea learn features weighted average image locations locations weighted based saliency maps produced highest convolutional layers network. intuition behind approaches saliency maps generated last convolutional layer dcnns trained weakly labelled images highlight regions image important classiﬁcation. soft attention recently used learning direct mapping radiological reports corresponding histopathology specimens second model proposed here ramaf uses recurrent attention model spatial feedback reward explore image building previous work chest radiohgraphs conaf outperforms state-of-the-art methods ramaf provides improvement original approach annotated images available. ramaf instance hard attention mechanisms whereby learning evolves iteratively focusing selectively chosen regions within image. early attempts introduce hard attention local information extracted images sequentially integrated variety ways e.g. boltzmann machines geometric means intermediate predictions recent proposals focused stochastic exploration sequence image regions. number computational operations involved models independent size input image contrast soft attention models whose computational complexity directly proportional number image pixels. allows hard attention models scale large input images stochastic selection image regions yield diﬀerentiable solutions hinders applicability back-propagation. instead models typically trained using reinforcement learning methods related studies assessed performance systems lung nodule detection using datasets sample sizes hundreds patients recently access large amount historical exams allowed studies scaled several thousand examples chest x-rays images spanning disease classes used learning automatically detect disease annotate context. recently database chest radiographs made publicly available spanning eight disease classes", "year": 2017}