{"title": "Combining Evaluation Metrics via the Unanimous Improvement Ratio and its  Application to Clustering Tasks", "tag": ["cs.AI", "cs.LG"], "abstract": "Many Artificial Intelligence tasks cannot be evaluated with a single quality criterion and some sort of weighted combination is needed to provide system rankings. A problem of weighted combination measures is that slight changes in the relative weights may produce substantial changes in the system rankings. This paper introduces the Unanimous Improvement Ratio (UIR), a measure that complements standard metric combination criteria (such as van Rijsbergen's F-measure) and indicates how robust the measured differences are to changes in the relative weights of the individual metrics. UIR is meant to elucidate whether a perceived difference between two systems is an artifact of how individual metrics are weighted.  Besides discussing the theoretical foundations of UIR, this paper presents empirical results that confirm the validity and usefulness of the metric for the Text Clustering problem, where there is a tradeoff between precision and recall based metrics and results are particularly sensitive to the weighting scheme used to combine them. Remarkably, our experiments show that UIR can be used as a predictor of how well differences between systems measured on a given test bed will also hold in a different test bed.", "text": "many artiﬁcial intelligence tasks cannot evaluated single quality criterion sort weighted combination needed provide system rankings. problem weighted combination measures slight changes relative weights produce substantial changes system rankings. paper introduces unanimous improvement ratio measure complements standard metric combination criteria indicates robust measured diﬀerences changes relative weights individual metrics. meant elucidate whether perceived diﬀerence systems artifact individual metrics weighted. besides discussing theoretical foundations paper presents empirical results conﬁrm validity usefulness metric text clustering problem tradeoﬀ precision recall based metrics results particularly sensitive weighting scheme used combine them. remarkably experiments show used predictor well diﬀerences systems measured given test also hold diﬀerent test bed. many artiﬁcial intelligence tasks cannot evaluated single quality criterion sort weighted combination needed provide system rankings. many problems instance require considering precision recall compare systems’ performance. perhaps common combining function f-measure includes parameter sets relative weight metrics; metrics relative weight computes harmonic mean. problem weighted combination measures relative weights established intuitively given task time slight change relative weights produce substantial changes system rankings. reason behavior overall improvement often derives improvement individual metrics expense decrement other. instance system improves system precision loss recall better viceversa depending relative weight precision recall situation common might expect. table shows evaluation results diﬀerent tasks extracted conference proceedings combined using f-measure. paper considered three evaluation results maximizes presented best result paper baseline alternative method also considered. note cases ranked system improves baseline according f-measure cost decreasing metrics. instance case paper word alignment average grows decreases paper sentiment analysis increases four points decreases points. reasonable assume contrastive system indeed improving baseline? evaluation results alternative approach also controversial cases alternative approach improves best system according metric improved according other. therefore depending relative metric weighting alternative approach could considered better worse best scored system. conclusion parameter crucial comparing real systems. practice however authors standard agnostic choice requires justiﬁcation. thus without notion much perceived diﬀerence systems depends relative weights metrics interpretation results combination scheme misleading. goal therefore estimating extent perceived diﬀerence using metric combination scheme robust changes relative weights assigned individual metric. paper propose novel measure unanimity improvement ratio relies simple observation system improves system according individual metrics better weighting scheme. given test collection test cases test cases improvements unanimous robust perceived diﬀerence words well statistical signiﬁcance tests provide information robustness evaluation across test cases meant provide information robustness evaluation across variations relative metric weightings supported high unanimous improvement ratio much likely hold diﬀerent test collection. perhaps relevant practical application predictor much result replicable across test collections. although work presented paper applies research areas focus clustering task relevant examples clustering tasks specially sensitive metric relative weightings. research goals investigate empirically whether clustering evaluation biased precision recall relative weights recent test collections focused text clustering problem introduce measure quantiﬁes robustness evaluation results across metric combining criteria leads propose measure derived conjoint measurement theory illustrate application comparing systems context shared task measure serves predictor consistency evaluation results across diﬀerent test collections. frequent combining evaluation metrics f-measure originally proposed evaluation information retrieval systems expanded many tasks. given metrics rijsbergen’s f-measure combines single measure eﬃciency follows assumes value particular evaluation scenario. parameter represents relative weight metrics. particular metrics correlated. instance figure shows precision recall levels obtained conll- shared task evaluating semantic role labeling systems except system every substantial improvement precision involves also increase recall. case relative metric weighting substantially modify system ranking. cases metrics completely correlated decreasing marginal effectiveness property ensures certain robustness across values. satisﬁes property states large decrease metric cannot compensated large increase metric. therefore systems precision recall obtain f-values value. discussed detail section however show section cases decreasing marginal another combining metrics consists evaluating system point metric equals method applicable system represented trade-oﬀ metrics instance precision/recall curve. method relies idea increasing metrics implies necessarily overall quality increase. instance assumes obtaining precision recall point better obtaining precision recall point actually break-even point assumes relevance metrics. considers precision/recall point system distributes eﬀorts equitably metrics. indeed could change relative relevance metrics computing break-even point. figure illustrates idea. continuous curve represents trade-oﬀ precision recall system straight diagonal represents points metrics return score. quality system corresponds therefore intersection diagonal precision/recall curve. hand discontinuous curve represents another system achieves increase precision recall levels cost decreasing precision high recall levels. according break-even points second system superior ﬁrst one. computes average precision across number recall levels. another example receiver operating characteristic function used evaluate binary classiﬁers computes probability positive sample receives conﬁdence score higher negative sample independently threshold used classify samples. functions related area exists precision/recall curve high recall regions relative relevance computing area. again could change measures order assign diﬀerent weights high recall levels. indeed weighted area curve proposed. something similar would happen average across diﬀerent values. note measures applied certain kinds problem binary classiﬁcation document retrieval system output seen ranking diﬀerent cutoﬀ points ranking give diﬀerent precision/recall values. directly applicable particular clustering problem focus work here. section present metric combination experiments speciﬁc clustering task. results corroborate importance quantifying robustness systems across diﬀerent weighting schemes. clustering applications wide range artiﬁcial intelligence problems. particular context textual information access clustering algorithms employed information retrieval document summarization topic tracking opinion mining etc. scenarios clustering distributions produced systems usually evaluated according similarity manually produced gold standard wide metrics measure similarity rely quality dimensions extent items cluster also belong group gold standard; extent items diﬀerent clusters also belong diﬀerent groups gold standard. wide extrinsic metrics proposed entropy class entropy purity inverse purity precision recall bcubed metrics metrics based counting pairs etc. weps campaigns focused task disambiguating person names search results. input systems ranked list pages retrieved search engine using person name query challenge correctly estimate number diﬀerent people sharing name search results group documents referring individual. every person name weps datasets provide around pages search results using quoted person name query. order provide diﬀerent ambiguity scenarios person names sampled census wikipedia listings program committee members computer science conferences. systems evaluated comparing output gold standard manual grouping documents produced human judges rounds note single document assigned cluster amazon search results list instance refer books written diﬀerent authors name. weps task therefore overlapping clustering problem general case clustering items restricted belong single cluster. weps datasets oﬃcial evaluation metrics reﬂect fact. experiments focused evaluation results obtained weps- weps- evaluation campaigns. weps- corpus also includes data test used trial purposes follows similar annotation guidelines although number document ambiguous name variable. refer corpora weps-a weps-b weps- clustering task involves three main aspects determine system’s output quality. ﬁrst method used measuring similarity documents; second clustering algorithm third aspect considered usually consists couple related variables ﬁxed similarity threshold pages considered related stopping criterion determines clustering process stops consequently number clusters produced system. figure shows purity inverse purity values change diﬀerent clustering stopping points systems evaluated weps-b corpus purity focuses frequency common category cluster clusters evaluated categories weps datasets selected experiments address relevant well-deﬁned clustering task; widespread weps datasets used hundreds experiments since ﬁrst weps evaluation runs submitted participants weps- weps- available essential experiment diﬀerent evaluation measures. weps datasets freely available http//nlp.uned.es/weps. purity penalizes noise cluster reward grouping items category together; simply make cluster item reach trivially maximum purity value. inverse purity focuses cluster maximum recall category. inverse purity deﬁned inverse purity rewards grouping items together penalize mixing items diﬀerent categories; reach maximum value inverse purity making single cluster items. change stopping point implies increase purity cost decrease inverse purity viceversa. therefore possible value rewards diﬀerent stopping points. phenomenon produces high dependency clustering evaluation results metric combining function. determining appropriate value given scenario trivial. instance user’s point view weps task easier discard irrelevant documents good cluster check additional relevant documents clusters therefore seems inverse purity priority purity i.e. value point view company providing people search service however situation quite diﬀerent priority high precision mixing proﬁles criminal doctor result company sued. perspective receive high value. weps campaign decided agnostic neutral value. table shows resulting system ranking weps-b according ranking includes baseline systems consists grouping document separate cluster consists grouping documents single cluster. maximizes purity maximizes inverse purity. obtain high f-measure depending value. table shows outperforms also considerable number systems. reason result that weps-b test many singleton clusters means default strategy making cluster document achieve maximal purity also acceptable inverse purity however ﬁxed goes bottom ranking outperformed systems including baseline note outperforming trivial baseline system crucial optimize systems given optimization cycle could otherwise lead baseline approach like drawback informative crucially sensitive variations words performance robust changes metric combination criterion. remarkably scoring system best values. primary motivation article quantify robustness across values order complement information given traditional system ranking. average size clusters gold standard change test another. aﬀects purity inverse purity trade-oﬀ clustering system obtain diﬀerent balance metrics diﬀerent corpora; produce contradictory evaluation results comparing systems across diﬀerent corpora even value. instance weps-b test substantially outperforms weps- data however outperforms reason singletons less common weps-. words comparison depends value particular distribution reference cluster sizes test bed. primary motivation article quantify robustness across values order complement information given traditional system rankings. introduce section unanimous improvement ratio. problem combining evaluation metrics closely related theory conjoint measurement rijsbergen argued possible determine empirically metric combining function adequate context information retrieval evaluation. however starting measurement theory principles rijsbergen described properties metric combining function satisfy. includes independence axiom monotonicity property derives. monotonicity property states quality system surpasses equals another according metrics necessarily equal better other. words system theoretical properties unanimous improvement described depth section important property unanimous improvement relational structure depend relative metric weightings satisfying independence axiom. words claim that system improvement according metric combining function depend whatsoever metric weightings quality decrease according individual metric. theoretical justiﬁcation assertion developed section test cases samples improves samples improves also samples biased improvements refer sets ta≥∀b tb≥∀a ta∀b respectively. unanimous improvement ratio deﬁned according three formal restrictions illustration computed consider experiment outcome table systems compared terms precision recall test cases. test case instance unanimous improvement better terms precision recall table value necessary meant provide ranking complement ranking provided f-measure indicating robust results changes section illustrates integrated insights provided system ranking. second limitation consider improvement ranges; therefore less sensitive f-measure. empirical results however show sensitive enough discriminate robust improvements versus metric-biased improvements; section make empirical comparison non-parametric deﬁnition parametric version results make non-parametric deﬁnition preferable. section discuss theoretical foundations unanimous improvement ratio framework conjoint measurement theory. proceed describe formal properties implications point view evaluation methodology. readers interested solely practical implications using proceed directly section problem combining evaluation metrics closely related conjoint measurement theory independently discovered economist debreu mathematical psychologist duncan luce statistician john tukey theory measurement deﬁnes necessary conditions state homomorphism empirical relational structure numeric relational structure case conjoint measurement theory relational structure factored ordered substructures context numerical structures given evaluation metric scores however empirical quality ordering clustering systems. diﬀerent human assessors could assign relevance purity inverse purity viceversa. nevertheless conjoint measurement theory provide mechanisms state kind numerical structures produce homomorphism assuming empirical structure satisﬁes certain axioms. rijsbergen used idea analyze problem combining evaluation metrics. axioms shape additive conjoint structure. quality system according evaluation metrics axioms f-measure proposed rijsbergen arithmetic mean satisfy axioms. according restrictions indeed unlimited acceptable combining functions evaluation metrics deﬁned. relational structure however satisﬁes another property satisﬁed functions arithmetic mean. property decreasing marginal eﬀectiveness. basic idea increasing unit metric decreasing unit metric improve overall quality imply great loss metric compensated great increase other. deﬁned according this high values metrics required obtain high overall improvement. makes measures observing property robust arbitrary metric weightings. posed rijsbergen metric combining functions transitivity independence thomsen condition restricted solvability essential components decreasing marginal eﬀectiveness; exception connectedness property. given comparability derived unanimous improvement possible system pairs neither could satisfy connectedness considering biased improvements represent equivalent system pairs case transitivity would satisﬁed. instance table according table fact f-measure satisﬁes monotonicity axiom unanimous improvement grounded. property essential purpose checking robustness system improvements across values. crucially unanimous improvement function satisﬁes property. precisely unanimous improvement relational structure that satisfying monotonicity contradict additive conjoint structure case could deﬁne additive conjoint structure combined measure additive conjoint structure would contradict therefore would compatible conclusion predicate true unanimous improvement interesting corollary derived analysis. unanimous improvement compatible relational structure formally conclude measurement system improvements without dependence metric weighting schemes derive weak order corollary practical implications possible establish system ranking independent metric weighting schemes. natural proceed therefore unanimous improvement addition standard f-measure provides additional information robustness system improvements across values. section perform number empirical studies weps corpora order behaves practice. first focus number empirical results show rewards robustness across values information complementary information provided second examine extent correlated. figure shows three examples system comparisons weps-b corpus using metrics purity inverse purity. curve represents value obtained system according diﬀerent values. system compared three graphs. cases similar quality increase according fα=.; however ranges depending robust diﬀerence changes highest diﬀerence system pair systems swap values value. smallest value better values worse larger. comparison illustrates captures similar increments ones less dependent relative weighting scheme precision recall. consider two-system combinations weps-b corpus dividing sets system pairs increases values pairs relative system’s performance swaps value; i.e. increases values decreases rest. would expect average increase larger system pairs beats every value. surprisingly true table shows average increments fα=. sets. behaves expected average value substantially larger diﬀerent lead contradictory results average relative increase fα=. however similar sets conclusion certain fα=. improvement range anything whether purity inverse purity simultaneously improved not. words matter large measured improvement still extremely dependent weighting individual metrics measurement. conclusion corroborated considering independently metrics according statistical signiﬁcance improvements independent metrics distinguish three cases fα=. average increase even larger opposite improvements concordant improvements according results would seem fα=. rewards individual metric improvements obtained cost decreases metric. hand sharply diﬀerent behavior strongly rewarding concordant improvements consistent diﬀerence systems values rewards larger improvement ranges. illustrate behavior considering three sample system pairs taken weps- test bed. another interesting ﬁnding that metrics improved metric weakest improvement determines behavior uir. figure illustrates relationship system pairs largest improvement; pearson correlation graph words individual metrics improve sensitive weakest improvement. point marked case figure corresponds comparison systems exists substantial diﬀerence systems according fα=.. however value i.e. improvement robust changes according uir. visual explanation results seen figure shows purity inverse purity results systems every test case. test cases important advantage purity cost slight consistent loss inverse purity. given fα=. compares purity inverse purity ranges states exists important statistically signiﬁcant improvement however slight consistent decrease inverse purity aﬀects decreases case opposite example small diﬀerence systems according fα=. diﬀerences purity inverse purity also small. however gives small consistent improvements purity inverse purity unanimous improvements. therefore considers exists robust overall improvement case. mentioned earlier parallelism statistical signiﬁcance tests typically used information retrieval estimate probability observed diﬀerence systems obtained chance i.e. diﬀerence artifact test collection rather true diﬀerence systems. computing statistical signiﬁcance useful establish threshold allows binary decision; instance result often said statistically signiﬁcant signiﬁcant otherwise. choosing level signiﬁcance arbitrary nevertheless helps reporting summarizing signiﬁcance tests. stricter thresholds increase conﬁdence test increased risk failing detect signiﬁcant result. situation applies would like establish threshold decides whether observed diﬀerence reasonably robust changes threshold? could restrictive decide instance improvement never satisﬁed practice therefore test would informative. hand permissive threshold satisﬁed system pairs again informative. question whether exists threshold values obtaining threshold guarantees improvement robust time strong satisﬁed practice. given two-system combinations surpasses certain candidate figure shows conditions every threshold range threshold accepts around system pairs ratio signiﬁcant opposite improvements high ratio signiﬁcant concordant improvements. threshold half robust cases increases values order answer question applied results weps- evaluation campaign campaign best runs system ranked according bcubed precision recall metrics combined fα=.. addition participant systems three baseline approaches included ranking words sref represents system replaced order robustly improve results across diﬀerent values. finally last column displays system reference note adds insights evaluation process. highlight although three top-scoring systems similar performance terms consistently best system according reference systems contrast reference only reference only. therefore together strongly point towards best system alone able discern three top-scoring systems. systems according improvement robust according uir. note signal near-baseline behaviors participant systems value receive large depending nature test collection average cluster large small systems tend cluster everything nothing artiﬁcially rewarded. opinion substantial improvement using alone. common issue evaluating systems deal natural language results diﬀerent test collections often contradictory. particular case text clustering factor contributes problem average size clusters vary across diﬀerent test beds variability modiﬁes optimal balance precision recall. system tends favor precision creating small clusters good results dataset small average cluster size worse results test collection larger average cluster size. therefore apply combine single metrics reach contradictory results diﬀerent test beds. depend metric weighting criteria hypothesis high value ensures robustness evaluation results across test beds. following experiment designed verify hypothesis. implemented four diﬀerent systems weps problem based agglomerative clustering algorithm used best systems weps-. system employs certain cluster linkage technique certain feature extraction criterion system experimented stopping criteria. therefore used system variants overall. evaluated systems weps-a weps-b weps- corpora. ﬁrst observation that given system pairs fα=. gives consistent results three test beds cases. system pairs best system diﬀerent depending test collection. robust evaluation criterion predict given single test collection whether results still hold collections. system pair reference corpus compute improvement system respect according uir. take system pairs improves certain threshold uirc results systems test-bed results system test-bed trace precision/recall curve predictors compare results. figures show precision/recall values ﬁgure displays results reference test-beds wepsaweps-b weps-. opinion remarkable result diﬀerences better indicators reliability measured diﬀerence amount measured diﬀerence. therefore useful know stable results changes also changes test collection i.e. indicator reliable perceived diﬀerence note explicitly tested dependency results number test cases reference collection. however working collection less test cases unlikely practical terms usability granted test collections least respect number test cases. probabilities estimated frequentist manner. said main drawback unanimous improvement threevalued function consider metric ranges; inherits drawback. consequence less sensitive combining schemes measure. order solve drawback could estimate parametrically. however results section seem indicate best option. order compare eﬀectiveness parametric versus original repeated experiment described section adding uirparam precision/recall curves figures squares ﬁgures represent results parametric version uir. note behavior lies somewhere nonparametric levels recall behaves like original uir; intermediate levels general worse original deﬁnition better recall high-end overlaps results probably fact parametric estimation considers ranges becomes sensitive unreliability high improvements based theory measurement established relevant theoretical results fundamental monotonic relational structure contradict additive conjoint structure unique relationship transitive. implies possible establish ranking systems without assuming arbitrary relative metric weighting. transitive relationship however necessary ensure robustness speciﬁc pairwise system comparisons. based theoretical analysis introduced unanimous improvement ratio estimates robustness measured system improvements across potential metric combining schemes. measure complementary metric combination scheme works similarly statistical relevance test indicating perceived diﬀerence systems reliable biased particular weighting scheme used evaluate overall performance systems. empirical results text clustering task particularly sensitive problem conﬁrm indeed useful analysis tool pairwise system comparisons similar increments captures ones less dependent relative weighting scheme precision recall; unlike rewards system improvements corroborated statistical signiﬁcance tests single measure; practice high tends imply large increase large increase imply high uir; words large increase completely biased weighting scheme therefore essential information looking results evaluation campaign proved useful discern best system among systems similar performance according penalize trivial baseline strategies systems baseline-like behavior. perhaps relevant result side eﬀect proposed measure deﬁned good estimator robust result changes test collection. words given measured increase test collection high value makes likely increase also observed test collections. remarkably estimates cross-collection robustness increases much better absolute value increase. limitation present study tested text clustering problem. usefulness clustering problems already makes useful analysis tool potential goes well beyond particular problem. natural language problems general many problems artiﬁcial intelligence evaluated terms many individual measures trivial combine. powerful tool many scenarios.", "year": 2014}