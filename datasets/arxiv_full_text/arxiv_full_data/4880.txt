{"title": "Can Evolutionary Sampling Improve Bagged Ensembles?", "tag": ["cs.LG", "cs.AI"], "abstract": "Perturb and Combine (P&C) group of methods generate multiple versions of the predictor by perturbing the training set or construction and then combining them into a single predictor (Breiman, 1996b). The motive is to improve the accuracy in unstable classification and regression methods. One of the most well known method in this group is Bagging. Arcing or Adaptive Resampling and Combining methods like AdaBoost are smarter variants of P&C methods. In this extended abstract, we lay the groundwork for a new family of methods under the P&C umbrella, known as Evolutionary Sampling (ES). We employ Evolutionary algorithms to suggest smarter sampling in both the feature space (sub-spaces) as well as training samples. We discuss multiple fitness functions to assess ensembles and empirically compare our performance against randomized sampling of training data and feature sub-spaces.", "text": "perturb combine group methods generate multiple versions predictor perturbing training construction combining single predictor motive improve accuracy unstable classiﬁcation regression methods. well known method group bagging. arcing adaptive resampling combining methods like adaboost smarter variants methods. extended abstract groundwork family methods umbrella known evolutionary sampling employ evolutionary algorithms suggest smarter sampling feature space well training samples. discuss multiple ﬁtness functions assess ensembles empirically compare performance randomized sampling training data feature subspaces. bagging various variants widely popular studied extensively last decades notable work understanding theoretical underpinning bootstrap aggregating makes powerful method adapsampled replacement probability tive resampling combining techniques modify probability training example sampled based heuristics also developed widely used random subspace methods also known attribute bagging refer creating ensembles predictors trained randomly selected subsets total features predictors error based resampling algorithms zero detrain-set error signed bagged ensembles minimal intersection diversity uncorrelated errors importance sampling etc. areas studied improve bagged ensembles. either multiple answers question answer changes dataset. instead ﬁguring precisely sampling combination training sets make bagged ensemble better deﬁnition better allow bootstrapped training sets evolve order align deﬁnition. generate multiple sampled candidate training sets ﬁnal ensemble compete mutate mate optimal sampling combination. evolutionary computation used selection different predictors part ensemble also selection suitable machine learning pipeline classiﬁcation problem parameter selection crossover population size per-individual mutation rate per-individual crossover rate generations ensemble size individual table.results comparing performance ﬁrst individual hall fame unseen data. values averages runs. statistical tests p-values paired t-tests test mean squared error compared hoi. proportion runs lower unseen data. across generations considered optimal solution. evolutionary sampling followed standard genetic algorithm. initially population multiple ensembles generated randomly sampling training data multiple times. ensemble generation evaluated based ﬁtness function. individuals selected next generation. this crossover applied ﬁxed percentage individuals wherein individuals swap predictors. post this ﬁxed percentage individuals unaffected crossover undergo random mutation. randomly selected member datasets selected individual rows/features deleted replaced inserted equal probability. feature subspacing features subject perturbation whereas sub-sampling rows perturbed. we’ve used python package deap implement parameters shown table suggested before instead understanding makes bagged ensemble better rely definition better evolve ensemble same. ﬁtness function guides sampling combination different sampled datasets. propose three ﬁtness functions analyse performance. fempo fitness model private bag. takes predictor part candidate ensemble measures performance samples left it’s training final ﬁtness ensemble mean model’s rmse. fegt fitness ensemble global test. start algorithm training data aside. ensemble’s prediction based average prediction it’s member predictors. rmse calculated aside global test. conduct experiments variants sampling subsampling sub-spacing. sub-sampling works sampling training examples whereas sub-spacing works generating multiple feature sets. conduct experiments benchmark datasets compare mean squared error ﬁrst individual ﬁrst generation hall fame generations. assume ﬁrst individual ﬁrst generation representative ensemble randomly samples rows features like traditional bagging. analyse whether able evolve better ensembles starting random specimens. uniformly unpruned decision tree regressor depth arbitrarily win-ratio would suggest performance ensemble undergoing better random counterpart half times. mean standard deviation also good metric compare random instantiation. null hypothesis paired t-test suggests average mean squared error methods same. p-value smaller threshold reject null hypothesis equal averages. better random counterparts. though percentages almost half many cases could algorithm initialized optimal combination sampling. fegt shows improvement abalone sub-spacing fempo fegt signiﬁcantly better random sub-spacing. deﬁnitely helped improving accuracy model. note narrow exploration space case feature subspacing compared sub-sampling features play signiﬁcant role deciding model’s behaviour rows data. results suggest possibly useful cases maximum accuracy needs juiced computation issue. it’s evident better robust ﬁtness functions need explored even multi-objective ﬁtness functions better represent generalizability error ensemble. needs explored methods used generate different models smaller segments patches dataset segments suggested along ﬁtness functions take account models ﬁtness used different cohorts dataset? guided sub-spacing using linear base estimators useful high dimensional problems like genomic data selecting features important keeping ﬁnal models interpretable. interesting happens algorithm allowed generations till ﬁtness test error reduces approximately zero. plan experiment different base estimators sampled dataset also explore sub-spacing sub-sampling combined algorithm. reproduction we’ve regoing theme framework github leased encourage researchers contribute project test different ﬁtness functions themselves.", "year": 2016}