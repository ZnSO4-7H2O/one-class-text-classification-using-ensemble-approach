{"title": "Neural Domain Adaptation for Biomedical Question Answering", "tag": ["cs.CL", "cs.AI", "cs.NE"], "abstract": "Factoid question answering (QA) has recently benefited from the development of deep learning (DL) systems. Neural network models outperform traditional approaches in domains where large datasets exist, such as SQuAD (ca. 100,000 questions) for Wikipedia articles. However, these systems have not yet been applied to QA in more specific domains, such as biomedicine, because datasets are generally too small to train a DL system from scratch. For example, the BioASQ dataset for biomedical QA comprises less then 900 factoid (single answer) and list (multiple answers) QA instances. In this work, we adapt a neural QA system trained on a large open-domain dataset (SQuAD, source) to a biomedical dataset (BioASQ, target) by employing various transfer learning techniques. Our network architecture is based on a state-of-the-art QA system, extended with biomedical word embeddings and a novel mechanism to answer list questions. In contrast to existing biomedical QA systems, our system does not rely on domain-specific ontologies, parsers or entity taggers, which are expensive to create. Despite this fact, our systems achieve state-of-the-art results on factoid questions and competitive results on list questions.", "text": "factoid question answering recently beneﬁted development deep learning systems. neural network models outperform traditional approaches domains large datasets exist squad wikipedia articles. however systems applied speciﬁc domains biomedicine datasets generally small train system scratch. example bioasq dataset biomedical comprises less factoid list instances. work adapt neural system trained large open-domain dataset biomedical dataset employing various transfer learning techniques. network architecture based state-of-theart system extended biomedical word embeddings novel mechanism answer list questions. contrast existing biomedical systems system rely domain-speciﬁc ontologies parsers entity taggers expensive create. despite fact systems achieve state-of-the-art results factoid questions competitive results list questions. biomedical domain bioasq challenge provides factoid list questions i.e. questions several answers respectively. work focuses answering questions example drugs included fec- regimen? ﬂuorouracil epirubicin cyclophosphamide. restrict focus extractive i.e. instances correct answers represented spans contexts. contexts relevant documents provided information retrieval system. traditionally pipeline consists namedentity recognition question classiﬁcation answer processing steps methods applied biomedical datasets moderate success creation large-scale open-domain datasets squad recently enabled development neural systems e.g. wang jiang xiong weissenborn leading impressive performance gains traditional systems. however creating large-scale datasets speciﬁc domains biomedical would expensive need domain experts therefore desirable. recent success deep learning based methods open-domain datasets raises question whether capabilities trained models transferable another domain domain adaptation techniques. although domain adaptation studied traditional systems deep learning systems knowledge applied end-to-end neural systems. main adaptation techniques transfer knowledge trained state-of-the-art neural system biomedical domain using much smaller bioasq dataset. order answer list questions addition factoid questions extend fastqa novel answering mechanism. evaluate various transfer learning techniques comprehensively. factoid questions show mere ﬁne-tuning reaches state-of-the-art results improved forgetting cost regularization list questions results competitive existing systems. manual analysis subset factoid questions suggests results even better automatic evaluation states revealing many incorrect answers fact synonyms gold-standard answer. traditional question answering traditional factoid list question answering pipelines subdivided named-entity recognition question classiﬁcation answer processing components systems also applied biomedical oaqa system besides number domain-independent features incorporate rich amount biomedical resources including domain-speciﬁc parser entity tagger thesaurus retrieve concepts synonyms. logistic regression classiﬁer used question classiﬁcation candidate answer scoring. candidate answer generation oaqa employs different strategies general factoid/list questions choice questions quantity questions. neural question answering neural systems differ traditional approaches algorithm subdivided discrete steps. instead single model trained end-to-end compute answer directly given question context. typical architecture systems summarized follows fastqa fastqa schema reduces complexity architecture removing interaction layer maintaining state-of-the-art performance instead several interaction layers rnns fastqa computes simple wordin-question features token appended embedding vectors encoding layer. chose base work architecture state-of-the-art performance faster training time reduced number parameters. unsupervised domain adaptation unsupervised domain adaptation describes task learning predictor target domain labeled training data exists different source domain. context deep learning common method ﬁrst train autoencoder large unlabeled corpus domains learned input representations input features network trained actual task using labeled source domain dataset another approach learn hidden representations directly target task. example domain-adversarial training optimizes network computes hidden representations help predictions source domain dataset indistinguishable hidden representations unlabeled target domain dataset techniques cannot straightforwardly applied question answering task because require large corpus biomedical question-context pairs supervised domain adaptation contrast unsupervised case supervised domain adaptation assumes access small amount labeled training data target domain. simplest approach supervised domain adaptation neural models pre-train network data source domain ﬁne-tune parameters data target domain. main drawback approach catastrophic forgetting describes phenomenon neural networks tend forget knowledge i.e. performance source domain drops signiﬁcantly trained dataset. even though directly good performance source domain measures catastrophic forgetting serve useful regularizer prevent over-ﬁtting. issue keeping original parameters ﬁxed adding units access previously learned features method adds signiﬁcant amount parameters trained scratch well-suited target domain dataset small. riemer ﬁne-tuning additional forgetting cost term punishes deviations predictions original parameters. another approach loss punishes deviation original parameters. kirkpatrick apply loss selectively parameters important source domain. network architecture based fastqa state-of-the-art neural system. network architecture exchangeable treat black subtle changes input output layer well decoding training procedure. changes described following. figure overview system. figure network architecture system biomedical question answering. core uses extractive neural system black embedding layer modiﬁed order include biomedical word embeddings question type features. output layer adjusted ability answer list questions addition factoid questions. character embeddings used fastqa proposed originally employ -dimensional convolutional neural network computes word embeddings characters word. biomedical wordvec embeddings dimensional vectors trained using wordvec million pubmed abstracts vectors speciﬁc biomedical domain expect help biomedical optional step entity features token embeddings concatenation. entity tags provided dictionary-based entity tagger based umls metathesaurus. entity feature vector -dimensional vector umls semantic types states whether current token part entity type. step applied explicitly finally one-hot encoding question type appended input vectors. embedding vectors input invoke fastqa produce start scores context tokens. denote start start scores conditioned scores predicted start position start index index output layer adapted output layer convert start scores span probabilities. computation probabilities independent question type. interpretation however depends question type factoid questions list answer spans interpreted ranked list answer candidates list questions answers certain probability threshold interpreted answers question. sigmoid function. consequence multiple tokens chosen likely start tokens network expected select single token given start token hence softmax function. finally probability given span answers question end. extension generalizes fastqa output layer multiple answer spans different start positions high probability allowing retrieve multiple answers list questions. decoding given trained model start probabilities obtained running forward pass computing start probability equation starts compute probabilities given start probabilities extract answer spans ranked span. simple post-processing step remove duplicate strings retain highest probability. factoid questions output likely answer spans ranked list answers. list questions learn probability cutoff threshold deﬁnes list answers {|pij span choose threshold optimizes list score respective development set. domain adaptation fine-tuning training procedure consists phases pre-training phase train model squad using token score training objective weissenborn refer resulting parameters base model. ﬁne-tuning phase initialize model parameters base model continue optimization bioasq dataset smaller learning rate. forgetting cost regularization avoid catastrophic forgetting ﬁne-tuning means regularize model optionally additional forgetting cost term proposed riemer deﬁned cross-entropy loss current predictions base model’s predictions. weight regularization also loss term penalizes deviations base model’s parameters. note advanced approach would apply loss selectively weights particularly important source domain ﬁnal loss computed inal loriginal hyperparameters unless otherwise noted. datasets squad squad dataset questions relevant contexts answers sparked research interest development neural systems recently. contexts excerpts wikipedia articles crowd-source workers generated questions-answer pairs. large amount training examples squad lends perfectly source dataset. work focus task phase bioasq challenge systems must answer questions gold-standard snippets. questions either yes/no questions summary questions factoid questions list questions. because employ extractive system restrict study answering factoid list questions extracting answer spans provided contexts. bioasq training dataset contains questions factoid list questions. questions snippets average average tokens long. found around factoid questions around list questions least extractable answer. questions extractable answers answers spans computed simple substring search provided snippets. questions ignored training treated answered incorrectly evaluation. training minimize cross-entropy loss gold standard answer spans. however multiple answer spans refer answer minimize loss span lowest loss. adam optimization squad learning rate starting halved whenever performance drops between checkpoints. ﬁne-tuning phase continue optimization bioasq dataset smaller learning rate starting during phases model regularized variational dropout rate evaluation ofﬁcial evaluation measures bioasq mean reciprocal rank factoid questions score list questions factoid questions list ranked answers entries long. score measured gold standard list elements. measures case-insensitive string matches used check correctness given answer. list synonyms provided gold-standard answers. system’s response matches them answer counts correct. evaluation different ﬁnetuning datasets depending experiment bioasqb contains questions ﬁrst three bioasq challenges bioasqb additionally contains test questions fourth challenge. bioasqb used training dataset ﬁfth bioasq challenge whereas bioasqb used training fourth challenge. datasets small perform fold cross-validation report average performance across folds. larger bioasqb dataset except evaluating ensemble comparing participating systems previous bioasq challenges. models implemented using tensorflow hidden size context bioasq usually comprises multiple snippets processed independently parallel question. answers snippets belonging question merged ranked according individual probabilities. baseline baseline without transfer learning experiment trains model bioasq only. bioasq dataset small dropout rate used because worked best preliminary experiments. observe rather performance expected applying deep learning small dataset. fine-tuning experiments evaluate pure ﬁne-tuning approach base model system trained squad tested bioasq experiment ﬁne-tuned base model bioasqb training set. observe performance increases signiﬁcantly especially list questions. increase expected network trained table comparison various transfer learning techniques. experiment model trained bioasq only. experiment model trained squad tested bioasq. refer base model. experiment base model parameters ﬁne-tuned bioasq training set. experiments evaluate utility domain dependent word vectors features. experiments address problem catastrophic forgetting. experiments conducted bioasqb dataset -fold cross-validation. biomedicallist questions part squad dataset ﬁrst time. overall performance ﬁne-tuned model question types much higher baseline system without transfer learning. features order evaluate impact using biomedical word embeddings repeat experiment without factoid list performance drop percentage points respectively showing biomedical word embeddings help increase performance. experiment append entity features word vector described section even though features provide network domain-speciﬁc knowledge found actually harms performance factoid questions. because entity features active ﬁne-tuning small dataset conjecture performance decrease over-ﬁtting. catastrophic forgetting continue study techniques combat catastrophic forgetting means regularize training ﬁne-tuning. experiment table ﬁne-tune base model half-half mixture bioasq squad questions form joint training yielded signiﬁcant performance gains. experiment regularizes model additional forgetting cost term proposed riemer explained section generally found technique increases performance factoid questions performance boost largest fact forgetting loss decreases performance list questions surprising predictions pushed towards predictions base model poor performance list questions. experiment adds loss penalizes deviations base model’s parameters. found performance decreases increase value shows technique help all. sake completeness report results lowest value yielded signiﬁcant drop performance. ensemble model ensembles common method tweak performance machine learning system. ensembles combine multiple model predictions example averaging order improve generalization prevent over-ﬁtting. evaluate utility ensemble training models bioasqb dataset using -fold crossvalidation. models evaluated test data i.e. data included bioasqb. table performance model ensemble. five models trained bioasqb dataset tested test questions. report average best single model performances well ensemble performance. models best performance across models performance ensemble. observe performance gains percentage points factoid questions less percentage point list questions relative best single model. demonstrates small performance gain consistent literature. ﬁnal results ﬁfth bioasq challenge available time writing compare system best systems last year’s challenge comparison best single model model ensemble trained bioasqb evaluate model batches last year’s challenge using ofﬁcial bioasq evaluation tool. batch contains questions factoid list questions. note results underestimate system’s performance because competing system’s responses manually evaluated humans system’s responses evaluated automatically using string matching potentially incomplete list synonyms. fact qualitative analysis section shows many answers counted incorrect synonyms gold-standard answer. results summarized table compared best systems challenge batches question type categories. system winning four batches factoid questions consider stateof-the-art biomedical factoid question answering especially considering results might higher manual evaluation. results list questions slightly worse still competitive. surprising given network never list question prior ﬁnetuning phase. small test sizes sampling error batch large causing single model outperform model ensemble batches. order better insight quality predictions manually validated predictions factoid questions batch fourth bioasq challenge given best single model total factoid questions gold standard answer span contexts. according ofﬁcial bioasq evaluation questions predicted correctly however identiﬁed rank- answers counted correct synonyms gold standard answer. examples include cmtd disease instead charcot-marie-tooth disease tafazzin instead tafazzin gene β-glucocerebrosidase instead beta glucocerebrosidase. total labeled questions correct questions having correct answer predictions. following give examples mistakes made system. questions presented italics. context underline predicted answers present correct answers boldface. identiﬁed eight questions semantic type answer differs question answer type. cases completely wrong predictions. however category also includes subtle mistakes like following table comparison systems last year’s bioasq challenge factoid list questions. batch question type list performance best competing system single model ensemble. note qualitative analysis suggests factoid performance batch would twice high synonyms contained gold standard answers. given answer summary judgment questions answered correctly questions answered correctly answers. surprisingly high numbers considering score automatic evaluation signiﬁcant result work state-of-the-art results biomedical question answering achieved even absence domain-speciﬁc feature engineering. competing systems require structured domain-speciﬁc resources biomedical ontologies parsers entity taggers. resources available biomedical domain available domains. system hand requires large open-domain dataset biomedical word embeddings small biomedical dataset. suggests methodology easily transferable domains well. furthermore explored several supervised domain adaptation techniques. particular demonstrated usefulness forgetting cost factoid questions. decreased performance list questions surprising model’s performance questions unsupervised domain adaptation could interesting direction future work biomedical domain offers large amounts textual data might even contain questions corresponding answers. believe leveraging resources holds potential further improve biomedical paper described deep learning approach address task biomedical question answering using domain adaptation techniques. experiments reveal mere ﬁne-tuning combination biomedical word embeddings yield state-of-the-art performance biomedical despite small amount in-domain training data lack domain-dependent feature engineering. techniques overcome catastrophic forgetting forgetting cost boost performance factoid questions. overall show employing domain adaptation neural systems trained large-scale open-domain datasets yield good performance domains large datasets available. references mart´ın abadi ashish agarwal paul barham eugene brevdo zhifeng chen craig citro greg corrado andy davis jeffrey dean matthieu devin tensorﬂow large-scale machine learning heterogeneous distributed systems. arxiv preprint arxiv. john blitzer mark dredze fernando pereira biographies bollywood boom-boxes blenders domain adaptation sentiment classiﬁcation. acl. volume pages konstantinos bousmalis george trigeorgis nathan silberman dilip krishnan dumitru erhan. domain separation networks. advances neural information processing systems. pages yaroslav ganin evgeniya ustinova hana ajakan pascal germain hugo larochelle franc¸ois laviolette mario marchand victor lempitsky. domain-adversarial training neural netjournal machine learning research works. xavier glorot antoine bordes yoshua bengio. domain adaptation large-scale sentiment proclassiﬁcation deep learning approach. ceedings international conference machine learning pages james kirkpatrick razvan pascanu neil rabinowitz joel veness guillaume desjardins andrei rusu kieran milan john quan tiago ramalho agnieszka grabska-barwinska overcoming catastrophic forgetting neural networks. proceedings national academy sciences page tomas mikolov ilya sutskever chen greg corrado jeff dean. distributed representations words phrases compositionaladvances neural information processing ity. systems. pages jeffrey pennington richard socher christopher manning. glove global vectors word representation. empirical methods natural language processing pages http//www.aclweb.org/anthology/d-. metthew riemer elham khabiri richard goodwin. representation stability regularizer improved text analytics transfer learning https//openreview.net/pdf?id=hyenwcgx. andrei rusu neil rabinowitz guillaume desjardins hubert soyer james kirkpatrick koray kavukcuoglu razvan pascanu raia hadsell. progressive neural networks. arxiv preprint arxiv. george tsatsaronis georgios balikas prodromos malakasiotis ioannis partalas matthias zschunke michael alvers dirk weissenborn anastasia krithara sergios petridis dimitris polychronopoulos overview bioasq largescale biomedical semantic indexing question answering competition. bioinformatics", "year": 2017}