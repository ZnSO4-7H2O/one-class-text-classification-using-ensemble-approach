{"title": "Semi-Supervised Online Structure Learning for Composite Event  Recognition", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "Online structure learning approaches, such as those stemming from Statistical Relational Learning, enable the discovery of complex relations in noisy data streams. However, these methods assume the existence of fully-labelled training data, which is unrealistic for most real-world applications. We present a novel approach for completing the supervision of a semi-supervised structure learning task. We incorporate graph cut minimisation, a technique that derives labels for unlabelled data, based on their distance to their labelled counterparts. In order to adapt graph cut minimisation to first order logic, we employ a suitable structural distance for measuring the distance between sets of logical atoms. The labelling process is achieved online (single-pass) by means of a caching mechanism and the Hoeffding bound, a statistical tool to approximate globally-optimal decisions from locally-optimal ones. We evaluate our approach on the task of composite event recognition by using a benchmark dataset for human activity recognition, as well as a real dataset for maritime monitoring. The evaluation suggests that our approach can effectively complete the missing labels and eventually, improve the accuracy of the underlying structure learning system.", "text": "fig. data partitioning examples. example contains ground query atom either labelled unlabelled well true ground evidence atoms relate query atom constants. sets treated training examples. true evidence ground atoms ground query atoms interest micro-batch example contain exactly ground query atom proper subset evidence atoms corresponding given sets construct example ground query atom regardless whether labelled not. partition evidence atoms grouping constants share vector values vertices partitioning hold values labelled unlabelled vertices respectively. solving constrained optimisation problem expressed clause cached vertex number times clause appeared data far. similarly opposite clause clause exactly body negated head counts. instance inverse clause goal eventually select contradicting clauses. deﬁne function nc+nc range represents probability clause appear data instead opposite clause according hoeﬀding bound true mean probability diﬀerence holds probability hence accept hypothesis indeed best clause probability thus kept point. similarly best −∆¯p therefore order select receive micro-batch ground query atoms ground evidence atoms. partition data vertices partition partition labelled unlabelled vertices cacheupdateandfilter union unique labelled nodes unlabelled ones supervisioncompletion perform structure learning step using", "year": 2018}