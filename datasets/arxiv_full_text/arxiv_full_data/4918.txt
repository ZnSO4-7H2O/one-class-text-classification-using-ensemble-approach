{"title": "A Spacetime Approach to Generalized Cognitive Reasoning in Multi-scale  Learning", "tag": ["cs.AI", "cs.LG", "I.2.11; F.4.1; I.2.4; G.2.2"], "abstract": "In modern machine learning, pattern recognition replaces realtime semantic reasoning. The mapping from input to output is learned with fixed semantics by training outcomes deliberately. This is an expensive and static approach which depends heavily on the availability of a very particular kind of prior raining data to make inferences in a single step. Conventional semantic network approaches, on the other hand, base multi-step reasoning on modal logics and handcrafted ontologies, which are ad hoc, expensive to construct, and fragile to inconsistency. Both approaches may be enhanced by a hybrid approach, which completely separates reasoning from pattern recognition. In this report, a quasi-linguistic approach to knowledge representation is discussed, motivated by spacetime structure. Tokenized patterns from diverse sources are integrated to build a lightly constrained and approximately scale-free network. This is then be parsed with very simple recursive algorithms to generate `brainstorming' sets of reasoned knowledge.", "text": "abstract—in modern machine learning pattern recognition replaces realtime semantic reasoning. mapping input output learned ﬁxed semantics training outcomes deliberately. expensive static approach depends heavily availability particular kind prior training data make inferences single step. conventional semantic network approaches hand base multi-step reasoning modal logics handcrafted ontologies expensive construct fragile inconsistency. approaches enhanced hybrid approach completely separates reasoning pattern recognition. report quasi-linguistic approach knowledge representation discussed motivated spacetime structure. tokenized patterns diverse sources integrated build lightly constrained approximately scalefree network. parsed simple recursive algorithms generate ‘brainstorming’ sets reasoned knowledge. reasoning long associated formal logic computer science argued reasoning subset wider class narratives told joining together assertions. logic’s goal maximize certainty narrative derived prior concepts transforming according constrained largely deterministic rules step selects unique possibility. however value limited circumstances. cases unique certainty available practical expansive kind ‘brainstorming’ needed problem solving allows multiple possibilities remain open selection later time. brainstorming ﬁrst stage process reasoning ‘whittling’. idea create large hypothesis subsequent reduction something focused. whittling often emergent iterative. reasoning interpretation cognitive process allows observer integrate experiences perhaps evidentially linked even provably true order form speculative hypotheses. process contextual elimination converges iteratively much smaller ﬁnal answer using variety criteria freshness relevance importance. dynamical approach criteria like semantic dynamic stability stories important logical idealizations like ‘truth’ determinations ‘correctness’ underestimated aspect intelligent behaviour learning individuals explain things terms prior experience make sense world. form story know difference correlation causation correlations direction i.e. arrow progression used accumulate narrative storyline. hence correlation offer short-range explanations uncertainty grows number claims similarity. combining directed associations reasoned argument different problem altogether requires propagation semantics step step. combine concepts stories small sets thing; applying expansive reasoning systems vast numbers sensors sporting different characteristics whole challenge. imagine scenario like monitoring massive array smart connected systems e.g. internet things smart buildings cities etc. data different kinds generated many different scales vast number different sources. could begin interpret phenomena across different scales? concepts need? challenge making sense data scale urgently calls broader view artiﬁcial reasoning based improved semantic labelling collected data. might scale meaningful interpretation data. simply case collecting data. monitoring sensory data would incomplete without ability reason observations. reasoning requires deﬁnition concepts tied operational goals. work summarizes model invariant storytelling based spacetime inference approach reduces computational complexity story inference orders magnitude. describes semantic associations collected arbitrary sensors inputs knowledge representation learn context-dependent interpretations inputs order later generate explanatory narrative automatically. summarizes practical implementational aspects promise theoretic notion ‘semantic spacetime’ implements number experiments based model. promise theory motivates graph theoretical approach semantic scaling based observation cognitive relationships ultimately derive elementary spacetime relationships. recursive structures leads partially deterministic connected paths represents reasoned ‘stories’ explanatory content. work show apply structures tentatively simple cases. promise theory frames elementary questions intent scales cooperative interaction extensive spatial networks properties express spacetime-like variations mirror representation environment. based considerations expect number information processing stages cognitive learning system sensory apparatus inputting exterior information. stage replaces sensory patterns semantic tokens i.e. naming. stage associates semantics i.e. meaning named tokens associating clusters called concepts associated predictable qualifying ways. introspective story-generating stage able ‘think’ activate interior concepts feed resulting stream consciousness back posttokenization stages along side sensory inputs. although used thinking systems explained narratives organized arrangement understood terms stories goal completely general. discussions so-called artiﬁcial intelligence discuss stages work deals mainly stages onwards believe orthogonal. latter stages much common linguistics indeed invariant patterns ﬁnite alphabet tokens every reasoning problem maps linguistic problem. simple prototype system explore underlying principles reconstructed earlier cognitive approaches applied pervasive computing management cfengine modernized extended cellibrium project typically lead claims deep knowledge. revisiting experiences i.e. iterative process observing learning build trust stable ‘invariant’ representation knowledge fig. coarse grain space time regions partially indistinguishable equivalence e.g. different experimental ‘trials’. concurrence coincidence deﬁne boundaries cognitive experience. cognition every timelike frame experiment must learning even experimental inequivalence. certainty related choice scaling granularity. learning happens hierarchy timescales fundamental concepts evolved stabilizing ‘genetic’ adaptations long term selection group; concepts build stability frame newly learned concepts congeal generations adapted passed socially includes specialized sensors tokenize dimensionally reduce information intensive data compressed conceptual representations finally concepts build foregoing formed shorter timescales observation introspection single observer latter normally think learning; however important remember builds stable preconditions evolved prior current learning episode. would expect consistent knowledge represented eigenstates memory network. fast knowledge representation contains memory representations able form stories without outside stimulus system think associate freely leading concepts. would essentially talking oneself would naturally share linguistic representation exterior sharing. finally memory system would complete without processes annealing garbage collection even clear away clusters memories become important dominate older ones. data singular events priori inferable interpretation. meaning single data point promised source. knowledge system able integrate diversity experiences stable aggregation channelling perceived conﬂicts contextualized differences thus preserving without neutralizing them. sense diversity prerequisite knowledge integration leads scaled form hashing. cognition leads association tokenized concepts process illustrated schematically ﬁgure prism separates data spectrum four basic associative types known irreducible types mirrors ideas linguistics classiﬁcation nouns. semantics cognition different semantics experimental observation science. ensemble measurement eliminating ‘self’ experience. cognition observer subjectivity aspect cannot disregarded. this suggests language would co-evolve conceptual representation knowledge utterances i.e. statements stories would grow sophistication along side knowledge evolved society representations brains. attention given algebraic aspects measurement physics e.g. quantum mechanics surprisingly little attention given semantics data cognitive perception except case experimental error extent measurement disturbs system measurement affects promised measurement. measurables property ‘compatibility’ meaning measurement inﬂuence measurement other. slow training random variations whittled away behaviours memories encoded long-term memory providing seeds framing newer ideas formed realtime recombination. hypothesis ideas naturally associated invariant aspects space time leading four basic kinds conceptual association well basic ability compress extensive spacetime datasets simple tokenized concepts software system represented hardcoded semantics specialized sensors designed discriminate pre-understood concepts virtue adaptation fast cognitive assessment context context changes quickly concepts associations formed timescale. independent observer inherits adaptations learned previous generations build basis assembling context sensory experiences assessing emotional state pattern recognition. sensory channel eventually supplemented introspective channel effect simultaneously mind observation thought leads aggregate clusters composite concepts co-activation named concepts. software represents monitoring classiﬁcation data. might represented facial handwriting recognition algorithms training etc. slow training given lexicon tokens concepts inherited compressed form passed individual another e.g. word mouth text book. longer need direct experience. concepts thus remembered knowledge bank generational societal memory handed domain expertise. form knowledge acts second level boundary conditions framing seeding concepts. fast cognitive knowledge useless without seeds constraints provide machine learning tries bulk recorded experience detail directly singular neural network simulating direct ﬁrst-hand experience brute force reconstruction adapting hardwired nature match presumed semantics. however humans also able learn books stories passed verbally learn simpliﬁed tokenized representations knowledge experience every sensation emotion source did. even learning read books neural network techniques would need read every book network order train rather using short summary book about. humans able scale knowledge acquisition summarization trust without verifying directly source. order scale machine learning machines must also able this. training network second hand teaching alone lose realistic sensory emotional context forms part access recover memories. thus model cannot simulate reality memory standpoint. aspects context simulated described second-hand realistic emotional state normally match actual ﬁrst-hand experience. ability second-hand agent empathize concepts sensations primary agent therefore play major role ability pass knowledge. hand compression complex lookup compact address allows reorder concepts categories generalize them overlooking irrelevances based context. this introspective simulation emotional context well evolutionary purpose empathy given enormous value saving communication computational processing. described ﬁgure ‘prism’ separates data spectrum associative types theory predicts represent different spacetime characteristics called irreducible types conceptual prism bears similarity staged structures neural networks; however neural networks relatively expensive compression algorithms well suited latter ‘expansive’ stages reasoning bulk input data would make reasoning slow. dimensionally reduced concept tokens forward backward associations type respectively context labels. tuples represent links edges graph whose nodes conceptual tokens whose edges associations. summarizes associative relationship implied observation. also weight relative strength tuple timestamp last updated elements strings. example highlighting main features tuple represent simple qualitative description tuple noteworthy tuples absence data types tokens translating untyped graph. conventional data representation; rather symbolic representation. must since semantics extended reference concepts must rooted somewhere language. concepts thus symbolic strings interpretation lies associated. linkage determine associations relevant contexts also concepts activated contexts encoding concepts linked associations forms recursive structure described below. regular manner cayley tree result closer ‘semantic small worlds’ graph naming things representation meaningful observer. name pattern represents concept. names useful shared multiple agents concepts communicated committed shared memory used explain phenomena. thus without consistent pattern representation concepts could recall memory thus concepts would useless irretrievable. thus language necessary condition semantic interpretation. neural network approaches dimensional reduction number inputs small number outputs meaningful clearly unambiguously identify output channels named concepts. simple language transformation. argued fundamental basis conceptual association origins structure spacetime represented four types relationship give speciﬁc associative meaning different spacetime coincidences naming associations according abstracted concepts. concepts associations nodes edges graph conditional parameter represents context terms edge active. since context changes deﬁnition fast think environment perceived elementary tokens associated context must expected large number number invariant sensory perceptions observer rapidly changing symbols knowledge representation. reason could expect primary context characterizations hardwired i.e. built functional nature agent specialized eyes ears face cells place cells secondary characteristics could learned time provided remain simple enough activated quickly. unlikely context would expressed complex concepts. however could role emotions sensations complex sensory perception without strong rational linkage multiple aliases alternative interpretations four spatial relationships possible indeed encouraged effective communication expressivity qualiﬁcation. example type interpreted adjacency apto etc. type proximately equal represent time unidirectional ordering causation dependency etc. table examples four irreducible association types characterized spacetime origins graph representation ‘has attribute’ ‘contains’ clearly independent implementation details still compress number types. type represent membership group generalization collection concepts location inside outside perimeter etc. however also cautious informal association linguistic metaphor also leads confusions appropriate classiﬁcation meaning irreducible types interpretation metaphor ﬂuid human language associations must retain speciﬁc interpretation every link also generic type affects parse structure hence reason associations. meaningful narrative usually driven mainly type embellished type discriminating properties lateral reasoning types semantically enhanced concepts derived aggregation primitive concepts associative clustering. cluster compound agent representative making associative links. acts gateway qualiﬁed concept’s associative network much router gateway subnet larger internet. concept therefore agent scale aggregation unique name representing meaning. addition names contextualized associations within cluster without speciﬁcity concepts expressed. based trial error experience seems comprehensible ‘natural’ linguistic naming strategy follows scaling agency i.e. aggregation described scaled approach combines names interior promises yield compound name collective concept exterior promises express associations composite concepts linguistics called compounding. scaling compatible patterns observed cognitive linguistics indicating language understand forms good network structure concept representation. cognitive perspective turn data concepts depends spacetime boundary conditions imposed exterior environment. semantics data different depending whether samples originate single source collection sources. information culture people sometimes talk pets versus cattle meaning unique instances names labels versus herds without distinct identities. data terms singletons ensembles. batch experiment multiple samples contribute collective impression data points within ensemble considered equivalent homogeneous semantics. words choose overlook differences name. dataset stream scalar values every would considered interchangeable. indices relabelled results preserved. properties derived dataset must therefore invariant relabellings array index invariant representations formed. invariant representations crucial avoid explosion contextualization would expensive would render concepts non-reusable. fig. semantics representing aggregation. group aggregated properties linking centrally singular basis agent attribute expression effectively inverse membership basis agent alone represents collective ensemble. clusters property. approximation proximity named concepts close together either interior representation form labelled proximity cluster. nature proximity physical literal semantic depending label. encoding cases label. ﬁgure causal aggregation dependencies come together head single outcome causal determinant multiple sources. deﬁnition arrow time. ﬁgure symmetry spacelike homogeneity) concepts joined single represents collective identity ‘contains/contained must distinguished using construction attribute association. construction generic form call schema datatype computing. recognizable without specially arranged protocol observed associations. ﬁgure depends linked recursively atomic concepts also possible compound name forgets association concepts derived survives independently frequency associative density use. fig. compound formation reduced functional pattern representative name linked partial concepts main subject header dimensional reduction strategy refer compound name drag along conceptual baggage associations accordingly. note however interpretation privileged role sometimes ambiguous. study compound terminology major topic linguistics addresses conceptual origins names language. example table referred single compound word phrase ‘tableleg’ compound role ‘leg’ contextual attribute ‘table’ example straightforward fairly unambiguous. name reﬂects components directly conventional ordering leading simple rule construct compound identiﬁer. however many compound concepts directly reﬂect origins fact forget origins time window window neither wind word serves purpose whiff metaphysical. cases linguistic term qualiﬁcation need distinguish ambiguous concepts qualifying context e.g. consider ‘doctor’. doctor refer medical doctor general practitioner surgeon someone etc. could simply unique names these approach easily scale; hence normal describe ‘namespaces’ contextual constraints. done forming compound name phrase ‘doctor role instance somewhat ambiguous role qualiﬁer construction. could argued ‘gp’ role doctor redundant ‘doctor’ role ‘gp’ qualiﬁer. distinction somewhat arbitrary computational scaling conceptual agency representations direct application promise theory summarized according four irreducible spacetime attributes elucidated parsing algorithm remarkably simple associations organized around elementary spacetime concepts distinction location order expressed properties. earlier work showed promise view structure motivated identiﬁcation concepts spanning sets matroids labelled graph. convenient representation bind related clusters node whose name collective name cluster. offers scalable approach spanning concepts upwardly extensible uniqueness. associating collection associated concepts single point address throw kind perimeter around spokes emanating form single concept. clusters overlap without limit thus mutually exclusive branching process unlike hashing approach unique naming uniqueness assured combinatoric compounding names. collection named concepts cluster accessed single node acts gateway aggregation parts. name matroid represents name composite concept formed internal association interior concepts. concepts whether primitive derived therefore thought ‘lexical fragments’ ‘syntax fragments’ generally language fragment formed recursive scaling. compound essence long name contains evidence concepts this broadly analogous name compound data schema object computing. name object entirety members names associated items. association types analogous data types. analogy breaks matroid hubs name arbitrary collections data form mutually exclusive nonoverlapping memory segments. concepts aggregated without limit qualiﬁcation cannot subdivided without limit. thus taxonomies ontologies branching processes scalable adaptation. viewpoint sometimes helpful able distinguish privileged component describes behaviour function term. various experiments conducted course work topic maps present model seems appropriate place agent role network lies associations pairs concepts rather concepts themselves. tries ‘type’ concepts etc) prevents free association ideas analogy central human reasoning. thus classic idea ‘data type’ concepts semantic network appears simply wrong leads over-constrained network much uniqueness. resulting network sparse allow percolation hence propagation storyline finally central problem think names concept clusters? naming clusters seems analogous matter forming nominal compounds approach abandon linguistic meaning form unique hash. approach used natural language processing claimed success. however hashing one-way transformation unsuitable associative map. create interactive system knowledge need able read back concepts form parsable humans. matroid hubs compound names binding points conﬂuences association semantic correlators i.e. authoritative anchor points expressing uniqueness. follow approach consistently conceptual speciﬁcity increases upwards level aggregation rather downwards depth branching taxonomic hierarchies leads bottom-up approach conceptualization entirely compatible modern genetic understanding phylogeny phenotype expressed aggregation genetic ﬂavours. also motivated promise-oriented interpretation. mirroring proposed usage approach language formation cognitive linguistics chemistry semantic atoms mixed distinct molecular combinations differentiated functional meaning. result cognitive process tokenize complex data inputs tokens summarize data invariant representation; might approximate proportionately immune variations link together association. promise theory language concept tokens agents associations promised agents. ladder sensing conceptualization proceeds aggregation involves work thus takes increasing time process complex associative concepts. concepts clusters agents. basis interpretational semantics lies following observations occurs together associated. thus context belongs associations concepts. measurements different locations different times necessarily causally related correlated. naming association undetermined. averages stabilize semantics decoupling temporal spatial approximate regions. data sampled combined different sources treated ensemble averages single concurrent experiment. meaning time location lost averages semantics stabilized decoupling. measurements comparable semantics. cognition observations comparable experimental sense unless deliberately overlook certain information. thus semantic stability depends information throw away. fig. climbing knowledge ladder takes longer longer advance towards sophisticated concepts fast sensing pondering concepts iteration aggregation crude neural network relative activation level association thus integral weights incoming edges. triggering policy could also employed generality tuning; however simulate spatial interference process neumann computers.. context used frame circumstances under associations concepts identiﬁed. striking balance context strives coordinatized precision maximally invariant central challenge building addressing system semantics knowledge implementation cellibrium thus assumed that context attached associations concepts. co-activation associative bond needs activates ends speciﬁc members differ evolution contextual awareness cognitive agent. approximate similar location space. common cause outcome convergence path past future. common enclosure membership. shared property leading implicit membership expressed externally sensors plays different role expressed internally introspection section interior exterior properties continue play role distinguishing. figure illustrates this. interior exterior contexts play role addressing i.e. labelling retrieving concepts remains question context activate deactivate story pathways. artiﬁcial system especially made domain speciﬁc purpose information content semantic complexity inherent context annotation training might small give reasonable chance discrimination relevance real-world circumstances. unless sufﬁcient density discriminators either fail possible pathways include many losing point context reﬁnement criterion. singular context names meaningful readers broad cultural knowledge simple allow meaningful discrimination machine processing. need understand extend context labels efﬁcient addressing semantic relevance. recursive nature concepts promise model scaled agency suggests helpful distinguish interior exterior context concept. interior context refers qualifying associations positioned ‘behind’ hubs help support qualify interpretation concept. exterior context refers concepts active recent train thought total cognitive system interfaces world sensory apparatus table semantic scaling leads notion interior exterior many levels. distinctions play important role deﬁning cognitive linguistic recursion learning retrieval stories. interior memory context acts kind ‘type’ ‘role’ interpretation concepts selected deselected exterior memory context whereas interior awareness context represents feedback system talking past experiences thoughts. cases functional treatment memory context handled invariant algorithm great computational simplicity. context addition descriptive words learning also linking compound states sub-concepts depend too. following approach average degree connectivity graph increases superlinearly making non-trivial stories increasingly likely also providing switches exclude pathways based later context retrieval. fig. scaling association cognition. context labelling associations interior compound concepts exterior concepts. context acquisition cognition interior agent observer exterior structure following examples helps show context important aggregate clusters concept-property matroids situation-context groups. settheoretic interpretation. contextual information interior exterior following cases help exemplify issue could normalized ‘probability’ unit story length could build score analogous shannon entropy associations symbols associative alphabet. remains future investigation. fig. example programming statements leading formation graph within programming environment. system could principle instrumented within offer semantic hints aggregation central ‘brain’. helper functions divide generate patterns illustrated ﬁgures activates certain concepts associations. exterior context exchanged slower stable introspection derived concepts back context ‘thinking about’ particular topic. tokens followed individually activated parallel search consequences particular concept current context. implementing context channel challenging aspect building cognitive knowledge representation. ﬁrst stages addressed report. ﬁrst somewhat analogous quantum path integral several possible pathways might play concepts given context. example without sufﬁcient context know interpretations ‘oslo’ ‘america’ unary associations play simultaneously reasoning process suggests something like shown ﬁgure help automate structural regularity documentation concepts associations i.e. semantic learning. notice using matroid hubs compound concepts reduce dimensionality conceptual activations single concept also achieve economy scale attendant computational simpliﬁcation. encoded retrieval associations achieved reparsing representation ﬁgure subject independently maintained context. sensory context somewhat elementary tokens type entirely encoded recursive compounding structures knowledge representation. retrieve knowledge kind context purely qualifying explanatory usage. major links concepts fully qualiﬁed nodes interior context hidden unless explicitly examined given level recursion. exterior associations link concepts another knowledge representation determine concepts lead concepts. however exterior associations judged relevance comparing context learned current context state mind agent. leads complex causation concepts overlap association context overlaps pairs concepts perhaps beyond. therefore channels evolving parallel short term memory context long term memory qualiﬁed concepts measuring relevance forward pathways remains unsolved problem. current context evolve traverse story. quickly context forgotten? increase scope context evolving thoughts drifted off-topic highly subtle determination lend algorithmic pattern based solution. might well relevance needs bank multiple pathways interfering across entire length story path. apply software problem natural treat story markov process step independent last activation context adding transverse memory. probably simplistic work must limit ambition. ﬁrst approximation take lexical overlap context sets estimation relevance. using this sort stories link link judge relevance twist turn. relevance total story cannot calculated without particular end-topic. goes beyond scope notes. machine learning applied document processing story fragments treated patterns recognized relevant forward pathways determined based statistical ensemble support rather semantic relevance many issues trying match relevance based context small system. present context match context time learning degrees freedom coupling contexts together. turn rely universal invariant context markers like emotional states play role activation selection. although poorly understood play central role joining together ideas cannot easily joined explanations semantics. even know seem potentially contradictory without sufﬁcient density linkage qualifying context. must quite careful over-constrain reasoning projecting human expectations onto process early. likely concepts true false emergent rather prescriptive. four sets activate another stories generated ‘deterministically’. current concept natural part state mind agent thus belongs interior cognitive context much sensory inputs. cognitive context agent divides interior exterior parts. interior context agent thinking about independently sensory inputs. exterior context sensory channels. thus context information naturally inward-looking introspective information outwardlooking interior awareness context determines relevance forward pathways state mind calibrator intent. exterior awareness context framing current experience grounding experience feeling. thus cognitive ‘awareness’ channels different semantic roles context evolves focus consciousness ‘what system thinking about’ i.e. current concept concepts story frame. interior associative context plays role functional usual important remember semantics secondary dynamics enable thus causal propagation meaning cannot assumed across different timescales expect timescales learning retrieval become separated eventually retrieval times much longer training times must still recall modify stories learnt previously. gives clues encoding. particular tells causal information needs encoded exterior associations relying context light answers directly like primary database key. fig. timescales associated learning retrieval stories. links concepts causal long separations context always causally related concepts short timescales. excessive speciﬁcity enemy retrieval speciﬁcity important encoding phase knowledge. example general concept birds depends concept ﬂight rather fully qualiﬁed instance bird. words careful confuse general speciﬁc level recursion lead manifest errors reasoning ‘all birds depend ﬂight’. matching conceptual scales another problem must deferred study future work. time writing simple proof concept implementation foregoing cognitive system implemented. simplest level interior/exterior context conditioning used activate screen paths owing complexity simulating feedback system software. initial goal illustrate principles. four kinds data source imported semantic graph hope ﬁrst generating stories brainstorming. even simple ﬁrst step application causal analysis qualitative hypothesis testing etc. data sources were ‘computer immunology’ derivative embedded machine learning pattern level) output realtime production datacentre environment scenario. intentional system intended policy could also encoded connected agent describing desired activities state. thus data observations intentionally measured actual state system converted invariant forms intended interpretation relative determined policy goals constraints. ﬁgure policy documentation ﬁles describing intent incorporated intended meanings software functions links documentation well coding particular policy rules. source code software agent could scanned extract error messages given particular context. domain knowledge design intent software included manually well remarks world computer datacentres servers operating systems. software system example data scanned nesting structure dependencies software packaged process containers bundles linked binaries probed using intended composition rules ﬁgures doctor online registration wizard domain knowledge imaginary online scenario patient trying register doctors appointment city. concepts associations input directly wizard overview knowledge intent smart distributed service software uses dependencies workﬂows etc. ﬁgure picture semantic index example domain knowledge contributed possibly multiple sources giving cognitive overview entire environment experience. ﬁgure sensory data collectors sample exterior sources timescale accordance nyquist’s theorem. collector independent semantics transmutes sample data separate invariant representation learns signiﬁcant patterns states bayesian statistical current programming languages make easy export contextual intent behind code user messages. future innovation become essential scaled monitoring software society. description lexical name representation selected small invariant states. associations updated regular timescale associative link acts independent bayesian learning process giving links semantic network weights relating importance frequency visitation. applies recursive scale concept aggregation. intentional aspects system designed evolved niche purpose central encoding semantics. information captured source simply lost. users software later reinterpret intent light current assumptions intended meaning ultimately originates source matches promises ‘promise/intent offered’ ‘promise/intent accepted’ receiver always last word interpretation however however contexts arise thus clusters always lasting meaning composite concepts. running catalogues currently going somewhat analogous browser history relevant words pertaining agent state simply strung together particular order. analogous original cfengine classes context collection class strings probed environment specialized software sensors. combinations classes could constructed quasi-logical expressions activate certain concepts basic atoms drawn system variables. general cases higher level abstraction context must include ‘state mind’ cognitive system recent past encapsulates intent well environmental impulses. expressible terms higher level concepts prototype code creating parsing knowledge representation shared cellibrium project. employs simplest possible proof concept avoiding programming concerns favour pedagogy. concepts represented directory names containing subdirectories association types; then turn association annotations including timestamps weights bayesian updating. although ﬁlesystem limitations make approach unsuitable long made coding prototype pleasantly free dependencies obscure apis. everything could handled fast efﬁcient posix system calls. concepts directories root node contain subdirectories corresponding four spacetime association types. ﬁles document concepts reached following type association frame context separate control channel used mainly implementation convenience. context association spacetime containment type groupings. contexts work exactly concepts composites sub-clusters. would seem though graph database would ideal candidate representing data thus input query languages databases clumsy ill-suited kind structure. assessing success prototype ‘brainstorming’ experiments easy matter given qualitative nature results. much weakness experiment nature problem. although possible manufacture artiﬁcial metrics collection numerical data e.g. numbers proposed stories conceptual overlap context along path measures largely unhelpful correlate easily subjective sense ﬁnding helpful outcome. left kind ‘turing test’ assessment approach i.e. looks human. later applies approach speciﬁc problem target goals incorporated beginning able better establishing consistent criteria. shall address report. data sets used consisted hundreds thousands concept tuples collected variety sources. numbers quite small realistic application sufﬁce test comparative aspects approach. association data generated annotating system monitoring realtime software outputs documentation scans manual knowledge documentation hints. early trials realtime monitoring data knowledge representation retained speciﬁc information might stabilize comprehensible emergent pattern. however framing limiting context hard pedagogical problem. semantic spacetime knowledge representation somewhat similar higher dimensional ﬁeld theory ultraviolet cutoff information discrete ﬁnite. story like transition function s-matrix element whose vertex rules based causal associations propagation rules. fig. software associations used propose template scanning software services. model template distributed software crawler could written user-secure manner extract operational knowledge deployed software. cluster concepts illustrates build template core ontology within small domain. measurement leads different context i.e. making time generator context number concepts would prohibitively large cannot escape fact human brains builtin limitations. since dealing semantic interpretations cannot simply ‘big data’ treat every knowledge problem forensic investigation cannot guarantee focused concepts emerge data. different problem expert hand already fait necessary knowledge. thus must look invariant representations data cumulatively time interpreted small number concepts sake comprehension. fortunately studies shown meaningful patterns system monitoring behaviours number compared bulk non-meaningful noise output brainstorming episode based given starting concept tended lead either stories many stories. reasons depended structure data selection criteria. initial attempts quality stories hampered simply absence data. ﬁrst trials using data types represent contexts relatively unsuccessful. input knowledge took huge manual effort curate terms syntactic semantic burdens placed author; then even someone could persuaded undertake encoding would fragile under-connected. little unexpected emergence possible typing made data overconstrained. sparseness fragility typed structure meant concepts could easily discovered free association searches resulted results. topic inspired structures created mainly trivial stories project aside almost years. following hiatus models based topic maps abandoned ideas promise theoretic approach revived. removal ‘types’ discriminators replacement context-free lexical terms large increase density stories. difﬁcult numerical measures improvement radical restructuring many aspects involved shift results dependent particular characteristics example data preserved intervening years difference although attempt made reconstruct similar data. best could qualitative improvement results. earliest attempts discovering emergent connections implemented collaborator alva couch used shortest path approach selecting unique ‘route’ concepts initial ﬁnal boundary conditions. slightly different full brainstorming already constrained deﬁnite target concept. ultimately abandoned shortest path approach creates tension quantitative metrics dynamical selection criteria rather semantic relationships. idea single path based length could correct answer exclusion others well motivated; although plausible that given semantically valid paths shortest might interesting qualities. advantages ﬁxing boundary conditions start story compelling always clear looking exploring causes interpretations. derivation four irreducible spacetime association types brought signiﬁcant simpliﬁcation algorithm exploring locales. initially linear search needed identify matching concepts number type ‘namespaces’. associations could followed question whether associations could propagate encoded directly association requiring another lookup so-called inference rule. possible complexity order product length inference table number outgoing associations thus pre-classiﬁcation according spacetime ‘compass types’ reduction order magnitude computational complexity eliminating need inference table. propagation types inferences deﬁned spacetime classiﬁcations matching required. reduction degree ‘grammatical complexity’ come aggregation multiple concepts aggregate classes. associations made larger umbrella concepts rather concepts speciﬁc cost recursion spared. thus seem context-free expression linguistically sufﬁciently represented regular language expression. discussion grammatical complexity spacetime associations. addition context either positive negative matching intensive computation remaining; however observation seems critical establishing semantic relevance stories. context modelled original cfengine representation derived cellibrium implementation non-ordered linear list composed many atomic characterizations. evaluation context requires parsing entire list matches similar nonordered expression composed atoms. complexity could order product current context lookup learned context lookup association. supposing could logarithmic order hashing much better model without encoding spacetime types. size context cannot pre-determined ﬂuctuates short times grows longterm learning. link story complexity cost associated relevance link. measured size overlap current context learned context cfengine model context deﬁned ‘logical boolean expression’ enabled contextual relevance reduced even further single expression evaluation whose overlap generally quite small i.e. length speciﬁc boolean expression many ways optimize contextual matches using aggregate classiﬁcations caching largely execution cfengine context frozen moment time. nature cognitive system hand continuously changing always expensive compute. enough brainstorming paths analyze output search advantage spacetime approach knowledge representation. problems remained however whose remnants still seen ﬁgures stories often unreadable bizarre even valid lexical phrases coughed along pathways graph little meaning without original intent associations names preserved represented. loss intent seemed heart this. intent acts form context. often stories terminate without artiﬁcial length cutoff spite loop detection methods per-story basis simplistic recursion allowed stories contain another sub-parts free association. suggested success context constrain stories bring focus results. later repeated visitation concept forbidden across stories stories become ﬁnite; however argument could made search overconstrained choices might exclude certain combinatoric stories visited all. fact non-termination stories another indication graph well connected even small data sets used also artefact open-endedness brainstorming process. without clear goal either terms context speciﬁc concept deterministic criterion running combinatoric options. original approach used cfengine simulate ‘neuronal dead-time’ concepts eliminating loops virtue concepts ﬁred already worked cfengine simplistic linear processing approach. network multidimensional causation approach could easily prevent important answers emerging rather protect repetition. host£ ./stories cannot cidr notation xxx-yyy range notation software fault follows) cannot cidr notation xxx-yyy range notation caused network policy fig. brainstorming rooted error message generated cgngine system log. story frames possible cause initial error message anchor point nicely pin-points offending function ‘iprange’. context typing. basically analogous transition schemaless database. introduction recursive structure automation ﬁgure story density largely unchanged readability stories greatly improved allowing kinds outputs shown ﬁgures. structure naturally separation context interior exterior memory channels mentioned section vi-f. interior memory context immediate comprehension even strict linguistic form contrived. this course testament human linguistic acumen skill simple algorithm indicates essence language captured recursive identiﬁcation irreducible types. figures show typical samples outputs brainstorming. actual outputs much longer these. print format well suited show data. left hand margin shows spacetime association types followed make association indentation shows recursion depth along single path. ﬁgure data taken cgngine software using several data transmutors scan source code system policy. occurrence obscure error message system output immediately tied likely sources points expression allowing user trace source back intended policy software layers. figure shows data acquired software build pipeline. shows deployed software depends containerized packaging software dependencies host operating system base location deployment. chain dependencies developers operations risk analysis personnel name few. figure shows straightforward recursive decomposition library dependencies discovered using linux command. deeply nested extensive list cross dependencies quite impossible human comprehend straightforward encode analysis. figure shows facsimile distributed system used patients register doctor norway curated perspective domain expert. procedure involves going website ﬁrst must number credentials third party sites totally unrelated public service. kind constellation independent services integrated meaningful whole would handled kind wizard software task single computer. single agency responsibility integrate information. cognitive system monitors services smart city could this instance. figure shows playful examples domain knowledge concerning purpose different services different contexts. lexical token like ‘tidal’ might refer many different things different contexts. brainstorming able distinguish cases using recursive structure matroid hubs. sophisticated rendition brain dump would able select speciﬁc interpretations structures without risk conﬂict. whether source semantics manual curation trained natural language processing alter beneﬁt approach used here namely orders magnitude cheaper build approach based repeated ‘big data’. approaches used discover vector congruences emergent functional semantics extensive training fig. knowledge scanned distributed application shows structure service software dependencies containers operating system package names. litany components service dependencies might used troubleshooting risk/vulnerability/impact analysis. notion context subject confusion misdirection. logic-based approaches semantic modelling tried context turned quite wrong exists objective version knowledge determine ﬁxed type-hierarchy preferred ontology. knowledge much beholder every observer forms individual ontology context objective categorization running state mind long treat knowledge representation objective static boundary condition knowledge rather private subjective interpretation difﬁculties. present approach motivated spacetime classiﬁcation semantics thus ignores preferred ordering link weights semantic stability encouraged simply structural aggregation concepts analogous human language. even random variations using promises like near effectively allows collapse disconnected multiple stories single broader line story. important reasoning lies causal paths integrated speciﬁc boundary conditions start end. recent focus work artiﬁcial intelligence training artiﬁcial neural networks recognize increasingly complicated patterns like voice faces handwriting. trained networks mimic human cognitive sensory systems usually one. neural networks trained attempting replay lifetime experiences high-speed learning process. extent network accumulated made predictive depends extent spatial structure mimic representation semantics happens looking single trigger however impossible measure certainty even simple kind reasoning indicating entirely separate stage processing deterministic representation needed reasoning goes beyond single inference. follows) application cgn-agent depends cgn-agent follows) follows) follows) preceds) pendencies security) follows) follows) preceds) preceds) cies security) follows) preceds) preceds) libpcre.so. depends libpthread.so. libpthread.so. partly determines libdbus-.so. libdbus-.so. partly determines libavahi-client.so. form consumption others without experiments interesting plenty issues address future work. finding constrain stories bring focus trains thought major problem. spacetime inspired structure stories longer scarce trying overconstrained typed approach. lateral reasoning possible relevance maintained representing context. treatment context note weak much room improvement. speculated role emotional state determining context. emotional weight plays signiﬁcant role cognition setting context interpretation priorities. viewpoint emotions seem play role coarse aggregate ‘concepts’ stimulated sensory/introspective inputs. emotional context thus systemic assessment ‘agent’ based identity credentials uses step httpsurlformelement identity credentials required partly determines doctor authenticated doctor service depends patient appointment follows) follows) follows) follows) follows) follows) thentication veriﬁcation dentity authentication veriﬁcation) follows) preceds) tication veriﬁcation ntity authentication veriﬁcation) preceds) tient doctor registration patient doctor registration) follows) follows) follows) preceds) follows) follows) text need visit doctor) follows) preceds) follows) follows) follows) follows) follows) follows) thentication veriﬁcation dentity authentication veriﬁcation) accepted doctor patient binding depends doctor authorized accepted doctor patient binding depends doctor accepted doctor patient binding depends patient patient authenticated partly determines have public health service access have public health service access depends public health service available public health service available depends general practictioner doctor available services cohesive storyline connect them without aggregating intended relationships them. intentional documentation allows generate kind documentation ‘wizard’ realtime processes changing realtime. causal links show representation complicated distributed system could basis wizard integrating apparently unrelated parts single view. states like distress easy measure ﬁnite system. threshold behaviour reached system unable keep promises e.g. thrashing empty queue. emotions could semanticized versions major conditions. states like good danger happy components would think emotional states. give clear meanings measurements respond context associations make good times affect recall concepts later. feel strongly something translates importance rank association. want acknowledgement indebted steve pepper depth discussions linguistics knowledge representations. also grateful nikos anerousis anup kalia maja vukovic xiao helpful conversations. facebook authentication service offered facebook facebook authentication service offered facebook tidal generalized gravitational effect gravitational effect depends distance gravitational effect depends mass cntains) follows) follows) cntaind) follows) moon satellite distortion) expr-by) cntaind) follows) hasprop) cntains) apprxnr) follows) follows) hierarchy increasing invariance. following excerpted diagrams help illustrate different aspects fully cyclic graph links picking particular ‘parse trees’ full structure. example expression explained event professor plum murders miss scarlet library breadknife won’t marry him’ shown ﬁgure central propositions understood contexts composed hierarchy concepts. complex temporary proposition point possibly ephemeral permanance degree invariance permanence increasing outwards rings around reaching maximum primitive concepts. note intermediate levels conceptual aggregation full expression. could arge eliminated ﬂattened ﬁgure obfuscates reuse concepts ranking permanence. might argue structure difﬁcult automate levels semantics cannot inferred level proposition; however thinking upside down. sensors evolved imprint semantics bottom. propositions based semantics make sense context formed figure shows sensory inputs anomalies might contribute formation context structure. simply collecting data sensors alone advance towards clear human understanding relationships without skeleton model imprint data. nature might occur form spontaneous symmetry breaking separation timescales persistent structures skeleton shorter timescale corrections attract. weakly non-linear feedback lead emergent structure results humanly comprehensible unless particular conceptual structures evolved ourselves. thus pure emergence right bring human inspectable results. hierarchy start invariances levels permanance timescale sensitivity. short term context built long-term concepts create sense ‘here now’. aggregated main structure contains fragments narrative meaning longer timescale. turn reduce core long-term concepts again. sequence chases tail acyclic decomposition rather eigenstate cyclic graph. consider example system measurment website trafﬁc sushi restaurant called ‘jaws’ high users getting muddled looking tickets festival featuring steven spielberg movie ‘jaws’. connection would allow make inference clearly name jaws without particular semantics. postulate kinds specialized sensor semaphores need construct cognitive narrative. fig. representation context around event ‘professor plum murders miss scarlet breadknife library refused marry him’. hierarchy concepts least invariance single proposition becomes increasingly invariant father towards edges. note context envelops concepts includes costs much terms processing. compensation much structure temporary leaves behind smaller cheaper residue. high level assume sensors aggregations done jobs construct graph obtain picture something like ﬁgures causal parsing based sensor anomaly makes connection inputs different sensory semaphores attributing high trafﬁc trunk line hits website sushi restaurant. happens name popular movie festival. confusion websites real reason anomalous trafﬁc. brainstorming analysis stop ﬁnding presumed ‘root cause’ however wandering territory since reason eliminate pathways. major task solved future work selection relevant pathways boundaries. stephen tratz eduard hovy. taxonomy dataset classiﬁer automatic noun compound interpretation. proceedings annual meeting association computational linguistics pages association computational linguistics r.h. dieck. measurement uncertainty instrument systems automation society triangle park north carolina third edition edition schwinger. quantum kinematics dynamics. addison wesley fig. causal parsing making connection inputs different sensory semaphores attributing high trafﬁc trunk line hits sushi restaurant happens name popular movie festival. analysis stop ﬁnding presumed ‘root cause’ wandering territory since reason eliminate pathways. couch burgess. human-understandable inference proc. international workcausal relationships. shop knowledge management future services networks osaka japan mikolov zweig. linguistic regularities continuous space word representations. proceedings conference north american chapter association computational linguistics human language technologies pages burgess skipitaris. adaptive locks frequently scheduled tasks unpredictable runtimes. proceedings eleventh systems administration conference page", "year": 2017}