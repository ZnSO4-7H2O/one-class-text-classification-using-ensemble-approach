{"title": "Language as a matrix product state", "tag": ["cs.CL", "cond-mat.dis-nn", "cs.LG", "cs.NE", "stat.ML"], "abstract": "We propose a statistical model for natural language that begins by considering language as a monoid, then representing it in complex matrices with a compatible translation invariant probability measure. We interpret the probability measure as arising via the Born rule from a translation invariant matrix product state.", "text": "abstract. propose statistical model natural language begins considering language monoid representing complex matrices compatible translation invariant probability measure. interpret probability measure arising born rule translation invariant matrix product state. acknowledgements trace-density model language structures corpus text trace density representations trace-density model corpus text graphical language tensor networks density identity constraints right density constraint left density constraint quantum physical interpretation trace density models finding trace-density models references statistical language modelling whose capture joint probability distribution sequences words applications problems including information retrieval speech recognition artiﬁcial intelligence human-machine interfaces translation natural language problems involve incomplete information. early successes statistical language models industry include next-word prediction vector embeddings words based colocation reasonable performance word similiarity exams. efforts build early successes encounter difﬁculties arising high-dimensionality data—the number meaningful texts lanugage exponentially smaller number texts room full randomly typing monkeys could produce approach address curse high-dimensionality truncate sequences consideration ﬁnite length phrases n-grams employ hidden markov model. since hidden markov models essentially cutoff correlations words beyond ﬁxed distance success approach depends application. example -gram -gram models employed effectively speech recognition translation applications long distance correlations limited importance however n-gram models belie essential critical behavior inherent language human languages like many biological systems including families proteins genomes neurons brain notes musical symphony signiﬁcant long-range correlations decay power contrast markov hidden-markov system n-gram model long range correlations decay exponentially. recently long-short term memory recurrent neural networks employed produce statistical language model applications considerately outperform based hidden markov models. notably google’s neural machine translation system technology google voice advanced state translation speech recognition. much unknown deep networks operate research indicates hard match long range higher order statistics natural languages even lstm recurrent neural networks certain applications translating phrases matching higher order statistics important artiﬁcial intelligence applications machine determination humorous deceptive narratives essential. order develop statistical language model capable capturing higher order statistics language turn quantum statistical physics contains models solvable lattice models exhibit correlation functions decay power law—the kind critical behavior biological systems. unlike classical statistical physics spacial dimension sufﬁces exhibit criticality quantum statistical physics even dimensional quantum statistical language model could better alternative lstm recurrent neural networks likened classical statistical physics. entanglement quantum many body system metaphorical vehicle statistical correlation language serves proposed method attack highdimensionality data. number basis states quantum many body system makes state-space large work entirely number physically relevant states occupy subspace exponentially smaller dimension accessible restricting low-energy. paper introduce simple translation-invariant quantum statistical language model one-dimensional lattice call trace-density model. tracedensity model isn’t critical experimental ﬁrst step toward critical quantum model language. model involves matrix-product-states approximate power–law decays over quite long distances cubic constraintes introduced. constraints physically motivated mathematically related moment based maximizing entropy minimizing energy similar what’s described developed density matrix renormalization used. model introduced ﬁrst using representation theoretic language interpretted using physical language mps. related language model based isometric tensor network considered acknowledgements. authors would like thank maxim kontsevich miles stoudenmire helpful stimulating discussions. research v.p. project received funding european research council european union’s horizon research innovation program j.t. supported part grant army research development engineering command mathematical sciences division -ma-ii; y.v. received funding simons foundation award mathematical model called trace-density model corpus text described three steps. first input structures related corpus text explained notation ﬁxed. second concept trace-density representation corpus deﬁned. third property representation must possess order considered trace-density model given. elements vocabulary words denote typical words letter vocabulary comprised symbols representing atomic elements corpus constructed sequence. denote phrases contained corpus phrase ﬁnite subsequence consisting adjacent elements. phrases structure merely set. graded—each phrase well deﬁned length given number words comprising phrase phrases disjoint union sets phrases word length tion phrases. adding formal zero phrase graded component product extended deﬁning product phrases zero concatanation phrase contained corpus. product compatible grading sufﬁciently large probability distribution considered approximation nonexistent idealized probability distribution phrases language corpus observed sample. goal model collection idealized probability distributions. trace density representations. density hilbert space positive semideﬁnite operator here ﬁnite dimension work entirely standard inner product operators identiﬁed matrices. density deﬁnes nonnegative real valued function matd×d complex matrices here superscript denotes complex conjugate transpose denotes trace. element mpm∗ nonegative real number dictionary assigns complex matrix word vocabulary extends function md×d phrases mapping phrase mapped matrix trace density trace density representation nonegative real valued function deﬁned store matrices assigned phrases sentences paragraphs etc... relatively efﬁcient computation required matrix product polynomial dimension representation linear number words. denote complex n-dimensional vector space generated vocabulary. dictionary d-dimensional trace-density representation assembled single extending assignment linearly. single described complex numbers {miab} deﬁnes tensor order particular number miab entire describe pair technically important constraints trace-density representation called left density constraint right density constraint. constraints guarantee trace-density abstract properties required joint-probability distributions phrases language. constraints also physical interpretation model describe section trace-density phrase nonnegative real number priori restrictions. density constraint however implies trace-density representation gives rise probability distributions length phrases right density constraint together left density constraint imply probability distributions deﬁned trace-density together joint probabilities sequences words probability distributions phrases different length related marginal probability distributions. note left right density constraints cubic entries matrices constraints imply inﬁnitely many higher order constraints stated proposition proposition required joint distributions determined trace-density together must statistical language model. section relates quantum physical interpretation trace density model language. imagine word quantum system consisting single particle possible states—each word vocabulary possible state. n-dimensional complex vector space generated vocabulary space becomes hilbert orthonormal basis consisting vectors wii...ik ⊗···⊗ state many body system unit trace density probability system observed state wi...ik projection wi...ik density induces density note decomposition unique. even ﬁxed auxillary spaces large gauge group acting decomposition. example automorphisms nontrivially decomposition ﬁxing state obtained contraction. trace-density model language attempts approximate pure state translation invariant mps. putting aside moment happens left right boundaries translation invariant involves single auxillary space dimension consider boundary conditions. assume state essentially inﬁnite number copies then ﬁnite partial trace induces state tracing left right yields density pictured shows representations satisfying left density right density constraints exist. describe moduli space constrained representations note left density constraint form isometry constraint tensor considered moreover automorphism group preserving hermitian form. modulo action automorphism group moduli space tensors satisfy left density constraint grassmanian d-dimensional complex planes nd-dimensional complex left density right density constraints make possible numerically trace-density model maximum log-likelihood algorithm idea trace-density representation maximizes trace-density training corpus. intuitively constraints make certain total trace density possible phrases ﬁxed length equal maximizing trace-densities phrases corpus automatically make exponential number nonsense phrases nearly zero trace-density.", "year": 2017}