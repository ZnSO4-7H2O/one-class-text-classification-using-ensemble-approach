{"title": "Unsupervised Learning of Disentangled and Interpretable Representations  from Sequential Data", "tag": ["cs.LG", "cs.CL", "cs.SD", "eess.AS", "stat.ML"], "abstract": "We present a factorized hierarchical variational autoencoder, which learns disentangled and interpretable representations from sequential data without supervision. Specifically, we exploit the multi-scale nature of information in sequential data by formulating it explicitly within a factorized hierarchical graphical model that imposes sequence-dependent priors and sequence-independent priors to different sets of latent variables. The model is evaluated on two speech corpora to demonstrate, qualitatively, its ability to transform speakers or linguistic content by manipulating different sets of latent variables; and quantitatively, its ability to outperform an i-vector baseline for speaker verification and reduce the word error rate by as much as 35% in mismatched train/test scenarios for automatic speech recognition tasks.", "text": "present factorized hierarchical variational autoencoder learns disentangled interpretable representations sequential data without supervision. speciﬁcally exploit multi-scale nature information sequential data formulating explicitly within factorized hierarchical graphical model imposes sequence-dependent priors sequence-independent priors different sets latent variables. model evaluated speech corpora demonstrate qualitatively ability transform speakers linguistic content manipulating different sets latent variables; quantitatively ability outperform i-vector baseline speaker veriﬁcation reduce word error rate much mismatched train/test scenarios automatic speech recognition tasks. unsupervised learning powerful methodology leverage vast quantities unannotated data order learn useful representations incorporated subsequent applications either supervised unsupervised fashions. principle approaches unsupervised learning probabilistic generative modeling. recently signiﬁcant interest three classes deep probabilistic generative models variational autoencoders generative adversarial networks auto-regressive models recently also studies combining multiple classes models gans bypass inference latent variables auto-regressive models abstain using latent variables vaes jointly learn inference model generative model allowing infer latent variables observed data. despite successes vaes understanding underlying factors latent variables associate major challenge. research focuses supervised semi-supervised setting using vaes also research attempting develop weakly supervised unsupervised methods learn disentangled representations dc-ign infogan β-vae another line research analyzing latent variables labeled data model trained much research investigating static data aforementioned ones relatively little research learning sequential data moreover best knowledge attempt learn disentangled interpretable representations without supervision sequential data. information encoded sequential data speech video text naturally multi-scaled; speech example information channel speaker linguistic content encoded statistics session utterance segment levels respectively. leveraging source constraint learn disentangled interpretable factors unsupervised manner. paper propose novel factorized hierarchical variational autoencoder learns disentangled interpretable latent representations sequential data without supervision figure fhvae decoding results three combinations latent segment variables latent sequence variables utterances aurora- clean noisy fhvaes learn encode local attributes linguistic content encode global attributes noise level therefore replacing noisy utterance clean utterance fhvae decodes denoised utterance preserves linguistic content. reconstruction results clean noisy utterances also shown right. audio samples available https//youtu.be/najzitvcfi. explicitly modeling multi-scaled information factorized hierarchical graphical model. inference model designed model optimized segment level instead sequence level cause scalability issues sequences become long. sequence-to-sequence neural network architecture applied better capture temporal relationships. evaluate proposed model speech datasets. qualitatively model demonstrates ability factorize sequence-level segment-level attributes different sets latent variables. quantitatively model achieves equal error rate unsupervised supervised speaker veriﬁcation tasks respectively outperforms i-vector baseline. speech recognition tasks reduces word error rate mismatched train/test scenarios rest paper organized follows. section introduce proposed model describe neural network architecture section experimental results reported section discuss related work section conclude work well discuss future research plans section generation sequential data speech often involves multiple independent factors operating different time scales. instance speaker identity affects fundamental frequency volume sequence level phonetic content affects spectral contour durations formants segmental level. multi-scale behavior results fact attributes volume tend smaller amount variation within utterance compared utterances; attributes phonetic content tend similar amount variation within utterances. refer ﬁrst type attributes sequence-level attributes segment-level attributes. work achieve disentanglement interpretability encoding types attributes latent sequence variables latent segment variables respectively former regularized sequence-dependent prior latter sequence-independent prior. formulate generative process speech propose factorized hierarchical variational autoencoder consider dataset consisting i.i.d. sequences {x}n sequence observed variables. referred number segments i-th sequence referred n-th segment i-th sequence. note segment refers variable smaller temporal scale compared sequence fact sub-sequence. drop index whenever clear referring terms associated single sequence. assume sequence generated random process involving latent variables following generation process illustrated figure considered s-vector drawn prior distribution i.i.d. latent segment variables drawn sequence-dependent prior distribution sequence-independent prior distribution respectively; i.i.d. observed variables {x}n drawn conditional distribution joint probability sequence formulated priors s-vectors latent segment variables centered isotropic multivariate gaussian distributions. prior latent sequence variable conditioned isotropic multivariate gaussian centered conditional distribution observed variable multivariate gaussian diagonal covariance matrix whose mean diagonal variance parameterized neural networks input denote parameters generative model. generative model factorized latent sequence variables within sequence forced close well euclidean distance therefore encouraged encode sequence-level attributes larger variance across sequences smaller variance within sequences. constraint latent segment variables imposed globally therefore encourages encoding residual attributes whose variation distinguishable inter intra sequences. variational autoencoder tractable inference model inference model figure part inference model parameters utterance would optimized training. therefore denote posterior mean i-th sequence; posterior covariance matrix also neural sequences. similar generative model denoted collectively variational lower networks whose parameters along bound inference model marginal likelihood sequence derived follows detailed derivation found appendix approximated posterior depend sequence sequence variational lower bound decomposed l|˜µ) conditional segment variational lower bounds segments plus prior probability constant. therefore instead sampling batch sequence level maximize sequence variational lower bound sample batch segment level maximize segment variational lower bound approach provides better scalability sequences extremely long computing entire sequence batched update computationally expensive. paper introduce scales attributes; however easily extend model scales simply introducing constrains prior distribution latent variables scales session-dependent prior dataset-dependent prior. idea sequence-speciﬁc priors sequence encourage model encode sequence-level attributes segment-level attributes different sets latent variables. however sequences prior probability s-vector maximized kl-divergence inferred posterior measured conditional prior sequences. would result trivial s-vectors therefore would factorized encode sequence segment attributes respectively. testing want s-vector unseen sequence {˜x} sequence-level attribute representation tasks speaker veriﬁcation. since exact maximum posterior estimation intractable approximate estimation using conditional segment variational lower bound follows section introduce detailed neural network architectures proposed fhvae. segment sub-sequence contains time steps denotes t-th time step recurrent network architectures encoders capture temporal relationship among time steps generate summarized ﬁxed-dimension vector consuming entire sub-sequence. likewise adopt recurrent network architecture generates frame step step conditioned latent variables complete network seen stochastic sequence-to-sequence autoencoder encodes stochastically stochastically decodes back figure sequence-to-sequence factorized hierarchical variational autoencoder. dashed lines indicate sampling process using reparameterization trick encoders pink amber respectively decoder blue. darker colors denote recurrent neural networks lighter colors denote fully-connected layers predicting mean variance. lstm refers long short-term memory recurrent neural network refers multi-layer perceptron related weight matrices. none neural network parameters shared. refer model seqseq-fhvae. log-likelihood qualitative comparison alternative architectures found appendix speech inherently contains information multiple scales channel speaker linguistic content test model. learning disentangle mixed information surface representation essential wide variety speech applications example noise robust speech recognition speaker veriﬁcation voice conversion following corpora used experiments timit contains broadband recordings phonetically-balanced read speech. total utterances presented sentences speakers approximately male female. aurora- broadband corpus designed noisy speech recognition tasks based wall street journal corpus microphone types clean/channel included noise types artiﬁcially added microphone types results four conditions clean channel noisy channel+noisy. hour training sets used clean four conditions. noise types microphones used generate development test sets consist utterances four conditions resulting utterances total set. speech represented sequence dimensional mel-scale ﬁlter bank features dimensional log-magnitude spectrum computed every mel-scale features popular auditory approximation many speech applications consider sample sub-sequence order length syllable implies seqseq-fhvae model lstm networks one-layered adam used optimization. details model architecture training procedure found appendix figure examples generated varying different latent variables. illustration harmonics formants ﬁlter bank images. green block contains four reconstructed examples. block contains original sequences ﬁrst corresponding reconstructed examples second row. entry i-th j-th column blue block reconstructed example using latent segment variable i-th block latent sequence variable j-th column block ‘b’. qualitatively study factorization information latent segment variable latent sequence variable generate examples varying respectively. figure shows examples block combinations latent segment variables extracted block latent sequence variables extracted block ‘b.’ examples block leftmost examples block male speakers rest female speakers show higher fundamental frequencies harmonics. figure fhvae decoding results three combinations latent segment variables latent sequence variables male-speaker utterance female-speaker utterance aurora-. replacing male-speaker utterance femalespeaker utterance fhvae decodes voice-converted utterance preserves linguistic content. audio samples available https//youtu.be/vmxizywydg. observe along block linguistic phonetic-level content manifests form spectral contour temporal position formants well relative position formants similar elements; speaker identity however changes hand column speaker identity remains consistent despite change linguistic content. factorization sequence-level attributes segment-level attributes proposed seqseq-fhvae clearly evident. addition also show examples modifying entire utterance figure achieves denoising replacing latent sequence variable noisy utterance clean utterance achieves voice conversion replacing latent sequence variable speaker another speaker. details operations applied modify entire utterance well larger-sized examples different values found appendix also show extra latent space traversal experiments appendix quantify performance model disentangling utterance-level attributes segment-level attributes present experiments speaker veriﬁcation task timit corpus evaluate well estimated encodes speaker-level information. sanity check modify estimate alternative s-vector based latent segment variables follows i-vector method baseline representation used state-of-the-art speaker veriﬁcation systems. dimensional subspace gaussian mixture model mean supervector space universal background model models generative process speech. i-vectors extracted without supervision; speaker labels available training techniques linear discriminative analysis applied improve linear separability representation. experiments fast scoring approach uses cosine similarity similarity metric compute equal error rate details experimental settings found appendix compare different dimensions features well different training fhvae models. results table show dimensional s-vectors outperform i-vector baselines unsupervised supervised settings shown fourth column; discriminatively fhvae model trained better speaker timit standard corpus speaker veriﬁcation good corpus show utterance-level attribute learned task main attribute consistent within utterance speaker identity aurora- speaker identity background noise consistent within utterance. veriﬁcation results achieves. moreover appropriately chosen dimension dimensional reaches even lower hand negative results using also validate success disentangling utterance segment level attributes. speaker adaptation robust speech recognition automatic speech recognition often seen domain adaptation problems available labeled data limited hence data distributions training testing mismatched. approach reduce severity issue extract speaker/channel invariant features tasks. demonstrated section s-vector contains information domains. evaluate latent segment variables contains domain invariant linguistic information evaluating task train proposed seqseq-fhvae using fbank feature covers different domains. train lstm acoustic model covers partial domains using mean variance latent segment variable extracted trained seqseq-fhvae. test system domains. baseline also train models fbank features alone. detailed conﬁgurations appendix timit assume male female speakers constitute different domains show results table ﬁrst results shows model trained domains using fbank features upper bound. trained male speakers phone error rate female speakers increases fbank features; however despite slight degradation male speakers unseen domain female speakers improves compared fbank features. aurora- four domains considered clean noisy channel noisy+channel train fhvae development purposes fhvae considered general feature extractor trained arbitrary collection data necessarily include data subsequent applications. aurora- contains domain label utterance possible control domain observed fhvae. table shows word error rate results aurora- observe fbank representation suffers severe domain mismatch problems; speciﬁcally increases noise presented mismatched microphone recordings contrast fhvae trained data domains using latent segment variables features reduce compare baseline mismatched domains less degradation matched domain. addition β-vaes trained data fhvae serve baseline feature extractor extract latent variables feature show result third sixth rows. β-vae features outperform fbank mismatched domains inferior latent segment variable fhvae domains. results demonstrate importance learning disentangled also interpretable representations achieved proposed fhvae models. sanity check replace latent sequence variable train results terrible performance shown eighth expected. finally train another fhvae domains excluding combinatory domain shows results last table observed latent segment variable still outperforms baseline feature lower noise channel combined data even though fhave seen noise channel variation independently. number prior publications extended vaes model structured data altering underlying graphical model dynamic bayesian networks srnn vrnn hierarchical models neural statistician svae models shown success quantitatively increasing log-likelihood qualitatively generating reasonable structured data sampling. however remains unclear whether independent attributes disentangled latent space. moreover learned latent variables models interpretable without manually inspecting using labeled data. contrast work presents framework addresses problems explicitly modeling difference rate temporal variation attributes operate different scales. work also related β-vae respect unsupervised learning disentangled representations vaes. boosted kl-divergence penalty imposed β-vae training encourages disentanglement independent attributes provide interpretability without supervision. demonstrate domain invariant experiments learning interpretable representations important applications achieved fhvae model. addition idea boosting kl-divergence regularization complimentary model potentially integrated better disentanglement. introduce factorized hierarchical variational autoencoder learns disentangled interpretable representations sequence-level segment-level attributes without supervision. verify disentangling ability qualitatively quantitatively speech corpora. future work plan extend levels hierarchy investigate adversarial training disentanglement apply model types sequential data text videos. infogan interpretable representation learning information maximizing generative adversarial nets. advances neural information processing systems page junyoung chung kyle kastner laurent dinh kratarth goel aaron courville yoshua bengio. recurrent latent variable model sequential data. advances neural information processing systems pages najim dehak reda dehak patrick kenny niko brümmer pierre ouellet pierre dumouchel. support vector machines versus fast scoring low-dimensional total variability space speaker veriﬁcation. interspeech volume pages najim dehak patrick kenny réda dehak pierre dumouchel pierre ouellet. front-end factor analysis speaker veriﬁcation. ieee transactions audio speech language processing john garofolo lori lamel william fisher jonathon fiscus david pallett. darpa timit acoustic-phonetic continous speech corpus cd-rom. nist speech disc nasa sti/recon technical report goodfellow jean pouget-abadie mehdi mirza bing david warde-farley sherjil ozair aaron courville yoshua bengio. generative adversarial nets. advances neural information processing systems pages alex graves navdeep jaitly abdel-rahman mohamed. hybrid speech recognition deep bidirectional lstm. automatic speech recognition understanding ieee workshop pages ieee irina higgins loic matthey arka christopher burgess xavier glorot matthew botvinick shakir mohamed alexander lerchner. beta-vae learning basic visual concepts constrained variational framework. wei-ning zhang james glass. unsupervised domain adaptation robust speech recognition variational autoencoder-based data augmentation. automatic speech recognition understanding ieee workshop ieee matthew johnson david duvenaud alex wiltschko ryan adams sandeep datta. composing graphical models neural networks structured representations fast inference. advances neural information processing systems pages diederik kingma shakir mohamed danilo jimenez rezende welling. semi-supervised learning deep generative models. advances neural information processing systems pages toru nakashika tetsuya takiguchi yasuhiro minami toru nakashika tetsuya takiguchi yasuhiro minami. non-parallel training voice conversion using adaptive restricted boltzmann machine. ieee/acm trans. audio speech lang. proc. november douglas paul janet baker. design wall street journal-based corpus. proceedings workshop speech natural language pages association computational linguistics daniel povey arnab ghoshal gilles boulianne lukas burget ondrej glembek nagendra goel mirko hannemann petr motlicek yanmin qian petr schwarz kaldi speech recognition toolkit. ieee workshop automatic speech recognition understanding number epfl-conf-. ieee signal processing society iulian vlad serban alessandro sordoni ryan lowe laurent charlin joelle pineau aaron courville yoshua bengio. hierarchical latent variable encoder-decoder model generating dialogues. thirty-first aaai conference artiﬁcial intelligence aäron oord sander dieleman heiga karen simonyan oriol vinyals alex graves kalchbrenner andrew senior koray kavukcuoglu. wavenet generative model audio. corr abs/. dong adam eversole mike seltzer kaisheng zhiheng huang brian guenter oleksii kuchaiev zhang frank seide huaming wang introduction computational networks computational network toolkit. technical report tech. rep. microsoft research http//codebox/cntk zhang guoguo chen dong kaisheng yaco sanjeev khudanpur james glass. highway long short-term memory rnns distant speech recognition. ieee international conference acoustics speech signal processing pages ieee expected kl-divergence gaussian distributions gaussian computed analytically. dimensionality denote variational mean standard deviation evaluated ˆµzj ˆσzj denote j-th element vectors. have described section inference s-vector unseen utterance {˜x} cast approximated maximum posterior estimation problem uses conditional segment variational lower bound l|µ) approximate conditional likelihood segment pθ|µ). dimensionality denote variational mean evaluated denote j-th element vectors. optimal seqseq-fhvae model network consists layer hidden units network layer output dimension equal variable whose mean variance parameterizes variances experiment various dimensions latent variable models trained stochastic gradient descent using mini-batch size minimize negative discriminative segment variational lower bound plus l-regularization weight adam optimizer used initial learning rate training continues epochs unless segment variational lower bound development improve epochs. sequences development test estimated using closed form solution section study performance proposed architecture replacing lstm module three baseline architectures fully-connected feed-forward network vanilla recurrent neural network gated recurrent neural network models hidden layer dimensions trained model entire segment ﬂattened feed fully-connected layers; therefore temporal structure simply ignored. table shows segment variational lower bound timit test set. recurrent models outperform feed-forward model using fewer parameters demonstrates importance considering temporal structure within segment. figure shows reconstruction results using model lstm model. lstm model reconstructs sharper images preserves speech detail particular presents superior high frequency harmonic structure model highlighted boxes. figure three examples different speakers. within example left right original segment reconstructed segment lstm reconstructed segment. leftmost images show expanded views higher frequency harmonic structure spectrogram suggesting lstm reconstruction superior model. figure shows zoomed-in version left part figure observe harmonic patterns clearly. figure illustrate results experiments model trained aurora- corpus instead. particular sample speakers test choose four noise conditions clean babble restaurant without microphone channel effect. furthermore since noise artiﬁcially added clean utterance test actually choose corresponding segment different noise conditions given speaker. eight examples used block block results combinations latent segment variables latent sequence variables total. observed latent sequence variables capture speaker information also noise information sequence-level attributes. therefore modifying latent sequence variables transform speaker identities also carry denoising noise corruption. moreover disentanglement evident model trained without discriminative training model trained discriminative training figure examples generated varying different latent variables fhvae model trained timit dataset. green block contains four reconstructed examples. block contains original examples ﬁrst corresponding reconstructed examples second row. entry i-th j-th column blue block reconstructed example using latent segment variable i-th block latent sequence variable j-th column block ‘b.’ addition transforming single segment also interested transforming target sequence xtar different speaker different noise condition reference sequence xref mathematically means mapping distribution latent sequence variable xtar xref since distributions gaussian covariance matrices centered s-vectors µtar µref simple solution shift latent sequence variable s-vector difference µref −µtar. therefore transform target utterance given reference utterance shifting segment target utterance decode-and-concatenate segment using unmodiﬁed modiﬁed figure shows examples modifying entire utterances achieves voice conversion denoising respectively. figure examples generated varying fhvae models trained respectively aurora- dataset. green block block contains eight examples test set. block original examples shown ﬁrst corresponding reconstructed examples shown second row. entry i-th j-th column blue block reconstructed example using latent segment variable i-th block latent sequence variable j-th column block ‘b.’ veriﬁcation performance reported terms equal error rate false rejection rate equals false acceptance rate. baseline system i-vectors provided kaldi extracted using mel-frequency cepstral coefﬁcients plus delta delta-delta voice activity detection full-covariance gender-independent mixtures trained training i-vector dimensionality tuned development set. veriﬁcation pairs created test target/non-target. total speakers pairs testing. seqseq-fhvae model dimension closed form solution inferred s-vector mentioned section represent utterance veriﬁcation. gaussian mixture model-hidden markov models systems built ﬁrst generate senone alignments later neural network acoustic model training replaces acoustic model. tasks gmm-hmm system built kaldi using standard recipes. lstm acoustic model hybrid dnn-hmm system implemented using cntk toolkit. training recipe follows baseline uses -dimensional fbank features input. model lstm-projection layers layer cells output projected figure fhvae decoding results three combinations latent segment variables latent sequence variables clean utterance utterance noise aurora-. replacing noisy utterance clean utterance fhvae decodes denoised utterance preserves linguistic content. audio samples available https//youtu.be/popdvzwrjm. figure fhvae decoding results three combinations latent segment variables latent sequence variables female-speaker utterance male-speaker utterance aurora-. replacing female-speaker utterance male-speaker utterance fhvae decodes voice-converted utterance preserves linguistic content. audio samples available https//youtu.be/rurjbynrs. dimensional space. truncated bptt used train lstm unrolls frames; utterances processed parallel form mini-batch. seqseq-fhvae model conﬁguration achieved best result speaker veriﬁcation task dimensional weight discriminative training. model dimension latent variable number hidden units lstm encoder doubled latent variable dimension number hidden units encoder compared fhvae model model latent variables encoder. therefore fhvae models would comparable number parameters well latent space dimensionalities. section present qualitative analysis traversing single latent sequence variable latent segment variable range keeping remaining latent variables ﬁxed. corresponds different seed pair inferred seed segment randomly drawn test set. leftmost column ﬁgure shows seed segments row. seed segments traversing latent variable. fhvae model trained timit dimensional log-magnitude spectrum used frame feature representations. figures show examples traversing four different latent segment variables keeping latent sequence variables ﬁxed. observed latent segment variables encode information segment-level attributes speech data rising/falling back vowel/front vowel vowel/fricative closure/non-closure. contrast figures illustrate examples traversing four different latent sequence variables keeping latent segment variables ﬁxed. seen spectral contour temporal position relative frequency-axis position formants remain almost intact traversing latent sequence variables. attributes changed traversing latent sequence variables related sequence-level attributes harmonic patterns volume offsets formant frequencies. results demonstrate ability proposed fhvae learn disentangled representations also enable interpretation information captured different sets latent variables.", "year": 2017}