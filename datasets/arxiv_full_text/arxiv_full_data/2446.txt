{"title": "Matroid Bandits: Fast Combinatorial Optimization with Learning", "tag": ["cs.LG", "cs.AI", "cs.SY", "stat.ML"], "abstract": "A matroid is a notion of independence in combinatorial optimization which is closely related to computational efficiency. In particular, it is well known that the maximum of a constrained modular function can be found greedily if and only if the constraints are associated with a matroid. In this paper, we bring together the ideas of bandits and matroids, and propose a new class of combinatorial bandits, matroid bandits. The objective in these problems is to learn how to maximize a modular function on a matroid. This function is stochastic and initially unknown. We propose a practical algorithm for solving our problem, Optimistic Matroid Maximization (OMM); and prove two upper bounds, gap-dependent and gap-free, on its regret. Both bounds are sublinear in time and at most linear in all other quantities of interest. The gap-dependent upper bound is tight and we prove a matching lower bound on a partition matroid bandit. Finally, we evaluate our method on three real-world problems and show that it is practical.", "text": "matroid notion independence combinatorial optimization closely related computational efﬁciency. particular well known maximum constrained modular function found greedily constraints associated matroid. paper bring together ideas bandits matroids propose class combinatorial bandits matroid bandits. objective problems learn maximize modular function matroid. function stochastic initially unknown. propose practical algorithm solving problem optimistic matroid maximization prove upper bounds gap-dependent gap-free regret. bounds sublinear time linear quantities interest. gap-dependent upper bound tight prove matching lower bound partition matroid bandit. finally evaluate method three real-world problems show practical. combinatorial optimization well-established ﬁeld many practical applications ranging resource allocation designing network routing protocols modern combinatorial optimization problems often massive even low-order polynomial-time solutions practical. fortunately many important problems ﬁnding minimum spanning tree solved greedily. problems often viewed optimization matroid notion independence combinatorial optimization closely related computational efﬁciency. particular well known maximum constrained modular function found greedily feasible solutions problem inpaper propose algorithm learning maximize stochastic modular function matroid. modular function represented weights items chosen ground matroid items. weights items stochastic represented vector vector drawn i.i.d. probability distribution distribution initially unknown learn interacting repeatedly environment. many real-world optimization problems formulated setting building spanning tree network routing delays links network stochastic distribution known problem solved ﬁnding minimum spanning tree. distribution unknown must learned perhaps exploring routing networks seem initially suboptimal. return problem experiments. paper makes three main contributions. first bring together concepts matroids bandits propose class combinatorial bandits matroid bandits. hand matroid bandits viewed learning framework broad important class combinatorial optimization problems. hand matroid bandits class k-step bandit problems solved computationally sample efﬁciently. second propose simple greedy algorithm solving problem explores based optimism face uncertainty. refer approach optimistic matroid maximization computationally sample efﬁcient. particular time complexity episode comparable sorting numbers. moreover expected cumulative regret sublinear number episodes linear number items maximum number chosen items minimum spanning tree cannot computed weights edges unknown. happen practice. instance consider problem building routing network represented spanning tree expected delays links network initially unknown. work study variant maximizing modular function matroid address kind problems. formalize learning problem matroid bandit. matroid bandit pair matroid probability distribution weights items e-th entry weight item weights stochastic drawn i.i.d. distribution denote expected weights items assume weights non-negative item associated assume multiple arms pulled. subset arms pulled independent set. return pulling arms weights items arms pulled observe weight item model feedback known semi-bandit assume matroid known distribution unknown. without loss generality assume support bounded subset would like stress make structural assumptions ﬁrst problem learn routing networks. second problem learn policy assigning loans microﬁnance network maximizes chances loans repaid. third problem learn movie recommendation policy. three problems solved efﬁciently framework. demonstrates practical solve wide range real-world problems. matroids matroid pair items called ground family subsets called independent sets. family deﬁned following properties. first second every subset independent independent. finally must exist item known augmentation property. denote well-known combinatorial optimization problem. problem solved greedily greedy algorithm main stages. first initialized second items ground sorted according weights highest lowest greedily added order. item added make dependent. learning problem episodic. episode choose basis gain realization stochastic weights episode goal learn policy sequence bases minimizes expected cumulative regret episodes solution designed based optimism face uncertainty principle particular variant greedy method ﬁnding maximum-weight basis matroid expected weight item substituted optimistic estimate therefore refer approach optimistic matroid maximization ˆwete estimate beginning episode ct−te represents radius conﬁdence interval around estimate number times chooses item episode second order items ucbs highest lowest greedily order. item added make dependent. finally choose basis observe weights items basis update model world. deﬁned upper conﬁdence bound high probability upper bound weight role ucbs encourage exploration items chosen often. number episodes increases estimates weights improve starts exploiting best items. term increases time enforces exploration avoid linear regret. greedy algorithm therefore extremely computationally efﬁcient. particular time complexity checking independence time complexity episode comparable sorting numbers. design algorithm surprising motivated prior work main challenge derive tight upper bound regret would reﬂect structure problem. section analyze regret omm. analysis organized follows. first introduce basic concepts notation. second show decompose regret single episode. particular partition regret suboptimal basis regrets individual items. part analysis relies heavily structure matroid novel. third derive upper bounds gap-dependent gap-free regret omm. fourth prove lower bound matches gap-dependent upper bound. finally summarize results analysis. last inequalities follow fact bijection every item suboptimal basis matched unique item remarkable aspect regret decomposition exact form bijection required rest analysis. rely properties stated theorem assume items ordered k-th item highest expected weight. episode chooses basis k-th item chosen omm. item suboptimal belongs suboptimal items. pair suboptimal optimal items deﬁne decomposition motivated observation bases matroid cardinality. result difference expected values bases always written differences weights items. particular bijection lemma important properties. first choose item step however selects design happen item item result know steps second lemma guarantees every optimal item paired item rest paper represent bijection using indicator function. indicator function upper bounds reasonably tight. speciﬁcally gap-dependent upper bound theorem matches lower bound theorem proved partition matroid bandit. furthermore gap-free upper bound theorem matches lower bound audibert adversarial combinatorial semi-bandits factor gap-dependent upper bound form bound auer multi-armed bandits. observation suggests sample complexity learning maximum-weight basis matroid comparable multi-armed bandit. major difference deﬁnitions gaps. conclude learning matroids extremely sample efﬁcient. experiments episodic. episode selects basis observes weights individual items basis updates model environment. performance measured expected perstep return episodes expected cumulative return episodes divided compared baselines. ﬁrst baseline maximum-weight basis expectation. basis computed equation notion optimality. derive asymptotic lower bound expected cumulative regret dependence upper bound theorem bound proved class matroid bandits equivalent bernoulli bandits. partition matroid rank probability distribution weights items weight item distributed independently items. weight item drawn i.i.d. bernoulli distribution mean partition matroid bandit. property equivalent independent bernoulli bandits partition. optimal item partition item smallest index mini∈bk gaps formalize result need introduce notion consistent algorithms. algorithm consistent matroid bandit suboptimal number times item chosen episodes. rest analysis focus consistent algorithms. without loss generality. particular deﬁnition inconsistent algorithm performs poorly problems therefore extremely well others. this difﬁcult prove good problem-dependent lower bounds inconsistent algorithms. main claim below. theorem partition matroid bandit deﬁned equations parameterized regret consistent algorithm bounded table description networks experiments expected per-step cost building minimum spanning trees networks episodes. latencies costs milliseconds. ﬁrst experiment evaluate problem learning routing network internet service provider make assumption routing network spanning tree. objective learn tree lowest expected latency edges. problem formulated graphic matroid bandit. ground edges graph represents topology network. experiment networks rocketfuel dataset contain nodes edges edges considered independent contain cycle. latency edge expected latency recorded dataset; exponential noise. latency ranges milliseconds. noise model motivated following observation. latency networks mostly explained geographical distances expected latency noise tends small order hundred microseconds unlikely cause high latency. observe trends networks. first expected cost approaches optimal solution number episodes increases. second outperforms ε-greedy policy less episodes. expected costs policies networks reported table observe consistently outperforms ε-greedy policy often large margin. learns quickly networks sparse. particular number edges network never four times larger number edges spanning tree. therefore least theory edge observed least four episodes method learn quickly mean latency edge. second experiment study assignment lending institutions lenders microﬁnance setting kiva problem formulated family matroids called transversal matroids ground transversal matroid left vertices corresponding bipartite graph independence consists sets left vertices belong possible matchings graph edges matching share endpoint. weight weight associated left vertices bipartite graph. goal learn transversal bipartite graph maximizes overall weight selected figure kiva dataset modeled bipartite graph connecting lenders ﬁeld partners which turn fund several loans region. expected per-step return ﬁnding maximum weight transversal episodes. selected partners assigned based mean success rate optimal solution optimal solution involves partner/lender assignments. used sample loans kiva microﬁnance dataset created bipartite graph. every loan handled partner total partners dataset represent left vertices bipartite graph therefore ground matroid. lenders dataset. grouped lenders clusters according location representing individual state united states representing foreign lenders. lender clusters constitute right vertices bipartite graph. edge partner lender lender among supporters partner resulting approximately edges bipartite graph. weight probability loan handled partner paid back. estimate dataset number loans handled partner. assume loan repayment paid otherwise. beginning episode choose loan random. optimal solution transversal graph maximizes overall success rate selected partners. twelve partners selected based mean success rate optimal solution shown figure partner lender partner assigned along number eligible partners lender average success rate listed table. objective ε-greedy policies similar optimal policy difference success rates known beforehand must learned interacting repeatedly environment. comparison results three policies reported figure similar previous experiment observe following trends. first expected return approaches last experiment evaluate problem learning diverse popular movies. kind movies typically recommended existing content recommender systems. movies popular therefore user likely choose them. movies diverse therefore cover many potential interests user. problem formulated linear matroid bandit. ground movies movielens dataset dataset thousand people rated million movies. restrict attention rated movies movies well known. cardinality movie deﬁne feature vector indicates movie belongs genre movies considered independent movie vector cannot written linear combination feature vectors remaining movies notion diversity. expected weight probability movie chosen. estimate indicator person rated movie number people dataset. beginning episode choose person random. twelve popular movies optimal solution listed figure movies cover wide range movie genres appear diverse. validates assumption linear independence suitable modeling diversity. expected return reported ﬁgure. observe trends previous experiments. speciﬁcally expected return movie title american beauty jurassic park saving private ryan matrix back future silence lambs black fargo shakespeare love l.a. conﬁdential e.t. extra-terrestrial ghostbusters movie genres comedy drama action adventure sci-fi action drama action sci-fi thriller comedy sci-fi drama thriller action adventure comedy sci-fi crime drama thriller comedy romance crime film-noir mystery thriller children’s drama fantasy sci-fi comedy horror figure left. twelve popular movies optimal solution optimal solution involves movies. right. expected per-step return three movie recommendation policies episodes. problem viewed stochastic combinatorial semi-bandit feasible solutions independent sets matroid. stochastic combinatorial semibandits pioneered proposed algorithm solving problems. chen proved expected cumulative regret method gap-dependent regret bound factor tighter bound chen analysis relies heavily properties problem therefore derive much tighter bound. comband osmd algorithms adversarial combinatorial semi-bandits. main limitation comband osmd guaranteed computationally efﬁcient. speciﬁcally comband needs sample distribution exponentially many solutions osmd needs project convex hull solutions. computationally efﬁcient practical time complexity increases time. hand guaranteed computationally efﬁcient solve special class combinatorial bandits matroid bandits. matroids broad important class combinatorial optimization problems active area research past years. ﬁrst paper studies well-known matroid problem bandit setting proposes learning algorithm solving easy show submodular monotonic maximum-weight basis matroid solution maxa|a|=k many algorithms learning maximize submodular function proposed recently none algorithms suitable solving problem. reasons. first algorithm designed maximize speciﬁc submodular function function type. second algorithms near optimal learn note method guaranteed optimal learn ﬁrst work studies problem learning maximum-weight basis matroid weights items initially unknown learned interacting repeatedly environment. propose practical algorithm solving problem bound regret. regret sublinear time linear quantities interest. evaluate method three real-world problems show practical. regret bounds therefore practical number items large. believe kinds problems solved efﬁciently introducing additional structure linear generalization. case weight item would modeled linear function features goal learn parameters function. many combinatorial optimization problems viewed optimization matroid generalizations maximum-weight matching bipartite graph minimum cost ﬂows. sense hardest problems combinatorial optimization solved optimally polynomial time work show problems efﬁciently learnable. believe ideas work quite general applied problems involve matroids.", "year": 2014}