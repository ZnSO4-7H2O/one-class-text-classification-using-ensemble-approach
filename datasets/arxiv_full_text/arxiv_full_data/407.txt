{"title": "Examining Cooperation in Visual Dialog Models", "tag": ["cs.CV", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "abstract": "In this work we propose a blackbox intervention method for visual dialog models, with the aim of assessing the contribution of individual linguistic or visual components. Concretely, we conduct structured or randomized interventions that aim to impair an individual component of the model, and observe changes in task performance. We reproduce a state-of-the-art visual dialog model and demonstrate that our methodology yields surprising insights, namely that both dialog and image information have minimal contributions to task performance. The intervention method presented here can be applied as a sanity check for the strength and robustness of each component in visual dialog systems.", "text": "work propose blackbox intervention method visual dialog models assessing contribution individual linguistic visual components. concretely conduct structured randomized interventions impair individual component model observe changes task performance. reproduce state-of-the-art visual dialog model demonstrate methodology yields surprising insights namely dialog image information minimal contributions task performance. intervention method presented applied sanity check strength robustness component visual dialog systems. combining vision language tasks require high-level image understanding image captioning visual question answering leverage performance deep neural networks attempt simulate humans acquire information different modalities environment. recent work availability large-scale datasets seen dialog models proposed medium communicating visual information recent approaches proposed models acquire natural language multi-agent dialog downstream visual task models asymmetrically primed initial textual visual information leverage information agents simulate human-like conversation. goal dissect contributions linguistic visual components interplay. believe progressing visually-grounded conversational artiﬁcial intelligence requires understanding communicative protocols exchanged agents utilize language visual information cooperatively. work present simple black-box intervention method aims determine source linguistic visual information agents exploit order complete task. method model-agnostic utilized sanity-check process designing model. demonstrate method visual dialog model presented method empirically tests robustness model respect variations inputs performs unit testing speciﬁc components. replicate supervised hierarchical recurrent encoder-decoder model proposed engages cooperative image guessing game introduced game includes question answer bots provided short description image a-bot additionally accesses image itself. without seeing image q-bot must communicate a-bot asking questions order guess image. since outcome game decided based accuracy q-bot’s prediction ground truth image a-bot must cooperate q-bot game. choosing model primarily motivated structure incorporates multiple components working towards goal well visdial dataset sound testbed type investigation diversity size. quantify performance model q-bot asked rank correct image among candidates. consistent original evaluation mean-percentile rank metric. mean-percentile rank means prediction q-bot closer ground truth image images set. guessing game forcing agents communicate natural language enables humans inspect behaviours agents painlessly creating meaningful interpretable interventions. consider types interventions intervening initial condition intervening course conversation changing responses generated either agent. understanding initial condition crucial designing conversational example sheds light data collect natural interface humans understand role images captions perform interventions follows. image replace image feature vector random noise uniform. images useful cues intervention completely destroys piece essential information. therefore expect degradation evaluation performance. intervening dialogs hand allows glimpse model’s internal representations ability exploit exchange meaningful bits information. expect intelligent systems sensitive perturbations especially trained cope setting intervene addition random noise propose using negation principled approach gaining insights cooperative behaviors agents. particularly change answer a-bot vice versa. q-bot behaves cooperatively predictions alternate dramatically. choose manipulate a-bot observe outcomes visdial game easier negate answer question. moreover answers make responses a-bot training validation data therefore reasonable expect bots learn negation concept. experiments performed model described perform four interventions described section inference validation set. study performance modiﬁed dialog system task ranking image inside collection compare regular performance without interventions. understand whether dialog image leveraged provide information q-bot make better predictions. priori expect observe large decline performance intervention experiments essentially involve replacing information source random noise. speciﬁcally intervene caption different probabilities start dialog image answers questions round case image intervention replace entire image random noise. section present mean percentile rank validation visdial dataset intervention experiment well regular inference without interventions described section caption interventions displayed figure higher values correspond poorer performance. despite fact caption seen start dialog nevertheless plays important role predictive performance network across rounds. figure appendix provides example \"positive\" manual intervention replacing original image caption informative resulted much better ranking. image caption answer interventions seen figure interventions negative effect performance intervention round however decrease performance individual experiment much smaller decrease interventions captions. suggests q-bot relies mainly caption contains information needed make predictions. also note randomly intervening questions affects performance most. clearly observe large discrepancy rankings caption interventions experiments. surprisingly decline performance caused interventions answers questions less expected suggesting dialog used effectively image identiﬁcation. interestingly replacing images complete noise minimal impact performance model. q-bot mainly relies caption provided beginning dialog make predictions. suggests little cooperation bots. effect clearly observed extreme case intervene rounds shown table note ranking performance caption interventions improved dialog continues although never recovers completely. table shows results negation intervention experiments. start intervening round comparing across rounds q-bot sensitive non-cooperative behaviors a-bot however small degree results suggest addition downstream evaluation cooperative game setting forcing agent play non-cooperatively could help researchers design better experimental setup understand cooperative behaviours amongst agents system. presented simple effective method assessing interaction linguistic visual components visual dialog models. using example combines multiple sources information cooperative multi-agent setup demonstrated impairing individual components reveal extent information source exploited agents accomplish goals. pitfall designing multi-modal blackbox systems role individual components deduced overall performance model. series surprising results discovered role images minimal image retrieval performance. furthermore evaluation suggests dialog exploited signiﬁcantly bots cooperative setting. argue designing multi-modal systems requires careful evaluation unit testing component. grounding natural language difﬁcult problem models combine modalities must account individual impact information source. encourage future researchers account effect modality total performance model. interesting research direction learn interaction models independent modalities shown generalize well conjunction avoid pitfall overﬁtting spurious correlations optimize surrogate learning objectives independent modality. reinforcement learning traditionally used train dialog models motivated natural training paradigm dialogue models applied visual dialog models include methods analysis leave assessment future work.", "year": 2017}