{"title": "CARLA: An Open Urban Driving Simulator", "tag": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "abstract": "We introduce CARLA, an open-source simulator for autonomous driving research. CARLA has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, CARLA provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions. We use CARLA to study the performance of three approaches to autonomous driving: a classic modular pipeline, an end-to-end model trained via imitation learning, and an end-to-end model trained via reinforcement learning. The approaches are evaluated in controlled scenarios of increasing difficulty, and their performance is examined via metrics provided by CARLA, illustrating the platform's utility for autonomous driving research. The supplementary video can be viewed at https://youtu.be/Hp8Dz-Zek2E", "text": "abstract introduce carla open-source simulator autonomous driving research. carla developed ground support development training validation autonomous urban driving systems. addition open-source code protocols carla provides open digital assets created purpose used freely. simulation platform supports ﬂexible speciﬁcation sensor suites environmental conditions. carla study performance three approaches autonomous driving classic modular pipeline endto-end model trained imitation learning end-to-end model trained reinforcement learning. approaches evaluated controlled scenarios increasing difﬁculty performance examined metrics provided carla illustrating platform’s utility autonomous driving research. sensorimotor control three-dimensional environments remains major challenge machine learning robotics. development autonomous ground vehicles long-studied instantiation problem difﬁcult form navigation densely populated urban environments setting particularly challenging complex multi-agent dynamics trafﬁc intersections; necessity track respond motion tens hundreds actors view given time; prescriptive trafﬁc rules necessitate recognizing street signs street lights road markings distinguishing multiple types vehicles; long tail rare events road construction child running onto road accident ahead rogue driver barreling wrong side; necessity rapidly reconcile conﬂicting objectives applying appropriate deceleration absent-minded pedestrian strays onto road ahead another rapidly approaching behind rear-end brakes hard. research autonomous urban driving hindered infrastructure costs logistical difﬁculties training testing systems physical world. instrumenting operating even robotic requires signiﬁcant funds manpower. single vehicle sufﬁcient collecting requisite data cover multitude corner cases must processed training validation. true classic modular pipelines even datahungry deep learning techniques. training validation sensorimotor control models urban driving physical world beyond reach research groups. alternative train validate driving strategies simulation. simulation democratize research autonomous urban driving. also necessary system veriﬁcation since scenarios dangerous staged physical world simulation used training driving models since early days autonomous driving research recently racing simulators used evaluate approaches autonomous driving custom simulation setups commonly used train benchmark robotic vision systems commercial games used acquire high-ﬁdelity data training benchmarking visual perception systems ad-hoc simulation autonomous driving research widespread existing simulation platforms limited. open-source racing simulators torcs present comfigure street town shown third-person view four weather conditions. clockwise left clear daytime rain daytime shortly rain clear sunset. supplementary video recordings simulator. plexity urban driving lack pedestrians intersections cross trafﬁc trafﬁc rules complications distinguish urban driving track racing. commercial games simulate urban environments high ﬁdelity grand theft auto support detailed benchmarking driving policies little customization control environment limited scripting scenario speciﬁcation severely limited sensor suite speciﬁcation detailed feedback upon violation trafﬁc rules limitations closed-source commercial nature fundamentally different objectives development. paper introduce carla open simulator urban driving. carla developed ground support training prototyping validation autonomous driving models including perception control. carla open platform. uniquely content urban environments provided carla also free. content created scratch dedicated team digital artists employed purpose. includes urban layouts multitude vehicle models buildings pedestrians street signs etc. simulation platform supports ﬂexible setup sensor suites provides signals used train driving strategies coordinates speed acceleration detailed data collisions infractions. wide range environmental conditions speciﬁed including weather time day. number environmental conditions illustrated figure carla study performance three approaches autonomous driving. ﬁrst classic modular pipeline comprises vision-based perception module rule-based planner maneuver controller. second deep network maps sensory input driving commands trained end-to-end imitation learning. third also deep network trained end-to-end reinforcement learning. carla stage controlled goal-directed navigation scenarios increasing difﬁculty. manipulate complexity route must traversed presence trafﬁc environmental conditions. experimental results shed light performance characteristics three approaches. community. engine provides state-of-the-art rendering quality realistic physics basic logic ecosystem interoperable plugins. engine free non-commercial use. carla simulates dynamic world provides simple interface world agent interacts world. support functionality carla designed server-client system server runs simulation renders scene. client implemented python responsible interaction autonomous agent server sockets. client sends commands meta-commands server receives sensor readings return. commands control vehicle include steering accelerating braking. metacommands control behavior server used resetting simulation changing properties environment modifying sensor suite. environmental properties include weather conditions illumination density cars pedestrians. server reset agent re-initialized location speciﬁed client. environment. environment composed models static objects buildings vegetation trafﬁc signs infrastructure well dynamic objects vehicles pedestrians. models carefully designed reconcile visual quality rendering speed low-weight geometric models textures maintain visual realism carefully crafting materials making variable level detail. models share common scale sizes reﬂect real objects. time writing asset library includes different buildings animated vehicle models animated pedestrian models. used assets build urban environments following steps laying roads sidewalks; manually placing houses vegetation terrain trafﬁc infrastructure; specifying locations dynamic objects appear designed towns town total drivable roads used training town drivable roads used testing. towns shown supplement. challenges development carla conﬁguration behavior non-player characters important realism. based non-player vehicles standard vehicle model kinematic parameters adjusted realism. also implemented basic controller governs non-player vehicle behavior lane following respecting trafﬁc lights speed limits decision making intersections. vehicles pedestrians detect avoid other. advanced non-player vehicle controllers integrated future pedestrians navigate streets according town-speciﬁc navigation conveys location-based cost. cost designed encourage pedestrians walk along sidewalks marked road crossings allows cross roads point. pedestrians wander around town accordance avoiding trying avoid vehicles. collides pedestrian pedestrian deleted simulation pedestrian spawned different location brief time interval. increase visual diversity randomize appearance non-player characters added simulation. pedestrian clothed random outﬁt sampled pre-speciﬁed wardrobe optionally equipped following smartphone shopping bags guitar case suitcase rolling umbrella. vehicle painted random according model-speciﬁc materials. also implemented variety atmospheric conditions illumination regimes. differ position color intensity color diffuse radiation well ambient occlusion atmospheric cloudiness precipitation. currently simulator supports lighting conditions midday sunset well nine weather conditions differing cloud cover level precipitation presence puddles streets. results total illumination-weather combinations. four illustrated figure sensors. carla allows ﬂexible conﬁguration agent’s sensor suite. time writing sensors limited cameras pseudo-sensors provide ground-truth depth semantic segmentation. illustrated figure number cameras type position speciﬁed client. camera parameters include location orientation respect car’s coordinate system ﬁeld view depth ﬁeld. semantic segmentation figure three sensing modalities provided carla. left right normal vision camera ground-truth depth ground-truth semantic segmentation. depth semantic segmentation pseudo-sensors support experiments control role perception. additional sensor models plugged api. pseudo-sensor provides semantic classes road lane-marking trafﬁc sign sidewalk fence pole wall building vegetation vehicle pedestrian other. addition sensor pseudo-sensor readings carla provides range measurements associated state agent compliance trafﬁc rules. measurements agent’s state include vehicle location orientation respect world coordinate system speed acceleration vector accumulated impact collisions. measurements concerning trafﬁc rules include percentage vehicle’s footprint impinges wrong-way lanes sidewalks well states trafﬁc lights speed limit current location vehicle. finally carla provides access exact locations bounding boxes dynamic objects environment. signals play important role training evaluating driving policies. carla supports development training detailed performance analysis autonomous driving systems. used carla evaluate three approaches autonomous driving. ﬁrst modular pipeline relies dedicated subsystems visual perception planning control. architecture line existing autonomous driving systems second approach based deep network trained end-to-end imitation learning approach represents long line investigation recently attracted renewed interest third approach based deep network trained end-to-end reinforcement learning begin introducing notation common methods proceed describe turn. consider agent interacts environment discrete time steps. time step agent gets observation must produce action action threedimensional vector represents steering throttle brake. observation tuple sensory inputs. include high-dimensional sensory observations color images depth maps lower-dimensional measurements speed readings. addition momentary observations approaches also make plan provided highlevel topological planner. planner takes current position agent location goal input uses algorithm provide high-level plan agent needs follow order reach goal. plan advises agent turn left turn right keep straight intersections. plan provide trajectory contain geometric information. thus weaker form plan given common navigation applications guide human drivers autonomous vehicles physical world. metric maps. ﬁrst method modular pipeline decomposes driving task among following subsystems perception planning continuous control. since metric provided input visual perception becomes critical task. local planning completely dependent scene layout estimated perception module. perception stack uses semantic segmentation estimate lanes road limits dynamic objects hazards. addition classiﬁcation model used determine proximity intersections. local planner uses rule-based state machine implements simple predeﬁned polices tuned urban environments. continuous control performed controller actuates steering throttle brake. describe modules detail. perception. perception stack describe built upon semantic segmentation network based reﬁnenet network trained classify pixel image following semantic categories {road sidewalk lane marking dynamic object miscellaneous static}. network trained labelled images produced training environment using carla. probability distributions provided network used estimate ego-lane based road area lane markings. network output also used compute obstacle mask aims encompass pedestrians vehicles hazards. addition estimate likelihood intersection using binary scene classiﬁer based alexnet network trained images balanced classes. local planner. local planner coordinates low-level navigation generating waypoints near-term goal states represent desired position orientation near future. goal planner synthesize waypoints keep road prevent collisions. local planner based state machine following states road-following left-turn right-turn intersection-forward hazard-stop. transitions states performed based estimates provided perception module topological information provided global planner. details found supplement. local plan form waypoints delivered controller along vehicle’s current pose speed. continuous controller. proportional-integral-derivative controller simplicity ﬂexibility relative robustness slow response times. controller receives current pose speed list waypoints actuates steering throttle brake respectively. target cruise speed km/h. controller parameters tuned training town. second method conditional imitation learning form imitation learning uses highlevel commands addition perceptual input method utilizes dataset driving traces recorded human drivers training town. dataset consists tuples contains observation command action commands provided drivers data collection indicate intentions akin turn signals. four commands follow lane drive straight next intersection turn left next intersection turn right next intersection. observations images forward-facing camera. increase robustness learned policies inject noise data collection. dataset used train deep network predict expert’s action given observation control command details provided codevilla collected around hours driving data training. network trained using adam optimizer improve generalization performed data augmentation dropout. details provided supplement. third method deep reinforcement learning trains deep network based reward signal provided environment human driving traces. asynchronous advantage actor-critic algorithm algorithm shown perform well simulated three-dimensional environments tasks racing navigation three-dimensional mazes asynchronous nature method enables running multiple simulation threads parallel important given high sample complexity deep reinforcement learning. train goal-directed navigation. training episode vehicle reach goal guided high-level commands topological planner. episode terminated vehicle reaches goal vehicle collides obstacle time budget exhausted. reward weighted terms positively weighted speed distance traveled towards goal negatively weighted collision damage overlap sidewalk overlap opposite lane. details provided supplement. network trained parallel actor threads total million simulation steps. limit training million simulation steps computational costs imposed realistic simulation. correspond roughly days non-stop driving frames second. considered limited training data deep reinforcement learning standards common train hundreds millions steps corresponding months subjective experience. ensure setup fair million simulation steps sufﬁcient learning complex environment trained copy agent navigate three-dimensional maze agent reached score million simulation steps good result compared reported dosovitskiy koltun million simulation steps less optimized hyperparameters. evaluate three methods modular pipeline imitation learning reinforcement learning four increasingly difﬁcult driving tasks available towns weather conditions. note three approaches agent four tasks ﬁne-tune separately scenario. tasks goal-directed navigation agent initialized somewhere town reach destination point. experiments agent allowed ignore speed limits trafﬁc lights. organize tasks order increasing difﬁculty follows straight destination straight ahead starting point dynamic objects environment. average driving distance goal town town turn destination turn away starting point; dynamic objects. aver navigation restriction location destination point relative starting point dynamic objects. average driving distance goal town town navigation dynamic obstacles previous task dynamic objects experiments conducted towns. town used training town testing. consider weather conditions experiments organized groups. training weather used training includes clear clear sunset daytime rain daytime rain. test weather never used training includes cloudy daytime soft rain sunset. combination task town weather testing carried episodes. episode objective reach given goal location. episode considered successful agent reaches goal within time budget. time budget time needed reach goal along optimal path speed km/h. infractions driving sidewalk collisions lead termination episode logged reported. table reports percentage successfully completed episodes four different conditions. ﬁrst training condition town training weather set. note start goal locations different used training general environment ambient conditions same. three experimental conditions test aggressive generalization previously unseen town previously unencountered weather test weather set. results presented table suggest several general conclusions. overall performance methods perfect even simplest task driving straight line success rate declines difﬁcult tasks. generalization weather easier generalization town. modular pipeline agent trained imitation learning perform tasks conditions. reinforcement learning underperforms relative approaches. discuss four ﬁndings detail. table quantitative evaluation three autonomous driving systems goal-directed navigation tasks. table reports percentage successfully completed episodes condition. higher better. tested methods modular pipeline imitation learning reinforcement learning performance four tasks. surprisingly none methods performs perfectly even simplest task driving straight empty street training conditions. believe fundamental reason variability sensory inputs encountered agents. training conditions include four different weather conditions. exact trajectories driven training repeated testing. therefore performing perfectly task requires robust generalization challenging existing deep learning methods. advanced tasks performance methods declines. difﬁcult task navigation populated urban environment best methods modular pipeline imitation learning success conditions test town. results clearly indicate performance saturated even training conditions generalization environments poses serious challenge. generalization. study types generalization previously unseen weather conditions previously unseen environment. interestingly results dramatically different two. modular pipeline imitation learning performance weather condition close performance training condition sometimes even better. however generalization town presents challenge three approaches. challenging navigation tasks performance methods falls least factor switching test town. phenomenon explained fact models trained multiple weather conditions single town. training diverse weather supports generalization previously unseen weather town uses different textures models. problem likely ameliorated training diverse environments. overall results highlight importance generalization learning-based approaches sensorimotor control. modular pipeline end-to-end learning. instructive analyze relative performance modular pipeline imitation learning approach. systems represent general approaches designing intelligent agents carla enables direct controlled comparison them. surprisingly performance systems close testing conditions performance methods typically differs less notable exceptions general rule. modular pipeline performs better weather condition training conditions. speciﬁc selection training test weathers perception system happens perform better test weathers. another difference approaches underperforms navigation town condition going straight town weather. perception stack fails systematically complex weather conditions context environment. perception stack able reliably drivable path rules-based planner classic controller unable navigate destination consistent way. performance therefore bimodal perception stack works whole system works well; otherwise fails completely. sense fragile end-to-end method. imitation learning reinforcement learning. contrast performance endto-end trained systems imitation learning reinforcement learning. tasks agent trained reinforcement learning performs signiﬁcantly worse trained imitation learning. despite fact trained using signiﬁcantly larger amount data days driving compared hours used imitation learning. underperform despite strong results tasks atari games maze navigation reason known brittle common perform extensive task-speciﬁc hyperparameter search trials environment reported mnih using realistic simulator extensive hyperparameter search becomes infeasible. selected hyperparameters based evidence literature exploratory experiments maze navigation. another explanation urban driving difﬁcult tasks previously addressed instance compared maze navigation driving scenario agent deal vehicle dynamics complex visual perception cluttered dynamic environment. finally poor generalization reinforcement learning explained fact contrast imitation learning trained without data augmentation regularization dropout. infraction analysis. carla supports ﬁne-grained analysis driving policies. examine behavior three systems hardest task navigation presence dynamic objects. characterize approaches average distance traveled infractions following types driving opposite lane driving sidewalk colliding vehicles colliding pedestrians hitting static objects. details provided supplement. table reports average distance driven infractions. approaches perform better training town. conditions strays onto opposite lane least frequently worst metric. similar pattern observed regards veering onto sidewalk. surprisingly collides pedestrians least often could explained large negative reward incurred collisions. however reinforcement learning agent successful avoiding collisions cars static objects modular pipeline generally performs best according measure. results highlight susceptibility end-to-end approaches rare events breaking swerving avoid pedestrian rare occurrence training. carla used increase frequency events training support end-to-end approaches deeper advances learning algorithms model architectures necessary signiﬁcant improvements robustness presented carla open simulator autonomous driving. addition open-source code protocols carla provides digital assets created speciﬁcally purpose reused freely. leverage carla’s simulation engine content test three approaches autonomous driving classic modular pipeline deep network trained end-to-end imitation learning deep network trained reinforcement learning. challenged systems navigate urban environments presence vehicles pedestrians. carla provided tools develop train systems evaluate controlled scenarios. feedback provided simulator enables detailed analyses highlight particular failure modes opportunities future work. hope carla enable broad community actively engage autonomous driving research. simulator accompanying assets released open-source http//carla.org. carla would possible without development team barcelona. authors particularly grateful nestor subiron principal programmer francisco perez lead digital artist tireless work. sincerely thank artists iris saez alberto abal programmer marc garcia trafﬁc behavior programmer francisco bosch. thank artists mario gonzalez juan gonzalez ignazio acerenza contributions programmer francisco molero support. antonio l´opez felipe codevilla acknowledge spanish mineco project tra--c--r spanish project spip- well generalitat catalunya cerca program accio agency. felipe codevilla supported part grant fi-b-. authors thank epic games support concerning jaderberg mnih czarnecki schaul leibo silver kavukcuoglu. reinforcement learning unsupervised auxiliary tasks. international conference learning representations mnih kavukcuoglu silver rusu veness bellemare graves riedmiller fidjeland ostrovski petersen beattie sadik human-level control deep reinforcement learning. nature mnih badia mirza graves lillicrap harley silver kavukcuoglu. asynchronous methods deep reinforcement learning. international conference machine learning sellart materzynska v´azquez l´opez. synthia dataset large collection synthetic images semantic segmentation urban scenes. computer vision pattern recognition carla designed client-server system. server runs renders carla world. client provides interface users interact simulator controlling agent vehicle certain properties simulation. commands. agent vehicle controlled types commands sent client throttle pressure throttle pedal represented real number brake pressure brake pedal represented real number hand brake boolean value indicating whether hand brake activated not. reverse gear boolean value indicating whether reverse gear activated not. number vehicles integer number non-player vehicles spawned city. number pedestrians integer number pedestrians spawned city. weather index weather/lighting presets use. following currently supported clear midday clear sunset cloudy midday cloudy sunset soft rain midday soft rain sunset medium rain midday cloudy rain midday cloudy rain sunset medium rain sunset hard rain midday hard rain sunset rain noon rain sunset. cameras cameras speciﬁc parameters position orientation ﬁeld view resolution camera type. available camera types include optical camera pseudo-cameras provide ground-truth depth semantic segmentation. player position position player respect world coordinate system. player speed player’s linear speed kilometers hour. collision cumulative impact collisions three different types objects cars player orientation unit-length vector corresponding agent orientation. sensor readings current readings camera sensors. non-client-controlled agents information positions orientations bounding boxes carla provides towns town town figure shows maps towns representative views. large variety assets produced carla including cars pedestrians. figure demonstrates diversity. perception module. training semantic segmentation network performed using adam learning rate epochs batch size back-end resnet pre-trained imagenet frozen training. data augmentation used. intersection classiﬁer network trained images balanced classes. used adam learning rate epochs batch size pre-training data augmentation used. local planning modular pipeline. road-following state local planner uses ego-lane mask computed semantic segmentation select points maintain ﬁxed distance right edge road. left-turn intersections complex temporary absence lane markings longer distance target lane limited ﬁeld view forward-facing camera. deal challenges ﬁrst compute waypoints towards center intersection predeﬁned skew angle; helps improve visibility target lane. auxiliary camera used determine shape alignment vehicle respect target lane. second step waypoints laid yield smooth trajectory center intersection target lane. right-turn state uses similar strategy. however turning right easier given target lane proximity number waypoints needed lower forward-facing information required. intersection-forward state handled similarly road-following. hazard-stop mode activated dynamic obstacle presents cumulative probability obstacle predeﬁned threshold. case system generates special waypoint request emergency break controller. architecture. table details conﬁguration network used imitation learning approach network composed four modules perception module focused processing image inputs measurement module processes speed input joint input module merges perception measurement information control module produces motor commands joint input representation. control module consists identical branches command-conditional modules predicting steering angle brake throttle four commands. four command-conditional modules selected based input command. perception module implemented convolutional network takes image input outputs -dimensional vector. modules implemented fullyconnected networks. measurement module takes input measurement vector outputs -dimensional vector. training details. trained networks adam used mini-batches samples. balanced mini-batches using number samples command. starting learning rate multiplied every mini-batch iterations. trained iterations total. momentum parameters used weight decay performed dropout hidden fully-connected layers dropout convolutional layers. reduce overﬁtting performed extensive data augmentation adding gaussian blur additive gaussian noise pixel dropout additive multiplicative brightness variation contrast variation saturation variation. feeding image network cropped pixels bottom resized resulting image resolution training data. expert training data collected sources automated agent human driver data. automated agent access privileged information locations dynamic objects ego-lane states trafﬁc lights. demonstrations provided automated agent human driver. order improve robustness learned policy injected noise expert’s steering training data collection. namely random points time added perturbation steering angle provided driver. perturbation triangular impulse increases linearly reaches maximal value linearly declines. simulates gradual drift desired trajectory similar might happen poorly trained controller. triangular impulse parametrized starting time duration sign intensity every second driving started perturbation probability pperturb. used pperturb experiments. sign perturbation sampled random duration sampled uniformly seconds intensity ﬁxed base agent network architecture proposed mnih input network consists recent images observed agent resized pixels well vector measurements. measurement vector includes current speed distance goal damage collisions current high-level command provided topological planner one-hot encoding. inputs processed separate modules images convolutional module measurements fully-connected network. outputs modules concatenated processed jointly. trained parallel actor threads total million environment steps. used -step rollouts following jaderberg initial learning rate entropy regularization learning rate linearly decreased zero course training. reward weighted terms distance traveled towards goal speed km/h collision damage intersection sidewalk intersection opposite lane opposite lane car’s footprint wrong-way lanes. sidewalk car’s footprint sidewalk. collision static object makes contact static object pole building. collision makes contact another car. collision pedestrian makes contact pedestrian.", "year": 2017}