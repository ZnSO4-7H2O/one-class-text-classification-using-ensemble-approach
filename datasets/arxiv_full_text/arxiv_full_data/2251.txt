{"title": "Similarity-based Multi-label Learning", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Multi-label classification is an important learning problem with many applications. In this work, we propose a principled similarity-based approach for multi-label learning called SML. We also introduce a similarity-based approach for predicting the label set size. The experimental results demonstrate the effectiveness of SML for multi-label classification where it is shown to compare favorably with a wide variety of existing algorithms across a range of evaluation criterion.", "text": "multi-label classiﬁcation important learning problem many applications. work propose principled similarity-based approach multi-label learning called sml. also introduce similarity-based approach predicting label size. experimental results demonstrate effectiveness multi-label classiﬁcation shown compare favorably wide variety existing algorithms across range evaluation criterion. multi-label classiﬁcation important learning problem applications bioinformatics image video annotation query suggestions goal multi-label classiﬁcation predict label vector given unseen data point previous work mainly focused reducing multi-label problem standard multi-class binary classiﬁcation ranking regression recent survey. standard multi-class approaches used mapping multi-label problem labels multi-class problem labels binary classiﬁcation methods also used copying feature vector times copy additional dimension added value training label label present otherwise rank-based approaches attempt rank relevant labels higher irreverent ones regression methods label space onto vector space standard regression methods applied work introduce similarity-based approach multi-label learning called gives rise class methods multi-label classiﬁcation. furthermore also present similarity-based size prediction algorithm predicting number labels associated unknown test instance experiments number data sets demonstrate effectiveness compares favorably existing methods across wide range evaluation criterion. experimental results indicate practical signiﬁcance sml. addition direct approach multi-label learning. contrast existing methods mostly indirect approaches transform multi-label problem binary multi-class regression problem apply standard algorithms furthermore rankbased approaches rank-svm also indirect extensions multi-label classiﬁcation. notably completely avoids mappings based general notion similarity. denote input space denote possible class labels. given multi-label training deﬁned -dimensional training vector representing single instance label associated given goal multi-label learning problem learn function predicts labels unseen instance multi-label learning algorithm typically outputs real-valued function conﬁdence label unseen test instance given instance associated label good multi-label learning algorithm output larger values labels smaller values labels consider variety evaluation criterion comparing multi-label learning algorithms. multi-label hamming loss fraction incorrectly classiﬁed instance-label pairs predicate indicator function holds otherwise. given labels ordered likely least coverage measures position ordered list proper labels recovered section presents general similarity-based approach multi-label learning called sml. given multi-label training -dimensional training vector representing single instance label associated goal multi-label classiﬁcation predict label unseen instance assume w.l.o.g. feature vectors normalized length given subset training instances label deﬁned arbitrary similarity function. notably proposed family similarity-based multilabel learning algorithms leverage arbitrary similarity function furthermore approach require mappings high-dimensional hilbert spaces required ranksvm deﬁne parameterized similarity functions below. given -dimensional vectors similarity function inner product vectors degree polynomial regularization term trading higher-order terms lower-order ones polynomial. linear-sml quadratic-sml special cases respectively. furthermore label weights denoted test instance estimated predict label section details. aside binary multi-class problems special cases proposed family similarity-based multi-label learning algorithms. furthermore binary multi-class algorithms recovered special cases |yi| indeed proposed similarity-based multi-label learning approach expresses family algorithms many components interchangeable similarity function normalization weighting function used control inﬂuence individual similarity score sampling sketching approach reduce training data. expressiveness ﬂexibility enables easily adapted application-speciﬁc tasks domains. addition lends efﬁcient straightforward parallel implementation. present similarity-based approach predicting label size. label corresponding training instance training label |yi| i.e. number denote -dimensional lalabels associated label instance replaced transformed label encodes label size |yi| furthermore {|yi|}n denote label space given transformation denote number unique labels straightforward transforms original multi-label classiﬁcation problem general multi-class problem predicting label size. given label size unseen instance predicted follows. first similarity respect training instance derived similarities training instances size combined addition. formally similarity instances size respect complement learning threshold function predict label unseen instance nevertheless approach predicts label learned weights used sml; possibilities. given single test instance runtime number training instances number attributes |yi| average number labels training instance. straightforward derives similarity training instance’s -dimensional attribute vector. space complexity single test instance number labels. obviously taking account space required methods store training instances associated label sets. similarity-based size prediction approach time complexity since label size maximum similarity maintained time. however approach uses space straightforward incorporate sampling mechanism approach improve time space requirements. particular given test instance sample small fraction training instances denoted arbitrary distribution smaller predicting labels ml-knn knn-based multi-label approach uses euclidean distance top-k instances closest. ml-knn shown perform well variety multi-label problems. boostexter boosting-based multi-label algorithm called boostexter. adtboost.mh multi-label decision tree approach. rank-svm multi-label approach based ranking. boostexter adtboost.mh boosting rounds respectively since performance change rounds rank-svm polynomial kernels degree performs best shown unless otherwise mentioned approach uses similarity function hyperparameter learned automatically k-fold cross-validation labeled data. work systematically compare multi-label learning algorithms using data different domains. ﬁrst multi-label learning task evaluate based predicting functions genes yeast saccharomyces cerevisiae widely studied organism bioinformatics gene take multiple functional classes. investigation used yeast data gene consists concatenation micro-array expression data phylogenetic proﬁle data. following elisseeff preprocess data known structure functional classes used. resulting multi-label yeast data consists genes gene represented -dimensional feature vector. labels denoting functional classes. -fold cross-validation show mean standard deviation. experimental results multi-label learning algorithms reported table notably multi-label algorithms compared across wide range evaluation metrics. best result evaluation criterion shown bold. cases approach outperforms multi-label learning algorithms across evaluation criterion. furthermore variance also smaller variance multi-label learning algorithms cases. holds across multi-label learning algorithms coverage average precision ranking loss. second multi-label learning task evaluate natural scene classiﬁcation using image data. scene classiﬁcation image assigned multiple labels representing different natural scenes image labeled mountain sunset scene. therefore given unseen image task predict scenes present scene data consists images image contains manually assigned labels. labels namely desert mountains sunset trees. image represented -dimensional feature vector derived using approach -fold cross-validation show mean standard deviation. experimental results multi-label algorithms using natural scene classiﬁcation data reported table best result evaluation criterion bold. table obvious outperforms multi-label algorithms evaluation criterion namely coverage. terms coverage ml-knn boostexter tied slightly lower coverage sml. described general framework similarity-based multi-label learning called gives rise novel class methods multi-label problem. furthermore also presented similarity-based approach predicting label size. experiments number data sets demonstrate effectiveness compares favorably existing methods across wide range evaluation criterion.", "year": 2017}