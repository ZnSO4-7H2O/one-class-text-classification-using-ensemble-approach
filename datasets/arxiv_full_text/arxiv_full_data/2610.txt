{"title": "Reinforcement Learning Approach for Parallelization in Filters  Aggregation Based Feature Selection Algorithms", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "One of the classical problems in machine learning and data mining is feature selection. A feature selection algorithm is expected to be quick, and at the same time it should show high performance. MeLiF algorithm effectively solves this problem using ensembles of ranking filters. This article describes two different ways to improve MeLiF algorithm performance with parallelization. Experiments show that proposed schemes significantly improves algorithm performance and increase feature selection quality.", "text": "classical problems machine learning data mining feature selection. feature selection algorithm expected quick time show high performance. melif algorithm eﬀectively solves problem using ensembles ranking ﬁlters. article describes diﬀerent ways improve melif algorithm performance parallelization. experiments show proposed schemes signiﬁcantly improves algorithm performance increase feature selection quality. keywords machine learning feature selection rank aggregation multi-armed bandit parallel computation melif melif+ pqmelif mamelif. almost business scientiﬁc problems nowadays involve processing huge amounts data machine learning algorithms. universal applicability machine learning became promising researched scientiﬁc domains. particular application bioinformatics giant amounts data gene expression diﬀerent organisms obtained ﬁeld. order ﬁlter data noise reduce model complexity necessary select relevant features. techniques methods achieving goal called feature selection. gene expression data enable researchers spot pieces responsible reactions particular environment change internal processes organism. main problem processing data high dimensionality instances. gene expression datasets often high number features relatively number objects. dataset properties hard build model data well. feature selection algorithm meets several requirements. expected work fast show good performance. however universal algorithm feature selection exists. wrappers family methods based searching optimal feature subset maximizes preselected classiﬁer eﬀectiveness. problem statement leads high performance found solution. however size search space grows exponentially instance dimensionality. fact makes wrapper rarely applicable bioinformatics number features datasets could hundreds thousands. cases feature selection algorithms known ﬁlters used. filters based estimation feature importance. filters usually perform worse wrappers much faster. special group feature selection methods embedded selectors uses particular properties selected classiﬁer. ensembling process building combination several simple algorithms widely used technique machine learning melif algorithm proposed applies ensembling feature selection. algorithm tries linear combination basic ranking ﬁlters selects relevant features dataset. ranking ﬁlter consists separate parts feature importance measure cutting rule. basically melif tries tune coeﬃcients feature importance measure linear combination. process involves classiﬁer training evaluating comparing ranking ﬁlters themselves thus making comparatively slow. parallelization become really handy helpful improve algorithm computational time. main disadvantage na¨ıve scheme scale well. starts search best coeﬃcient vector several starting points using separate thread point. optimization processes ends thread stops resources stay unreleased therefore cannot used work. thus useful allocate resources process stay unused. overcome problem necessary cores processing server eﬀectively. processing melif visits points linear space process points using task executor. research proposes diﬀerent approaches using parallel coordinate descent building ensembles ranking ﬁlters called pqmelif mamelif. ﬁrst algorithm stores points processed priority queue. second algorithm solves theparallelization problem reducing multi-armed bandit problem. remainder paper organized follows section describes melif algorithm section contains proposed parallelization schemes section outlines experimental setup section contains experiment results ﬁnally section contains conclusion. ranking ﬁlter pair feature importance measure cutting rule. object feature return importance label prediction. sorted list features cuts worst. core idea melif several ranking ﬁlters order merge single ranking ﬁlter ﬁnding eﬀective linear combination feature importance measures. combination feature importance measure cutting rule inherited ranking ﬁlters performance measure used evaluate ranking ﬁlter eﬀectiveness. paper classiﬁer eﬀectiveness estimated score. classiﬁer). however dimensionality search space less order magnitude number features. detail allows classifying algorithm melif family hybrid ﬁlter wrapper inherits ﬁlter speed wrapper focus resulting performance. original melif performs coordinate descent search space. observed experiments best option particular choice starting points corresponding basic ranking ﬁlter used corresponding equally weighted combination basic ranking ﬁlters. point reaches melif tries shift coordinate value evaluates eﬀectiveness point. evaluation result greater current maximum algorithm assigns current maximum equal coordinates point starts searching ﬁrst coordinate. coordinates shifted quality improvement observed algorithm stops. point obtained coordinate descent algorithm measures value resulting linear combination basic ﬁlters feature dataset. that results sorted algorithm selects topmost features. used train test particular classiﬁer. classiﬁcation quality treated point score. cached compared points. paper propose parallelization schemes melif show conﬁgurations speed improvement growing linearly number processors. furthermore proposed schemes show equal even better performance quality comparison single-threaded version melif. priority queue. algorithm variation best-ﬁrst search algorithm algorithm stores points processed priority queue. iteration algorithm polls point queue calculates score puts visited neighbors back queue priority equal calculated score. initiating algorithm starting points queue maximum priority ensures processed beginning starting points taken account simultaneously. unlike melif melif+ pqmelif enables tune halting criteria trade-oﬀ feature selection quality algorithm performance limit number points processed. experiments determined optimal number enables algorithm perform better original melif fast possible. experiments described next sections showed pqmelif performed much better melif melif+. however uncovered drawbacks. algorithm starts working initially starting points queue number ﬁxed equals number basic ranking ﬁlters plus one. server cores extra cores stay unused points added queue. possible solution problem process starting points order keep server cores busy. algorithms drawback overcome next algorithm. main idea algorithm consider problem selecting points reinforcement learning problem need trade-oﬀ exploration exploitation order apply idea adopted well-known algorithm parallelization problem reducing multi-armed bandit problem. reduction performed following way. firstly split search space diﬀerent areas correspond area arm. then evaluating point area understood playing corresponding arm. reward obtained playing score evaluated point problem faced implementation reinforcement learning algorithm multi-agent environment delayed feedback. basically thread needs select information results threads moment. forced make decision lack information. authors proposed make decision based results already computed provide theoretical proof error function additive based duration delay. classiﬁer used polynomial kernel soft margin parameter implemented weka library. used -fold cross-validation. number selected features constant basic ﬁlters used spearman rank correlation symmetric uncertainty criterion also executed melif melif+ recorded work time point best classiﬁcation result. used datasets diﬀerent sizes archives broad institute. cancer program data sets kent ridge bio-medical dataset feature selection datasets arizona state university rsctc discovery challenge datasets dnamicroarray datasets high number features comparatively number objects halted gets highest score results basic melif melif+ presented table best conﬁgurations pqmelif mamelif presented marel correspondingly. could seen table pqmelif mamelif strongly outperform melif+ resulting approximately linear scaling number computational cores. also methods gain average small boost original melif feature selection quality. paper presented parallelization schemes melif algorithm search best combination simple feature selection algorithms. experiments showed schemes namely pqmelif mamelif demonstrated linear speed improvement number used cores comparing single-threaded melif without loss classiﬁcation quality. furthermore algorithms sometimes showed better feature selection quality. could explained fact methods search points original melif method. happens delay thread synchronization. future research make estimations search space split size mamelif method depending number cores. proper split lead better computational results. also apply tests diﬀerent system conﬁgurations order amdahls optimum algorithm.", "year": 2016}