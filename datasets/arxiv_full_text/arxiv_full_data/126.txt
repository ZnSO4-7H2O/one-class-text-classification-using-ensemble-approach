{"title": "Symbol Grounding Association in Multimodal Sequences with Missing  Elements", "tag": ["cs.CV", "cs.CL", "cs.LG", "cs.NE"], "abstract": "In this paper, we extend a symbolic association framework for being able to handle missing elements in multimodal sequences. The general scope of the work is the symbolic associations of object-word mappings as it happens in language development in infants. In other words, two different representations of the same abstract concepts can associate in both directions. This scenario has been long interested in Artificial Intelligence, Psychology, and Neuroscience. In this work, we extend a recent approach for multimodal sequences (visual and audio) to also cope with missing elements in one or both modalities. Our method uses two parallel Long Short-Term Memories (LSTMs) with a learning rule based on EM-algorithm. It aligns both LSTM outputs via Dynamic Time Warping (DTW). We propose to include an extra step for the combination with the max operation for exploiting the common elements between both sequences. The motivation behind is that the combination acts as a condition selector for choosing the best representation from both LSTMs. We evaluated the proposed extension in the following scenarios: missing elements in one modality (visual or audio) and missing elements in both modalities (visual and sound). The performance of our extension reaches better results than the original model and similar results to individual LSTM trained in each modality.", "text": "federico raue andreas dengel thomas breuel marcus liwicki computer science departmenttu kaiserslautern gottlieb-daimler strasse kaiserslautern germany mindgaragetu kaiserslautern gottlieb-daimler strasse kaiserslautern germany smart data knowledge servicesgerman research center artiﬁcial intelligence trippstadter strasse kaiserslautern germany paper extend symbolic association framework able handle missing elements multimodal sequences. general scope work symbolic associations object-word mappings happens language development infants. words diﬀerent representations abstract concepts associate directions. scenario long interested artiﬁcial intelligence psychology neuroscience. work extend recent approach multimodal sequences also cope missing elements modalities. method uses parallel long short-term memories learning rule based em-algorithm. aligns lstm outputs dynamic time warping propose include extra step combination operation exploiting common elements sequences. motivation behind combination acts condition selector choosing best representation lstms. evaluated proposed extension following scenarios missing elements modality missing elements modalities performance extension reaches better results original model similar results individual lstm trained modality. striking feature human brain link abstract concepts sensory input signals visual audio. result multimodal association abstract concept several representations maps modality another modality vice versa. example abstract concept ball sentence john plays ball associated several instances diﬀerent spherical shapes sound waves several ﬁelds neuroscience psychology artiﬁcial intelligence interested determining factors involved binding semantic concepts physical world. scenario known symbol grounding problem still open problem mind infants start learning binding abstract concepts real world multimodal scenario. gershkoﬀ-stowe smith found initial words infants mainly nouns dog. contrast lack stimulus limit language development i.e. deafness blindness. asano found diﬀerent patterns brain activity infants depending semantic correctness visual audio stimulus. simpler terms brain activity pattern visual audio signals represent semantic concept. otherwise pattern ‘b’. related work proposed model combines symbol grounding problem association learning. ballard explored framework learns association objects spoken names day-to-day tasks. nakamura introduced multimodal categorization applied robotics. framework exploited relation concepts diﬀerent modalities using multimodal latent dirichlet allocation. previous approaches focused associating isolated elements. work proposes another approach multimodal sequences input association task. text lines classiﬁcation breuel ul-hasan al-azawi shafait image segmentations byeon breuel raue liwicki successful examples sequence approach. furthermore association task sequences present semantic concepts modalities. moreover interested multimodal sequences represent semantic concept sequence constraint elements make concept part modalities; element unique modality. instance modality sequence represented modality represented ‘two six’; unique text modality ‘ﬁve’ unique spoken modality. work investigate multimodal association weakly labeled sequences based alignment latent spaces. detail elements sequence modality present modality. note work extension raue modalities represent semantic sequence similarly raue long short-term memories main components presented model output vectors aligned time axis using dynamic time warping contributions paper following claiming cognitively plausible). moreover model handles multimodal sequences semantic concepts modalities. also operation time-axis novel architecture motivation exploit cross-modality shared semantic concepts. semantic concepts modality. second scenario semantic concepts missing modality. example visual sequence audio sequence ‘two four’. visual audio modalities share semantic concepts four. contrast semantic concepts three figure comparison components traditional setup setup associating multimodal signals. note task extra learnable component whereas traditional scenario already predeﬁned moreover ﬁnal goal agree coding scheme modality. paper organized follows. shortly describe long short-term memory networks recurrent neural network section section explains lstm trained based weakly labeled sequences. section describes original model object-word association. section presents novel model handling missing elements. section shows dataset multimodal sequences missing elements. section compare performance proposed extension original model single lstm network trained modality traditional setup work interested unifying symbol grounding problem association learning neural network architecture. example penning d’avila garcez lamb meyer proposed model combines neural networks temporal rules. consider cross-modal scenario isolated object spoken word represent semantic concept. option learning association neural networks network visual channel another audio channel. safe assume output vectors neural networks carry attributes discriminant information input samples. thus output vectors considered numerical symbolic feature. mind deﬁne association task inspired symbol grounding problem follows. symbolic features semantic vectors binding initially. decision usually taken training external network. contrast presented task requires model learn binding. figure shows comparison traditional association task presented task observed traditional association already deﬁned elements association samples binding semantic concepts symbolic features. elements deﬁned semantic concepts network output using scheme. hand training algorithm includes previous elements case network training incorporates tasks. first neural network learns binding semantic concepts symbolic features. second neural networks learning agree binding symbolic features semantic concepts. machine learning applied successfully several scenarios architecture exploits multimodal relation input samples. following want indicate diﬀerences previous multimodal tasks work. multimodal feature fusion task combine features diﬀerent modalities creating better feature. manner generated feature exploits best qualities modality. recently deep boltzmann machines learns combine diﬀerent modalities unsupervised environments iqbal silver proposed architecture combined three modalities previous approaches combine modalities. image captioning task generate textual description given images input. words task seen machine translation images captions. approaches solving image captioning combination convolutional neural networks lstm encodes images lstm generates textual descriptions weakly labeled association task related learn association parallel sequences represent order semantic concepts. essential requirement sequences weakly labeled. scenarios require words must already segmented raue proposed model parallel lstm networks exploit multimodal latent space produced lstm networks. lstms align training. goal lstm modality learns latent space produced modality long short-term memory recurrent neural network handles vanishing gradient problem long sequences lstm solves vanishing gradient problem based gates manages lstm trained similar gradient-based method. moreover common approaches training proposed werbos deﬁned algorithm called backpropagation time updates network parameters last time step ﬁrst time step. words algorithm describes loss function follows explained lstm. additionally another approach combines lstms following manner. lstm runs another lstm runs setup called bidirectional lstm motivation exploit surrounded context speciﬁc position lstm successfully applied several scenarios image captioning texture classiﬁcation machine translation previous examples require segmented data. example words sentences show type segmentation based spaces previous example segmentation words relatively easy task. contrast segmentation speech recognition optical character recognition requires vast human eﬀort. example consider human eﬀort annotating bounding boxes character page. represents number target sequence string figure shows example weakly labeled sequence. observed length input sequence larger target sequence. graves proposed connectionist temporal classiﬁcation authors included extra class called blank class target sequence re-written blank class bbbbbb. intuition blank class learn transition digits handle repeated characters extending target sequence layer exploits similarities lstm hidden markov models case lstm uses forward-backward procedure similar training algorithm. ctc-forward-backward step requires recursive variables forward backward generating target vector forward-backward algorithm employs output vectors lstm. idea propagate forward backward probabilities target sequence. finally output forward-backward algorithm target sequence training lstm. ﬁnal step training predict label sequence given unknown input sequence. step called decoding methods proposed best path decoding preﬁx search decoding. figure shows example lstm classiﬁcation. please refer original paper exploits beneﬁts training sequences align semantic sequence. mind bidirectional lstm networks deﬁned modality manner training uses latent space produced vice versa. model components. ﬁrst component learn binding semantic concepts symbolic features component alignment multimodal space produced lstms general model works follows. initially receive input visual audio components multimodal sequence consequently network produces output vectors modalities last time step figure association model based parallel bidirectional lstm networks proposed raue note semantic concept presented channels. observed module aligns layer produces layer produces result target vector training purely obtained training based follows similar process. features. additionally indexes represent semantic concept duck. decision made internally model. therefore sets concept vectors introduced modality motivation behind implement winning-take-all rule semantic concepts symbolic features diﬀerent binding relations determining likely binding lstm output modality binding forward-backward step consequently output modality described steps applied independently modality. learning association exploiting multimodal latent space output vectors aligned time-axis dynamic time warping hence training modality uses latent space modality vice versa. figure illustrates training algorithm example. association scenario crucial constraint related binding semantic concepts symbolic features deﬁned training. mentioned binding semantic concepts output vectors learned based novel concept vectors. clear note concepts cannot vectorial representations. component employs em-style algorithm. explanation purposes described considering lstm concept vectors e-step predicts mapping semantic concepts sequence symbolic representation given lstm output concept vectors. ﬁrst step combine weighting vectors output sequence deﬁned lstm output vector time concept vector number time steps sequence power element-wise power operation output vector time step concept vector then matrix assembled concatenating ˆzc. result assembled matrix represents relation semantic concepts symbolic features permutation identity matrix. simplicity column vector represent j-th identity vector cannot same. words column vector represent identity vector row-column elimination procedure ranks values matrix. next position maximum value found determines row-th identity column vector ecol. example maximum value found correspondence vector values previous column previous zero. columnrow elimination applied times. hence vectors mapping semantic concepts symbolic feature module goal combine lstms latent space. combination possible multimodal sequence represents sequence semantic concepts monotonic behavior lstm. alignment output modalities. moreover berndt cliﬀord proposed aligning signals. similarly also utilize lstm output sequences. requires steps alignment signals. ﬁrst step calculate cost matrix following relation dist euclidean distance output vectors timestep timestep second step alignment path lstms. case path tuples maps time step lstm another time step lstm. words function previous section described multimodal association model exploits weakly labeled samples based training. initial assumption channel multimodal sequence represents ordered sequence semantic concepts. however initial assumption limitation. paper present extension handles missing elements sequences. goal exploit semantic concepts presented modalities. additionally multimodal combination boosted using operation combines best modality whereas previous model exploits modality. formally association task rewritten follows coupling lstms occurs module. similar section model follows procedure step. reminder output alignment function modality modality. words function main diﬀerences model proposed raue relies parts. ﬁrst part combine semantic concepts shared channels probability distribution produces lstms similar furthermore operation common approach combining vectors. second part related semantic concepts presented channel. case required another modality. thus step formulated follows element-wise maximum operation. note scalar goal assemble vectors ˆya→vt ˆyv→at combines cases afterwards target vectors used based operation. equations updated generated several multimodal datasets elements sequence missing modalities relative order elements same. example visual semantic concept sequence text line digits audio semantic concept sequence represented seven. case assumed simpliﬁed scenario symbol grounding continuity semantic concepts diﬀerent modality. visual component horizontal arrangement isolated objects audio component spoken semantic concepts elements visual component vice versa. want point visual component similar panorama view. procedure generating multimodal datasets explained. figure model handle semantic concepts presented modalities. work include module combines audio visual information based presence semantic concepts. moreover channels combined semantic concept.otherwise combination. also operation improves combination channels. generating semantic sequences scenarios considered generating semantic sequences modality missing elements modalities modality. ﬁrst scenario generated sequence semantic concepts. later randomly remove zero elements sequence. result diﬀerent sequences diﬀerent modalities obtained common elements them. second scenario follow similar procedure. case modality sequence semantic concepts modality missing addition vocabulary semantic concepts spanish bote botella caja carro gato queso cigarrillo gaseosa bebida pato cara comida hamburguesa higiene liquido loci´on cebolla piment´on pera redondo sanduche cuchara tel´efono tomate ﬂorero veh´ıculo madera. visual component used subset objects coil- standard dataset isolated objects. isolated object views diﬀerent angles black background. selecting object sequence object converted grayscale re-scaled pixels. visual components composed horizontally stacking isolated objects. additionally ﬁnal image added random noise background. segmentation audio component recorded semantic concept times twelve diﬀerent subjects spanish native speakers diﬀerent countries center south america. afterwards concatenating isolated semantic concepts generates audio sequences. training contains eleven voices training whereas testing contains two. training testing multimodal datasets generated three diﬀerent multimodal conﬁgurations evaluating model. ﬁrst setup missing elements modalities. second setup semantic concepts visual component audio modality ﬁxed number missing elements. thus evaluate impact missing elements. setup covers zero missing semantic concepts. third dataset similar idea concerning second dataset. case testing audio sequence semantic concepts visual component ﬁxed number missing elements. additionally multimodal sequences generated subject setup. follow -fold cross-validation scheme eleven subjects selected training remaining subjects used testing. example elements missing modalities shown figure apply pre-processing step visual component. contrast audio component converted mel-frequency cepstral coeﬃcient using toolkit. audio representation vector components fourier ﬁlter-bank coeﬃcients including ﬁrst second derivatives. audio visual components normalized zero mean standard deviation one. also proposed extension compared original model also compared extension lstm layer predeﬁned coding scheme. parameters visual lstm were memory cells learning rate momentum hand audio lstm memory cells learning rate momentum visual lstm. furthermore learning rate statistical constraint parameters selected based best performance lstm trained independently modality. mentioned previously assumption original model represent semantic concept sequence modalities. words one-to-one relationship exists modalities. contrast work assumption challenging semantic concept modality cannot present modality. evaluate multimodal association task using association accuracy deﬁned following equation length longest common sequence outputai outputvi output classiﬁcation modality gtai gtvi ground-truth labels modality number elements dataset. words evaluating association common elements. model learns association also learns classify modality. mind also reported label error rate performance metric deﬁned outputi output classiﬁcation ground-truth edit distance output classiﬁcation ground-truth. reminder training multimodal sequences whereas testing multimodal sequences. work reported average results. table summarizes performance lstm trained predeﬁned coding scheme original model presented extension. results divided parts follows. first proposed extension handles missing elements multimodal sequences better original model. inferred operation keeps strongest common semantic concepts modalities. note representations update weights backward step. second proposed extension reaches similar results standard lstm. case lstm trained modality independently. reminder mentioned setups classiﬁcation tasks traditional setup setup used work. want point visual lstm boost performance audio sequences compared lstm. result model reaches lower label error rate audio sequences standard lstm trained audio sequence. table association accuracy label error rate multimodal dataset seen original missing elements modalities. model performs worse proposed combination. furthermore presented extension reached similar results lstm conditions reaches better results another outcome work conformity symbolic structure modalities even missing elements. figure shows examples coding scheme agreement. observed lstm networks learn classify object-word relation weakly labeled multimodal sequences. moreover common concepts modalities represented similar symbolic feature located right position sequence. example semantic concept madera represented index modalities. note common elements also missing elements classiﬁed correctly. furthermore common semantic concepts correctly classiﬁed even lstm correctly classify semantic concepts sequence. second example figure shows semantic concept loci´on represented index addition considerations made also interested robustness presented model number missing elements. mind generated several datasets modality semantic concepts ﬁxed number missing elements semantic concepts. figure shows association accuracy original model presented model handling missing elements. first original model decreases performance number missing elements increases modalities. results expected original model relies one-to-one relation modalities. second recognize presented model shows better performance compared original model modalities. thus conclude presented model reduce performance even elements missing modalities. note operation boosts performance model zero missing elements. figure shows label error rate modality. pattern appears zero missing elements. model reaches better performance original model audio modality. case combination audio visual latent spaces helps cases represent semantic concept diﬀerent coding vectors network. however networks retrieve correctly concept regardless diﬀerent coding scheme. figure several examples output classiﬁcation cost matrices. ﬁrst multimodal sequence shows example output classiﬁcations correct second multimodal sequence shows correct incorrect output classiﬁcation summary presented solution inspired symbol grounding problem object-word association problem. additionally model relies multimodal sequences semantic elements presented modalities. however believe interesting direction analyze quantitative model cognitive plausible. work planned realistic scenarios visual component segmentable. moreover interested extending wordassociation problem two-dimensional image speech. mind incorporate visual attention mechanism synchronization speech. future model evaluated modalities instance visual audio motor figure association multimodal setups. case modality semantic concepts modality ﬁxed number missing elements. presented model outperforms original model regardless modality number missing elements. sensors three modalities aligned them. note sensorial input collects data action. approaches considered alignment step. option apply three dimensions approach align pair signals evaluate suitable relation. example visual-audio motor-visual audio-motor. finally human language development relies relationship abstract concepts real world collected sensory input. scenario symbol grounding problem might considered simple. however many questions remain still open", "year": 2015}