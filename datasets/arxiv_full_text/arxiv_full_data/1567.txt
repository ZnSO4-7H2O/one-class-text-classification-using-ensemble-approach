{"title": "Reinforcement Learning for Bandit Neural Machine Translation with  Simulated Human Feedback", "tag": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "abstract": "Machine translation is a natural candidate problem for reinforcement learning from human feedback: users provide quick, dirty ratings on candidate translations to guide a system to improve. Yet, current neural machine translation training focuses on expensive human-generated reference translations. We describe a reinforcement learning algorithm that improves neural machine translation systems from simulated human feedback. Our algorithm combines the advantage actor-critic algorithm (Mnih et al., 2016) with the attention-based neural encoder-decoder architecture (Luong et al., 2015). This algorithm (a) is well-designed for problems with a large action space and delayed rewards, (b) effectively optimizes traditional corpus-level machine translation metrics, and (c) is robust to skewed, high-variance, granular feedback modeled after actual human behaviors.", "text": "machine translation natural candidate problem reinforcement learning human feedback users provide quick dirty ratings candidate translations guide system improve. current neural machine translation training focuses expensive human-generated reference translations. describe reinforcement learning algorithm improves neural machine translation systems simulated human feedback. algorithm combines advantage actor-critic algorithm attention-based neural encoderdecoder architecture algorithm well-designed problems large action space delayed rewards effectively optimizes traditional corpus-level machine translation metrics robust skewed high-variance granular feedback modeled actual human behaviors. bandit structured prediction task learning solve complex joint prediction problems limited feedback model system must produce single structured output world reveals score measures good output provides neither correct output feedback possible output extreme sparsity feedback common experimental setup pre-trains good-but-not-great reference system based whatever labeled data available seeks improve time using bandit feedback. common motivation problem setting cost. case translation bilingual experts read source sentence possible translation much quickly provide rating translation produce full translation own. furthermore often collect even less expensive ratings non-experts bilingual breaking reliance expensive data could unlock previously ignored languages speed development broad-coverage machine translation systems. work bandit structured prediction know makes important simplifying assumption score provided world exactly score system must optimize case parsing score attachment score; case machine translation score bleu. simplifying assumption incredibly useful building algorithms highly unrealistic. time want optimize system collecting user feedback must take account ﬁrst contribution strategy simulate expert non-expert ratings evaluate robustness bandit structured prediction algorithms general realistic environment exploitation especially difﬁcult task like machine translation where twenty token sentence vocabulary size approximately possible outputs algorithm gets test exactly one. despite challenges learning nonexpert ratings desirable. real-world scenarios non-expert ratings easy collect stronger forms feedback prohibitively expensive. platforms offer translations quick feedback free users improve systems even setting annotators paid much less expensive bilingual speaker provide rating proposed translation professional translator produce scratch. section describes neural machine translation architecture system formulate bandit neural machine translation reinforcement learning problem discuss standard actor-critic algorithms struggle problem finally describe effective training approach based advantage actor-critic algorithm neural machine translation neural machine translation model neural encoder-decoder directly computes probability translating target sentence source sentence construct family perturbations capture three attributes granularity variance skew. apply perturbations automatically generated scores simulate noisy human ratings. make simulated ratings realistic possible study recent human evaluation data models match noise proﬁles actual human ratings second contribution reinforcement learning solution bandit structured prediction study robustness simulated human ratings combine encoderdecoder architecture machine translation advantage actor-critic algorithm yielding approach simple implement works lowresource bandit machine translation. even substantially restricted granularity high variance feedback skewed rewards combination improves pre-trained models particular realistic settings noise parameters algorithm’s online reward ﬁnal heldaccuracies signiﬁcantly degrade noise-free setting. world reveals context algorithm predicts structured output world reveals reward consider problem learning translate human ratings bandit structured prediction framework. round translation model receives source sentence produces translation receives rating human reﬂects qualr translation. seek algorithm achieves high reward rounds challenge even though model knows good translation knows neither mistakes correct translation looks like. must balance exploration gradient requires rating possible translations feasible bandit nmt. na¨ıve monte carlo reinforcement learning methods reinforce estimates values sample means yields high variance action space large leading training instability. reinforcement learning methods rely function approximation preferred tackling bandit structured prediction large action space capture similarities between structures generalize unseen regions structure space. actor-critic algorithm uses function approximation directly model function called critic model. early attempts bandit adapted actor-critic algorithm bahdanau employs algorithm supervised learning setting. speciﬁcally encoder-decoder critic model substitute true function enables taking full inside expectation unable obtain reasonable results approach. nevertheless insights approach fails problem explains effectiveness approach discussed next section. properties bahdanau problem lacks elements successful actor-critic. ﬁrst access reference translations critic model able observe reference translations training setting bandit assumes never available. second per-step rewards reward function setting known exploited compute immediate rewards taking action bandit actorcritic algorithm struggles credit assignment receives reward translation completed. bahdanau report algorithm degrades rewards delayed until consistent observations. encoder-decoder architecture global attention encoder decoder recurrent neural networks models normally trained supervised learning reference translations available setting reinforcement learning methods require numerical feedback function. bandit reinforcement learning generating process viewed markov decision process continuous state space. states hidden vectors hdec generated decoder. action space target language’s vocabulary. generate translation source sentence model starts initial state hdec representation computed encoder. time step model decides next action take deﬁning stochastic policy directly parametrized parameters model. policy takes current state hdec input produces probability distribution actions next action chosen taking sampling distribution. model computes next state hdec updating current state hdec induces biases potentially drives model wrong optima. values rarely taken actions often overestimated without explicit constraint values actions bahdanau ad-hoc regularization term loss function mitigate issue stablizes algorithm delay update scheme time introduces extra tuning hyper-parameters. advantage actor-critic bandit follow approach advantage actorcritic combine neural encoder-decoder architecture. resulting algorithm—which call ned-ac— approximates gradient single centers reward sample using state-speciﬁc expected future reward reduce variance train separate attention-based encoderdecoder model estimate values. model encodes source sentence decodes sampled translation time step computes whcrt current decoder’s hidden vector learned weight vector. critic model minimizes between estimates true values r]∇ωvω ned-ac better suited problems large action space advantages actor-critic. large action spaces approximating gradients using critic model induces lower biases using critic model. implied deﬁnition model robust biases incurred rarely taken actions since rewards actions weighted small probabilities expectation. addition model much smaller number parameters thus sample-efﬁcient stable train model. attractive properties studied ac’s original paper algorithm summarizes ned-ac bandit nmt. draw single sample model used estimating gradients model critic model. algorithm mini-batches aggregate gradients minibatch update. although focus bandit algorithm naturally works bandit structured prediction problem. goal establish feasibility using real human feedback optimize machine translation system setting collect expert feedback well setting collects non-expert feedback. cases consider expert feedback gold standard wish optimize. establish feasibility driving learning human feedback without full costly user study begin simulation study. aspects human feedback capture mismatch training objective feedbackmaximizing objective human ratings typically binned individual human ratings high variance non-expert ratings skewed respect expert ratings experts high variance human feedback high variance around expected value. natural goal variance model human annotators simulate—as closely possible—how human raters actually perform. human evaluation data recently collected part shared task data consist sentences multiply annotated giving non-expert annotators amazon mechanical turk reference sentence single system translation asking raters judge adequacy translation. data treat average human rating ground truth consider individual human ratings vary around mean. visualize results kernel density estimates standard deviation. figure shows mean rating deviation human ratings mean.as expected standard deviation small extremes large middle fairly large range middle translation whose average score human evaluation scores anywhere between high probability. linear approximation deﬁne variance-based perturbation function gaussian distribution parameterized scale grows shrinks variances current limitation model simulated noise i.i.d. conditioned rating stronger realistic model assuming noise real noise likely heteroscedastic dependent input. erage sentence-bleu algorithm. however realistic scenario human feedback vary average reward algorithm receives perturbed variant sentence-bleu. particular sentence-bleu score algorithm observe pert pert perturbation distribution. reference machine translation system pre-trained using log-likelihood already mismatch training objective feedback focus below. humans provide granular feedback collecting human feedback often effective collect discrete binned scores. classic example likert scale human agreement star ratings product reviews. insisting human judges provide continuous values demotivate raters without improving rating quality glish german tokenize clean sentences using moses chinese stanford chinese word segmenter segment sentences tokenize. remove sentences length greater resulting average sentence length iwslt data supervised training development iwslt data bandit training previous years’ development evaluation data testing. task ﬁrst supervised training pre-train reference model using supervised learning. training also pre-train critic model translations sampled pre-trained model. next enter bandit learning mode models observe source sentences bandit training set. unless speciﬁed differently train models ned-ac pass bandit training set. perturbation function applied per-sentence bleu scores applied stage pre-training stage. measure improvement evaluation metric bandit training sref sref metric computed reference models metric computed models trained ned-ac. primary interest per-sentence bleu average sentence-level bleu translations sampled scored bandit learning pass. metric represents average expert ratings want optimize real-world scenarios. also measure heldout bleu corpuslevel bleu unseen test translations greedily decoded models. shows much method improves translation quality since corpus-level bleu correlates better human judgments sentence-level bleu. randomness random sampling model exploration well randomness reward function repeat experiment times report mean results conﬁdence intervals. over bandit learning set’s sentences seen supervised learning. performance gain mainly reﬂects well model leverages weak learning signals improve previously made predictions. generalizability measured performance gain test sets overlap training sets. figure average rating versus kernel density estimate variance human ratings around mean linear ﬁts. human scores vary around middling judgments extreme judgments. choose language pairs different language families different typological properties german-to-english chinese-to-english parallel transcriptions talks pairs languages machine translation track iwslt language pair split data four sets supervised training bandit training development testing model conﬁguration model critic model encoder-decoder models global attention encoder decoder unidirectional single-layer lstms. word embedding size lstm hidden size source target vocabulary sizes dropout experiments. train models adam optimizer batch size adam’s hyperparameter during pre-training bandit learning pre-training starting ﬁfth pass decay factor perplexity development increases. model reaches highest corpus-level bleu development passes supervised training data critic model’s training error stabilizes passes. training speed s/batch supervised pre-training s/batch training ned-ac algorithm. section describe results experiments broken following questions ned-ac improves reference models effect three perturbation functions algorithm whether algorithm improves corpus-level metric corresponds well human judgments single round feedback. setting models observe source sentence producing translation. deen zh-en ned-ac improves per-sentence bleu reference models single pass poor initialization. policy gradient algorithms difﬁculty improving poor initializations especially problems large action space model-based exploration ineffective actions equal probabilities whether ned-ac problem repeat experiment setup reference models pretrained single pass. surprisingly nedac highly effective improving poorly trained models comparisons supervised learning. demonstrate effectiveness nedac compare training reference models supervised learning single pass bandit training set. surprisingly observing ground-truth translations barely improves models per-sentence bleu fully trained possible explanation models already reached full capacity beneﬁt examples. ned-ac enhances models eliminates mismatch supervised training objective evaluation objective. weakly trained reference models ned-ac also signiﬁcantly outperforms supervised learning table translation scores improvements based single round un-perturbed bandit feedback. per-sentence bleu heldout bleu comparable former sentence-bleu latter corpus-bleu. multiple rounds feedback. supervised learning models memorize reference translations models able exploit explore effectively. train models ned-ac passes observe much signiﬁcant ∆persentence bleu training single pass pairs language granular rewards. discretize persentence bleu scores using pertgran vary compared continuous rewards pairs languages ∆per-sentence bleu affected least granularity decreases ∆persentence bleu monotonically degrades. however even models still improve least point. high-variance simulate noisy rewards using model human rating models withstand amount variance human eval data without dropping ∆persentence bleu. amount variance attains matching amount variance human data ∆per-sentence bleu pairs languages. variance injected models degrade quickly still improve pre-trained models. variance detrimental type perturbation ned-ac among three aspects human ratings model. skewed skewed raters ned-ac robust skewed scores. ∆per-sentence bleu least unskewed scores skew values. scores extremely harsh ∆per-sentence bleu degrade signiﬁcantly degree skew score suppressed less giving little signal models learn from. spectrum models less sensitive motivating scores per-sentence bleu unaffected zh-en decreases de-en. method also improves pre-trained models heldout bleu metric correlates translation quality better per-sentence bleu scores perturbed rating model observe similar patterns persentence bleu models robust perturbations except scores coarse harsh high variance supervised learning improves heldout bleu better possibly maximizing log-likelihood reference translations correlates strongly maximizing heldout bleu predicted translations maximizing per-sentence bleu predicted translations. figure performance gains models trained ned-ac per-sentence bleu heldout bleu various degrees granularity variance skew scores. performance gains models trained un-perturbed scores within shaded regions. ratings provided humans used effective learning signals machines. reinforcement learning become facto standard incorporating feedback across diverse tasks robot voice control myoelectric control virtual assistants recently learning framework combined recurrent neural networks solve machine translation dialogue generation neural architecture search device placement approaches general structured prediction bandit feedback show broader efﬁcacy framework. ranzato describe mixer training neural encoder-decoder models reinforcement learning approach closely related requires policy-mixing strategy uses linear critic model. among work bandit closest kreutzer also tackle problem using neural encoder-decoder models take advantage state-of-the-art reinforcement learning method; devise strategy simulate noisy rewards; demonstrate robustness method noisy simulated rewards. results show bandit feedback effective feedback mechanism neural machine translation systems. despite errors human annotations hurt machine learning models many tasks obvious question whether could extend framework model individual annotator preferences learn personalized models handle heteroscedastic noise another direction apply active learning techniques reduce sample complexity required improve systems extend richer action spaces problems like simultaneous translation requires prediction reordering among strategies minimize delay effectively translate sentence many thanks yvette graham help human evaluations data. thank clip members useful discussions ideas paper. also thank anonymous reviewers thorough insightful comments. work supported grants iis-. boyd-graber also partially supported grants iis-iis- ncse-. daum´e also supported grant well amazon research award. opinions ﬁndings conclusions recommendations expressed authors necessarily reﬂect view sponsor. references gediminas adomavicius jingjing zhang. impact data characteristics recommender systems performance. transactions management information systems dzmitry bahdanau philemon brakel kelvin anirudh goyal ryan lowe joelle pineau aaron courville yoshua bengio. actor-critic algorithm sequence prediction. international conference learning representations mauro cettolo christian girardi marcello federico. inventory transcribed translated talks. conference european association machine translation trento italy. mauro cettolo niehues sebastian st¨uker luisa bentivogli roldano cattoni marcello federico. iwslt evaluation campaign. international workshop spoken language translation mauro cettolo niehues sebastian st¨uker luisa bentivogli marcello federico. report iwslt evaluation campaign iwslt international workshop spoken lan. guage translation kai-wei chang akshay krishnamurthy alekh agarwal daum´e john langford. learning search better teacher. proceedings international conference machine learning pi-chuan chang michel galley chris manning. optimizing chinese word segmentation workshop machine translation performance. machine translation. neural machine translation model consists encoder decoder recurrent neural network closely follow structure model. directly models posterior distribution translating source sentence target sentence tokens target sentence prior local disitribution modeled multinomial distribution target language’s vocabulary. compute distribution applying linear transformation followed softmax function decoder’s output vector hdec training encoder ﬁrst encodes continuous vector used initial hidden vector decoder. paper simply returns last hidden vector encoder. decoder performs updates produce sequence hidden vectors alvin grissom jordan boyd-graber john morgan daum´e iii. don’t ﬁnal verb wait reinforcement learning simultaneous machine translation. empirical methods natural language processing jiwei monroe alan ritter michel galley jianfeng jurafsky. deep reinforcement learning dialogue generation. empirical methods natural language processing jordan boyd-graber daum´e iii. interpretese translationese uniqueness human strategies simultaneous interpretaconference north american chaption. association computational linguistics alvin grissom jordan boyd-graber daum´e iii. syntax-based rewriting simultaneous machine translation. empirical methods natural language processing jonathan herlocker joseph konstan john riedl. explaining collaborative ﬁltering recacm conference computer ommendations. supported cooperative work. charles isbell christian shelton michael kearns satinder singh peter stone. social reinternational coninforcement learning agent. ference autonomous agents sham kakade shai shalev-shwartz ambuj tewari. efﬁcient bandit algorithms online international conference multiclass prediction. machine learning kristian kersting christian plagemann patrick pfaff likely hetwolfram burgard. intereroscedastic gaussian process regression. national conference machine learning philipp koehn hieu hoang alexandra birch chris callison-burch marcello federico nicola bertoldi brooke cowan wade shen christine moran richard zens moses open source toolkit statistical machine translation. association computational linguistics robert loftin james macglashan michael littman matthew taylor david roberts. strategy-aware technique learning behaviors discrete human feedback. technical report north carolina state university. dept. computer science. minh-thang luong hieu pham christopher manning. effective approaches attentionempirbased neural machine translation. ical methods natural language processing azalia mirhoseini hieu pham quoc benoit steiner rasmus larsen yuefeng zhou naveen kumar mohammad norouzi samy bengio jeff dean. device placement optimization reinforcement learning. international conference machine learning shachar mirkin scott nowson caroline brun julien perez. motivating personality-aware conference machine translation. empirical methods natural language processing volodymyr mnih adria puigdomenech badia mehdi mirza alex graves timothy lillicrap harley david silver koray kavukcuoglu. asynchronous methods deep reinforcement learning. international conference machine learning patrick pilarski michael dawson thomas degris farbod fahimi jason carey richard sutton. online human training myoelectric prosthesis controller actor-critic reinforcement learning. ieee international conference rehabilitation robotics carolyn preston andrew colman. optimal number response categories rating scales reliability validity discriminating power respondent preferences. acta psychologica ella rabinovich shachar mirkin nath patel lucia specia shuly wintner. personalized machine translation preserving original author traits. association computational linguistics marc’aurelio ranzato sumit chopra michael auli wojciech zaremba. sequence level traininternational recurrent neural networks. conference learning representations rion snow brendan o’connor daniel jurafsky andrew cheap fast—but good? evaluating non-expert annotations natural language tasks. empirical methods natural language processing artem sokolov julia kreutzer christopher stefan riezler. learning structured predictors bandit feedback interactive nlp. association computational linguistics artem sokolov stefan riezler tanguy urvoy. bandit structured prediction learning partial feedback statistical machine translation. proceedings summit miami tenorio-gonzalez eduardo morales luis villase˜nor-pineda. dynamic reward shaping training robot voice. ibero-american conference artiﬁcial intelligence. springer pages andrea thomaz cynthia breazeal. teachable robots understanding human teaching behavior build effective robot learners. artiﬁcial intelligence andrea lockerd thomaz cynthia breazeal reinforcement learning human teachers evidence feedback guidance implications learning performance. association advancement artiﬁcial intelligence", "year": 2017}