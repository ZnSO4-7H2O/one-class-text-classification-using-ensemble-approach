{"title": "Attribute2Image: Conditional Image Generation from Visual Attributes", "tag": ["cs.LG", "cs.AI", "cs.CV"], "abstract": "This paper investigates a novel problem of generating images from visual attributes. We model the image as a composite of foreground and background and develop a layered generative model with disentangled latent variables that can be learned end-to-end using a variational auto-encoder. We experiment with natural images of faces and birds and demonstrate that the proposed models are capable of generating realistic and diverse samples with disentangled latent representations. We use a general energy minimization algorithm for posterior inference of latent variables given novel images. Therefore, the learned generative models show excellent quantitative and visual results in the tasks of attribute-conditioned image reconstruction and completion.", "text": "abstract. paper investigates novel problem generating images visual attributes. model image composite foreground background develop layered generative model disentangled latent variables learned end-to-end using variational auto-encoder. experiment natural images faces birds demonstrate proposed models capable generating realistic diverse samples disentangled latent representations. general energy minimization algorithm posterior inference latent variables given novel images. therefore learned generative models show excellent quantitative visual results tasks attributeconditioned image reconstruction completion. generative image modeling fundamental interest computer vision machine learning. early works studied statistical physical principles building generative models lack eﬀective feature representations results limited textures particular patterns well-aligned faces. recent advances representation learning using deep neural networks nourish series deep generative models enjoy joint generative modeling representation learning bayesian inference adversarial training works show promising results generating natural images generated samples still resolution perfect fundamental challenges learning unconditioned generative models images. paper interested generating object images high-level description. example would like generate portrait images match description young girl brown hair smiling conditioned treatment reduces sampling uncertainties helps generating realistic images thus potential real-world applications forensic semantic photo editing high-level descriptions usually natural languages underlies corresponding images essentially group facts visual attributes extracted sentence. example above attributes inspired layered image models disentangle latent factors groups related uncertain properties foreground object related background model generation process layered composition. particular foreground overlaid background background visibility depends foreground shape position. therefore propose novel layered image generative model disentangled foreground background latent variables. entire background ﬁrst generated background variables foreground variables combined given attributes generate object layer shape determining visibility background ﬁnally image composed summation object layer background layer gated visibility map. learn layered generative model end-to-end deep neural network using variational auto-encoder variational auto-encoder includes encoders recognition models approximating posterior distributions foreground background latent variables respectively decoders generating foreground image full image composition. assuming latent variables gaussian whole network trained end-to-end back-propagation using reparametrization trick. generating realistic samples certainly important goal deep generative models. moreover generative models also used perform bayesian inference novel images. since true posterior distribution latent variables evaluate proposed model datasets labeled faces wild dataset caltech-ucsd birds-- dataset dataset attributes -dimensional vectors describing gender expressions hair many others dataset -dimensional binary attribute vectors converted descriptions bird parts colors. organize experiments following tasks. first demonstrate quality attribute-conditioned image generation comparisons nearest-neighbor search analyze disentangling performance latent space corresponding foreground-background layers. second perform image reconstruction completion novel test images posterior inference quantitative evaluation. results experiments show superior performance proposed model previous art. contributions paper summarized follows tackle problem learning conditional variational auto-encoders propose novel layered foreground-background generative model signiﬁcantly improves generation quality complex images. propose general optimization-based method posterior inference novel images evaluate generative models context image reconstruction completion. image generation. terms generating realistic novel images several recent work relevant ours. dosovitskiy proposed generate chairs given graphics code using deep convolutional neural networks kulkarni used variational auto-encoders model rendering process objects. models assume existence graphics engine training virtually inﬁnite amount training data and/or pairs rendered images diﬀer factor variation. therefore directly applicable natural image generation. work studied generation rendered images complete description trained synthetic images generation images incomplete description still under-explored. fact image generation incomplete description challenging task one-to-one mapping formulation inherently limited. gregor developed recurrent variational auto-encoders spatial attention mechanism allows iterative image generation patches. elegant algorithm mimics process human drawing time faces challenges scaling large complex images. recently generative adversarial networks developed image generation. models trained other generative model aims capture data distribution discriminative model attempts distinguish generated samples training data. training based min-max objective known challenging optimize. layered modeling images. layered models representations images studied context moving still object segmentation layered structure introduced generative image modeling tang modeled occluded images gated restricted boltzmann machines achieved good inpainting denoising results well cropped face images. roux explicitly modeled occlusion layer masked restricted boltzmann machine separating foreground background demonstrated promising results small patches. though similar proposed gating form models face challenges applied model large natural images diﬃculty learning hierarchical representation based restricted boltzmann machine. multimodal learning. generative models image text studied multimodal learning model joint distribution multiple data modalities example srivastava salakhutdinov developed multimodal deep boltzmann machine models joint distribution image text sohn proposed improved shared representation learning multimodal data bi-directional conditional prediction deriving conditional prediction model data modality given vice versa. works focused shared representation learning using hand-crafted low-level image features therefore limited applications conditional image text retrieval actual generation images. section describe proposed method attribute-conditioned generative modeling images. ﬁrst describe conditional variational autoencoder followed formulation layered generative model variational learning. log-likelihood proposed variational auto-encoders maximize variational lower bound log-likelihood speciﬁcally auxiliary distribution introduced approximate true posterior refer base model conditional variational refer auxiliary proposal distribution recognition model conditional data distribution generation model. ﬁrst term kl||pθ) regularization term reduces prior proposal distribution second term likelihood samples. practice usually distribution given convenient assume standard deviation function constant shared pixels latent factors capture data variations. keep assumption rest paper particularly mentioned. thus rewrite second term equation suﬀer incorrectly estimated mask gates foreground region imperfect mask estimation. instead approximate following formulation robust estimation error mask lighting condition stable background distance safely assume foreground background pixels generated independent latent factors. propose disentangled representation latent space together attribute captures foreground factors background factors. result foreground layer generated background layer foreground shape position determine background occlusion gating layer generated last layer sigmoid function. learning. challenging learn layered generative model fullyunsupervised manner since need infer image only. paper assume foreground layer observable training train model disentangled latent variables refer layered model disentangling conditional variational auto-encoder compare graphical models discvae vanilla cvae figure based layered generation process write generation model error predicting cross entropy predicting binary mask supplementary material details derivation. generation recognition models parameterized convolutional neural networks trained end-to-end single architecture back-propagation. introduce exact network architecture experiment section. attribute-conditioned generative model trained inference generation image given attribute latent variable straight-forward. however inference latent variable given image corresponding attribute unknown. fact latent variable inference quite useful enables model evaluation novel images. simplicity introduce inference algorithm based vanilla cvae algorithm directly applied proposed discvae generative models thrown away variational learning objective; hand approximation even exist models gans. propose general approach posterior inference optimization latent space. using bayes’ rule formulate posterior inference note abuse mean function general image generation function. since complex neural network optimizing essentially error back-propagation energy function variable solve adam method algorithm actually shares similar spirit recently proposed neural network visualization texture synthesis algorithms diﬀerence generation models recognition algorithms recognition models generation. compared describes diﬀerent aspects facial appearance gender facial expression. trained model using data following training-testing split face identities distinct train test sets. experiments cropped bird region using tight bounding computed attribute vector describes bird parts colors. trained model using data following training-testing split model training held-out training data validation. color channel random value augmenting image residual random tradeoﬀ parameter rotating images around centering point random angle rescaling images scale performing random cropping regions. note methods designed invariant architecture design. discvae build four convolutional neural networks auto-encoding style training. foreground encoder network consists convolution layers followed fully-connected layers attribute stream merged image stream recognition network. foreground decoder network consists fully-connected layers followed convolution layers -by- upsampling separated last convolution layer. adopt encoder/decoder architecture background networks fewer number channels. supplementary material details. diﬀerent architectures diﬀerent datasets dimensions foreground latent space dimensions background latent space experiments dataset; dimensions foreground background latent spaces dataset. compared vanilla cvae proposed discvae parameters additional convolutions introduced twostream architecture. however found adding parameters vanilla cvae lead much improvement terms image quality. although proposed method segmentation masks supervision naive mask prediction comparable proposed model setting based preliminary results. fact proposed discvae architecture assigns foreground/background generation individual networks composite gated interaction found eﬀective practice. implementation details. used adam stochastic optimization experiments. training used mini-batch size learning rate also added dropout layer ratio image stream encoder network merging attribute stream. posterior inference used learning rate iterations. models implemented using deep learning toolbox torch baselines. vanilla cvae model used convolution architecture foreground encoder network foreground decoder network. demonstrate signiﬁcance attribute-conditioned modeling trained unconditional variational auto-encoders almost convolutional architecture cvae. sampled isotropic gaussian distribution. vanilla cvae output generation. comparison discvae foreground image considered by-product layered generation process. evaluation visualized samples generated model figure compared corresponding image testing name reference image. demonstrate model exploit trivial solution attribute-conditioned generation memorizing training data added simple baseline experimental comparison. basically given attribute description testing conducted nearest neighbor search training set. used mean squared error distance metric nearest neighbor search visual results code please refer project website https//sites.google.com/site/ attributeimage/. attribute-conditioned face image generation. figure face images generated proposed models look realistic non-trivially diﬀerent other especially view-point background color. moreover clear images generated discvae clear boundaries background. comparison boundary regions hair area background quite blurry samples generated vanilla cvae. observation suggests limitation vanilla cvae modeling hair pattern face images. also justiﬁes signiﬁcance layered modeling latent space disentangling attribute-conditioned generation process. compared nearest neighbors training generated samples better reﬂect input attribute description. quantitative evaluations please refer supplementary material details. attribute-conditioned bird image generation. compared experiments database bird image modeling challenging bird images diverse shapes color patterns binary-valued attributes sparse higher dimensional. figure diﬀerence versions proposed cvae model. basically samples generated vanilla cvae blurry sometimes blended background area. however samples generated discvae clear bird shapes reﬂect input attribute description well. conﬁrms strengths proposed layered modeling images. attribute-conditioned image progression. better analyze proposed model generate images interpolated attributes gradually increasing decreasing values along attribute dimension. regard process attribute-conditioned image progression. speciﬁcally attribute vector modify value attribute dimension interpolating minimum maximum attribute value. then generate images interpolating value attribute vectors keeping latent variable ﬁxed. visualization attribute vector testing set. figure samples generated progression visually consistent attribute description. face images changing attributes like gender identity-related visual appearance changed accordingly viewpoint background color facial expression well preserved; hand changing attributes like facial expressioneyewear hair color global appearance well preserved diﬀerence appears local region. bird images changing primary color other global shape background color well preserved. observations demonstrated generation process model well controlled input attributes. analysis latent space disentangling. better analyze discvae performed following experiments latent space. model image generation process driven three factors attribute foreground latent variable background latent variable changing variable ﬁxing analyze variable contributes ﬁnal generation results. visualize samples generated background gating variables figure summarized observations follows background generated samples look diﬀerent identical foreground region change background latent variable only; foreground region generated samples look diverse terms viewpoints still look similar terms appearance samples uniform background pattern change foreground latent variable only. interestingly face images identify hole background generation. considered location prior face images since images relatively aligned. meanwhile generated background birds relatively uniform demonstrates model learned recover missing background training also suggests foreground background disentangled latent space. image completion. given test image synthetic occlusion evaluate whether model capacity occluded region recognizing observed region. denote occluded region observed region respectively. completion ﬁrst maximizes types occlusions occlusion region occlusion mouth region occlusion face region occlusion right half image. occluded regions pixel value bird image consider blocks general good reconstructing predicting occluded region unseen images however bird images vanilla cvae model signiﬁcant failures general. agreed previous results attributeconditioned image generation. addition demonstrate signiﬁcance attribute-conditioned modeling compared vanilla cvae discvae unconditional image reconstruction completion. seen fig. generated images using attributes actually perform better terms expression eyewear quantitative comparisons measured pixel-level mean squared error entire image occluded region reconstruction completion respectively. summarized results table quantitative analysis highlighted beneﬁts attributeconditioned modeling importance layered modeling. conclude paper studied novel problem attribute-conditioned image generation proposed solution cvaes. considering compositional structure images proposed novel disentangling cvae layered representation. results faces birds demonstrate models generate realistic samples diverse appearance especially discvae signiﬁcantly improved generation quality bird images. evaluate learned generation models novel images also developed optimization-based approach posterior inference applied tasks image reconstruction completion quantitative evaluation. acknowledgement. work supported part career iis- n--- sloan research fellowship gift adobe. acknowledge nvidia donation gpus. also thank yuting zhang scott reed junhyuk ruben villegas seunghoon hong wenling shang kibok lajanugen logeswaran zhang changhan wang zhang helpful comments discussions. provide detailed derivation objective function disentangling cvae similarly vanilla cvae input image foreground mask attribute labels latent variables fully-connected layers neurons). attribute stream merged image stream recognition network. foreground decoder network consists fully-connected layers followed convolution adopt encoder/decoder architecture background networks fewer number channels. better modeling background latent variable introduce attribute foreground latent variable background encoder network also agrees assumption made order measure performance quantitatively attribute space propose evaluate whether generated samples exactly capture condition therefore trained separate convolutional neural network scratch attribute regressor using image-attribute pairs training set. attribute regressor shares almost architecture auxiliary recognition model used generative training. reference attribute regressor achieves mean squared error cosine similarity test set. attribute vector test randomly generate samples feed attribute regressor. compute cosine similarity mean squared error reference attribute predicted attributes generated samples. baseline method compute cosine similarity reference attribute predicted attributes nearest neighbor samples furthermore verify proposed method take unfair advantage evaluation someblurred image generation another baseline method blurring images average ﬁlter. table generated samples quantitatively closer reference attribute testing nearest attributes training set. addition explicit foreground-background modeling produces accurate samples attribute space. table quantitative comparisons attribute-conditional image generation. best samples evaluated cosine similarity mean squared error attribute space. pre-trained convolutional neural network predict attributes generated samples.", "year": 2015}