{"title": "Tutorial on Answering Questions about Images with Deep Learning", "tag": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.NE"], "abstract": "Together with the development of more accurate methods in Computer Vision and Natural Language Understanding, holistic architectures that answer on questions about the content of real-world images have emerged. In this tutorial, we build a neural-based approach to answer questions about images. We base our tutorial on two datasets: (mostly on) DAQUAR, and (a bit on) VQA. With small tweaks the models that we present here can achieve a competitive performance on both datasets, in fact, they are among the best methods that use a combination of LSTM with a global, full frame CNN representation of an image. We hope that after reading this tutorial, the reader will be able to use Deep Learning frameworks, such as Keras and introduced Kraino, to build various architectures that will lead to a further performance improvement on this challenging task.", "text": "together development accurate methods computer vision natural language understanding holistic architectures answer questions content real-world images emerged. tutorial build neural-based approach answer questions images. base tutorial datasets daquar vqa. small tweaks models present achieve competitive performance datasets fact among best methods combination lstm global full frame representation image. hope reading tutorial reader able deep learning frameworks keras introduced kraino build various architectures lead performance improvement challenging task. tutorial build architectures answer questions images. architectures based papers topic malinowski malinowski broadly project towards visual turing test. particular encoder-decoder perspective malinowski allows effectively experiment various design choices. sake simplicity consider classiﬁcation-based approach answer questions images although approach generate answers word-by-word also studied community tutorial mainly focus daquar dataset possible directions apply learnt techniques also pointed. first familiar task answering questions images dataset implements task next build blind models answer questions images without actually seeing images. models already exhibit reasonable performance effectively learn various biases exist dataset also interpret learning common sense knowledge subsequently build language+vision models answer questions based textual visual inputs. finally leave tutorial possible research directions. technical aspects tutorial originally written using python notebook reader welcome download tutorial. instructions necessary notebook version tutorial provided following https//github.com/mateuszmalinowski/visual_turing_test-tutorial. tutorial heavily python code therefore expected reader either already knows language quickly learn however made effort make tutorial approachable wider audience. kraino framework prepared tutorial order simplify development question answering architectures. hood uses theano keras frameworks build deep learning models. also various cnns representations extracted images downloaded explained beginning notebook tutorial. also highlight exercises curious reader attempt solve. this tutorial presented ﬁrst time summer school integrating vision language deep learning. http//mpii.de/visual_turing_test https//github.com/mateuszmalinowski/visual_turing_test-tutorial/blob/master/visual_ right side black telephone left side chair desk image front white door left side desk telephone image desk book scissor papers tape dispenser image largest brown objects carton image color chair front white wall image note format question answer image. look figure ﬁgure lists images associated question-answer pairs. also comments challenges associated question-answerimage triplets. answer properly wide range questions answerer needs understand scene visually understand question also arguably resort common sense knowledge even know preferences person asking question e.g. ‘behind’ exactly means ‘what behind table?’. hence architectures answer questions images face many challenges. ambiguities make also difﬁcult judge provided answers. revisit issue later section. meantime curious reader answer following question. following code returns dictionary three views daquar dataset. look ‘text’ view. returns function dataset split dataset’s textual view. executing following code makes clear. access textual representation questions. however helpful since neural networks expect numerical input hence cannot really work text. need transform textual input numerical value vector values. particularly successful representation called one-hot vector binary vector exactly non-zero entry. entry points corresponding word vocabulary. illustration shown figure illustrative example above ﬁrst need build suitable vocabulary textual training data next transform one-hot representations. following code this. start building frequencies table wordcount_x frequencies.split) print least frequent words n_show print key=lambda reverse=true)) print key=lambda addition special extra symbols occur training dataset. important former sequences order number temporal elements; latter words exist training set. armed vocabulary build one-hot representations training data. however necessary even wasteful. one-hot representation input text explicitly build long sparse vectors instead operates indices. example figure would encoded sparsity existing one-hot representation efﬁciently operate indices instead performing full linear transformations matrix-vector multiplications. reﬂected following claim. kraino.utils.input_output_space import encode_answers_one_hot train_raw_y train_text_representation wordcount_y frequencies.split) wordindex_y indexword_y build_vocabulary train_y encode_answers_one_hot is_only_first_answer_word=true max_answer_time_steps=max_answer_time_steps) last step encode test questions. need later well models generalize question-answerimage triplets. remember however vocabulary generated training samples. summary started questions training set. build vocabulary. next encode questions sequences one-hot vectors based vocabulary. finally vocabulary encode questions test set. word absent extra token denote fact encode token word. call learning rate gradient wrt. weights learning rate hyper-parameter must advance. rule shown called update variants also possible. fact variant called adam cast question answering problem classiﬁcation framework classify input class represents answer word. therefore commonly used classiﬁcation logistic regression objective ewzφ. denotes output model note however another variant providing answers called answer generation also possible training need execute following code. theano since computing gradients quickly become tedious especially complex models search tools could automatize process. imagine build model gradient executing tool something like following piece code. would deﬁnitely speed prototyping. theano tool speciﬁcally tailored work deep learning models. broader understanding theano check suitable tutorial. following coding example deﬁnes relu popular activation function deﬁned relu well derive derivative using theano. note however that example obviously scratch surface. theano_x t.scalar define relationship symbolic input symbolic output theano_y t.maximum it’s time symbolic gradient wrt. symbolic variable theano_nabla_y t.grad keras builds upon theano signiﬁcantly simpliﬁes creating deep learning models well training models effectively speeding prototyping even further. keras also abstracts away technical burden symbolic variable creation. many examples using keras found following links https//keras.io/getting-started/sequential-model-guide/ https//keras.io/ getting-started/functional-api-guide/. note that tutorial older sequential model. please also attention version keras since versions compatible tutorial. purpose visual turing test tutorial compiled light framework builds keras simplify building training ‘question answering’ machines. tradition using greek names call kraino. note parts kraino data provider already covered tutorial. following lstm approaches answer questions images surprisingly without images. turns substantial fraction questions answered without access image rather resorting common sense instance ‘what placed table?’ ‘how many eyes human have?’. answers like ‘chair’ quite likely good answers. figure illustrates method. already seen before ﬁrst encode input sentence one-hot vector representations. sparse representation next embedded denser space matrix next denser representations summed classiﬁed ‘softmax’. notice that identity matrix would obtain histogram word’s occurrences. first define model using keras/kraino keras.layers.core import activation keras.layers.core import dense keras.layers.core import dropout keras.layers.core import timedistributedmerge keras.layers.embeddings import embedding kraino.core.model_zoo import abstractsequentialmodel kraino.core.model_zoo import abstractsingleanswer kraino.core.model_zoo import abstractsequentialmultiplewordanswer kraino.core.model_zoo import config kraino.core.keras_extensions import dropmask kraino.core.keras_extensions import lambdawithmask kraino.core.keras_extensions import time_distributed_masked_ave model inherits abstractsingleanswer produces single answer words multiple answer words need inherit abstractsequentialmultiplewordanswer class blindbow although working pretty well still something disturbing approach. consider following question ‘what right side black telephone left side chair swap ‘chair’ ‘telephone’ question would different meaning. recurrent neural networks developed mitigate issue directly processing time series. figure illustrates ﬁrst word embedding given unit. unit next processes embedding outputs second unit. unit takes output ﬁrst unit word embedding inputs outputs algebraic combination inputs. last recurrent unit builds representation whole sequence. output next given softmax classiﬁcation. among challenges approaches deal maintaining long-term dependencies. roughly speaking inputs coming following steps getting easier ‘forget’ information beginning lstm particularly popular recurrent neural networks preserve longer dependencies extent. create recurrent neural network following. first define model using keras/kraino keras.layers.core import activation keras.layers.core import dense keras.layers.core import dropout keras.layers.embeddings import embedding keras.layers.recurrent import keras.layers.recurrent import lstm kraino.core.model_zoo import abstractsequentialmultiplewordanswer kraino.core.model_zoo import config kraino.core.keras_extensions import dropmask kraino.core.keras_extensions import lambdawithmask kraino.core.keras_extensions import time_distributed_masked_ave model inherits abstractsingleanswer produces single answer words multiple answer words need inherit abstractsequentialmultiplewordanswer class blindrnn curious reader encouraged experiment language-only models. instance inﬂuence particular modules overall performance reader following exercise. summary models opposite consider order words question. moreover substantial number questions answered without access images. explained models learn speciﬁc dataset statistics interpreted common sense knowledge. able monitor progress task need ways evaluate architectures task. otherwise would know judge architectures even worse would even know goal moreover also automatic evaluation measures otherwise reproducibility questionable evaluation costs high. although early work visual turing test argues keeping answer words ﬁxed vocabulary order keep evaluation simpler still difﬁcult automatically evaluate architectures ambiguities occur answers. ambiguities naming objects sometimes synonyms sometimes fuzziness. instance ‘chair’ ‘armchair’ ‘chair’ ‘armchair’ something between? semantic boundaries become even fuzzy increase number categories. could easily mutually exclusive different categories categories categories? arguably cannot think terms equivalence class anymore rather terms similarities. ‘chair’ semantically similar ‘armchair’ ‘horse’. simple example shows main drawback traditional binary evaluation measure accuracy. metric scores names otherwise. acc. call ambiguities word-level ambiguities ambiguities arguably difﬁcult handle. instance question phrased multiple ways. language spatial relations also ambiguous. language tends also rather vague sometimes skip details resort common sense. ambiguities rooted culture. address world-level ambiguities malinowski fritz propose wups. address ambiguities caused various interpretations image question malinowski propose consensus measures. sake simplicity tutorial wups. hand arguably easier evaluate architectures daquar image captioning datasets. former restricts output space categories still requires holistic comprehension. remind figure shows ambiguities exists daquar. wu-palmer similarity depends choice ontology. popular large ontology wordnet although wu-palmer similarity work shallow ontologies rather interested ontologies hundreds even thousands categories. indoor scenarios turns many indoor ‘things’ share similar levels ontology hence wu-palmer similarities small entities. following code exempliﬁes issue. ‘armchair’ ‘wardrobe’ surprisingly close other. because large ontologies indoor ‘things’ semantically ‘indoor things’. issue motivated deﬁne thresholded wu-palmer similarity score deﬁned follows hand-chosen threshold. empirically found works daquar moreover since daquar answers sets answer words ‘knifefork’ ‘forkknife’ extended measure work sets. call wu-palmer score shortly wups. detailed exposition wups beyond tutorial curious reader encouraged read ‘performance measure’ paragraph malinowski fritz note measure malinowski fritz deﬁned broader essentially abstracts away particular similarities wu-palmer similarity ontology. wups wups threshold worth noting practical implementation wups needs deal synsets. thus recommended download script http//datasets.d.mpi-inf.mpg.de/ mateuszvisual-turing/calculate_wups.py re-implement caution. consensus measure handles ambiguities caused various interpretations question image. tutorial cover measure. curious reader encouraged read ‘human consensus’ malinowski lack coverage since wups based ontology always recognizes words. instance ‘garbage bin’ missing ‘garbage can’ perfectly ﬁne. check yourself either source code provided above using online script. deal problem? daquar take optimistic perspective always consider highest similarity score. works wups restricted indoor domain vocabulary based training set. issue taken caution whenever wups adapted domains. threshold good threshold dataset dependent. case seems work well forgivable rather reported ‘historical’ reasons. however following papers still consider report plain set-based accuracy scores computed script using argument wups. predict probabilities every word predictions_scores text_bow_model.predict) print follow maximum likelihood principle best indices vocabulary predictions_best argmax print decode predicted indices word answers predictions_answers predictions_best] print) kraino.core.model_zoo import word_generator first need word_generator _config maximum likelihood word generator text_rnn_model._config.word_generator word_generator predictions_answers text_rnn_model.decode_predictions. already extracted features advance using caffe another excellent framework deep learning particularly good cnns. also makes sure visual textual features aligned correspondingly train_image_names train_text_representation name visual features cnn_name=’vgg_net’ cnn_name=’googlenet’ cnn_name=’fb_resnet’ layer used extract features perception_layer=’fc’ perception_layer=’pool-x_s’ perception_layer=’resc-’ prefix since l-normalized visual features perception_layer=’l_resc-’ similarly blind model start encoding question. here explore ways combining modalities concatenation piece-wise multiplication. sake simplicity ﬁne-tune visual representation keras.models import sequential keras.layers.core import activation keras.layers.core import dense keras.layers.core import dropout keras.layers.core import layer keras.layers.core import merge keras.layers.core import timedistributedmerge keras.layers.embeddings import embedding kraino.core.model_zoo import abstractsequentialmodel kraino.core.model_zoo import abstractsingleanswer kraino.core.model_zoo import abstractsequentialmultiplewordanswer kraino.core.model_zoo import config kraino.core.keras_extensions import dropmask kraino.core.keras_extensions import lambdawithmask kraino.core.keras_extensions import time_distributed_masked_ave model inherits abstractsingleanswer produces single answer words multiple answer words need inherit abstractsequentialmultiplewordanswer class visionlanguagebow first define model using keras/kraino keras.models import sequential keras.layers.core import activation keras.layers.core import dense keras.layers.core import dropout keras.layers.core import layer keras.layers.core import merge keras.layers.core import timedistributedmerge keras.layers.embeddings import embedding kraino.core.model_zoo import abstractsequentialmodel kraino.core.model_zoo import abstractsingleanswer kraino.core.model_zoo import abstractsequentialmultiplewordanswer kraino.core.model_zoo import config kraino.core.keras_extensions import dropmask kraino.core.keras_extensions import lambdawithmask kraino.core.keras_extensions import time_distributed_masked_ave model inherits abstractsingleanswer produces single answer words multiple answer words need inherit abstractsequentialmultiplewordanswer class visionlanguagebow textual_embedding_dim=embedding_dim visual_embedding_dim=embedding_dim multimodal_merge_mode=multimodal_merge_mode input_dim=len) output_dim=len) visual_dim=train_visual_features.shape) first define model using keras/kraino keras.models import sequential keras.layers.core import activation keras.layers.core import dense keras.layers.core import dropout keras.layers.core import layer keras.layers.core import merge keras.layers.core import timedistributedmerge keras.layers.embeddings import embedding keras.layers.recurrent import keras.layers.recurrent import lstm kraino.core.model_zoo import abstractsequentialmodel kraino.core.model_zoo import abstractsingleanswer kraino.core.model_zoo import abstractsequentialmultiplewordanswer kraino.core.model_zoo import config kraino.core.keras_extensions import dropmask kraino.core.keras_extensions import lambdawithmask kraino.core.keras_extensions import time_distributed_masked_ave model inherits abstractsingleanswer produces single answer words multiple answer words need inherit abstractsequentialmultiplewordanswer class visionlanguagelstm textual_embedding_dim=embedding_dim visual_embedding_dim=embedding_dim hidden_state_dim=embedding_dim multimodal_merge_mode=multimodal_merge_mode input_dim=len) output_dim=len) visual_dim=train_visual_features.shape) summary previously using makes sequence processing order-aware. time however combine modalities whole model ‘sees’ images. finally also important modalities combined. train_or_test=’test’ names_list=test_image_names parts_extractor=none max_parts=none perception=cnn_name layer=perception_layer second_layer=none kraino.core.model_zoo import word_generator first need word_generator _config maximum likelihood word generator text_image_bow_model._config.word_generator word_generator predictions_answers text_image_bow_model.decode_predictions kraino.core.model_zoo import word_generator first need word_generator _config maximum likelihood word generator text_image_rnn_model._config.word_generator word_generator predictions_answers text_image_rnn_model.decode_predictions. section train evaluate models. since reader already familiar pieces quickly jump coding. sake simplicity architectures. since hides test data purpose challenge publicly available validation evaluate architectures. vqa_dp data_provider.select answers associated question. take frequently occuring answers formal argument ’keep_top_qa_pairs’ allows filter rare answers associated questions. want keep question answer pairs change results differ vqa_train_text_representation vqa_dp vqa_train_raw_y vqa_train_text_representation vqa_val_raw_x vqa_val_text_representation vqa_val_raw_y vqa_val_text_representation start building frequencies table vqa_wordcount_x frequencies.split) keep answer words answer class therefore artificial split symbol split answer words difference replace print vqa_wordcount_y vqa_wordcount_y frequencies.split) vqa_wordcount_y kraino.utils.input_output_space import build_vocabulary kraino.utils.input_output_space import encode_questions_index kraino.utils.input_output_space import encode_answers_one_hot maxlen= vqa_wordindex_x vqa_indexword_x build_vocabulary kraino.core.model_zoo import word_generator re-using blindbow mode please make sure cell class definition larger increase dimensionality embedding vqa_model_config config parts_extractor=none max_parts=none perception=vqa_cnn_name layer=vqa_perception_layer second_layer=none train_or_test=’val’ names_list=vqa_val_text_representation parts_extractor=none max_parts=none perception=vqa_cnn_name layer=vqa_perception_layer second_layer=none textual_embedding_dim=vqa_embedding_dim visual_embedding_dim=vqa_embedding_dim multimodal_merge_mode=vqa_multimodal_merge_mode input_dim=len) output_dim=len) visual_dim=vqa_train_visual_features.shape word_generator=word_generator) task tests machines questions content images quite research direction recently gained popularity. therefore many opportunities available. tutorial enlisting possible directions. global representation tutorial global full-frame representation images. representation destroy much information. therefore seems ﬁne-grained alternatives valid options. maybe detections object proposals question dependent detections mokarian forooshani object proposals enrich visual representation). could also attention models become quite successful answering questions images however still hope global representations trained end-to-end task question dependent. global representation extracted cnns trained different dataset different task scene representation current approaches neural-based approaches trained images. however spatial relations ‘behind’ need representation scene design spatial rules using coordinate system). daquar built silberman provides modes however richer visual information currently fully exploited. recurrent neural networks disturbingly small models. seen tutorial questions clearly require order questions time become longer semantically difﬁcult require better visual understanding world. handle need rnns architectures better ways fusing modalities better global representation. logical reasoning questions require sophisticated logical reasoning negation. recurrent neural networks learn logical operators? compositionality language? perhaps mixed approaches similar work andreas language vision still small language vision language models. clearly need pictures answer questions images. missing here? global representation scene representation something missing fusing modalities? latter studied encouraging results fukui learning examples visual turing test many questions quite unique. models generalize questions? question completely parts already observed models guess meaning word context? ambiguities deal ambiguities? inherent task cannot ignored evaluation measures although wups consensus perfect. consensus higher annotation cost ambiguous tasks unclear formally deﬁne good consensus measure. wups ontology dependent quite costly build interesting domains? finally current evaluation metrics ignore tail answer distribution encouraging models focus frequent answers. references jacob andreas marcus rohrbach trevor darrell klein. neural module networks. cvpr stanislaw antol aishwarya agrawal jiasen margaret mitchell dhruv batra lawrence zitnick devi parikh. fr´ed´eric bastien pascal lamblin razvan pascanu james bergstra goodfellow arnaud bergeron nicolas bouchard yoshua bengio. theano features speed improvements. deep learning unsupervised feature learning nips workshop kyunghyun bart merrienboer caglar gulcehre fethi bougares holger schwenk dzmitry bahdanau yoshua bengio. learning phrase representations using encoder-decoder statistical machine translation. emnlp franois chollet. keras. https//github.com/fchollet/keras christiane fellbaum. wordnet. wiley online library akira fukui dong park daylen yang anna rohrbach trevor darrell marcus rohrbach. multimodal compact sepp hochreiter j¨urgen schmidhuber. long short-term memory. neural computation ilija ilievski shuicheng jiashi feng. focused dynamic attention model visual question answering. diederik kingma jimmy adam method stochastic optimization. arxiv. jiasen jianwei yang dhruv batra devi parikh. hierarchical question-image co-attention visual question answermateusz malinowski mario fritz. towards visual turing challenge. learning semantics mateusz malinowski mario fritz. hard cheat turing test based answering questions images. aaai george miller. wordnet lexical database english. cacm ashkan mokarian forooshani mateusz malinowski mario fritz. mean pooling rich image representation olga russakovsky deng jonathan krause sanjeev satheesh sean zhiheng huang andrej karpathy aditya khosla michael bernstein alexander berg fei-fei. imagenet large scale visual recognition challenge. arxiv.", "year": 2016}