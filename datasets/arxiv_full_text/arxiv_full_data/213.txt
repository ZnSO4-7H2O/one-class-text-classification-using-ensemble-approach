{"title": "Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet", "tag": ["stat.ML", "cs.CV", "cs.LG", "cs.NE"], "abstract": "Video sequences contain rich dynamic patterns, such as dynamic texture patterns that exhibit stationarity in the temporal domain, and action patterns that are non-stationary in either spatial or temporal domain. We show that a spatial-temporal generative ConvNet can be used to model and synthesize dynamic patterns. The model defines a probability distribution on the video sequence, and the log probability is defined by a spatial-temporal ConvNet that consists of multiple layers of spatial-temporal filters to capture spatial-temporal patterns of different scales. The model can be learned from the training video sequences by an \"analysis by synthesis\" learning algorithm that iterates the following two steps. Step 1 synthesizes video sequences from the currently learned model. Step 2 then updates the model parameters based on the difference between the synthesized video sequences and the observed training sequences. We show that the learning algorithm can synthesize realistic dynamic patterns.", "text": "video sequences contain rich dynamic patterns dynamic texture patterns exhibit stationarity temporal domain action patterns non-stationary either spatial temporal domain. show spatialtemporal generative convnet used model synthesize dynamic patterns. model deﬁnes probability distribution video sequence probability deﬁned spatial-temporal convnet consists multiple layers spatial-temporal ﬁlters capture spatialtemporal patterns different scales. model learned training video sequences analysis synthesis learning algorithm iterates following steps. step synthesizes video sequences currently learned model. step updates model parameters based difference synthesized video sequences observed training sequences. show learning algorithm synthesize realistic dynamic patterns. wide variety dynamic patterns video sequences including dynamic textures textured motions exhibit statistical stationarity stochastic repetitiveness temporal dimension action patterns non-stationary either spatial temporal domain. synthesizing analyzing dynamic patterns interesting problem. paper focus task synthesizing dynamic patterns using generative version convolutional neural network convnet proven immensely successful discriminative learning machine. convolution operation convnet particularly suited signals images videos sounds exhibit translation invariance either spatial domain temporal domain both. recently researchers become increasingly interested generative aspects convnet purpose visualizing knowledge learned convnet synthesizing realistic signals developing generative terms synthesis various approaches based convnet proposed synthesize realistic static images however much work literature synthesizing dynamic patterns based convnet focus present paper. speciﬁcally propose synthesize dynamic patterns generalizing generative convnet model recently proposed generative convnet derived discriminative convnet. random ﬁeld model energy-based model form exponential tilting reference distribution gaussian white noise distribution uniform distribution. exponential tilting parametrized convnet involves multiple layers linear ﬁlters rectiﬁed linear units seek capture features patterns different scales. generative convnet sampled langevin dynamics. model learned stochastic gradient algorithm analysis synthesis scheme seeks match synthesized signals generated langevin dynamics observed training signals. speciﬁcally learning algorithm iterates following steps initializing parameters synthesized signals. step updates synthesized signals langevin dynamics samples currently learned model. step updates parameters based difference between synthesized data observed data order shift density model synthesized data towards observed data. shown learning algorithm synthesize realistic spatial image patterns textures objects. article generalize spatial generative convnet adding temporal dimension resulting convnet consists multiple layers spatial-temporal ﬁlters seek capture spatial-temporal patterns various scales. show learning algorithm training spatial-temporal generative convnet synthesize realistic dynamic patterns. also show possible learn model incomplete video sequences either occluded pixels missing frames model learning indexes layers. layer ﬁlters nl−} ﬁlters layer used index ﬁlters layers respectively numbers ﬁlters layers respectively. ﬁlters locally supported range within local support weight parameters nl−) deﬁne linear ﬁlter operates nl−). linear ﬁltering operation followed relu max. bottom layer indexes three color channels. subk sampling implemented spatial-temporal ﬁlters multiple layers expected capture spatial-temporal patterns multiple scales. possible top-layer ﬁlters fully connected spatial domain well temporal domain dynamic pattern exhibit spatial temporal stationarity. spatial-temporal generative convnet energybased model random ﬁeld model deﬁned image sequence form exponential tilting reference distribution counts number pixels domain without loss generality shall assume scoring function tilts gaussian reference distribution non-gaussian model. fact purpose identify non-gaussian spatialtemporal features patterns. deﬁnition ﬁlter responses layer ﬁlters positions times. spatial temporal pooling reﬂects fact assume model stationary spatial temporal domains. dynamic work generalization generative convnet model adding temporal dimension. work dynamic patterns video sequences. spatial-temporal discriminative convnet used analyzing video data. connection discriminative convnet generative convnet studied dynamic textures textured motions studied instance proposed vector auto-regressive model coupled frame-wise dimension reduction single value decomposition. linear model gaussian innovations. proposed dynamic model based sparse linear representation frames. recent review dynamic textures. spatial-temporal generative convnet non-linear non-gaussian model expected ﬂexible capturing complex spatial-temporal patterns dynamic textures multiple layers non-linear spatial-temporal ﬁlters. recently generalized generative adversarial networks model dynamic patterns. model energy-based model also adversarial interpretation. section details. temporal data popular model recurrent neural network causal model requires starting frame. contrast model non-causal require starting frame. compared recurrent network model convenient direct capturing temporal patterns multiple time scales. notation image sequence video deﬁned square image domain time domain indexes coordinates pixels indexes frames video sequence. treat three dimensional function deﬁned spatial-temporal ﬁlter denote ﬁltered image sequence feature denote ﬁlter response feature pixel time indexes time steps step size dynamics driven reconstruction error bwδ. ﬁniteness step size corrected metropolis-hastings acceptance-rejection step. langevin dynamics extended hamiltonian monte carlo sophisticated versions learning training image sequences accomplished maximum expectation approximated monte carlo samples produced langevin dynamics. algorithm description learning sampling algorithm. algorithm keeps synthesizing image sequences current model updating model parameters order match synthesized image sequences observed image sequences. learning algorithm keeps shifting probability density energy regions model synthesized data towards observed data. learning algorithm langevin sampling step involves computation parameter updating step involves computation /∂w. convnet structure gradients computed efﬁciently back-propagation gradients share chain rule computations back-propagation. term mcmc sampling langevin dynamics samples evolving distribution keeps changing. thus learning sampling algorithm runs non-stationary chains. adversarial interpretation simple consequential property relu nonlinearity indicator function otherwise. result scoring function piecewise linear linear piece deﬁned multiple layers binary activation variables tells whether local spatial-temporal pattern represented k-th ﬁlter layer detected position time activation pattern divides image space large number pieces according value piece image space ﬁxed scoring function linear i.e. deﬁned fact computed backpropagation back-propagation process deﬁnes top-down deconvolution process ﬁlters multiple layers become basis functions layers activation variables different layers become coefﬁcients basis functions top-down deconvolution. energy-based model whose energy function combination norm comes reference distribution piecewise linear scoring function i.e. const −awδ bwδ/ constant piece image space ﬁxed since piecewise quadratic function piecewise gaussian. piece image space ﬁxed value truncated denote identity matrix. mean gaussian piece within also local mode local mode satisﬁes hierarchical autoencoder bottom-up encoding process top-down decoding process bwδ. general image sequence considered reconstruction reconstruction exact local mode figure synthesizing dynamic textures spatial temporal stationarity. category ﬁrst displays frames observed sequence second third rows display corresponding frames synthesized sequences generated learning algorithm. river. ocean. parameters top-down convnet. recently developed alternating back-propagation algorithm train generator network without involving extra network. recently developed cooperative training method recruits generator network reconstruct regenerate synthesized image sequences {˜im} speed mcmc sampling. show synthesis results displaying frames video sequences. posted synthesis results project page http//www.stat.ucla.edu/ ~jxie/stgconvnet/stgconvnet.html reader watch videos. ﬁrst learn model dynamic textures stationary spatial temporal domains. spatial-temporal ﬁlters convolutional spatial temporal domains. ﬁrst layer ﬁlters sub-sampling size pixels frames. updating increase shifting energy regions synthesized image sequences {˜im} observed image sequences {im} whereas updating {˜im decrease moving synthesized image sequences towards energy regions. adversarial interpretation learning sampling algorithm. also considered generalization herding method exponential family models general energy-based models. work i/σ. also assuming uniform reference distribution experiments show model uniform also synthesize realistic dynamic patterns. generative adversarial learning generator network. unlike model based bottom-up convnet generator network generates top-down convnet latent vector follows known prior distribution collects figure synthesizing dynamic textures temporal stationarity. category ﬁrst displays frames observed sequence second displays corresponding frames synthesized sequence generated learning algorithm. ﬂashing lights. fountain. burning heating pot. spring water. second layer ﬁlters sub-sampling size third layer ﬁlters sub-sampling size figure displays results. category ﬁrst displays frames observed sequence second third rows show corresponding frames synthesized sequences generated learning algorithm. layer-by-layer learning scheme. starting ﬁrst layer sequentially layers one. time learn model generate synthesized image sequence using algorithm learning layer ﬁlters reﬁne lower layers ﬁlters back-propagation. figure comparison synthesizing dynamic texture waterfall. bottom segments observed sequence synthesized sequence method synthesized sequence method category observed video prepared size range intensities mean subtraction used pre-processing. chain langevin sampling. number langevin iterations every consecutive updates parameters number learning iterations layer every iterations. layer-speciﬁc learning rates learning rate higher layer less lower layer order obtain stable convergence. many dynamic textures structured background objects stationary spatial domain. case network used experiment fail. however modify network experiment using ﬁlters fully connected spatial domain second layer. speciﬁcally ﬁrst layer ﬁlters sub-sampling size pixels frames. second layer spatially fully connected layer contains ﬁlters fully connected spatial domain convolutional temporal domain. temporal size ﬁlters frames sub-sampling size frames temporal dimension. spatial full connectivity second layer spatial domain feature maps third layer reduced third layer ﬁlters sub-sampling size temporal dimension. end-to-end learning scheme learn -layer spatial-temporal generative convnet dynamic textures. iteration layers ﬁlters updated different layer-speciﬁc learning rates. learning rate higher layer much less lower layer avoid issue large gradients. videos using langevin dynamics. figure displays results. category ﬁrst shows frames observed sequence second shows corresponding frames synthesized sequence generated learning algorithm. parameters categories without tuning. figure compares method linear dynamic system model. image sequence generated model appears blurred sequence generated method. learning model scaled learn pattern training videos mini-batch implementation. size mini-batch videos. video contains frames mini-batch parallel chains langevin sampling used. experiment slightly modify network using ﬁlters sub-sampling size pixels frames ﬁrst layer spatially fully connected ﬁlters temporal size frames sub-sampling size second layer keeping setting third layer unchanged. number learning iterations figure shows frame observed sequences corresponding frame synthesized sequences. examples synthesized sequences also displayed. experiment generating action patterns figure synthesizing action patterns. action video sequence continuous frames shown. running cows. frames training sequences displayed. corresponding frames synthesized sequences generated learning algorithm displayed. running tigers. frames observed training sequences displayed. corresponding frames synthesized sequences displayed. ment. also specialize learning roughly aligned video sequences action patterns non-stationary either spatial temporal domain using single toplayer ﬁlter covers whole video sequence. learn -layer spatial-temporal generative convnet video sequences aligned actions. ﬁrst layer ﬁlters sub-sampling size pixels frames. second layer fully connected layer single ﬁlter covers whole sequence. observed sequences size figure displays results modeling synthesizing actions roughly aligned video sequences. learn model category number training sequences running example running tiger example. videos collected internet frames. example figure displays segments observed sequences segments synthesized action sequences generated learning algorithm. paralleled chains experiment running cows paralleled chains experiment running tigers. experiments show model capture non-stationary action patterns. training image sequences occluded pixels binary masks indicating locations occluded pixels training image sequences number synthesized image sequences number langevin steps synthesizing image sequences number langevin steps recovering occluded pixels number learning iterations steps langevin dynamics recover occluded region i.e. starting step follows equation current occluded pixels updated step. steps langevin dynamics update i.e. starting current step follows equation quantitatively evaluate qualities recovered videos test method video sequences collected dyntex++ dataset types occlusions. model structure used experiment number langevin steps recovering equal number langevin steps synthesizing experiment report recovery errors measured average pixel difference original image sequence recovered image sequence occluded pixels. range pixel intensities compare results model learn video sequences occluded pixels. task inspired fact videos contain occluded objects. learning method adapted task minimal modiﬁcation. modiﬁcation involves iteration running steps langevin dynamics recover occluded regions observed sequences. iteration completed observed sequences synthesized sequences compute gradient log-likelihood update model parameters. method simultaneously accomplishes following tasks recover occluded pixels training video sequences synthesize video sequences learned model learn model updating model parameters using recovered sequences synthesized sequences. algorithm description learning sampling recovery algorithm. design types occlusions type salt pepper occlusion randomly place masks image domain cover pixels videos. type single region mask occlusion randomly place mask image figure learning occluded video sequences. experiment ﬁrst shows segment occluded sequence black masks. second shows corresponding segment recovered sequence. type salt pepper mask. type single region mask. type missing frames. results obtained generic markov random ﬁeld model deﬁned video sequence. model markov random ﬁeld whose potentials pairwise differences nearest neighbor pixels nearest neighbors deﬁned spatial temporal domains. image sequences recovered sampling intensities occluded pixels conditional observed pixels using gibbs sampler. table shows comparison results types occlusions. model recover incomplete data learning them. moving object video occluded frame turns recovery algorithm become algorithm background inpainting videos goal remove undesired moving object video. model experiment figure figure shows examples removals moving boat walking person respectively. videos collected example ﬁrst column displays frames original video. second column shows corresponding frames masks occludfigure background inpainting videos. experiment ﬁrst column displays frames original video. second column shows corresponding frames black masks occluding target removed. third column shows inpainting result algorithm. moving boat. walking person. target removed. third column presents inpainting result algorithm. video size example example experiment different video inpainting interpolation. synthesize image patches empty regions video running langevin dynamics. experiments single langevin chain synthesis. paper propose spatial-temporal generative convnet model synthesizing dynamic patterns dynamic textures action patterns. experiments show model synthesize realistic dynamic patterns. moreover possible learn model video sequences occluded pixels missing frames. mcmc sampling model sped learning sampling models multiple scales recruiting generator network reconstruct regenerate synthesized examples cooperative training younes. convergence markovian stochastic algorithms rapidly decreasing ergodicity rates. stochastics international journal probability stochastic processes", "year": 2016}