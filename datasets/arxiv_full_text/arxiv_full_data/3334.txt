{"title": "Ensemble Robustness and Generalization of Stochastic Deep Learning  Algorithms", "tag": ["cs.LG", "cs.CV", "stat.ML"], "abstract": "The question why deep learning algorithms generalize so well has attracted increasing research interest. However, most of the well-established approaches, such as hypothesis capacity, stability or sparseness, have not provided complete explanations (Zhang et al., 2016; Kawaguchi et al., 2017). In this work, we focus on the robustness approach (Xu & Mannor, 2012), i.e., if the error of a hypothesis will not change much due to perturbations of its training examples, then it will also generalize well. As most deep learning algorithms are stochastic (e.g., Stochastic Gradient Descent, Dropout, and Bayes-by-backprop), we revisit the robustness arguments of Xu & Mannor, and introduce a new approach, ensemble robustness, that concerns the robustness of a population of hypotheses. Through the lens of ensemble robustness, we reveal that a stochastic learning algorithm can generalize well as long as its sensitiveness to adversarial perturbations is bounded in average over training examples. Moreover, an algorithm may be sensitive to some adversarial examples (Goodfellow et al., 2015) but still generalize well. To support our claims, we provide extensive simulations for different deep learning algorithms and different network architectures exhibiting a strong correlation between ensemble robustness and the ability to generalize.", "text": "question deep learning algorithms generalize well attracted increasing research interest. however well-established approaches hypothesis capacity stability sparseness provided complete explanations work focus robustness approach i.e. error hypothesis change much perturbations training examples also generalize well. deep learning algorithms stochastic revisit robustness arguments mannor introduce approach ensemble robustness concerns robustness population hypotheses. lens ensemble robustness reveal stochastic learning algorithm generalize well long sensitiveness adversarial perturbations bounded average training examples. moreover algorithm sensitive adversarial examples still generalize well. support claims provide extensive simulations diﬀerent deep learning algorithms diﬀerent network architectures exhibiting strong correlation ensemble robustness ability generalize. deep neural networks successfully applied many artiﬁcial intelligence tasks providing state-of-the-art performance remarkably small generalization error. hand dnns often trainable model parameters number samples trained shown large enough capacity memorize training data thus statistical learning theory explains generalization hypothesis capacity struggle explain generalization ability large artiﬁcial neural networks. work focus diﬀerent approach study generalization dnns i.e. connection robustness deep learning algorithm ability generalize. mannor shown algorithm robust generalization performance also guaranteed. however context dnns practitioners observe contradicting evidence attributes. hand dnns generalize well other fragile adversarial perturbation inputs nevertheless adversarial training shown improve generalization deep neural network models indicating implicit connection robustness neural ability generalize. moreover observed dropout coupled adversarial training best hindering memorization without reducing model’s ability learn order solve contradiction revisit robustness argument present ensemble robustness characterize generalization performance deep learning algorithms. proposed approach intended give tight performance guarantees general deep learning algorithms rather pave addressing question deep learning perform well fragile adversarial examples? answering question diﬃcult present evidence ensemble robustness concerns fact randomized algorithm dropout bayes-by-backprop etc.) produces distribution hypotheses instead deterministic one. therefore ensemble robustness takes consideration robustness population hypotheses even though hypotheses sensitive perturbation inputs algorithm still generalize well long hypotheses sampled distribution robust average. kawaguchi took diﬀerent approach claimed deep neural networks generalize well despite nonrobustness. however deﬁnition ensemble robustness together empirical ﬁndings suggest deep learning methods typically robust although fragile adversarial examples. ensemble robustness prove following holds high probability randomized learning algorithms generalize well long output hypothesis bounded sensitiveness perturbation average speciﬁed deep learning algorithms reveal hypotheses diﬀerent runs deep learning method perform consistently well terms robustness performance deep learning method conﬁdently expected. moreover hypothesis sensitive adversarial examples long robust average. although ensemble robustness diﬃcult compute analytically demonstrate empirical estimate ensemble robustness investigate role ensemble robustness extensive simulations. results provide supporting evidence claim ensemble robustness consistently explains generalization performance deep neural networks. furthermore ensemble robustness measured solely training data potentially allowing testing examples training selecting best model based ensemble robustness. proposed consider model robustness estimating generalization performance deterministic algorithms lasso suggest using robust optimization construct learning algorithms i.e. minimizing empirical loss respect adversarial perturbed training examples. introducing stochasticity deep learning algorithms achieved great success practice also receives theoretical investigation. hardt analyzed stability property methods dropout introduced control over-ﬁtting randomly omitting subsets features iteration training procedure. diﬀerent explanations empirical success dropout proposed including avoiding over-ﬁtting regularization method explaining dropout bayesian approximation gaussian process diﬀerent works work extend results randomized algorithms order analyze ensemble robustness perspective. adversarial examples deep neural networks ﬁrst introduced recent works propose utilize regularization technique training deep models however works attempt worst case examples local neighborhood original training data focused measuring global robustness algorithm studying connection robustness generalization. work investigate generalization property stochastic learning algorithms deep neural networks establishing bounds. section provide preliminary facts necessary developing approach ensemble robustness. introducing problem setup interested particular highlight inherent randomness deep learning algorithms give unknown distribution target learning obtain neural network minimizes expected classiﬁcation error i.i.d. samples throughout paper consider training ﬁxed size training distribution hypotheses instead single hypothesis. example running deep learning algorithm dropout multiple times produce diﬀerent hypotheses deemed samples distribution important observation make deep learning analysis work point randomness actually plays important role deep learning algorithms perform well. therefore proceeding analyze performance deep learning provide formal deﬁnition randomized learning algorithms here. learning randomized algorithm target minimize expected empirical loss speciﬁc output hypothesis similar ones loss incurred speciﬁc output hypothesis instantiation randomized algorithm examples internal randomness deep learning algorithm include dropout rate random shuﬄe among training samples initialization weights diﬀerent layers name few. robustness generalization mannor established relation algorithmic robustness generalization ﬁrst time. algorithm robust following holds samples close other associated losses also close. self-contained brieﬂy review algorithmic robustness induced generalization guarantee. based robustness property algorithms prove robust algorithm also generalizes well. motivated results shaham proposed adversarial training algorithm minimize empirical loss synthesized adversarial examples. however results cannot applied characterizing performance modern deep learning models well. order explain good performance deep learning needs understand internal randomness deep learning algorithms population performance multiple possible hypotheses. intuitively single output hypothesis cannot robust adversarial perturbation training samples deterministic robustness argument cannot applied here. fortunately deep learning algorithms generally output hypothesis sampled distribution hypotheses. therefore even samples nice speciﬁc hypothesis aren’t likely fail hypothesis produced distribution. thus deep learning algorithms able generalize well. intuition motivates introduce concept ensemble robustness deﬁned distribution output hypotheses deep learning algorithm. ensemble robustness weaker requirement model compared robustness proposed better explaining deep learning. following section demonstrate simulations deep learning model robust indeed ensemble robust. practice deep model still achieve good generalization performance. algorithm strong ensemble robustness provide good generalization performance expectation w.r.t. generated hypothesis stated following theorem. note proofs theorems present section found supplementary material. addition supplementary material holds additional proof special case dropout. theorem randomized algorithm ensemble robustness training denote output hypothesis distribution probability least respect random draw following holds note theorem hide dependency generalization bound ensemble robustness measure space limitations technical lemmas details proofs throughout paper deferred supplementary material. theorem leads following corollary gives minimize expected loss directly. corollary randomized algorithm ensemble robustness. partition write fall training sample generated i.i.d. draws probability least following holds corollary suggests minimize expected error deep learning algorithm eﬀectively minimizing empirical error training samples perturbed adversarial way. fact adversarial training strategy exploited theorem suggests controlling variance deep learning model substantially improve generalization performance. note need consider trade-oﬀ expectation variance ensemble robustness. this consider following extreme examples. therefore allowing certain variance produced hypotheses randomized algorithm tolerate non-robustness hypotheses certain samples. long ensemble robustness small algorithm still perform well. section devoted simulations quantitatively qualitatively demonstrating ensemble robustness deep learning method explains performance. ﬁrst introduce experiment settings implementation details. data sets conduct simulations benchmarks. mnist dataset handwritten digit images training samples test samples notmnist mnist like database containing font glyphs letters training contains samples testing examples. images scaled pixel range note cross-validation data. network architecture parameter setting without explicit explanation multi-layer perceptrons throughout simulations. networks examined composed three fully connected layers followed rectiﬁed linear unit top. output last fully-connected layer -way softmax. order avoid bias brought speciﬁc network architecture compared algorithms evaluate compare ensemble robustness well generalization performance following deep learning algorithms. explicit ensembles i.e. using stochastic algorithm train diﬀerent members ensemble running algorithm multiple times diﬀerent seeds. practice implemented using stochastic algorithm trained minimize cross-entropy loss. implicit ensembles i.e. learning probability distribution weights neural network sampling ensemble members implemented bayes-by-backprop algorithm recent approach training bayesian neural networks. uses backpropagation learn probability distribution weights neural network minimising expected lower bound marginal likelihood methods correspond adding adversarial training ensemble methods magnitude perturbation measured present simulations empirically validate theorem i.e. ensemble robustness highly correlated generalization performance. ensemble robustness involves taking expectation possible output hypothesis computationally intractable exactly measure ensemble robustness diﬀerent deep learning algorithms. simulation take empirical average robustness adversarial perturbation diﬀerent hypotheses learning algorithm ensemble robustness. case variants conﬁguration collect ensemble output hypotheses repeating training procedures using conﬁguration using diﬀerent random seeds. case bayes-by-backprop methods algorithm explicitly outputs distribution output hypothesis simply sample networks learned weight distribution. particular empirically demonstrate deep learning algorithm stronger ensemble robustness presents better generalization performance recall deﬁnition ensemble robustness deﬁnition another obstacle calculating ensemble robustness adversarial perturbation speciﬁc pre-deﬁned magnitude constraint perturbation ∆si. simulations vary magnitude order calculate empirical ensemble robustness diﬀerent perturbation levels. generalization performance diﬀerent learning algorithms diﬀerent networks compared empirical ensemble robustness mnist given figure notice x-axis corresponds empirical ensemble robustness y-axis corresponds test error. examining figure observe high correlation ensemble robustness generalization learning algorithms i.e. algorithms robust generalize better data set. addition adversarial training methods consistently present stronger ensemble robustness pure bayes-by-backprop. figure presents similar results notmnist dataset although observe lower correlation bayes-by-backprop algorithm case. observations support claim relation ensemble robustness algorithm generalization performance theorem also compare ensemble robustness robustness mnist table robustness measured similarly ensemble robustness using equation indeed observe averaging instances algorithm exhibits higher correlation generalization robustness i.e. ensemble robustness better estimation generalization performance standard robustness. paper investigated generalization ability stochastic deep learning algorithm based ensemble robustness; i.e. property testing sample similar training sample loss close training error. established theoretically experimentally evidence ensemble robustness algorithm measured training indicates generalization performance well. moreover theory experiments suggest dnns robust fragile speciﬁc adversarial examples. measuring ensemble robustness stochastic deep learning algorithms computationally prohibitive needs sample several output hypotheses algorithm. thus demonstrated learning probability distribution weights neural network explicitly e.g. variational methods bayes-by-backprop still observe positive correlation robustness generalization using fewer computations making ensemble robustness feasible measure. direct consequence potentially measure generalization error algorithm without using testing examples. future work plan investigate ensemble robustness used model selection instead cross-validation particular problems small training set. diﬀerent direction study resilience deep learning methods adversarial attacks strauss recently showed ensemble methods useful mean defense adversarial attacks. however considered implicit ensemble methods computationally prohibitive. simulations show explicit ensembles robust well believe likely useful defense strategy reducing computational cost. finally theorem suggests randomized algorithm tolerate non-robustness hypotheses certain samples; help explain proposition kawaguchi dataset exist arbitrarily unstable non-robust algorithms small generalization gap. leave intuition future work.", "year": 2016}