{"title": "Deep Learning and Data Assimilation for Real-Time Production Prediction  in Natural Gas Wells", "tag": ["cs.LG", "cs.AI", "physics.flu-dyn", "physics.geo-ph", "stat.ML"], "abstract": "The prediction of the gas production from mature gas wells, due to their complex end-of-life behavior, is challenging and crucial for operational decision making. In this paper, we apply a modified deep LSTM model for prediction of the gas flow rates in mature gas wells, including the uncertainties in input parameters. Additionally, due to changes in the system in time and in order to increase the accuracy and robustness of the prediction, the Ensemble Kalman Filter (EnKF) is used to update the flow rate predictions based on new observations. The developed approach was tested on the data from two mature gas production wells in which their production is highly dynamic and suffering from salt deposition. The results show that the flow predictions using the EnKF updated model leads to better Jeffreys' J-divergences than the predictions without the EnKF model updating scheme.", "text": "abstract—the prediction production mature wells complex end-of-life behavior challenging crucial operational decision making. paper apply modiﬁed deep lstm model prediction rates mature wells including uncertainties input parameters. additionally changes system time order increase accuracy robustness prediction ensemble kalman filter used update rate predictions based observations. developed approach tested data mature production wells production highly dynamic suffering salt deposition. results show predictions using enkf updated model leads better jeffreys’ j-divergences predictions without enkf model updating scheme. mature north wells currently endof-life make production predictions challenging. increasing energy demands predictions increasingly crucial operational decision making. traditionally expensive physics based models used prediction models however operators access large database sensor data wells. becomes natural extension explore possibility using deep learning model methods applied ﬁeld. also would like system used deploy forget manner hence framework robust enough different ﬁeld conditions. industry familiar kalman ﬁlters data assimilation method also used model parameter estimation. also work done used decoupled-extended kalman filter online training neural network model. recently computer vision work also done combine approaches together. found lstm kalman filter model temporal regularization outperform standalone kalman ﬁlter standalone lstm approaches extended kalman ﬁlter many variants including dekf drawback cannot handle highly nonlinear dynamical functions therefore paper would like ensemble kalman filter update prediction model parameter online. manner call bayesian lstm. difference apply approach real valued time series data used results anomaly detection system. reference also observed enkf trained rnns outperform gradient descent learning. also widely used online parameter estimation unscented kalman filter real valued time series data shown enkf performs much better exist rich knowledge base data assimilation methods within weather prediction reservoir engineering communities. general data assimilation methods split approaches deterministic approach involves solving minimization problem data probabilistic approach kalman filter belongs second group enkf many variants proven successful atmospheric oceanic sciences quick search many available work enkf citing already order gives indication much wealth knowledge communities have. restrict overview deep learning models regression based models. such commonly used models sequences time series data recurrent neural networks overview recent advances rnns claimed well-trained model dynamical system. hence idea using models prediction model enkf approach. deep lstms variants described successfully modelled speech acoustic modelling. reference investigated rnns short term load predictions real-valued time series data characteristics well production data. water. since well production declines time salt precipitation ultimately clog well completely important predict decline rate plan shutwash operations optimally. production performance slowly decreases time depletion reservoir irrecoverable salt precipitation near well bore. thus forward model needs initially trained dataset capture production decline trend afterwards updated take account changes system time. production trends wells shown fig. data wells available april data consists pressure temperature rate top-side choke valve opening minute intervals. variables dataset shift scale data using minimum range data well respectively. assumed gaussian distributions. normalized input variables given table along scaled standard deviations. obtain scaled standard deviations taking claimed sensor accuracy manufacturer multiply scaling factor. preserves variance measurements sample normalized inputs distributions. testing sets four different datasets used evaluate performance developed approach relative baseline approach. periods data wells. ﬁrst period july second period march predictions approaches would compared sets. reason ﬁrst period chosen represents typical cycle well shutin production decline proﬁle wells. second period chosen period shutins shorter durations well dynamics involved provide challenging robustness test approaches. summary methodology modiﬁed deep lstm model prediction model enkf framework parameter estimation. compare close prediction distributions enkf updated model measurements using jeffreys’ j-divergence. baseline approach predictions also compared measurements using performance metric. determine approach combining enkf update bias parameter modiﬁed deep lstm model improve increase robustness timestep ahead predictions. modiﬁed deep lstm network described prediction model. allows capture nonlinear dynamics different time scales dataset regularization input gaussian noise layer standard deviation training prevent overﬁtting. also parametric relu layer regular densely-connected neural network layers network. reasoning behind using prelu dense layers sigmoid activation function ensure rate predictions always non-negative. fig. shows summary model. limitations space discussing equations lstm layer found numerous literature already. entire implementation model based keras framework using theano backend training performed using nvidia gpu. normalized dataset well train deep lstm model section ii-a. fig. show model losses training process function epoch. model weights last epoch paper. variables deﬁned table used model training sliding window timesteps. short prediction model represented vectorized form n-th timestep rate choke valve settings four variables fig. deﬁne model error covariance timestep sample covariances kalman gain measurements vector measurements covariance mapping state space measurements space variable represents prior distribution state used prediction performance comparisons baseline approach orange variable represent posterior distribution measurements timestep assimilated. initialize ﬁlter using variable distributions table wbias also used ensemble sizes justify fact enkf already works well sample sizes order dimension compare performance predictions enkf model updating approach predictions baseline approach using jeffreys’ j-divergence gaussian distributions kullback-leibler divergence. represents modiﬁed deep lstm model weights. note choke valve settings timestep instead choke settings serve control parameter dynamical system. note variables considered random variables. assume weights model choke valve settings variances. baseline approach evaluate gaussianity model predictions perform monte carlo simulations samples using normalized variables distributions. deﬁne system state additionally wbias bias parameter last layer prediction model section iii-a. augmented system state used enkf framework bias parameter estimation described hence system state space effective size system dynamical model given mentioned methodology section test enkf model update scheme wells different production periods. section ﬁrst determine predicted samples prediction model typically follow gaussian distribution. done performing normality test timestep given dataset testing periods. test performed gives feel enkf would perform provided dataset. proceed apply enkf algorithm well modiﬁed deep lstm model trained determine performance enkf known well production periods apply scheme second well test production periods. note uncertainty bounds shown ﬁgures within section bounds correspond usual conﬁdence interval. terms computational speed predictions using enkf model updated approach take maximum wall clock-seconds timestep ensemble size since measurements recorded minute intervals allows real-time predictions automated applications discussing paper further. enkf algorithm optimal sense bayesian updating system variables involved measurement update step gaussian distributed therefore need check outputs forward model gaussian. shapiro-wilk test threshold reject null hypothesis samples particular timestep gaussian distribution. test shown test higher statistical power three formal normality tests table shows number rejected null hypothesis timesteps different wells dataset periods. notice ﬁrst three cases predominantly gaussian since timesteps failed normality test. expect enkf algorithm perform optimally ﬁrst three cases table perform suboptimally last case well period march fig. shows typical histogram shape predicted samples timestep well periods. contrast fig. shows typical histogram predicted samples well last case table clearly samples gaussian distributed. ﬁgures conﬁrm results table fig. show predicted rate proﬁles baseline approach enkf model updating approach well july period. seen larger uncertainty bands around mean enkf proﬁle higher median j-divergence median j-divergence enkf updated proﬁle. still interesting note baseline algorithm show physical relationships means still bumps predicted ﬂowrates valve opened brief shutin period. difference bias errors mean baseline case measurements. surprising enkf updated model predictions would perform better mean sense well terms matching measured distributions indicated signiﬁcantly lower median j-divergence. clearly j-divergence proﬁles methods fig. ignoring ﬁlter spin-up phase july period march also interesting period baseline approach already performs quite well seen mean j-divergence proﬁles shown fig. respectively. notice enkf approach perform slightly worse baseline approach median j-divergence baseline approach enkf updated approach attributed spin-up phase ﬁlter fig. j-divergences enkf updated approach higher baseline approach spin-up phase however notice j-divergences enkf updated predictions lower baseline predictions. hence conclude well deployment modiﬁed deep lstm model enkf bias updating provide accurate robust predictions real-time manner. testing well different periods predictive model trained dataset well hence hidden relationships input variables would learned model training process. however apply well hidden relationships might hold anymore various physical factors affecting well behaviour. want test approach robust enough automatically adapt changing conditions deployed totally unknown well prediction model. dynamical behaviour follow general trends bias parameter different different well characteristics. predicted production proﬁles approaches measured production. baseline approach still quite well prediction mean bias predictions measurements. indicates indeed model bias errors corrected enkf updated model approach. ﬁgure observe bias error predictions enkf updated model measurement minimized. fig. provides visual proof indeed developed approach improve prediction performance. median j-divergence period challenging period approaches. clearly fig. baseline approach correctly predict measured ﬂow. seems high bias error prediction model least since cannot inspect well speculate structure well managed cause conditions similar shut-in periods well produces rate predictions. despite differences enkf updated model performs satisfactorily. initially ﬁlter struggle high uncertainties predictions especially spin-up period converges able track measured proﬁle correctly. mean sense even initial spin-up phase produces vastly superior prediction baseline approach. conﬁrm j-divergence proﬁles fig. median j-divergence satisfactory prediction proﬁle given fact well conditions known model could update bias model parameter. proves utility enkf model updating approach novice machine learning completeness sake also tested approach longer period conﬁdent enkf updated model approach improve prediction robustness. dataset well period predicted production proﬁles shown fig. j-divergence proﬁles shown fig. based ﬁgures median j-divergence indeed observed enkf model updated approach improve well production predictions adapt different system conditions. also notice ﬁlter spin-up period affect long term performance predictions hence continuously running system spin-up behaviour major issue long aware existence methods mitigate behaviour given objective paper tested enkf model updating approach real data results approach help make model predictions robust. shows current application enkf approach coupled deep lstms invaluable mirikitani nikolaev dynamic modeling ensemble kalman ﬁlter trained recurrent neural networks seventh international conference machine learning applications sch¨oniger nowak h.-j. hendricks franssen parameter estimation ensemble kalman ﬁlters transformed data approach application hydraulic tomography water resources research vol. n/a–n/a available http//dx.doi.org/./wr bianchi maiorino kampffmeyer rizzi jenssen overview comparative analysis recurrent neural networks short term load forecasting corr vol. abs/. available http//arxiv.org/abs/. prior probability estimation london mathematical physical engineering sciences vol. available http//rspa.royalsocietypublishing.org/content/// shapiro wilk analysis variance test normality biometrika vol. available http//dx.doi.org/./biomet/.-. deployed real-time production optimization environment. given results obtained actual development real well monitoring system would next step. authors would like thank netherlands enterprise agency also wish acknowledge industry partners model update consortium alphabetical order datasets funding work. p´erez-ortiz gers schmidhuber kalman ﬁlters improve lstm network performance problems unsolvable traditional recurrent nets neural netw. vol. mar. available http//dx.doi.org/./s- coskun achilles dipietro navab tombari long short-term memory kalman ﬁlters recurrent neural estimators pose regularization corr vol. abs/. available http//arxiv.org/abs/.", "year": 2018}