{"title": "Computationally Efficient Target Classification in Multispectral Image  Data with Deep Neural Networks", "tag": ["cs.CV", "cs.AI", "cs.NE", "eess.IV", "eess.SP"], "abstract": "Detecting and classifying targets in video streams from surveillance cameras is a cumbersome, error-prone and expensive task. Often, the incurred costs are prohibitive for real-time monitoring. This leads to data being stored locally or transmitted to a central storage site for post-incident examination. The required communication links and archiving of the video data are still expensive and this setup excludes preemptive actions to respond to imminent threats. An effective way to overcome these limitations is to build a smart camera that transmits alerts when relevant video sequences are detected. Deep neural networks (DNNs) have come to outperform humans in visual classifications tasks. The concept of DNNs and Convolutional Networks (ConvNets) can easily be extended to make use of higher-dimensional input data such as multispectral data. We explore this opportunity in terms of achievable accuracy and required computational effort. To analyze the precision of DNNs for scene labeling in an urban surveillance scenario we have created a dataset with 8 classes obtained in a field experiment. We combine an RGB camera with a 25-channel VIS-NIR snapshot sensor to assess the potential of multispectral image data for target classification. We evaluate several new DNNs, showing that the spectral information fused together with the RGB frames can be used to improve the accuracy of the system or to achieve similar accuracy with a 3x smaller computation effort. We achieve a very high per-pixel accuracy of 99.1%. Even for scarcely occurring, but particularly interesting classes, such as cars, 75% of the pixels are labeled correctly with errors occurring only around the border of the objects. This high accuracy was obtained with a training set of only 30 labeled images, paving the way for fast adaptation to various application scenarios.", "text": "detecting classifying targets video streams surveillance cameras cumbersome error-prone expensive task. often incurred costs prohibitive real-time monitoring. leads data stored locally transmitted central storage site post-incident examination. required communication links archiving video data still expensive setup excludes preemptive actions respond imminent threats. effective overcome limitations build smart camera analyzes data on-site close sensor transmits alerts relevant video sequences detected. deep neural networks come outperform humans visual classifications tasks also performing exceptionally well computer vision tasks. concept dnns convolutional networks easily extended make higher-dimensional input data multispectral data. explore opportunity terms achievable accuracy required computational effort. analyze precision dnns scene labeling urban surveillance scenario created dataset classes obtained field experiment. combine camera -channel vis-nir snapshot sensor assess potential multispectral image data target classification. evaluate several dnns showing spectral information fused together frames used improve accuracy system achieve similar accuracy smaller computation effort. achieve high per-pixel accuracy even scarcely occurring particularly interesting classes cars pixels labeled correctly errors occurring around border objects. high accuracy obtained training labeled images paving fast adaptation various application scenarios. video analysis widely used enhanced surveillance inspection applications many commercial industrial products. video analysis based algorithms process images acquired camera extract features meaning automatically detect significant events. last years many algorithms proposed achieve best performance video analysis using several approaches today novel algorithms based deep neural networks overcoming performance previous algorithms coming close exceeding accuracy humans. moreover dnns achieving multispectral images widely used remote sensing geophysical monitoring astronomy industrial process monitoring target detection– ability capture information material properties facilitating analysis image data seeing normal cameras human eye. however cameras channels still relatively rare large share likely used defense applications stationary setup mounted vehicles size weight procurement cost. last years type fully-integrated multispectral cmos sensor become available shrinking device size weight normal cameras time making much affordable. application dnn-based embedded visual analytics multispectral images scarcely explored area significant potential improved robustness accuracy. dnns also known computationally expensive. popular provide computation power needed process images video large number expensive servers datacenter connected camera ethernet fast communication interfaces. example approach used google facebook process images video users distributed world. however constantly increasing number cameras sending data servers supercomputers posing problem huge amount data transferred computational power needed. moreover approach significantly increases time required meaning processing data limiting possibility real-time processing. contrast approach emerging solution process data close sensors embedded processors. brings several benefits reducing amount data needed transferred improving response time detect dangerous situations requiring fast external connectivity huge storage capacity work properly. properties cameras embed computational resources board well-known smart cameras becoming popular used emerging surveillance applications. although today embedded processors high computational power pushed advances mobile phones portable computers still orders magnitude less powerful supercomputers workstations. reason video processing embedded processors remains challenging task especially implement highly accurate dnns. algorithms embedded platform combination optimized dnns highly efficient implementation needed–. paper analyze potential multispectral sensors embeddable dnns automated analysis video surveillance data smart multispectral camera system. create dataset using camera combined multispectral imaging device providing equally-spaced spectral bands range urban surveillance perspective. obtained data evaluate accuracy achievable several different dnns analyzing data automatically labeling pixel classes. rest paper organized follows section list related work explaining dataset collected section present three different type dnns section evaluate test section section concludes paper. ground-breaking performance deep learning convolutional neural networks particular undisputable nowadays. convnets shown outperform traditional computer vision approaches large margin many applications areas even proven beyond-human performance visual tasks image classification. paper focusing scene labeling sometimes referred semantic segmentation convnets showing similarly outstanding results–. hypermultispectral data images obtained specific spectral filters successfully used industrial computer vision remote sensing time. however multispectral sensors expensive bulky often required non-trivial synchronization system. recent appearance singlechip multispectral snapshot sensor become much comparable industrial image sensors. alongside this analysis tools become available freely like scyven. existing work using convnets analyze multispectral image data limited different application areas often spectral channels. work authors combine images single thermal lwir channel detect pedestrians car’s perspective collecting dataset using traditional features. authors works report using convnets classify aerial scenes ucmerced land-use dataset dataset brazilian coffee scenes dataset last includes multispectral images channels green nir. scene labeling always computationally expensive task requiring powerful gpus able process low-resolution images second using convnets often several minutes frame traditional computer vision methods– obtain decent quality results. already assumes optimized software implementations currently specialized hardware implementations using fpgas even asics provide reasonable throughput accuracy within power limits embedded platform. limited related work using many-channel multispectral information perform scene labeling none urban surveillance scenarios. furthermore types sensors used related work strongly focused using beam splitters dedicated imaging sensors channel instead multispectral mosaic sensor. able perform evaluations towards answering question whether multispectral data improve scene labeling results simplify processing pipeline obtain good results need create dataset. combine lower resolution multispectral -channel mosaic visnir sensor high resolution camera could integrated embedded processor tegra build smart camera able process data on-site. section explain collected dataset. identify specific cameras used explain data sensors merged ground truth labeling created. collected dataset using sensors high-resolution sensor capture shapes accurately lower resolution multispectral sensor obtain additional information materials. images used high-resolution camera point grey flea fl-u-sc-cs built around sony cmos sensor providing pixel images frame/s equipped camera fujinon yv.x.sa- lens variable focal length multispectral images acquired using ximea xispec mqhg-im-smx-nir camera features cmos snapshot mosaic sensor imec. sensor based monochrome cmosis device pixels additional interference filter-based mosaic obtain different spectral channels. provides equally-spaced spectral bands center frequencies range stream multispectral cubes frame/s used tamron lens focal length device combined schneider long-pass filter suppress light half wavelength individual resonance filters creating mosaic sensor. selection lenses strongly influenced desire capture surveillance camera view scenery. camera measures weight lens long diameter weights multispectral camera weighs fits ././ housing. lens adds another long diameter. devices respectively. first step mosaic multispectral image converted data layout multispectral cube pixels channels. overlaying images distortion differences become visible. correct this infer geometric transformation using local weighted mean transform closest points used deduce degree polynomial transformation control point pair based total correspondence pairs scattered across image. transform warp multispectral image cube image using bicubic interpolation aligning pixels image sources stacked channel image. finally resulting image cube cropped pixel areas data sources available remain illustrated figure mentioned procedure perform debayering/demosaicking large variety algorithms exist make visual perception images pleasing possible. many cannot easily adapted non-rgb data straight-forward would bilinear interpolation well. decided interpolation step also represented first convolution layer convnet explicitly would primarily overall computational effort without much benefit. first convolution layer also compensate varying sensitivity individual spectral bands. collected images street surveillance perspective. based image labeled pixel classes car/truck building road/gravel tree/shrubbery tram water distant background. evaluation randomly partitioned dataset training images test images. sample images shown figure order facilitate creation ground truth developed program assist labeling dataset shown figure instead assigning class pixel individually segment image superpixels using slic algorithm label these. slic clusters pixels based combination photo distance distance image plane create oversegmentation image. label assigned pixel within superpixel. proven useful start large superpixels improve finer-grained segmentation. manual labeling process sped making static background taking labeling image starting point next one. manual labelling dataset straight-forward. assigned labels accurately possible include hard-to-classify unclassified ambiguous class. means pedestrians cover pixels classified like surroundings pixels. also distinction distant background buildings trees based clearly able distinguish given resolution might vary based personal perception. furthermore dataset contains trees front buildings road leaving gaps background visible. labeled entire area covered foreground object class labeling gaps background visible cover several pixels. class distribution uneven might interesting classes car/truck tram make small share total number labeled pixels dataset section present three types neural networks starting per-pixel classification normal multi-layer neural network explore possible relatively simple classifier. move present proposed convnets exploring improvement obtained based shape texture objects image. approach adapting known scene labeling convnet targeted different rgb-only dataset explore convnets based concepts current state-of-the-art image recognition adapt application. spectral information long successfully used material classification. type analysis done perpixel basis independent neighboring values. perform material-based classification using -layer neural network evaluated pixel individually analyze whether additional multispectral channels improve segmentation results setting. provide data point corner fast energy-efficient analysis lower accuracy complex convnets. classify pixel individually channels rgb-only multispectral image respectively. train -layer neural network output channels layer. non-linearity layers relu activation function preceded batch normalization speedy training. explained next sections neural networks include pooling layers subsampling factor directions. order able compare networks better subsample input image applying pixel-wise classification. looking individual pixels image optimal desire obtain high-quality semantic segmentation scene. based input only would also tremendously difficult humans solve task. ingredient high-quality segmentation recognition shape objects texture contextual relation. per-pixel analysis little information texture pixel’s color little contextual information given dataset acquisition setup class distribution. using convnet improve always taking spatially local neighborhood consideration building hierarchy increasingly abstract representations capture information wheels dark tires occurs road. done typical stacking sequences convolutional activation pooling layer. performance baseline used structure network presented optimized stanford backgrounds dataset. dataset contains images street view scenes classes resolution used convnet shown figure using max-pooling relu activations. convnet comes flavors single-scale multi-scale. applying feature extractor convnet scaled versions image build limited invariance features size objects wide-spread concept computer vision. order able train convnet end-to-end feature extraction part applied images scaled factor resulting feature bilinearly interpolated feature maps size stack per-pixel classification applied. three feature differently original implementation apply convolutional layers zero-padding input order loose pixels borders image applying convolutions also single-scale configuration. obtain borderless result since multi-scale configuration would otherwise imply wide borders full output labeling desirable case. order reduce evaluation time memory requirements training convnet scaled-down input image pixel. network output resolution smaller factor direction max-pooling layers. order process data also multispectral information simply increase number input layers first convolutional layer contrary original network proven effective include preprocessing steps contrast normalization. network presented previous section optimized different dataset newer types networks showing better accuracy image recognition tasks become available. deep residual networks current state-of-the-art method sequence small filters every layers bypass path able train deeper layers network well. take concept build convnets optimize application. constructed several convnets varying depth different numbers feature maps analyze effect multi-scale features multispectral data. kept interesting results pareto-optimal front terms error rate computational effort. torch framework training convnets. optimization trained parameters done using adam algorithm batch normalization layers front activation functions dropout. apply equalweight multi-class margin loss function target class index output convnet. optimizes parameters network maximize distance training samples figure resnet module shown serves basis resnet-inspired convnets. maxpooling operations applied mentioned convolution module lower path inserted number feature maps differs input output. networks evaluated shown center bottom image. pixel-wise classification shown figure output space convnet similar linear objective. networks used output lower resolution pooling layers. train network accordingly down-sampled ground truth labeling. evaluated aforementioned neural networks determine per-pixel error rate well computational effort important criteria smart camera. performing per-pixel classification using multispectral data obtained error rate test set. comparison convnet described section yielded error rate resnet-like convnets achieved error rates deeper shallower respectively. several additional neural networks based concepts shown section evaluated report pareto-optimal front terms error rate computation effort. major goals experiments find whether multispectral camera would relevant information improve classification accuracy. thus trained best performing network data well suffering noticeable degradation increase error rate. clearly shows additionally gathered information aids improving quality results. also generally shows indeed possible train convnet task using relatively small dataset. variations analyzed neural networks terms error might seem small slightly less accurate network acceptable however dataset unbalanced obtained application scenario strongly leveraged impact error rate uncommon classes. confusion matrices figure visualize this. difference per-pixel error rate results drop classification car/truck pixels. however error rate e.g. case tram mean objects missed rather classification around borders somewhat fuzzy. important note every truck tram test always partially recognized. embedded platform hard power constraints computation effort limit choice neural networks deployable. thus become acceptable accuracy losses networks network error rate rgb-only network smaller computational burden makes interesting multispectral sensor save power system level. nvidia tegra platform two-core processor small specifically targeting embedded computer vision applications able perform gop/s consuming watts means either process frame/s network frame/s network achieving accuracy network evaluated without multispectral data. work evaluated benefits combining camera multispectral camera embedded smart camera. collected dataset scene labeling urban surveillance perspective including multispectral camera. presented novel convnets scene labeling using additional data. showed even limited amount labeled data highly accurate convolutional networks trained making interesting option even rapid deployment surroundings. report multispectral data used improve accuracy alternatively reduce computational effort effectively increasing overall energy efficiency pushing real-time processing closer range possible embedded processing platforms. gross boehler schilling middelmann weyermann wellig oechslin kneubuehler assessment target detection limits hyperspectral data proc. spie secur. def. bioucas-dias plaza camps-valls scheunders nasrabadi chanussot hyperspectral remote sensing data analysis future challenges ieee geosci. remote sens. mag. güneralp filippi randall estimation floodplain aboveground biomass using multispectral remote sensing nonparametric modeling int. appl. earth obs. geoinf. dissing papadopoulou tassou ersboll carstensen panagou nychas using multispectral imaging spoilage detection pork meat food bioprocess technol. meer werff ruitenbeek hecker bakker noomen meijde carranza smeth multihyperspectral geologic remote sensing review int. appl. earth obs. geoinf. elsevier b.v. chen wang chen temam diannao small-footprint highthroughput accelerator ubiquitous machine-learning proc. int. conf. archit. support program. lang. oper. syst. farabet martini corda akselrod culurciello lecun neuflow runtime reconfigurable dataflow processor vision proc. ieee conf. comput. vis. pattern recognit. work. nogueira miranda santos dos. improving spatial feature representation aerial scenes using convolutional networks brazilian symp. comput. graph. image process. -octob", "year": 2016}