{"title": "Exploiting Points and Lines in Regression Forests for RGB-D Camera  Relocalization", "tag": ["cs.CV", "cs.AI"], "abstract": "Camera relocalization plays a vital role in many robotics and computer vision tasks, such as global localization, recovery from tracking failure and loop closure detection. Recent random forests based methods exploit randomly sampled pixel comparison features to predict 3D world locations for 2D image locations to guide the camera pose optimization. However, these image features are only sampled randomly in the images, without considering the spatial structures or geometric information, leading to large errors or failure cases with the existence of poorly textured areas or in motion blur. Line segment features are more robust in these environments. In this work, we propose to jointly exploit points and lines within the framework of uncertainty driven regression forests. The proposed approach is thoroughly evaluated on three publicly available datasets against several strong state-of-the-art baselines in terms of several different error metrics. Experimental results prove the efficacy of our method, showing superior or on-par state-of-the-art performance.", "text": "fig. line segment example. original image line features. scenes little texture repetitive patterns typical indoor environments line features robust. important geometric information robust image features shown fig. therefore propose line point features regression forests improve camera relocalization performance. main contributions work thoroughly evaluate methods three publicly available datasets several strong state-of-theart baselines proving efﬁcacy method superior on-par accuracy. camera relocalization widely studied large scale global localization recovery tracking failure loop closure detection visual slam global localization mobile robotics sports camera calibration various methods proposed advance camera relocalization performance. provide review random forests based methods refer review methods. moreover related work line segments introduced. random forests based method camera relocalization approaches based random forests camera relocalization random forests used regressors also refer regression forests. approaches ﬁrst employ regression forest learn image pixel’s corresponding points scene’s world coordinates abstract— camera relocalization plays vital role many robotics computer vision tasks global localization recovery tracking failure loop closure detection. recent random forests based methods exploit randomly sampled pixel comparison features predict world locations image locations guide camera pose optimization. however image features sampled randomly images without considering spatial structures geometric information leading large errors failure cases existence poorly textured areas motion blur. line segment features robust environments. work propose jointly exploit points lines within framework uncertainty driven regression forests. proposed approach thoroughly evaluated three publicly available datasets several strong state-of-the-art baselines terms several different error metrics. experimental results prove efﬁcacy method showing superior on-par state-of-the-art performance. camera relocalization plays vital role many computer vision robotics augmented reality virtual reality tasks. real world camera relocalization powered recent consumer robotics products dyson irobot roomba know visited ar/vr products hololens oculus rift camera relocalization helps correctly overlay visual objects image sequence real world. scene coordinate regression forests ﬁrst machine learning based method camera relocalization. method regression forest trained infer estimate pixel’s correspondence points scenes world coordinate frame. correspondences used infer camera pose robust optimization scheme. since then various machine learning based methods mainly random forests based deep learning based methods proposed accelerate progress camera relocalization parallel traditional still active feature-based methods key-frame based methods random forests based methods either rgbd/rgb pixel comparison features sparse features sift employed without considering spatial structures. poorly textured areas existence motion blur line segments provide lili meng frederick tung james little clarence silva institute computing information cognitive systems university british columbia vancouver canada. training rgb-d images corresponding ground truth poses. camera pose optimization conducted adapted version preemptive ransac random forests based methods need compute descriptors search nearest-neighbors time-consuming steps local feature based key-frame based methods. environment generally repeated objects similar chairs ofﬁce room random forests multi-outputs input resulting ambiguities. solve problem proposed hybrid discriminativegenerative learning architecture choose optimal camera poses scrf. improve camera relocation accuracy exploits uncertainty regression forests using gaussian mixture model leaf nodes. extend random forests based method single image test stage employing perspective-n-point method rather kabsch algorithm camera pose optimization stage. however rgb-d images still needed training stage. integrates local features regression forests enable rgb-only images training testing. however none random forests based methods evaluated dynamic scenes indoor environment dynamic objects people pets common. line segment detection exploitation studied three decades still active robust gradient orientations line segment rather robust endpoints gradient magnitudes play crucial role line segment literature besides line segment detection work also related pose estimation using line and/or point features unlike methods using line features direct matching integrate line features random forests supervised learning. following three assumptions rgb-d camera input data made camera intrinsics known; depth frames synchronized; training contains rgb-d frames corresponding camera pose encoding rotation translation camera coordinates world coordinates. problem formulated given single acquired rgb-d image infer pose rgb-d camera relative known scene. solve problem propose exploit line point features uncertainty driven regression forests. method consists major components. ﬁrst component regression forests trained using general points line points respectively. forests predict general points line points testing. second component camera pose optimization scheme using point-to-point constraints point-on-line constraints. fig. depth corruption discontinuity line segments. line segments overlaid original image truncated depth map. effective depth information always available line segments corresponding image wrong depth values shown desk glass corridor areas. tures integrated training modeling uncertainty line point predictions. second uncertainty points lines simultaneously used optimize camera pose. line segment sampling directly back-projecting endpoints line using depth information cause large errors discontinuous depth object boundaries lack depth information shown fig. avoid problem line segment detector employed extract line segments l···} image shown fig. uniformly sample points line shown fig. using sample scheme could discard sample points whose depths unavailable back-project remaining points camera coordinates. backprojected points contain outliers could removed ransac line. fig. training random forests coordinate correspondence regression. labeled sample pixels randomly chosen entire tree world coordinate label pixel tree grows recursively root node leaf node. goal optimize parameters tree split nodes. spatial-variance used represent entropy. left subset right subset threshold feature fφi. although here random pixel comparison features weak learner model general features adapt application scenarios sift feature outdoor environment fig. shows training process. training samples reach leaf nodes. leaf node present work uses mean shift method estimate modes. mode mean vector covariance matrix described clustered points. addition proposed method stores mean vector local patch descriptors mode. local patch descriptor used choose optimal predictions. fig. line estimation based sampling points. within pinhole camera model image points evenly sampled image line back-projected scene coordinate scene points. scene points contain outliers could removed ransac line scene coordinate. scene coordinate labels random sampled points points points sampled line segment camera coordinate corresponding pixel computed back-projecting depth image pixels. scene’s world coordinate position corresponding pixel computed present sampling method train point prediction model line prediction model way. alternative different models. model predicts point-to-point correspondences another model directly predicts line-to-line correspondences. difﬁcult part method robust efﬁcient representations lines feature space. therefore proposed method predicts line-point-to-linepoint correspondences employs point-on-line constraint camera optimization process greatly simpliﬁes model learning prediction process. regression forest ensemble independently trained decision trees. stage train general point regression forest line-point regression forest. tree binary tree consisting split nodes leaf nodes. weak learner model split node represents weak learner parameterized {φiτi} feature dimension threshold. tree grows recursively root node leaf node. split node parameter sampled randomly sampled candidates split node incoming training samples evaluated split nodes learn split parameter best splits left child subset apartments practical application indoor robot localization. image sequences recorded resolution pixels depth resolution re-sampled images depth image resolution align images. ground truth camera poses bundlefusion main results analysis table shows main quantitative result scenes dataset. proposed method plforests considerably outperforms baselines achieves highest accuracy sequences average correct frame percentage fig. shows qualitative results present camera pose estimation. estimated camera poses including translations orientations similar ground truth camera poses. however scenes luke still exists large error camera pose estimates. investigate large error images large error poses shown fig. images seen little color information available present random pixel comparison features needed differentiate other. time line segments shown fig. apparent well. dataset microsoft scenes dataset consists scenes recorded handheld kinect rgb-d camera resolution. scene includes several camera sequences contain rgb-d frames together corresponding ground-truth camera poses obtained kinectfusion system. dataset exhibits fig. regression forests prediction. test split node feature compared feature response determine whether left right child node. arrows represent prediction process without backtracking purple arrows represent backtracking process. particular input along different paths different trees indicated purple arrows. testing backtracking technique optimal prediction within time budgets using priority queue. backtracking optimal mode minimum feature distance patch descriptor. fig. shows prediction process. speed backtracking number instead point-on-line segment forests general point forests make pointon-line general points predictions respectively. method optimizes camera pose using types constraints. ﬁrst constraint point-to-point correspondence. sampled camera coordinate point mode found concurrently best explains transformed observation second constraint point-on-line constraint. predicted edge point present work transforms location camera coordinate h−xw measures mahalanobis distance associated line optimized minimizing table camera relocalization results stanford scenes dataset. percentage correct frames developed method shown state-of-the-art methods orb+pnp sift+pnp random+sift best performance highlighted. fig. qualitative results stanford scenes dataset. best viewed color. living ofﬁce evenly sample every frames reconstructed scenes visualization. ground truth present estimated camera pose similar. please note scenes used visualization purposes used present algorithm. fig. large error examples stanford scenes dataset luke. image overlaid line segments ground truth estimated camera pose scene. white sheet gray ﬂoor dominate scene little color information line segments cause large camera pose error. uncertainty version scrf autocontext version scrf dense correspondence using terms correct frame percentage. also provide results terms median translation error rotation error bayesian posenet posenet+geometric cnn+lstm active search scrf btbrf main results analysis main results shown comparison strong baselines terms correct frames table terms median performance table. iii. proposed method achieves superior accuracy terms median performance on-par accuracy terms correct frames compared various methods. admittedly dense achieves little better average accuracy method still improve accuracy larger backtracking leaf node numbers compromise speed. compared stanford scenes dataset average accuracy microsoft scenes dataset relatively low. several reasons account this training testing sequences stanford scenes table relocalization results scenes dataset. test frames satisfying error metric shown proposed method scenes strong state-of-the-art methods scrf multi uncertainty autoconext dense. best performance highlighted. table median performance microsoft scenes dataset. results shown scenes baselines posenet+geomeric bayesian posenet active search without prioritization scrf btbrf best performance highlighted. high ambiguity especially stairs scene severe motion blur. fig. show qualitative results heads scene scenes dataset. present estimated camera pose similar ground truth. large errors occur places test poses different training poses. similar ﬁndings also seen scenes. rgb-d dynamic dataset rgb-d dataset mainly evaluation rgb-d slam systems. large image sequences various characteristics microsoft kinect rgb-d sensor. ground truth highly accurate time-synchronized motion capture system. sequences contain color depth images image resolution here dynamic objects dataset used complement previous static microsoft scenes dataset stanford scenes dataset dynamic objects exist. dynamic dataset challenging severe occlusions moving objects scene. training scenes listed table test respective evaluation sequences. fig. qualitative results heads scene microsoft scenes dataset. best viewed color enlarge. training test ground truth test estimated camera poses evenly sampled every images. present estimated camera pose similar ground truth translation rotation. large errors occur places training poses different test poses. recorded time whole sequence person training test sequences microsoft scenes dataset recorded different users different sequences split distinct training testing sequence sets. depth image better quality better registration stanford scenes. scenes microsoft scenes challenging fig. failure cases dynamic dataset. walking halfsphere. dynamic objects dominates image severe motion blur exists. walking halfsphere overlaid line segments many line segments dynamic objects. sitting halfsphere walking rpy. large rotation angle changes. results good sequences. sequences dynamic occlusions dominate scene cause inliers therefore lead failure cases shown fig. important failure case large rotation angle changes shown fig. random comparison feature rotation invariant. although plforests performs much better static scenes microsoft scenes stanford scenes btbrf signiﬁcant difference btbrf plforests dynamic scenes terms correct frames median performance. shows different error metric matters. possible reason many line segments dynamic objects shown fig. stable line segments correspondence matching ﬁltered outliers ransac situation. work propose exploit line point features within framework uncertainty driven regression forests. simultaneously consider point line predictions uniﬁed camera pose optimization framework. extensively evaluate proposed approach three datasets different space scale dynamics. experimental results demonstrate efﬁcacy developed method showing superior state-of-the-art on-par performance. furthermore different failure cases thoroughly demonstrated throwing light possible future work. baselines error metric three error metrics used evaluation ’correct frames’ percentage test frames within median translational angular error root mean squared error absolute trajectory error commonly used many slam system unlike microsoft scenes stanford scenes datasets training evaluation data different world coordinate systems. estimated trajectory still training data world coordinate. alignment dataset benchmark provide tools using horn’s method align estimated trajectory ground truth trajectory time step computed however could used auxilliary error metric considers translational error ignoring rotational errors. translational rotational error simultaneously optimized. main results analysis table shows main results proposed method dynamic dataset. compared static stanford scenes microsoft scenes performance lower high dynamics still work cases. proposed method accurate btbrf terms average correct frames rmse average median performance. proposed method could work satisfactorily highly dynamic scenes challenges still struggles extreme cases. fig. shows qualitative table camera relocalization results dynamic dataset. performances shown using three different error metrics correct percentage median rmse ate. valentin nießner kohli torr izadi keskin learning navigate energy landscape brachmann michel krull ying yang gumhold rother uncertainty-driven pose estimation objects scenes single image cvpr kendall grimes cipolla posenet convolutional network real-time -dof camera relocalization iccv kendall cipolla modelling uncertainty deep learning schmidt newcombe self-supervised visual descriptor learning dense correspondence ieee ra-letters lowe little vision-based global localization glocker shotton criminisi izadi real-time rgb-d camera relocalization randomized ferns keyframe encoding visualization computer graphics ieee trans. kabsch solution best rotation relate sets vectors acta crystallographica section crystal physics diffraction theoretical general crystallography gioi jakubowicz j.-m. morel randall fast line segment detector false detection control pami rehbinder ghosh pose estimation using line-based dynamic vision inertial sensors ieee trans automatic control nießner zoll¨ofer izadi theobalt bundlefusion real-time globally consistent reconstruction using on-the-ﬂy surface re-integration trans. graphics sturm engelhard endres burgard cremers benchmark evaluation rgb-d slam systems iros mur-artal montiel tard´os orb-slam versatile accurate monocular slam system ieee trans. robotics", "year": 2017}