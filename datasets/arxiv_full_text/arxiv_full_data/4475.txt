{"title": "Automatically Selecting Useful Phrases for Dialogue Act Tagging", "tag": ["cs.AI", "cs.LG", "I.2.7; I.2.6"], "abstract": "We present an empirical investigation of various ways to automatically identify phrases in a tagged corpus that are useful for dialogue act tagging. We found that a new method (which measures a phrase's deviation from an optimally-predictive phrase), enhanced with a lexical filtering mechanism, produces significantly better cues than manually-selected cue phrases, the exhaustive set of phrases in a training corpus, and phrases chosen by traditional metrics, like mutual information and information gain.", "text": "present empirical investigation various ways automatically identify phrases tagged corpus useful dialogue tagging. found method enhanced lexical ﬁltering mechanism produces signiﬁcantly better cues manually-selected phrases exhaustive phrases training corpus phrases chosen traditional metrics like mutual information information gain. although machine learning approaches achieved success many areas natural language processing researchers recently begun investigate applying machine learning methods discourse-level problems important task discourse understanding interpret utterance’s dialogue concise abstraction speaker’s intention; figure presents hypothetical dialogue labeled dialogue acts. recognizing dialogue acts critical discourse-level understanding also useful applications resolving ambiguity speech recognition. however computing dialogue acts challenging task often dialogue cannot directly inferred literal interpretation utterance. investigated applying transformation-based learning task computing dialogue acts. transformation-based learning symbolic supervised machine learning method generates sequence rules. method applied previously discourse-level problems number attractive characteristics task intuitive learned model resistance overﬁtting. machine learning algorithm makes several abstract features extracted particular eﬀective features utterances phrases utterance provide useful information dialogue tagging experimentally compared eﬀectiveness various automatic methods selecting phrases applying verbmobil tagged corpus corpus consists appointment-scheduling dialogues utterance manually labeled eighteen dialogue acts greet suggest accept. although understand problems dialogue acts corpus assume correct issues beyond scope project. event another tagged corpus become available methods presented directly applicable. results showed metric enhanced simple lexical ﬁltering mechanism select phrases eﬀective dialogue tagging phrases chosen human intuitive approaches traditional metrics several researchers identiﬁed phrases useful discourse processing way. cases research focused selecting phrases might generally useful; however found many phrases appear useful purposes included previous literature. analyzing phrases tags corpus automatic methods directly address three important factors speciﬁc dialogue acts want identify aﬀect usefulness phrases. example verbmobil dialogue acts thank motivates need phrases like thank thanks. intuitively phrases examples seem perfectly reasonable indicators dialogue acts. however knowledge previously identiﬁed phrases phrases. leads suspect domain task tags need considered selecting phrases. relatively diﬃcult human coders label utterances dialogue acts consistent manner. traditionally intercoder reliability intracoder reliability signiﬁcant problems dialogue tagging. there substantial disagreement select eﬀective dialogue acts. although several researchers currently addressing problem research community still lacks standardized dialogue acts. cooccurrences conditional probability entropy test mutual information selectional preference strength information gain deviation deviation conditional probability goal research devise method automatically identiﬁes dialogue cues. section discusses baseline approaches several automatic methods listed figure used sets phrases baselines comparison. consists diﬀerent phrases proposed twelve papers dissertations books represents extreme approach selecting sequences three words found training corpus. although likely include useful phrases also includes many extraneous phrases hypothesize irrelevant phrases overwhelm machine learning algorithm. general approach metric estimates useful phrase dialogue tagging analyzing dialogue acts utterances containing phrase training corpus. section discuss motivations limitations several diﬀerent metrics considered. reasonable expect dialogue would cooccur frequently speciﬁc dialogue act. example verbmobil corpus phrase found utterances labeled suggesting dialogue cue. straightforward rank phrases count often phrase occurs utterances labeled dialogue act. cooccurence method sorts phrases decreasing order cooc scores considering dialogue distribution. simple cooc metric take account priori distribution dialogue acts. unless dialogue equally likely frequently-occurring dialogue acts generate many high-scoring phrases even though inappropriate. might better replace joint frequency cooc conditional probability phrase given dialogue act. conditional probability method sorts phrases decreasing order scores since cooc maximize dialogue acts scores account dialogue phrase. might expect dialogue cooccur frequently dialogue acts infrequently others; theoretically optimal dialogue would correlate perfectly single dialogue represented dashed line figure might worthwhile consider skewed distribution dialogue acts cooccurring phrase criterion captured entropy dialogue acts given phrase. entropy method sorts phrases increasing order scores however like cooc account priori distribution dialogue acts. suppose original dialogue distribution relatively entropy phrase completely independent dialogue acts. also relatively incorrectly signifying conveys useful information. account priori dialogue distribution examined four diﬀerent metrics based kullback-liebler distance mutual information test information gain. selectional preference strength method considers diﬀerence distribution dialogue acts given particular phrase priori distribution dialogue acts estimate amount information phrase carries dialogue acts cooccurs with. special case kullback-liebler distance measures much information dialogue would lost failing recognize speciﬁc phrase. selectional preference strength method sorts phrases decreasing order scores mutual information used measure reduction uncertainty factor results introduction another factor. consider mutual information dialogue acts phrase compute reduction uncertainty utterance’s dialogue utterance contains phrase. mutual information method sorts phrases decreasing order scores test used measure statistical diﬀerence distributions. test priori distribution dialogue acts distribution dialogue acts given phrase. test method sorts phrases decreasing order ttest scores information gain typically utilized estimate usefulness feature. example information gain used determine split node decision tree considering distributions data fall along branch. task testing existence phrase information gain measure reduction entropy dialogue acts resulting partitioning utterances based whether contain phrase. information gain method sorts phrases decreasing order scores addition adapting existing metrics also designed metrics evaluate phrases based estimated eﬀectiveness hypothetical rule recall that optimal dialogue correlates perfectly single dialogue dialogue rule valid. therefore hypothetical dialogue would perfect indicator dialogue metrics measure much phrase deviates optimal design assigning penalty point utterance rule fails. points. however unsoundness alone suﬃcient. phrase produce perfect unsoundness score still optimal. extreme case phrase appears training corpus unsoundness score possible address problem consider thin line figure represents phrase occurs utterances utterances labeled suggest. although certainly useful phrase since sound optimal phrase notice suggest utterances include phrase. expect another equally-sound phrase occurs frequently ranked higher considering case rule incomplete meaning applies incorrectly. utterance labeled contain assign penalty point phrase total points. unclear combine unsoundness incompleteness general metric. certainly choosing equally sound phrases would prefer phrase complete vice versa. initial approach considered adding incompleteness unsoundness together. deviation method sorts phrases decreasing order scores like cooc metric account priori distribution dialogue acts. considered replacing joint frequencies conditional probabilities. deviation conditional probability method sorts phrases increasing order scores conducted experiments evaluate merits various metrics discussed last section. first used metric order phrases then manually examined highest-ranking phrases intuitively compare methods. qualitative analysis immediately revealed problems. several methods suﬀer undesirable bias based frequency. many methods susceptible infrequent phrases; phrase appears twice corpus cannot really draw reliable conclusions usefulness. hand number methods biased toward phrases appear frequently phrases cooccurring frequently several dialogue acts making poor discriminators dialogue acts. address frequency bias might want remove phrase frequency outside arbitrary range. however believe diﬃcult appropriate range would prefer address problem developing automatic mechanism. addition analyzed tradeoﬀs unsoundness incompleteness. figure lists phrases believe dialogue cues specifying would ranked based unsoundness incompleteness alone. example phrase thanks occurs eleven utterances training corpus utterances labeled thank dialogue act. result assigned good unsoundness score. however since every phrase occurs training corpus gets perfect unsoundness score outrank thanks unsoundness considered. alternatively using incompleteness thanks ranked method ranks ﬁfth. problem unsoundness biased toward low-frequency phrases incompleteness biased toward high-frequency phrases. clear combine factors order balance biases. methods simply them although also considered weighting incompleteness unsoundness diﬀerent ways. another potential problem that several methods many highest-ranking phrases appear address goal. example eight phrases signal suggest dialogue basically way. surprising since phrases receives good score should. however hypothesize repetitions eliminated order produce concise phrases since increase eﬀectiveness machine learning method tagging dialogue acts. furthermore want select predetermined number phrases wide variety diﬀerent phrases probably useful many redundant phrases. starting point easily eliminate redundant phrases simple lexical ﬁltering mechanism introduced samuel phrase contains another phrase subsequence second phrase ranked higher ﬁrst phrase probably repetitious unlikely contribute anything useful. example suppose phrase ranked higher will indicating informative. since appears every utterance will appears good reason keep phrase will you. phrase better coverage better score always serve better feature dialogue tagging. lexical ﬁlter removes phrase subsequences ranked higher. several experiments compare methods figure task labeling utterances dialogue acts. experiments applied transformation-based learning using three classes features experimentally found particularly eﬀective attractive characteristic transformation-based learning generates preliminary tags training. tags used features reﬁne learned model. ramshaw marcus referred leveraged learning. help determine dialogue given utterance system used preliminary dialogue assigned preceding utterance feature. system utilized change-of-speaker feature represented information speaker given utterance. boolean feature true utterance speaker utterance diﬀers speaker preceding utterance false otherwise. eﬀective heuristic cluster certain words semantic classes collapse several dialogue cues single dialogue cue. example appointmentscheduling corpora strong correlation utterances mention weekdays suggest dialogue express fact necessary consider separate dialogue cues monday tuesday wednesday thursday friday the. however weekdays combined label weekday information captured single dialogue times much data supporting experiments presented paper following semantic clusters weekday month number ordinal-number proper-name. since methods supposed rank dialogue cues higher phrases able separate dialogue cues phrases. test this applied various cutoﬀ points method determine many lower-ranking phrases removed accuracy begins decrease. wanted investigate cutoﬀ points isolation lexical ﬁlter used experiments. figure presents accuracy method function number phrases used. sets also included ﬁgure comparison. four methods ttest produced accuracies signiﬁcantly phrases selected. implies many dialogue cues ranked bottom methods suggesting problem phrase orderings. hand four methods cooc could remove phrases without signiﬁcantly aﬀecting accuracy. methods also produced signiﬁcantly higher accuracy scores set. therefore automatic methods select phrases better dialogue tagging phrases found literature. experiments paper diﬀerences analyzed statistical signiﬁcance test tukey honest signiﬁcant diﬀerences test extension test appropriate comparing distributions. higher all’s accuracy. hypothesized above appears irrelevant phrases limit accuracy machine learning method. expect eﬀect would pronounced larger training corpus another machine learning method however cutoﬀ points lower signiﬁcantly worse all. believe susceptible repetitive phrases. since assigns high scores many redundant phrases require relatively large phrases order capture full variety dialogue cues. precisely problem lexical ﬁlter designed address. next experiments tested lexical ﬁlter. phrases ordered properly ﬁlter eliminate redundant phrases without compromising accuracy labeling dialogue acts. first ordered phrases method applied ﬁlter. then used various cutoﬀ points select top-ranked phrases training testing dialogue tagger. ﬁgure three methods cooc omitted clarity results similar ig’s results. also lexical ﬁlter four curves don’t extend beyond phrases lexical ﬁlter removes phrases case. believe important ﬁlter consider phrase selected. example phrase tends signal greet dialogue utterance likely init. ﬁlter would erroneously remove phrase losing relevant information. modiﬁed ﬁlter follow rule second condition requires explanation. cooc methods metrics maximize dialogue acts. given phrase determine dialogue producing maximum value deﬁne dialogue referred second condition. methods metrics dialogue acts. cases follow resnik selecting dialogue produces greatest contribution sum. eﬀect modiﬁed ﬁlter varies dramatically removing phrases shown figure however figure shows that expected using ﬁlter cause accuracy decrease. addition allows system maintain high accuracy fewer phrases. particular dcp’s accuracy signiﬁcantly higher all’s accuracy using phrases all. suggests ﬁlter eﬀectively removing redundant phrases produce parsimonious phrases. paper presented investigation various methods selecting useful phrases. argued traditional method selecting phrases human researcher analyzes discourse chooses general phrases intuition could miss useful phrases. address problem introduced automatic methods tagged training corpus select phrases experimental results demonstrated methods outperform manual approach. another advantage automatic methods easily transferred another tagged corpus. experiments also showed eﬀectiveness diﬀerent methods dialogue tagging task varied signiﬁcantly using relatively small sets phrases. method used metric produced signiﬁcantly higher accuracy scores baselines traditional metrics analyzed. addition hypothesized repetitive phrases eliminated order produce concise phrases. experimental results showed modiﬁed lexical ﬁlter eliminate many redundant phrases without compromising accuracy enabling system label dialogue acts eﬀectively using phrases. number research areas would like investigate future including following intend experiment diﬀerent weightings unsoundness incompleteness metric; believe simple lexical ﬁlter presented paper enhanced improve would like study merits enforcing frequency thresholds methods frequency bias; semantic-clustering technique selected clusters words hand would interesting taxonomy wordnet could used automate process; since experiments paper single corpus order show results generalize tasks domains would necessary experiments diﬀerent corpora. members verbmobil research group dfki germany including norbert reithinger alexandersson elisabeth maier generously granted access verbmobil corpora. work partially supported grant ger-. eugenio moore paolucci. learning features predict usage. proceedings annual meeting association computational linguistics conference european chapter association computational linguistics. madrid spain. halliday hasan. cohesion english. longman group limited london england. heeman byron allen. identifying discourse markers spoken dialog. applying machine learning discourse processing papers american association artiﬁcial intelligence spring symposium. stanford california. litman classifying phrases text speech using machine learning. proceedings twelfth national conference american association artiﬁcial intelligence. seattle washington. ramshaw marcus. exploring statistical derivation transformation rule sequences part-of-speech tagging. proceedings annual meeting association computational linguistics. cruces mexico. balancing workshop. samuel carberry vijay-shanker. computing dialogue acts features transformation-based learning. applying machine learning discourse processing papers american association artiﬁcial intelligence spring symposium. stanford california. samuel carberry vijay-shanker. dialogue tagging transformation-based learning. proceedings international conference computational linguistics annual meeting association computational linguistics. montr´eal qu´ebec canada. warner discourse connectives english. garland publications york york. wiebe o’hara mckeever ¨ohrstroem-sandgren. empirical approach temporal reference resolution. proceedings second conference empirical methods natural language processing. providence rhode island. zukerman pearl. comprehension-driven generation meta-technical utterances math tutoring. proceedings sixth national conference american association artiﬁcial intelligence. philadelphia pennsylvania.", "year": 1999}