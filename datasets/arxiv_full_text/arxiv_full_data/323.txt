{"title": "Conditional Generative Adversarial Nets", "tag": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "abstract": "Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.", "text": "generative adversarial nets recently introduced novel train generative models. work introduce conditional version generative adversarial nets constructed simply feeding data wish condition generator discriminator. show model generate mnist digits conditioned class labels. also illustrate model could used learn multi-modal model provide preliminary examples application image tagging demonstrate approach generate descriptive tags part training labels. generative adversarial nets recently introduced alternative framework training generative models order sidestep difﬁculty approximating many intractable probabilistic computations. adversarial nets advantages markov chains never needed backpropagation used obtain gradients inference required learning wide variety factors interactions easily incorporated model. unconditioned generative model control modes data generated. however conditioning model additional information possible direct data generation process. conditioning could based class labels part data inpainting like even data different modality. work show construct conditional adversarial net. empirical results demonstrate experiment. mnist digit data conditioned class labels flickr dataset multi-modal learning. despite many recent successes supervised neural networks remains challenging scale models accommodate extremely large number predicted output categories. second issue much work date focused learning one-to-one mappings input output. however many interesting problems naturally thought probabilistic one-to-many mapping. instance case image labeling many different tags could appropriately applied given image different annotators different terms describe image. help address ﬁrst issue leverage additional information modalities instance using natural language corpora learn vector representation labels geometric relations semantically meaningful. making predictions spaces beneﬁt fact prediction errors still often ‘close’ truth also fact naturally make predictive generalizations labels seen training time. works shown even simple linear mapping image feature-space word-representation-space yield improved classiﬁcation performance. address second problem conditional probabilistic generative model input taken conditioning variable one-to-many mapping instantiated conditional predictive distribution. generative adversarial nets recently introduced novel train generative model. consists ‘adversarial’ models generative model captures data distribution discriminative model estimates probability sample came training data rather could non-linear mapping function multi-layer perceptron. learn generator distribution data data generator builds mapping function prior noise distribution data space discriminator outputs single scalar representing probability came form training data rather trained simultaneously adjust parameters minimize log) adjust parameters minimize logd following two-player min-max game value function generative adversarial nets extended conditional model generator discriminator conditioned extra information could kind auxiliary information class labels data modalities. perform conditioning feeding discriminator generator additional input layer. generator prior input noise combined joint hidden representation adversarial training framework allows considerable ﬂexibility hidden representation composed. discriminator presented inputs discriminative function generator noise prior dimensionality drawn uniform distribution within unit hypercube. mapped hidden layers rectiﬁed linear unit activation layer sizes respectively mapped second combined hidden relu layer dimensionality ﬁnal sigmoid unit layer output generating -dimensional mnist samples. simply conditioning input prior noise inputs single hidden layer could imagine using higher order interactions allowing complex generation mechanisms would extremely difﬁcult work traditional generative framework. model trained using stochastic gradient decent mini-batches size initial learning rate exponentially decreased decay factor also momentum used initial value increased dropout probability applied generator discriminator. best estimate log-likelihood validation used stopping point. table shows gaussian parzen window log-likelihood estimate mnist dataset test data. samples drawn class gaussian parzen window ﬁtted samples. estimate log-likelihood test using parzen window distribution. details estimate constructed.) conditional adversarial results present comparable network based outperformed several approaches including non-conditional adversarial nets. present results proof-of-concept demonstration efﬁcacy believe exploration hyper-parameter space architecture conditional model match exceed non-conditional results. user-generated metadata differ ‘canonical’ image labelling schems typically descriptive semantically much closer humans describe images natural language rather identifying objects present image. another aspect synoymy prevalent different users different vocabulary describe concepts consequently efﬁcient normalize labels becomes important. conceptual word embeddings useful since related concepts represented similar vectors. section demonstrate automated tagging images multi-label predictions using conditional adversarial nets generate distribution tag-vectors conditional image features. image features pre-train convolutional model similar full imagenet dataset labels output last fully connected layer units image representations. world representation ﬁrst gather corpus text concatenation user-tags titles descriptions yfccm dataset metadata. pre-processing cleaning text trained skip-gram model word vector size omitted word appearing less times vocabulary thereby ending dictionary size experiments flickr dataset extract image tags features using convolutional model language model described above. images without omitted experiments annotations treated extra tags. ﬁrst examples used training set. images multiple tags repeated inside training associated tag. evaluation generate samples image closest words using cosine similarity vector representation words vocabulary sample. select common words among samples. table shows samples user assigned tags annotations along generated tags. best working model’s generator receives gaussian noise size noise prior maps dimension relu layer. maps dimension image feature vector dimension relu hidden layer. layers mapped joint representation dimension linear layer would output generated word vectors. discriminator consisted dimension relu hidden layers word vectors image features respectively maxout layer units pieces join layer ﬁnally single sigmoid unit. model trained using stochastic gradient decent mini-batches size initial learning rate exponentially decreased decay factor also momentum used initial value increased dropout probability applied generator discriminator. another obvious direction left future work construct joint training scheme learn language model. works shown learn language model suited speciﬁc task. project developed pylearn framework would like thank pylearn developers. also like thank goodfellow helpful discussion afﬁliation university montreal. authors gratefully acknowledge support vision machine learning production engineering teams flickr", "year": 2014}