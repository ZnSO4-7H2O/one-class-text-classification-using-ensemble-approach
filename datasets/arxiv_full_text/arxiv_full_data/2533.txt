{"title": "Noisy Submodular Maximization via Adaptive Sampling with Applications to  Crowdsourced Image Collection Summarization", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "We address the problem of maximizing an unknown submodular function that can only be accessed via noisy evaluations. Our work is motivated by the task of summarizing content, e.g., image collections, by leveraging users' feedback in form of clicks or ratings. For summarization tasks with the goal of maximizing coverage and diversity, submodular set functions are a natural choice. When the underlying submodular function is unknown, users' feedback can provide noisy evaluations of the function that we seek to maximize. We provide a generic algorithm -- \\submM{} -- for maximizing an unknown submodular function under cardinality constraints. This algorithm makes use of a novel exploration module -- \\blbox{} -- that proposes good elements based on adaptively sampling noisy function evaluations. \\blbox{} is able to accommodate different kinds of observation models such as value queries and pairwise comparisons. We provide PAC-style guarantees on the quality and sampling cost of the solution obtained by \\submM{}. We demonstrate the effectiveness of our approach in an interactive, crowdsourced image collection summarization application.", "text": "like select small subset images summarizes theme cathedrals venice figure cast summarization task problem maximizing submodular function cardinality constraints. submodular maximization. usually assumed known i.e. evaluated exactly querying oracle. case greedy algorithm typically used maximization. greedy algorithm builds items picking highest marginal utility every iteration given items selected far. despite greedy nature algorithm provides best constant factor approximation optimal solution computable polynomial time maximization noise. however many realistic applications function known evaluated noise. instance image summarization task querying users’ feedback form clicks ratings individual images image-sets provide noisy evaluations. settings marginal gains hard compute exactly e.g. computing marginal gains nodes viral marketing applications conditional information gains feature selection tasks cases apply naive uniform sampling approach estimate marginal gains error apply standard greedy algorithm. simple uniform sampling approach could high sample complexity rendering impractical real-world applications. work propose adaptive sampling strategies reduce sample complexity maintaining high quality solutions. approach adaptive sampling. ﬁrst insight efﬁcient adaptive sampling need estimate marginal gains necessary conﬁdence decide best item select next. however difference marginal gains best item second best item small approach also suffers high sample complexity. overcome this exploit second insight instead focusing selecting single best item sufﬁcient select item small subset size high quality items cardinality constraint. based insights propose novel exploration module topx proposes good elements adaptively sampling noisy function evaluations. address problem maximizing unknown submodular function accessed noisy evaluations. work motivated task summarizing content e.g. image collections leveraging users’ feedback form clicks ratings. summarization tasks goal maximizing coverage diversity submodular functions natural choice. underlying submodular function unknown users’ feedback provide noisy evaluations function seek maximize. provide generic algorithm expgreedy maximizing unknown submodular function cardinality constraints. algorithm makes novel exploration module topx proposes good elements based adaptively sampling noisy function evaluations. topx able accommodate different kinds observation models value queries pairwise comparisons. provide pac-style guarantees quality sampling cost solution obtained expgreedy. demonstrate effectiveness approach interactive crowdsourced image collection summarization application. many applications involve selection subset items e.g. summarization content web. typically task select subset items limited cardinality goal maximizing utility. utility often measured properties like diversity information relevance coverage. submodular functions naturally capture fore-mentioned notions utility. intuitively submodular functions functions satisfy natural diminishing returns property. widely used diverse applications including content summarization recommendations sensor placement viral marketing numerous machine learning computer vision tasks summarization image collections. motivating applications subject experimental evaluation summarization image collections. given collection images venice flickr would figure image collection summarized; summaries obtained using pairwise comparisons crowdsourcing themes venice venice carnival venice cathedrals. images numbered order selection. provide greedy algorithm expgreedy submodular maximization function noisy evaluations. core part algorithm exploration module topx invoked every iteration implements novel adaptive sampling scheme efﬁciently selecting small items high marginal utilities. theoretical analysis experimental evaluation provide insights trade-off quality subsets selected expgreedy number evaluation queries performed topx. demonstrate applicability algorithms real-world application crowdsourcing summarization image collections eliciting crowd preferences based pairwise comparisons figure submodular function maximization submodular functions arise many applications therefore optimization studied extensively. example celebrated result nemhauser wolsey fisher shows non-negative monotone submodular functions cardinality constraints maximized constant factor simple greedy algorithm. submodular maximization furthermore studied variety different constraints e.g. matroid constraints graph constraints different settings e.g. distributed optimization function evaluated noise naive uniform sampling approach employed estimate marginal gains approach could high sampling complexity. learning submodular functions. could approach maximization unknown submodular function ﬁrst learning function interest subsequently optimizing tschiatschek present approach learning linear mixtures known submodular component functions image collection summarization. work complimentary approach wherein directly target subset selection problem without learning underlying function. general learning submodular functions submodular function maximization work also related online submodular maximization bandit feedback. streeter golovin present approaches maximizing sequence submodular functions online setting. adversarial setting forces conservative algorithms slow convergence. guestrin study restricted setting objective linear combination known submodular functions stochastic noise. related spirit approaches minimize cumulative regret. contrast identify single good solution performing queries possible mentioned results apply setting. best identiﬁcation exploratory bandits learner ﬁrst explores actions time budget constraints exploits gathered information choosing estimated best action beyond best individual actions zhou chen design algorithm topm identiﬁcation problem goal return subset size whose aggregate utility within compared aggregate utility best actions. chen generalize problem considering combinatorial constraints subsets selected e.g. subsets must size represent matchings etc. present general learning algorithms decision classes admit ofﬂine maximization oracles. dueling bandits variants bandit problem feedback limited relative preferences pairs actions. best-identiﬁcation problem studied weaker information model various notions ranking models busa-fekete h¨ullermeier however contrast work reward functions considered chen existing algorithms modular thus limiting applicability algorithms. work also related contemporary work hassidim singer treat submodular maximization noise. algorithms apply persistent noise technique computationally demanding enable noisy preference queries. note obtaining optimal solutions problem intractable however greedy optimization scheme based marginal utilities items provide solution sgreedy i.e. solution within constant factor optimal solution efﬁciently determined. setting evaluate unknown utility function noisy queries thus cannot hope achieve guarantees. idea stochastic setting algorithms make repeated queries aggregate noisy evaluations obtain sufﬁciently accurate estimates marginal gains items. study proposed algorithms setting i.e. design algorithms that given positive constants determine sthat \u0001-competitive relative reference solution probability least natural baseline constant factor approximation optimal solution i.e. determine probability least present algorithm expgreedy maximizing submodular functions noise. intuitively aims mimic greedy algorithms noise-free settings ensuring selects good element iteration. since canevaluate marginal gains exactly must experiment different items statistical inference select items high value. experimentation core part algorithm implemented novel exploration module called topx. algorithm expgreedy algorithm iteratively builds invoking topx every iteration select next item. topx returns candidate items could potentially included maximize utility. simplest adaptive sampling strategy topx could implement estimate marginal gains necessary conﬁdence decide next best item select however difference marginal gains best second best item small approach could suffer high sample complexity. extending ideas randomized greedy algorithm show theorem every iteration instead focusing sufﬁcient expgreedy select item small subset items high utility. corresponds following conditions topx topx returns subset size probability least items satisfy utility model. items. assume utility function subsets given items utility furthermore assume non-negative monotone submodular. monotone functions satisfy submodular functions satisfy following diminishing returns condition v\\{a} holds {a}) conditions satisﬁed many realistic complex utility functions concretely image collection summarization example collection images function assigns every summary score preferring relevant diverse summaries. observation model. classical submodular optimization assumed known i.e. evaluated exactly oracle. contrast assume noisy evaluations obtained. instance summarization example evaluate query users rate summary elicit user preferences pairwise comparisons different summaries. following formally describe types queries detail value queries. variant query value model noisy evaluation response query random variable xa|s unknown sub-gaussian distribution. assume xa|s mean repeated queries return samples drawn i.i.d. unknown distribution. preference queries. items preference query aims determining whether item preferred item context model noisy response pairwise comparison random variable xa>b|s takes values assume xa>b|s follows unknown distribution satisﬁes following properties xa>b|s mean larger mapping utilities probabilities monotone sense given given gaps utilities satisfy items mean xa>b|s greater equal mean xa>b|s. instance distribution induced commonly used bradley-terry-luce preference model satisﬁes conditions. assume repeated queries return samples drawn i.i.d. unknown distribution. approximated stochastic simulations hand preference queries natural learn relevant interesting users compared asking assign numerical scores difﬁcult calibrate. figure example illustrate idea topl item selection items parameter identiﬁcation identiﬁcation high sample complexity identiﬁcation relatively easy. topx value queries begin observation ﬁxed exploration module topx satisfying condition implemented solving topl identiﬁcation problem. seen follows. given input parameter deﬁne value deﬁne then value modular function. thus setting meeting condition requires identifying maximizing modular function cardinality constraints noisy queries. corresponds topl best-arm identiﬁcation problem. particular chen proposed algorithm clucb identifying best subset modular functions combinatorial constraints. high level clucb maintains upper lower conﬁdence bounds item values adaptively samples noisy function evaluations pessimistic estimate current best topl subset exceeds optimistic estimate subset size worst case sample complexity problem characterized values l-th item item mentioned sample complexity topl problem vary orders magnitude different values figure unfortunately know value lowest sample complexity advance. however modify clucb jointly estimate marginal gains solve topl problem lowest sample complexity. proposed algorithm implementing idea presented algorithm maintains conﬁdence intervals marginal item values conﬁdence radius item computed radt corresponding random variables xi|s assumed r-sub-gaussian tail number observations made item time exact value known upper bounded range upon termination algorithm returns satisﬁes condition extending results chen bound sample complexity algorithm follows. consider gaps permutation items iteration satisfying conditions equivalent solving topl identiﬁcation problem pac-parameters topx essentially returns size containing items largest marginal utilities given consider special cases iterations. then noise free setting expgreedy case mimics classical greedy algorithm case randomized greedy algorithm respectively. discussed next section sample complexity cases high. insight expgreedy could efﬁciently solve topl problem size solution submodular maximization problem guaranteed high quality. summarized following theorem theorem using invoking topx algorithm returns probability satisﬁes guarantee probability least sion paper turns solutions greedy algorithm noiseless setting sgreedy often utility larger therefore also seek algorithms probability least identify solutions satisfying condition actually equivalent requiring topx high probability identiﬁes element largest marginal utility. proof follows application union bound. theorem ensures construct corresponding exploration module successfully compete greedy algorithm access however prohibitively expensive terms required number queries performed topx appendix extended version paper |s). every ﬁxed sample complexity identifying items characterized reason small many samples needed ensure conﬁdence bounds radt small enough distinguish elements runner-up. insight adaptive largest long value large able enjoy sample complexity theorem given algorithm returns v|a| probability least satisﬁes condition using topx preference queries show noisy preference queries used. introduced previously assume exists underlying preference model induces probabilities pi>j|s item preferred item given values work focus identifying borda winner i.e. item maximizing borda score formally given j∈v\\{i} pi>j|s. borda score measures probability item preferred another item chosen uniformly random. furthermore model assume increasing utilities leads monotonic increase induced probabilities holds items terms marginal gains items terms borda scores. make result called borda reduction technique allows reduce preference queries value queries consequently invoke algorithm small modiﬁcations. deﬁning values borda score. item algorithm tracks updates mean estimates values preference queries values replaced borda scores. sample complexity theorem given terms borda scores. instance bradley-terryluce preference model borda score item given +exp here captures problem difﬁculty corresponds case noisefree responses corresponds uniformly random binary responses. effect illustrated synthetic experiments. incorporating noisy responses. observing value item preference query model corresponds pairing item \\{i} selected uniformly random. observed preference response provides unbiased estimate borda score item generally pick small ﬁxed size selected uniformly random replacement compare member then observed borda score item calculated xi>j|s. here parameter algorithm. observe cost preference query times cost value query. effect illustrated experiments. experimental setup utility function items synthetic experiments assume underlying submodular utility function maximize. exploration module topx performs value preference queries receives noisy responses based model parameters marginal gains items function. experiments constructed realistic probabilistic coverage utility function following ideas el-arini ground items. details construction important results stated found appendix extended version paper figure experimental results using synthetic function simulated query responses results value queries results preference queries. expgreedy dramatically reduces sample complexity compared uniform adaptive baselines. expgreedy adaptively allocates queries identify largest execution instance showing marginal gains sizes topl solutions returned topx. expgreedy robust noise outperforms uniform baseline. omitting means \u0001/k. benchmarks compare performance deterministic greedy algorithm greedy well random selection random. natural competitive baseline compare algorithms uniform replacing topx module naive exploration module uniformly samples items best item identiﬁcation. experiments used parameters cardinality constraint iteration x-axis total budget available terms queries performed equivalent times average budget shown x-axis. particular compare quality solutions obtained expgreedy different figure different figure averaged runs. parameter controls noise-level responses preference queries whereas algorithm’s parameter indicating many pairwise comparisons done query reduce variance. reference show extreme case equivalent random; case equivalent greedy. general higher value queries lower smaller preference queries budget must spent achieve solutions high utility. figure figure also report quality solutions obtained uniform case respectively. results order achieve desired value total utility uniform require times budget comparison required expgreedy. figure compares different algorithms allocate budget across items iterations. observe expgreedy exploration across different items compared expgreedyg expgreedyo. however exploration heavily skewed comparison uniform adaptive sampling topx. figure shows marginal gain utility considered algorithms different iterations particular execution instance expgreedy size topl solutions returned topx every iteration indicated results sample complexity. figure consider value queries compare number queries performed different algorithms varying noise-levels convergence solution desired guarantees. variance generated query responses sampling uniformly interval expected value query. reference query cost greedy access unknown function marked sample complexity differs orders magnitude i.e. number queries performed expgreedy grows much slower expgreedyg expgreedyo. sample complexity uniform worse orders magnitude compared variants algorithm. varying value queries preference queries. next investigate quality obtained solutions limited budget total number queries performed. although convergence slow still good solutions early many cases. figures vary available average budget item present results crowdsourced image collection summarization application performed amazon’s mechanical turk platform. image retrieved images related city venice flickr figure total distinct workers participated summarization task. workers queried pairwise preferences follows. told goal summarize images venice motivated application selecting small pictures send friends returning trip venice. detailed instructions found appendix extended version paper three instances algorithm three distinct summarization tasks themes venice venice carnival venice cathedrals. workers told particular theme summarization. additionally images already selected proposal images shown. asked images would improve summary added already selected images. running expgreedy used average budget queries item iteration figure note make function constructed synthetic experiments i.e. function maximized known results experiment shown figure demonstrating methodology works real-word settings produces high quality summaries captures semantics task. considered problem cardinality constrained submodular function maximization noise i.e. function optimized evaluated noisy queries. proposed algorithms based novel adaptive sampling strategies achieve high quality solutions sample complexity. theoretical analysis experimental evaluation provide insights trade-offs solution quality sample complexity. furthermore demonstrated practical applicability approach crowdsourced image collection summarization application. acknowledgments. would like thank besmira nushi helpful discussions. research supported part snsf grant nano-tera.ch program part opensense project. singla tschiatschek krause noisy submodular maximization adaptive sampling applications crowdsourced image collection summarization http//arxiv.org/abs/..", "year": 2015}