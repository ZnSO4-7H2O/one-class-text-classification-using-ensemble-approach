{"title": "Deep Learning Methods for Efficient Large Scale Video Labeling", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "We present a solution to \"Google Cloud and YouTube-8M Video Understanding Challenge\" that ranked 5th place. The proposed model is an ensemble of three model families, two frame level and one video level. The training was performed on augmented dataset, with cross validation.", "text": "addition supplying video data dataset authors also provided starter code base competition. starter code well structured provided whole pipeline data input model training prediction output. included several base models proved robust baseline creative model work. evaluation following three sections describe elements work. first describe data augmentation followed descriptions used models assembly. finally describe model training techniques tested used. ﬁnal solution includes frame level video level models. hence description cover cases everything applicable models. provided video level data consists mean mean audio. google research team reported better model performance adding second moments ordinal statistics feature dimension feature engineering efforts started similar extensions ﬁrst generated ﬁrst three moments audio features frame level data. named mean mean audio audio audio. also used number frames video rames second moments audio entire frame level video data. features used combination video level models contributed model performance. noticed high correlation present solution google cloud youtubem video understanding challenge ranked place. proposed model ensemble three model families frame level video level. training performed augmented dataset cross validation. gathering huge datasets organizing competitions driven forward machine learning model development. fact breakthroughs achieved part competitions however large scale video predicting remains date non-trivial problem. tackle problem google cloud hosted kaggle competition dataset consisting million thousand labeled unlabeled videos respectively. labels vocabulary consisted labels. participants asked develop machine learning model would predict labels assigned videos test dataset. organizers provided datasets; video level features another frame level features. frame level consisted features audio features frame video sampled every second frames. features extracted last relu activation hidden layer before classiﬁcation layer inception-v network. extraction features dimension reduced whitened. video level features simply average whitened frame level features. details please refer original youtube-m dataset paper dataset available project’s website https//research.google.com/youtubem/. trying capture non-linearity also introduced basic transformations mean mean audio included taking inverse square root input. lack time computing power experimented nonlinear features. google’s research paper mentioned added value top- features. experimented early stage extract much value result ﬁnal models. training data augmentation getting training data effective ways improve model performance. took approaches achieve goal. first decided integrate validation training data set. million videos training million validation set. integrated training data larger. training model split data fashion fold cross-validation trained model variables fold. allowed monitor on-line evaluation also ensemble predictions folds. reported next section material improvement model performance fold setup. second approach took augment training data splitting videos. rationale that since person watching minute video able tell topic seeing either halves model able same. approach frame level video yielded three sets video level data entire video ﬁrst half second half. therefore total video examples training. worth mentioning three data sets video correlated high level. still added value augmented data clearly visible. naturally would think splitting video even parts. investigated dividing parts observe additional performance gain parts. going video data noticed frame level data frame. team member reported competition organizers. believe version released videos competition ﬁnished. ﬁnal model weighted ensemble ensembles mixture neural-network experts long shortterm memory gated recurrent units section describe hides behind abbreviations provide details major video level model called monn mixture neural-network experts. mixture experts model inter-connected multi-hidden layer neural networks. model ﬁrst introduced consists parts gating experts. former ends softmax layer latter sigmoid. ﬁnal predictions products last layers gating experts. extension model tried adding layers gating expert parts. best preforming model called monnlw. hidden layers expert part network layers relatively wide sizes neurons. gate activation left sample code ﬁrst layer submitted predictions mostly three experts balance model size memory constraints. also calculated exponentially weighted moving average model variables half-life smaller number steps. prediction stage choose either snapshot version model. model training session augmented training data split folds like classical cross validation approach. model deﬁned folds saving checkpoints every steps till steps picked fold last checkpoints made predictions. calculated predictions either model variables snapshot version variables. found model consistently scored higher stayed time. example monnlw ensemble shown table. model trained nvidia geforce gpu. took around hours fold making predictions checkpoints. typical single fold single checkpoint prediction scored ensemble checkpoints fold scored ensemble folds checkpoints scored total gain close single prediction model ensemble. experimented parameter found gives slightly better results shorter steps. included another model instead means took account third powers dimension. hoped slightly less correlated model based means another fold model based means. beside models mentioned similar exercise couple models. ﬁnal ensemble monn type models consisted models listed below model’s name stands wide narrow means represents third powers represents audio rames always included training. nvidia gpu. consequently prioritized exploitation good models exploration ones. ﬁnal submission used types recurrent neural networks lstms grus. types recurrent networks used dynamic versions recurrent neural networks maximum length frames. propagated input layer network. ﬁrst layer bidirectional network consisting models running opposite direction. outputs models step concatenated feed second single direction layer. memory last state used input network experts. schematic representation networks presented fig. case lstms used unit cells bidirectional single direction rnns respectively. models trained initial learning rate batch size used default starter code values hyperparameters. total trained models scratch. trained available data. able boost score summarize made many models monn class different features slightly different structures found equal weights ensemble worked well class models. three techniques helped improve score ﬁnal submission consisted model predictions after training approximately thousand batches. additional training weights done batches half life steps. pooled layer wider helps improving score. made fold bootstrap aggregating dbof ensemble average pooling thousand units layer pooling operation. folds checkpoint ensemble yielded private leaderboard score unfortunately using predictions together rnns monns improvement score. also tried training single hybrid dbof/gru network. network concatenated aggregated values feeding ﬁnal expert classiﬁer. however able fully train network before competition ended. observed network kept good properties networks. training score quickly increased plateaued several thousand batches finally explored usage convolution alternative frame aggregating method. initial experiment combined convolutions different ﬁlter lengths strides frame skipping polling methods training score plateaued believe increasing model capacity would improve score. model ensemble major models except lstm model trained data folds. fold picked checkpoints half epoch apart fully trained regime. calculated equal weighted average probability predictions. video level model monns ensemble prediction generally higher single fold single checkpoint prediction gap. frame level models gain even higher expected ensembles model predictions correlation tend enjoy higher added value. effective model ensemble created measure prediction correlation. video viewed prediction -dimension vector. following standard approach vector analysis deﬁne correlation predictions cells. training time days epocs comparable lstm training time. unlike lstms trained grus using bootstrap aggregating. used data training leaving remaining folds fold leaving different samples. final evaluation done checkpoints training approximately thousand batches. addition presented lstms grus also trained several frame level models. although models ﬁnal ensemble hypothesize might useful properly optimized assembled. made models available part code. tried increase width lstm models feeding every second frame different layer lstm network. last memory states summed being feed classiﬁer. fold bootstrap aggregating submission checkpoints yielded private public score respectively. model gave better score starter code lstm network lower score previously described bidirectional model. next tried coupling lstm aggregation regularized monn classiﬁer instead classiﬁer. training model single hidden layer observed training substantially slower. checkpoint prediction achieved private leaderboard score signiﬁcantly lower bidirectional checkpoints model. vector probabilities. practice kept ﬁrst dimensions calculated correlations merged predictions. believe measure robust reﬂected relations among models well. considered experimented several ensemble approaches including kelly strategy mean-variance type optimization. tight computing resources took practical approach discretionarily determined weights component models based single model correlation matrix. ﬁnal prediction weight summation three model families monns lstms grus. inidivual components’ scores correlation matrix shown table. table. weights monns lstms grus respectively. best score private leaderboard public leaderboard. ensemble gained best individual component model. baseline models provided organizers much ever seen kaggle. included basic implementations logistic regression mixture experts long short term memory deep frames many parameters pick tune. code well structured experimentation. section brieﬂy describe several ideas tried state worked not. training video level models helpful techniques introduced run-time validation. every steps evaluation currently trained model holdout sample. beginning validation sample prepared organizers included training dataset randomly selected holdout subset. allowed clearly in-sample out-of-sample performance training allowed stop training entered over-ﬁtting regime. monn models found best out-of-sample performance achieved epochs augmented data set. dropout ﬁrst novelty code introduced dropout layers originally described ides behind randomly drop neurons training phase prevent over-ﬁtting inference them. introducing dropout extends learning time signiﬁcantly adds couple parameters train. data mixed performance dropout layers. ﬁnal models dropout. truncated labels vocabulary labels consisted expressions. really popular like games vehicle video game really rare russian pyramid kids decided explore models would work smaller vocabulary i.e. excluding bottom labels. hoped focusing small subset labels could avoid variances introduced less popular labels. best single model prediction ﬁtted ﬁrst labels achieved score public leaderboard without ensemble ema. although correlation truncated model prediction regular predictions truncation predictions value ensemble lower scores. ﬁnal models. exponential moving average video level frame level models calculated exponential moving average model variables. prediction phase choose either snapshot variable values perform inference. found that single checkpoint using able increase monn model score lstm model however ensembles based predictions improved monn family. think indicates variance reductions model ensemble overlapping components. still concretely helped improve overall model performance. batch normalization global normalization training video level models experimented batch normalization global normalization found models performed better without normalization. batch normalization expected make training converge sooner however time introduces variation values observation depend observations happened batch. observed data highly homogeneous decided calculate global moments feature dimension based train data. applied global normalization using calculated train data moments. model converged fast normalization case reached slightly higher validation gap. later found models performed even better normalization applied. believe relative value among different dimensions data carried information. reason come data prepared. process naturally lined components decreasing variance relative variance carried information. normalization step would remove information. although google generous give google cloud credits competition’s participants enough test couple models. work still done locally. challenges feed data fast possible keep fully utilized. ways increase data compression. barely utilized models used decompress data without performance hits. also compressed ﬁles smaller using result faster reading speeds result obtain close full utilization whole learning process. discussed previous section model trained folds data sub-sample. early data analysis stage came conclusion data well shufﬂed highly homogeneous. therefore fold simply selected every ﬁfth validation used four training. sub-sampling data folds introduced randomization trained models able achieve higher model score averaging folds checkpoints. boosting technique widely used statistical learning. competition designed implemented simple boosting network. design follows. ﬁrst layer neural network model monnl logisticmodel starter code. second neural network model built train errors between ﬁrst layer model’s prediction true labels. call second layer model boosting model. since errors base model range used tanh activation function boosting model used loss function instead cross-entropy loss function. hoped boosting model value general. however practically boostging model helped base model weaker model didn’t clear added value base model large. experiments indicated base model digest information features boosting help. practical case feed complimentary features boost model base model focus major features. report described team’s models training techniques solving youtube competition. found video level frame level models achieve level ensemble beyond found models larger sizes performed better. video level models size wider models seem perform better deeper models. indicate importance model memory. think experiment data augmentation sub-sampling online validation helped achieve better performance. boosting model idea worth discussion. authors would like thank computational biophysics group university pompeu fabra letting computational resources. would also like acknowledge jose jimenez valuable discussion feedback.", "year": 2017}