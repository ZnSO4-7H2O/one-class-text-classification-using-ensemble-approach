{"title": "Counting Markov Blanket Structures", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Learning Markov blanket (MB) structures has proven useful in performing feature selection, learning Bayesian networks (BNs), and discovering causal relationships. We present a formula for efficiently determining the number of MB structures given a target variable and a set of other variables. As expected, the number of MB structures grows exponentially. However, we show quantitatively that there are many fewer MB structures that contain the target variable than there are BN structures that contain it. In particular, the ratio of BN structures to MB structures appears to increase exponentially in the number of variables.", "text": "learning markov blanket structures proven useful performing feature selection learning bayesian networks discovering causal relationships. present formula efficiently determining number structures given target variable variables. expected number structures grows exponentially. however show quantitatively many fewer structures contain target variable structures contain particular ratio structures structures appears increase exponentially number variables. important task machine learning data mining characterize target variable influenced variables domain. example goal classification regression algorithm learn target variable best predicted variables. approach characterizing influence target variable identify subset variables shields variable influence variables domain. subset variables called markov blanket target variable. introduced pearl term refers subset variables shield target variable influence variables domain. minimal markov blanket markov boundary minimal subset variables shield target variable influence variables domain many authors refer minimal markov blanket markov blanket follow convention. notion identification several uses machine learning data mining. identification variable useful feature subset selection problem feature selection useful removing irrelevant redundant variables improving accuracy classifiers identification used guiding learning graphical structure bayesian network identifying also useful discovery causal structures goal discover direct causes direct effects common causes variable interest several methods learning data described literature target variable extracted learned methods methods learn target variable efficient. general motivation searching space smaller space bns. given domain variables quantify size search space compare size search space. derive formula efficiently determining number structures target variable given variables also compute ratio structures structures given number variables. remainder paper organized follows. review briefly sections section derive formula counting mbs. section compare number structures structures section provide summary results. bayesian network probabilistic model combines graphical representation quantitative information represent joint probability distribution random variables. specifically representing random variables domain consists pair first component represents structure directed acyclic graph contains node every variable pair nodes corresponding variables directly probabilistically dependent. conversely absence pair nodes denotes probabilistic independence corresponding variables. variable represented corresponding node labeled graph figure structure domain variables. includes nodes within circled region namely parents children spouses example structure demonstrating various node types. target node parent node child node spousal node node. note nodes part structure arcs allowed parents parent spouse formula efficiently determining number structures first developed robinson independently stanley number structures constructed variables given following recurrence formula number dags constructed given nodes time complexity computing equation number variables. equation seen computed four terms first term takes time second term gives number ways choose nodes nodes takes paper terms node variable interchangeably. second component represents parameterization probability distribution space possible instantiations local probabilistic models encode quantitatively nature dependence node parents. node local probability distribution defined node state parents. local probability distributions associated nodes comprises complete parameterization note phrase structure refers graphical structure term refers structure corresponding parameters terminology kinship used denote various relationships among nodes kinship relations defined along direction arcs. predecessors node immediate remote called ancestors particular immediate predecessors called parents similar fashion successors immediate remote called descendants particular immediate successors called children node termed spouse parent child nodes consisting node parents called family example structure given figure time third term takes time fourth term retrieved time cache. analysis assumes operations done time probably reasonable assumption small enough operations cause arithmetic overflow underflow. gets large special routines needed handle operations increase time complexity. variable denoted defines variables conditioned conditionally independent variables outside minimal minimal conditioned conditionally independent variables outside mentioned introduction shall refer minimal analogous structure refers graphical structure refers structure corresponding parameters. structure consists parents children childrenâ€™s parents illustrated figure different entail factorization conditional distribution belong markov equivalence class. define structure specifically respect structure nodes categorized five groups target node parent nodes target child nodes target spousal nodes parent nodes children nodes part node consideration called target node. parent node outgoing target node additional outgoing arcs child nodes. child node incoming target node additional incoming arcs parent nodes spousal nodes child nodes outgoing arcs child nodes. spousal node outgoing arcs child nodes neither incoming target node outgoing node considered potential spousal node explain below. example demonstrating various types nodes structure given figure mentioned earlier structure disallow arcs parent nodes arcs parent nodes spousal nodes arcs child nodes nodes. specified number nodes. first term gives number ways partitioned parent nodes child nodes spousal nodes; term sometimes called multiplicity. second term gives number distinct structures differ presence absence arcs parent nodes child nodes. parent node none child nodes total distinct structures. parent nodes number distinct structures differ presence absence arcs parent nodes child nodes third term gives number distinct structures differ presence absence arcs spousal nodes child nodes. derivation similar derivation previous term. spousal node none child nodes total distinct structures. spousal nodes number distinct structures differ presence absence arcs spousal nodes child nodes fourth last term gives number dags constructed child nodes. summation carried possible values nso; selection particular values determines value hence explicit summation required values note number parent nodes number child nodes number derive formula counting number distinct structures respect target variable. number possible structures domain variables given following equation table number structures structures function number nodes number structures respect single target node count structures nodes. last column gives ratio types structures. exponential ioannis constantin time sample efficient discovery markov blankets direct causal relations. proceedings ninth sigkdd international conference knowledge discovery data mining washington d.c. acm. margaritis thrun bayesian network induction local neighborhoods. proceedings conference advances neural information processing systems denver press. example domain containing three variables number structures number structures given equations respectively. figure shows structures indicates structures respect domain variables. time complexity computing equation number domain variables. equation seen computed four terms first term takes time second third terms take time fourth term takes time derived previously equation table gives values ranging computed equations respectively. seen table fewer structures target variable structures number structures exponential number variables. thus generally appreciated exhaustive search space structures usually infeasible domains containing variables heuristic search appropriate. last column table gives values ratio ranging appears ratio increasing exponentially thus searching space structures likely relatively much efficient searching space structures. presented formula efficiently determining number structures without enumerating explicitly. although fewer structures structures number structures exponential number variables. however ratio structures structures appears increase exponentially number domain variables. thus searching exhaustively space structures usually infeasible searching space structures likely efficient searching space structures. thus algorithms need learn structure paper quantifies degree preferable", "year": 2014}