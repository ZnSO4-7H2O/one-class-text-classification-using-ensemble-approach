{"title": "Consistent feature attribution for tree ensembles", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "Note that a newer expanded version of this paper is now available at: arXiv:1802.03888  It is critical in many applications to understand what features are important for a model, and why individual predictions were made. For tree ensemble methods these questions are usually answered by attributing importance values to input features, either globally or for a single prediction. Here we show that current feature attribution methods are inconsistent, which means changing the model to rely more on a given feature can actually decrease the importance assigned to that feature. To address this problem we develop fast exact solutions for SHAP (SHapley Additive exPlanation) values, which were recently shown to be the unique additive feature attribution method based on conditional expectations that is both consistent and locally accurate. We integrate these improvements into the latest version of XGBoost, demonstrate the inconsistencies of current methods, and show how using SHAP values results in significantly improved supervised clustering performance. Feature importance values are a key part of understanding widely used models such as gradient boosting trees and random forests, so improvements to them have broad practical implications.", "text": "random forests importance values typically attributed input feature. importance values computed either single prediction entire dataset explain model’s overall behavior. concerningly current feature attribution methods tree ensembles inconsistent meaning assign higher importance features lower impact model’s output. inconsistency effects large number users since tree ensemble methods widely applied research industry. show connecting tree ensemble feature attribution methods recently deﬁned class additive feature attribution methods motivate shapley additive explanation values possible consistent feature attribution method desirable properties. shap values theoretically optimal challenging compute. address derive exact algorithms tree ensemble methods reduce computational complexity computing shap values exponential number trees maximum number leaves tree maximum depth tree. integrating algorithm xgboost popular tree ensemble package demonstrate performance enables predictions models thousands trees hundreds inputs explained fraction second. follows ﬁrst discuss inconsistencies current feature attribution methods implemented popular tree enemble software packages introduce shap values possible consistent attributions present tree shap high speed algorithm estimating shap values tree ensembles finally supervised clustering task compare shap values previous feature attribution methods critical many applications understand features important model individual predictions made. tree ensemble methods questions usually answered attributing importance values input features either globally single prediction. show current feature attribution methods inconsistent means changing model rely given feature actually decrease importance assigned feature. address problem develop fast exact solutions shap values recently shown unique additive feature attribution method based conditional expectations consistent locally accurate. integrate improvements latest version xgboost demonstrate inconsistencies current methods show using shap values results signiﬁcantly improved supervised clustering performance. feature importance values part understanding widely used models gradient boosting trees random forests. believe work improves state-of-the-art important ways impacts current user tree ensemble methods. understanding model made prediction important trust actionability accountability debugging many common tasks. understand predictions tree ensemble methods gradient boosting trees figure tree models meant demonstrate inconsistencies current feature attribution methods. cough feature larger impact tree assigned less importance three standard methods. output attributions explain difference expected value model output current output. gain represents change mean squared error whole dataset features used features used. calculations assume dataset perfectly matching model evenly spread among leaves. section describes standard path methods section describes shap values interpretation. tree ensemble implementations popular packages xgboost scikit-learn package allow user compute measure feature importance. values meant summarize complicated ensemble model provide insight features drive model’s prediction. unfortunately standard feature importance values provided packages inconsistent means model change relies given feature importance assigned feature decreases packages feature importance values calculated entire dataset default based reduction loss contributed split tree ensemble. feature importances deﬁned gains splits given feature described friedman methods computing feature importance values single prediction less established packages recent version xgboost supports calculations natively. method used xgboost similar classical dataset level feature importance calculation instead measuring reduction loss measures change model’s output. current feature attribution methods described consider effect splits along decision path term path methods. figure shows result applying methods simple regression trees. gain calculations assume equal coverage four tree leaves perfect regression accuracy. words equal number dataset points fall leaf label points exactly equal prediction leaf. tree figure represents simple function tree figure represents function additional increase predicted value cough yes. point figure compare feature attributions between clear cough larger impact model model highlighted tree current path methods inconsistent because allocate less importance cough even though cough larger impact output tree output task explains change model output expected value current predicted value given fever cough. gain explains reduction mean squared error contributed feature contrast current approaches shap values consistent even order features appear tree changes. cally accurate method obeys missingness property uses conditional dependence measure missingness strong motivation shap values tree ensemble feature attribution particularly since current tree ensemble feature attribution methods already obey properties except consistency. means shap values provide strict theoretical improvement existing approaches eliminating unintuitive consistency problems shown figure focus tree models propose fast shap value estimation methods speciﬁc trees ensembles trees. start deﬁning straightforward slow algorithm section present much faster complex tree shap algorithm section ignore computational complexity compute shap values decision tree estimating using equation xs]. tree model estimated recursively using algorithm vector node values takes value internal internal nodes. vectors represent left right node indexes internal node. vector contains thresholds internal node vector indexes features used splitting internal nodes. vector represents cover node propose novel algorithm calculate values section polynomial time instead exponential time. speciﬁcally propose algorithm runs balanced trees unbalanced trees. general idea polynomial time algorithm recursively keep track proportion possible subsets leaves tree. similar running algorithm simultaneously subsets equation seem reasonable simply keep track many subsets class covers methods explain model’s output real values attributed input feature. previously described lundberg important attribute class additive feature attribution methods single unique solution class local accuracy missingthree desirable properties ness consistency local accuracy states feature attributions equal output function seeking explain. missingness states features already missing attributed importance. consistency states changing model feature larger impact model never decrease attribution assigned feature. order evaluate effect missing features model necessary deﬁne mapping maps original function input space binary pattern missing features represented given mapping evaluate calculate effect observing observing feature shap values deﬁne classic shapley values game theory attribute values feature figure shap values explain output function effects feature introduced conditional expectation. importantly non-linear functions order features introduced matters shap averages possible orderings. proofs game theory show possible consistent locally accurate approach. contrast standard path methods tree ensembles similar using single ordering deﬁned tree’s decision path. cover splitting algorithm pass branch tree. however combines subsets different sizes prevents proper weighting subsets since weights equation depend |s|. address keep track possible subset size recursion. extend method algorithm grows subsets according given fraction ones zeros unwind method reverses process. extend method used descend tree. unwind method used undo previous extensions split feature twice undo extension path inside leaf correctly compute weights feature path. algorithm path unique features split contains four attributes feature index fraction zero paths branch fraction paths branch used hold proportion sets given cardinally present. notation access members whole vector represents vector feature indexes. intriguing prediction level feature attributions term supervised clustering instead using unsupervised clustering method directly data features clustering feature attributions supervised clustering naturally handles challenging problems unsupervised clustering determining feature weightings many times want cluster data using features different units. features dollars meters unit-less scores etc. whenever dimensions single multidimensional space forces distance metric compare relative importance change different units even inputs units often features important others. supervised clustering uses feature attributions naturally convert input features values units model output. means unit change feature attributions comparable unit change feature attribution. also means ﬂuctuations feature values effect clustering ﬂuctuations impact outcome interest. compare feature attribution methods applying supervised clustering disease sub-typing area unsupervised clustering contributed important discoveries. goal disease sub-typing identify subgroups patients similar mechanisms disease consider alzheimer’s disease predicted outcome cerad cognitive score features gene expression modules representing positive feature attributions bars negative feature attributions blue bars stack visually represent model output sum. figure vertically participant. explanations participant stacked horizontally according figure shap feature attributions produce better clusters standard path attributions supervised clustering participants alzheimer’s research study. xgboost model trees depth trained gene expression module features using shrinkage factor model used predict cerad cognitive score participant. prediction explained clustered using hierarchical agglomerative clustering feature attributions push score higher blue feature attributions push score lower. clusters formed standard path explanations xgboost. clusters using tree shap xgboost implementation. figure quantitative performance measure clusterings shown figure samples placed group group predicts mean value group value groups merged one-by-one decline single group hierarchical clusterings well separate outcome value retain high longer merging process. unsupervised clustering better random supervised clustering xgboost path method signiﬁcantly better shap values signiﬁcantly better still. leaf order hierarchical clustering. groups participants similar predicted outcomes similar reasons predicted outcome together. clearer structure figure indicates shap values better feature attributions theoretically also practically. improvement clustering performance seen figure quantiﬁed examining well clustering explains variance cerad score outcome. since hierarchical clusterings encode many possible groupings plot figure change value number groups shrinks group sample single group shown classic feature attribution methods tree ensembles inconsistent meaning assign less importance feature true effect feature increases. contrast shap values shown unique consistently attribute feature importance. deriving fast algorithms shap values integrating xgboost make practical replacement previous methods. future directions include deriving fast dataset-level shap algorithms gain integrating shap value algorithms released versions common packages. celik saﬁye logsdon benjamin su-in. efﬁcient dimensionality reduction high-dimensional netinternational conference mawork estimation. chine learning chen tianqi guestrin carlos. xgboost scalable tree boosting system. proceedings sigkdd international conference knowledge discovery data mining mirra suzanne heyman mckeel sumi crain barbara brownlee vogel hughes belle berg consortium establish registry alzheimer’s disease part standardization neuropathologic assessment alzheimer’s disease. neurology pedregosa fabian varoquaux ga¨el gramfort alexandre michel vincent thirion bertrand grisel olivier blondel mathieu prettenhofer peter weiss dubourg vincent scikit-learn machine learning python. journal machine learning research", "year": 2017}