{"title": "End-to-End Multi-View Networks for Text Classification", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "We propose a multi-view network for text classification. Our method automatically creates various views of its input text, each taking the form of soft attention weights that distribute the classifier's focus among a set of base features. For a bag-of-words representation, each view focuses on a different subset of the text's words. Aggregating many such views results in a more discriminative and robust representation. Through a novel architecture that both stacks and concatenates views, we produce a network that emphasizes both depth and width, allowing training to converge quickly. Using our multi-view architecture, we establish new state-of-the-art accuracies on two benchmark tasks.", "text": "propose multi-view network text classiﬁcation. method automatically creates various views input text taking form soft attention weights distribute classiﬁer’s focus among base features. bag-of-words representation view focuses different subset text’s words. aggregating many views results discriminative robust representation. novel architecture stacks concatenates views produce network emphasizes depth width allowing training converge quickly. using multi-view architecture establish state-of-theart accuracies benchmark tasks. state-of-the-art deep neural networks leverage task-speciﬁc architectures develop hierarchical representations input layer building reﬁned abstraction layer came text classiﬁcation think single reader building increasingly reﬁned understanding content. departure philosophy propose divide-and-conquer approach team readers focus different aspects text combine representations make joint decision. precisely proposed multi-view network text classiﬁcation learns generate several views input view formed focusing different sets words view-speciﬁc attention mechanism. views arranged sequentially subsequent view build upon deviate previous views appropriate. ﬁnal representation concatenates diverse views robust noise components. furthermore different sentences look similar view different under another allowing network devote particular views distinguishing subtle differences sentences resulting discriminative representations. unlike existing multi-view neural network approaches image processing multiple views provided part input learns automatically create views input text focusing different sets words. compared deep convolutional networks text strategy emphasizes network width depth. shorter connections view loss function enable better gradient networks makes system easier train. multiple views similar spirit weak learners used ensemble methods views produce vector-valued intermediate representations instead classiﬁcation scores views trained jointly feedback ﬁnal classiﬁer. experiments benchmark data sets stanford sentiment treebank english news corpus show method achieves competitive accuracy views distinguish others better categorizing speciﬁc classes base bag-of-words feature augmented convolutional features method establishes state-of-the-art data sets. learned parameter matrices represents concatenation. ﬁrst last views formed solely however play different roles network. completely disconnected others independent attempt good feature selection intended increase view diversity conversely forms base structure similar multi-layer perceptron shortcutting deﬁned recurrence equation here concatenation previous views implements short-cutting recursive deﬁnition view implements stacking forming deep network depicted horizontal arrows figure structure makes view aware information previous allowing build upon other. note matrices view-speciﬁc grow view making overall parameter count quadratic number views. ﬁnal step transform views classiﬁcation input text. concatenating view vectors fully connected projection followed softmax function produce distribution possible classes. dropout regularization applied softmax layer mvn’s selection layer operates matrix feature vectors thus corresponded word vectors. view’s selection makes intuitive sense features correspond words easy imagine different readers text focusing different words reader arriving useful interpretation. however wealth knowledge construct powerful feature representations text used convolutional neural networks demonstrate utility architecture depicted figure first individual selection vectors created formed distinct softmax weighted word vectors input text. next selections sequentially transformed views view inﬂuencing views come finally views concatenated two-layer perceptron classiﬁcation. selection constructed focusing different subset words original text determined softmax weighted given piece text words represent bag-of-words feature matrix irh×d. matrix corresponds word represented d-dimensional vector provided learned word embedding table. selection view softmax weighted features figure present test-set accuracies obtained varying number views convolutional features. results indicate better predictive accuracy achieved increasing number views eight. eight accuracy starts drop. number views tuned application good many views required achieve optimal performance task. better understand beneﬁts method analyzed eight views constructed best model. training obtained view representation vectors training testing data independently trained simple fast stable na¨ıve bayes classiﬁer view. report class-speciﬁc f-measures views weight arbitrary feature vectors augment bag-of-words representation vectors built n-gram ﬁlters max-pooled entire text feature vector n-gram order augmented matrix rows. unlike word vectors vectors provide representations entire text. returning reader analogy could imagine correspond quick careful skims text. regardless whether feature vector built embedding table max-pooled n-gram ﬁlters always back-propagate feature construction layers become specialized task. stanford sentiment treebank contains sentences movie reviews. splits training test data predict ﬁne-grained -class sentiment categories sentences. comparison purposes following train models using phrases sentences evaluate sentences test time. word embeddings using publicly available dimensional pre-trained vectors glove learned views dimensions each requires project dimensional word vectors implemented using linear transformation whose weight matrix bias term shared across words followed tanh activation. optimization used adadelta starting learning rate mini-batch size also used dropout avoid overﬁtting. hyperparameters determined experiments measuring validation-set accuracy. test-set accuracies obtained different learning methods including current state-ofthe-art results presented table results indicate bag-of-words outperforms methods obtains lower accuracy state-of-the-art results achieved tree-lstm high-order however conneau categorized news articles news outlets web. task four classes class training documents test documents. random sample training used hyper-parameter tuning. training testing settings task exactly presented stanford sentiment treebank task section except mini-batch size reduced view dimension test errors obtained various methods presented table results show bag-of-words outperforms state-of-theart accuracy obtained non-neural n-gram tfidf approach well several deep cnns accuracy improved augmented convolutional features. presented novel multi-view neural network text classiﬁcation creates multiple views input text represented weighted base feature vectors. views work together produce discriminative feature representation text classiﬁcation. unlike many neural approaches classiﬁcation view figure ﬁgure observe different views focus different target classes. example ﬁrst views perform poorly classes achieve highest f-measures class. meanwhile non-neutral classes different view achieves highest f-measure. suggests views specialized order better separate subsets training data. provide ablation study table first construct traditional ensemble model. independently train eight models single view serve weak learners. vote equal weight ﬁnal classiﬁcation obtaining test-set accuracy next restrict views unaware other. replace equation removes horizontal links figure drops performance finally experiment variant view connected recent previous view replacing equation tanh)) leading version parameter count grows linearly number views. drops test-set performance experiments suggest enabling views build upon crucial achieving best performance. geoffrey hinton nitish srivastava alex krizhevsky ilya sutskever ruslan salakhutdinov. improving neural networks preventing co-adaptation feature detectors. corr abs/.. muslea steven minton craig knoblock. active semi-supervised learning robust multi-view learning. proceedings nineteenth international conference machine learning. icml pages richard socher alex perelygin jean jason chuang christopher manning andrew christopher potts. recursive deep models semantic compositionality sentiment treebank. emnlp hang subhransu maji evangelos kalogerakis erik learned-miller. multi-view convolutional neural networks shape recognition. proceedings ieee international conference computer vision iccv pages weiran wang raman arora karen livescu jeff bilmes. deep multi-view representation learning. international conference machine learning lille france. architecture emphasizes network width addition depth enhancing gradient training. used multi-view network architecture establish state-of-the-art results benchmark text classiﬁcation tasks. future wish better understand beneﬁts generating multiple views explore sources base features apply technique problems translation tagging.", "year": 2017}