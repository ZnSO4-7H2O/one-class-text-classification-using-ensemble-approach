{"title": "Multi-Agent Cooperation and the Emergence of (Natural) Language", "tag": ["cs.CL", "cs.CV", "cs.GT", "cs.LG", "cs.MA"], "abstract": "The current mainstream approach to train natural language systems is to expose them to large amounts of text. This passive learning is problematic if we are interested in developing interactive machines, such as conversational agents. We propose a framework for language learning that relies on multi-agent communication. We study this learning in the context of referential games. In these games, a sender and a receiver see a pair of images. The sender is told one of them is the target and is allowed to send a message from a fixed, arbitrary vocabulary to the receiver. The receiver must rely on this message to identify the target. Thus, the agents develop their own language interactively out of the need to communicate. We show that two networks with simple configurations are able to learn to coordinate in the referential game. We further explore how to make changes to the game environment to cause the \"word meanings\" induced in the game to better reflect intuitive semantic properties of the images. In addition, we present a simple strategy for grounding the agents' code into natural language. Both of these are necessary steps towards developing machines that are able to communicate with humans productively.", "text": "angeliki lazaridou∗ alexander peysakhovich marco baroni google deepmind facebook research university trento angelikigoogle.com {alexpeysmbaroni}fb.com current mainstream approach train natural language systems expose large amounts text. passive learning problematic interested developing interactive machines conversational agents. propose framework language learning relies multi-agent communication. study learning context referential games. games sender receiver pair images. sender told target allowed send message ﬁxed arbitary vocabulary receiver. receiver must rely message identify target. thus agents develop language interactively need communicate. show networks simple conﬁgurations able learn coordinate referential game. explore make changes game environment cause word meanings induced game better reﬂect intuitive semantic properties images. addition present simple strategy grounding agents’ code natural language. necessary steps towards developing machines able communicate humans productively. tried break gently learn unknown language interact native speaker asking questions holding conversation sort thing want learn aliens’ language someone talk alien. recordings alone aren’t sufﬁcient. chiang story life main aims develop agents cooperate others achieve goals coordination requires communication. coordination partners include humans obvious channel communication natural language. thus handling natural-language-based communication step toward development thrive world populated agents. given success deep learning models related domains image captioning machine translation would seem reasonable cast problem training conversational agents instance supervised learning however training canned conversations allow learners experience interactive aspects communication. supervised approaches focus structure language excellent learn general statistical associations sequences symbols. however capture functional aspects communication i.e. humans words coordinate others make things happen paper introduces ﬁrst steps research program based multi-agent coordination communication games. games place agents simple environments need develop language coordinate earn payoffs. importantly agents start blank slates playing game together develop bootstrap knowledge others leading emergence language. central problem program then following design environments foster development language portable situations communication partners start basic challenge using language order refer things context two-agent game. focus questions. first whether tabula rasa agents succeed communication. second features environment lead development codes resembling human language. assess latter question ways. first consider whether agents associate general conceptual properties broad object categories symbols learn use. second examine whether agents’ word usage partially interpretable humans online experiment. researchers proposed communication-based environments development coordination-capable work multi-agent systems focused design pre-programmed communication systems solve speciﬁc tasks related work sukhbaatar foerster show neural networks evolve communication context games without pre-coded protocol. pursue question change environment make emergent language interpretable. others propose building communicating putting humans loop beginning. approach beneﬁts faces serious scalability issues active human intervention required step. attractive component game-based paradigm humans added players need time. third branch research focuses wizard-of-oz environments agents learn play games interacting complex scripted environment approach gives designer tight control learning curriculum imposes heavy engineering burden developers. also stress importance environment focus simpler environments multiple agents force smarter bootstrapping other. leverage ideas work linguistics cognitive science game theory emergence language game variation lewis’ signaling game rich tradition linguistic cognitive studies using similar setups distinguishes literature eventually develop practical motivates focus realistic input data trying align agents’ language human intuitions. lewis’ classic games studied extensively game theory name cheap talk. games used models study evolution language theoretically experimentally major question game theory whether equilibrium actually occurs game convergence learning guaranteed equilibrium reached particularly true cheap talk games exhibit nash equilibria precise language emerges others vague language emerges others language emerges addition games language ex-ante meaning emerges context equilibrium emergent languages natural. results speak convergence question question features game cause appearance different types languages. thus results also interest game theorists. evolutionary perspective recently advocated mitigate data hunger traditional supervised approaches research conﬁrms learning bootstrapped competition agents. focus however cooperation agents foster learning reducing need annotated data. general framework includes players parametrized collection tasks/games players perform communication protocol enables players communicate other payoffs assigned players deterministic function well-deﬁned goal. paper focus particular version this referential games. games structured follows. many extensions basic referential game explored possible. images sophisticated communication protocol rotation sender receiver roles human occasionally playing roles etc. images mcrae al.’s base-level concrete concepts spanning across general categories randomly sample images concept imagenet create target/distractor pairs randomly sample concepts image concept whether ﬁrst second image serve target. apply image forward-pass pretrained convnet represent activations either softmax layer second-to-last fully connected layer agent players sender receiver simple feed-forward networks. sender experiment architectures depicted figure sender architectures take input target distractor representations always order implicitly informed image target agnostic sender generic neural network maps original image vectors onto gamespeciﬁc embedding space followed sigmoid nonlinearity. fully-connected weights applied embedding concatenation produce scores vocabulary symbols. informed sender also ﬁrst embeds images game-speciﬁc space. applies convolutions image embeddings treating different channels. informed sender uses convolutions kernel size applied dimension-by-dimension image embeddings followed sigmoid nonlinearity. resulting feature maps combined another ﬁlter produce scores vocabulary symbols. intuitively informed sender inductive bias towards combining images dimensionby-dimension whereas agnostic sender senders motivated discrete nature language enforce strong communication bottleneck discretizes communication protocol. activations layer converted gibbs distribution single symbol sampled resulting probability distribution. receiver takes input target distractor image vectors random order well symbol produced sender embeds images symbol game-speciﬁc space. computes products symbol image embeddings. ideally similarity higher image better denoted symbol. products converted gibbs distribution receiver points image sampling resulting distribution. general training details following hyperparameters without tuning embedding dimensionality number ﬁlters applied embeddings informed sender temperature gibbs distributions explore vocabulary sizes symbols. sender receiver parameters learned playing game. weights shared supervision used communication success i.e. whether receiver pointed right referent. setup naturally modeled reinforcement learning outsender follows policy receiver policy lined section loss function agents must minimize −ie˜r] reward function returning parameters updated reinforce rule apply mini-batch updates batch size total iterations test time compile games using method training games. turn main questions. ﬁrst whether agents learn successfully coordinate reasonable amount time. second whether agents’ language thought natural language i.e. symbols assigned meanings make intuitive sense terms conceptualization world. ﬁrst question whether agents converge successful communication all. agents almost perfectly coordinate rounds following training games every architecture parameter choice figure left communication success function training iterations informed senders converge faster agnostic ones. right spectrum example symbol usage matrix ﬁrst dimensions capture partial variance suggesting usage symbols informed sender synonymy. table playing referential game test results training games. used symbols column reports number distinct vocabulary symbols produced least test phase. text explanation comm success purity. purity values highly signiﬁcant compared simulated chance symbol assignment matching observed symbol usage. obschance purity column reports difference observed expected purity chance. informed sender makes symbols available vocabulary agnostic sender constantly uses compact -symbol vocabulary. suggests informed sender using varied word-like symbols however could also case informed sender vocabulary simply contains higher redundancy/synonymy. check this construct matrix rows game image pairs columns symbols entries represent often symbol used pair. decompose matrix svd. sender indeed using strategy effective symbols high synonymy expect -dimensional decomposition. figure plots normalized spectrum matrix. redundancy matrix language still requires multiple dimensions summarize turn investigating semantic properties emergent communication protocol. recall vocabulary agents arbitrary initial meaning. understand emerging semantics looking relationship symbols sets images refer figure t-sne plots object vectors color-coded majority symbols assigned informed sender. object class names shown random subset. left conﬁguration table right table objects images categorized broader categories mcrae agents converged higher level semantic meanings symbols would expect objects belonging category would activate symbols e.g. that target images depict bayonets guns sender would symbol refer them whereas cows guns share symbol. quantify this form clusters grouping objects symbols often activated target images contain them. assess quality resulting clusters measuring purity respect mcrae categories. purity standard measure cluster quality. purity clustering solution proportion category labels clusters agree respective cluster majority category. number reaches perfect clustering always compare observed purity score would obtained random permutation symbol assignments objects. table shows purity perfect signiﬁcantly chance cases. conﬁrm moreover informed sender producing symbols semantically natural agnostic one. still surprisingly purity signiﬁcantly chance even latter using symbols. qualitative evaluations case agents converge characterization objects living-vs-non-living which intriguingly recognized basic human semantic system rather using hard clusters also whether symbol usage reﬂects semantics visual space. construct vector representations object averaging representations category images data-set note layer near deep expected capture highlevel visual properties objects moreover since average across many speciﬁc images vectors capture rather general high-level properties objects. average object vectors dimensions t-sne mapping color-code majority symbol sender used images containing corresponding object. figure shows results current experiment. objects close space associated symbol however still appears quite variation. strategy remove aspects common knowledge game. common knowledge game-theoretic parlance facts everyone knows everyone knows everyone knows coordination occur basis coordination common knowledge therefore remove facts common knowledge preclude agents coordinating them. case want remove facts pertaining details input images thus forcing agents coordinate abstract properties. remove low-level common knowledge letting agents play using class-level properties objects. achieve modifying game show agents different pairs images maintaining imagenet class target distractor table reports results various conﬁgurations. agents still able coordinate. moreover observe small increase symbol usage purity expected since agents coordinate general properties object classes rather speciﬁc properties image. effect clearer figure repeat t-sne based visualization relationship emerges visual embeddings words used refer experiment. results section show communication robustly arising game change environment nudge agents develop symbol meanings closely related visual class-based semantics images. still would like agents converge language fully understandable humans ultimate goal develop conversational machines. this need ground communication. taking inspiration alphago reached master level combining interactive learning games self-play passive supervised learning large human games combine usual referential game agents interactively develop communication protocol supervised image labeling task sender must learn assign objects conventional names. sender naturally encouraged names conventional meaning discriminate target images playing game making communication transparent humans. experiment sender switches equiprobably game playing supervised image classiﬁcation task using imagenet classes. note supervised objective improving agents’ coordination performance. instead supervision provides basic grounding natural language concurrent interactive game playing teach effectively grounding communicate. informed sender image representations vocabulary size supervised training based labels subset object names data-set predicting object names sender uses usual game-embedding layer coupled softmax layer dimensionality corresponding object names. importantly game-embedding layers used object classiﬁcation reference game shared. consesupervised objective negative effect communication success agents still able reach full coordination training trials sender uses many symbols training previous experiment symbol purity dramatically increases even importantly many symbols become directly interpretable thanks direct correspondence labels. considering image pairs target gold standard label corresponds labels used supervised phase cases sender produced exactly symbol corresponding correct supervised label target image image pairs target image belongs directly supervised categories surprising sender adopted conventional supervised label signal target however interesting effect supervision improves interpretability code even agents must communicate images contain objects supervised category set. emerged follow-up experiment which training sender exposed supervised classiﬁcation task above agents played referential game different dataset images derived referitgame general format referitgame contains annotations bounding boxes real images referring expressions produced humans playing game. purposes constructed pairs randomly sampling bounding boxes target distractor. again agents converged perfect communication trials time used available symbols trial. asked whether language human-interpretable. symbol used trained sender randomly extracted image pairs sender picked symbol receiver pointed right target annotated pair word corresponding symbol supervised set. pairs included words among corresponding referring expressions referitgame. large majority cases sender faced pair containing categories used supervised phase training produce word could best indirectly refer depicted target image. tested whether code would understandable humans. essence replaced trained agent receiver human. prepared crowdsourced survey using crowdflower platform. pair human participants shown images sender-emitted word participants asked pick picture thought related word. collected ratings pair. found cases subjects able guess right image. logistic regression predicting subject image choice ground-truth target images subjects words random effects conﬁrmed highly signiﬁcant correlation true guessed images thus perfect supervised learning separate data provide grounding communication humans generalizes beyond conventional word denotations learned supervised phase. looking results qualitatively found often sender-subject communication succeeded sender established sort metonymic link words possession contents image. figure shows example sender produced dolphin refer picture showing stretch fence patch land. similar semantic shifts core characteristic natural language thus subjects were many cases able successfully play referential game sender encouraging. although language developed referential games initially limited agents humans possess sort ﬂexibility displayed last experiment noisy shared common ground might sufﬁce establish basic communication. results conﬁrmed fairly simple neural-network agents learn coordinate referential game need communicate large number real pictures. also suggest meanings agents come assign symbols setup capture general conceptual properties objects depicted image rather low-level visual properties. also showed path grounding communication natural language mixing game supervised task. future work encouraged preliminary experiments object naming want study ensure emergent communication stays close human natural language. predictive learning retained important building block intelligent agents focusing teaching structural properties language however also important learn function-driven facets language hold conversation interactive games potentially fruitful method achieve goal. andreas blume douglas dejong yong-gwan geoffrey sprinkle. experimental evidence evolution meaning messages sender-receiver games. american economic review jakob foerster yannis assael nando freitas shimon whiteson. learning communicate solve riddles deep distributed recurrent q-networks. technical report arxiv. http//arxiv.org/pdf/.v. drew fudenberg alexander peysakhovich. recency records recaps learning nonequilibrium behavior simple decision problem. proceedings ﬁfteenth conference economics computation goodfellow jean pouget-abadie mehdi mirza bing david warde-farley sherjil ozair aaron courville yoshua bengio. generative adversarial nets. advances neural information processing systems david silver huang christopher maddison arthur guez laurent sifre george driessche julian schrittwieser ioannis antonoglou veda panneershelvam marc lanctot sander dieleman dominik grewe john nham kalchbrenner ilya sutskever timothy lillicrap madeleine leach koray kavukcuoglu thore graepel demis hassabis. mastering game deep neural networks tree search. nature kelvin jimmy ryan kiros kyunghyun aaron courville ruslan salakhudinov rich zemel yoshua bengio. show attend tell neural image caption generation visual attention. proceedings icml lille france ying zhao george karypis. criterion functions document clustering experiments analysis. technical report university minnesota department computer science", "year": 2016}