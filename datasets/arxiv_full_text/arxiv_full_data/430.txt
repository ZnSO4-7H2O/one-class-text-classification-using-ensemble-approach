{"title": "Physics-guided Neural Networks (PGNN): An Application in Lake  Temperature Modeling", "tag": ["cs.LG", "cs.AI", "cs.CV", "physics.data-an", "stat.ML"], "abstract": "This paper introduces a novel framework for combining scientific knowledge of physics-based models with neural networks to advance scientific discovery. This framework, termed as physics-guided neural network (PGNN), leverages the output of physics-based model simulations along with observational features to generate predictions using a neural network architecture. Further, this paper presents a novel framework for using physics-based loss functions in the learning objective of neural networks, to ensure that the model predictions not only show lower errors on the training set but are also scientifically consistent with the known physics on the unlabeled set. We illustrate the effectiveness of PGNN for the problem of lake temperature modeling, where physical relationships between the temperature, density, and depth of water are used to design a physics-based loss function. By using scientific knowledge to guide the construction and learning of neural networks, we are able to show that the proposed framework ensures better generalizability as well as scientific consistency of results.", "text": "figure schematic representation physics-guided neural networks context knowledge discovery approaches either physics data. x-axis measures data -axis measures scientiﬁc knowledge. sole dependence available labeled data often limited number scientiﬁc problems. particular black-box data science model supervised learning problem good representative quality labeled data with. size training test sets small easy learn spurious relationships look deceptively good training test sets generalize well outside available labeled data. serious concern black-box applications data science models lack scientiﬁc consistency predictions respect known laws physics. hence even black-box model achieves somewhat accurate performance lacks ability adhere mechanistic understandings underlying physical processes cannot used basis subsequent scientiﬁc developments. spectrum physics-based models founded core scientiﬁc principles strive advance understanding physical world learning explainable relationships inpaper introduces novel framework combining scientiﬁc knowledge physics-based models neural networks advance scientiﬁc discovery. framework termed physics-guided neural network leverages output physics-based model simulations along observational features generate predictions using neural network architecture. further paper presents novel framework using physics-based loss functions learning objective neural networks ensure model predictions show lower errors training also scientiﬁcally consistent known physics unlabeled set. illustrate eﬀectiveness pgnn problem lake temperature modeling physical relationships temperature density depth water used design physicsbased loss function. using scientiﬁc knowledge guide construction learning neural networks able show proposed framework ensures better generalizability well scientiﬁc consistency results. data science become indispensable tool knowledge discovery data volume data continues explode practically every research domain. recent advances data science deep learning immensely successful transforming state-of-the-art number commercial industrial applications natural language translation image classiﬁcation using billions even trillions data samples. light advancements growing anticipation scientiﬁc community unlock power data science methods accelerating scientiﬁc discovery however major limitation using black-box data science models agnostic underlying scientiﬁc principles driving real-world phenomena output variables. models cornerstone knowledge discovery wide range scientiﬁc engineering disciplines. basic forms physical knowledge generally available physics-based rules equations dictate relationships physical variables form numerical models complex physical systems e.g. simulations dynamical systems heavily used computational chemistry ﬂuid dynamics climate science particle physics. models signiﬁcantly advanced understanding physical universe limited ability extract knowledge directly data mostly reliant available physics. example many physics-based models parameterized forms approximations representing complex physical processes either fully understood cannot solved using computationally tractable methods. calibrating parameters physics-based models challenging task combinatorial nature search space. particular result learning over-complex models lead incorrect insights even appear interpretable ﬁrst glance. example challenges modeling hydrological processes using state-of-theart physics-based models subject series debate papers water resources research dichotomy physics-based models black-box neural network models schematically depicted figure occupy extreme ends knowledge discovery either relying data scientiﬁc knowledge paper introduce novel framework knowledge discovery scientiﬁc problems combines power neural networks physicsbased models termed physics-guided neural networks primary contributions work. first present approach create hybrid combinations physics-based models neural network architectures make full physics data. second present novel framework training neural network architectures using knowledge contained physics-based equations ensure learning physically consistent solutions. demonstrate framework pgnn consider illustrative problem modeling temperature water lake varying depths times using input drivers well physics-based model simulations. problem exploit physical relationship temperature density depth water form physics-based loss function. section presents generic framework physicsguided neural networks applied domain availability scientiﬁc knowledge. section presents speciﬁc pgnn formulation illustrative problem lake temperature modeling. section describes evaluation procedure presents experimental results section provides concluding remarks. section describe generic framework physics-guided neural networks involves steps creating hybrid combinations physics-based models neural networks termed hybrid-physics-data models using scientiﬁc knowledge physics-based loss functions learning objective neural networks described following. constructing hybrid-physics-data models consider predictive learning problem given input drivers physically related target variable interest standard approach train data science model e.g. neuulate value target variable given physical relationships input drivers. analogous process training physics-based models often require calibrating model parameters using observational data—a process time-consuming label-expensive. furthermore provide incomplete representation target variable simpliﬁed missing physics thus resulting model discrepancies w.r.t. observations. hence basic goal modeling combine overcome complementary deﬁciencies leverage information physics data. schematically illustrated figure setup notice physics-based model accurate perfectly matches observations model learn predict however systematic discrepancies learn complement extracting complex features space input drivers thus reducing knowledge gaps. using physics-based loss functions standard approach training model described figure minimize empirical loss model predictions training maintaining model complexity follows measures complexity model trade-oﬀ hyper-parameter. however eﬀectiveness training procedure limited size labeled training often small many scientiﬁc problems. particular guarantee model trained minimizing equation produce results consistent knowledge physics. hence introduce physics-based loss functions guide learning data science models physically consistent solutions follows. equations either involve algebraic manipulations partial diﬀerentials measure physics-based equations violated model predictions evaluate following physics-based loss function relu denotes rectiﬁed linear unit function. since loss.p require actual observations target variable evaluated even unlabeled data instances contrast traditional loss functions. complete learning objective pgnn involving loss.p stated hyper-parameter decides relative importance minimizing physical inconsistency compared empirical loss model complexity. since known laws physics assumed hold equally well unseen data instance ensuring physical consistency model outputs learning objective pgnn help achieving better generalization performance even training data small fully representative. additionally output pgnn model also interpreted domain expert ingested scientiﬁc workﬂows thus leading scientiﬁc advancements. several optimization algorithms used minimizing equation e.g. stochastic gradient descent algorithm variants found great success training deep neural networks. particular gradients loss.p w.r.t model parameters easily computed using automatic diﬀerentiation procedures available standard deep learning packages. makes neural networks particularly suited choice incorporating physicsbased loss functions learning objective data science models. section describe pgnn formulation illustrative problem modeling temperature water lakes. following ﬁrst provide background information motivating problem lake temperature modeling describe pgnn approach. background lake temperature modeling temperature water lake known ecological master factor controls growth survival reproduction warming water temperatures increase occurrence aquatic invasive species displace native aquatic organisms result harmful algal blooms understanding temobservations. step custom-calibrating laborcomputation-intensive tradeoﬀ increasing accuracy model expanding feasability study large number lakes. proposed pgnn formulation consider physical variables governing dynamics lake temperature every depth time-step input drivers includes meteorological recordings surface water amount solar radiation diﬀerent wavelengths wind speed temperature well value depth year. construct model type shown figure simulations lake temperature along input drivers every depth time-step obtain augmented features adopt basic multi-layer perceptron architecture regress temperature given depth time using fully-connected network hidden layers amounts following modeling equations relating input features target prediction represents weight bias parameters across hidden output layers activation function used hidden layers. mean squared error choice loss function norms network weights regularization terms equation follows incorporate knowledge physics loss function training neural networks employ physical relationship temperature density depth water physics-based equation following introduce components physical relationship describe approach using ensure learning physically consistent results. perature change resulting biotic winners losers timely science also directly applied inform priority action natural resources. accurate water temperatures critical understanding contemporary change predicting future thermal economically valuable ﬁsh. since observational data water temperature broad spatial scales incomplete high-quality temperature modeling necessary. particular interest problem modeling temperature water given depth certain time problem referred d-modeling temperature number physics-based models developed studying lake temperature e.g. state-of-the-art general lake model model captures variety physical processes governing dynamics temperature lake e.g. heating water surface incoming shortwave radiation attenuation radiation beneath surface mixing layers varying energies diﬀerent depths dissipation heat surface lake evaporation longwave radiation shown pictorially figure preferred choice physics-based model lake temperature modeling. number parameters needs custom-calibrated lake training data available. basic idea behind calibration steps model possible combination parameter values select maximum agreement ensure physics-based equation upheld temperature predictions physics-based model construct physics-based loss function follows. consider unlabeled data input features regular grid depth values time-steps. pair consecutive depth values compute diﬀerence density estimates model time-step figure shows plot relationship temperature density water maximally dense ◦celsius given temperature predictions model depth time-step equation compute corresponding density prediction positive value viewed violation physics-based equation depth time evaluated non-zero occurrence relu). hence consider mean physical violations across every consecutive depth-pair time-step physics-based loss function using physics-based loss along empirical loss regularization terms learning objective obtain complete pgnn formulation. note particular problem lake temperature modeling even though neural network trained improve accuracy task predicting water temperatures physics-based loss function ensures temperature predictions also translate consistent relationships physical variables namely density depth thus resulting wholesome solution physical problem. data consider example lakes demonstrate eﬀectiveness pgnn framework lake temperature modeling lake mille lacs minnesota lake mendota wisconsin usa. lakes reasonably large show suﬃcient dynamics temperature proﬁles across depth time making interesting test cases analyses. observations lake temperature collated variety sources including minnesota department natural resources resource collates data federal state agencies academic monitoring campaigns citizen data temperature observations vary distribution across depths time years seasons heavily sampled time periods little observations. overall data lake mille lacs comprised temperature observations june overall data mendota comprised temperature observations april observation used meteorological drivers input variables listed table many drivers directly measured also used domain-recommended ways constructing derived features growing degree days used general lake model physics-based approach modeling lake temperature experimental studies. uses drivers listed table input parameters balances energy water budget lakes reservoirs daily sub-daily timestep. performs modeling variety lake variables using vertical lagrangian layer scheme. apart labeled data instances observations temperature also considered large unlabeled instances regular grid depth values discrete steps daily timescale april model unlabeled instances produce along input drivers every unlabeled instance. ignoring instances missing values amounted total unlabeled instances lake mille lacs unlabeled instances lake mendota. training test splits ensure test indeed independent training data sets temporally auto-correlated. particular chose center portion overall time duration testing remainder time periods ends used training. example construct training instances chose median date overall data kept adding dates sides date testing till number observations remainder time periods became less equal using protocol constructed training sets size lake mille lacs lake mendota used calibrating physics-based model lakes. used entire unlabeled instances evaluating physics-based loss function every lake. neural network models used paper implemented using keras package using tensorﬂow backend. used adadelta algorithm performing stochastic gradient descent model parameters neural network. used batch size maximum number epochs equal avoid over-ﬁtting employed early stopping procedure using training data validation value patience kept equal also performed gradient clipping avoid problem exploding gradients common regression problems standardized dimension input attributes mean standard deviation applied transformation test set. fully-connected neural network architecture comprised hidden layers hidden nodes. value hyper-parameters kept equal experiments conducted paper demonstrate special tuning hyper-parameters performed speciﬁc problem. value hyper-parameter corresponding physics-based loss function kept equal std/std factor differences scales physics-based loss function mean squared error loss function. used uniformly random initialization neural network weights hence experiments report mean standard deviation evaluation metrics every neural network method runs involving diﬀerent random initialization. value incorporating knoweldge physics data science models consider three standard non-linear regression models support vector machine radial basis function kernel least squares boosted regression trees neural network model. models trained predict temperature using input drivers pgnn without using knowledge physics order understand contribution physics-based loss function pgnn consider intermediate product framework pgnn another baseline uses hybrid-physics-data modeling setup described figure physics-based loss function learning objective hence pgnn diﬀers black-box models physics-based model simulations input attributes diﬀers pgnn purely data-driven learning objective. generalizability contribution pgnn ensure learning physically consistent model predictions. hence apart computing rmse model test also compute fraction time-steps model makes physically inconsistent predictions report fraction physical inconsistency measure. note measure require actual observations hence compute measure plentifully large unlabeled data set. results figure provides summary performance diﬀerent methods modeling lake temperature example lakes mille lacs mendota. x-axis plots represents physical inconsistency model axis represents rmse model predictions w.r.t. observations test set. also show standard deviation around evaluation metrics neural network-based methods since used random initialization network weights every runs. lake mille lacs figure test rmse physics-based model black-box data science models lsboost learn nonlinear relationships drivers temperature directly without using physics would test rmse even higher phy. inconsistency further also show high physical model predictions instead black-box model learns non-linear compositions features space input drivers achieve test rmse signiﬁcantly lower phy. provides evidence information contained driver data used eﬀectively help closing knowledge gaps phy. however improvement rmse comes cost large value physical inconsistency model predictions makes unﬁt process scientiﬁc discovery although able somewhat improve predictions target variable incurring large errors capturing physical relationships temperature variables leading non-meaningful results. output physics-based model along drivers inputs pgnn model achieve even lower value test rmse output contains vital physical information dynamics lake temperature coupled powerful data science frameworks neural networks result major improvements rmse. however results pgnn still physically inconsistent roughly time. contrast physics-based loss functions pgnn achieve rmse also substantially lower value physical inconsistency appreciate signiﬁcance drop rmse note lake-speciﬁc calibration approach produced median rmse lakes considered state-ofthe-art ﬁeld accurate well physically consistent pgnn provides opportunity produce physically meaningful analyses lake temperature dynamics used subsequent scientiﬁc studies. similar summary results also obtained figure lake mendota. test rmse physics-based model lake considerably higher mille lacs. shows complex nature temperature dynamics mendota ineﬀectively captured phy. average test rmse scores pgnn lake respectively. hand pgnn able achieve average rmse physically consistent. demonstration added value using physical consistency learning objective data science models improving generalization performance. baseline methods. figure shows variations test rmse physical inconsistency diﬀerent methods lake mille lacs vary training size figure test rmse values data science methods increase reduce training size. example test rmse black-box model seen over-shoot test rmse physics-based model training sizes smaller hand pgnn pgnn show gradual increase test rmse values reducing training size. fact pgnn seen provide smaller rmse values baseline methods especially training sizes physicsbased loss function ensures learned pgnn model consistent knowledge physics thus spurious. model thus stands better chance capturing generalizable patterns avoiding phenomena over-ﬁtting even trained limited number training samples. reduce training size results lower rmse values pgnn promising biggest gains using pgnn arise drastically lower values physical inconsistency compared data science methods shown figure even training sizes small. note results pgnn physically consistent across time-steps pgnn violate densitydepth relationship time-steps average. also almost zero value physical inconsistency since inherently designed physically consistent. analysis results provide deeper insight results produced competing methods analyze predictions lake temperature produced model follows. described previously estimate temperature converted corresponding density estimate using physical relationship between temperature density represented equation hence given time-step produce proﬁle density estimates varying values depth every model match density estimates observed temperature test instances. visualizing density proﬁles help understand variations model predictions across depth relationship test observations. examples density proﬁles diﬀerent dates lake mille lacs mendota provided figure x-axis represents estimated density -axis represents depth. density proﬁles diﬀerent algorithms lake mille lacs figure density estimates removed actual observations certain amount indicating bias physics-based model. three data science methods pgnn pgnn attempt compensate bias shifting density proﬁles closer actual observations. three depth values observations pgnn pgnn show lower discrepancy observations compared phy. fact density proﬁle pgnn matches almost perfectly observations thus demonstrating value using physics-based loss function better generalizability. however striking insight figure although density estimate pgnn reasonably close three observations density estimates soon start showing physically inconsistent patterns move lower depth beyond observations. particular density estimates pgnn start decreasing increase depth beyond violation monotonic relationship density depth illustrated figure presence physical inconsistencies reduces usefulness model’s predictions scientiﬁc analyses even model shows test rmse. contrast predictions pgnn being closer actual observations always consistent monotonic relationship density depth. figure shows another example density proﬁles diﬀerent date lake mendota. pgnn able improve upon produce density estimates closest observations. hand pgnn shows large discrepancies respect actual observations. complex nature relationships drivers temperature lake mendota diﬃcult captured withuse physical relationships learning neural networks. additionally model predictions pgnn seen violate physical relationship density depth thus reducing conﬁdence pgnn representing physically meaningful results. paper presented novel framework learning physics-guided neural networks using outputs physics-based model simulations well leveraging physics-based loss functions guide learning neural networks physically consistent solutions. anchoring neural network methods scientiﬁc knowledge able show proposed framework shows better generalizability also produces physically meaningful results comparison black-box data science methods. anticipate paper stepping stone broader theme research using physics-based learning objectives training data science models. speciﬁc formulation pgnn explored paper developed example problem modeling lake temperature similar developments could explored number scientiﬁc engineering disciplines known forms physical relationships exploited physics-based loss functions. paper paves towards learning neural networks improving ability solve given task also cognizant physical relationships model outputs tasks thus producing holistic view physical problem. number directions future research explored continuation work. first speciﬁc problem lake temperature modeling given spatial temporal nature problem domain natural extension would exploit spatial temporal dependencies test instances e.g. using recurrent neural network based architectures. second analysis physically consistent model predictions produced pgnn could used investigate modeling deﬁciencies baseline physics-based model detail. third paper presented simple constructing hybrid-physicsdata models ingested input data science model complex ways constructing models physics-based data science components tightly coupled need explored. fourth theoretical analyses studying impact introducing physics-based loss functions sample complexity convergence guarantees need investigated. fifth research direction pgnn complemented related eﬀorts producing interpretable data science results. particular physics-based equations interpreting results data science methods needs explored. finally paper explored physical relationships temperature density depth water learning multi-layer perceptrons forms physical relationships diﬀerent neural network models explored future work. particular value would develop generative models trained capture structure unlabeled data also guided physics-based models discover emulate known laws physics. paradigm pgnn eﬀectively utilized could help combining strengths physics-based data science models opening novel scientiﬁc discovery based physics data.", "year": 2017}