{"title": "DeepBrain: Functional Representation of Neural In-Situ Hybridization  Images for Gene Ontology Classification Using Deep Convolutional Autoencoders", "tag": ["cs.CV", "cs.LG", "cs.NE", "stat.ML"], "abstract": "This paper presents a novel deep learning-based method for learning a functional representation of mammalian neural images. The method uses a deep convolutional denoising autoencoder (CDAE) for generating an invariant, compact representation of in situ hybridization (ISH) images. While most existing methods for bio-imaging analysis were not developed to handle images with highly complex anatomical structures, the results presented in this paper show that functional representation extracted by CDAE can help learn features of functional gene ontology categories for their classification in a highly accurate manner. Using this CDAE representation, our method outperforms the previous state-of-the-art classification rate, by improving the average AUC from 0.92 to 0.98, i.e., achieving 75% reduction in error. The method operates on input images that were downsampled significantly with respect to the original ones to make it computationally feasible.", "text": "abstract. paper presents novel deep learning-based method learning functional representation mammalian neural images. method uses deep convolutional denoising autoencoder generating invariant compact representation situ hybridization images. existing methods bio-imaging analysis developed handle images highly complex anatomical structures results presented paper show functional representation extracted cdae help learn features functional gene ontology categories classiﬁcation highly accurate manner. using cdae representation method outperforms previous state-of-the-art classiﬁcation rate improving average i.e. achieving reduction error. method operates input images downsampled signiﬁcantly respect original ones make computationally feasible. large volume high-spatial resolution imaging datasets available days various domains calling wide range exploration methods based image processing. dataset become recently available ﬁeld neuroscience thanks allen institute brain science. dataset contains situ hybridization images mammalian brains unprecedented amounts motivated research eﬀorts powerful technique localizing speciﬁc nucleic acid targets within ﬁxed tissues cells; provides eﬀective approach obtaining temporal spatial information gene expression images reveal highly complex patterns gene expression varying multiple scales. however analytical tools discovering gene interactions data remain open challenge various reasons including diﬃculties extracting canonical representations gene activities images inferring statistically meaningful networks representations. challenge analyzing images extracting patterns relevant functionally providing meaningful representation allows neuroscientists interpret extracted patterns. initiative unify representation gene gene product attributes across species speciﬁcally aims maintaining developing controlled vocabulary gene gene product attributes annotating them. task done; fact several gene gene product functions many organisms discovered annotated gene function annotations associations gene term controlled vocabulary describing gene functional features paramount importance modern biology. used design novel biological experiments interpret results. since gene validation vitro biomolecular experiments costly lengthy deriving computational methods software predicting prioritizing biomolecular annotations would make important contribution ﬁeld words deriving eﬀective computational procedure predicts reliably likely annotations thus speed discovery gene annotations would useful past methods analyzing brain images reference brain atlas based smooth non-linear transformations types analyses insensitive local patterns like found layered structure cerebellum spatial distribution. addition machine vision approaches address challenge providing human interpretable analysis. conversely bioimaging usually goal reveal features structures hardly seen even human experts. example functions follow approach presented using histogram local scale-invariant feature transform descriptors several scales. recently many machine learning algorithms designed implemented predict annotations research examine artiﬁcial neural network many layers order achieve functional representations neural images. order compact representation images explored autoencoders convolution neural networks found convolutional autoencoder appropriate technique. subsequently representation learn features functional categories every image using simple support vector machine classiﬁer result image represented point lower-dimensional space whose axes correspond meaningful functional annotations. similar example work krizhevsky hinton used deep autoencoders create short binary codes content-based images. resulting representations deﬁne similarities images easily explained hopefully functional categories. experimental results demonstrate so-called convolutional denoising autoencoder representation outperforms previous state-of-the-art classiﬁcation rate improving average i.e. achieving reduction error. method operates input images downsampled signiﬁcantly respect original ones make computationally feasible. images mammalian brains reveal highly complex patterns gene expression varying multiple scales. study follows pursue using deep learning. authors present funcish learning method functional representations images using histogram local descriptors several scales. ﬁrst represent image collection local descriptors using sift features. next construct standard bag-of-words description image giving -dimension representation vector gene. finally given predeﬁned annotations gene train separate classiﬁer known biological category using sift bag-of-words representation input vector. speciﬁcally used l-regularized logistic regression classiﬁers training. scheme representing work presented figure applying method genomic mouse neural images available allen brain atlas found neural biological processes could inferred spatial expression patterns high accuracy. despite ignoring annotations used detect gene-gene similarities captured previous global correlation-based methods. according combining local global patterns expression important topic research e.g. sophisticated non-linear classiﬁers. pursuing classiﬁcation problem poses number challenges. first cannot deﬁne certain rules image conform order classify correct category. therefore conventional computer vision techniques capable identifying shapes objects image likely provide eﬀective solutions problem. thus deep learning achieve better results functional representations images. yields interpretable measure similarity complex images diﬃcult analyze interpret. deep learning techniques support kind problems well successful preforming feature extraction ﬁnding compact representations kind large images dealing with. traditional machine learning useful algorithms learn iteratively data second issue concerns type data possess. data consist images representing diﬀerent genes i.e. average image gene. prevents extracting features gene independently rather consider data entirety. moreover image gene merely genes every examined category genes unique category i.e. gene belong category. despite diﬃculties machine learning capable capturing underlying insights without resorting manual feature selection. makes possible automatically produce models analyze larger complex data achieving thereby accurate results. next section present convolutional autoencoder approach operates solely pixel data. supports main goal i.e. learning representations given brain images extract useful information easily building classiﬁers predictors. representations obtained vectors used solve variety problems e.g. problem classiﬁcation. reason good representation also useful input supervised predictor allows build classiﬁers biological categories known. feature extraction using convolutional autoencoders auto-encoders convolutional neural networks eﬀective supervised framework provided large training available incompatible case. small number training samples available unsupervised pre-training methods restricted boltzmann machines autoencoders proven highly eﬀective. neural network sets target values equal input using hidden layers smaller smaller size comprise bottleneck. thus trained unsupervised manner forcing network learn higher-level representation input. improved approach outperforms basic autoencoders many tasks denoising autoencoders built regular input corrupted added noise setting zero portion values. although input sample corrupted network’s objective produce original values output layer. forcing network recreate uncorrupted values results reduced network overﬁtting extraction highlevel features. autoencoder-based approach training complete decoder layer removed given input passes network yields high-level representation data. implementations representations used supervised classiﬁcation. convolutional autoencoders cnns combined produce caes. cnns weights shared among locations input preserving spatial locality reducing number parameters. practice combine cnns necessary encoder layer corresponding decoder layer. deconvolution layers essentially convolutional layers similarly standard autoencoders either learned equal original convolution layers tied weights autoencoders unpooling operation method exists unpooling locations maximum value stored layer similarly training unpooling deconvolution layers removed. point neural composed convolution pooling layers used functional representation case initialize supervised cnn. similarly input corrupted added noise called convolutional denoising autoencoders figure depicts framework capturing representation funcish. siftbased module used feature extraction. alternatively scheme learns cdae-based representation applying similar classiﬁcation method layers -fold cross-validation used training classiﬁer tuning logistic regression regularization hyperparameter. unsupervised training cdae genomic mouse neural images available allen brain atlas includes images representing genes. jpeg images average resolution fig. grayscale images indicating level gene expression siftcdaebased feature extraction compact vector representation gene vector representation feature extraction vectors trained respect categories best classiﬁcation l-regularized logistic regression classiﬁers categories classiﬁcation accuracy measured. sampled images follow input layer consists image resampled pixels corrupted setting zero values three sequential convolutional layers ﬁlters each max-pooling layer size three sequential convolutional layers ﬁlters each max-pooling layer size sequential convolutional layers ﬁlters each convolutional layer single ﬁlter unpooling layer size three sequential deconvolution layers ﬁlters each unpooling layer size three sequential deconvolution layers ﬁlters each deconvolution layer single ﬁlter output image mapped vector functional features. given predeﬁned annotations gene trained separate classiﬁer biological category. training requires careful consideration case vastly imbalanced nature training sets. network yields remarkable results every category categories reported figure illustrates scores achieved various representation vectors. average score reported average using cdae scheme i.e. reduction error. improvement achieved vector size larger -dimensional vector obtained sift. attempt maintain much possible scheme’s performance comparable vector size explored smaller vectors resampling images diﬀerent scales constructing cdaes various numbers convolution pooling layers. figure shows average categories mentioned earlier cdae structure images resampled smaller scales thus obtaining lower-dimensionality representation vectors. architecture consists following layers input layer consists values four sequential convolutional layers ﬁlters each max-pooling layer size four sequential convolutional layers ﬁlters each max-pooling layer size three sequential convolutional layers ﬁlters each convolutional layer single ﬁlter unpooling layer size four sequential deconvolution layers ﬁlters each unpooling layer size four sequential deconvolution layers ﬁlters each deconvolution layer single ﬁlter output layer uncorrupted resampled image. learning rate starts multiplied epoch denoising eﬀect obtained randomly removing pixels every image input layer. used measure classiﬁcation accuracy. many machine learning algorithms designed lately predict annotations. task learning functional representations mammalian neural images used deep learning techniques found convolutional denoising autoencoder eﬀective. speciﬁcally using presented scheme feature learning functional categories improved previous state-of-the-art classiﬁcation accuracy average i.e. reduction fig. results using convolutional denoising autoencoder feature extraction obtained training classiﬁer category using compact representation vector every gene; representation vector dimensionality depends method used image resampling rate; average classiﬁers trained diﬀerent representation vectors cdae diﬀerent resampling brain images. error. demonstrated reduce vector dimensionality compared sift vectors little degradation accuracy. results attest advantages deep convolutional autoencoders applied extracting meaningful information high resolution images highly complex anatomical structures. gene product functions species discovered cdaes well continue serve ﬁeld bioinformatics designing novel biological experiments. provide brief explanation choice main parameters cdae architecture. objective obtain compact feature representation -dimensional vector used funcish. since used representation along grid capture twodimensional structure input i.e. image dimensions determined according intended representation vector maintaining aspect ratio original input image. thus picked -dimensional feature vector inate feature redundancy array convolution layers purpose detecting locally connected features previous layer. number convolution layers determined experimenting several diﬀerent layers gave similar results. choosing layers provided best result. network parameters learned contribute much feature extraction improvement results. using learning rate decay training large networks proven helpful network’s convergence. speciﬁcally combination learning rate parameter learning rate decay resulted optimal change parameter value. case small changes parameters result signiﬁcant changes results.", "year": 2017}