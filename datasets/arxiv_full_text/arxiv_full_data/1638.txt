{"title": "Analogical Inference for Multi-Relational Embeddings", "tag": ["cs.LG", "cs.AI", "cs.CL"], "abstract": "Large-scale multi-relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs. An effective and scalable solution for this problem is crucial for the true success of knowledge-based inference in a broad range of applications. This paper proposes a novel framework for optimizing the latent representations with respect to the \\textit{analogical} properties of the embedded entities and relations. By formulating the learning objective in a differentiable fashion, our model enjoys both theoretical power and computational scalability, and significantly outperformed a large number of representative baseline methods on benchmark datasets. Furthermore, the model offers an elegant unification of several well-known methods in multi-relational embedding, which can be proven to be special instantiations of our framework.", "text": "figure commutative diagram analogy solar system rutherford-bohr model viewing atom system miniature solar system able complete missing facts latter mirroring facts former. analogy built upon three basic analogical structures planets nucleus electrons mass nucleus charge planets mass eletrons charge. world knowledge graph extremely large highly incomplete nature observed triplets incomplete graph induce unobserved triples graph presents tough challenge machine learning research. various statistical relational learning methods proposed task among vector-space embedding models particular advantageous performance scalability idea approaches dimensionality reduced representations entities relations hence force models generalize course compression. representative models kind include tensor factorization neural tensor networks translationbased models bilinear models variants pathwise methods embeddings based holographic representations product graphs utilizes additional site information predictions unseen edges semi-supervised manner large-scale multi-relational embedding refers task learning latent representations entities relations large knowledge graphs. effective scalable solution problem crucial true success knowledgebased inference broad range applications. paper proposes novel framework optimizing latent representations respect analogical properties embedded entities relations. formulating learning objective differentiable fashion model enjoys theoretical power computational scalability signiﬁcantly outperformed large number representative baseline methods benchmark datasets. furthermore model offers elegant uniﬁcation several well-known methods multi-relational embedding proven special instantiations framework. multi-relational embedding knowledge graph embedding task ﬁnding latent representations entities relations better inference knowledge graphs. problem become increasingly important recent machine learning broad range important applications large-scale knowledge bases freebase dbpedia google’s knowledge graph including question-answering information retrieval natural language processing knowledge base typically stores factual information subject-relation-object triplets. collection triplets forms directed graph whose nodes entities whose edges relations among entities. reallearning embeddings entities relations viewed knowledge induction process induced latent representations used make inference triplets seen before. despite substantial efforts great successes research multi-relational embedding important aspect missing i.e. study solutions problem analogical inference point view mean rigorously deﬁne desirable analogical properties multi-relational embedding entities relations provide algorithmic solution optimizing embeddings w.r.t. analogical properties. argue analogical inference particularly desirable knowledge base completion since instance system analogous system unobserved triples could inferred mirroring counterparts figure uses example illustrate intuition system corresponds solar system three concepts system corresponds atom system another three concepts. analogy exists systems miniature result knowing entities related system allows make inference entities related system analogy. although analogical reasoning active research topic classic early computational models mainly focused non-differentiable rulebased reasoning hardly scale large freebase google’s knowledge graph. leverage intuition analogical reasoning statistical inference automated embedding large knowledge graphs studied knowledge. worth mentioning analogical structures observed output several word/entity embedding models however observations stopped merely empirical observations. mathematically formulate desirable analogical structures leverage objective functions improve multi-relational embedding? case develop algorithms tractable inference embedding large knowledge graphs? questions present fundamental challenge addressed existing work answering questions main contributions paper. name open challenge analogical inference problem distinction rule-based analogical reasoning classic algorithmic solution conducting analogical inference differentiable manner whose implementation scalable fastest known relational embedding algorithms; theoretical insights framework provides uniﬁed view several representative methods special cases generalization cases lead advantageous performance method empirically observed. rest paper organized follows introduces related background multi-relational embedding formulated linear maps. describes optimization framework desirable analogical structures rigorously deﬁned commutative property linear maps. offers efﬁcient algorithm scalable inference exploiting special structures commutative linear maps shows framework subsumes several representative approaches principled reports experimental results followed concluding remarks related background notations space entities relations. knowledge base collection triplets stand subject object relation respectively. denote r|e|×m look-up table vector embedding entity denote tensor r|r|×m×m another look-up table rm×m matrix embedding relation learned formulate relation linear that given transforms subject original position vector space somewhere near object words expect latent representations valid satisfy holyoak hofstadter provide mathematical formulation analogical structures interest multi-relational embedding latent semantic space support algorithmic inference embeddings entities relations knowledge graph. multi-relational embeddings members modeled linear maps case. relational maps visualized using commutative diagram category theory shown figure node denotes entity edge denotes linear transforms entity other. also refer diagram parallelogram highlight particular algebraic structure. parallelogram figure represents basic analogical structure could informative inference unknown facts sense analogies would help inference unobserved facts notice entities form analogical structure example parallelogram structure fully determined symmetry. means know induce remaining triplets words understanding relation king helps unknown relation woman queen. contrast previous models relations modeled additive translating operators namely multiplicative formulation offers natural analogy ﬁrst-order logic relation treated predicate operator input arguments clearly linear transformation deﬁned matrix a.k.a. linear richer operator additive transformation deﬁned vector. multiplicative models also found substantially outperform additive models empirically instead allowing arbitrary linear maps used representing relations particular family matrices studied well-behaved linear maps. family named normal matrices. deﬁnition real matrix normal normal matrices nice theoretical properties often desirable form relational modeling e.g. unitarily diagonalizable hence conveniently analyzed spectral theorem representative members normal family include circulant matrices implicitly used recent work holographic representations matrices usually related learning latent representations fourier domain analogical structures limited parallelograms course though parallelograms often serve building blocks complex analogical structures. example figure show compound analogical structure form triangular prism mirroring correspondent entities/relations atom system solar system. formally deﬁne desirable analogical structures computationally tractable objective optimization solving problem introduce next. although tempting explore potentially interesting parallelograms modeling analogical structure computationally intractable examine entire powerset entities candidate space analogical structures. reasonable strategy identify desirable properties analogical structures want model properties constraints reducing candidate space. desirable property linear maps want directed paths starting node node form compositional equivalence. denoting composition operator relations parallelogram figure contains equivalent compositions means connected either path. call commutativity property linear maps necessary condition forming commutative parallelograms therefore corresponding analogical structures. another example given figure traverse charge along multiple alternative paths length three implying commutativity relations surrounded made scale down. require commutative constraint satisﬁed pair relations simultaneously present commutative parallelogram certain subsets entities. case relations form commuting family. worth mentioning closed matrix multiplication. result composition rule always yield legal relation—wr◦r longer normal matrix. however commuting family indeed closed multiplication. explains necessity commuting family relations alternative perspective. generic goal multi-relational embedding entity relation representations positive triples labeled receive higher score negative triples labeled formulated wrvo score function based embeddings loss function data distribution constructed based training impose analogical structures among representations addition require linear maps associated relations form commuting family normal matrices. gives objective function analogy esroy∼d constraints corresponding normality commutativity requirements respectively. constrained optimization appear computationally expensive ﬁrst glance. however recast simple lightweight problem update carried efﬁciently time. constrained optimization computationally challenging large number model parameters tensor matrix normality constraints quadratic number pairwise commutative constraints interestingly exploiting special properties commuting normal matrices show corollary analogy alternatively solved another formulation substantially lower complexity. ﬁndings based following lemma theorem lemma real normal matrix exists real orthogonal matrix block-diagonal matrix diagonal block either real scalar lemma suggests real normal matrix blockdiagonalized almost-diagonal canonical form. theorem real normal matrices form commuting family namely aiaj ajai block-diagonalized real orthogonal basis theorem implies dense relational matrices {wr}r∈r mutually commutative always simultaneously block-diagonalized another sparse almost-diagonal matrices {br}r∈r. corollary given solution optimization always exists alternative embeddings φv∗w φu∗b∗ given solution constraints alternative optimization problem handled simply binding together coefﬁcients within blocks note consists free parameters allowing gradient w.r.t. given triple efﬁciently evaluated following provide uniﬁed view several embedding models showing restricted versions framework hence implicitly imposing analogical properties. explains strong empirical performance compared baselines entity analogies encouraged distmult diagonal matrices diag’s normal mutually commutative. however distmult restricted model symmetric relations only since translation-based models relations modeled translation operators embedding space including transe variants transh transr transd stranse rtranse multi-relational latent factor models including rescal based collective matrix factorization. models subsumed proposed framework including distmult based simple multiplicative interactions complex using complex coefﬁcients hole based holographic representations. models implicitly leveraging analogical structures previous analysis. hard verify circulant matrices normal commute hence entity analogies encouraged hole optimization reduces unconstrained problem equalities automatically satisﬁed wr’s circulant. next proposition reveals hole equivalent complex minor relaxation. proposition hole embeddings equivalently obtained using following score function metrics would ﬂawed negative instances created test phase ranked list contain positive instances training validation sets recommended remedy followed remove trainingvalidation-set triples ranked lists testing. ﬁlt. indicate evaluation metrics without ﬁltering respectively. ﬁrst experiments used hitsk reported methods literature. also provide additional results analogy subset representative baseline methods using hits hits enable comparison methods whose published results metrics. logistic loss analogy throughout experiments namely sigmoid activation function. empirically found simple loss function perform reasonably well compared sophisticated ranking loss functions. implementation runs analogy requires lightweight linear algebra routines. asynchronous stochastic gradient descent optimization gradients respect different mini-batches simultaneously evaluated multiple threads gradient updates shared model parameters carried without synchronization. asynchronous highly efﬁcient causes little performance drop parameters associated different mini-batches mutually disjoint high probability adapt learning rate based historical gradients using adagrad since valid triples explicitly given training invalid triples need artiﬁcially created. speciﬁcally every positive example generate three negative instances corrupting random entities/relations union positive negative instances deﬁnes data distribution updates. table hits models categories three groups baselines without modeling analogies; baselines proposed analogy implicitly explicitly enforce analogical properties induced embeddings baseline relying large external data resources addition provided training set. models unstructured rescal transh transe transr tkrl rtranse transd ctransr stranse distmult transsparse ptranse-mul ptranse-rnn ptranse-add complex hole conducted grid search hyperparameters analogy maximize ﬁltered validation enumerating combinations embedding size weight decay factor model coefﬁcients ratio negative positive samples resulting hyperparameters dataset dataset number scalars diagonal always initial learning rate datasets adjust using adagrad optimization. models trained epochs. methods literature datasets. methods scores missing slots indicated best score dataset marked bold face; differences among second third scores statistically signiﬁcant scores also bold faced. used one-sample proportion test p-value level testing statistical signiﬁcances. tables analogy performs either best best equivalent class best score case according statistical signiﬁcance test. speciﬁcally harder dataset table large number relations model outperforms baseline methods. results provide good evidence effective modeling analogical structures approach. pleased table analogy outperforms distmult complex hole metrics latter three viewed constrained versions method furthermore assertion hole special case complex justiﬁed table fact performance hole dominated complex. figure show empirical scalability analogy completes epoch seconds datasets also scales linearly size embedding problem. compared single-threaded adagrad asynchronous adagrad threads offers speedup respectively single commercial desktop. notice proportion tests apply performance scores proportions including hitsk applicable nonproportional scores mrr. hence conducted proportion tests hitsk scores. figure time epoch analogy. ﬁgure left shows time increasing embedding sizes threads; figure right shows time increasing number threads embedding size presented novel framework explicitly modeling analogical structures multi-relational embedding along differentiable objective function linear-time inference algorithm large-scale embedding knowledge graphs. proposed approach obtains state-of-the-art results popular benchmark datasets outperforming large number strong baselines cases. although focused multi-relational inference knowledge-base embedding believe analogical structures exist many machine learning problems beyond scope paper. hope work shed light broad range important problems scalable inference analogical analysis would make impact machine translation image captioning leave interesting topics future work. bollacker kurt evans colin paritosh praveen sturge taylor jamie. freebase collaboratively created graph database structuring human knowledge. proceedings sigmod international conference management data bordes antoine weston jason collobert ronan bengio yoshua. learning structured embeddings conference artiﬁcial intelliknowledge bases. gence number epfl-conf- bordes antoine glorot xavier weston jason bengio yoshua. joint learning words meaning representations open-text semantic parsing. aistats volume bordes antoine usunier nicolas garcia-duran alberto weston jason yakhnenko oksana. translating embeddings modeling multi-relational data. advances neural information processing systems chen danqi socher richard manning christopher andrew learning facts knowledge bases neural tensor networks semantic word vectors. arxiv preprint arxiv. dalton jeffrey dietz laura allan james. entity query feature expansion using knowledge base links. proceedings international sigir conference research development information retrieval ferrucci david brown eric chu-carroll jennifer james gondek david kalyanpur aditya lally adam murdock william nyberg eric prager john building watson overview deepqa project. magazine gabrilovich evgeniy markovitch shaul. wikipediabased semantic interpretation natural language processing. journal artiﬁcial intelligence research shizhu kang guoliang zhao jun. learning represent knowledge graphs gaussian embedding. proceedings international conference information knowledge management jenatton rodolphe roux nicolas bordes antoine obozinski guillaume latent factor model highly multi-relational data. advances neural information processing systems guoliang kang shizhu zhao jun. knowledge graph completion adaptive sparse proceedings thirtieth aaai transfer matrix. conference artiﬁcial intelligence february phoenix arizona usa. http//www.aaai.org/ocs/index.php/ aaai/aaai/paper/view/. nickel maximilian rosasco lorenzo poggio tomaso holographic embeddings knowledge proceedings thirtieth aaai confergraphs. ence artiﬁcial intelligence february phoenix arizona usa. http//www.aaai.org/ocs/index.php/ aaai/aaai/paper/view/. recht benjamin christopher wright stephen feng. hogwild lock-free approach parallelizing stochastic gradient descent. advances neural information processing systems socher richard chen danqi manning christopher andrew. reasoning neural tensor networks knowledge base completion. advances neural information processing systems mikolov tomas sutskever ilya chen corrado greg dean jeff. distributed representations adwords phrases compositionality. vances neural information processing systems nickel maximilian tresp volker kriegel hanspeter. three-way model collective learning multi-relational data. proceedings international conference machine learning toutanova kristina chen danqi. observed versus latent features knowledge base text inference. proceedings workshop continuous vector space models compositionality johannes riedel sebas´ bouchard guillaume. tian gaussier eric simple link prediction. complex embeddings proceedings international conference machine learning icml york city june http//jmlr.org/proceedings/ papers/v/trouillon.html. yang bishan wen-tau xiaodong jianfeng deng embedding entities relations learning inference knowledge bases. corr abs/. http//arxiv.org/ abs/.. yang yiming xin. re-examination text categorization methods. proceedings annual international sigir conference research development information retrieval", "year": 2017}