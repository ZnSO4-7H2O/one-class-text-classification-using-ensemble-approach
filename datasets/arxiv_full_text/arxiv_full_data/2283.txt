{"title": "Visual Analytics in Deep Learning: An Interrogative Survey for the Next  Frontiers", "tag": ["cs.HC", "cs.AI", "cs.LG", "stat.ML", "H.5.2; I.5.1.d; I.6.9.c; I.6.9.f; I.2.6.g"], "abstract": "Deep learning has recently seen rapid development and significant attention due to its state-of-the-art performance on previously-thought hard problems. However, because of the innate complexity and nonlinear structure of deep neural networks, the underlying decision making processes for why these models are achieving such high performance are challenging and sometimes mystifying to interpret. As deep learning spreads across domains, it is of paramount importance that we equip users of deep learning with tools for understanding when a model works correctly, when it fails, and ultimately how to improve its performance. Standardized toolkits for building neural networks have helped democratize deep learning; visual analytics systems have now been developed to support model explanation, interpretation, debugging, and improvement. We present a survey of the role of visual analytics in deep learning research, noting its short yet impactful history and summarize the state-of-the-art using a human-centered interrogative framework, focusing on the Five W's and How (Why, Who, What, How, When, and Where), to thoroughly summarize deep learning visual analytics research. We conclude by highlighting research directions and open research problems. This survey helps new researchers and practitioners in both visual analytics and deep learning to quickly learn key aspects of this young and rapidly growing body of research, whose impact spans a diverse range of domains.", "text": "abstract—deep learning recently seen rapid development signiﬁcant attention state-of-the-art performance previously-thought hard problems. however innate complexity nonlinear structure deep neural networks underlying decision making processes models achieving high performance challenging sometimes mystifying interpret. deep learning spreads across domains paramount importance equip users deep learning tools understanding model works correctly fails ultimately improve performance. standardized toolkits building neural networks helped democratize deep learning; visual analytics systems developed support model explanation interpretation debugging improvement. present survey role visual analytics deep learning research noting short impactful history summarize state-of-the-art using human-centered interrogative framework focusing five thoroughly summarize deep learning visual analytics research. conclude highlighting research directions open research problems. survey helps researchers practitioners visual analytics deep learning quickly learn aspects young rapidly growing body research whose impact spans diverse range domains. broader ﬁeld machine learning attributed study usage deep artiﬁcial neural networks learn structured representations data. first mentioned early deep learning seen dominate pervasive resurgence many research domains producing state-of-the-art results number diverse data tasks. example premiere machine learning deep learning artiﬁcial intelligence conferences seen enormous growth attendance paper submissions since early furthermore opensource toolkits programming libraries building training evaluating deep neural networks become robust easy democratizing deep learning non-experts. result barrier developing deep learning models lower ever deep learning applications becoming pervasive widespread. technological progress impressive comes unique novel challenges. example lack interpretability transparency neural networks learned representations underlying decision process important problem address solve. making sense particular model misclassiﬁes test data instances behaves poorly times challenging task model developers. similarly end-users interacting application relies deep learning make critical decisions question reliability explanation given model become bafﬂed explanation convoluted. explaining neural network decisions important numerous problems arise deep learning. example safety security compromised model trust opaque automatic decision making inherent model data bias name few. challenges often compounded massive datasets required train deep learning models. worrisome problems grow bigger ai-powered systems deployed used world. therefore general sense model understanding beneﬁcial often required address solve aforementioned problems. data visualization visual analytics excel knowledge communication insight discovery using encodings transform abstract data meaningful representations. seminal work zeiler fergus technique called deconvolutional networks enabled projection model’s learned feature space back pixel space. technique results give insight types features deep neural networks learning speciﬁc layers also acts debugging tool better improve model. work often attributed popularizing visualization within machine learning computer vision communities recent years bringing spotlight powerful tool help people understand improve deep learning models. however visualization research neural network started well handful years many different techniques introduced help interpret neural networks learning. many techniques generate static images attention maps heatmaps image classiﬁcation indicating parts image important classiﬁcation. however interaction also fig. visual overview illustration interrogative survey questions what when where relate another. question corresponds section paper indicated labelled near question title. section lists major subsections identiﬁed discussed survey. incorporated model understanding process visual analytics tools better help facilitate insight hybrid area research grown academia industry forming basis many research papers academic workshops deployed industry tools. survey summarize large number deep learning visualization works using five figure presents visual overview interrogative questions reveal organize various facets deep learning visualization research related topics. framing survey many existing papers description following example order model developers interpret representations learned deep models visualize neuron activations convolutional neural networks training phase using t-sne embeddings survey introductory text researchers practitioners wishing gain insight ﬁeld hopes better understand visualization support deep learning research applications. contributions method survey contributions present comprehensive timely survey visualization visual analytics deep learning research using human-centered interrogative framework. method enables position work respect five ﬂexibly discuss highlight existing works’ multifaceted contributions. human-centered approach using five based familiarize topics everyday settings enables newcomers quickly grasp important facets young rapidly growing body research. broad range domains survey goes beyond visualization-focused venues extending wide scope encompasses relevant works many venues artiﬁcial intelligence machine learning deep learning computer vision. highlight visual analytics integral component solving ai’s biggest modern problems neural network interpretability trust security. deep learning generally touches aspects daily lives synthesize surveyed papers highlight important research directions open problems future work. areas future research include improving technical capabilities visual analytics systems furthering interpretability conducting effective design studies evaluating usability utility systems conjecturing humans important role aipowered systems promoting proper ethical applications beneﬁt social good. survey methodology summarization process selected existing works computer science conferences journals visualization visual analytics deep learning international conference machine learning since ﬁeld growing much relevant work appeared workshops related deep learning visualization interpretation previously mentioned venues; therefore also include works survey. reference summary premiere traditional academic venues relevant workshops listed table also inspected preprints posted arxiv since deep learning spawned high-visibility community presence multiple arxiv subjects order sustain rapid progression. finally aside traditional aforementioned venues include non-academic venues gathered signiﬁcant attention distill industry research blogs research blogs inﬂuential ﬁgures ﬁeld. rapid growth deep learning research lack perfect publishing disseminating work hybrid area inclusion non-traditional sources important review highly inﬂuential impactful ﬁeld. visualization takes many forms throughout deep learning literature particularly focus information visualization visual analytics deep learning. however since research area relatively include many previous works invent static visualizations typically seen computer vision communities. select work recorded following inforicml workshop visualization deep learning icml workshop human interpretability machine learning nips workshop interpreting explaining visualizing deep learning industry involvement open-source code information used five organize historical works current state-of-the-art visualization visual analytics deep learning. related surveys larger literature visualization machine learning including human-in-the-loop interactive machine learning knowledge existing survey visualization visual analytics deep learning. regarding deep neural networks related surveys include recent book chapter discusses visualization deep neural networks related ﬁeld computer vision unpublished essay proposes preliminary taxonomy visualization techniques paper focuses describing interactive model analysis that describing high-level framework general machine learning models mention deep learning contexts hensive provide supporting information growing ﬁeld deep learning visualization. different articles mentioned above survey provides comprehensive human-centered interrogative framework describe deep learning visual analytics tools discusses rapidly growing community large presents major research trajectories synthesized existing literature. overview organization paper structured following section discusses brief history deep learning particular event drove progress researchers academia industry. there bulk paper dedicated towards survey structured around five ordered best motivate visualization visual analytics deep learning rich exciting area research. want visualize deep learning? afterwards section present research directions open problems future work gathered distilled literature survey. lastly section present ﬁnal remarks conclude survey. visual overview paper structure figure background common terminology enhance readability survey well invite researchers lacking background deep learning contribute growing ﬁeld listed sampling relevant common deep learning terminology used paper found table reader want return tables throughout paper technical terms meanings synonyms used various contexts discussion. meant introduction summarization state-of-the-art take term meanings strict mathematical theoretical deﬁnitions; exact deﬁnitions encourage reader seek outside resources speciﬁc deep learning neural network design neural networks deep learning. ﬁrst mention using artiﬁcial neurons computation proposed neurologist mathematician early simple electronic circuit presented model human brain however multiple decades over-promised unfulﬁlled results research neural computation declined. would resurgence artiﬁcial neural networks research funding would resume. computational power modern computer researchers able build deep neural networks multiple layers artiﬁcial neurons order achieve better performance thus designating area machine learning research deep learning. rise deep learning imagenet. previously popular machine learning techniques research deep learning continued forward. often attributed inﬂection point deep learning progress imagenet large scale visual recognition challenge held annual competition participants given visual recognition task build image classiﬁer scores highest accuracy learning image dataset containing different image classes competition ﬁrst submitted convolutional neural network model challenge. model showed powerful convolutional layers learn image features dropout layers better regularization model implementation computer’s graphics processing unit accelerate training process model dubbed alexnet became important milestone ﬁeld since results considerably better submission using deep neural network. type representation learning sparked international interest competition academia industry. milestone models submitted leading another signiﬁcant boost accuracy imagenet dataset benchmark. first googlenet model introduced inception modules pruned neural network total parameter count enabling faster training accurate learned features second model became community standard extracting features images uniform architecture. model’s weights made publicly available despite fact weight sizes large challenging tackle beyond imagenet. competition also year anniversary ilsvrc challenge prompted survey discussing history lessons learned submissions notably survey reports human-level accuracy imagenet dataset single percentage away scoring model googlenet however following year submission resnet introduced skip connections heavy batch normalization achieve better performance estimated human-level benchmark years nearly submission using deep neural networks progress steadily made. recently problem supervised image classiﬁcation imagenet dataset deemed solved challenge concluded pribiologically-inspired models form basis deep learning; approximate functions dependent upon large unknown amount inputs consisting layers neurons type neural network introduces shortcut connections across stacks layers enabling easier learning residual mappings instead complicated original mappings activation function input data neural network output often non-linear transformations computed neuron; enables network learn complex decision boundaries; given trained network pass data recover activations layer network obtain current mapping type neural network composed convolutional layers typically assume image data input; layers depth unlike typical layers width make ﬁlters extract spatially invariant representations type neural network often used text analysis addresses vanishing gradient problem using memory gates propagate gradients network learn long-range dependencies also seen general contexts deﬁnes success looks like learning representation i.e. measure difference neural network’s prediction ground truth method conduct unsupervised learning pitting generative network discriminative network; ﬁrst network mimicks probability distribution training dataset order fool discriminative network judging generated data instance belongs training visualize deep learning interpretability explainability abundant members community important reason visualize deep learning understand deep learning models make decisions representations learn order place trust model notion general model understanding called interpretability explainability referring machine learning models however neural networks particularly suffer problem since oftentimes real world highperformance models contain large number parameters exhibit extreme internal complexity using many non-linear transformations different stages training. many works often times motivational phrases opening peering blackbox transparency interpretable neural networks mentioned referring innate complexity neural network learned representations. discordant deﬁnitions interpretability unfortunately explainable interpretable deep learning universally formalized agreed upon deﬁnition makes classifying qualifying interpretations explanations troublesome. paper lipton titled mythos model interpretability performs survey interpretability literature revealing literature diverse motivations interpretability important occasionally discordant. despite ambiguity attempts reﬁne notion interpretability making ﬁrst step towards providing comprehensive taxonomy desiderata methods interpretability research. important point lipton makes difference interpretability explanation; explanation show predictions without elucidating mechanisms models work another paper originally presented tutorial international conference acoustics speech signal processing montavona authors propose exact deﬁnitions interpretation explanation. first interpretation mapping abstract concept domain human make sense provide examples interpretable domains images text noninterpretable domains abstract vector spaces second explanation collection features interpretable domain contributed given example produce decision example explanation heatmap highlighting pixels input image strongly support classiﬁcation decision image classiﬁcation task natural language processing explanations highlight certain phrases within text data. however previous works written members community whereas another work miller titled explanation artiﬁcial intelligence insights social sciences postulates much current research uses researchers’ intuition constitutes ‘good’ explanation claims focus explicitly explaining decisions actions human observer goal techniques succeed explanations generate structure humans accept. much miller’s work paper highlights vast valuable bodies research philosophy psychology cognitive science people deﬁne generate select evaluate present explanations argues interpretability explainability research leverage build upon history anessay offert argues make interpretability rigorous ﬁrst identify might still impaired intuitive considerations consider precisely terms multiple works bring different perspectives lipton makes keen observation research meaningful ﬁeld progress community must critically engage issue problem formulation step right direction time help solidify notions interpretation explanation rigorous widely accepted deﬁnitions. research interpretation relatively impact already seen applied deep learning contexts. number applied data science projects deep learning models include section interpretation qualitatively evaluate support model’s predictions paper’s claims overall. example approach end-to-end neural machine translation. work johnson authors present simple efﬁcient translate multiple languages using single model taking advantage multilingual data improve neural machine translation languages involved. authors visualize embedding text sequences example sentences multiple languages support hint universal interlingua representation. another work visualizes large machine learning embeddings zahavy authors analyze deep qnetworks popular reinforcement learning model understand describe policies learned dqns three different atari video games. application social good robinson demonstrates apply deep neural networks satellite imagery order perform population prediction disaggregation jointly answering questions where people live? many people live there?. general show methodology effective tool extracting information inherently unstructured remotely sensed data provide effective solutions social problems. application domains visualization deep learning interpretation successfully used. others include building trust autonomous driving vehicle models explaining decisions made medical imaging models mris brain scans order provide medical experts information making diagnoses using visual analytics explore automatically learned features street imagery order urban spaces gain perspective identity function demographics afﬂuence useful urban design planning survey mention interpretation explanation often common forms motivation deep learning visualization. later discuss different visualization techniques visual analytics systems focus neural network interpretability embeddings text quantifying interpretability many different image-based techniques stemming communities debugging improving models building machine learning models iterative design process developing deep neural networks different. mathematical foundations laid deep learning well-deﬁned traditional machine areas. example ﬁnding exact combinations model depth layer width ﬁnely tuned hyperparameters unknown nontrivial. response this many visual analytics systems proposed help model developers build debug models hope expediting iterative experimentation process ultimately improve performance oftentimes requires monitoring models training phase identifying misclassiﬁed instances testing handful well-known data instances observe performance allowing system suggest potential directions model developer explore reason wish visualize deep learning ultimately provides better tools speed model development machine learning engineers researchers experts identify problems within model quickly improve overall performance. certainly related model debugging improvement model comparison selection slightly different tasks visualization useful oftentimes model comparison describes notion choosing single model among ensemble well-performing models debugging done; models learned trained semi-successfully. therefore selecting single best-performing model requires inspecting model metrics visualizing parts model order pick highest accuracy lowest loss generalizable avoiding pitfalls memorizing training data overﬁtting. systems take high-level approach compare user-deﬁned model metrics like accuracy loss aggregate interactive charts pure performance comparison frameworks compare neural networks trained different random initializations important step model design order discover initializations effect performance also quantifying performance interpretation approaches compare models image generation techniques performing image reconstruction internal representations layer different networks order compare different network architectures similarly comparing model architectures systems solely rely data visualization representations encodings order compare models others compare different snapshots single model trains time i.e. comparing model epochs model epochs training time another important reason want visualize deep learning ensure deployed models applications making predictions inferences based true underlying signal biased towards particular decision outcome. identiﬁed major problem deep learning number researchers using visualization order understand model biased example google’s tool facets visual analytics system designed specifically preview visualize machine learning datasets training. allows inspect large datasets exploring different classes data instances order high-level imbalances class data distribution. apart data bias works begun explore mathematical algorithms biased towards particular decisions. example interactive article titled attacking discrimination smarter machine learning wattenberg explores create fair unfair threshold classiﬁers example task loan granting scenarios bank grant deny loan based single automatically computed number credit score. article aims highlight equal opportunity preserved machine learning algorithms ai-powered systems continue make important decisions finally mentioned bias data bias algorithms also knows human inherently biased. fact growing area research detecting understanding bias visual analytics affect decision making process pressing problem faced deep learning visualization work currently early work developed metrics detect types bias present user data analysis process could also applied deep learning visual analytics tools future teaching deep learning concepts shifting away experts another important reason wish visualize deep learning namely educating non-expert users general. exact deﬁnition non-experts vary source reasonable approximation would place non-experts continuum ranging general public users ai-powered system interested individuals wish learn deep learning ﬁrst time. example targets general public teachable machines web-based experiment explores teaches foundations image classiﬁer. users train three-way image classiﬁer using computer’s webcam generate training data. providing three different examples physical objects around user system performs real-time inference whichever object view webcam shows chart corresponding classiﬁcation scores. since inference computed real-time charts wiggles jumps back forth user removes object pencil view instead holds coffee mug. visualization used simple chart never exceeds three bars provides elegant introduction image classiﬁcation rich modern-day computer vision problem. examples users wish investigate deep learning ﬁrst time include tools like deep visualization toolbox also uses webcam instant feedback interacting neural network. taking instantaneous feedback step further works used direct manipulation means engage non-experts learning process. tensorflow playground robust web-based visual analytics tool exploring simple neural networks claims direct manipulation reinforces deep learning concepts importantly elicits intuition neural networks work within user. visual analytics system non-traditional mediums used teach deep learning concepts build intuition neural networks behave. longform interactive scrollytelling webpages focus particular topics display interactive visualizations short exploratory demos gaining popularity. examples include t-sne effectively wattenberg users play hundreds small datasets vary single parameters observe effect resulting embedding many chris olah’s blog posts. example similar previous t-sne work visualizing mnist olah visually shows different types embeddings produce different embedding algorithms uses deep learning visualization section describes groups people could stand beneﬁt deep learning visualization visual analytics. certainly narrow groups individuals speciﬁc uses believe people largely included following three groups model developers model users non-experts loosely organized level deep learning knowledge noted difference model developers model users described below many discussed research tools used both therefore presentation tools aimed communities thought exclusive. model developers builders ﬁrst group people deep learning visualization individuals whose primarily focused developing experimenting with deploying deep neural networks. model developers builders whether researchers engineers typically strong understanding deep learning techniques well-developed intuition surrounding model building. example intuition eclipses decisions types models perform best certain types data rather describes ﬁner level mastery models like knowing vary hyperparameters right fashion achieve better performance. individuals years experience neural network models spend much time programming languages building large-scale models training gpu-supported computers solve real-world problems therefore tooling research users much technical focused e.g. exposing many hyperparameters detailed model control. existing deep learning visual analytics tools published handful tackle problem developing tools model developers seen widespread adoption. arguably well-known system tensorboard google’s included open-source visualization platform data graph library tensorflow. tensorboard includes number built-in components help model developers understand debug optimize tensorflow programs. includes real-time plotting quantitative model metrics training instance level predictions visualization computational graph. computational graph component published separately wongsuphasawat works applying series graph transformations enable standard layout techniques produce legible interactive diagrams tensorflow models. number tools aimed model developers exist deepeyes assist number model building tasks identifying stable layers during training process identifying unnecessary layers degenerated ﬁlters contribute model’s decisions pruned removed identifying patterns undetected network case indicate ﬁlters layers needed. another tool alsallakh allows model builder accelerate model convergence alleviate overﬁtting revealing class confusion patterns follow hierarchical structure classes relation cnn-internal data. research developed metrics beyond numbers like loss accuracy visualize training inspect evaluate networks tools also address inherent iterative nature training neural networks. example ml-o-scope focuses capabilities around time-lapse engine inspect model’s training dynamics better tune hyperparameters work chae visualizes classiﬁcation results training suggests potential directions improve performance embedded model building pipeline. lastly visual analytics tools beginning built expert users wish challenging models work with. example dgmtracker visual analytics tool built help users understand diagnose training process deep generative models powerful networks perform unsupervised semi-supervised learning primary focus discover hidden structure data without resorting external labels. model users second group people beneﬁt deep learning visualization model users. users technical background potentially code neural network novices. common tasks include training smaller-scale models downloading pre-trained model weights online starting point. although discussed much detail survey group users also include machine learning artists models enable showcase forms artistic expression. example visual analytics system model users activis visual analytics system interpreting results neural networks using novel visual representation uniﬁes instancesubset-level inspections neuron activations. model users ﬂexibly specify subsets using input features labels intermediate outcomes machine learning pipeline. activis built engineers data scientists facebook explore interpret deep learning models results deployed facebook’s internal system. lstmvis visual analysis tool recurrent neural networks focus understanding hidden state dynamics sequence modeling. tool allows model users perform hypothesis testing selecting input range focus local state changes match states changes similar patterns large data ﬁnally align results structural annotations. lstmvis paper describes three types users namely architects wish develop deep learning methodologies trainers wish apply lstms task domain experts users pretrained models various tasks. moving away sequential data e.g. text focusing images cnnvis helps model users reﬁne neural networks clustering reordering important visualized network parameters order address scalability largescale networks. lastly embedding projector speciﬁcally deep learning exclusive visual analytics tool support interactive visualization interpretation large-scale embeddings. paper presents three important tasks model users often perform using embeddings output neural network models. tasks include exploring local neighborhoods viewing global geometry clusters ﬁnding meaningful directions within embedding. third group people visualization could non-experts deep learning. individuals typically prior knowledge deep learning technical background. much research targeted group educational purposes trying explain neural network works high-level sometimes never revealing deep learning present. group also includes people simply ai-powered machines consumer applications. ﬁrst paper informally called deep visualization toolbox tool visualizes activations produced layer trained processes image video. authors recommend using live webcam input claiming looking live video activations change response user input helps building valuable intuitions cnns work. another system tensorflow playground sturdy web-browser based interactive visualization simple dense network. tensorflow playground supports direction manipulation experimentation rather coding enabling users quickly build intuition neural network models. system used teach students foundational neural network properties using living lessons also makes straightforward create dynamic interactive educational experience. similarly educational-focused shapeshop another web-browser based system allows users explore understand relationship between input data network’s learned representations. shapeshop heavily utilizes algorithmic image generation technique called class activation maximization visualize speciﬁc classes image classiﬁer. system allows users interactively select classes collection simple shapes select hyperparameters train model view generated visualizations real-time. tools built non-experts particularly educational focus becoming popular web. number web-based javascript frameworks training neural networks inference developed; however convnetjs karpathy deeplearn.js google used enabled developers create highly interactive explorable explanations deep learning models. visualize deep learning section discusses technical components make surround neural network models could visualized. following section section describes components networks visualized existing work. subsections following section strongly correlated even share one-to-one correspondence difference things visualized things visualized. computational graph network architecture ﬁrst thing visualized deep learning model model architecture. includes computational graph deﬁnes graphical model train test save data disk checkpoint epoch iterations also called dataﬂow graph deﬁnes data ﬂows operation operation order successfully train model. different neural network’s edges weights parameters tweaked training. types architectures including dataﬂow graph neural network edges visualized potentially inform model developers types computations occurring within model. neural network edge weights neural network models built many sometimes diverse constructions layers computational units layers send information throughout network using edges connect layers another oftentimes linear manner recent architectures shown skipping certain layers combining information unique ways lead better performance. regardless edge associated weight sends signal neuron layer potentially thousands neurons adjacent layer parameters tweaked backpropagation phase training deep model could worthwhile visualize understanding model learned. convolutional filters case convolutional neural networks particular type layer aptly called convolutional layers extra hyperparameter depth associated given layer convolutional layers apply ﬁlters input data oftentimes images represented two-dimensional matrix values order generate smaller representations data pass layers network. ﬁlters like previously mentioned traditional weights updated throughout training process. commonly ﬁlters learned network support given task. therefore visualizing learned ﬁlters could useful alternate explanation model learned individual computational units albeit reductionist neural networks thought collection layers neurons connected edge weights. discussed edges visualized neurons source data investigate. generators output embedding could worth exploring. common technique dimensionality reduction take space spanned activations embed visualization purposes; however discussed following sections activations activation functions’ values given trained model perform inference model using data instance obtain results previously trained task. throughout network neurons compute activations using activation functions combine signal previous layer node mapping characteristics allows neural network learn. inference recover activations produced layer. although mappings typically highdimensional vectors feature representations input data certain stage within network could valuable visualize observe input data transformed higher-level feature representation network components respond certain types data commonly called instance-level observation intensive analysis scrutiny placed single data instance’s transformation process throughout network ultimately ﬁnal output representation. done many types data images text time series types sequential data moreover recover activations collections type data referred instance groups discussed shortly. gradients error measurement train neural network process process known backpropagation backpropagation sometimes called backpropagation errors calculate amount error produced iteration batch input data. used combination optimization algorithm e.g. gradient descent compute error output layer redistribute error updating weights using computed gradient. gradients edges deﬁned network contain weights opposite direction. e.g. output layer input layer. therefore could useful visualize gradients network much error produced certain outputs distributed neurons high-dimensional space continuing discussion visualizing activations data instance group instances think feature vectors mappings recovered vectors highdimensional space. neuron layer becomes dimension. shift perspective powerful since take advantage high-dimensional visualization techniques visualize extracted activations sometimes individuals neural networks simply feature generators leave actual task performed computational techniques e.g. traditional machine learning models perspective think deep neural networks robust feature aggregated information groups instances mentioned earlier instance-level activations allow recover mapping data input feature vector output. done single data instance also done collections instances. ﬁrst seem like major differentiation before instance groups provide unique advantages example since instance groups deﬁnition composed many instances compute activations shot. using visualization compare individual activations similar different another. taking further instance groups take multiple groups potentially differing classes compare distribution activations group compares differs another. aggregation known instances higher-level groups could useful uncovering learned decision boundary classiﬁcation tasks. model metrics instancegroup-level activations could useful investigating neural networks respond particular results a-priori suffer scalability issues since deep learning models typically wrangle massive datasets. alternative object visualize model metrics including loss accuracy measures error summary statistics typically computed every epoch represented time series course model’s training phase. representing state model single number handful numbers abstracts away much subtly interesting features deep neural networks; however metrics indicators communicating network progressing training phase example network learning anything learning much simply memorizing data causing overﬁt? metrics describe notions single model’s performance time case model comparison metrics become important provide easy interpretable compare multiple models once. reason visualizing model metrics important powerful tool consider visual analytics. visualize deep learning previous section described technical components neural networks could visualized. section summarize components visualized existing literature. includes common visual representations interactions used. preface noticed components neural network seem visualized example network architectures often represented node-link diagrams embeddings large amount activations typically represented scatter plots model metrics epoch time almost always represented line charts; however discuss representations section. given neural network’s dataﬂow graph architecture common visualize data moves magnitude edge weights network using node-link diagram. represent neurons nodes i.e. single points edge weights links i.e. lines connecting points. computational dataﬂow graphs kahng describe methods creating nodelink diagrams neural networks. ﬁrst represents operations nodes second represents operations data nodes. ﬁrst slowly become standard popularity tensorboard inclusion interactive dataﬂow graph visualization however graph drawing know node-link diagrams suffer scalability issues many links screen resulting visualization crowded patterns. graphs called hairballs. address challenges wongsuphasawat separate highdegree nodes allow users deﬁne super-groups within code. another approach place information node reduce clutter dgmtracker visual analytic system provides quick snapshot dataﬂow node visualizing activations within node. regarding neural network architecture many visual analytics systems node-link diagrams neurons nodes weights links weight magnitude sign encoded using color link thickness. technique ﬁrst proposed trend continued literature. another interactive system visualizes convolution windows layer activations propagate network make ﬁnal classiﬁcation similar dataﬂow graph examples above works include richer information inside node besides activation value showing list images highly activate neuron activations neuron matrix mentioned dataﬂow graph visualizations node-link diagrams network architecture work well smaller networks also suffer scalabilty issues. cnnvis visual analytics system visualizes convolutional neural networks proposes using bi-clustering-based edge bundling technique reduce visual clutter caused many links. section what discussed different types highdimensional embeddings text represented vectors word embeddings natural language processing images represented feature vectors activations inside neural network. types embeddings mathematically represented large twodimensional matrices terms data structures common technique visualize embeddings performing dimensionality reduction matrix reduce number columns e.g. features three. project dimensions generated coordinates every data instance. similarly three dimensions simply component case plot every data instances point obtain scatter plot axes interpretable meaning t-distributed stochastic neighbor embedding case still plot data instance point space interactions rotate navigate space however viewing space computer screen sometimes misleading comparing exact distances. types embeddings often included visual analytics systems main views also used application papers static ﬁgures since reduced coordinate location corresponds original data instance another common approach retrieve original image place reduced coordinate location. although image size must greatly reduced prevent excessive overlap viewing images provide insight deep learning model learned seen example authors visualize imagenet test data example authors create many synthetic images single class compare variance across many random initial starting seeds generation algorithm discussed typical case scatter plot data instance work also used neuron layer separate data instances visualize another paper studies closely data instances transformed information passed deep network effect visualizes neural network separates various classes along approximated decision boundaries also possible time dependent data visualize embedding change time case deep learning epochs useful evaluating quality embedding training phase. however scatter plots raise problems too. quality embedding greatly depends algorithm used perform reduction. works studied t-sne differ mathematical visually suggest reduction techniques capture semantic syntactic qualities particularly within word embeddings also shown sensitive popular reduction techniques like t-sne changes hyperparamter space. work wattenberg meticulously explores different hyperparamter settings t-sne revealing surprising results offering lessons learned practical advice wish highdimensional reduction methods. techniques used often still iterative improvements done using clever interaction design ﬁnding similar instances projected space nearby targeted instance. helps give intuition data line charts temporal metrics model developers builders track progression deep learning models monitoring observing number different metrics reported epoch. include loss accuracy different measure errors. useful diagnosing training process important since training deep learning models takes time. common visualization technique visualizing data considering metrics time series plotting report metrics line chart another common view deep learning visual analytics tools epoch entry time series reported therefore tools like tensorboard alongside models train update latest status tensorboard focuses much screen realestate types charts provides nice interactions plotting multiple metrics small multiples plotting multiple models another ﬁltering different models providing tooltips exact metric values resizing charts closer inspection. technique straightforward appears many visual analytics systems staple model training comparison selection. instance-based analysis exploration repeatedly seen deep learning models complex biggest challenges deep learning visualization make models interpretable. method deep learning experts often debugging models test speciﬁc data instances order understand progress throughout model. many times experts built collection data instances time becoming comfortable behavior models also knowing ground truth labels example instance consisting single image single text phrase much easier understand entire image dataset word embedding consisting thousands numerical features extracted user’s data. identifying analyzing misclassiﬁed instances application instance-level analysis using instances unit tests deep learning models. best case scenario familiar instances classiﬁed predicted correctly; however important understand speciﬁc instance fail fails. example task predicting population satellite imagery authors showcase three maps areas high error using transparent heatmap overlaid satellite imagery inspecting instances reveals three geographic areas contain high amounts man-made features signs activity registered people living them. three areas presented army base national walt disney world; however authors include visualization show proposed model indeed learning high-level features input data. another popular technique analyzing particular data instances using text data instead images color background particular characters phrase words sentence using divergent color scheme according criteria oftentimes activation magnitude another example technique analyzes misclassiﬁed instances hoggles algorithm visualizes feature spaces using object detectors inverting visual features back natural images. authors visualizing features misclassiﬁed images although classiﬁcation wrong image space feature space look deceptively similar true positives. therefore visualizing feature spaces misclassiﬁed instances gain intuitive understanding recognition systems. presents challenge event expert speciﬁc data instances test locate guide users towards important interesting instances? solve this visual analytics system called blocks uses confusion matrices technique summarizing performance classiﬁcation algorithm matrix-level sorting interactions reveal class error often occurs hierarchies. instead inspecting individual data instances testing debugging model also common experts groups instances perform similar tasks. detail lost scaling groups instances allows experts test model looking average aggregate performance different groups. much work using technique done text data using lstm models examples compute saliency groups words across model visualize values matrix others also matrix visualization show activations word groups represented feature vectors word embedding system activis places instance group analysis focus interactive interface allowing users compare preset user-deﬁned groups activations. similar matrix visualization summarizes activations class cnnvis activis also uses scrolling matrix visualization unify instance-level grouplevel analysis single view users compare activations user-deﬁned instances. however sometimes challenging deﬁne groups images text. textual data default words group documents provide aggregated data. conceptvector solves instance group generation problem providing interactive interface create interesting groups concepts model testing. furthermore system also suggests additional words include user-deﬁned groups helping guide user create semantically sound concepts. another interesting area deep learning visualization used makes heavy interactions experimenting models. using direct manipulation testing models user pose what questions observe models responding user-provided input data engage user desired concepts taught many systems require user provide kind input data system obtain results. visual analytics systems webcam watch internals neural network models respond live video input another example visualization trained classic mnist dataset shows convolution windows activations images user draws hand example drawing designated area passes example throughout network populates visualization corresponding activations using node-link diagram. ﬁnal example using image data shapeshop system allows user select data bank simple shapes classiﬁed. system trains neural network using class activation maximization technique generate visualizations learn features model. done realtime therefore quickly train multiple models different shapes observe effect adding diverse data improve internal model representation. example uses text interactive handwriting prediction article distill demos allow user write words screen real-time system draws multiple to-be-drawn curves predicting user’s next stroke ﬁnal example adversarial playground visual analytics system enables nonexperts compare adversarially perturbed images visually helps understand adversarial example fool cnn-based image classiﬁer; topic discussed in-depth later user select mnist digits adjust adversarial attack power. system compares classiﬁcations scores chart observe simple perturbations greatly impact classiﬁcation accuracy. hyperparameters affect results known deep learning models automatically adjust internal parameters hyperparameters still require ﬁne-tuning. hyperparameters major impact model performance robustness. visual analytics systems expose model parameters user order interactive experimentation. example previously mentioned tensorflow playground users direct manipulation adjust architecture simple fully-connected neural network well hyperparameters associated learning algorithm learning rate activation function regularization. another example distill article meticulously explores hyperparaemters t-sne dimensionality reduction method article tests dozens synthetic data different arrangements varying hyperparameters t-sne perplexity number iterations algorithm for. ﬁnal method visualize deep learning hails computer vision communities. algorithmic techniques entail synthetic image generation. typically given trained model select single image instance algorithmic techniques generate image size either highlights important salient parts image reconstruction image network entirely image class. types papers standard large full-page ﬁgures consisting hundreds images corresponding multiple images classes therefore uncommon interactively works primary contribution algorithm interactive system includes since focus interrogative survey visual analytics deep learning spend much time discussing detail various types algorithmic techniques rather mention prominent techniques developed since still impactful growing ﬁeld deep learning visualization could incorporated visual analytics systems future. in-depth breakdown techniques input modiﬁcation deconvolutional methods input reconstruction methods following taxonomy survey computer vision techniques visualizing learned features convolutional neural networks another tutorial explains theory behind many interpretation techniques also provides tricks recommendations make efﬁcient techniques real data noteable types work area generate semitransparent heatmaps overlaid image highlight saliency sensitivity class activation maps technique called visual backpropagation attempts visualize parts image contributed classiﬁcation real-time debugging tool self-driving vehicles another technique invert image attempt reconstruct image understand amount rich information contained features prediction difference analysis method highlights features image provide evidence certain class work hearkens back traditional computer vision techniques exploring object detectors emerge cnns attempts give humans object detector vision capabilities better align deep learning models seeing images visualizing ﬁlters model also popular famously shown generate dream-like images becoming popular artistic tasks work interpreting visual question answering models tasks heatmaps explain parts image model looking unison text activation maps answering given textual questions however recent work shown methods fail provide correct results argue develop explanation methods work simple models scaling class activation maximization regarding image generation techniques proven interesting studied techniques class activation maximization maximizes activation chosen speciﬁc neuron using optimization scheme gradient ascent generates synthetic images representative model learned chosen class number papers improving qualitative quality generated images. studies generated hundreds non-deterministic synthetic images clustered variations class activation maximization algorithm affects output image recent work topic ngyuen present hundreds high-quality images using deep generator network improve upon stateof-the-art includes ﬁgures comparing technique many existing previous attempts improve quality generated images. area research improved dramatically past years possibly synthetically generate photorealistic looking images visualize deep learning process section describes visualizing deep learning relevant useful. section primarily around training process deep learning model foundational iterative step deep learning process. therefore identify distinct times visualize training training. however noted works propose used training training exact separation groups exact. training number visual analytics tools developed primarily focus assisting model developers sometimes model users build train test deep neural networks. shown artiﬁcial neural networks learn higher-level features useful class discrimination training progress using visualization training process potential monitor one’s model trains order observe closely track model’s performance many systems category separate web-browser alongside training process interface underlying model order pull latest model status. users able visually explore rigorously monitor real time model trains elsewhere. enables visualization systems update charts metrics computed every epoch training example loss accuracy epoch training time. particular emphasis metrics since model developers rely communicate model begun learn anything model converging reaching peak performance potentially overﬁt simply memorized training data preventing useful inference. therefore many visual analytics systems used training support show updating line charts primary view interface work zhong system deep view takes advantage plotting metrics training process deﬁne metrics visualize rather loss discriminability metric evaluates neuron evolution density metric evaluates output feature maps. detecting something overﬁtting user wait long view density metric infer overﬁtting observing neuron density early training phase. similarly systems reduce development time introducing features shorten time takes beginning training model determining model learning worth letting train process complete using visualization model training users save development time designing networks steering models utilizing suggestions promising directions improvement lastly another approach minimizing model development time focus diagnosing neurons layers training correctly misclassifying data instances. examples include deepeyes system identiﬁes stable unstable layers neurons users prune models enabling faster training blocks system visualizes class confusion reveals confusion patterns follow hierarchical structure classes exploited design hierarchy-aware architectures dgmtracker system proposes credit assignment algorithm indicates neurons contribute output particular failing neurons. training signiﬁcant work develop tools support neural network design iterative model building process also body work focuses visualization efforts model trained. words works assume trained model input system visualization technique. also worth noting many previously mentioned algorithmic techniques developed artiﬁcial intelligence ﬁelds class activation maximization saliency heatmaps image generation techniques performed training. techniques discussed section embedding projector specializes visualizing embeddings produced trained neural networks. users could visualize typical high-dimensional datasets tool embedding projector tailors experience towards embeddings commonly used deep learning. neural network model trained compute activations given test dataset visualize activations embedding projector visualize explore space network learned. another suite tools informally called deep visualization toolbox takes trained model input looks live activations large small-multiples view gain understanding types ﬁlters convolutional network learned. instead generating overview embedding test dataset system visualizes ﬁlters single data instance live webcam typical visual analytics systems also developed inspect model ﬁnished training. example activis visual analytics system neural network interpretation deployed facebook reports facebook engineers data scientists visual analytics systems directly normal workﬂow. another system rnnvis visualizes compares different models various natural language processing tasks. system natural extension tensorflow naively accepts multiple tensorflow models input; system analyzes trained models extract learned representations hidden states processes evaluation results visualization. lastly lstmvis system visual analysis tool interpretability separates model training visualization. system takes model input must trained separately model gathers required information produce interactive visualizations rendered web-based front-end. deep learning visualization last question interrogative survey divide where subsections deep learning visualization research applied deep learning visualization research conducted describing community risen. introduced topics earlier survey division ﬁnal interrogative question provides concise summary practitioners wish investigate usage described techniques ideation provides researchers main locations area research read deeper existing literature. application domains models researchers practitioners still many nonneural approaches real-world applications deep learning models successfully achieved state-of-the-art performance several domains. previously section presented examples research papers apply neural networks particular domain visualizations lend qualitative support usual quantitative results strengthen credibility model. domains included neural machine translation reinforcement learning social good autonomous vehicles medical imaging diagnostics urban planning deep learning visualization enormous potential already made signiﬁcant contributions practitioners researchers; summarize communities contributed deep learning visualization. much work image-based data models namely convolutional neural networks since generate synthetic image explanations model learned image dataset. cnns exclusively used images become quite popular computer vision community often used image classiﬁcation interactive image-based creative research tasks. community also contributed many saliency heatmap generation techniques used describe imagebased models. aside images sequential data also studied. research stems natural language processing community researchers typically favored using recurrent neural networks learn deep representations large text corpora. researchers wrangle large word embeddings using interactive tools support dimensionality reduction techniques order solve problems sequence-to-sequence conversion translation audio recognition. also research using image text data combining cnns rnns image captioning visual question answering harder still types networks called generative adversarial networks gans short produced remarkable results data generation name examples researchers using gans produce fake photo-realistic images training image datasets seen survey utilizing visualization deep learning enables researchers many domains harness power contemporary neural networks possess. rapid progress deep learning visualization research currently permanent publication venue disseminated research. academia premiere venues deep learning visualization research split groups information visualization visual analytics community; artiﬁcial intelligence deep learning community. furthermore since area relatively seen attention multiple workshops previously mentioned academic conferences. list current targeted academic conferences workshops table another consequence rapidly developing area empirical results immediately publicized open sourced instead waiting yearly conference deadlines. many releases take form preprint publication posted arxiv deep learning presence thrived. common academic research labs individuals publish work arxiv companies industry also continuously publishing results code tools. example popular libraries implementing neural networks open source consistent contributions improving areas codebase installation computation extension larger programming language’s open source environment. works corresponding blog post industry research blog which nontraditional made large impact ﬁeld large readership exposure. posting preprints early possible certainly non-traditional could raise future problems community broken another norm better open sourcing developed code including direct links within preprints becoming standardized. although overwhelming digest amount research published daily access work code better encourages reproducibility allows community build upon work faster. summary given increasing interest deep learning visualization research importance believe strong existing community continue grow expand thrive successfully impacting many domains years come. furthering interpretability unsurprisingly amount attention importance interpretability explainability deep learning visualization literature ﬁrst area future work continuing create interpretable methods deep learning models. information visualization community could constitute creating visual representation component deep learning model. visual analytics community user experience designers another approach could using inventive interaction techniques visual analytics system reveal deeper insights one’s model. lastly communities insightful image generation explanation techniques trained models fast i.e. computational cheap could incorporated web-based visualization systems. wielding ability summon perform image generation techniques extemporaneously within visual analytics system could consideration understanding neural network models. system visual scalability throughout survey covered many visual analytics systems developed facilitate interpretation model understanding; however systems suffer scalability. visual scalability challenge arises dealing large data case deep neural networks millions parameters many hyperparameters. work already done simplify complicated dataﬂow graphs network weights better model explanations even dimensionality reduction techniques limit usability comes number points visualize however think still active research direction especially considering information aside visual scalability current tools also suffer lack system scalability. problems engineering-centric think order visual analytics systems used adopted become part researcher’s practitioner’s pipeline systems need able handle state-of-the-art deep models without penalizing performance increasing model development time. furthermore systems beneﬁt greatly fast computations oftentimes web-browser order maintain real-time support rich user interactions especially true preprocessing needed visual system rendering visualization screen. important facet visualization research evaluation utility usefulness visual representation considering evaluating interactive visual analytics deployed systems usability. encouraging many visual analytics systems recognize importance report design studies conducted experts building tool understand users needs common usage scenarios cases illustrative examples demonstrate capabilities interactive system works beyond user studies evaluate utility usability said algorithmic image generation techniques communities. many types papers conduct human-based user studies greatly beneﬁt showing proposed methods superior ones tested taking idea quantiﬁable extreme related avenue evaluating techniques notion quantifying interpretability recently studied domains recognized interpretable deep learning research require evaluation techniques interpretations argue large body work ﬁelds philosophy cognitive science social psychology could utilized short remark course survey seen deep learning visualization research beneﬁts multiple people diverse backgrounds working single problem together. inspecting interfaces tools many contain multiple-coordinated views different visual representations sometimes clumsily stacked another muddying information hierarchy. displaying much information off-putting users interpretability primary focus visualizations approachable easy grasp. therefore think works could beneﬁt including members humancomputer interaction community including interface user experience designers could help organize prioritize system displays using interface guidelines studied decades. human role interpretability human machine understanding world deep learning interpretability work researchers developing methods produce better explanations black-box unfortunately methods produce visualizations that visually interesting thought-provoking fully understandable human viewers. important facet deep learning interpretability namely producing visualizations interpretations human understandable methods compare algorithmic results empirically derived human baseline; enables comparison machine human generated responses objects world particularly images ultimately researchers seek understand commonalities differences humans machines decompose world tools surveyed achieve using live-video compare input images neural network’s activations ﬁlters real time tools give users explicit control experiment training multiple small models exposed hyperparameters automatically generating visualizations effect input data learned representation what-if tools scenarios could potentially extended incorporate human feedback training model steering process neural network better improve performance. human-ai pairing much survey dedicated towards reviewing state-of-the-art visual analytics deep learning focus interpretability. works visualization explain explore debug models order choose best preforming model given task oftentimes placing human loop. however slight twist idea hearkening back original envisioning computer lead emergence research area tasks exclusively performed humans machines complement another. area recently dubbed artiﬁcial intelligence augmentation describes systems help develop methods intelligence augmentation related works already seen already proposed artiﬁcial intelligence augmentation ideas system suggests potentially interesting directions explore high-dimensional clustered embedding predicting showing next stroke word could handwriting text dynamically changing steering neural network model trains believe rich untapped area future research using well-design interfaces humans interact machine learning models machine learning models augment creative human tasks. social good protecting adversarial attacks articial intelligence augmentation describes aspirational pairing humans machines yet. there must continue democratize artiﬁcial intelligence educational tools perhaps using direct manipulation invitation people engage clear explanations model decision making robust tooling libraries programming languages people develop models however must ensure applications remain ethical fair safe transparent beneﬁting society already looked number ways visualization used identify communicate prevent data bias maintain equal opportunity used help reveal insights world around affect governmental policy however would remiss immediately instill trust systems; like technologies security faults. identiﬁed studied seminal works shown deep learning models image classiﬁers easily fooled perturbing input image number different ways alarming perturbations subtle untraceable human completely fool model misclassiﬁcation sparked great interest communities much work done understand fragile deep neural network image classiﬁers ways break methodologies protecting adversarial attacks. norton demonstrate adding adversarial perturbations images interactive tool users tweak type intensity attack order observe resulting correct incorrect classiﬁcation. great ﬁrst start using visualization identify potential attacks think visualization majorly impactful research space showcasing attacks work detecting them also taking action protecting systems attacks themselves. work primarily originating communities proposed computational techniques protect based attacks identifying attack examples classiﬁcation modifying network architecture modifying training process performing pre-processing steps classiﬁcation think still much room improvement booming research area visualization. presented comprehensive timely survey visualization visual analytics deep learning research using human-centered interrogative framework. method helps researchers practitioners visual analytics deep learning quickly learn aspects young rapidly growing body research whose impact spans broad range domains. survey goes beyond visualization-focused venues extend wide scope also encompasses relevant works venues computer vision. highlighted visual analytics integral component addressing pressing issues modern helping discover communicate insight discerning model bias understanding models promoting safety. concluded highlighting impactful research directions open problems. zeiler fergus visualizing understanding convolutional networks european conference computer vision. springer f.-y. tzeng k.-l. opening black data driven visualization neural networks ieee visualization. ieee towards better analysis deep convolutional neural networks ieee tvcg vol. wongsuphasawat smilkov wexler wilson man´e fritz krishnan vi´egas wattenberg visualizing dataﬂow graphs deep learning models tensorﬂow tvcg vol. smilkov carter sculley viegas wattenberg direct-manipulation visualization deep networks icml workshop visualization deep learning chen zhang maciejewski recent progress trends predictive visual analytics frontiers computer science amershi cakmak knox kulesza power people role humans interactive machine learning magazine vol. sacha sedlmair zhang weiskopf north keim human-centered machine learning interactive visualization european symposium artiﬁcial neural networks computational intelligence machine learning seifert aamir balagopalan jain sharma grottel gumhold visualizations deep neural networks computer vision survey transparent data mining small data. springer zeng towards better understanding deep learning visualization department computer science engineering hong kong university science technology wang towards better analysis machine learning models visual analytics perspective visual informatics vol. goodfellow bengio courville deep learning. press http//www.deeplearningbook.org. deng dong socher l.-j. fei-fei imagenet large-scale hierarchical image database ieee cvpr. russakovsky deng krause satheesh huang karpathy khosla bernstein imagenet large scale visual recognition challenge international journal computer vision vol. compet convnet available http//karpathy.github.io//// what-i-learned-from-eompeting-against-a-convnet-on-imagenet zhang deep residual learning johnson schuster krikun chen thorat vi´egas wattenberg corrado google’s multilingual neural machine translation system enabling zeroshot translation arxiv preprint arxiv. robinson hohman dilkina deep learning approach population estimation satellite imagery sigspatial workshop geospatial humanities ser. geohumanities’. smilkov thorat nicholson reif vi´egas wattenberg embedding projector interactive visualization interpretation embeddings nips workshop interpretable machine learning complex systems chen hovy jurafsky visualizing understanding neural models arxiv preprint arxiv. karpathy johnson fei-fei visualizing understanding recurrent networks arxiv preprint arxiv. carter johnson olah experiments handwriting neural network distill available http//distill.pub//handwriting zhou khosla oliva torralba network dissection quantifying interpretability deep visual representations ieee cvpr available http//netdissect.csail.mit.edu/ nguyen dosovitskiy yosinski brox clune synthesizing preferred inputs neurons neural networks deep generator networks advances neural information processing systems kulesza burnett w.-k. wong stumpf principles explanatory debugging personalize interactive machine learning proceedings international conference intelligent user interfaces. rong adar visual tools debugging neural language models icml workshop visualization deep learning chae ramanthan steed tourassi visualization classiﬁcation deep neural networks workshop visual analytics deep learning mcmahan holt sculley young ebner grady phillips davydov golovin chikkerur wattenberg hrafnkelsson boulos kubica click prediction view trenches kdd. kahng fang chau visual exploration machine learning results using data cube analysis sigmod workshop human-in-the-loop data analytics. dean monga tensorﬂow googles latest machine learning system open sourced everyone google research blog zeng haleem plantaz cnncomparator comparative analytics convolutional neural networks workshop visual analytics deep learning barocas selbst data’s disparate impact calif. rev. vol. attacking discrimination smarter machine learning google research website available https//research.google.com/ bigpicture/attacking-discrimination-in-ml/ facets google pair pair-code.github.io/facets/ wall blaha franklin endert warning bias occur proposed approach detecting cognitive bias interactive visual analytics ieee visual analytics science technology yosinski clune nguyen fuchs lipson understanding neural networks deep visualization icml deep learning workshop bruckner ml-o-scope diagnostic visualization system deep machine thesis eecs department university california berkeley available http//www.eecs.berkeley.edu/ pubs/techrpts//eecs--.html large-scale machine learning heterogeneous distributed systems arxiv preprint arxiv. theano http//deeplearning.net/software/theano/ accessed january harley interactive node-link visualization convolutional neural networks proceedings international symposium visual computing chung park kang choo kwon revacnn steering convolutional neural network real-time visual analytics nips workshop future interactive learning machines cashman patterson mosca chang rnnbow visualizing learning backpropagation gradients recurrent neural networks workshop visual analytics deep learning nguyen yosinski clune multifaceted feature visualization uncovering different types features learned neuron deep neural networks icml workshop visualization deep learning rauber falc˜ao telea visualizing timedependent data using dynamic t-sne proc. eurovis short papers vol. p.-t. bremer thiagarajan srikumar wang livnat pascucci visual exploration semantic relationships neural word embeddings ieee tvcg vol. norton adversarial-playground visualization suite showing adversarial examples fool deep learning visualization cyber security ieee symposium ieee rupprecht navab tombari taxonomy library visualizing learned features convolutional neural networks icml workshop visualization deep learning mueller chen beyond saliency understanding convolutional neural networks saliency prediction layerwise relevance propagation arxiv preprint arxiv. nguyen yosinski bengio dosovitskiy clune plug play generative networks conditional iterative generation images latent space arxiv preprint arxiv. vinyals toshev bengio erhan show tell neural image caption generator ieee cvpr antol agrawal mitchell batra lawrence zitnick parikh visual question answering proceedings ieee international conference computer vision tensorﬂow https//www.tensorﬂow.org/ accessed january keras https//keras.io/ accessed january caffe http//caffe.berkeleyvision.org/ accessed january pytorch http//pytorch.org/ accessed january maljovec wang p.-t. bremer pascucci visualizing high-dimensional data advances past decade tvcg vol. samek binder montavon lapuschkin k.-r. ¨uller evaluating visualization deep neural network learned ieee transactions neural networks learning systems c.-y. tsai characterizing visual representations within convolutional neural networks toward quantitative approach icml workshop visualization deep learning agrawal zitnick parikh batra human attention visual question answering humans deep networks look regions? computer vision image understanding metzen genewein fischer bischoff detecting adversarial perturbations proceedings international conference learning representations available https//arxiv.org/abs/. fred hohman student college computing georgia tech. research interests combine principles techniques machine learning improve deep learning interpretability using interactive data visualization. received b.s. mathematics physics awards including sigmod’ best demo honorable mention microsoft earth award using improve sustainability president’s fellowship awarded incoming doctoral students. minsuk kahng computer science student georgia tech. thesis research focuses building visual analytics tools exploring interpreting interacting complex machine learning models results combining methods information visualization machine learning databases. received graduate research fellowship. activis system deep learning visualization deployed facebook’s machine learning platform. robert pienta industry researcher applied machine learning visual analytics. received degree computational science engineering georgia tech flamel fellow presidential scholar georgia tech. research interests include visual analytics graph analytics machine learning. particular algorithms design techniques interactive graph querying exploration. duen horng chau assistant professor georgia tech. research bridges data mining make sense massive datasets. ph.d. carnegie mellon’s dissertation award honorable mention. received faculty awards intel google yahoo lexisnexis; outstanding junior faculty award; symantec fellowship; best paper awards sigmod sdm. published refereed articles. steering committee member conference co-chair program co-chair. research deployed technologies facebook symantec yahoo.", "year": 2018}