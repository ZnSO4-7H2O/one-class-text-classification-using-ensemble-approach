{"title": "Identifying individual facial expressions by deconstructing a neural  network", "tag": ["cs.CV", "cs.NE", "stat.ML"], "abstract": "This paper focuses on the problem of explaining predictions of psychological attributes such as attractiveness, happiness, confidence and intelligence from face photographs using deep neural networks. Since psychological attribute datasets typically suffer from small sample sizes, we apply transfer learning with two base models to avoid overfitting. These models were trained on an age and gender prediction task, respectively. Using a novel explanation method we extract heatmaps that highlight the parts of the image most responsible for the prediction. We further observe that the explanation method provides important insights into the nature of features of the base model, which allow one to assess the aptitude of the base model for a given transfer learning task. Finally, we observe that the multiclass model is more feature rich than its binary counterpart. The experimental evaluation is performed on the 2222 images from the 10k US faces dataset containing psychological attribute labels as well as on a subset of KDEF images.", "text": "department brain cognitive engineering korea university seoul korea machine learning group fraunhofer heinrich hertz institute berlin germany abstract. paper focuses problem explaining predictions psychological attributes attractiveness happiness conﬁdence intelligence face photographs using deep neural networks. since psychological attribute datasets typically suﬀer small sample sizes apply transfer learning base models avoid overﬁtting. models trained gender prediction task respectively. using novel explanation method extract heatmaps highlight parts image responsible prediction. observe explanation method provides important insights nature features base model allow assess aptitude base model given transfer learning task. finally observe multiclass model feature rich binary counterpart. experimental evaluation performed images faces dataset containing psychological attribute labels well subset kdef images. deep convolutional networks architecture choice many practical problems large-scale image recognition typically networks millions free parameters learned large datasets. great success convnets abundance hardware software frameworks availability pre-trained models speciﬁed tasks. retraining pre-trained models task allows successfully convnets also small sample settings procedure instance transfer learning paradigm nutshell model trained domain related problem hand adapted target domain data points. contribution pre-trained deep neural network trained gender classiﬁcation used subsequently retrained predict psychological attributes attractiveness happiness conﬁdence intelligence face photographs. since labelled attribute datasets rather small pre-trained model thus harvest rich representation neural network learned related problem. tasks suﬃciently similar transfer knowledge acquired pre-trained model domain e.g. gender another e.g. happiness attractiveness. study based faces dataset note subset images dataset labelled needed attributes. therefore retrain neural network reproduce human assessment labels bainbridge dataset. however focus primarily excellent prediction attributes such explanation thereof. focus question makes neural network assign certain attractiveness happiness scores etc. novel test image whether assignment corresponds humans expect. apply recently proposed explanation method termed layer-wise relevance propagation allows better understanding neural network using decisive features single sample basis. visualize rationale trained predictors using method study robustness relate results human expectations. explanation method going following experiments layer-wise relevance propagation basic idea perform backward pass ﬁnal score given image neural network ﬁnds mapping score images input pixels reﬂects relevance respective pixels image network’s decision. ﬁrst proposition method conservation relevance layers. adjacent layers conservation relevance expressed sums neurons respective layers. conservation principle ensures network’s output redistributed input domain relative distribution relevance scores input domain reﬂects importance respective pixels overall score. call image pixel-wise relevance scores heatmap visualized interpreted individual assignment relevance scores done using methods. weighted activation neuron onto neuron following layer. ﬁrst rule assigns weighted average weighted activations node. mathematically rule written fig. illustration layer-wise relevance propagation happiness classiﬁcation. ﬁrst step procedure regular forward pass yields classiﬁcation score ﬁrst node. second step backward pass passes network reverse order. backward pass score redistributed layer layer node lower layer receive relevance score relative activations node based rules second rule based weighted average rationale well. however second rule positive negative weighted activations treated separately weighted additional parameters force certain ratio positive negative contributions. denote positive negative part respectively zij. relevance conservation property holds. empirical comparison diﬀerent explanation methods found theoretical view refer reader applications beyond image classiﬁcation implementation found downloaded www.heatmapping.org. following heatmaps obtained using retrain models gender faces dataset predict individual ratings attractiveness happiness conﬁdence intelligence images scores dataset. retraining happens base model modes. ﬁrst mode dense layers network retrained target scores. second mode entire network including convolution units retrained. presented subject faces those part subset faces bainbridge dataset licensed publishing. individual image rating scores rescaled output domain input images rescaled input format network labelled subset images faces dataset used train diﬀerent networks. images randomly split training test samples. total diﬀerent networks. half model base model half gender model base model. networks either completely retrained dense layers adapted. images composed white frame contains oval central region face. train model using stochastic gradient descent learning rate using nesterov momentum weights initialized base models provided levi annotated dataset split equally test training set. error given terms human scaling points. interestingly gain retraining full model attractiveness assessment yield high improvement computational cost retraining full convnet signiﬁcantly higher solely retraining dense layers. transfer learning want select base model already captures many possible relevant features task case base models would need make choice whether take gender base model base model. following demonstrate explanation methods algorithm helpful making educated guess model basis transfer learning task. figure illustrates sample image diﬀerence features picked models scale. turns model picks facial details gender model sensitive overall shape face. edges face seem provide already quite information subject’s gender. note gender model binary classiﬁer model multi-class classiﬁer placing subject many possible groups. multi-class structure model might reason it’s feature richness. wrinkles example relevant higher groups teeth universally relevant. learning curves ﬁgure show dense retrained models based gender learning slower models based age. thus interpretation heatmaps terms feature richness model correlates slower rate convergence training error. therefore conclude based model captures relevant features thus network based model learns faster retrain whole model fully connected layers ﬁgure conﬁrms method assessment aptitude base model given transfer learning task especially possess additional knowledge structure problem model assigns bulk relevance signiﬁcant feature subset conjecture network applies human-like strategy opposed model responding random artifact happens correlate task. faces dataset contain face diﬀerent emotional state. therefore taken another dataset karolinska directed emotional faces contains adult person diﬀerent emotional states following analysis. applied preprocessing described above. figure depicts heatmaps female male subject happy unhappy state. heatmaps female subject three principal regions interest. number pointed indicator arrow mouth. happy face smile teeth important. heatmap unhappy face also shows teeth relevant happy case. region number indicator arrow nostrils cheeks. nostrils wider compared state. furthermore cheeks lifted forming dimples. lastly outline eyebrows shown indicator arrow marked relevant both happy unhappy face. however roundish shape outline happy face relevance assigned straight counterpart face. male counterpart make similar observations. firstly shape lips seems matter. secondly smile showing subject’s teeth indicates happiness. thirdly dimples matter too. examples relevance assigned gender unspeciﬁc features smiles dimples however relevance also assigned outline eyebrows gender speciﬁc. test subjects ﬁgure show three basic features according model indicative advanced age. indicator arrow left image shows earlobe seen evidence advanced age. furthermore indicator arrow points signiﬁcant wrinkle around region. wrinkles around indeed indicators advanced age. however dominant feature indicating advanced saggy eyelids. figure shows individuals classiﬁed attractive. cases relevance assigned eyes. furthermore straight lines appear heatmaps. possible interpretation indicators symmetry. heatmap female shows straight line nose indicating symmetry part. furthermore female person possesses large space eyes eyebrows considered relevant. fig. test subjects corresponding heatmaps. indicator arrows showing areas high relevance. ﬁrst individual right earlobe wrinkle birthmark upper bags second testsubject upper bags well saggy eyelids relevant features indicated high age. straight lines male example ﬁgure correspond nose eyes partially mouth. asymmetric deviation mouth appears less relevant. vertical texture man’s hair also assessed relevant. validate insights obtained analysis heatmaps experiment analyzes model heatmaps react selective occlusions. figure shows sample subject various facial features occluded mouth right eyes. skin color occlusion order reduce visual artefacts below image show heatmap prediction score models happiness pretrained model pretrained gender model. observed cases mouth occlusion causing happiness score decrease signiﬁcantly. hand removing eyes sometimes even increases perception happiness likely attention ported exclusively mouth region. fig. sample subject occluded various ways shown next heatmap happiness score considered models. mouth occlusion causes happiness scores decrease models heatmap values mouth region drop well. modern learning machines allow modeling highly complex nonlinear problems. recently however unclear provide explanations neural network decisions predictions exactly terms inputs made learning machine provide prediction single novel data point. explanation methods able successfully solve important open problem. present contribution applied particularly complex domain namely assessing multifaceted properties images gender attractivity etc. humans excellently trained socialization estimate properties perhaps less aware speciﬁc features inﬂuence judgement distinguishing elderly younger person. clearly wrinkles general percept freshness would help holistically guess age. state-ofthe-art convolutive neural nets trained work also holistic approach accurately predict interesting question features come good prediction. obviously diﬀer greatly young faces exactly relevant features speciﬁc image extracted convolutive neural net. addition qualitatively quantitatively shown robustness occlusion. sense probe artiﬁcial neural network percept gender attractivity etc. future research relate psychophysical studies human perception. established basic convolutive neural network models predicting certain data rich properties could reuse models adapt data poorer properties attractivity transferring neural network representation using data point retraining. done straight forward manner subject future research consider transfer optimal manner also interesting study whether generative neural network better suited include prior representation knowledge prediction task other. would like stress focus paper open black complex learning model successfully learned task optimal prediction strategy pursued artiﬁcial system somewhat unclear. particular also enabled judge whether generalization properties yielding good sample predictor based artifacts data appriopriate problem decomposition strategy. work supported german ministry education research berlin data center bbdc deutsche forschungsgesellschaft brain korea plus program national research foundation korea funded ministry education. correspondence", "year": 2016}