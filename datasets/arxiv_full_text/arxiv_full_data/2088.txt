{"title": "Transfer Learning Across Patient Variations with Hidden Parameter Markov  Decision Processes", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Due to physiological variation, patients diagnosed with the same condition may exhibit divergent, but related, responses to the same treatments. Hidden Parameter Markov Decision Processes (HiP-MDPs) tackle this transfer-learning problem by embedding these tasks into a low-dimensional space. However, the original formulation of HiP-MDP had a critical flaw: the embedding uncertainty was modeled independently of the agent's state uncertainty, requiring an unnatural training procedure in which all tasks visited every part of the state space---possible for robots that can be moved to a particular location, impossible for human patients. We update the HiP-MDP framework and extend it to more robustly develop personalized medicine strategies for HIV treatment.", "text": "physiological variation patients diagnosed condition exhibit divergent related responses treatments. hidden parameter markov decision processes tackle transfer-learning problem embedding tasks low-dimensional space. however original formulation hip-mdp critical embedding uncertainty modelled independently agent’s state uncertainty requiring unnatural training procedure tasks visited every part state space—possible robots moved particular location impossible human patients. update hip-mdp framework extend robustly develop personalized medicine strategies treatment. physiological variation patients diagnosed condition exhibit divergent related responses treatments. develop optimal treatment control policies patient undesirable ineffectual start afresh time individual cared for. however patient still require tailored treatment plan one-size-ﬁts-all\" treatments introduce risk aggressive diagnoses. ideally agent tasked developing optimal health management policy would able leverage similarities across separate related instances also customizing treatment individual. paradigm learning introduces compelling regime transfer learning. hidden parameter markov decision process formalizes transfer learning task following ﬁrst assumes task instance fully parameterized bounded number latent parameters posit dynamics dictating patient’s physiological response expressed patient second assume system dynamics change task agent would capable determining change occurs doshi-velez konidaris show hip-mdp identify dynamics task instance ﬂexibly adapt variations present therein. however original hip-mdp formulation critical embedding uncertainty latent parameter space modelled independently agent’s state uncertainty. assumption required agent ability visit every part state space identifying variations present dynamics current instance. feasible robotic systems generally available domains healthcare. present alternative hip-mdp formulation alleviates issue gaussian process latent variable model approach creates uniﬁed gaussian process model inferring transition dynamics within task instance also transfer task instances steps taken avoid negative transfer selecting representative examples prior instances regards latent parameter setting. change model allows better uncertainty quantiﬁcation thus robust direct transfer. ground approach recent advances approximate dynamical systems transfer learning well discuss relevant reinforcement learning applications healthcare sec. formalize adjustments hip-mdp framework sec. present performance adjusted hip-mdp developing personalized treatment strategies within simulators. development optimal control policies decision making strategies healthcare gaining signiﬁcant momentum methodologies begun adequately account uncertainty variations problem space. notable efforts made administration anesthesia personalizing cancer therapies understanding causality macro events diabetes managment marivate formalized routine accommodate multiple sources uncertainty batch methods better evaluate effectiveness treatments across subpopulations patients. similarly attempt address identify variations across subpopulations development treatment policies. instead attempt account variations developing effective treatment policies approximate online fashion. increasingly used facilitate methods recent advances modeling dynamical systems efﬁcient robust formulations particularly approximation simulation dynamical systems. hip-mdp approximates underlying dynamical system task training gaussian process dynamical model small portion true system dynamics observed common partially observable markov decision processes order facilitate transfer task instances embed latent low-dimensional parametrization system dynamics states. virtue latent embedding allows hip-mdp infer across similar task instances provide better prediction currently observed system. facilitate transfer previously learned information instances similar task rich history recently advances organizing used transfer constrained select previous task instances positive transfer occurs adaptive approach transfer learning helps avoid previous instances would otherwise negatively affect effective learning current instance. selecting relevant instances current task transfer learning current instance becomes efﬁcient. model hip-mdp described tuple sets states actions reward function mapping utility taking action state transition dynamics task instance depends value hidden parameters possible parameters denoted prior parameters. finally factor discounted express inﬂuential immediate rewards learning control policy. thereby hip-mdp describes class tasks; particular instances class obtained independently sampling parameter vector initiation task instance assume invariant duration instance signaling distinct learning frontiers instances newly drawn accompanies observed additions hip-mdp presented provided transition model form sought learn weights based latent factor corresponding task instance ﬁlter parameters zkad denoting whether latent parameter relevant predicting dimension taking action well task speciﬁc basis functions fkad drawn formulation expressive presents problematic trained. independence weights basis functions fkad training hip-mdp requires canvassing state space order infer ﬁlter parameters zkad learn instance speciﬁc weights latent parameter. bypass applying gplvm jointly represent dynamics latent weights corresponding speciﬁc task instance leads providing input approximated transition model hyperparameters augmented state latent embedding features reformulating hip-mdp gplvm allows robust efﬁcient transfer. demonstration demonstrate example domain agent able learn separate policies according hidden latent parameter. instances inhabiting blue\" latent parametrization pass goal region blue boundary red\" parametrization cross boundary. training instances hip-mdp able separate latent classes develops individualized policies each. ﬂexibility enabled embedding latent parametrization system’s state gplvm identiﬁes class current instance belongs within ﬁrst couple training episodes. total example took approximately minutes develop optimal policies task instances. place unclassiﬁed survey point left quadrant gather information policy uncertainty given latent classes. figure problem schematic outlining domain learned policy red\" parametrization learned policy blue\" parametrization uncertainty measure input point according separate latent classes. parameter learning updates deploy hip-mdp agent provided large amount batch observational data several task instances tasked quickly performing well instances. observational data transition functions learned individual weighting distributions optimized. however training number data points collected instance streamline approximation choose support points sparsely approximate full optimization procedures exist select points accurately however heuristically select points minimize maximum reconstruction error within batch using simulated annealing. control policy control policy learned task instance following procedure outlined tuples observed policy periodically updated online fashion leveraging approximate dynamics create synthetic batch data current instance. generated batch data used improve current policy double deep network variant ﬁtted-q using prioritized experience replay multiple episodes instance optimize policy completing task hidden parameter setting hyperparameters deﬁning updated learning another randomly manifest task instance. baselines benchmark hip-mdp framework domain observing agent would perform without transferring information prior patients efﬁcient development treatment policy current patient. representing ends precision medicine spectrum; one-size-ﬁts-all\" approach learns single treatment policy patients using previous patient data together \"personally tailored\" treatment plan single patient’s data used train policy. represent baselines environments model present absent treatment ernst et.al. leverage mathematical representation patient responds treatments developing approach effective treatment policies using methods introduced learned treatment policies cycle different types anti-retroviral medication sequence maximizes long-term health. perturbing underlying system parameters simulate varied patient physiologies. leverage variations gplvm augmentation hip-mdp efﬁciently learn treatment policies match naive personally tailored\" baseline reliance much less data. hip-mdp also outperforms one-size-ﬁts-all\" baseline expected. gplvm driven hip-mdp capable immediately taking advantage prior information previously learned data even face unique physiological characteristics. robust efﬁcient manner hip-mdp achieves results domain promising turn motivates inquiry generalized learning agent development individualized medical treatment plans. figure representative results applying gplvm aided hip-mdp model treatment simulator provided hip-mdp learned treatment policy matches improves naive baseline policy development strategies. quinonero candela girard murray-smith rasmussen. propagation uncertainty bayesian kernel models application multiple-step ahead time series forecasting. proceedings icassp pages deisenroth rasmussen. gaussian processes data-efﬁcient learning robotics control. ieee transactions pattern analysis machine intelligence february doshi-velez konidaris. hidden parameter markov decision processes semiparametric regression approach discovering latent task parametrizations. corr abs/. http//arxiv.org/abs/.. ernst stan goncalves wehenkel. clinical data based optimal strategies hiv; reinforcement learning approach. proceedings ieee conference decision control leen peltonen kaski. focused multi-task learning using gaussian processes. joint european conference machine learning knowledge discovery databases pages springer marivate chemali brunskill littman. quantifying uncertainty batch personalized sequential decision making. workshops twenty-eighth aaai conference artiﬁcial intelligence moore pyeatt kulkarni panousis padrez doufas. reinforcement learning closed-loop propofol anesthesia study human volunteers. journal machine learning research shortreed laber lizotte stroup pineau murphy. informing sequential clinical decision-making reinforcement learning empirical study. machine learning urtasun darrell. discriminative gaussian process latent variable model classiﬁcation. proceedings international conference machine learning pages", "year": 2016}