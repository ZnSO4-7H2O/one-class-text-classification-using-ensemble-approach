{"title": "Deep Private-Feature Extraction", "tag": ["stat.ML", "cs.CR", "cs.CV", "cs.IT", "cs.LG", "math.IT"], "abstract": "We present and evaluate Deep Private-Feature Extractor (DPFE), a deep model which is trained and evaluated based on information theoretic constraints. Using the selective exchange of information between a user's device and a service provider, DPFE enables the user to prevent certain sensitive information from being shared with a service provider, while allowing them to extract approved information using their model. We introduce and utilize the log-rank privacy, a novel measure to assess the effectiveness of DPFE in removing sensitive information and compare different models based on their accuracy-privacy tradeoff. We then implement and evaluate the performance of DPFE on smartphones to understand its complexity, resource demands, and efficiency tradeoffs. Our results on benchmark image datasets demonstrate that under moderate resource utilization, DPFE can achieve high accuracy for primary tasks while preserving the privacy of sensitive features.", "text": "abstract—we present evaluate deep private-feature extractor deep model trained evaluated based information theoretic constraints. using selective exchange information user’s device service provider dpfe enables user prevent certain sensitive information shared service provider allowing extract approved information using model. introduce utilize log-rank privacy novel measure assess effectiveness dpfe removing sensitive information compare different models based accuracy-privacy tradeoff. implement evaluate performance dpfe smartphones understand complexity resource demands efﬁciency tradeoffs. results benchmark image datasets demonstrate moderate resource utilization dpfe achieve high accuracy primary tasks preserving privacy sensitive information. inferred from browsing habits wearable devices smartphones alongside emergence data internet things devices fueling many classes applications services. include healthcare wellbeing apps ﬁnancial management services personalized content recommendations social networking tools. many systems apps rely data sensing collection user side uploading data cloud consequent analysis. many data-driven services apps potentially beneﬁcial underlying unvetted opaque data collection aggregation protocols cause excessive resource utilization importantly data security threats privacy risks collection processing private information cloud introduces number challenges tradeoffs especially scalability data collection uploading practice taken consideration. data often machine learning models extracting insights features commercial interest information exposed data brokers service providers. certain features data interest speciﬁc applications presence additional information data lead unintended subsequent privacy leakages current solutions problem cryptography complete data isolation local processing efﬁcient data techniques relying deep learning today’s data-driven ecosystem privacy challenges inherent side effect many data machine learning applications. seyed osia taheri hamid rabiee advanced innovation center department computer engineering sharif university technology iran. shahin shamsabadi kleomenis katevas school electronic engineering computer science queen mary university london. hamed haddadi faculty engineering imperial college paper focus providing privacy ﬁrst step ecosystem exchange acquired user data user service provider. propose novel solution based compromise scalability privacy. proposed framework based idea preparing data subsequent analysis service provider user need hide information means cryptographic methods resource-hungry overly complex end-user device. instead might sufﬁce remove sensitive parts information time preserving necessary information analysis. also case many surveillance applications central node required process user data sensitive aspects. proposed hybrid framework user cloud collaborate analyze user data private efﬁcient manner depicted ﬁgure work relies assumption service provider releases publicly veriﬁable feature extractor module based initial training set. user performs minimalistic analysis extracts private-feature data sends service provider subsequent analysis. private-feature analyzed cloud result yields back user. fundamental challenge using framework design feature extractor module removes sensitive information properly hand impact scalability imposing heavy computational requirements user’s device. fig. privacy concerns exist when data holder shares public dataset anonymity individuals threatened; data holders participate model training procedure private data; model provider shares publicly-learned model privacy individuals’ data used training risk; user shares his/her data service provider private information revealed service provider; service provider shares query answers user attacker infer model launching repeated queries. rest paper ﬁrst discuss privacy issues different aspects machine learning consider problem user data privacy interaction cloud services main purpose paper. design feature extractor module express privacy preservation concerns optimization problem based mutual information relax addressable deep learning. present deep private-feature extractor tool solving aforementioned relaxed problem. propose privacy measure log-rank privacy verify proposed feature extractor measure privacy evaluate efﬁciency model removing sensitive information. log-rank privacy interpreted different perspectives including entropy k-anonymity classiﬁcation error. evaluate framework facial attribute prediction problem using face images. context remove face identity information keeping facial attribute information analyze privacy-accuracy performance tradeoff. finally implement different private-feature extractors mobile phone compare performance different solutions addressing scalability concern. main contributions paper proposing hybrid user-cloud framework user data privacy preservation problem utilizes private-feature extractor core component; designing privatefeature extractor based information theoretic concepts leading optimization problem proposing deep neural network architecture solve optimization problem proposing measure evaluate privacy verify feature extractor module public dataset privacy training data crucial component learning system. collecting sharing rich datasets data mining tasks highly beneﬁcial learning community although might come privacy concerns make double-edged sword. publishing dataset satisﬁes parties preserving users’ privacy useful information data mining tasks challenging problem long line work. agrawal srikant ﬁrst address privacy concern data mining sharing generic dataset learning tasks addition considering users’ privacy. utilized randomization technique adding noise data guaranteed privacy. resulting distribution noisy data might different original distribution. reconstruct original distribution recovery method introduced paper extended agrawal utilizing method possible train learning model reconstructed data distribution original data. many works followed trend extended idea however approach faces important obstacles curse dimensionality non-robustness attacks make inefﬁcient high dimensional data side informations. k-anonymity another popular option addressing problem anonymous dataset publishing ﬁrst introduced sweeney publishing health database contains patient sensitive information favored instance k-anonymity usages. assuming data points identity documents kept private kanonymity deals transforming dataset that individual data features cannot infer among least identities. many researches presented make database k-anonymous based generalization suppression features nevertheless approach deals important challenges facing attacks although tried overcome challenges. furthermore well-suited structured databases high level features makes hard deploy type data newton published kanonymous image dataset proposing k-same algorithm. build desired dataset constructing average images among identities employed models reliable today. privacy machine learning machine learning methods need analyze sensitive data many usecases perform desired tasks violate users’ privacy. fundamental dichotomy appearing different aspects machine learning listed figure concerns classiﬁed public dataset privacy training phase privacy training data privacy model privacy user data privacy discussed rest section. training phase privacy common problem centralized learning collection training data especially dealing individual’s sensitive data people usually reluctant sharing data includes habits interests geographical positions. upcoming solution problem federated learning data holders keep data private communicate central node order train learning model cooperative manner. tried address problem using distributed stochastic gradient descent party loads latest parameters update using upload selected parameters central node holds global model. case direct leakage private data prevented uploaded gradients might still include sensitive information training data. thus differentially private algorithm required sharing gradients proposed work. approach still major problems e.g. loose privacy bound addressed potential threats generative adversarial networks addressed alternative solution problem could cryptographic techniques like secure multi-party computation recently used however techniques still applicable complex neural networks efﬁciency accuracy. training-data privacy growing popularity public learning models raises concern privacy individuals involved training dataset. differentially private algorithms brought rigorous answer problem providing method answer queries statistical database without disclosing individuals’ information formalized algorithm called differentially private conditional likelihood ratio presence absence individual given transformed statistic close one. adding noise original statistic popular method leading differential privacy. consider learning model complex statistic training data reveal information individuals. answering complex queries combining simple queries various learning models principal component analysis k-means made differentially private recently differentially private deep models proposed authors introduced privacy preservation framework utilizing differential privacy speciﬁc learning model possesses state privacy-accuracy tradeoff. model privacy model privacy concern service provider deals keeping learning model private returning inference results user. throughout years less attention paid model privacy although works studied problem. general adversary infer model parameters making many queries learning model aggregate answers. considered approach basic models e.g. logistic regression multilayer perceptron decision tree. user data privacy increasing usage cloud-based systems triggered situation preserving privacy challenging important task. user data pretrained learning model accessible place inevitably user data must sent service provider analysis. usually cryptographic schemes prevalent situations parties trust other. focusing deep models offered cloud service introduced problem proposed homomorphic encryption method execute inference directly encrypted data. even though work interesting approach problem number shortcomings makes impractical. fact approximating deep neural network degree polynomial function feasible without sacriﬁcing accuracy. furthermore complexity encryption relatively high makes inefﬁcient real-world online applications. alternative homomorphic encryption suggested used garbled circuit protocol address discussed challenges however limited employing simple neural networks high computational cost. summary using cryptographic techniques complex deep neural networks feasible problem user data privacy getting important everyday cloud computing era. paper targeting challenge address machine learning solution based speciﬁc kind feature extraction model formulated next section. problem formulation section address user data privacy challenge different manner encryption-based methods. intuition many applications remove user’s sensitive information retaining ability infer primary information. opposed encryption-based solutions encode information authorized users access instance want focus hiding individuals’ identities video surveillance system still allow count number participants. scenario trivial solution censor people’s faces frames however solution fails purpose measure facial attributes emotion gender. henceforth address problem privacy preservation problem terms primary sensitive information information needed preserved removed respectively. assuming service provider knows primary sensitive random variables abstract concept optimization problem utilizing mutual information input primary sensitive variables. would like extract feature applying function informative primary variable non-informative sensitive variable. refer extracted feature private-feature. speciﬁcally desired private-feature obtained maximizing mutual information feature primary variable minimizing mutual information feature sensitive variable follows information bottleneck optimization problem problem non-convex solved known convex optimization algorithms. overcome challenge common bound optimization problem using iterative methods similar obtain desired results. ﬁrst obtain lower upper bounds respectively maximize lower bound equation henceforth assume discrete sensitive variable order address classiﬁcation privacy problem. members parametric family distributions {q|φ right hand side equation considered lower bound mutual information. equality happens equal therefore consider rich family distributions member approximate well enough obtain tight enough lower bound mutual information maximizing right hand side equation respect utilizing deﬁnition entropy obtain desired lower bound. upper bound two-step procedure used upper bound mutual information. first lemma jensen inequality prove theorem obtain primitive upper bound kernel density estimation lemma obtain desired upper bound theorem lemma assume discrete random variable even though ﬁrst glance seems optimal solution problem equal best estimation applicable many real world applications because optimal model perfectly predicts complicated hence using feature extractor client-side impossible; service provider share whole model client reasons copyright issues. assuming accurately estimate using member family functions {g|θ optimization problem becomes optimizing mutual information widely used many information theoretic approaches machine learning problems. authors formulated infomax tried address problem unsupervised deterministic invertible feature extraction maximizing mutual information input feature. relaxed limiting invertibility constraint used variational approach leads algorithm maximizing mutual information. recently used similar method maximize mutual information generative adversarial networks. works considered fundamental works problem unsupervised feature extraction information theoretic viewpoint however since utilizing supervised approach methods cannot applied case. among works considering supervised feature extraction information bottleneck introduced relevant work. general information bottleneck provides information theoretic framework analyzing supervised feature extraction procedure. although optimization problem almost looks similar ours fundamental difference approaches. speciﬁcally instead meaning irrelevant information removed minimizing process feature extraction. therefore directly consider privacy constraints moreover optimization problem solved analytical approach assumes joint probability distribution known. however practice distribution often unavailable. although analytical method considering corollary together theorem realize random pair feature points decrease distance labels different increase distance same. similar contrastive loss idea presented popular loss function siamese architecture siamese networks used metric learning purposes tends form feature space similar points gathered near other. opposite achieve increase distance similar points decrease distance dissimilar points. since computing equation tractable approximation technique obtain upper bound. employing kernel density estimation efﬁciently estimate utilize silverman’s rule thumb gaussian kernel desired diagonal covariance matrix. next normalizing dimension feature space zero mean unit variance acquire symmetric gaussian kernel ﬁxed covariance matrix constant depending dimensionality feature space size training data. kind normalization common process machine learning impartial relations among different dimensions including independency correlation. finally conditioning think gaussian mixture model following lemmas obtain reliable upper bound. lemma multidimensional gaussian distributions expected values covariance matrix have considering equation optimize objective function consists loss functions loss primary variable preservation modeled classiﬁcation loss loss sensitive variable elimination modeled contrastive loss thus general training framework private-feature extractor contains three main modules feature extractor primary variable predictor sensitive variable remover shown figure note according second term equation loss function removing sensitive variable deﬁned pairs samples result y-remover module also operates pairs features. fig. deep architecture private-feature extraction independent random samples corresponding sensitive labels. y-remover ﬁrst checks equality sensitive labels apply information removal loss function. argue separating layers deep model sufﬁcient obtain ideal private-feature intermediate layer nature deep networks. general higher layers deep architecture provide abstract representation data drop irrelevant information including sensitive information preserve primary variable therefore need ﬁne-tune model suggested dpfe architecture. however argument easily rejected considering counter example provided deep visualization techniques. example provided method reconstruct input image intermediate layers deep network. osia et.al. used method demonstrated original face image reconstructed intermediate layers gender recognition model. thus guarantee intermediate layers drop sensitive information fig. private-feature extraction framework. primary sensitive variables respectively. independent samples corresponding features. z-predictor uses compute ﬁrst term loss function whereas y-remover uses compute second term loss function solid lines show data dotted lines indicate affection. non-convex objective functions based algorithms accurately estimate complex non-linear functions. today large portion state learning models deep. therefore general framework privacy preserving deep inference necessary. paper focus image data propose deep architecture based optimize objective function relaxed problem worth mentioning proposed framework generalized applications deep architectures call proposed deep private-feature extractor architecture; dpfe. consider consecutive cnns; feature extractor primary variable predictor. simple strategy building modules layer separation mechanism introduced also employ batch normalization layer normalize dimension feature space stated section following ﬁrst introduce layer separation mechanism proceed dimensionality reduction noise addition issues enhance preservation privacy. deploy framework start pre-trained recognizer primary variable make private sensitive variable order this choose output arbitrary intermediate layer pre-trained model preliminary private-feature simply partition layers model sets elementary secondary layers form feature extractor primary variable predictor respectively. model easily ﬁne-tuned appending contrastive loss function continuing optimization process leading private-feature intermediate layer’s output. procedure shown fig. leads following deﬁnition dividing formulas order normalized measure zero one. deﬁnition log-rank privacy discrete sensitive variable given observed feature vector deﬁned -questions game interpretation. consider questions game want guess unknown object asking yes/no questions oracle. stated entropy equivalent minimum number questions could order correct answer. consider situation cannot kind yes/no questions questions guess candidate ﬁnal answer e.g. answer chair?’. also assume guess correct answer questions would penalized wrong guesses punished beginning. evidently optimal strategy minimum expected penalty guess objects order probabilities. using strategy expected penalty would equal log-rank privacy. k-anonymity expected rank. k-anonymity deals number entities equally uncertain about. expected rank considered soft interpretation number relaxing equal uncertainty weighted ranks. thus rank variable expectation thought expected number entities doubt about. classiﬁcation error extension. could suggest using classiﬁcation error privacy measure represents deﬁciency classiﬁer. using measure equal considering zero penalty correct wrong guesses ﬁrst question respectively. thus situations correct label nevertheless potential disadvantage dimensionality reduction negatively affect accuracy primary variable prediction. however show experiments adverse effect dimensionality reduction negligible. reducing dimensionality done preprocessing step pre-trained network. fact choosing intermediate layer ﬁrst execute following operations embed auto-encoder dimensional hidden layer chosen layer; fine-tune model obtain primary variable predictor choose auto-encoder’s hidden layer intermediate layer dimensional. consequently ﬁne-tune model dpfe architecture dimensional private-feature. noise addition mentioned earlier many privacy preservation methods randomization technique differentially private algorithms rely noise addition gain privacy increases uncertainty. utilize technique ﬁnishing training procedure test phase dimensionality reduction employed granularity sensitive variable ﬁner primary variable adding noise private-feature smooth conditional distributions primary sensitive variables form tradeoff privacy accuracy tradeoff helpful real world applications choose desired point privacy-accuracy curve based importance privacy accuracy speciﬁc application. discuss tradeoff detail section privacy measure section propose method evaluating quality privacy algorithms. considering problem formulation mutual information suggest negative mutual information extracted private-feature sensitive variable privacy measure. since constant approach equivalent considering privacy measure. however measure shortcomings difﬁcult obtain efﬁcient estimation intuitive interpretation measure privacy. order resolve problems relax deﬁnition uncertainty. achieve partitioning conditional probabilities rank order build lower bound conditional entropy attribute prediction model intermediate layer size output attribute linear auto-encoder input/output size hidden layer initialize weights output embed ﬁne-tune identity ﬁne-tune dpfe architecture second tenth question considered equal penalized one. log-rank privacy handles issue penalizing different questions using ranks’ logarithm considered extension classiﬁcation error. sensitivity analysis. empirically approximating expected value drawing samples probability distribution common method machine learning comparing empirical estimation log-rank privacy entropy need estimate order probabilities former exact values probabilities needed later. general approximating log-rank privacy less sensitive error density estimation gain lower variance. detailed sensitivity analysis scope paper considered future work. evaluation section evaluate proposed private-feature extractor considering problem facial attribute prediction. face image input infer facial attributes gender expression supervised manner. extract feature facial attribute prediction time non-informative respect identity person experiments used celeba face dataset presented includes binary facial attributes gender smiling corresponding identity labels. following ﬁrst explain experiment setting discuss results. evaluations used layer separation mechanism followed dimensionality reduction noise addition. selected state pre-trained facial attribute prediction model presented called original model. then chose attribute preserve information private-feature. next selected intermediate layer chosen network. since layer also high dimensional tensor embeded linear auto-encoder applied batch normalization hidden layer obtain normalized intermediate features. finally ﬁne-tuning network attribute prediction model dimensional intermediate feature refer simple model rest paper. lowdimensional feature preserves information attributes necessarily omit sensitive information. hence ﬁne-tune network proposed dpfe architecture remove identity information intermediate features. refer model dpfe model. steps depicted procedure implemented models caffe framework utilizing adam optimizer contrastive loss function. accuracy facial attribute prediction achieving higher accuracy implies primary variable information well preserved. identity privacy evaluate privacy feature extractor using different measures. first log-rank privacy measure introduced section second utilize identity classiﬁer consider misclassiﬁcation rate must high order preserve privacy demonstrate higher layers deep network reliable. show generality proposed method consider four different intermediate layers together attribute sets results twenty simple twenty dpfe models. {gender} {gender age} {gender smiling} gasl {gender smiling lips} gasln {gender smiling lips nose} follows ﬁrst explain accuracy-privacy tradeoff based log-rank privacy measure misclassiﬁcation rate present visualization result ﬁnally address complexity issue private-feature extractor implementing proposed framework smartphone order adjust accuracy-privacy trade-off used noise addition mechanism. training phase estimate covariance matrix feature space scale different ratios covariance matrix gaussian noise. increasing amount noise accuracy primary variable prediction decreases privacy sensitive variable increases. result build accuracy-privacy trade-off curves manner similar trade-off rate-distortion theory evaluation steps shown procedure accuracy-privacy curves different models compared based following deﬁnition. deﬁnition models preserve privacy sensitive variable maintain accuracy primary variable always results higher value privacy ﬁxed value accuracy acc-priv superior. considering equation seems relative importance accuracy privacy controlled changing values parameter however feasible practice challenges training stage. example training constant consequent noise addition mechanism possible different accuracyprivacy strategies utilizing single trained model. case various models considering different values used cross validation order choose suitable ﬁxed value experiments. computed accuracy-privacy trade-off test data identities. setting noise zero intermediate layers attribute sets simple dpfe models reached accuracy level original model error margin less therefore conclude simple dpfe models preserve facial attribute information concentrate effect dpfe ﬁne-tuning. order verify superiority dpfe ﬁne-tuning simple ﬁne-tuning compared accuracy-privacy curve different models ﬁne-tuned dpfe simple architectures. figure shows results combination layers attribute sets different privacy measures. cases dpfe models acc-priv superiority simple models. words ﬁxed value accuracy dpfe consistently achieves higher levels privacy. effect higher layers. comparison accuracyprivacy curves different layers attribute depicted figure results illustrate acc-priv superiority higher layers attribute sets privacy measures. observation inline earlier assumptions higher layers. effect attribute extension. accuracy-privacy dpfe ﬁne-tuned models different trade-off attribute sets conv intermediate layer shown ﬁgure results show enlarge attribute restrict model preserving information preserving privacy becomes challenging intrinsic correlation identity facial attributes. guaranteeing privacy. discussed section instead log-rank could also consider rank analyzing mean variance. idea depicted ﬁgure simple dpfe models. results show dpfe model acc-priv superiority simple model. importantly forces conditional distribution sensitive variable converge uniform distribution least rank-mean standard deviation sense. fact mean standard deviation rank measure discrete uniform distribution respectively. shown ﬁgure privacy increased statistics dpfe model converge corresponding values uniform distribution. consider normal distribution rank variable provide privacy guarantee similar method used differential privacy example depicted ﬁgure achieve gender accuracy rank-mean standard deviation hence probability claim rank-privacy greater achieved anonymity. visualization visualization method understanding behavior deep networks. provides insightful intuition information different layers. used auto-encoder objective visualization technique validate sensitive information removal dpfe. reconstruction images done feeding privatefeature alexnet decoder proposed therefore visually verify identity removal property private-feature comparing original reconstructed case dpfe models. therefore relying output higher layers original model assure acceptable privacy preservation performance dpfe models assure privacy identities. regarding accuracy observe detect facial attributes models. complexity efﬁciency although higher intermediate layers achieve better accuracy-privacy trade-off cases lowpower devices smartphones computational complexity acceptable. therefore limited resources devices privacy-complexity trade-off results analyzed aspects accuracy desired attributes privacy identities. privacy perspective identity people reconstructed images original model readily observed last layers analyzing complexity different layers lead considering accuracy-privacy-complexity trade-offs. example consider figure suppose want preserve gender information. comparing conv conv- setting accuracy obtain log-rank privacy cost inference time. choose right strategy based importance accuracy privacy complexity. also using dimensionality reduction highly decrease communication cost although case consider effect dimensionality reduction complexity negligible. conclude algorithm implemented modern smartphone. choosing proper privacycomplexity trade-off using different intermediate layers able signiﬁcantly reduce cost running model mobile device time preserving important user information uploaded cloud. conclusion future work paper proposed hybrid framework user data privacy preservation. framework consists feature extractor analyzer module. feature extractor provides user private-feature contains user’s desired sensitive information still maintains required information service provider used analyzer module cloud. order design feature extractor used information theoretic approach formulate optimization problem proposed novel deep architecture solve measure privacy extracted private-feature verify feature extractor proposed privacy measure called log-rank privacy. finally considered problem facial attribute prediction face image attempted extract feature contains facial attributes information contain identity information. using dpfe ﬁne-tuning implementing model mobile phone showed achieve reasonable tradeoff facial attribute prediction accuracy identity privacy computational efﬁciency. work extended number ways. used proposed framework image processing application used learning applications e.g. speech text analysis extended deep architectures e.g. recurrent neural networks. formulated problem discrete sensitive variables extended general cases. analyzing log-rank privacy measure also many potential applications privacy domain. interesting future direction could involving log-rank privacy design learning rank algorithms. ongoing work considering challenge privacy machine learning-as-a-service platform. also considered. order address problem evaluated original architecture without dimensionality reduction smartphone measured complexity different layers. results shown ﬁgure gradually reducing complexity private-feature extractor also managed reduce inference time memory usage hiding user’s sensitive information. evaluated proposed implementation modern handset device shown table evaluated intermediate layers cumulatively compared on-premise solution used caffe mobile android load model measured inference time model memory usage conﬁgurations. conﬁgured model core device’s experiment comparison different conﬁgurations speciﬁc device. results show large increase inference time memory loading on-premise solution increased size model proving efﬁciency solution. speciﬁcally considering layer conv baseline experienced inference time memory usage increase conv inference time memory usage increase conv inference time memory usage increase conv inference time memory usage increase layers usage also increases conﬁguration however multitasking nature android device challenging isolate usage single process naturally results ﬂuctuates. moreover lower intermediate layers signiﬁcantly reduce complexity privatefeature extractors especially dealing implementing complex deep architectures e.g. vgg- edge devices smartphones fig. visualization different layers different models bottom rows show input images reconstructed images original model reconstructed images dpfe model. second shows separating layers deep model relying speciﬁcity higher layers provide identity privacy. references vallina-rodriguez shah finamore grunenberger papagiannaki haddadi crowcroft breaking commercials characterizing mobile advertising proceedings internet measurement conference. acquisti brandimarte loewenstein privacy human behavior information science vol. garcia lopez montresor epema datta higashino iamnitchi barcellos felber riviere edge-centric computing vision challenges sigcomm computer communication review vol. osia shamsabadi taheri rabiee lane haddadi hybrid deep learning architecture privacypreserving mobile analytics arxiv preprint arxiv. agrawal srikant privacy-preserving data mining rebollo-monedero forne domingo-ferrer from tcloseness-like privacy postrandomization information theory ieee transactions knowledge data engineering vol. papernot abadi erlingsson goodfellow talwar semi-supervised knowledge transfer deep learning private training data proceedings international conference learning representations hitaj ateniese p´erez-cruz deep models information leakage collaborative deep learning proceedings sigsac conference computer communications security. abadi goodfellow mcmahan mironov talwar zhang deep learning differential privacy proceedings sigsac conference computer communications security. gilad-bachrach dowlin laine lauter naehrig wernsing cryptonets applying neural networks encrypted data high throughput accuracy international conference machine learning barber agakov algorithm variational approach information maximization proceedings international conference neural information processing systems. press chen duan houthooft schulman sutskever abbeel infogan interpretable representation learning information maximizing generative adversarial nets neural information processing systems duong hazelton convergence rates unconstrained bandwidth matrix selectors multivariate kernel density estimation journal multivariate analysis vol. hershey olsen approximating kullback leibler divergence gaussian mixture models ieee international conference acoustics speech signal processing iv–. chopra hadsell lecun learning similarity metric discriminatively application face veriﬁcation ieee conference computer vision pattern recognition ioffe szegedy batch normalization accelerating deep network training reducing internal covariate shift international conference machine learning malekzadeh clegg haddadi replacement autoencoder privacy-preserving algorithm sensory data analysis acm/ieee international conference internetof-things design implementation rudd ¨unther boult moon mixed objective optimization network recognition facial attributes european conference computer vision. springer shelhamer donahue karayev long girshick guadarrama darrell caffe convolutional architecture fast feature embedding arxiv preprint arxiv. y.-d. park choi yang shin compression deep convolutional neural networks fast power mobile applications arxiv preprint arxiv. haykin neural networks learning machines. pearson upper quantizing intuitive concepts like uncertainty information main information theory advantages. part brieﬂy discuss phenomenons refer readers detailed discussion shahin shamsabadi received b.s. degree electrical engineering shiraz university technology m.sc. degree electrical engineering sharif university technology currently ph.d. candidate queen mary university london. research interests include deep learning data privacy protection distributed centralized learning. kleomenis katevas received b.sc. degree informatics engineering university applied sciences thessaloniki m.sc. degree software engineering queen mary university london currently ph.d. candidate queen mary university london. research interests includes mobile ubiquitous computing applied machine learning crowd sensing humancomputer interaction. seyed osia received b.sc. degree software engineering sharif university technology currently ph.d. candidate department computer engineering sharif university technology. research interests includes statistical machine learning deep learning privacy computer vision. taheri received b.sc. degree software engineering shahid beheshti university received m.sc. degree artiﬁcial intelligence sharif university technology research interests includes deep learning privacy. hamed haddadi received b.eng. m.sc. ph.d. degrees university college london. postdoctoral researcher planck institute software systems germany postdoctoral research fellow department pharmacology university cambridge royal veterinary college university london followed years lecturer consequently senior lecturer digital media queen mary university london. currently senior lecturer deputy director research dyson school design engineering academic fellow data science institute faculty engineering imperial college london. interested user-centered systems applied machine learning data security privacy. enjoys designing building systems enable better digital footprint respecting users’ privacy. also broadly interested sensing applications human-data interaction. hamid rabiee received b.s. m.s. degrees electrical engineering california state university long beach respectively; degree electrical computer engineering university southern california angeles ph.d. degree electrical computer engineering purdue university west lafayette member technical staff at&t bell laboratories. worked senior software engineer intel corporation. adjunct professor electrical computer engineering portland state university portland oregon graduate institute beaverton oregon state university corvallis since september department computer engineering sharif university technology tehran iran professor computer engineering director sharif university advanced information communication technology research institute digital media laboratory mobile value added services laboratory also founder aict advanced technologies incubator vasl. currently sabbatical leave visiting professor imperial college london. initiator director national international-level projects context united nation open source network program iran national development plan. received numerous awards honors industrial scientiﬁc academic contributions. senior member ieee holds three patents. also initiated number successful start-up companies cloud computing storage systems data analytics. research interests include statistical machine learning bayesian statistics data analytics complex networks applications multimedia systems social networks cloud data privacy bioinformatics brain networks.", "year": 2018}