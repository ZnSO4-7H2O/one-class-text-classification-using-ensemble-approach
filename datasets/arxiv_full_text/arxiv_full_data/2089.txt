{"title": "Overcoming catastrophic forgetting in neural networks", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 2600 games sequentially.", "text": "ability learn tasks sequential fashion crucial development artiﬁcial intelligence. neural networks general capable widely thought catastrophic forgetting inevitable feature connectionist models. show possible overcome limitation train networks maintain expertise tasks experienced long time. approach remembers tasks selectively slowing learning weights important tasks. demonstrate approach scalable effective solving classiﬁcation tasks based mnist hand written digit dataset learning several atari games sequentially. achieving artiﬁcial general intelligence requires agents able learn remember many different tasks legg hutter particularly difﬁcult real-world settings sequence tasks explicitly labelled tasks switch unpredictably individual task recur long time intervals. critically therefore intelligent agents must demonstrate capacity continual learning ability learn consecutive tasks without forgetting perform previously trained tasks. continual learning poses particular challenges artiﬁcial neural networks tendency knowledge previously learnt task abruptly lost information relevant current task incorporated. phenomenon termed catastrophic forgetting occurs speciﬁcally network trained sequentially multiple tasks weights network important task changed meet objectives task whilst recent advances machine learning particular deep neural networks resulted impressive gains performance across variety domains little progress made achieving continual learning. current approaches typically ensured data tasks simultaneously available training. interleaving data multiple tasks learning forgetting occur weights network jointly optimized performance tasks. regime—often referred multitask learning paradigm—deep learning techniques used train single agents successfully play multiple atari games tasks presented sequentially multitask learning used data recorded episodic memory system replayed network training. approach impractical learning large numbers tasks setting would require amount memories stored replayed proportional number tasks. lack algorithms support continual learning thus remains barrier development artiﬁcial general intelligence. marked contrast artiﬁcial neural networks humans animals appear able learn continual fashion recent evidence suggests mammalian brain avoid catastrophic forgetting protecting previously-acquired knowledge neocortical circuits mouse acquires skill proportion excitatory synapses strengthened; manifests increase volume individual dendritic spines neurons critically enlarged dendritic spines persist despite subsequent learning tasks accounting retention performance several months later spines selectively erased corresponding skill forgotten provides causal evidence neural mechanisms supporting protection strengthened synapses critical retention task performance. together experimental ﬁndings—together neurobiological models —suggest continual learning mammalian neocortex relies process task-speciﬁc synaptic consolidation whereby knowledge perform previously acquired task durably encoded proportion synapses rendered less plastic therefore stable long timescales. work demonstrate task-speciﬁc synaptic consolidation offers novel solution continual learning problem artiﬁcial intelligence. develop algorithm analogous synaptic consolidation artiﬁcial neural networks refer elastic weight consolidation algorithm slows learning certain weights based important previously seen tasks. show used supervised learning reinforcement learning problems train several tasks sequentially without forgetting older ones marked contrast previous deep-learning techniques. brains synaptic consolidation enables continual learning reducing plasticity synapses vital previously learned tasks. implement algorithm performs similar operation artiﬁcial neural networks constraining important parameters stay close values. section explain expect solution task neighbourhood older implement constraint ﬁnally determine parameters important. deep neural network consists multiple layers linear projection followed element-wise non-linearities. learning task consists adjusting weights biases linear projections optimize performance. many conﬁgurations result performance relevant over-parameterization makes likely solution task learning task therefore protects performance task constraining parameters stay region error task centered around shown schematically figure constraint implemented quadratic penalty therefore imagined spring anchoring parameters previous solution hence name elastic. importantly stiffness spring parameters; rather greater parameters matter performance task order justify choice constraint deﬁne weights important task useful consider neural network training probabilistic perspective. point view optimizing parameters tantamount ﬁnding probable values given data compute conditional probability prior probability parameters probability data using bayes’ rule note probability data given parameters simply negative loss function problem hand assume data split independent parts deﬁning task task then re-arrange equation figure elastic weight consolidation ensures task remembered whilst training task training trajectories illustrated schematic parameter space parameter regions leading good performance task task learning ﬁrst task parameters take gradient steps according task alone minimize loss task destroy learnt task hand constrain weight coefﬁcient restriction imposed severe remember task expense learning task conversely ﬁnds solution task without incurring signiﬁcant loss task explicitly computing important weights task information task must therefore absorbed posterior distribution posterior probability must contain information parameters important task therefore implementing ewc. true posterior probability intractable following work laplace approximation mackay approximate posterior gaussian distribution mean given parameters diagonal precision given diagonal fisher information matrix three properties equivalent second derivative loss near minimum computed ﬁrst-order derivatives alone thus easy calculate even large models guaranteed positive semi-deﬁnite. note approach similar expectation propagation subtask seen factor posterior given approximation function minimize loss task only sets important task compared labels parameter. moving third task task keep network parameters close learned parameters task enforced either separate penalties noting quadratic penalties quadratic penalty. start addressing problem whether elastic weight consolidation could allow deep neural networks learn complex tasks without catastrophic forgetting. particular trained fully connected multilayer neural network several supervised learning tasks sequence. within task trained neural network traditional namely shufﬂing data processing small batches. ﬁxed amount training task however allowed training task’s dataset. constructed tasks problem classifying hand written digits mnist dataset according scheme previously used continual learning literature task generated ﬁxed random permutation input pixels images would shufﬂed. task thus equal difﬁculty original mnist problem though different solution would required each. detailed description settings used found appendix training sequence tasks plain stochastic gradient descent incurs catastrophic forgetting demonstrated figure blue curves show performance testing sets different tasks. point training regime switches training ﬁrst task training second performance task falls rapidly task climbs steeply. forgetting task compounds training time addition figure results permuted mnist task. training curves three random permutations using regularization plain sgd. note capable mantaining high performance tasks retaining ability learn tasks. average performance across tasks using dropout regularization dashed line shows performance single task only. similarity fisher information matrices function network depth different amounts permutation. either small square pixels middle image permuted large square pixels permuted note different tasks smaller overlap fisher information matrices early layers. subsequent tasks. problem cannot countered regularizing network ﬁxed quadratic constraint weight here performance task degrades much less severely task cannot learned properly constraint protects weights equally leaving little spare capacity learning however thus take account important weight task network learn task well without forgetting task exactly expected behaviour described diagrammatically figure previous attempts solve continual learning problem deep neural networks relied upon careful choice network hyperparameters together standard regularization methods order mitigate catastrophic forgetting. however task achieved reasonable results random permutations using similar cross-validated hyperparameter search compared traditional dropout regularization ewc. stochastic gradient descent dropout regularization alone limited scale tasks contrast allows large number tasks learned sequence modest growth error rates. given allows network effectively squeeze functionality network ﬁxed capacity might whether allocates completely separate parts network task whether capacity used efﬁcient fashion sharing representation. assess this determined whether task depends sets weights measuring overlap pairs tasks’ respective fisher information matrices small overlap means tasks depend different sets weights large overlap indicates weights used tasks figure shows overlap function depth. simple control network trained tasks similar tasks depend similar sets weights throughout whole network tasks dissimilar other network begins allocate separate capacity tasks nevertheless even large permutations layers network closer output indeed reused tasks. reﬂects fact permutations make input domain different output domain shared. next tested whether elastic weight consolidation could support continual learning demanding reinforcement learning domain. agents dynamically interact environment order develop policy maximizes cumulative future reward. asked whether deep networks architecture achieved impressive successes challenging settings —could harnessed successfully support continual learning classic atari task speciﬁcally experiment consisted games chosen randomly played human level dqn. training time agent exposed experiences game extended periods time. order presentation games randomized allowed returning games several times. regular intervals would also test agent’s score games without allowing agent train notably previous reinforcement learning approaches continual learning either relied either adding capacity network learning task separate networks used train single network play games. contrast approach presented makes single network ﬁxed resources minimal computational overhead. addition using protect previously-acquired knowledge used domain address broader requirements needed successful continual learning systems particular higher-level mechanisms needed infer task currently performed detect incorporate novel tasks encountered allow rapid ﬂexible switching tasks primate brain prefrontal cortex widely viewed supporting capabilities sustaining neural representations task context exert topgating inﬂuences sensory processing working memory action selection lower-level regions inspired evidence used agent similar described differences network parameters smaller transition table task-speciﬁc bias gains layer full action atari task-recognition model penalty. full details hyper-parameters described appendix appatari. brieﬂy describe important modiﬁcations agent task-recognition module implementation penalty. treat task context latent variable hidden markov model. task therefore associated underlying generative model observations. main distinguishing feature approach allow addition generative models explain recent data better existing pool models using training procedure inspired forget process order apply compute fisher information matrix task switch. task penalty added anchor point given current value parameters weights given fisher information matrix times scaling factor optimized hyperparameter search. added penalty games experienced least million frames. also allowed agents maintain separate short-term memory buffers inferred task allow action values task learned off-policy using experience replay mechanism such overall system memory time-scales short time-scales experience replay mechanism allows learning based interleaved uncorrelated experiences longer time scales know-how across tasks consolidated using ewc. finally allowed small number network parameters game-speciﬁc rather shared across games. particular allowed layer network biases element multiplicative gains speciﬁc game. compare performance agents ones sets games figure measure performance total human-normalized score across games. average across random seeds choice games played also clip human-normalized score game measure performance therefore number maximum means agent good random agent. rely plain gradient descent methods agent never learns play game harm inﬂicted forgetting games means total human-normalized score remains one. using however agents indeed learn play multiple games. control also considered beneﬁt agent explicitly provided agent true task label rather relying learned task recognition algorithm improvement modest. figure results atari task. schedule games. black bars indicate sequential training periods game. training segment performance games measured. constraint activated protect agent’s performance game agent experienced million frames game. total scores method across games. curve denotes network infers task labels using forget algorithm; brown curve network provided task labels. curves start diverging games start played protected ewc. sensitivity single-game trained breakout noise added weights. performance breakout shown function magnitude weight perturbation. weight perturbation drawn zero mean gaussian covariance either uniform inverse fisher blue; i.e. mimicking weight changes allowed ewc) uniform within nullspace fisher evaluate score agent full game episodes drawing random weight perturbation every timestep. augmenting agent allows learn many games sequence without suffering catastrophic forgetting reach score would obtained training separate dqns possible reason consolidated weights game based tractable approximation parameter uncertainty fisher information. therefore sought test quality estimates empirically. trained agent single game measured perturbing network parameters affected agent’s score. regardless game agent trained observed patterns shown figure first agent always robust parameter perturbations shaped inverse diagonal fisher information opposed uniform perturbations validates diagonal fisher good estimate important certain parameter within approximation perturbing nullspace effect performance performance. empirically however observe perturbing space effect perturbing inverse fisher space. suggests over-conﬁdent certain parameters unimportant therefore likely chief limitation current implementation under-estimates parameter uncertainty. present novel algorithm elastic weight consolidation addresses signiﬁcant problem continual learning poses neural networks. allows knowledge previous tasks protected learning thereby avoiding catastrophic forgetting abilities. selectively decreasing plasticity weights thus parallels neurobiological models synaptic consolidation. implement soft quadratic constraint whereby weight pulled back towards values amount proportional importance performance previously-learnt tasks. extent tasks share structure networks trained reuse shared components network. show effectively combined deep neural networks support continual learning challenging reinforcement learning scenarios atari games. algorithm grounded bayesian approaches learning. formally task learnt network parameters tempered prior posterior distribution parameters given data previous task. enables fast learning rates parameters poorly constrained previous tasks slow learning rates crucial. previous work using quadratic penalty approximate parts dataset applications limited small models. speciﬁcally used random inputs compute quadratic approximation energy surface. approach slow requires re-computing curvature sample. ella algorithm described requires computing inverting matrices dimensionality equal number parameters optimized therefore mainly applied linear logistic regressions. contrast time linear number parameters number training examples. could achieve computational complexity making several simpliﬁcations notably approximating posterior distribution parameters task factorized gaussian computing variance using point-estimate parameters diagonal fisher information matrix. despite computational cost empirical successes—even setting challenging domains—our point estimate posterior’s variance constitute signiﬁcant weakness initial explorations suggest might improve local estimate using bayesian neural networks paper primarily focused building algorithm neurobiological observations also instructive consider whether algorithm’s successes feed back understanding brain. particular considerable parallels computational theories synaptic plasticity. respect perspective offer aligns recent proposal synapse stores current weight also implicit representation uncertainty weight idea grounded observations post-synaptic potentials highly variable amplitude synapses variable amenable potentiation depression explore computational beneﬁts sampling posterior here work aligns notion weight uncertainty inform learning rates. take step further emphasize consolidating high precision weights enables continual learning long time scales. three values stored synapse weight itself variance mean. interestingly synapses brain also carry piece information. example state short-term plasticity could carry information variance weight early phase plasticity could encode current synaptic strength whereas weight associated late-phase plasticity consolidated phase could encode mean weight. ability learn tasks succession without forgetting core component biological artiﬁcial intelligence. work show algorithm supports continual learning—which takes inspiration neurobiological models synaptic consolidation—can combined deep neural networks achieve successful performance range challenging domains. demonstrate current neurobiological theories concerning synaptic consolidation indeed scale large-scale learning systems. provides prima facie evidence principles fundamental aspects learning memory brain. acknowledgements. would like thank dayan wierstra mohamed whye kavukcuoglu.", "year": 2016}