{"title": "Recurrent Neural Networks for Multivariate Time Series with Missing  Values", "tag": ["cs.LG", "cs.NE", "stat.ML"], "abstract": "Multivariate time series data in practical applications, such as health care, geoscience, and biology, are characterized by a variety of missing values. In time series prediction and other related tasks, it has been noted that missing values and their missing patterns are often correlated with the target labels, a.k.a., informative missingness. There is very limited work on exploiting the missing patterns for effective imputation and improving prediction performance. In this paper, we develop novel deep learning models, namely GRU-D, as one of the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e., masking and time interval, and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve better prediction results. Experiments of time series classification tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic datasets demonstrate that our models achieve state-of-the-art performance and provides useful insights for better understanding and utilization of missing values in time series analysis.", "text": "multivariate time series data practical applications health care geoscience biology characterized variety missing values. time series prediction related tasks noted missing values missing patterns often correlated target labels a.k.a. informative missingness. limited work exploiting missing patterns effective imputation improving prediction performance. paper develop novel deep learning models namely gru-d early attempts. gru-d based gated recurrent unit state-of-the-art recurrent neural network. takes representations missing patterns i.e. masking time interval effectively incorporates deep model architecture captures long-term temporal dependencies time series also utilizes missing patterns achieve better prediction results. experiments time series classiﬁcation tasks real-world clinical datasets synthetic datasets demonstrate models achieve state-of-the-art performance provides useful insights better understanding utilization missing values time series analysis. multivariate time series data ubiquitous many practical applications ranging health care geoscience astronomy biology others. often inevitably carry missing observations various reasons medical events saving costs anomalies inconvenience noted missing values usually informative missingness i.e. missing values patterns provide rich information target labels supervised learning tasks illustrate idea show examples mimic-iii real world health care dataset figure plot pearson correlation coefﬁcient variable missing rates indicates often variable missing time series labels interests mortality icd- diagnoses. observe missing rate correlated labels missing rates rate values usually highly correlated labels. ﬁndings demonstrate usefulness missingness patterns solving prediction task. past decades various approaches developed address missing values time series simple solution omit missing data perform analysis observed data. variety methods developed missing values smoothing interpolation spectral analysis kernel methods multiple imputation figure demonstrations informative missingness mimic-iii dataset. left ﬁgure shows variable missing rate middle/right ﬁgures respectively shows correlations missing rate mortality/icd- diagnosis categories please refer appendix details. algorithm schafer graham references therein provide excellent reviews related solutions. however solutions often result twostep process imputations disparate prediction models missing patterns effectively explored thus leading suboptimal analyses predictions meantime recurrent neural networks long short-term memory gated recurrent unit shown achieve state-of-the-art results many applications time series sequential data including machine translation speech recognition rnns enjoy several nice properties strong prediction performance well ability capture long-term temporal dependencies variable-length observations. rnns missing data studied earlier works applied speech recognition blood-glucose prediction. recent works tried handle missingness rnns concatenating missing entries timestamps input performing simple imputations. however works systematically model missing patterns time series classiﬁcation problems. exploiting power rnns along informativeness missing patterns promising venue effectively model multivariate time series main motivation behind work. paper develop novel deep learning model based namely gru-d effectively exploit representations informative missingness patterns i.e. masking time interval. masking informs model inputs observed time interval encapsulates input observation patterns. model captures observations dependencies applying masking time interval inputs network states jointly train model components using back-propagation. thus model captures long-term temporal dependencies time series observations also utilizes missing patterns improve prediction results. empirical experiments real-world clinical datasets well synthetic datasets demonstrate proposed model outperforms strong deep learning models built imputation well strong baselines. experiments show proposed method suitable many time series classiﬁcation problems missing data particular readily applicable predictive tasks emerging health care applications. moreover method provides useful insights general research challenges time series analysis missing data beyond classiﬁcation tasks including general deep learning framework handle time series missing data effective solutions characterize missing patterns missing-completely-at-random time series data modeling masking time interval insightful approach study impact variable missingness prediction labels decay analysis. models time series missing variables denote multivariate time series variables length rt×d represents t-th observations variables denotes measurement d-th variable denote time-stamp t-th observation obtained assume ﬁrst observation made time investigate recurrent neural networks time-series classiﬁcation recursive formulation allow handle variable-length sequences naturally. moreover shares parameters across time steps greatly reduces total number parameters need learn. among different variants speciﬁcally consider gated recurrent units similar discussion convolutions also valid models lstm matrices vectors model parameters. element-wise sigmoid function element-wise multiplication. formulation assumes variables observed. sigmoid soft-max layer applied output layer last time step classiﬁcation task. existing work handling missing values lead three possible solutions modiﬁcation network structure. straightforward approach simply replacing missing observation mean variable across training examples. context last time d-th variable observed. instead explicitly imputing missing values third approach simply indicates variables missing long missing part input concatenating measurement masking time interval vectors either equation later refer approach gru-simple. approaches solve missing value issue certain extent however known imputing missing value mean forward imputation cannot distinguish whether missing values imputed truly observed. simply concatenating masking time interval vectors fails exploit temporal structure missing values. thus none fully utilize missingness data achieve desirable performance. fundamentally address issue missing values time series notice important properties missing values time series especially health care domain first value missing variable tend close default value last observation happens long time ago. property usually exists health care data human body homeostasis mechanisms considered critical disease diagnosis treatment second inﬂuence input variables fade away time variable missing while. example medical feature electronic health records signiﬁcant certain temporal context therefore propose gru-based model called gru-d decay mechanism designed input variables hidden states capture aforementioned properties. introduce decay rates model control decay mechanism considering following important factors. first input variable health care time series medical meaning importance. decay rates ﬂexible differ variable variable based underlying properties associated variables. second lots missing patterns informative prediction tasks decay rate indicative patterns beneﬁts prediction tasks. furthermore since missing patterns unknown possibly complex learning decay rates training data rather ﬁxed priori. model vector decay rates exp{− model parameters train jointly parameters gru. chose exponentiated negative rectiﬁer order keep decay rate monotonically decreasing reasonable range note formulations sigmoid function used instead long resulting decay monotonic range. proposed gru-d model incorporates different trainable decays utilize missingness directly input feature values implicitly states. first missing variable input decay decay time toward empirical mean instead using last observation assumption trainable decay scheme readily applied measurement vector last observation d-th variable empirical mean d-th variable. decaying input variable directly constrain diagonal effectively makes decay rate variable independent others. sometimes input decay fully capture missing patterns since missingness information figure plots input decay histrograms hidden state decay variables gru-d model predicting mortality physionet dataset. variables green measurements; variables vital signs; refers missing rate. represented decayed input values. order capture richer knowledge missingness also hidden state decay gru-d. intuitively effect decaying extracted features rather input variables directly. implemented decaying previous hidden state computing hidden state respectively updated equation parameters masking vector validate gru-d model demonstrate utilizes informative missing patterns figure show input decay plots hidden decay histograms variables predicting mortality physionet dataset. input decay notice decay rate almost constant majority variables. however variables large decay means model relies less previous observations prediction. example changes variable values weight arterial temperature respiration rate known impact patients health condition. hidden decay histograms show distribution decay parameters related variable. noticed parameters related variables smaller missing rate spread out. indicates missingness variables impact decaying keeping hidden states models. notice decay term generalized lstm straightforwardly. practical applications missing values time series contain useful information variety ways. better model ﬂexibility capture different missing patterns. order demonstrate capacity gru-d model discuss model variations appendix demonstrate performance proposed models synthetic real-world health-care datasets compare several strong machine learning deep learning approaches classiﬁcation tasks. evaluate models different settings early prediction different training sizes investigate impact informative missingness. gesture phase segmentation dataset dataset multivariate time series features regularly sampled missing values different gesticulations. extracted time series generate synthetic datasets purpose understanding model behaviors different missing patterns. treat multi-class classiﬁcation task. physionet challenge dataset dataset physionet challenge publicly available collection multivariate clinical time series intensive care unit records. record multivariate time series roughly hours contains variables albumin heart-rate glucose etc. used training subset experiments since outcomes publicly available subset. conduct following prediction tasks dataset mortality task predict whether patient dies hospital. patients positive mortality label. treat binary classiﬁcation problem. tasks predict tasks in-hospital mortality length-of-stay less days whether patient cardiac condition whether patient recovering surgery. treat multi-task classiﬁcation problem. mimic-iii dataset public dataset deidentiﬁed clinical care data collected beth israel deaconess medical center contains hospital admission records. extracted time series features admission records modalities including input-events output-events lab-events prescription-events modalities known extremely useful monitoring patients. ﬁrst hours data admission time series. perform following predictive tasks mortality task predict whether patient dies hospital hours. patients positive mortality label perform binary classiﬁcation. icd- code tasks predict icd- diagnosis categories admission. treat multi-task classiﬁcation problem. non-rnn baselines evaluate logistic regression support vector machines random forest widely used health care applications. baselines take gru-mean gru-forward gru-simple lstm-mean recently models explored modeling diseases patient diagnosis health care domain using data. methods systematically handle missing values data equivalent baselines. provide detailed discussions comparisons appendix a... non-rnn baselines cannot handle missing data directly. carefully design experiments nonrnn models capture informative missingness much possible fair comparison methods. since non-rnn models work ﬁxed length inputs regularly sample time-series data ﬁxed length input perform imputation missing values. similar baselines concatenate masking vector along measurements feed non-rnn models. physionet dataset sample time series hourly basis propagate measurements forward time gaps. mimic-iii dataset consider hourly samples forward imputation. preliminary experiments showed -hourly samples obtains better performance one-hourly samples mimic-iii. report results concatenation input masking vectors input vector without masking scikit-learn non-rnn model implementation tune parameters cross-validation. choose kernel since performs better kernels. models layer model sequence apply soft-max regressor last hidden state classiﬁcation. hidden units gru-mean mimic-iii physionet datasets respectively. models constructed figure classiﬁcation performance gesture synthetic datasets. x-axis average pearson correlation variable missing rates target label dataset; y-axis score. comparable number parameters. gru-simple mean imputation input shown equation batch normalization dropout rate applied regressor layer. train models adam optimization method early stopping best weights validation dataset. input variables normalized mean standard deviation. report results -fold cross validation terms area curve exploiting informative missingness synthetic dataset illustrated figure missing patterns useful solving prediction tasks. robust model exploit informative missingness properly avoid inducing inexistent relations missingness predictions. evaluate impact modeling missingness conduct experiments synthetic gesture datasets. process data different settings missing rate different correlations missing rate label. higher correlation implies informative missingness. figure shows score comparison three baseline models proposed gru-d. since gru-mean gru-forward utilize missingness perform similarly across settings. gru-simple gru-d beneﬁt utilizing missingness especially correlation high. gru-d achieves best performance settings gru-simple fails correlation low. results synthetic datasets demonstrates proposed model model distinguish useful missing patterns data properly compared baselines. prediction task evaluation real datasets evaluate methods section mimic-iii physionet datasets. noticed dropout recurrent layer helps models datasets probably contain input variables training samples synthetic dataset. similar apply dropout rate dropout samples time step weights table shows prediction performance models mortality task. models except random forest improve performance feed missingness indicators along inputs. proposed gru-d achieves best score datasets. also conduct multi-task classiﬁcation experiments tasks physionet icd- code tasks mimic-iii using models. shown table gru-d performs best terms average score across tasks single tasks. online prediction early stage although model trained ﬁrst hours data makes prediction last time step used directly make predictions sees time series make predictions useful applications health care early decision making beneﬁcial critical patient care. figure shows online prediction results mimic-iii mortality task. around ﬁrst hours models keeps increasing longer time series models. gru-d gru-simple explicitly handle missingness perform consistently superior compared methods. addition gru-d outperforms gru-simple making predictions given time series hours least higher score hours. indicates gru-d able capture utilize long-range temporal missing patterns. furthermore gru-d achieves similar prediction performance best non-rnn baseline model less time series data. shown ﬁgure gru-d performance hours best non-rnn baseline model hours. hour improvement gru-d non-rnn baseline highly signiﬁcant hospital settings time-saving critical decisions demands accurate early predictions. model scalability growing data size many practical applications model scalability large dataset size important. evaluate model performance different training dataset size subsample three smaller datasets admissions entire mimic-iii dataset keeping mortality rate. compare proposed models baselines competitive non-rnn baselines observe models achieve improved performance given training samples. however improvements non-rnn baselines quite limited compared models gru-d model achieves best results larger datasets. results indicate performance non-rnn baselines continue grow data become available. summary paper proposed novel gru-based model effectively handle missing values multivariate time series data. model captures informative missingness incorporating masking time interval directly inside architecture. empirical experiments synthetic real-world health care datasets showed promising results provided insightful ﬁndings. future work explore deep learning approaches characterize missing-not-at-random data conduct theoretical analysis understand behaviors existing solutions missing values. kyunghyun bart merri¨enboer caglar gulcehre dzmitry bahdanau fethi bougares holger schwenk yoshua bengio. learning phrase representations using encoder-decoder statistical machine translation. arxiv preprint arxiv. geoffrey hinton deng dong george dahl abdel-rahman mohamed navdeep jaitly andrew senior vincent vanhoucke patrick nguyen tara sainath deep neural networks acoustic modeling speech recognition shared views four research groups. signal processing magazine ieee david kreindler charles lumsden. effects irregular sample missing data time series analysis. nonlinear dynamical systems analysis behavioral sciences using real data zachary lipton david kale randall wetzel. directly modeling missing data sequences rnns improved classiﬁcation clinical time series. arxiv preprint arxiv. pedregosa varoquaux gramfort michel thirion grisel blondel prettenhofer weiss dubourg vanderplas passos cournapeau brucher perrot duchesnay. scikit-learn machine learning python. journal machine learning research kira rehfeld norbert marwan jobst heitzig j¨urgen kurths. comparison correlation analysis techniques irregularly sampled time series. nonlinear processes geophysics ivanovitch silva galan moody daniel scott celi roger mark. predicting in-hospital mortality patients physionet/computing cardiology challenge cinc many time series applications pattern missing variables time series often informative useful prediction tasks. here empirically conﬁrm claim real health care dataset investigating correlation missingness prediction labels denote missing rate variable calculate number time steps prediction task compute pearson correlation coefﬁcient label across time series. shown figure observe mimic-iii dataset missing rates rate values usually highly correlated labels. distinct correlation missingness labels demonstrates usefulness missingness patterns solving prediction tasks. proposed gru-d applies trainable decays input hidden state transitions order capture temporal missing patterns explicitly. decay idea straightforwardly generated parts inside models separately jointly given different assumptions impact missingness. comparisons also describe evaluate several modiﬁcations gru-d model. gru-di gru-ds decay input hidden state equation respectively. considered simpliﬁed models proposed gru-d. gru-di aims capturing direct impact missing values data gru-ds captures indirect impact missingness. another intuition comes perspective input variable missing attention missingness; however variable missing long time keeps missing missingness becomes less important. utilize assumption decaying masking. brings model gru-dm shown figure replace masking alternatively gru-rnn predict missing values next timestep own. missing values occur test time simply train model predict measurement vector next time step language model missing values test time. unfortunately applicable time series applications health care domain also missing data training. instead propose goal-oriented imputation model called gru-imp view missing values latent variables probabilistic graphical model. given timeseries denote missing variables observed ones then training time-series classiﬁer missing variables becomes equivalent maximizing marginalized log-conditional probability correct label i.e. exact marginalized log-conditional probability however intractable compute instead maximize lowerbound although lowerbound still intractable compute exactly approximate monte carlo method amounts sampling missing variables time reads input sequence beginning reparametrization technique widely used stochastic variational inference estimate gradient lowerbound efﬁciently. test time simply mean missing variable i.e. seen improvement monte carlo approximation preliminary experiments. view approach goal-oriented imputation method show structure figure whole model trained minimize classiﬁcation cross-entropy error loss take negative likelihood observed values regularizer. several recent works rnns data model diseases predict patient diagnosis health care time series data irregular time stamps missing values none explicitly attempted capture model missing patterns rnns. choi feeds medical codes along time stamps model predict next medical event. feeding time stamps idea equivalent baseline gru-simple without feeding masking denote gru-simple pham takes time stamps lstm model modify forgetting gate either time decay parametric time time stamps. however non-trainable decay ﬂexible parametric time also change model structure similar gru-simple addition neither consider missing values time series medical records time stamp input used models vector patient matrix input variable patient ours. lipton achieves best performance diagnosis prediction feeding masking zero-ﬁlled missing values. model equivalent gru-simple without feeding time interval model structure modiﬁcation made capturing utilizing missingness. denote best model gru-simple conclusively gru-simple baseline considered generalization related models mentioned above. order fairly compare capacity gru-rnn models build model proper size share similar number parameters. table shows statistics gru-based models three datasets. show statistics mortality prediction real datasets it’s almost multi-task classiﬁcations tasks datasets. addition comparable number parameters also makes models number iterations training time close scale experiments. models multi-task learning tasks almost binary classiﬁcation except soft-max prediction layer replaced fully connected layer sigmoid logistic functions data-driven prior regularizer parameterized comorbidity counts training data applied prediction layer improve figure performance predicting tasks physionet dataset. mortality in-hospital mortality; los< length-of-stay less days; surgery whether patient recovering surgery; cardiac whether patient cardiac condition; y-axis score. classiﬁcation performance. show scores predicting icd- diagnosis categories mimic-iii dataset figure tasks physionet dataset figure proposed gru-d achieves best average score datasets wins icd- prediction tasks. finally test model variations mentioned appendix along proposed gru-d. include models trainable decays models simpliﬁed gru-simple results shown table gru-d performs best among models. table model performances variations measured score mortality prediction.", "year": 2016}