{"title": "Becoming More Robust to Label Noise with Classifier Diversity", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "It is widely known in the machine learning community that class noise can be (and often is) detrimental to inducing a model of the data. Many current approaches use a single, often biased, measurement to determine if an instance is noisy. A biased measure may work well on certain data sets, but it can also be less effective on a broader set of data sets. In this paper, we present noise identification using classifier diversity (NICD) -- a method for deriving a less biased noise measurement and integrating it into the learning process. To lessen the bias of the noise measure, NICD selects a diverse set of classifiers (based on their predictions of novel instances) to determine which instances are noisy. We examine NICD as a technique for filtering, instance weighting, and selecting the base classifiers of a voting ensemble. We compare NICD with several other noise handling techniques that do not consider classifier diversity on a set of 54 data sets and 5 learning algorithms. NICD significantly increases the classification accuracy over the other considered approaches and is effective across a broad set of data sets and learning algorithms.", "text": "widely known machine learning community class noise detrimental inducing model data. many current approaches single often biased measurement determine instance noisy. biased measure work well certain data sets also less eﬀective broader data sets paper present noise identiﬁcation using classiﬁer diversity method deriving less biased noise measurement integrating learning process. lessen bias noise measure nicd selects diverse classiﬁers determine instances noisy. examine nicd technique ﬁltering instance weighting selecting base classiﬁers voting ensemble. compare nicd several noise handling techniques consider classiﬁer diversity data sets learning algorithms. nicd signiﬁcantly increases classiﬁcation accuracy considered approaches eﬀective across broad data sets learning algorithms. goal supervised machine learning induce accurate generalizing function labeled training instances. however real-world data sets noisy. generally types noise considered attribute noise label noise. previous work found that general label noise harmful attribute noise consequences label noise summarized fr´enay verleysen include deterioration classiﬁcation performance increased learning requirements model complexity distortion observed frequencies. knowing instances noisy and/or detrimental non-trivial cases known task contained training instances. discussed related work section prior work examined handling label noise using variety approaches generally speciﬁc inspired individual learning algorithm information theoretic measure. commonly used approach removes instances misclassiﬁed learning algorithm although approach biased towards learning algorithm used generally shown work well examined data sets learning algorithms especially addition artiﬁcial noise. however also shown efﬁcacy speciﬁc noise handling technique given learning algorithm dependent upon data characteristics cases using noise handling technique reduces classiﬁcation accuracy especially without addition artiﬁcial noise ensembles often perform better constituent base classiﬁers classiﬁcation prior work used ensemble techniques improve handling class noise ensemble accurate individual classiﬁer ensemble base classiﬁers need accurate diverse using ensemble technique identifying noise implicitly lessens dependence single hypothesis. however none previous work explicitly focused selecting diverse base classiﬁers using ensemble approach. inspired ﬁnding noise handling always eﬃcacious using principles ensembles increase classiﬁcation accuracy propose noise identiﬁcation using classiﬁer diversity nicd ﬁrst explicitly selects diverse learning algorithms diversity determined predictions classiﬁers. diversity lessens dependence noise measure speciﬁc hypothesis. without diversity hypothesis could over-represented hypotheses always classify way. examine using diverse learning algorithms ﬁlter instances weight instances base classiﬁers voting ensemble. data sets learning algorithms compare nicd ﬁltering techniques weighting techniques voting ensemble composed diﬀerent base classiﬁers explicitly take classiﬁer diversity account. using classiﬁer diversity signiﬁcantly improves accuracy ﬁltering weighting voting ensembles across broad data sets learning algorithms noise levels demonstrating robustness label noise. term broad refers characteristic noise handling method developed speciﬁcally given data sets learning algorithms. overall using nicd voting ensemble select diverse base classiﬁers achieves signiﬁcantly higher classiﬁcation accuracy using standard noise handling technique. remainder paper organized follows. section reviews prior work handling label noise. section presents methodology selecting diverse learning algorithms. experimental methodology presented section results provided section section concludes paper. many real-wold data sets inherently noisy previous work examined class noise attribute noise aﬀects performance various learning algorithms works found class noise generally harmful attribute noise noise training harmful noise test set. thorough overview current state handling label noise classiﬁcation problems consult survey fr´enay verleysen learning algorithms designed tolerate certain degree noise making trade-oﬀ complexity inferred model minimizing error training data prevent overﬁt. example avoid overﬁt many algorithms validation early stopping pruning regularization adding complexity penalty loss function despite precautions learning algorithms completely robust noise sense learning algorithms adapted speciﬁcally better handle label noise. example noisy instances problematic boosting algorithms weight placed upon misclassiﬁed instances– often include mislabeled noisy instances. address this servedio presented boosting algorithm limits amount weight placed single training instance. support vector machines standard hinge-loss function misclassiﬁed instances always selected support vectors. address this collobert ramp-loss function place bound maximum penalty instance lies wrong side margin. rosales also modify allow certain number instances considered candidate support vectors probabilistic setting lawrence sch¨olkopf explicitly model possibility instance mislabeled using generative model expectation maximization update probability instance mislabeled. preprocessing data another approach explicitly handles label noise. done removing noisy instances weighting instances correcting incorrect labels. three approaches ﬁrst attempt identify instances noisy using various criteria. filtering noisy instances received much attention generally shown result increase classiﬁcation accuracy especially large amounts artiﬁcial noise added data however recently broad application noise handling techniques shown always increase classiﬁcation accuracy especially artiﬁcial noise added data saez also showed ﬁltering detrimental examined predicting eﬃcacy ﬁltering nearest neighbor classiﬁcation. found correlation data properties eﬃcacy ﬁltering. frequently used ﬁltering technique removes instance misclassiﬁed learning algorithm learning algorithms verbaeten assche pursued idea using ensemble ﬁltering using ideas boosting bagging. approaches information theoretic machine learning heuristics remove noisy instances. example segata remove instances close wrong side decision surface generated support vector machine. zeng martinez remove instances probability labeled correctly probability calculated using output neural network. filtering potential downside discarding useful instances. however assumed signiﬁcantly non-noisy instances throwing away correct instances noisy instances negative impact large data set. weighting instances training beneﬁt discarding instances. filtering considered special case weighting instance assigned weight pair-wise expectation maximization rebbapragada brodley weight instances using expectation maximization cluster instances belong pair classes. probabilities classes instance compiled used weight inﬂuence instance. similar weighting training instances data cleaning discard instances rather strives correct noise instances. ﬁltering output learning algorithm used clean data. automatic data enhancement uses output neural network correct label training instances probability correctly labeled. polishing trains learning algorithm predict value attribute predicted attribute values instances increase generalization accuracy validation used instead uncleaned attribute values. previous work considered eﬀects proposed noise handling technique small number data sets learning algorithms often using single learning algorithm. studies examined larger exception rather rule paper examine eﬀects noise data sets diverse learning algorithms. nicd diﬀerentiated previous work nicd explicitly considers diversity learning algorithms used handle label noise lessen bias using single bias. prior work also examined classiﬁer diversity primarily ﬁeld ensemble learning despite eﬀorts prior work formal deﬁnition diversity still lacking correlation classiﬁer diversity measures classiﬁcation accuracy ensemble method often small previous studies measured diversity considering pair classiﬁers correctly classiﬁed misclassiﬁed instance compute diversity classiﬁer output diﬀerence distinguished classiﬁer diversity measures considers case classiﬁers incorrect predict diﬀerent classes. previous work examined eﬀect noise performance ensembles primarily examining boosting bagging decorate ensemble algorithms create ensembles subset selection training set. knowledge impact classiﬁer diversity presence class noise majority voting ensemble noise identiﬁcation previously examined. ﬁrst step noise handling technique identify noisy instances. discussed section variety approaches used remove noisy instances often using heuristics biases current learning algorithms information theoretic measures. paper probability instance correctly classiﬁed used determine noisy training instance practice generally estimated using speciﬁc hypothesis induced learning algorithm biased approximation. dependence speciﬁc removed summing possible hypotheses multiplying prior formulation infeasible though practical hypotheses calculating non-trivial learning algorithms produce probability distribution. limitations make probabilistic generative models attractive kernel fisher discriminant algorithm however classiﬁcation tasks discriminative models generally lower asymptotic error generative models paper choose examine discriminative models. lessen dependence speciﬁc estimate using diverse learning algorithms. diversity learning algorithms refers learning algorithms classiﬁcation instances determined using unsupervised meta-learning ﬁrst uses classiﬁer output diﬀerence meafigure dendrogram considered learning algorithms clustered using unsupervised metalearning based classiﬁer output diﬀerence calculate classiﬁer diversity. sure diversity learning algorithms. measures distance learning algorithms probability learning algorithms make diﬀerent predictions. clusters learning algorithms based scores hierarchical agglomerative clustering. considered learning algorithms weka default parameters resulting dendrogram shown figure height line connecting clusters corresponds distance them. cut-point chosen create clusters representative algorithm cluster chosen create diverse learning algorithms. learning algorithms used approximate listed table multilayer perceptron trained back propagation decision tree locally weighted learning -nearest neighbors nearest neighbor generalization na¨ıve bayes ripple rule learner random forest repeated incremental pruning produce error reduction section present experimental methodology. noise identiﬁcation using classiﬁer diversity process selecting using diverse learning algorithms using learning algorithms learning process handle class noise. paper nicd uses diverse learning algorithms ﬁltering weighting base classiﬁers voting ensemble. examine noise handling using trained backpropagation random forest ripper learning algorithms data sets data repository table shows data sets used study noise handling method evaluated averaging results runs experiment. experiment data shuﬄed split training testing. training testing sets stratiﬁed. random noise introduced randomly changing class label training instances label chosen uniformly possible class labels random noise levels examined statistical signiﬁcance pairs algorithms determined using wilcoxon signed-ranks test suggested demˇsar approximate using classiﬁer diversity well biased approach. nicd quantity approximated using learning algorithms listed table generally classiﬁcation learning algorithms classify instance nominal classes produce probability distribution classes. since learning algorithms produce probability distribution consistent kronecker delta function instead produce real-valued score biased approach approximated hypothesis induced learning algorithm used induce model data. biased ﬁltering misclassiﬁed instances removed. real-value biased instance weighting single hypothesis compute classiﬁer score instance learning algorithm induces below present calculate classiﬁer scores investigated learning algorithms. multilayer perceptron multiple classes class data represented output node. training backpropagation classiﬁer score largest value output nodes normalized zero ﬁltering using instances misclassiﬁed percent learning algorithms ensemble ﬁltered training set. note percentages could also used. found generally produces good results compared values practice validation often used determine percentage would used. biased ﬁlter approach instance misclassiﬁed learning algorithm used induce model data ﬁltered training set. diﬀerence target value output network derivative activation function product input corresponding weight wjij. random forests distribution selecting instances random trees weighted rather uniformly weighted. learning algorithms keep track counts instance weighted represents summing instances meet criterion sums instances data set. section present results experiments. compare l-ﬁltering biased-ﬁlter seven ﬁltering approaches. lweighting compared biased-weighting instance weighting technique. compared noise handling techniques listed brief explanation. details consult cited work. saturation ﬁlter saturation ﬁlter based premise removing noisy instances reduces complexity least correct hypothesis removing correctly labeled instances not. instance whose removal training decreases clch ﬁltered training set. process continues clch longer reduced training instances removed. classiﬁcation ﬁlter classiﬁcation ﬁlter removes instances misclassiﬁed learning algorithm using -fold cross-validation training set. default learning algorithm -nearest neighbor. ensemble ﬁlter ensemble ﬁlter removes instances misclassiﬁed base classiﬁers. ensemble ﬁlter distinguished l-ﬁlter based base classiﬁers chosen ensemble. ensemble ﬁlter authors arbitrarily chose three well-known learning algorithms examined removing instances misclassiﬁed majority learning algorithms. paper instances removed misclassiﬁed learning algorithms. automatic noise removal ﬁlter estimates probability possible class training instances. probabilities used training instance probability assigned class corrected class highest probability. instances corrected training ﬁltered data set. cross-validated committees ﬁlter cross validated committees ﬁlter partitions data subsets approximately equal size learning algorithm induced times time leaving subsets training data. classiﬁers ensembled together determine instance noisy. instances misclassiﬁed ensembled classiﬁers ﬁltered training set. base classiﬁer used decision tree. iterative-partitioning ﬁlter iterative partitioning ﬁlter ﬁrst partitions training data subsets model induced subset. instances misclassiﬁed induced models ﬁltered. process repeated number noisy instances removed less size original training set. base classiﬁer used decision tree trained using pair-wise expectation maximization pwem weights instance using algorithm. first data binarized. pair classes instances belong classes clustered using number clusters determined using bayesian information criterion given clusterings calculated previous techniques used default parameters implemented keel toolkit except renn pwem. cases algorithm ﬁnish running data sets. example since saturation ﬁlter iteratively removes instance requires large amounts memory/time large data sets ﬁnish cases. rather remove large data sets examination include comparison data sets algorithms ﬁnish. tables section algorithm ﬁrst baseline algorithm algorithms subsequent rows compared against. values count rows represent number times accuracy baseline algorithm greater than equal less compared algorithm. bold p-values represent cases baseline algorithm achieves signiﬁcantly higher classiﬁcation accuracy. contrast underlined values gray cells represent cases accuracy compared algorithm signiﬁcantly higher baseline algorithm. p-value represents p-value less many previous works noise handling inspired often biased towards given learning algorithm measure. previous work added artiﬁcial noise data sets evaluate techniques showed signiﬁcant improvements data sets artiﬁcial noise. biased nature noise handling techniques surprising broad application noise handling approach data sets without artiﬁcial noise detrimental brieﬂy re-examine application noise handling broad data sets learning algorithms. table compares noise handling considered noise handling techniques averaged data sets artiﬁcially added noise. cases noise handling signiﬁcantly increases classiﬁcation accuracy. renn classiﬁcation ﬁlter signiﬁcantly decrease classiﬁcation accuracy investigated learning algorithms. important example highlights point often overlooked despite this previous work noise handling shown signiﬁcant improvement high amount noise data. determine instance noisy mislabeled without domain expert previous work added artiﬁcial noise show impact noise handling noise improves accuracy. generally large amounts noise using noise handling approach signiﬁcantly increases classiﬁcation accuracy. addition adding artiﬁcial noise also examine eﬀectiveness noise handling techniques addition artiﬁcial noise. figure graphs percent reduction error learning algorithm noise handling method considered artiﬁcial noise levels percent reduction error percentage error reduced noise handling technique used compared error obtained noise handling noise accuracy achieved using noise handling technique orig accuracy obtained using noise handling technique. x-axis represents change error using noise handling technique negative values represent increase error using noise handling technique positive values represent decrease error compared using noise handling. general reduction percentage error increases amount noise increases. exception classiﬁcation ﬁlter noise handling techniques signiﬁcantly increase classiﬁcation accuracy noise level increases. cases classiﬁcation ﬁlter broad application techniques appropriate although beneﬁcial speciﬁc tasks. decrease error greatest l-weighting l-ﬁltering learning algorithm. recall learning algorithms chosen diverse represent hypothesis space suggests better estimation produces signiﬁcant results instance weighting ﬁltering. shown empirically l-weighting l-ﬁltering greatest reduction error learning algorithm however obvious trade-oﬀ since obtaining accurate estimate table results considered learning algorithms using investigated noise handling approaches artiﬁcial noise added data sets averaged data sets. bold p-values represent cases noise handling signiﬁcantly decreases accuracy; underlined gray cells represent cases noise handling signiﬁcantly increases accuracy. orig nicd l-weighted p-val count pwem p-val count nicd l-filter p-val count renn p-val count p-val count classiﬁcationfilter p-val count cvcommitteesfilter p-val count ensemblefilter p-val count iterpartitionfilter p-val count saturationfilter p-val count examining performance considered learning algorithms note mlps random forests generally achieve highest classiﬁcation accuracy tolerant noise inherent data set. however mlps random forests also appear least robust obtain lowest average classiﬁcation accuracy instances corrupted noise. artiﬁcial noise mlps random forests achieve accuracy. artiﬁcial noise average accuracy decreases hand ripper achieve average accuracy artiﬁcial noise average accuracy artiﬁcial noise. high degrees noise built-in noise handling mechanisms learning algorithms become beneﬁcial. next compare nicd noise handling techniques techniques classiﬁer diversity. ﬁrst compare diﬀerent instance weighting schemes. table compares l-weighting using learning algorithms listed table biased weighting pwem. values bold represent cases l-weighting achieves signiﬁcantly higher classiﬁcation accuracy compared weighting method. l-weighting signiﬁcantly outperforms weighting schemes cases cases pwem b-w. biased-weighting pwem never achieve signiﬁcantly higher classiﬁcation accuracy l-weighting. results similar ﬁltering. table compares l-ﬁltering biased ﬁlter cross-validated committees ﬁlter ensemble ﬁlter ﬁlters chosen representative ﬁltering algorithms achieved highest signiﬁcant increase classiﬁcation accuracy. ﬁltering ﬁltering approach signiﬁcantly outperforms l-ﬁlter l-ﬁlter achieves signiﬁcantly higher classiﬁcation accuracy cases table comparison eﬀect investigated instance weighting methods considered learning algorithm averaged data sets. bold p-values represent cases l-weighting achieves signiﬁcantly higher accuracy compared technique. table comparison l-ﬁltering ﬁltering techniques considered learning algorithms averaged data sets. bold pvalues represent cases l-ﬁltering achieves signiﬁcantly higher accuracy compared technique. table comparison l-ensemble -ensemble weighted l-ensemble filtered l-ensemble averaged data sets. bold p-values represent cases l-ensemble achieves signiﬁcantly higher accuracy; underlined gray cells represent cases lensemble achieves signiﬁcantly lower accuracy. learning algorithms. three learning algorithms -ensemble chosen obtain high classiﬁcation accuracy diverse words selected learning algorithm three clusters highest classiﬁcation accuracy. chose cluster contains ripper learning algorithms typically achieved lowest classiﬁcation accuracy nine investigated learning algorithms. additionally classiﬁer scores random forests highest correlation using three learning algorithms gives limited view hypothesis space since many learning algorithms used. l-ensemble signiﬁcantly outperforms -ensemble noise levels. thus better sampling beneﬁcial case. table also compares l-ensemble weighted l-ensemble ﬁltered l-ensemble. base classiﬁers weighted l-ensemble biased-weighted classiﬁers used earlier. likewise base classiﬁers ﬁltered l-ensemble biased-ﬁltered classiﬁers. artiﬁcial noise added data l-ensemble without noise handling achieves signiﬁcantly higher classiﬁcation accuracy using noise handling base classiﬁers. surprising noise handling often decreases classiﬁcation accuracy little noise data however higher noise levels weighted ﬁltered l-ensembles signiﬁcantly increase classiﬁcation accuracy. class noise l-ensemble robust class noise. completeness table compares l-ensemble l-weighting lﬁltering ensemble ﬁlter. noise handling methods chosen representative achieved highest signiﬁcant gains classiﬁcation accuracy single learning algorithm. despite significant increase classiﬁcation accuracy original learning algorithm noise handling method l-ensemble achieves signiﬁcantly higher classiﬁcation accuracy considered learning algorithms noise levels. demonstrates l-ensemble’s robustness label noise. increase accuracy voting ensemble surprising ensembles shown perform better constituent base classiﬁers focus attention random forest learning algorithms since obtain highest classiﬁcation accuracy considered learning algorithms. although increase accuracy voting ensemble signiﬁcant generally within percent average accuracy achieved random forest l-weighting l-ﬁltering. noise handling increase classiﬁcation accuracy l-ensemble safe choice general. however compared -ensemble artiﬁcial noise l-weighting statistically equivalent. achieves average accuracy compared -ensemble. higher levels noise l-weighted achieves signiﬁcantly higher average accuracy. thus representing whether weighting ensembling base classiﬁers important ramiﬁcations. detailed results comparing l-weighting l-ﬁltering -ensemble provided table investigation diversity base learning algorithms impact noise classiﬁcation accuracy pursued topic on-going research. paper examined handling class noise using hypotheses diverse learning algorithms. introduced noise identiﬁcation using classiﬁer diversity uses diverse learning algorithms approximate using diverse learning algorithms examined nicd ﬁltering technique weighting technique base classiﬁers voting ensemble learning algorithms data sets. found nicd signiﬁcantly outperforms less diverse noise handling techniques. results suggest better estimate leads better noise handling however actually knowing compared noise handling l-weighting l-ﬁltering often achieve signiﬁcantly higher classiﬁcation accuracy never achieve signiﬁcantly lower classiﬁcation accuracy. thus nicd able applied across broad data sets learning algorithms. also signiﬁcantly outperform considered noise handling techniques cases. worst l-weighting l-ﬁltering statistically equivalent techniques. despite increase accuracy exhibited l-weighting l-ﬁltering l-ensemble achieves signiﬁcantly higher classiﬁcation accuracy learning algorithms noise handling techniques examined noise levels. l-ensemble voting ensemble composed diverse learning algorithms learning algorithm equally-weighted vote. thus voting ensemble exhibits robustness noise individual constituent learning algorithms possess. diversity base classiﬁers produces robustness label noise.", "year": 2014}