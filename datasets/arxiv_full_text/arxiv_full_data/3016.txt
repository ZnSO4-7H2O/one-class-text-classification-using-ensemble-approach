{"title": "Perception Driven Texture Generation", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "This paper investigates a novel task of generating texture images from perceptual descriptions. Previous work on texture generation focused on either synthesis from examples or generation from procedural models. Generating textures from perceptual attributes have not been well studied yet. Meanwhile, perceptual attributes, such as directionality, regularity and roughness are important factors for human observers to describe a texture. In this paper, we propose a joint deep network model that combines adversarial training and perceptual feature regression for texture generation, while only random noise and user-defined perceptual attributes are required as input. In this model, a preliminary trained convolutional neural network is essentially integrated with the adversarial framework, which can drive the generated textures to possess given perceptual attributes. An important aspect of the proposed model is that, if we change one of the input perceptual features, the corresponding appearance of the generated textures will also be changed. We design several experiments to validate the effectiveness of the proposed method. The results show that the proposed method can produce high quality texture images with desired perceptual properties.", "text": "paper investigates novel task generating texture images perceptual descriptions. previous work texture generation focused either synthesis examples generation procedural models. generating textures perceptual attributes well studied yet. meanwhile perceptual attributes directionality regularity roughness important factors human observers describe texture. paper propose joint deep network model combines adversarial training perceptual feature regression texture generation random noise user-deﬁned perceptual attributes required input. model preliminary trained convolutional neural network essentially integrated adversarial framework drive generated textures possess given perceptual attributes. important aspect proposed model that change input perceptual features corresponding appearance generated textures also changed. design several experiments validate effectiveness proposed method. results show proposed method produce high quality texture images desired perceptual properties. textures play important roles multimedia applications understanding generation multimedia content. texture synthesis generation also extensively investigated past years revival deep learning researchers mainly used example-based approaches synthesize textures. methods textures similar appearances existing samples produced. development deep learning methods texture generation proposed learning training data. however visual perceptual information involved process whereas humans commonly perceptual attributes texture roughness coarseness directionality describe textures. moreover majority deep learning based methods generate images quality. thus desired develop generating high-quality textures based human perceptual descriptions; example generation method able produce textures strong directionality less regularity required user. convolutional neural network inspired mechanism visual cortex shown great superiority latest studies deep convolutional networks researchers made breakthroughs many classical computer vision tasks. example imagenet large scale visual recognition challenge performance computer algorithms even surpassed human’s consequently researchers investigating different approaches based image generation proposed generative adversarial framework produced excellent results many image generation tasks. however generated samples still resolution perfect. order generate realistic images wang gupta factorized image generation process proposed joint model consisting style structure generative adversarial networks experimental results suggested great gain could obtained factoring trick generating realistic indoor scenes. work indicates promising practice exploit joint convolutional neural networks adversarial training schemes generating high-quality images. addition generating natural images another question generate semantics high-level descriptions. many efforts made regarding topic. karpathy proposed fragment embedding method essentially bidirectional retrieval scheme desired image must exist image database. modeled images composite foreground background developed layered generative model method shows promising results tasks attribute-conditioned image reconstruction completion. nevertheless quality generated images still good enough texture perception study. combines perceptual feature regression adversarial schemes generating textures based perceptual descriptions. unlike existing conditional generative adversarial networks discriminative model need estimate joint distribution condition vectors samples always provide enough information generator adjust parameters model perceptual feature regression supervise generator produce textures consistence human visual system. thus discriminative model assisted perceptual regression model therefore released inaccurate estimation joint distributions. furthermore perceptual model able supply information generator guide produce texture enough details lead high-quality output texture images. textures attracted widespread attention research ﬁeld visual perception computer vision. identiﬁed perceptual features people used classify textures also established correlation semantic attributes textures showed importance perceptual features understanding texture images. meanwhile texture synthesis texture generation active research areas many years. shin proposed pixel-based method texture synthesis non-parametric sampling proposed efﬁcient algorithm using tree-structured vector quantization realistic texture synthesis required sample texture input studies normally concern example based texture synthesis whereas work focuses generating textures according user-deﬁned perceptual attributes. deep learning models particularly deep convolutional neural networks achieved great success texture analysis strong learning capability. texture synthesis based research topic produced promising results. results suggest topic deserves research devotion. gatys combined conceptual framework spatial summary statistics feature responses feature space convolutional neural network goal generate textures given source image. ulyanov also trained feed-forward generation networks generate multiple samples texture arbitrary sizes manner representation given image learned convolutional networks samples generated networks. goodfellow proposed generative adversarial framework could estimate generative models adversarial process generative model discriminative model simultaneously trained. generative model responsible capturing data distribution discriminative model used estimate probability sample comes training data rather training procedure maximize probability making mistake. proven used generate realistic images uniformly distributed random noise furthermore extended cgan conditional image generation mirza osindero models received additional vector information condition. vector might contain information class training example. cgan successfully applied digit face image generation whereas interested generating textures given perceptual attributes. inspired previous works paper proposes joint model combines perceptual feature regression adversarial training scheme perception driven texture generation. since perceptual regression model provide additional information generator adversarial scheme proposed model able generate high-quality textures. section ﬁrst introduce overall architecture proposed joint model perception driven texture generation. provide details network design initialization. human observers essentially perceptual features texture description e.g. regularity repetitiveness according prominent perceptual features human perceive texture. practice human perceive features texture also imagine texture perceptual descriptions. example textures weak strong directionality easily depicted human mind; contrast computer algorithm able generate texture descriptions. therefore designed joint deep model order achieve goal. shown fig. overall architecture includes three parts perceptual feature regression model conditional generative model discriminative model. generative model responsible conditional texture generation whereas discriminative model used distinguish whether generated texture training sample distribution perceptual model drive generative model produce textures possessing certain attributes. inspired success inception-v model reached top- error rate even surpassed human performance imagenet large scale visual recognition challenge inception-v perceptual feature regression. first change activation function ﬁnal output layer auxiliary units tanh perceptual features scaled range reason scaling range units reached input neuron represents weight convolutional fully connected layer. relu used activation function network since reduce gradient vanishing effect make model learn fast. however would like output generator limited certain range image always limited pixel values. discriminator yield probability result indicates whether image comes real training samples. accordingly tanh activation function output layer generative model sigmoid discriminative model. thus adopt different initialization strategies output layer. order keep gradient variance activation function tanh initialize weights using truncated normal sigmoid. here assume weights initialized independently bias initialized zero. particular number units decreases much output layer slightly reduce deviation weights avoid output becoming saturated forward case. introduce details network design section noted that fully connected layer initialization strategy easily analyzed. however becomes complicated convolutional layers. take convolutional operation example easily extended high dimensional case. represent number units propagate gradient certain input unit. number input units becomes large calculate average value deﬁne universal formulation avoid saturation output neurons. furthermore tanh much easier trained sigmoid second change cross entropy loss softmax quadratic loss. train modiﬁed inception-v model using texture database perceptual feature prediction. following sections call modiﬁed inception-v perceptual model. cgan framework discriminator needs ﬁgure union distribution condition samples. distinguishing task relatively difﬁcult discriminator cannot supply enough information generator justify parameters. model perceptual model impose perceptual constraints generator; provide additional information generator produce certain perceived textures. represent generative discriminative perceptual model respectively. loss deﬁned represents training example corresponding perceptual feature vector zero indicating whether real pair number training examples. quadratic loss deﬁned tradeoff parameter random noise vector preliminarily trained trained adversarial scheme. manner discriminator makes generator produce realistic textures perceptual model makes generated textures possess certain perceptual attributes. subsection ﬁrst introduce initialization scheme deep networks present strategies design certain part network. inspired initialize weights layer proposed network formulation cases consider back propagation situation represents number represents maximal integer larger represents kernel size represents step size. illustrates period convolutional operation. line calculates number units reached certain input unit. period begins input unit. length cycle average value general situation average value calculate deviation initialization. extend dimensional situation simply expand dimensions. scheme used initialize networks experiments. order emphasize importance perceptual features texture generation stretch perceptual feature vector dimensions fully connected layer. random noise vector drawn uniformly dimensional space ranging reason using speciﬁc dimensions explained follows. random noise vector dimensions signiﬁcantly varied generate diverse textures given certain perceptual features. theory change dimension random noise vector step obtain different vectors. large enough space variant texture appearance. addition textures perceptual feature vector similar appearances. analysis demonstrate covariance shift avoided certain initialization strategy forward backward view. fully connected layers stretching perceptual features simply consider forward propagation. thus make represent number units input layer. consequently stretched perceptual features similar variance original. represent random variable. variance recall perceptual features scaled range represent perceptual feature following equation scaling transformation resulted owns variance since stretching layer initialized using forward principle variance stretched features also approximately result variance random noise three times larger stretched perceptual features. hence want perceptual features play role random noise generating task make number output units stretching layer three times larger random noise. work therefore number perceptual features dominate generating procedure. experiments perceptual texture database textures corresponding perceptual features textures resolution perceptual features include contrast repetitiveness granularity randomness roughness density directionality structural complexity coarseness regularity orientation uniformity. however since textures still train deep neural network expand examples following way. first crop texture textures size step used cropping second resize resulted textures regarding perceptual features resulted textures values original ones. eventually obtain examples size among train models. remaining textures left validation set. noted reasonable make resulted textures perceptual features originals. first textures isotropic; region cover area original texture therefor keep original perceptual characteristics. second resizing texture cause obviously blurring effect. since perceptual model modiﬁed inceptionv need train scratch. preliminary trained inception-v imagenet found since perceptual model differed inception-v output layer loss deﬁnition initialized output layer truncated gaussian noise layers reloaded preliminary trained inception-v model. ﬁne-tuned perceptual model initial learning rate rmsprop method used gradient descent optimization algorithm fig. textures generated existing perceptual feature vectors. textures column perceptual features. textures ﬁrst database second generated corresponding perceptual feature vectors. fig. training loss curves jointed models. regression curve. discriminative model training loss curve. generative model training loss curve. perceptual model training loss curve. iterations. process illustrated fig. finally euclidean loss converged ﬁnal evaluation error since perceptual features attributes standard error deviation attribute average calculated means accurately predict perceptual features texture small deviation. based observation make basic assumption here generated textures certain perceptual attributes correctly perceived perceptual model. preliminary trained perceptual model accessory whole generative framework. generate realistic textures must design reasonable network structure. kernel size vital factor generating high-quality images. experiments found kernel size small i.e. generated textures owned details looked crude. kernel size large i.e. generated textures looked smooth less details. eventually used kernels convolution inverse convolution discriminative generative models. also tried fuse kernels different size generating textures details global information. however produce good results. since part input generative model drawn random noise inﬁnitely many training examples practice. thus used adam method optimization. optimized generative model twice optimization discriminative model. made batch contain training examples. tradeoff parameter fig. textures generated manually created perceptual features. column vary perceptual feature large small others kept existing perceptual features. following perceptual features manually changed directionality contrast granular roughness feature density structural complexity. seen corresponding features gradually become less obvious. optimization iterations. training process illustrated fig. experiments designed models trained. first real perceptual features database different random noise generative model. generated textures shown fig. second manually edited perceptual features used generate textures. emphasized manually edited handcrafted perceptual features based existing perceptual features i.e. certain perceptual feature three different values whereas others kept existing ones. fig. provide results limited space results provided supplementary materials. example ﬁrst column fig. decrease perceptual feature value directionality textures gradually lose overall direction. results indicate proposed method able generate desired textures varying certain perceptual attributes. propose novel deep network model perception driven texture generation. proposed model perceptual regression component integrated generative framework drives produced textures possessing certain perceptual attributes. perceptual regression model partially releases discriminative model’s workload supply information generator produce better perceived texture. experimental results show jointed models able generate realistic texture given perceptual attributes. attribute success fact generated texture realistic enough potentiality correctly perceived preliminary trained deep network. noted perceptual features independent other. change perceptual attribute arbitrarily remaining relevant features might also need changed real distribution. future work design auxiliary model generating correct perceptual feature vectors; simply provide existing perceptual feature vector desired value certain attribute tool generate suitable input perceptual feature vector. alexey badalov irene cheng claudio silva anup basu in-place texture synthesis technique memory constrained multimedia applications ieee international conference multimedia expo kevin jarrett koray kavukcuoglu yann lecun what best multi-stage architecture object recognition? ieee international conference computer vision. ieee alex krizhevsky ilya sutskever geoffrey hinton imagenet classiﬁcation deep convolutional neural networks advances neural information processing systems vol. christian szegedy vincent vanhoucke sergey ioffe jonathon shlens zbigniew wojna rethinking inception architecture computer vision arxiv preprint arxiv. alexey dosovitskiy jost tobias springenberg thomas brox learning generate chairs convolutional neural networks proceedings ieee conference computer vision pattern recognition goodfellow jean pouget-abadie mehdi mirza bing david warde-farley sherjil ozair aaron courville yoshua bengio generative adversarial nets advances neural information processing systems nalini bhushan ravishankar gerald lohse texture lexicon understanding categorization visual texture terms relationship texture images cognitive science vol. li-yi marc levoy fast texture synthesis using tree-structured vector quantization proceedings annual conference computer graphics interactive techniques. press/addison-wesley publishing leon gatys alexander ecker matthias bethge texture synthesis using convolutional neural networks advances neural information processing systems gauthier conditional generative adversarial nets convolutional face generation class project stanford convolutional neural networks visual recognition winter semester vol. junyu dong xiaoxu mike chantler visual perception procedural textures identifying perceptual dimensions predicting generation models plos vol. kaiming xiangyu zhang shaoqing jian delving deep rectiﬁers surpassing humanlevel performance imagenet classiﬁcation proceedings ieee international conference computer vision kevin swersky geoffrey hinton nitish srivastava overview mini-batch gradient descent http// www.cs.toronto.edu/%etijmen/csc/ slides/lecture_slides_lec.pdf.", "year": 2017}