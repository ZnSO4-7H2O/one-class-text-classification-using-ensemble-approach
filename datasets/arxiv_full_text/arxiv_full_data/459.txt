{"title": "Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain  Factoid Question Answering", "tag": ["cs.CL", "cs.AI", "cs.NE"], "abstract": "While question answering (QA) with neural network, i.e. neural QA, has achieved promising results in recent years, lacking of large scale real-word QA dataset is still a challenge for developing and evaluating neural QA system. To alleviate this problem, we propose a large scale human annotated real-world QA dataset WebQA with more than 42k questions and 556k evidences. As existing neural QA methods resolve QA either as sequence generation or classification/ranking problem, they face challenges of expensive softmax computation, unseen answers handling or separate candidate answer generation component. In this work, we cast neural QA as a sequence labeling problem and propose an end-to-end sequence labeling model, which overcomes all the above challenges. Experimental results on WebQA show that our model outperforms the baselines significantly with an F1 score of 74.69% with word-based input, and the performance drops only 3.72 F1 points with more challenging character-based input.", "text": "question answering neural network i.e. neural achieved promising results recent years lacking large scale real-word dataset still challenge developing evaluating neural system. alleviate problem propose large scale human annotated real-world dataset webqa questions evidences. existing neural methods resolve either sequence generation classiﬁcation/ranking problem face challenges expensive softmax computation unseen answers handling separate candidate answer generation component. work cast neural sequence labeling problem propose end-to-end sequence labeling model overcomes challenges. experimental results webqa show model outperforms baselines signiﬁcantly score word-based input performance drops points challenging character-based input. question answering neural network i.e. neural active research direction along road towards long-term goal building general dialogue agents unlike conventional methods neural rely feature engineering end-toend trainable. reduces requirement domain speciﬁc knowledge signiﬁcantly makes domain adaption easier. therefore attracted intensive attention recent years. resolving problem requires several fundamental abilities including reasoning memorization etc. various neural methods proposed improve abilities tensor networks recursive networks convolution neural networks attention models memories etc. methods achieve promising results various datasets demonstrates high potential neural however believe still major challenges neural system development and/or evaluation realworld data although several high quality well-designed datasets proposed recent years still problems using develop and/or evaluate system real-world settings data size created. example babi factoid question-answer corpus artiﬁcially synthesized; trec datasets free webquestions human generated thousands questions; simplequestions daily mail news datasets large generated controlled conditions. thus large-scale real-world dataset needed. tion/ranking without loss generality methods used producing answers existing neural works roughly categorized sequence generation type classiﬁcation/ranking type. former generates answers word word e.g. generally involves softmax computation large vocabulary computational cost remarkably high hard produce answers out-of-vocabulary word. latter produces answers classiﬁcation predeﬁned answers e.g. ranking given candidates model score e.g. although generally lower computational cost former either also difﬁculties handling unseen answers requires extra candidate generating component hard end-to-end training. need design choice answer production computationally effective capable handling unseen words/answers. propose large-scale real-world factoid dataset webqa questions evidences evidence piece text contains relevant information answer question. hand dataset order magnitude larger existing real-world datasets generally insufﬁcient train end-to-end system. hand questions dataset asked real-world users daily life signiﬁcantly close real-world settings generated controlled conditions besides also provide multiple human annotated evidences question dataset used research evidence ranking answer sentence selection well. humans answers using search engine conditional random ﬁeld label answer question retrieved evidence. avoid feature engineering computing features neural model jointly trained crf. model rely predeﬁned vocabulary candidates handle unseen words/answers easily expensive softmax computation. experimental results show model outperforms baselines large margin webqa dataset indicating effective. furthermore model even achieves score character-based input comparable score word-based input demonstrating model robust. work focus open-domain factoid taking figure example formalize problem follows given question evidences task produce answer evidence piece text length contains relevant information answer question. advantage formalization evidences retrieved unstructured knowledge base improve system coverage signiﬁcantly. inspired introduce endto-end sequence labeling design choice answer production neural given question evidence assign label word evidence indicate whether word beginning inside outside answer difference work needs work feature engineering relies pos/ner tagging dependency parsing question type analysis etc. avoid feature engineerfigure neural recurrent sequence labeling model factoid model consists three components question lstm computing question representation evidence lstms analyzing evidence producing label sequence indicates whether word evidence beginning inside outside answer. word evidence also equipped features plot multiple times clarity. single model solve problem. furthermore compared sequence generation classiﬁcation/ranking methods answer production method avoids expensive softmax computation handle unseen answers/words naturally principled way. formally formalize sequence labeling problem follows suppose vocabulary size given question evidence one-hot question lstm computing question representation; evidence lstms evidence analysis; layer sequence labeling. question lstm form single layer lstm equipped single time attention takes question input generates question representation three-layer evidence lstms takes evidence question representation optional features input produces features layer. layer takes features input produces label sequence. details given following sections. second lstm layer stacks ﬁrst lstm layer processes output reverse order. third lstm layer stacks upon ﬁrst second lstm layers cross layer links output serves features layer. minibatch stochastic gradient descent algorithm rmsprop minimize objective function. initial learning rate batch size also apply dropout output lstm layers. dropout rate hyper-parameters determined empirically grid search validation set. question lstm question lstm consists single-layer lstm single-time attention model. question lstm produce sequence vector representations q··· question-evidence common word feature word evidence feature value word also occurs question otherwise intuition words occurring questions tend part answers factoid questions. evidence-evidence common word feature word evidence feature value word occurs anevidence otherwise intuition words shared evidences likely part answers. order train evaluate open-domain factoid system real-world questions build chinese dataset named webqa. dataset consists tuples similar example figure questions evidences answers collected web. table shows statistics dataset. questions answers mainly collected large community website baidu zhidao small portion hand collected documents. therefore questions indeed asked real-world users daily life instead controlled conditions. questions single-entity factoid type means question factoid question answer involves entity question figure positive example question children albert enistein? counter example answer involves three persons. type correctness question answer pairs veriﬁed least annotators. evidences retrieved internet using search engine questions queries. download pages returned ﬁrst result pages take text pieces sentences include least question word candidate evidences. evidence retrieval beyond scope work simply tf-idf values re-rank candidates. question training provide ranked evidences annotate evidence annotated positive question answered reading evidence without prior knowledge otherwise negative. evidences whose annotations agreed least annotators requestion validation test sets provide major positive evidence maybe additional positive compute features. annotated. retrieved evidences also provided evaluation purpose memnn end-toend trainable version memory networks encodes question evidence bag-of-word method stores representations evidences external memory. recurrent attention model used retrieve relevant information memory answer question. attentive impatient readers bidirectional lstms encode question evidence classiﬁcation large vocabulary based encodings. simpler attentive reader uses similar work compute attention evidence. complex impatient reader computes attention processing question word. difference model readers produce answer classiﬁcation large vocabulary computationally expensive difﬁculties handling unseen words. however model uses end-to-end trainable sequence labeling technique avoids problems nature. webqa collected answer expressed different surface forms golden standard answer evidence e.g. v.s. therefore ways count correctly answered questions referred strict fuzzy tables measures often also used evaluating system. however model gives conditional probabilities directly comparable different answers include measures work. baselines produce exactly answer retrieved evidence question provided automatically retrieved evidences evidences processed model independently answers voted frequency decide ﬁnal result. note large amount evidences negative model produce answer them. speciﬁed following hyper-parameters used reset section lstm layer width word embedding dimension feature embedding dimension word embeddings initialized pre-trained embeddings using -gram neural language model ﬁxed training. show injecting noise data important improving performance retrieved evidence setting section following experiments training evidences negative ones randomly selected annotated negative evidences retrieved trivial negative evidences percentages determined empirically. intuitively evaluation entire webqa dataset section evaluate model entire webqa dataset. evaluation results shown table although producing multi-word answers harder model achieves comparable results one-word answer subset demonstrating model effective single-word multi-word word settings. outperforms softmax signiﬁcantly cases. reason softmax predicts label independently suggesting modeling label transition explicitly essential improving performance. natural choice modeling label transition softmax take last prediction account result shown table softmax. however performance comparable softmax signiﬁcantly lower crf. reason enumerate possible label sequences implicitly dynamic programming predicting possible softmax indicates better choice. noise table means whether inject noise data evidences positive annotated evidence setting ability recognizing unreliable evidence useless. therefore performance model without noise comparable annotated evidence setting. however ability important improve performance retrieved evidence setting large amount retrieved evidences negative ones. result observe signiﬁcant improvement injecting noise data setting. effect word embedding stated section word embedding initialized embedding kept ﬁxed training. evaluate different initialization optimization methods section. evaluation evidence randomly sample anevidence rest evidences question compare compute e-e.comm feature develop powerful models process multiple evidences principle future. answer question webqa dataset involves entity distinguish label ﬁrst label sequence explicitly discourage model produce multiple answers question. example golden labels example evidence figure became einstein/o married/o his/o ﬁrst/o wife/o mileva/b mari´c/i in/o denote label ﬁrst fuzzy matching also used computing golden standard labels training set. baselines predict one-word answers experiments one-word answer subset webqa i.e. questions one-word answers retained training validation test. shown table model achieves signiﬁcant higher scores baselines. main reason relative performance memnn uses bag-of-word method encode question evidence higher order information like word order absent model. think performance improved designing complex encoding methods leave future work. attentive impatient readers access ﬁxed length representations doing classiﬁcation. however model access outputs time steps evidence lstms scores label sequence whole. therefore model achieves better performance. results shown table second shows results embedding optimized jointly training. performance drops signiﬁcantly. detailed analysis reveals trainable embedding enlarge trainable parameter number model gets ﬁtting easily. model acts like context independent entity tagger extend desired. example model location name evidence word occurs question. contrary pre-trained ﬁxed embedding forces model attention latent syntactic regularities. also carries basic priors fruit person thus model generalize better test data ﬁxed embedding. third shows result embedding randomly initialized jointly optimized. performance drops signiﬁcantly further suggesting pre-trained embedding indeed carries meaningful priors. shown table q-e.comm ee.comm features effective q-e.comm feature contributes overall performance. reason interaction question evidence limited q-e.comm feature value i.e. corresponding word also occurs question strong indication word part answer. effect question representations section compare single-time attention method computing widely used options element-wise operation maxi element-wise average operation average intuitively attention distill information ﬂexible {qi} average tends hide differences them lies attention average. results table suggest ﬂexible selective operation better performance effect evidence lstms structures investigate effect evidence lstms layer number layer width cross layer links section. results shown figure fair comparison cross layer links figure highlight results cross layer links circle square retrieved annotated evidence settings respectively. conclude that generally deeper wider model better performance cross layer links effective make third evidence lstm layer information directions. notated retrieved evidence settings respectively points lower corresponding scores word-based input respectively. performance promising demonstrating model robust effective. work build human annotated realworld dataset webqa developing evaluating system real-world data. also propose end-to-end recurrent sequence labeling model experimental results show model outperforms baselines signiﬁcantly. several future directions plan pursue. first multi-entity factoid non-factoid also interesting topics. second plan extend model multi-evidence cases. finally inspired residual network investigate deeper wider models future. jonathan berant andrew chou frostig percy liang. semantic parsing freebase question-answer pairs. proceedings conference empirical methods natural language processing pages october. antoine bordes nicolas usunier sumit chopra jason weston. large-scale qingqing alexander yates. large-scale semantic parsing schema matching lexicon extension. proceedings annual meeting association computational linguistics pages august. dong furu ming zhou question answering freebase multi-column convolutional neural networks. proceedings annual meeting association computational linguistics international joint conference natural language processing pages july. kaiming xiangyu zhang shaoqing jian sun. deep residual learning image recognition. proceedings ieee conference computer vision pattern recognition pages june. karl moritz hermann tomas kocisky edward grefenstette lasse espeholt mustafa suleyman phil blunsom. teachadvances machines read comprehend. neural information processing systems pages felix hill antoine bordes sumit chopra jason weston. goldilocks principle reading children’s books explicit proceedings iclr memory representations. xuchen benjamin durme chris callison-burch peter clark. answer extraction sequence tagging tree edit distance. proceedings conference north american chapter association computational linguistics human language technologies pages june. wen-tau xiaodong christopher meek. semantic parsing single-relation question answering. proceedings annual meeting association computational linguistics pages june. zhou end-toend learning semantic role labeling using recurrent neural networks. proceedings annual meeting association computational linguistics international joint conference natural language processing pages beijing china july. geoffrey hinton nitish srivasilya sutskever rustava alex krizhevsky salakhutdinov. improving neural networks preventing co-adaptation feature detectors. arxiv.v. jordan boyd-graber leonardo claudino richard socher daum´e iii. neural network factoid question answering paragraphs. proceedings conference empirical methods natural language processing pages october. ankit kumar ozan irsoy jonathan james bradbury robert english brian pierce peter ondruska ishaan gulrajani richard socher. anything dynamic memory networks natural language processing. proceedings international conference machine learning pages june. john lafferty andrew mccallum fernando pereira. conditional random ﬁelds probabilistic models segmenting laproceedings eighbeling sequence data. teenth international conference machine learning pages francisco usa. yann lecun l´eon bottou yoshua bengio patrick haffner. gradient-based learning applied document recognition. proceedings ieee nov. iulian vlad serban alberto garc´ıadur´an aglar g¨ulc¸ehre sungjin sarath cjandar aaron courville yoshua bengio. generating factoid questions recurrent neural networks factoid question-answer corpus. appear proceedings richard socher danqi chen christopher manning andrew reasoning neural tensor networks knowledge base completion. advances neural information processing systems pages sainbayar sukhbaatar arthur szlam jason weston fergus. endadvances neural to-end memory networks. information processing systems pages tijmen tieleman geoffrey hinton. lecture .-rmsprop divide gradient running average recent magnitude. coursera neural networks machine learning.", "year": 2016}