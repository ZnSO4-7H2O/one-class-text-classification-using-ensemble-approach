{"title": "Overcoming the Curse of Sentence Length for Neural Machine Translation  using Automatic Segmentation", "tag": ["cs.CL", "cs.LG", "cs.NE", "stat.ML"], "abstract": "The authors of (Cho et al., 2014a) have shown that the recently introduced neural network translation systems suffer from a significant drop in translation quality when translating long sentences, unlike existing phrase-based translation systems. In this paper, we propose a way to address this issue by automatically segmenting an input sentence into phrases that can be easily translated by the neural network translation model. Once each segment has been independently translated by the neural machine translation model, the translated clauses are concatenated to form a final translation. Empirical results show a significant improvement in translation quality for long sentences.", "text": "works well short sentences words) difﬁculty long sentences words) particularly sentences longer used training. training long sentences difﬁcult available training corpora include sufﬁciently many long sentences computational overhead update iteration training linearly correlated length training sentences. additionally nature encoding variablelength sentence ﬁxed-size vector representation neural network fail encode important details. paper hence propose translate sentences piece-wise. segment input sentence number short clauses conﬁdently translated model. show empirically approach improves translation quality long sentences compared using neural network translate whole sentence without segmentation. encoder–decoder model recent implementation encoder–decoder approach proposed independently consists rnns acting respectively encoder decoder. maintains hidden units makes ‘update’ decision symbol input sequence. decision depends input symbol previous hidden state. rnnenc uses special hidden unit adaptively forgets remembers previous hidden state activation hidden unit time comj puted authors shown recently introduced neural network translation systems suffer signiﬁcant drop translation quality translating long sentences unlike existing phrase-based translation systems. paper propose address issue automatically segmenting input sentence phrases easily translated neural network translation model. segment independently translated neural machine translation model translated clauses concatenated form ﬁnal translation. empirical results show signiﬁcant improvement translation quality long sentences. research efforts statistical machine translation research relied phrase-based system suggested recently however entirely neural network based approach proposed several research groups showing promising results standalone system additional component existing phrase-based system. neural network based approach encoder ‘encodes’ variable-length input sentence ﬁxed-length vector decoder ‘decodes’ variable-length target sentence ﬁxedlength encoded vector. source sentence composed words denote phrase subsequence encoder–decoder measure conﬁdently translate subsequence considering log-probability candidate translation generated model. addition log-probability also log-probability reverse encoder–decoder probabilities deﬁne conﬁdence score phrase pair approximate beam search search candidate translations maximize log-likelihood indicator variable equal include phrase segmentation otherwise rewrite segmentation problem optimization following objective function constraint states word sentence source phrases contains word i≤k≤j included segmentation. constraint matrix totally unimodular making integer programming problem solvable polynomial time. indicator variable j-th word target vocabulary time single indicator variable time. context vector representation input sentence encoded encoder. although model originally trained phrase pairs straightforward train model bilingual parallel corpus consisting sentence pairs done remainder paper rnnenc trained english–french sentence pairs hypothesis explaining difﬁculty encountered rnnenc model translating long sentences plain ﬁxed-length vector lacks capacity encode long sentence. encoding long input sentence encoder lose track subtleties sentence. consequently decoder difﬁcult time recovering correct translation encoded representation. solution would build larger model larger representation vector increase capacity model price higher computational cost. section however propose segment input sentence segmented clause easily translated encoder– decoder. words wish segmentation maximizes total conﬁdence score conﬁdence scores evaluate incrementally. evaluated sj’s compute well deﬁnition optimal segmentation decomposing index ﬁrst sequence approach described requires quadratic time respect sentence length. proposed segmentation approach avoid problem reordering clauses. unless source target languages follow roughly order english french translations simple concatenation translated clauses necessarily grammatically correct. despite lack long-distance reordering current approach nonetheless signiﬁcant gains translation performance neural machine translation. mechanism reorder obtained clause translations however important future research question. another issue heart purely neural machine translation limited model vocabulary size source target languages. shown translation quality drops considerably unknown words present input sentence. interestingly enough proposed segmentation approach appears robust presence unknown words intuition segmentation leads multiple short clauses less unknown words leads stable translation clause neural translation model. finally proposed approach computationally expensive requires scoring subphrases input sentence. however scoring process easily sped scoring phrases dataset evaluate proposed approach task english-to-french translation. bilingual parallel corpus words selected method combination europarl news commentary crawled corpora words respectively. performance models tested news-test news-test news-test. comparing phrase-based system moses ﬁrst used development tuning moses news-test used test set. train neural network models sentence pairs parallel corpus english french sentences words long. furthermore limit vocabulary size frequent words english french. words considered unknown mapped special token models approaches compare proposed segmentation-based translation scheme neural network model translations without segmentation. neural machine translation done encoder–decoder trained maximize conditional probability french translation given english sentence. rnnenc trained approximate beam-search used possible translations high likelihood. datasets trained moses models downloaded http//www-lium.univ-lemans.fr/ ˜schwenk/cslm_joint_paper/ website ninth workshop statistical machine translation validity automatic segmentation validate proposed segmentation algorithm described sec. comparing baseline segmentation approaches. ﬁrst randomly segments input sentence distribution lengths random segments mean variance identical segments produced algorithm. second approach follows proposed algorithm however using uniform random conﬁdence score. table news-test experiments. random segmentation refers randomly segmenting sentence mean variance segment lengths corresponded ones best segmentation method. random conﬁdence score refers segmenting sentence randomly generated conﬁdence score segment. table clearly proposed segmentation algorithm results signiﬁcantly better performance. interesting phenomenon random segmentation better direct translation without segmentation. indirectly agrees well previous ﬁnding neural machine translation suffers long sentences. results table clearly show importance using translation inverse translation models. furthermore able best performance incorporating short phrase penalty thus original formulation conﬁdence score uses models penalty. quantitative qualitative analysis expected translation proposed approach helps signiﬁcantly translating long sentences observe translation performance drop sentences lengths greater used train rnnenc similarly fig. observe translation quality proposed approach robust figure bleu scores achieved rnnenc without segmentation rnnenc penalized reverse conﬁdence score phrase-based translation system moses newstest-. paper propose automatic segmentation solution ‘curse sentence length’ neural machine translation. choosing appropriate conﬁdence score based bidirectional translation models observed signiﬁcant improvement translation quality long sentences. proposed segmentation-based translation robust presence unknown words. however since segment translated isolation segmentation input sentence negatively impact translation quality especially ﬂuency translated sentence placement punctuation marks capitalization words. authors would like acknowledge support following agencies research funding computing support nserc calcul qu´ebec compute canada canada research chairs cifar.", "year": 2014}