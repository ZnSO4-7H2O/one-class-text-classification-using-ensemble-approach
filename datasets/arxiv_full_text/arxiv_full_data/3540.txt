{"title": "Unsupervised Domain Adaptation for Semantic Segmentation with GANs", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Visual Domain Adaptation is a problem of immense importance in computer vision. Previous approaches showcase the inability of even deep neural networks to learn informative representations across domain shift. This problem is more severe for tasks where acquiring hand labeled data is extremely hard and tedious. In this work, we focus on adapting the representations learned by segmentation networks across synthetic and real domains. Contrary to previous approaches that use a simple adversarial objective or superpixel information to aid the process, we propose an approach based on Generative Adversarial Networks (GANs) that brings the embeddings closer in the learned feature space. To showcase the generality and scalability of our approach, we show that we can achieve state of the art results on two challenging scenarios of synthetic to real domain adaptation. Additional exploratory experiments show that our approach: (1) generalizes to unseen domains and (2) results in improved alignment of source and target distributions.", "text": "collecting data natural images easier obtain certain domains like medical imaging collecting data ﬁnding experts precisely label also expensive. promising approach addresses issues utility synthetically generated data training. however models trained synthetic data fail perform well real datasets owing presence domain datasets. domain adaptation encompasses class techniques address domain shift problem. hence focus paper developing domain adaptation algorithms semantic segmentation. speciﬁcally focus hard case problem labels target domain available. class techniques commonly referred unsupervised dovisual domain adaptation problem immense importance computer vision. previous approaches showcase inability even deep neural networks learn informative representations across domain shift. problem severe tasks acquiring hand labeled data extremely hard tedious. work focus adapting representations learned segmentation networks across synthetic real domains. contrary previous approaches simple adversarial objective superpixel information process propose approach based generative adversarial networks brings embeddings closer learned feature space. showcase generality scalability approach show achieve state results challenging scenarios synthetic real domain adaptation. additional exploratory experiments show approach generalizes unseen domains results improved alignment source target distributions. deep convolutional neural networks revolutionalized ﬁeld computer vision achieving best performance multitude tasks image classiﬁcation semantic segmentation visual question answering etc. strong performance attributed availability abundant labeled training data. annotating data relatively easier certain tasks like image classiﬁcation extremely laborious time-consuming others. semantic segmentation task requires great human effort involves obtaining dense pixel-level labels. annotation time obtaining pixel-wise labels single image cityscapes dataset highlighting level difﬁculty challenge lies traditional approaches domain adaptation involve minimizing measure distance source target distributions. commonly used measures maximum mean discrepancy learning distance metric using dcnns done adversarial approaches approaches good success classiﬁcation problems; however pointed performance improvement translate well semantic segmentation problem. motivates need developing domain adaptation techniques tailored semantic segmentation. method present work falls category aligning domains using adversarial framework. among recent techniques address problem wild approach uses adversarial framework. however unlike discriminator operates directly feature space project features image space using generator discriminator operates projected image space. adversarial losses derived discriminator. observed applying adversarial losses projected image space achieved signiﬁcant performance improvement compared applying losses directly feature space main contribution work propose technique employs generative models align source target distributions feature space. ﬁrst project intermediate feature representations obtained using dcnn image space training reconstruction module using combination adversarial losses. impose domain alignment constraint forcing network learn features source features produce target-like images passed reconstruction module vice versa. accomplished employing series adversarial losses. training progresses generation quality gradually improves time features become domain invariant. semantic segmentation well studied problem computer vision. fully convolutional networks shelhamer signiﬁed paradigm shift fully exploit representational power cnns pixel labeling task. performance steadily improving popular benchmarks pascal ms-coco address challenges domain shift within context semantic segmentation. domain adaptation widely explored computer vision primarily classiﬁcation task. earlier approaches involved using feature reweighting techniques constructing intermediate representations using manifolds dictionaries since advent deep neural networks emphasis shifted learning domain invariant features end-to-end fashion. standard framework deep domain adaptation involves minimizing term measures domain discrepancy along task solved. approaches maximum mean discrepancy kernel variants task others adversarial approaches. focus adversarial approaches since related work. revgrad performs domain adaptation applying adversarial losses feature space pixelda cogan operate pixel space. techniques perform adaptation classiﬁcation task approaches aimed semantic segmentation. best knowledge approaches address problem. wild proposes alignment strategies global alignment extension domain adversarial training proposed segmentation problem local alignment aligns class speciﬁc statistics formulating multiple instance learning problem. curriculum domain adaptation hand proposes curriculum-style learning approach easy task estimating global label distributions images local distributions landmark superpixels learnt ﬁrst. segmentation network trained target label distribution follow inferred label properties. possible direction address domain adaptation problem employ style transfer cross domain mapping networks stylize source domain images target train segmentation models stylized space. hence discuss recent work related style transfer unpaired image translation tasks. popular work gatys introduced optimization scheme involving backpropagation performing content preserving style transfer johnson proposed feedforward method same. cyclegan performs unpaired image-to-image translation employing adversarial losses cycle consistency losses. experiments compare approach style-transfer based data augmentation schemes. section provide formal treatment proposed approach explain detail iterative optimization procedure. rm×n×c arbitrary input image rm×n corresponding label map. given input denote output rm×n×nc number classes. vector representing class probability distribution pixel location output cnn. source target domains denoted embedding. following recent successful works image generation explicitly concatenate generator input random noise vector instead dropout layers throughout network. shown figure performs tasks distinguishing real source input generated source image source-real/source-fake producing pixel-wise label generated source image. given target input generator network takes target embedding input reconstructs target image. similar previous case trained distinguish real target data generated target images however different previous case performs single task i.e. classiﬁes target input target-real/target-fake. since target data labels training classiﬁer network active system presented target inputs. different adversarial losses used train models shown table. addition adversarial losses following losses lseg laux pixel-wise cross entropy loss used standard segmentation networks lrec loss input reconstructed images. directions information across different network blocks listed figure iteration randomly sampled triplet provided system. then network blocks updated iteratively following order d-update source inputs updated using combination within-domain adversarial loss advd auxiliary classiﬁcation loss aux. target inputs updated using adversarial loss advd. overall loss given advd advd g-update step generator updated using combination adversarial loss intended fool reconstruction loss lrec. adversarial loss encourages realistic output generator. pixelwise loss crucial ensure image ﬁdelity generator outputs corresponding input images. overall generator loss given figure directions data solid arrows forward pass gradient dotted arrows backward pass iterative update procedure. solid blocks indicate block frozen update step dotted block indicate updated. denoted source information blue denotes target information. first provide input-output description different network blocks pipeline. next describe separately treatment source target data followed description different loss functions corresponding update steps. finally motivate design choices involved discriminator architecture. base network whose architecture similar pre-trained model vgg- split parts embedding denoted pixel-wise classiﬁer denoted output label up-sampled size input discriminator network performs different tasks given input classiﬁes input real fake domain consistent manner performs pixel-wise labeling task similar network. note active source data since target data labels training. given source image label pair input begin extracting feature representation using network. classiﬁer takes embedding input produces image-sized label generator reconstructs source input conditioned figure training networks trained jointly adversarial framework. updated using combination supervised loss adversarial component. bottom right show test time usage. network blocks used. additional overhead evaluation compared base model. table within-domain cross-domain adversarial losses used update networks training. networks updated using within-domain losses updated using cross domain loss. adversarial losses originate network. ladvx implies gradients loss function used update only networks held ﬁxed. shift captured. parameters updated using combination several loss terms lseg illustrated table adversarial loss terms used update account domain adaptation. speciﬁcally iterative updates described considered min-max game networks. update step discussed earlier adversarial loss branch learns classify input images real fake domain consistent manner. update gradients lead reversal domain classiﬁcation i.e. source embeddings gradients corresponding classifying embeddings target domain target embeddings gradients corresponding classifying embeddings source domain note that similar min-max game pair except case traditional gans derived dcgan implementations output discriminator single scalar indicating probability input fake drawn underlying data distribution. recent works image generation utilized idea patch discriminator output dimensional feature pixel carries real/fake probability. results signiﬁcant improvement visual quality generator reconstructions. extend idea setting using variant patch discriminator pixel output indicates real/fake probabilities across source target domains hence general gans hard train tasks involve realistic images larger scale. promising approach training stable generative models framework auxiliary classiﬁer approach odena show conditioning training adding auxiliary classiﬁcation loss realize stable training even generate large scale images. inspired results image classiﬁcation extend idea segmentation problem employing auxiliary pixel-wise labeling loss network. components prove crucial performance. ablation study performed section shows effect design choices ﬁnal performance. speciﬁc details architectures network blocks found supplementary material. section provide quantitative evaluation method performing experiments benchmark datasets. consider challenging synthetic datasets available semantic segmentation synthia gta. synthia large dataset photo-realistic frames rendered virtual city precise pixellevel semantic annotations. following previous works synthia-rand-cityscapes subset contains images annotations compatible cityscapes. gta- another large-scale dataset containing labeled images. dataset curated richter generated extracting frames computer game grand theft auto used cityscapes real dataset. dataset contains urban street images collected moving vehicle captured cities around germany neighboring countries. dataset comes annotated images split three sets images train images images test set. experiments training models used labeled synthia gta- dataset source domain unlabeled cityscapes train target domain. compared proposed approach contemporary methods address problem wild curriculum domain adaptation following approaches designate images cityscapes test set. implementation details experiments images resized cropped trained model iterations using adam solver batch size learning rate used networks networks. evaluating cityscapes dataset whose images ground truth annotations size ﬁrst produce predictions sized image upsample predictions factor ﬁnal label used evaluation. make models code publicly available. experiment synthia dataset source domain cityscapes target domain. randomly pick images labeled images synthia dataset validation purposes rest images used training. unlabeled images corresponding cityscapes train training model. order ensure fairness experimental results followed exact evaluation protocol speciﬁed previous works common classes synthia cityscapes chosen used labels. predictions corresponding classes treated belonging void class backpropagated training. classes building road sidewalk fence vegetation pole trafﬁc sign person bicycle motorcycle trafﬁc light wall rider. table reports performance method comparison source-only model corresponds adaptation case i.e. training using source domain data achieves mean target-only values denote performance obtained model trained using cityscapes train serve crude upper bound domain adaptation performance. values included perspective performance gains obtained proposed approach. observe method achieves mean thereby improving baseline points thus resulting higher performance improvement compared reported methods. experiment adapt gta- dataset citysapes dataset. randomly pick images labeled images gta- dataset validation purpose rest images training. unlabeled images corresponding table results semantic segmentation adapting sytnhia cityscapes gta- cityscapes. compare approaches different base networks. obtain fair idea performance gain compare curriculum approach uses base network ours. target-only training procedure settings since cases target domain cityscapes. however results reported common classes results reported classes. cityscapes train training model. order ensure fairness experimental results followed exact evaluation protocol speciﬁed previous works common classes gta- cityscapes labels. results experiment reported table. similar previous experiment baseline performance higher performance reported difference network architecture experimental settings. this proposed approach yields improvement points obtain miou performance gain higher achieved compared approaches. note regarding different baselines baseline numbers reported match ones reported different experimental settings however would like point improve stronger baseline compared methods adaptation experiments. addition uses additional data pascal-context dataset obtain superpixel segmentation. contrast approach single stage end-to-end learning framework additional data obtains better performance improvement. section perform several exploratory studies give insight functionality effectiveness proposed approach. similar previous section evaluation results reported cityscapes unless speciﬁed otherwise. denote test set. would like note owing space constraints added example results label predictions images sampled generator network supplementary material. datasets considered paper consists images large resolution atleast twice larger commonly used segmentation benchmarks cnns i.e. pascal mscoco setting instructive understand effect image size performance algorithm quantitative computational perspective. table presents results approach applied three different image sizes along training evaluation times. noted curriculum approach used resolution comparing main results table approach provides table mean values computation times across different image size synthia cityscapes setting. numbers bold indicate absolute improvement performance source-only baseline. reported training evaluation times proposed approach averaged training evaluation runs. generative methods style transfer achieved great amount success recent past. simple approach performing domain adaptation approaches data augmentation method transfer images source domain target domain provided source ground truth train classiﬁer combined source target data. order compare proposed approach direct data augmentation procedure used state generative approach transfer images source domain target domain. observed results using generative approaches solely data augmentation method provides relatively small improvement source-only baseline clearly suboptimal compared proposed approach. augmenting feature learning process gradients pair method achieves superior performance reliable cases approaches based pure generation fail improve. experiment highlights difﬁculty achieving domain adaptation performing direct style transfer. table comparison semantic segmentation performance synthia cityscapes setting using based approach data augmentation. cyclegan cross domain generation procedure. following cases ours full implementation approach auxiliary pixel-wise loss here output network single branch classifying input real/fake. corresponds -update step. note that setting zero corresponds source-only setting experiments. setting improve source-only baseline cross domain adversarial loss. patch discriminator instead using network patch discriminator used regular gan-like discriminator output probability vector input image belongs four classes srcreal src-fake tgt-real tgt-fake. feature space based setting remove networks apply adversarial loss directly embedding. similar global alignment setting fcn-in-the-wild approach crucial aspect domain adaptation ﬁnding good measures domain discrepancy provide good illustration domain shift. exist several classical measures a-distance case image classiﬁcation extension measures pixel-wise problem semantic segmentation non-trivial. section devise simple experiment order illustrate proposed approach brings source target distributions closer learnt embedding space. start last layer network label embedding layer whose output spatial feature map. perform average pooling reduce spatial dimensional feature descriptor input image. begin cross domain retrieval task choosing pool nsrc +ntgt images combined source target training set. denote images denote feature descriptors computed then choose query sets consisting source images consisting target images disjoint corresponding feature sets denoted retrieve k-nn lists item query combined feature query point count number target samples retrieved corresponding k-nn list. |ak| indicates average number target samples retrieved entire source query query point count number source samples re|bk| indicates trieved corresponding k-nn list. average number source samples retrieved entire target query used cosine similarity metric compute k-nn lists. target samples retrieved source query point suggests source target distributions aligned well feature space. experiment sizes query sets feature follows nsrc ntgt |qs| |qt| mean average precision computed across entire query sets respective cross domain tasks. figure shows plot quantities |ak| |bk| range values observed plots tasks given rank number cross domain samples retrieved adapted model higher sourcemodel. effect becomes clear increases. observation supported better values adapted model shown figure sufﬁcient condition better segmentation performance however along results table imply proposed approach performs domain adaptation meaningful manner. owing difﬁculty visualizing mapping learned segmentation tasks cross domain retrieval experiment seen reasonable measure domain reduced feature space. desirable characteristic domain adaptation algorithm domain generalization i.e. improving performance domains seen training. test generalization capability proposed approach test model trained synthia cityscapes setting camvid dataset choose evaluate models common classes among three datasets. details regarding choice classes given supplementary material. table shows mean values computed source-only baseline adapted model. proposed approach yields improvement points performance signiﬁcant improvement considering fact camvid images seen adapted model training. experiment showcases ability proposed approach learn dofigure illustration domain adaptation achieved proposed approach. plot compares average number retrieved sampled cross domain retrieval task described section source-only model model adapted using proposed approach. target source implies query used belongs target domain items queried belong source domain vice-versa source target. general values plotted y-axis corresponds number samples retrieved belong opposite domain query set. paper addressed problem performing semantic segmentation across different domains. particular considered hard case abundant supervisory information available synthetic data information available real data proposed joint adversarial approach transfers information target distribution learned embedding using generator-discriminator pair. shown superiority approach existing methods address problem using experiments large scale datasets thus demonstrating generality scalability training procedure. furthermore approach extra computational overhead evaluation critical aspect deploying methods practice. future work would like extend approach explicitly incorporate geometric constraints accounting perspective variations adapt temporal inputs videos across different domains.", "year": 2017}