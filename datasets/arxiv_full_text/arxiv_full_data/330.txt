{"title": "Recognizing Semantic Features in Faces using Deep Learning", "tag": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "abstract": "The human face constantly conveys information, both consciously and subconsciously. However, as basic as it is for humans to visually interpret this information, it is quite a big challenge for machines. Conventional semantic facial feature recognition and analysis techniques are already in use and are based on physiological heuristics, but they suffer from lack of robustness and high computation time. This thesis aims to explore ways for machines to learn to interpret semantic information available in faces in an automated manner without requiring manual design of feature detectors, using the approach of Deep Learning. This thesis provides a study of the effects of various factors and hyper-parameters of deep neural networks in the process of determining an optimal network configuration for the task of semantic facial feature recognition. This thesis explores the effectiveness of the system to recognize the various semantic features (like emotions, age, gender, ethnicity etc.) present in faces. Furthermore, the relation between the effect of high-level concepts on low level features is explored through an analysis of the similarities in low-level descriptors of different semantic features. This thesis also demonstrates a novel idea of using a deep network to generate 3-D Active Appearance Models of faces from real-world 2-D images.  For a more detailed report on this work, please see [arXiv:1512.00743v1].", "text": "human face constantly conveys information consciously subconsciously. however basic humans visually interpret information quite challenge machines. conventional semantic facial feature recognition analysis techniques mostly lack robustness suffer high computation time. paper aims explore ways machines learn interpret semantic information available faces automated manner without requiring manual design feature detectors using approach deep learning. study effects various factors hyper-parameters deep neural networks investigated optimal network conﬁguration accurately recognize semantic facial features like emotions gender ethnicity etc. furthermore relation effect high-level concepts level features explored analysis similarities low-level descriptors different semantic features. paper also demonstrates novel idea using deep network generate active appearance models faces real-world images. picture worth thousand words many words picture face worth? humans make number conscious subconscious evaluations person looking face. identifying person deﬁning inﬂuence conversation based past experiences; estimating person’s making judgement ethnicity gender etc. makes sensitive culture habits. also often form opinions person analyse facial expressions gauge emotional state identify non-verbal communication messages intent convey information interacting other. fact argued neonates hours able interpret basic emotions faces form preferences older humans ability highly developed forms important skills social professional interactions. indeed hard imagine expression humour love appreciation grief enjoyment regret without facial expressions. predominantly following semantic features human face form primary information directly inferred faces humans expressed emotion gender ethnicity. addition these certain ‘add-on’ features like presence glasses facial hair inherent properties face also considered study. main objective paper build study deep learning based solution extract semantic features images faces. sub-section describes main questions researched course achieving objective. design deep neural network particular task involves determining multiple conﬁgurations parameters ensure network well suited task hand. every combination hyperparameters affects output system differently. therefore questions researched part paper could deep learning technique adapt task semantic facial feature recognition? question closely followed determining different conﬁgurations hyper-parameters scale input addition pre-processing steps affect performance accuracy system. figure conventional facial feature extraction pipeline layers combine low-level information determine higher-level concepts. respect deep network trained recognize different semantic features faces question asked high-level semantic descriptions related low-level feature descriptors? low-level descriptors deep networks trained classify different semantic features faces related other? finally several attributes human faces whose semantics easily deﬁned. example contraction speciﬁc facial muscles locations certain landmarks face lead easily interpretable semantic information. however information useful certain in-depth analysis good representation information achieved active appearance model face. leads following research question deep learning based method capable generating active appearance models faces images? typical conventional approach task facial feature recognition essentially follows pipeline shown figure majority conventional commercial facial analysis methods rely facial action coding system involves identifying various facial muscles cause changes physical facial appearance. uses model based approach called active appearance model classify emotion building model face encodes facial landmarks facial muscular movements derived. active appearance model generated using directly pre-processed pixels encoded deviation face average face. model used classify emotions expressed face using single layered neural network. primary tasks within ﬁeld computer vision detection tracking classiﬁcation. advent deep learning state-of-the-art three tasks considerably improved. successful demonstration capability deep learning task image classiﬁcation/detection done results also showed detector sensitive non-target high-level categories encounters dataset study presents important pooling rectiﬁcation contrast normalization steps deep convolutional neural networks. hinton srivastava successfully demonstrate improvements training dropouts successful papers showing application deep learning methods speciﬁcally deep convolutional networks image classiﬁcation krizhevsky work focuses image recognition imagenet dataset work sermanet demonstrated integrated solution deep convolutional neural networks three tasks detection localization classiﬁcation. work attained state-of-the-art classiﬁcation+localization task. baccouche demonstrated -dimensional convolutional neural networks combination recurrent neural networks human-action classiﬁcation videos thus making spatial well temporal information frame sequences generate state-of-the-art results. context paper focus task facial feature recognition. large body research dedicated problem deep learning emerged highly promising approach solving tasks. recent study shown near-human performance using deep networks task recognizing identity person faces. preprocessing steps like face alignment frontalization large dataset robust invariant classiﬁer produced sets state-of-the-art labelled faces wild dataset work utilises modiﬁed version deep convolutional networks certain convolutional layers using unshared weights task emotion recognition faces tang’s sets state-of-the-art facial expression recognition challenge dataset. achieved implementing stage network convolutional network trained supervised manner ﬁrst stage support vector machine second stage trained output ﬁrst stage. recent work kahou successfully demonstrates multi-modal deep learning based framework emotion recognition videos. task recognizing semantic features faces essentially umbrella term deciphering information encoded faces general apparent not-soapparent. thus viewed task extracting datasets used training testing network paper emotion-annotated dataset facial expression recognition challenge multi-annotated private dataset vicarvision examples statistics datasets shown ﬁgure pre-processing steps divided parts seek minimize distinct properties input image variation location pose face variations lighting conditions contrast. basic pipeline pre-processing steps illustrated figure face location normalization find faces image using face detection algorithm extract face-crop. perform in-plane rotate remove tile faces resize image approximate scale face constant. done ensuring distance eyes faces constant. image subtract local mean pixel image norm equal pixel image subtract global mean pixels location throughout dataset divide standard deviation. throughout experiments mentioned paper training network done using stochastic gradient descent momentum mini-batch mode batches data samples. negative log-likelihood used objective function. learning rate training initialized linearly decreased epochs training. training evaluated using validation roughly size total dataset stopping criteria network training based misclassiﬁcation rate/mean squared error validation set. network tested test also contains data samples dataset. difﬁcult deep network able handle high variations pose faces lighting conditions image. thus becomes necessary preprocess input make faces uniform. section description experiments given results performance network various test sets provided. experiments performed nvdia theano framework based pylearn library primarily used experiments. sub-section describes experiments conducted emotion recognition task ferc dataset under different network conﬁgurations well training parameters. baseline useful note random classiﬁer produces accuracy single-layer softmax regression model gives accuracy. architecture hyper-parameters network obtained basis empirical results described later. input image form grayscale pixels arranged matrix ﬁrst hidden layer network convolutional layer kernel size stride dimensions. number parallel feature-maps layer output image produced layer passed local contrast normalization max-pooling layer kernel size stride dimension results subsampling factor hence resulting image size second hidden layer also featuremap convolutional layer kernel size output layer pixel image feeds directly third hidden layer network convolutional layer feature maps kernel size finally output layer dimension last hidden layer network fully connected linear layer neurons. dropout applied fully connected layer dropout probability output layer connected output layer composed neurons representing class label. dataset mutually exclusive emotional expression labels softmax operation performed output neurons class highest activation chosen. layers network made relu units/neurons architecture illustrated figure network trained using stochastic gradient descent described section performance network test viewed figure network able correctly classify test samples maintaining average precision class seen network precision classes except fear could visual appearance face expressing fear varies considerably different people often confused surprise sadness. noted plot disgust happy surprised show good discrimination qualities despite relatively samples training could relatively large difference visual appearfigure best performance ferc test total classiﬁcation accuracy network average precision class ance disgusted faces compared emotions. comparison sate-of-the-art state-of-the-art results complete ferc test total classiﬁcation accuracy achieved network similar architecture absence face location normalization preprocessing step sofmax layer along addition stage classiﬁer. experiment width convolutional network altered changing number feature maps network depth network altered addition removal convolutional layer network keeping fully connected layer always last position. figure shows heat-map table accuracy different depths widths network. seen lower depth width gives lowest accuracy higher depth width provide highest accuracy. suggests intuitive fact larger network better performance. closer examination results surface plot ﬁgure also show depth network higher impact compared width network. however layers impact seems figure network performance terms accuracy varying applications pooling local contrast normalization. smaller. similar effects seen width network. experiment conducted order determine closest-to-optimal combination local contrast normalization max-pooling within neural network layers. max-pooling essentially results non-linear down-sampling step introducing translation invariance reducing computational complexity. local contrast normalization another well-used step designing deep architectures ensures competition among activations nearby neurons normalizing locally respect other. purpose experiment network similar shown ﬁgure without pooling layers considered baseline. max-pooling applied three locations within network outputs ﬁrst second third convolutional layers. figure network performance terms accuracy varying magnitudes dropout probability ﬁnal fully connected layer convolutional layers. max-pooling outputs ﬁrst convolution layer applying gives best results. simply applying without pooling outputs degrades results might absence pooling normalizing outputs locally leads extra emphasis certain noninformative activations also applying pooling network relatively advantageous starting layers network. could attributed fact activations deeper layers represent information activations starting layers hence down-sampling outputs lead loss useful information. dropout essentially means randomly omitting neurons layer certain probability. dropout important recent improvement neural networks. works equivalent adding random noise representation performing model averaging helps reduce overﬁtting results experiment shown figure observed fully-connected layer dropout probability gives best performance applying dropout convolutional layers results reduction performance. results support optimzsed network architecture used best performance obtained using dropouts fully connected layers. attributed fact fullyconnected layers prone overﬁtting additional noise caused dropouts could adversely affecting convolutional feature detector. sub-section details results experiments conducted dataset provided. time experiments focus network optimisation. network used training testing recognition various features dataset architecture deﬁned section optimized network ferc dataset. experiments follow training network done described section task emotion classiﬁcation dataset similar ferc dataset. however difference datasets emotion classes uniformly distributed seen figure network produced total classiﬁcation accuracy average precision performance network quite similar seen ferc dataset. average precision score closer total classiﬁcation accuracy uniform class distribution dataset. curves happy neutral show best-learned classiﬁcation categories network although labels also decent amount area curves experiments input image resolution results ethe experiments using different image sizes observed figure .the performance network image sizes reduces smoothly smaller image sizes. performance network drops image size increased pixels could fact using constant sized convolution kernel scaling input image size experiments pre-processing found global contrast normalization pre-processing step gives performance boost around classiﬁcation accuracy face alignment step improves accuracy roughly figure classiﬁcation dataset total classiﬁcation accuracy .%/.% year/± year resolution. average precision younger years group .%/.%. image. labels represent year intervals around ages multiples accommodate this ﬁnal softmax layer network architecture neurons class. network trained usual performance network test seen figure green squares represent correct classiﬁcation within ±.year resolution orange squares represent correct classiﬁcation within ±year resolution. seen distribution within dataset quite skewed towards range result seen confusion matrix bias network towards class. also note extreme lack data samples range network performance severely degraded. main reason average precision high total classiﬁcation accuracy. task estimation faces something humans inherently. observed estimation humans accurate range figure shows performance deep network approach automated estimation dataset estimation humans various resolutions fg-net ageing dataset. similarity type images reasonably large size fg-net dataset dataset assume performance humans similar dataset. seen performance deep network estimation fairly close humans. test performance network plotted figure a.the network able correctly classify faces test curve shows good discrimination characteristics. examples falsely classiﬁed faces seen figure large portion misclassiﬁed faces young children. misclassiﬁed images also include difﬁcult classify faces non-prominent mixed gender features lastly also exist small portion examples incorrect ground truth overall classiﬁcation accuracy presence hard-to-classify faces test suggests network performs near human level task gender classiﬁcation. deep network’s ﬁnal softmax output layer altered annotation setting number neurons network produced total classiﬁcation accuracy average precision classes also apparent figure distribution classes highly uneven caucasian east asian samples abundant african south asian others. effect seen performance network network performs well caucasian east asian faces average precision classes anfigure examples synthetic faces used training network source images synthetic faces obtained using aam. important point network color information images ethnicity facial attributes exhibits high variance color skin. network trained using setup described previous experiments ﬁnal softmax later altered neurons presence glasses neurons amount mustache amount beard performance network test sets follows accuracy presence glasses amount beard amount mustache. curves classiﬁcation labels plotted figure seen network’s precision detecting presence glasses heavy mustache high. however slightly ambiguous deﬁnition light beard class dataset network learn precise light beard classiﬁers. active appearance model produces model face using compressed representation encodes shape appearance face together. brieﬂy mentioned section conventionally produced applying directly pre-processed pixels face image. shape appearance parameters within encoded deviation face average face. apart this also consists pose face angles made normal face respect axes. however mentioned pre=processing sub-section in-plane rotation image removes plane tilt face. finally annotation expressed network terms compressed vector parameters plus angles. network trained synthetic faces corresponding active appearance models generated conventional face modelling method described reason using synthetic faces instead real faces synthetic faces generated corresponding modelling error cosine similarity score obtained ground truth tested real faces similarity score tested synthetic faces. moreover pose estimation test faces produced average error .◦/.◦ axes real faces .◦/.◦ axes synthetic faces. seen figure generated face models resemble real faces terms shape pose quite well. experiments explained above deep network required trained speciﬁc annotation-image pairs given task. however argued highlevel features faces combinations certain low-level features faces many low-level features common among different high-level feature descriptions. similarity first-layer weights study mentioned argument sub-section compares lowlevel descriptors combine form different higher level concepts. careful observation ﬁrst convolution layer reveals similarity general pattern weights feature-maps. figure illustrates heat-table cosine similarity scores ﬁrst layer weights networks trained different high level feature recognition certain patterns observed results. weights facial-hair gender similar could related fact females young children facial hair hence presence absence facial-hair good indicator person’s gender age. could also reason high similarity gender weights. weights emotions dissimilar weights ethnicity gender glasses facial-hair factors inﬂuence facial expressions person. hand weights joint classiﬁcation similar tasks since joint classiﬁcation involves classiﬁcation features. general could observed given task seems strong effect lower-level descriptors. higher correlation weights similar visual tasks also observed seen visually dissimilar tasks figure cosine inter-similarity scores ﬁrst-layer weights learnt network different tasks. exhibit lower correlation. joint classiﬁcation experiment order exploit low-level similarity observations previous subsection single network needs trained jointly classify multiple non-exclusive facial features. order achieve this different annotations image dataset combined single image annotation pair annotations represented non-exclusive class labels. difference performance joint classiﬁcation network individual networks found small average lower accuracy individual networks. suggests deep network capable learning classify multiple semantic features faces joint manner. conclusion paper deep learning based approach demonstrated task semantic facial feature recognition. approach primarily based convolutional neural networks dimensional pre-processed aligned images faces. study exploring effects network hyper-parameters classiﬁcation performance conducted leading estimation near-optimal conﬁguration network. study suggests deep convolutional network based approach naturally well suited task image based facial expression recognition. shown addition deterministic pre-processing alignment steps input data greatly aids improving performance. deep network easily adapted tasks recognizing additional semantic features. experimental results shown near-human performance. however discrimination power deep networks highly dependent distribution quality training data. relation high-level semantic features low-level descriptors also studied. speciﬁc intuitive similarities observed low-level descriptors different tasks. commonality among lowlevel descriptors demonstrated training single network jointly classify multiple semantic facial features. finally novel scheme training deep networks generate complete active appearance models faces images shown. best knowledge ﬁrst time deep networks used predict compressed image representation task also successfully achieved network.", "year": 2015}