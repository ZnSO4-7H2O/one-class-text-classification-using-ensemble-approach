{"title": "On Classification with Bags, Groups and Sets", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "Many classification problems can be difficult to formulate directly in terms of the traditional supervised setting, where both training and test samples are individual feature vectors. There are cases in which samples are better described by sets of feature vectors, that labels are only available for sets rather than individual samples, or, if individual labels are available, that these are not independent. To better deal with such problems, several extensions of supervised learning have been proposed, where either training and/or test objects are sets of feature vectors. However, having been proposed rather independently of each other, their mutual similarities and differences have hitherto not been mapped out. In this work, we provide an overview of such learning scenarios, propose a taxonomy to illustrate the relationships between them, and discuss directions for further research in these areas.", "text": "many classiﬁcation problems diﬃcult formulate directly terms traditional supervised setting training test samples individual feature vectors. cases samples better described sets feature vectors labels available sets rather individual samples individual labels available independent. better deal problems several extensions supervised learning proposed either training and/or test objects sets feature vectors. however proposed rather independently other mutual similarities diﬀerences hitherto mapped out. work provide overview learning scenarios propose taxonomy illustrate relationships them discuss directions research areas. recent years ﬁeld pattern recognition seen many problems diﬃcult formulate regular supervised classiﬁcation problems pairs available train classiﬁer that turn predict labels previously unseen feature vectors. subset problems contains learning scenarios objects represented sets bags feature vectors instances. learning scenarios include multiple instance learning classiﬁcation group-based classiﬁcation many others. paper review learning scenarios. several reasons representation might chosen pattern recognition problem. ﬁrst reason single feature vector often restrictive describe object. example drug activity prediction interested classifying molecules desired eﬀect not. however molecule list elements molecules fold diﬀerent shapes conformations inﬂuence activity molecule. furthermore number stable shapes figure supervised learning extensions. mi-mi scenario training test objects bags. mi-si scenario training objects bags test objects instances mi-si scenario training objects instances test objects bags. second reason labels level feature vectors diﬃcult costly and/or time-consuming obtain labels coarser level obtained easily. computer aided diagnosis applications expensive radiologist label individual pixels voxels image healthy diseased feasible full image large image regions single label. coarsely labeled scans regions used train classiﬁer predict labels level i.e. complete patient scans ﬁner grained region instance level e.g. labeling individual pixels voxels. another reason consider labeling bags instances instead single feature vectors structure labels instances. example face veriﬁcation video person available considering video frames jointly provide conﬁdent predictions labeling frames individually combining decisions. similarly neighboring objects images videos sounds time series forth typically correlated thus classiﬁed independently. examples diﬀerent goals assumptions therefore require diﬀerent representations training test phase. possibilities shown fig. occur training test objects single instances bags i.e. multiple instances traditional supervised learning si-si scenario training test objects instances. predicting molecule activity mi-mi scenario training test objects bags. image classiﬁcation problems found mi-mi scenario well mi-si scenario face veriﬁcation problem best represented si-mi scenario diction often motivates researchers method diﬀerent application image classiﬁcation. however necessarily case assumptions ﬁrst application still hold. example assumptions relationships instance labels diﬀerent molecules images lead poor performances. hand also happen type problem occurs diﬀerent applications researchers respective ﬁelds approach problem diﬀerent ways without beneﬁting other’s ﬁndings. therefore believe understanding relationships learning scenarios importance researchers diﬀerent ﬁelds. work goal provide overview learning scenarios bags instances play role stages learning classiﬁcation process provide insight interconnections. gathered papers proposed novel learning scenarios often combining synonyms word words classiﬁcation learning. work intended survey learning problems classiﬁers particular scenario although refer existing surveys type whenever possible. furthermore mainly focus single-label binary classiﬁcation scenario. focus complimentary multi-label and/or multi-class setting problem formulations covered work extended multi-label multi-class. examples found paper begins overview applications motivate representation section assumptions associated applications. explain categories learning scenarios methodologies used learn scenarios section paper concludes discussion section molecule activity prediction goal predict whether previously unseen molecule desired activity example whether protein binds another protein thus inﬂuences biological process. often molecules diﬀerent conformations shapes fold into inﬂuence binding properties. naturally diﬀerent molecules diﬀerent numbers conformations. therefore possibility represent molecules conformations. existing molecules however information conformations active available. possible assumption case least conformations active molecule regarded active. assumption used entails instances labels least instance positive positive well. aligning clouds comparing directly function previously unseen molecules predicted. assumption used instances labels logical atom active inactive certain combinations instances lead diﬀerent labels. words most instances contribute label. group image classiﬁcation applications bags images instances parts images pixels blobs segments. examples include natural scene classiﬁcation object recognition medical imaging often assumption parts image contribute image label. example image tiger surroundings present lung scan patient lung disease healthy lung tissue present well instance therefore label popular assumption call standard assumption least instance positive also positive. goal label novel images hand standard assumption might always suﬃcient. example instances pixels might suitable deﬁne pixels belonging tiger concept. perhaps fraction positive instances suitable. beach concept instances containing sand instances containing water might needed therefore asking conjunction concepts. relaxed assumptions deal problems described another assumption instances share label. assumption used classifying groups cells healthy anomalous added information cells group share label. although training done using labeled cells test phase might advantageous classify cells jointly rather using two-step approach cells classiﬁed ﬁrst decisions combined. general deﬁnition generation instances inﬂuences reasonable application hand. typically knowledge involved generating instances assumptions could applicable. consider application photographs photograph labeled people photo. face detector generate candidate instances reasonable assume instance corresponds person photograph opposed situation randomly sample patches images. another group applications instances images bags groups images videos. setup common face recognition example several images person available training. course assumption instances label. goals label single image group images. image annotation similar image classiﬁcation sense often bags images instances parts images. however goal diﬀerent instances rather bags need labeled. example goal label pixels patches belonging background objects portrayed image. goal classify segments spectrograms bird song recordings belonging particular bird species training spectrogram-level annotations. goal achieved supervised learning providing fully annotated training images pixel segment labeled. however providing annotated images costly especially medical imaging applications easier provide weakly annotated data case assumption image positive contains object interest negative not. sometimes additional assumptions used well. example bags labeled category also fraction instances contain tigers. information available label distribution output therefore reducing search space classiﬁer. even constraint instance allowed particular label example labeling faces photograph names another common example assumption spatially neighboring instances correlated therefore likely label regions interest medical images weakly annotated data also beneﬁt tracking instead providing instances tracked object learner bags patches used improve performance. however goal tracking algorithm label patches bags. document article email discussion website represented collection parts paragraphs individual webpages often described bag-of-words histograms. applications goal assign category unlabeled documents. again diﬀerent assumptions might applicable here less appropriate depending types documents document categories question. assumption positive least positive instance seems applicable consider classifying biomedical articles relevant particular gene ontology code. least paragraph relevant whole article considered relevant. classifying general-purpose documents websites email discussions situation might different. example social websites page describing security settings would wrong websites security category. application websites classiﬁed described website represented feature vectors assumptions made label relationships instance labels. applications goal classify unlabeled bags. however images documents also interested instance labels i.e. labeling individual emails webpages assumption often used cases neighboring instances webpages link other correlated labels. applications instances representation used detecting hard drive failures detecting fraudulent ﬁnancial accounts music information retrieval spam ﬁltering advertising several reasons motivate representations. cases weak labels provided clear instances correspond labels. example hard drive failures bags time series diﬀerent measurements hard drives known hard drive whether failure occurred not. however diﬃcult delineate exact time frame corresponds failure therefore multiple frames used instead. cases labels provided along percentages instance labels. example spam ﬁltering possible estimate proportions spam/normal particular user helps classify individual emails later advertising estimated proportion customers would product discount proportion would product circumstances. advertising campaign proportions help predict customers receive discount coupon rather diﬀerent case others addressing privacy issues application instance labels might available shared stored. instead could less problematic provide labels entire groups people collective income fraction group particular label. based information goal label instances assessing individual customers applying loan. notation overview mathematically instance represented single feature vector d-dimensional space represented feature vectors {xik; ...ni} denote possible classes possible labels case object class label focus overview multi-label scenario test object instance interested ﬁnding instance classiﬁer test object generally interested ﬁnding classiﬁer special cases tions labels instances labels bags related example assumption could instances label. assumptions play important role learning algorithms developed. characteristics lead categories leftmost column table following subsections organized ﬁrst characteristics explain category corresponding learning scenarios assumptions equivalence diﬀerent terms literature category empty. ﬁrst category table contains traditional supervised learning training test objects assumed independently generated underlying class distributions. assume reader familiar supervised learning. general introduction refer assumption independently drawn train test instances best possible approach train instance classiﬁer classify feature vector individually. however situations data independently generated make assumptions correlations data assumptions improve performance. classical rather general model dependencies observations markov random ﬁelds related currently popular conditional random ﬁelds crfs originally described setting labeling sequences assigning part-of-speech tags words sentence although graph structures also deﬁned. supervised learning batch classiﬁcation collective classiﬁcation sets feature vectors multiple instance learning multiple instance learning aggregate output learning learning label proportions group-based classiﬁcation classiﬁcation full-class classiﬁcation words. output space classiﬁer i.e. possible combinations parts-of-speech. labels space course dissected provide instance labels sentence classiﬁer originally interested batch classiﬁcation labeled instances available training goal label instances therefore task si-si category. however authors observe application correlations exist instances therefore advantageous label bags instances instead. correlations provided covariance matrix instances. instance classiﬁer bag-level constraints trained ﬁrst. test phase instance classiﬁed weighted average instances correlated although done explicitly also learning approach convert si-si task mi-mi task. collective classiﬁcation goal label instances given distinguishes types correlations exist instances. local approaches this call local global. approaches instance classiﬁers trained although relational features i.e. features encoding labels correlated instances also used. test phase initial prediction label test instance updated based labeling test instances. this turn changes relational features. process repeated iteratively. thus instance classiﬁers used bag-level constraints part encoded feature representation rather learning algorithm. training objects test objects bags additional assumptions labels present goal classiﬁcation sets feature vectors result possible strategy train classiﬁer comparing bags directly. possible deﬁning distances kernels bags embedding bags vector space. well-known kernel bags convolution kernel instances compared instances another kernel feature vectors gaussian kernel. assumption implicitly made instances contribute label. similar assumption made works regard bags samples probability distributions deﬁne kernel divergence distances hausdorﬀ distance variants also introduce certain assumptions. example deﬁnition mink minl assumes similar instances contribute similarity bags. alternative approach learn deﬁne single instance representation therefore embedding bags vector space. done summarizing instance statistics words representations representing distances training data standard supervised classiﬁer used representation. sense problem converted si-si learning task. another domain training test objects bags stronger assumptions made called multiple instance learning objects referred bags instances. originally labels instances positive least positive instance inside bag; negative instances negative. main approaches achieve goal classifying bags. assumption relationship instance labels earlier methods focused ﬁrst ﬁnding instance classiﬁer applying combining rule instance outputs. traditional assumption deﬁned noisy function follows relaxed formulations traditional assumption also proposed instance positive needs speciﬁc fraction positive instances. alternative assumptions still possible ﬁrst apply appropriate determine labels test bags. assuming instances contribute independently instance replaced product rule generalized rules combining instance posterior probabilities. several methods moved away using explicit assumptions relationships instance labels learn using assumptions bags whole therefore taking detour classiﬁcation scenario above. words methods ﬁnding directly rather combination approaches applied above i.e. deﬁning distances kernels embedding bags vector space. approaches used practice implicitly assume instances contribute label. extensive surveys assumptions classiﬁers found section concerned case training data labeled bag-level instance-level labels desired test phase. note possible assumptions made label transfer instances bags. mi-si weak assumptions category table empty making additional assumptions however something said instance-level labels test data. standard assumption multiple instance learning possibilities train classiﬁer using labeled bags provide instance-level labels test data. although originally goal train classiﬁer provide labels bags side-eﬀect algorithms instance labels predicted well. fact labels required produce instance labels means less labels required usual supervised setting. goals classifying instances classifying bags identical therefore many cases optimal classiﬁer optimal instance classiﬁer vice versa. important reason standard assumption. classiﬁcation done combining instance predictions false negative instances going less eﬀect performance false positive instances. consider positive positive instance misclassiﬁed negative positive instances negative instance falsely classiﬁed positive label still correct. however negative label changes soon single instance misclassiﬁed. similar observations made general reason optimal instance classiﬁers necessarily correspond unequal sizes. misclassifying instances less eﬀect instance performance misclassifying many instances. goals user goal classiﬁer therefore matched instance labels cases used caution. point important mention learning weakly annotated data links semi-supervised learning learning positive unlabeled data ﬁelds deal weakly annotated data sense annotated not. multiple instance learning data annotated however perspective instances annotations weak. semi-supervised positive-and-unlabeled scenarios deal bags either stage classiﬁcation process elaborate survey however connections ﬁelds found scenarios training objects bags learning individuals group statistics aggregate output learning learning label proportions independent names related ideas. labels class labels proportions class labeled positive negative. scenarios seen subset multiple instance learning fraction positive instances bags already speciﬁed. exact fraction stronger assumption non-zero fraction therefore easier learn witness rate given. real-life datasets assumes positive exactly positive instances. methods take advantage estimating witness rate ﬁrst using estimate build instance classiﬁers turn scenario instance-level labels available training bag-level labels needed test phase. assumptions made instance labels related impossible task reason category corresponding si-mi assumptions table empty. however similarly si-si approaches additional assumptions section dependencies feature vectors inside test exploited improve overall classiﬁcation. diﬀerence methodologies described section here interested labeling test bags instances. situation occurs group-based classiﬁcation classiﬁcation independently proposed names setting test objects sets feature vectors class. note setting easily transferred mi-mi scenario instances label straightforward create bags instances vice versa. classiﬁcation test distance-based done modifying supervised versions nearest neighbor nearest mean classiﬁers. broad approaches called voting pooling scheme. voting scheme instance labeled classiﬁer nearest neighbor labels combined majority voting pooling scheme distances aggregated ﬁrst converted label bag. results show pooling scheme produces better results. similar results obtained classiﬁcation instances done levels instances bags. although instance-level labels available instance classiﬁer built considering bag-level labels still beneﬁcial performance. several approaches studied straightforward approach involves combining predictions instance test phase i.e. deﬁning combination several instance classiﬁers. best performing approach borrows mi-mi scenario training test phase instance subsets generated. kernels deﬁned subsets test classiﬁed combining predictions subsets. added information instances share label examples setting testing objects bags. reversed setting full-class classiﬁcation additional constraint instances unique label i.e. known beforehand instance labels present bag. output classiﬁer instance labels jointly guaranteed perform better concatenating outputs instance classiﬁers note although instance labels obtained labels interested labels performance evaluated level either instances labeled correctly not. illustrate diagrams fig. many classiﬁcation problems deal objects represented sets feature vectors so-called bags instances. popularity surprising several motivating reasons choosing representation stages classiﬁcation process. firstly feature vectors provides greater representational power single feature vector might logical express multiple entities single entity. secondly often labels might available level costly obtain instance level therefore using instances representation form weak supervision. lastly advantageous consider bags whole rather independent instances relationships instances single bag. figure variants si-mi scenario. training objects instances test objects bags although labeled instance labels case instance labels decided jointly classiﬁer instance classiﬁer presented taxonomy illustrates relationships scenarios deal bags four categories si-si mi-mi mi-si si-mi according whether single instances multiple instances available training test phases learning scenarios. taxonomy becomes clear popularity representation also dangers several diﬀerent learning scenarios sometimes deﬁned problem several diﬀerent problems incorrectly grouped learning scenario hinder research progress connections existing learning scenarios missed erroneous connections therefore erroneous assumptions made. algorithms used across four categories diverse many supervised methods nearest neighbor classiﬁer extended work learning scenarios. important observation across algorithms main approaches direct training done type input originally available indirect training occurs converting problem diﬀerent scenario usually additional assumptions. canonical examples consider training labeled bags unlabeled instances test unlabeled bags example direct approach deﬁne distance bags nearest neighbor classiﬁer. example indirect approach assume proposed taxonomy allows heterogeneity training test objects limited training test objects homogeneous. would interesting investigate happens case training phase labeled bags labeled instances available already discussed section optimal classiﬁer necessarily correspond optimal instance classiﬁer. therefore deciding best available labels depend whether bags instances classiﬁed test phase. however bags instances expected classiﬁcation test phases? straightforward solution would train separate instance classiﬁers instance labels related integrated classiﬁer would perhaps suitable. another interesting observation hybrid categories taxonomy attracted attention learning scenarios proposed need rely strong assumptions relationships instance labels. questions raises minimal assumptions needed learn situations? furthermore learning scenarios reviewed exhaustively cover types constraints could present instance labels. learning scenarios proposed future gaps easily placed context works described overview. development would beneﬁcial ﬁeld collection instance-labeled benchmark datasets several scenarios adopted. would enable comparisons algorithms single scenario often done literature comparison diﬀerent learning scenarios thus suitable problem hand. authors would like thank brijnesh jain kind suggestions leading improve paper. anonymous reviewers kindly acknowledged critical comments suggestions.", "year": 2014}