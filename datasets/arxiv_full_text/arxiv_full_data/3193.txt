{"title": "Collaborative Receptive Field Learning", "tag": ["cs.CV", "cs.LG", "cs.MM", "stat.ML"], "abstract": "The challenge of object categorization in images is largely due to arbitrary translations and scales of the foreground objects. To attack this difficulty, we propose a new approach called collaborative receptive field learning to extract specific receptive fields (RF's) or regions from multiple images, and the selected RF's are supposed to focus on the foreground objects of a common category. To this end, we solve the problem by maximizing a submodular function over a similarity graph constructed by a pool of RF candidates. However, measuring pairwise distance of RF's for building the similarity graph is a nontrivial problem. Hence, we introduce a similarity metric called pyramid-error distance (PED) to measure their pairwise distances through summing up pyramid-like matching errors over a set of low-level features. Besides, in consistent with the proposed PED, we construct a simple nonparametric classifier for classification. Experimental results show that our method effectively discovers the foreground objects in images, and improves classification performance.", "text": "good image representation ﬁrst concerns robust features. current feature learning methods propose learn midlevel features hierarchically built low-level ones also preferably learned adaptively rather hand-crafted ones e.g. sift hog. then various representation learning methods proposed spatial pyramid multiple layers pooling downsampling representations roughly preserve salient object structures thus enhance discriminativeness image representations. adaptively learned features discriminative representations classiﬁcation performance improved accordingly. methods cannot effectively handle large translations scales objects accuracy gains still limited. approaches attempting localize foreground objects better encoding images saliency detection segmentation object detection essentially methods cast so-called receptive ﬁeld learning intend desirable image regions particular tasks. example solve problem optimizing spatial pyramid matching building midlevel features method selectively combines pooled features predeﬁned image regions improve discriminability overall image representations. however method using mid-level features learns combination patterns images different categories thus still fails handling prominent translations scales individual images. effectively handle arbitrary scales translations objects propose framework called collaborative receptive ﬁelds learning intends discover speciﬁc receptive ﬁelds image regions challenge object categorization images largely arbitrary translations scales foreground objects. attack difﬁculty propose approach called collaborative receptive ﬁeld learning extract speciﬁc receptive ﬁelds regions multiple images selected rf’s supposed focus foreground objects common category. solve problem maximizing submodular function similarity graph constructed pool candidates. however measuring pairwise distance rf’s building similarity graph nontrivial problem. hence introduce similarity metric called pyramid-error distance measure pairwise distances summing pyramid-like matching errors low-level features. besides consistent proposed construct simple nonparametric classiﬁer classiﬁcation. experimental results show method effectively discovers foreground objects images improves classiﬁcation performance. widely known difﬁculty automatic object categorization images largely arbitrary translations scales foreground objects. solve problem researchers designed robust image features like sift image representation reliable image matching techniques image alignment detection mainly cover foreground objects category. corfl merely requires weak labels exact object location information category-level label image. moreover corfl learns rf’s collaboratively among multiple images common category thus leading reciprocal accuracies discovering common object. note deﬁnitions receptive ﬁeld neural science different keep using term highlight meaning rf’s images received computer capture distinct foreground object. model corfl selecting speciﬁc vertices graph constructed pairwise similarities candidates images. borrowing vision-based priors formalize problem submodular function simple greedy method sufﬁces produce performanceguaranteed solutions. however building graph ﬁnding right metric pairwise distance rf’s varying sizes nontrivial problem. intuitive represent mid-level feature concatenated multi-layer pooled vectors length. features usually thousands dimensions lose distinct information vector quantization sparse coding reason introduce pyramid-error distance nonparametric method measure distance image regions sets low-level sift features. perform corfl training images category purify training preserving rf’s capture meaningful foreground objects. proposed design nonparametric classiﬁer match qeury images puriﬁed training set. experiments synthetic data benchmark databases show effectiveness proposed framework. contributions paper organization ﬁrst review essential preliminaries section elaborate framework corfl section metric pyramiderror distance section designed nonparametric classiﬁer section respectively. evaluate framework experiments section concluding section three keywords framework receptive ﬁeld learning submodular function similarity metric. receptive field learning multiple problems computer vision seen receptive ﬁeld learning image understanding. example saliency detection aims discover regions capture human attention images perceptual biases; result detected salient regions anticipate better image matching considering salient regions besides image segmentation simplify change representation image something meaningful easier analyze requiring localization information sande salient regions multi-scale segmentation multiple cues detect object interest moreover considering object translations scales russakovsky propose object-centric spatial pooling approach ﬁrst infers location objects uses locations pool foreground background regions separately form mid-level features. learns object detectors weak labels i.e. exact object location information images. condition work. particular explicitly work receptive ﬁeld learning learning selectively combine pooled vectors predeﬁned grids demonstrated fig. method learns combination pattern across images different categories. therefore facing notable translation scale changes foreground objects cannot guaranteed achieve improved performance. moreover duchenne introduce graph-matching kernel address object deformations every pair images however kernel requires time calibrate images largescale datasets also fails calibrating images extremely cluttered backgrounds submodular function natural wide applicability submodular function makes receiving attention recent years ﬁnite ground set. function submodular here complement property referred diminishing return property stating adding element smaller helps adding larger one. properties submodularity please refer references therein. similarity metric similarity measurement image regions still open problem. recently combination mid-level features classiﬁer generally produce promising results mid-level features usually generated concatenating multi-layer features within spatial pyramid pattern demonstrated fig. learned convolutional neural networks however pairwise similarity mid-level worth noting difference candidates pooled features image grids speciﬁcally method ﬁnds desired rf’s capture foreground objects predeﬁned grids; selected rf’s form training used classiﬁcation. contrast spm-based methods concatenate pooled vectors ﬁnal representation overall image result method explicitly considers object scale translation individual images. addition girshick propose extract region proposals images object detection region proposals also seen candidates required warped brutal force ﬁxed size different methods transformation destroy information related object appearance shape. contrast method preserves valuable information allowing various sizes rf’s. inspired area saliency detection assume capturing object salient others mainly cover background object parts. words large contrast between image images. call intrainter-image prior respectively. therefore oracle rf+’s small similarities rf−’s i.e. pairwise similarities selected small. besides multiple images given common category image least makes correlated semantically capturing common objects. based repeatedness principle interimage relationship exploited considering similarities rf+’s different images large. moreover pairwise similarities rf−’s small since rf−’s mainly capture cluttered background seen noises. model priors build graph rm×m record similarities pair candidates. larger element means receptive ﬁelds similar other. measurement nontrivial problem rf’s continue elaborate corfl graph construction section oracle vertices rf+’s indexed similarities within rf+’s maxima. meanwhile summed similarity features cannot reliably measured euclidean distance high dimension vector quantization sparse coding stage extracting mid-level features among methods euclidean distance low-level sift descriptors motivates proposed metric. section present proposed framework collaborative receptive ﬁeld learning detail. weak labels multiple images common category corfl collaboratively extracts speciﬁc receptive ﬁeld capture common foreground objects. solving problem core proposed framework because perform corfl training images category purify training matching queries resultant images preserve meaningful foreground objects. ﬁrst demonstrate extract candidates present vision-based priors before formalism corfl. suppose images available speciﬁc category without loss generality predeﬁne templates extract candidates images. work deﬁne candidates shown fig. leading candidates total images. contrast approach deﬁnes grids overlapping grids capture foreground objects reliably correctly thus preventing computation covering object parts many image backgrounds. solve corfl selecting desirable image regions receptive ﬁelds capture common distinct objects images. particular specify number selected rf+’s then crucial point sketch mechanism desirable rf+’s call balance principle i.e. number image balanced. speciﬁcally index rf+’s image j=aj indices positive rf+’s. penalty term objective function balance number rf+’s images property demonstrates adding smaller elements achieves greater reward. particular graph deﬁned vertices preferred selected images another. result balancing number elements achieved. inspired saliency detection exploit center-bias principle mildly constrain w.r.t location image. speciﬁcally appears around center image high probability. mild center-bias constraint means that searching rf+’s focus around image center still allows capture desired locating near image margin high ﬁdelity. intuitively center bias modeled position rf’s. denote distances rf’s image center specifying center-bias constraint candidates. intuitive example constrain small means subvector comprising elements indexed specify constant scalar sufﬁcient large ensure positive; positive parameters jointly control relative importance terms. operation used ensure following submodular property following lemma require beneﬁt desirable submodularity monotonicity model principles ﬁnding rf+’s. hereafter rewrite explicitly highlight sole parameter since common weak labels enable images category correlated other reasonable image contribute itself. thus extract least training image. beneﬁt alternatively store reciprocal center distances need constrain leads relatively larger maximizing pushes mechanism focus rf’s around images’ centers. parameters control interintra-image prior term balance penalty term center prior term respectively. proposition below exactly receptive ﬁelds extracted. submodularity described proposition indicates simple greedy algorithm sufﬁces produce performance-guaranteed solutions theoretical approximation greedy search requires evaluations marginal gains adding element iteration. speed optimization process lazy greedy constructing heap structure marginal gains element. even addition element impacts gains remaining ones merely update gain element heap instead recomputing gains every remaining element. idea gain element never increase diminishing return property submodular function illustrated naive search method fig. moreover recomputation gain element heap much smaller many cases hence element stay element even update. worst case update gain element re-establish heap addition elements leading complexity rebuilding heap overall complexity optimization. practice lazy algorithm requires updates heap iteration. hence complexity optimization effectively figure illustration pyramid-error distance ﬁrst presents original images corresponding rf’s learned algorithm second row. third shows pairwise ped. encourages similarity rf’s class larger different classes. section investigate measure pairwise similarity rf’s constructing graph. rf’s essentially image regions varying sizes measuring nontrivial problem. intuitive idea borrow mid-level pooled features represent candidates pooling process generates feature vectors ﬁxed length. produce disastrous results high dimensionality vector quantization sparse coding. therefore introduce metric called pyramid-error distance split candidate pre-deﬁned grids multiple levels. instance three partition scale leading grids total. please note pyramid partitions done single instead overall image. totally different spm-based methods concatenate pooled vectors grids represent whole. throughout work extracted low-level sift features grid measuring similarity rf’s ﬁrst calculate distance pair grids rf’s corresponding position indexed rp|i rp|j sets consisting p-dimensional descriptors representing correbased ped. dense extraction sift descriptors consistently leads thousands descriptors constructing graph extremely time-consuming. expedite stage either turn fast approximate graph construction original sift feature incorporates interest point detection feature descriptor extraction. merely original sift feature. essentially interest point detection technique sift descriptors generated image ×-pixel resolution. then efﬁcient enough calculating pairwise among candidates constructing similarity graph experiments. moreover contrast dense extraction scheme produce unnecessary descriptors detection technique leads meaningful sift descriptors informative regions. sponding grids respectively. result even various sizes grids represented sets low-level features. please also note descriptor number necessarily equal number feature points automatically detected rf’s different sizes. deﬁne distance level below framework similar multi-instance learning particularity especially reﬂected principles like center-bias intrainter-image contrast. solving problem collaborative receptive ﬁeld learning design nonparametric classiﬁer incorporating rf-to-class metric centerbias penalty. learned rf’s training sift features grids corresponding positions pools denote store descriptors training images class speciﬁc grid indexed then query image method ﬁrst extracts sift features candidates then predicts label comparing rf-to-class distances categories section ﬁrst qualitatively validate effectiveness method corfl synthetic dataset discovering rf+’s images. then public benchmarks quantitatively evaluate method object categorization including caltech caltech finally discuss parameters used experiments. indexes grid speciﬁc location within deﬁned pyramid partition. third fig. calculated grid distances pair rf’s. analyze complexity naively assume ngrid descriptors grid calculating complexity respectively. also worth noting building similarity graph costly stage computation. popular methods usually adopt dense feature extraction scheme which supposedly descriptors extracted images speciﬁc category requires computational complexity constructing graph figure demonstration proposed submodular function exemplar selection synthetic data set. leftmost column display generated data points selected exemplars proposed submodular function rest columns marginal gain iteration. ﬁgure illustrates that objective function similar correlated exemplars found. generate dataset three gaussian distributions produce random points plate demonstrated ﬁrst upper-left panel fig. three clusters seen three images intersection seen common objects images meanwhile points away intersection imagined cluttered backgrounds. therefore objective function expected points located intersection. please note center-bias prior apply synthetic data; euclidean distance locations plate build similarity graph gaussian kernel controlled parameter better understand process plot marginal gains ﬁrst iterations fig. desirable points bottom-left panel. optimization done native greedy method. marginal gain iteration points near intersection larger expected gains. owing inter-image prior ﬁgure demonstrates effectiveness approach ﬁnding correlated rf’s cover common foreground object. caltech caltech contain categories images respectively. caltech higher intra-class variability higher object location variability caltech. resize every image -pixel resolution original aspect ratio. follow common setup benchmarks i.e. images class randomly selected training rest testing. perform corfl category exactly rf+’s extracted class. average performance random splits reported. compare method several state-of-the-art ones. approaches learn mid-level features lowlevel ones represent overall image including convolutional deep belief networks adaptive deconvolutional networks lc-ksvd kernel sparse coding based locality-constrained linear coding receptive field learning cdbn belong deep feature learning framework hierarchically learns adaptive features image. generate mid-level features spatial pyramid partition kernel classiﬁcation. lc-ksvd deeper approach simultaneously learns linear classiﬁer higher-level dictionary mid-level features. rest methods learn codebook hand-craft descriptors like sift macrofeature encode codebook vector quantization sparse coding; adopt pooling technique obtain feature vectors image regions w.r.t -layer-pyramid partition. finally concatenate pooled vectors larger image feature feed linear svm. additionally naive-bayes nearest-neighbor closely related ours directly uses dense sift descriptors image-to-class metric classiﬁcation. list comparisons table illustration selected rf+’s method displayed fig. ﬁrst fig. seen table method outperforms others. worth noting improvement method nbnn attributes sift extraction interest point detection. explicitly considers shape/structure objects interest point detection removes noisy descriptors. contrast nbnn merely constrains position distances dense sift small thus incorporates noisy descriptors fails handle notable changes object translation scale. also worth noting performance gain brought method caltech higher caltech. assume reason changes object translation scale larger caltech caltech. moreover observe cluttered background images better performance method achieves ﬁnding objects. functionality objective function intends desirable rf+’s leaves behind assumed rf−’s hold smaller pairwise similarities. figure larger means locating rf+’s center caltech images brutal force smaller value produces rf+’s merely capture object parts. real rf+’s found suitable whole object appears image center images. siﬁcation performance visualization learned receptive ﬁelds suffer all. reason guess objective function constrains assumed rf−’s large therefore larger indirectly contribute discovering rf+’s ﬁnding dissimilar rf−’s. moreover larger value guarantees training image contribute least merely ensure this. controls mild center-bias constraint impact performance. since foreground objects appear near center images suitable helps real rf+’s. demonstrated fig. construct similarity graph essentially normalize ped-based distance graph dividing largest element entries values range then transform similarity graph gaussian kernel controlled plot impacts fig. caltech database. intuitively normalized dissimilarity graph anticipate meaningful outcomes setting curve accuracy also demonstrates intuition. therefore throughout work. work introduce problem called collaborative receptive ﬁeld learning intends receptive ﬁelds image regions multiple images cover foreground objects common category. corfl merely exploits weak labels without exact locations objects image. modeling problem selecting speciﬁc vertices similarity graph consideration vision-based priors solve corfl submodular function simple greedy algorithm sufﬁces produce performanceguaranteed solutions. furthermore propose pyramid error distance measure pairwise distance rf’s. perform corfl images category purify training puriﬁed merely preserves meaningful foreground objects. moreover consistent design simple nonparametric classiﬁer ﬁnal classiﬁcation. building similarity graph exploit sift feature within proposed ped. even though fast graph construction techniques explored sophisticated representations receptive ﬁelds solicited consideration robustness efﬁciency. especially learning adaptive features within deep architecture exploited represent image regions learning adaptive metric matching also research direction image region matching. model problem simple submodular function exploiting weak labels considerations worth exploring e.g. semi-supervised learning images providing accurate object locations. even model provides philosophy scale translation invariant region matching also consider arbitrary rotation sophisticated region representations discussing parameter interestingly meaningful patches selected instead whole foreground objects. motivate think learning discriminative image patches among images similar particular work also beneﬁt part-based model speciﬁc problems ﬁnegrained recognition farrell ryan zhang ning morariu vlad darrell trevor davis larry birdlets subordinate categorization using volumetric primitives pose-normalized appearance. iccv honglak grosse roger ranganath rajesh andrew convolutional deep belief networks scalable unsupervised learning hierarchical representations. icml fei-fei fergus perona pietro. learning generative visual models training examples incremental bayesian approach tested object categories. cviu leskovec jure krause andreas guestrin carlos faloutsos christos vanbriesen jeanne glance natalie. cost-effective outbreak detection networks. nguyen minh hoai torresani lorenzo torre fernando rother carsten. weakly supervised discriminative localization classiﬁcation joint learning process. iccv tatler benjamin central ﬁxation bias scene viewing selecting optimal viewing position independently motor biases image feature distributions. journal vision proposition exist proper make proposed function monotonically increasing submodular function. lemma monotonically increasing submodular function setting proof prove proposition lemma need prove lemma lemma simply leads possible choice parameter tuned positive scalar present auxiliary function below therefore auxiliary function submodular. summary since auxiliary monotonically increasing submodular function relationship show derived monotonically increasing submodular function. proof. therefore modular function. monotonically increasing modular function; thus objective function monotonically increasing submodular function. matroid proposed objective function induces matroid ground family feasible solution sets. trick build dissimilarity graph correlate pair images rf’s selecting ﬁxed number nearest rf’s brutal force smooth graph keeping ﬁxed number entries smallest values derive graph. figure iterations synthetic dataset select receptive ﬁelds. seen selected data intersection three classes/clusters. demonstrates effectiveness proposed method.", "year": 2014}