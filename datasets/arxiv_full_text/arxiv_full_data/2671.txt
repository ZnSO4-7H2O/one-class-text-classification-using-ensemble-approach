{"title": "Learning Hard Alignments with Variational Inference", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "There has recently been significant interest in hard attention models for tasks such as object recognition, visual captioning and speech recognition. Hard attention can offer benefits over soft attention such as decreased computational cost, but training hard attention models can be difficult because of the discrete latent variables they introduce. Previous work used REINFORCE and Q-learning to approach these issues, but those methods can provide high-variance gradient estimates and be slow to train. In this paper, we tackle the problem of learning hard attention for a sequential task using variational inference methods, specifically the recently introduced VIMCO and NVIL. Furthermore, we propose a novel baseline that adapts VIMCO to this setting. We demonstrate our method on a phoneme recognition task in clean and noisy environments and show that our method outperforms REINFORCE, with the difference being greater for a more complicated task.", "text": "fig. diagram models. denote bernoulli emission decision variables inputs targets hidden states recurrent neural networks parameterize conditional distributions models. square nodes deterministic round nodes stochastic. shaded indicates model chose consume input emit output unshaded mean model chose produce output consume input. example note shaded model produce output timestep instead consumes input next timestep. unshaded second timestep model produced output paper online sequence-to-sequence model described demonstrate methods. model sequence observed target tokens sequence observed inputs. bernoulli latent variables bm+n deﬁne model outputs tokens i.e. implies model emitted token timestep implies model emit token timestep model forced dwell input next time step i.e. observation timestep timestep number target tokens number inputs number steps model for. model assumes factorizes recently signiﬁcant interest hard attention models tasks object recognition visual captioning speech recognition. hard attention offer beneﬁts soft attention decreased computational cost training hard attention models difﬁcult discrete latent variables introduce. previous work used reinforce q-learning approach issues methods provide high-variance gradient estimates slow train. paper tackle problem learning hard attention sequential task using variational inference methods speciﬁcally recently introduced vimco nvil. furthermore propose novel baseline adapts vimco setting. demonstrate method phoneme recognition task clean noisy environments show method outperforms reinforce difference greater complicated task. attention models gained widespread traction successful tasks object recognition machine translation speech recognition used integrate information different parts input producing outputs. soft attention weighting combining input elements context vector hard attention selects speciﬁc inputs discards others leading computational gains greater interpretability. soft attention models differentiable end-to-end thus easy train hard attention models introduce discrete latent variables often require reinforcement learning style approaches. classic reinforcement learning methods reinforce q-learning used train hard attention models methods provide high-variance gradient estimates making training slow providing inferior solutions. alternative reinforcement learning variational inference trains second model called approximate posterior close true posterior latent variables. approximate posterior uses information input labels produce settings latent variables used train original model. provide lower-variance gradient estimates better solutions. paper leverage recent developments variational inference hard attention models sequential setting. specialize method sequences develop model approximate posterior. response issues applying variational inference techniques long sequences develop variance control methods. finally show experimentally approach improves performance substantially improves training time speech recognition timit dataset well challenging noisy multi-speaker version timit call multi-timit. simultaneously optimize parameters model improve lower bound. optimizing bound stochastic gradient ascent thought training maximum likelihood reproduce sampled updated reinforce-style gradients reward log-probability assigns given similar details. setting reinforce variational inference objectives admit multi-sample versions give tighter bounds log-likelihood particular multi-sample variational lower bound gradient takes similar form lowvariance term reinforce-style term high variance details similarly reinforce objective baseline reduce variance gradient long depend notably baseline trajectory allowed depend timesteps trajectories i.e. training models challenging high variance gradient estimates. reduce variance estimators using information multiple trajectories construct baselines. particular reinforce write gradient update baseline sample function trajectory’s state time well returns produced trajectories. goal pick good estimate return straightforward choice average return samples ignores fact make standard baseline unusable. example setting different trajectories emitted different numbers tokens given timestep resulting substantial differences return trajectories indicate relative merit trajectories. ideally would average multiple trajectories starting computationally expensive. authors propose following baseline adds residual term address this. instantaneous reward timestep baseline timestep written position output time input position time intuitively expression product time probability assigned current ground truth given model emitted multiplied probability model emitted. model emit time probability assigned ground truth timestep. brevity implicitly mean similarly refer similarly ranges time variables. model maximum likelihood concerned maximizing probability observed variables however written terms unobserved latents must marginalize them. maximize {bt− yt−} state time expectations note lower bound probability observed maximizing bound hopefully increase likelihood observed data. differentiating objective gives p|st return timestep understood intuitively probability model assigns observed data given series emission decisions. ﬁrst gradient term estimated single monte carlo sample second term exhibits high variance involves unbounded probability. reduce variance subtracts learned baseline return change expectation long independent performing stochastic gradient ascent gradient estimator standard reinforce algorithm reward log-likelihood. unfortunately requires sampling training lead gradient estimates high variance settings assign high likelihood rare variational inference family techniques importance sampling instead sample different model called approximate posterior approximates true posterior factorize approximate posterior approximate posterior access past future well past leverages information assign high probability produce large values intuitively speech recognition knowing token model must emit helpful deciding emit. table results timit test various models. shows reinforce performs comparably variational inference methods novel baselines improve training reinforce. also shows baselines improve performance uses model parametric baselines. number average three runs. methods horizontal line methods literature listed method reinforce leave-one-out baseline nvil baseline vimco baseline reinforce temporal baseline nvil temporal baseline vimco temporal baseline online alignment neural transducer unsupervised alignments online alignment monotonic alignment decoder neural transducer supervised alignments connectionist temporal classiﬁcation bound prior instead using variational posterior. work refer reinforce distinguish variational inference inference network. authors revisit topic using reweighted wake sleep train similar models. algorithm makes inference network optimize variational lower bound. instead optimize separate objectives model inference network produce biased estimate gradient marginal likelihood. experiments used standard timit phoneme recognition task. timit dataset training utterances validation utterances test utterances. audio waveforms processed frames ﬁlterbank spectrograms every stride frame frequency channels energy channel; deltas accelerations features append frame. result frame dimensional input. targets utterance sequence phonemes. used phoneme labels provided timit training decoding. compute phone error rate collapsed phonemes standard task model used -layer lstm units layer. variational posterior ﬁrst processed inputs -layer bidirectional lstm ﬁnal layer’s hidden state -layer unidirectional lstm along current target previous emission decision bt−. layer units. note case approximate posterior access yt+t timestep practice found giving access future improve performance. regularized models variational noise performed grid search values standard deviation noise. also used regularization grid searched values weight regularization. trajectory rewarded punished together. call leave-one-out baseline baseline given sample constructed using average return samples. note vimco optimizes multisample variational lower bound equation leave-one-out baseline nvil optimizes single sample variational lower bound equation baseline learned computed averages return strongly depends number emitted tokens time instead average return samples emitted number tokens sample mint ﬁrst timestep particular sample emitted number tokens sample timestep call baseline temporal leave-one-out baseline takes account temporal reward structure setting. baseline combined parametric baseline applicable variational inference reinforce objectives singlemulti-sample settings. explore performance baselines empirically experiments section. section ﬁrst highlight relationship model models attention. tang proposed visual attention within context generative models mnih proposed using recurrent models visual attention discriminative tasks. subsequently visual attention used image captioning model forms attention discrete variables attention location. recently ‘soft-attention’ models proposed neural machine translation speech recognition unlike earlier mentioned hard-attention models models attention entire input compute features blending spatial features attention vector normalized entire input. paper similar hard attention models features discrete locations used compute predictions. however different models training method hard attention models reinforce training follow variational techniques. also different models speciﬁc application attention models temporal locations only rather visual temporal locations. result additionally propose temporal leave-one-out baseline. attention model hard-attention model parallels prior work online sequence-to-sequence models neural transducer model either hard attention combination hard attention local soft attention. however explicitly splits input sequences chunks trained approximate maximum likelihood procedure similar policy search. model similar model. models architecture; however reinforce training explore vimco training attention model. also propose novel temporal baseline. similar model reinforce also used training online translation model training neural turing machines work would equally valid domains leave future work. fig. test phoneme error rate curves models trained reinforce nvil vimco timit dataset multi-timit mixing proportion dataset sample emission decisions different methods timit utterance evaluated three independent trials method. vimco converged quickly reinforce datasets. furthermore performance reinforce vimco increases multi-timit. hypothesize multi-timit challenging task strong approximation posterior lets model draw attention correct positions. nvil performed well timit struggled challenging multi-timit table results multi-timit various algorithms. seen task vimco outperforms reinforce vimco reinforce outperforms trained connectionist temporal classiﬁcation signiﬁcantly. beneﬁt vimco increases second speaker’s volume increases. connectionist temporal classiﬁcation transducer reinforce baseline nvil baseline vimco baseline reinforce temporal baseline nvil temporal baseline vimco temporal baseline paired utterance opposite gender. waveform utterances ﬁrst scaled within range scale second utterance reduced smaller volume mixing utterances. used three different scales second utterance utterances processed manner original timit utterances resulting dimensional input frame. transcript speaker used ground truth transcript utterance. multi-timit number train test utterances original timit well target phonemes. trained models conﬁguration described different mixing scales also trained -layer unidirectional lstm models connectionist temporal classiﬁcation comparison. results shown table right panel figure shows reinforce attempts wait emit outputs information come compared vimco. presumably requires information learning. vimco hand leverages variational posterior access future optimal place emit. experiments difference performance vimco reinforce larger complicated task multi-timit simpler task timit. explained considering samples models learn from. simpler problem single speaker timit monte-carlo samples generated reinforce high likelihood small number samples explain entire probability mass sampled easily left right ancestral pass model. similar samples generated approximate posterior vimco. result methods perform approximately same. case multi-timit however ancestral pass probabilities individual emissions much lower. thus likelihood less ’peaked’ large diversity samples chosen leading higher variance poor learning. vimco hand face problem samples approximate posterior close true posterior peaked around ‘correct’ samples experience. figure shows plot training curves different methods training different datasets. variational methods require many fewer training steps compared reinforce datasets. methods used batch size number samples training steps comparable. nvil performs well enough simple task like timit struggles multi-timit. seen reinforce paper showed adapt vimco perform hard attention case temporal problems introduce variance-reducing baseline. method outperforms methods training online sequence sequence models improvements greater difﬁcult problems noisy mixed speech. future apply techniques challenging domains visual attention. alex graves santiago fernández faustino gomez jürgen schmidhuber connectionist temporal classiﬁcation labelling unsegmented sequence data recurrent neural networks proceedings international conference machine learning. yichuan tang nitish srivastava ruslan salakhutdinov learning generative models visual attention advances neural information processing systems kelvin jimmy ryan kiros kyunghyun aaron courville ruslan salakhutdinov richard zemel yoshua bengio show attend tell neural image caption generation visual attention. icml vol. chorowski dzmitry bahdanau dmitriy serdyuk kyunghyun yoshua bengio attention-based models speech recognition advances neural information processing systems cortes lawrence sugiyama garnett eds. curran associates inc. navdeep jaitly david sussillo quoc oriol vinyals ilya sutskever samy bengio online sequence-to-sequence model using partial conditioning corr vol. abs/. jimmy ruslan salakhutdinov roger grosse brendan frey learning wake-sleep recurrent attention models advances neural information processing systems", "year": 2017}