{"title": "Explainable Prediction of Medical Codes from Clinical Text", "tag": ["cs.CL", "cs.LG", "stat.ML"], "abstract": "Clinical notes are text documents that are created by clinicians for each patient encounter. They are typically accompanied by medical codes, which describe the diagnosis and treatment. Annotating these codes is labor intensive and error prone; furthermore, the connection between the codes and the text is not annotated, obscuring the reasons and details behind specific diagnoses and treatments. We present an attentional convolutional network that predicts medical codes from clinical text. Our method aggregates information across the document using a convolutional neural network, and uses an attention mechanism to select the most relevant segments for each of the thousands of possible codes. The method is accurate, achieving precision @ 8 of 0.7 and a Micro-F1 of 0.52, which are both significantly better than the prior state of the art. Furthermore, through an interpretability evaluation by a physician, we show that the attention mechanism identifies meaningful explanations for each code assignment.", "text": "clinical notes text documents created clinicians patient encounter. typically accompanied medical codes describe diagnosis treatment. annotating codes labor intensive error prone; furthermore connectionbetweenthecodesandthetextisnotannotated obscuring reasons details behind speciﬁc diagnoses treatments. present attentional convolutional network predicts medical codes clinical text. method aggregates information across document using convolutional neural network uses attention mechanism select relevant segments thousands possible codes. method accurate achieving precision micro-f signiﬁcantly better prior state art. furthermore interpretability evaluation physician show attention mechanism identiﬁes meaningful explanations code assignment. introduction clinical notes free text narratives generated clinicians patient encounters. typically accompanied metadata codes international classiﬁcation diseases present standardized indicating diagnoses procedures performed encounter. codes variety uses ranging billing predictive modeling patient state manual coding timeconsuming error-prone automatic coding beenstudiedsinceatleastthes. task diﬃcult main reasons. first label space high-dimensional codes icd- taxonomy codes combined newer icd--cm icd--pcs taxonomies second clinical text includes irrelevant information misspellings non-standard abbreviations large medical vocabulary. features combine make prediction codes clinical notes especially diﬃcult task computers human coders alike application paper develop convolutional neural network -based methods automatic code assignment based text discharge summaries intensive care unit stays. better adapt multi-label setting employ per-label attention mechanism allows model learn distinct document representations label. call method convolutional attention multi-label classiﬁcation model design motivated conjecture important information correlated code’s presence contained short snippets text could anywhere document snippets likely diﬀer diﬀerent labels. cope large label space exploit textual descriptions code guide model towards appropriate parameters intheabsenceofmanylabeledexamples given code parameters similar codes similar textual descriptions. evaluate approach versions mimic open dataset medical records. record includes variety narrative notes describing patient’s stay including diagnoses procedures. approach substantially outperforms previous results medical code prediction mimic-ii mimic-iii datasets. consider applications work decision support setting. interpretability important decision support system especially ...line placed bronchoscopy performed showing large mucus plug left transfer to... ...also needed medication help body maintain blood pressure receiving iv... ...found large lingular pneumonia chest was... ...impression conﬂuent consolidation involving nearly entire left lung either bronchocentric vascular... ...and gelfoam embolization right hepatic artery branch pseudoaneurysm coil embolization gastroduodenal... ...coil embolization gastroduodenal artery history present illness a... ...foley hemodynamic monitoring serial hematocrits angio performed was... ...and gelfoam embolization right hepatic artery branch pseudoaneurysm coil embolization gastroduodenal... ...no mitral valve prolapse moderate severe mitral regurgitation seen tricuspid valve... ...is seen estimated pulmonary artery systolic pressure normal pericardial... ...and suggested starting hydralazine imdur continue aspirin admitted baseline appears patient... ...anticoagulation monitored tele pump systolic dysfunction seen recent echo... table presentation example qualitative evaluations. real evaluation system names generating -gram given. marking indicates snippet evaluated informative ‘hi’ indicates highly informative; details. medical domain. system able explain predicted code; even codes manually annotated desirable explain parts text relevant code. considerations motivate per-label attention mechanism assigns importance values \u0001-grams input document therefore provide explanations code form extracted snippets text input document. perform human evaluation quality explanations provided attention mechanism asking physiciantoratetheinformativenessofasetofautomatically generated explanations. method treat icd- code prediction multilabel text classiﬁcation problem representthesetoficd-codes; thelabelingproblem instance determine train neural network passes text convolutional layer comument makes\u0007î\u0007 binary classiﬁpute base representation text doccation decisions. rather aggregating across code data splits publicly available upon publication. focus codes icd- taxonomy rather recent icd- simple reason version used mimic datasets. representation pooling operation apply attention mechanism select parts document relevant possible code. attention weights applied base representation result passed output layer using sigmoid transformationtocomputethelikelihoodofeachcode. employ regularizer encourage code’s parameters similar codes similar textual descriptions. describe elements detail. convolutional architecture base layer model \u0001\u0001dimensionalpre-trainedembeddingsforeachword document horizontally concatenated matrix length document. adjacent word embeddings combined using convolutional ﬁlter ó\u0001×\u0001\u0001×\u0001\u0001 ﬁlter width size input embedding size ﬁlter output. step compute figure caml architecture per-label attention shown label. max-pooling architecture mapped directly vector maximizing dimension. plus norm model weights using adam optimizer embedding label descriptions dimensionality label space many codes observed handful times labeled data. improve performance codes leverage standardized text descriptions code world health organization examples found table descriptions build secondary module network learns embed vectors. vectors used target regularizationonthemodelparameters ifcode rarely observed training data regularizer encourage parameters similar codes similar descriptions. code embedding module consists maxpoolingcnnarchitecture. beamax-pooled vector obtained passing description code module. number true labels training example. following regularizing objective loss \u0001bce tradeoﬀ hyperparameter calibrates performance objectives. call model variant description regularizedcaml evaluation code prediction sectionevaluates theaccuracy ofcode prediction comparing models several competitive baselines. attention convolution document represented matrix ó\u0001\u0001×\u0001. typical reduce matrix vector applying pooling across length document selecting maximum average value however goal assign multiple labels document diﬀerent parts base representation relevant diﬀerent labels. reason apply per-label attention mechanism. additional beneﬁt selects \u0001-grams text relevant predicted label. formally label compute matrix-vector product avectorparameterforlabel wethenpasstheresulting vector softmax operator obtaining distribution locations document softmax element-wise exponentiation vector attention vector used compute vector representations label datasets mimic-iiiisanopen-access dataset text structured records hospital icu. following previous work focus dischargesummaries whichcondenseinformation aboutastayintoasingledocument. inmimic-iii admissions addenda summary concatenate form document. admission tagged human coders icd- codes describing diagnoses andprocedureswhichoccurredduringthepatient’s stay. unique icd- codes present datasets including diagnosis codes procedure codes. patients multiple admissions therefore multiple discharge summaries; split data patient patient appears training test sets. full-label setting discharge summaries patients training summaries summaries validation testing respectively. secondary evaluations comparison prior work also follow trainandevaluateonalabelsetconsistingofthe frequent labels. setting ﬁlter dataset instances least frequent codes subset training data equal size training resulting summaries trainingforvalidationandfortesting. also experiments mimic-ii dataset compare prior work baumel perotte train/test split perotte consists training examples testing examples. detailed statistics three settings summarized table preprocessing remove punctuationnumeric-only tokens lowercase tokens replace tokens appear fewer three training documents ‘unk’ token. pretrain word embeddings size using wordvec preprocessed text discharge summaries. documentsaretruncatedtoamaximumlengthof tokens. systems compare method baselines singlelayer one-dimensional convolutional neural network bag-of-words logistic regression model bidirectional gated recurrent unit bigru initialize embedding weights using pretrained wordvec vectors caml models. neural models implementedusingpytorch. thelogisticregression acting unigram bag-of-words features labels present training data. label present training data model never predict held-out data. parameter tuning wetunethehyperparameters caml model neural baselines using spearmint bayesian optimization package allow spearmint sample parameter values penalty model weights learning rate well ﬁlter size number ﬁlters dropout probability convolutional models number hidden layers dimension bi-gru using precision mimic-iii full-label validation performance measure. parameters drcaml well port optimized parameters tothemimic-iifull-labelandmimic-iii-label models andmanuallyﬁne-tunethelearningratein thesesettings. weselect \u0001fordr-camlbasedon pilot experiments validation sets. hyperparameter tuning summarized table convolutional models trained dropout embedding layer. ﬁxed batch size models datasets. evaluation metrics facilitate comparison future work report variety metrics. report microaveraged macro-averaged area curve micro-averaged values calculated treating pair separate prediction. macro-averaged values less frequently reported multi-label classiﬁcation literature calculated averaging metrics computed per-label. recall metrics pilot experiments found stronger https//github.com/pytorch/pytorch https//github.com/hips/spearmint denotes true positive examples denotes false negative examples. precision computed analogously. macro-averaged metrics place much emphasis rare label prediction. also report precision fraction highestscored labels present ground truth. motivated potential case decision support application user presented ﬁxed number predicted codes review. case suitable select model high precision high recall. choose compare prior work mimic-iii full label setting also compute precision roughly corresponds average number codes mimic-iii discharge summaries results main quantitative evaluation involves predicting full icd- codes based text mimic-iii discharge summaries. results shown table caml model gives strongest results metrics. attention yields substantial improvements vanilla convolutional neural network recurrent bi-gru architecture comparable vanilla logistic regression baseline substantially worse neural architectures. also dr-caml model improves upon caml metrics exception precision comparable caml results. among prior work scheurwegs evaluate full icd- code mimic-iii. reported results distinguished diagnosis codes procedure codes. caml models stronger sets. additionally method make external information structured data scheurwegs structured data various medical ontologies text representation. feel precision informative metrics measures ability system return small high-conﬁdence subset codes. even space thousands labels models achieve relatively high precision eight conﬁdent predictions average correct. also apparent diﬃcult achieve high macro-f scores metric’s emphasis rare-label performance. results context hypothetical system performs perfectly common labels ignores others would achieve macro-f micro-f secondary evaluations compare prior published work also evaluate common codes mimic-iii mimic-ii report dr-caml results -label setting mimic-iii mimic-ii -label setting mimic-iii also strong table results mimic-iii full labels. here diag denotes micro-f performance diagnosis codes only proc denotes micro-f performance procedure codes only. improvement prior work reported metrics well baselines exception precision baseline performs best. hypothesize relatively large value camlleadstoalargernetworkthatismoresuited larger datasets. baumel additionally report micro-f score training mimic-iii evaluating mimic-ii. model achieves better performance using mimic-ii training leaving alternative training protocol future work. evaluation interpretability evaluate explanations generated caml’s attention mechanism comparison three alternative heuristics. physician presented explanations four methods using random sample predicted codes mimic-iii full-label test set. important \u0001-gram method extracted along window words either side context. select setting emulate span attention words likely given human reader. examples found table observe snippets overlap multiple words. prompted evaluator select text snippets felt adequately explained presence given code provided code description option distinguish snippets highly informative found particularly informative others. extracting informative text snippets caml attention mechanism allows extract \u0001-grams text inﬂuential prediction label taking argmax softmax output max-pooling select \u0001-grams provide maximum value selected maxpooling least weighting ﬁnal layer weights. deﬁning argmax vector results max-pooling step select important \u0001-gram given label max\u0001 \u0001\u0001\u0001. logistic regression theinformativenessofeach \u0001-gramwithrespecttolabel isscoredbythesum coeﬃcients weight matrix words \u0001-gram. top-scoring \u0001-gram returned explanation. code descriptions finally calculate word similarity metric stemmed \u0001-gram stemmed icd- code description. compute idf-weighted cosine similarity weights calculated corpus consisting notes relevant code descriptions. select argmax \u0001-grams document breaking ties selecting ﬁrst occurrence. remove note-label pairs \u0001-gram score greater gives unfair advantage baseline. results results interpretability evaluation presented table model selects greatest number highly informative explanations selects informative explanations baseline logistic regression model. whilethecosinesimilaritymetricalsoperforms well examples table demonstrate strengths caml extracting text snippets line intuitive explanations presence code. noted above exist cases exclude cosine similarity model unable provide explanation \u0001-grams note non-zero similarityforagivenlabeldescription. thisoccurs note-label pairs test set. related work attentional convolution cnns successfully applied tasks sentiment classiﬁcation language modeling work combines convolution attention selectthemostrelevantpartsofthedischargesummary. recent work combined convolution attention attention mechanism similar context vectors compute attention speciﬁc locations text. work diﬀers compute separate attention weights label label space better tuned goal selecting locations document important predicting speciﬁc labels. automatic coding coding longstanding task medical informatics community approached machine learning handcrafted methods many recent approaches like ours unstructured text data source information though incorporates structured data well previous methods either evaluated strict subset full label space relied datasets focus subset medical scenarios evaluated data publicly available making direct comparison diﬃcult recent shared task icd- coding focused coding death certiﬁcates english french dataset also contains shorter documentsthanthoseweconsiderwithanaverage tokens certiﬁcate french corpus. open-access mimic datasets containingde-identiﬁedgeneral-purposerecordsofintensive care unit stays single hospital. perotteetal.useﬂatandhierarchical svms; former treats code individualprediction whilethelattertrainsonchildcodes parent code present predicts child codes parent code positively predicted. scheurwegs feature selection approach icd- icd- classiﬁcation incorporating structured unstructured text information ehrs. evaluate various medical specialties mimic-iii dataset. compare directly results full label mimic-iii. recent approaches employed neural network architectures. baumel apply recurrent networks hierarchical sentence andwordattentiontoclassifyicd diagnosis codes providing insights method caml code descriptions logistic regression table qualitative evaluation results. columns show number examples method selected informative highly informative. modeldecisionprocess. similarlyshietal. applied character-aware lstms generate sentence representations speciﬁc subsections dischargesummaries andapplyattentiontoforma soft matching representations codes. prakash memory networks draw discharge summaries well wikipedia predict top- top- codes. another recent neural architecture grounded recurrent neural network employs modiﬁed dimensions dedicated predicting presence individual labels. compare directly published results papers except vani evaluate code subset icd-. empirically caml architecture proposed paper yields stronger results across experimental conditions. attention yields dramatic improvements focusing critical features code rather applying uniform pooling operation codes. also observed convolution-based models eﬀective signiﬁcantly computationally eﬃcient recurrent neural networks bi-gru. explainable text classiﬁcation goal work code predictions explainable features text. prior work also emphasized explainability. model rationales latent variable tags word relevant document label. compute salience individual words derivative label score respect word embedding. ribeiro submodular optimization select subset features closely approximate speciﬁc classiﬁcation decision comparison theseapproachesweemployarelativelysimpleattentional architecture; simplicity motivated challenge scaling multi-label classiﬁcation thousands possible labels. prior work emphasized attention highlighting salient features text although papers perform human evaluations interpretability features selected attention mechanism. conclusions future work wepresentcamlaconvolutionalneuralnetwork multi-label document classiﬁcation employsanattentionmechanismthatadaptivelypools convolution output label learns identify highly-predictive locations label. model yields strong improvements previous metrics several formulations code prediction task providing satisfactory explanations predictions. although focus clinical setting model general andextensiblewithoutmodiﬁcationtoothermultilabel document tagging tasks including icd- coding. directions future work include exreferences miltiadis allamanis peng charles sutton. aconvolutionalattentionnetworkforextreme summarization source code. international conference machine learning.pages–. anand avati kenneth jung stephanie harman lance downing andrew nigam shah. improving palliative care deep learning. arxiv preprint arxiv. talbaumel jumananassour-kassis michaelelhadad noémie elhadad. multi-label classiﬁcationofpatientnotesacasestudyonicdcodeassignment. aaai workshop health intelligence. elena birman-deych waterman david nilasena martha radford brian gage. accuracy icd--cm codes identifying cardiovascular stroke risk factors. medical care edward choi mohammad taha bahadori andy schuetz walter stewart jimeng sun. doctor predicting clinical events recurrent neural networks. machine learning healthcare conference. pages luciano r.s. lima alberto h.f. laender berthier ribeiro-neto. hierarchical approach automatic categorization medical documents. proceedings seventh international conference information knowledge management. pages joshua denny marylyn ritchie melissa basford jill pulley lisa bastarache kristin browngentry deede wang masys rodenanddanac.crawford.. phewasdemonstrating feasibility phenome-wide scan discover gene–disease associations. bioinformatics alistair e.w. johnson pollard shen liwei lehman mengling feng mohammad ghassemi benjamin moody peter szolovits anthony celi roger mark. mimic-iii freely accessible critical care database. scientiﬁc data ramakanth kavuluru anthony rios yuan empirical evaluation supervised learning approaches assigning diagnosis codes electronic medical records. artiﬁcial intelligence medicine regina barzilay tommi jaakkola. proceedings rationalizing neural predictions. conference empirical methods natural language processing.associationforcomputational linguistics austin texas pages jiwei xinlei chen eduard hovy jurafsky. visualizing understanding neural models nlp. proceedings conference north american chapter association computational linguistics human language technologies.associationforcomputationallinguistics diego california pages http// www.aclweb.org/anthology/n-. andrew mccallum. multi-label text classiﬁcation mixture model trained aaai workshop text learning. pages aurélie névéol robert anderson bretonnel cohen cyril grouin thomas lavergne grégoire aude robert claire rondet pierre zweigenbaum. clef ehealth multilingual information extraction task overview coding death certiﬁcates english french. clef evaluation labs workshop online working notes ceur-ws. page adler perotte rimma pivovarov karthik natarajan nicole weiskopf frank wood noémie elhadad. diagnosis code assignment models evaluation metrics. journal american medical informatics association kevin swersky jasper snoek ryan adams. multi-task bayesian optimization. burges bottou welling ghahramani weinberger editors advances neural information processing systems curran associates inc. pages wang xiaojun chang guodong long lina quan sheng. diagnosis code assignment using sparsity-based disease correlation embedding. ieee transactions knowledge data engineering zichao yang diyi yang chris dyer xiaodong alexander smola eduard hovy. hierarchical attention networks document classiﬁcation. proceedings conference north american chapter association computational linguistics human language technologies.associationforcomputationallinguistics diego california pages wenpeng hinrich schütze bing xiang bowen zhou. abcnn attention-based convolutional neural network modeling sentence pairs. transactions association computational linguistics oladimeji farri. condensed memory networks clinical diagnostic inferencing. proceedings thirty-first aaai conference artiﬁcial intelligence. pages marco tulio ribeiro sameer singh carlos guestrin. trust you? explaining predictions classiﬁer. proceedings sigkdd international conference knowledge discovery data mining. pages alexander rush sumit chopra jason weneural attention model abston. proceedstractive sentence summarization. ings conference empirical methods natural language processing. association computational linguistics lisbon portugal pages http//aclweb.org/ anthology/d-. elyne scheurwegs boris cule luyckx léon luyten walter daelemans. selecting relevant features electronic health record clinical code prediction. journal biomedical informatics elyne scheurwegs luyckx léon luyten walter daelemans bulcke. data integration structured unstructured sources assigning clinical codes patient stays. journal american medical informatics association e–e. jasper snoek hugo larochelle ryan adams. practical bayesian optimization machine learning algorithms. pereira burges bottou weinberger editors advances neural information processing systems curran associates inc. pages michael subotin anthony davis. system predicting icd--pcs codes elecproceedings tronic health records. workshop biomedical natural language processing. michael subotin anthony davis. method modeling co-occurrence propensity clinical codes application icd--pcs autocoding. journal american medical informatics association", "year": 2018}