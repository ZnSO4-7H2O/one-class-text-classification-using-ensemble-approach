{"title": "Annotation Order Matters: Recurrent Image Annotator for Arbitrary Length  Image Tagging", "tag": ["cs.CV", "cs.AI"], "abstract": "Automatic image annotation has been an important research topic in facilitating large scale image management and retrieval. Existing methods focus on learning image-tag correlation or correlation between tags to improve annotation accuracy. However, most of these methods evaluate their performance using top-k retrieval performance, where k is fixed. Although such setting gives convenience for comparing different methods, it is not the natural way that humans annotate images. The number of annotated tags should depend on image contents. Inspired by the recent progress in machine translation and image captioning, we propose a novel Recurrent Image Annotator (RIA) model that forms image annotation task as a sequence generation problem so that RIA can natively predict the proper length of tags according to image contents. We evaluate the proposed model on various image annotation datasets. In addition to comparing our model with existing methods using the conventional top-k evaluation measures, we also provide our model as a high quality baseline for the arbitrary length image tagging task. Moreover, the results of our experiments show that the order of tags in training phase has a great impact on the final annotation performance.", "text": "fig. examples results showing differences top- annotations arbitrary length annotations. top- annotations tend generate false positives arbitrary length top- ground truth. right things. common conventional evaluation setting ﬁxed annotation length typical value used many previous methods ease comparison. however argue convention insufﬁciency previous work since normal humans annotate images assumption ﬁxed annotation length fact realistic images either shown figure therefore arbitrary length annotation required reasonable annotation results. top-k predictions traditional methods simply select tags highest prediction scores. arbitrary length annotation possible easily imagine naive extension threshold prediction scores. however ﬁnding good threshold difﬁcult merely setting hyper-parameter might expect optimal threshold actually dependent different image. instead struggling appropriate threshold want import explicit mechanism model annotation length originally form image annotation task sequence generation problem. therefore propose novel model called recurrent image annotator abstract—automatic image annotation important research topic facilitating large scale image management retrieval. existing methods focus learning image-tag correlation correlation tags improve annotation accuracy. however methods evaluate performance using top-k retrieval performance ﬁxed. although setting gives convenience comparing different methods natural humans annotate images. number annotated tags depend image contents. inspired recent progress machine translation image captioning propose novel recurrent image annotator model forms image annotation task sequence generation problem natively predict proper length tags according image contents. evaluate proposed model various image annotation datasets. addition comparing model existing methods using conventional top-k evaluation measures also provide model high quality baseline arbitrary length image tagging task. moreover results experiments show order tags training phase great impact ﬁnal annotation performance. image annotation task associate multiple semantic tags regarding contents images. rapid development internet social applications amount online images created users continuously increasing. large amount images brings heavy burden image management retrieval. since major approaches people search index images referring associated tags necessary step annotate images proper tags. however manually annotating images expensive labor intensive work human beings. hence better learn model available image-tag samples model automatically label images keywords annotation vocabulary. fact kind technique called automatic image annotation important research topic computer vision decades. previous researches focus learning image-to-tag correlation well tag-to-tag correlation improve annotation performance. although much progress made research community existing methods overlooked fundamental philosophy recognition recognizjointly uses convolutional neural networks recurrent neural networks predicting sequences. annotation phase image initial input automatically generate annotation tags shown figure idea inspired recent success machine translation especially image captioning task generate natural language sentences images. advantages using include nature generate varied length outputs also ability refer previous inputs predicting current time step output. ability allows exploit correlations image-to-tag tagto-tag. extract image visual features generate sequence visual features need next? answer order. machine translation image captioning generate sentences natural order available model learn from. unfortunately image annotation task natural order available. instead choose learn order make proposed model actually work. like sentences obey language rules form order believe exist intrinsic language rules tags form order describe image. points order good task. first order rule based semantic image information. second sequences training example follow rule sorted since model learn rule training examples generalize prediction test images. facilitate training model well testing importance orders propose several strategies provide orders. compare performance model different orders experiments. main contributions work follows best knowledge work ﬁrst form image annotation task sequence generation problem propose novel based model recurrent image annotator handle image annotation work. analyze insufﬁciency existing methods enough attention generate image dependent number tags natural requirement realistic tasks. propose model high quality baseline comparing performance arbitrary length image tagging. hope work help encourage future work task. found became publicly available arxiv.org ﬁnished work. though several similar ideas existing papers focuses motivations different. attention annotation length sequence order used training phase. fig. general architecture model. test phase model receives input image triggered start signal predicts ﬁrst output tag. starts loop uses previous output input next time step predicting sequence recursively. loop continue stop signal predicted. generally existing methods grouped three categories generative models discriminative models nearest neighbor type models. generative models minimize generative data likelihood based topic models topic distribution image features annotation tags mixture models models deﬁne joint distribution image features annotation tags. different generative models discriminative models focus directly learning classiﬁer prediction recently based multi-label classiﬁcation models proposed another simple powerful group models k-nearest-neighbor based models also beneﬁt metric learning multiple hand-crafted visual features. ﬁrst step extract effective efﬁcient visual features image pixels. traditional methods usually hand-crafted global region based image features combination recent researches indicate features extracted convolutional neural networks signiﬁcantly superior performance hand-crafted features single-label image classiﬁcation task however recent work show deep features outperform handcrafted features traditional methods. think possible reasons beneﬁt metric learning multiple hand-crafted features lost. another problem currently suitable loss function handle multi-label image classiﬁcation perfectly models training phase lstm accepts image embedding vector initial hidden state cell state lstm initialized zero. start signal lstm ﬁrst input time step model continue computing output score conditioned predicted index decided score index time step vocabulary size plus hand based current input previous hidden state cell state ct−. predicting tags model refer current input previous predicted tags. procedure hidden state cell state propagate time step described below gate units lstm represent corresponding weights bias. stand operator matrix multiplication elementwise multiplication respectively. loss function deﬁned cross-entropy prediction score testing phase referring figure procedure similar simpler. needed input test image start signal triggering ﬁrst output tag. sequence generation loop starts output time step used input next time step stop signal predicted. recurrent neural networks networks loops treated multiple copies network connected passing messages successor. however original architecture difﬁcult train long sequences gradient exploding vanishing problem gradient exploding problem easily coped gradient clipping i.e. limiting absolute value gradients. vanishing problem difﬁcult handle therefore several variants proposed solving problem long term dependencies example lstm variants hidden cell states gate functions control information previous time step combined propagated proved work better vanilla choose lstm sub-module widely used tested. recent researches compare lstm showing similar performance. model used decoder decode sequence image input crucial part predict arbitrary length annotation results. section describe entire model architecture ﬁrst explain details sub-module. convenience readability denote single training example image target sequence target sequence contains training annotations special stop signal similarly input sequence contains start signal followed training annotation tags shown figure decoder decodes sequence input image image sequence model ﬁrst embed latent image space space image embedding embedding submodule respectively. train model embedded image vectors. training model able generate sequence tags input image. either pre-trained features jointly train extract image features. cases linear projection layer project output dimensional space number nodes hidden layer. directly joined sub-module. instead directly using one-hot vectors represent tags tags dimensional embedding vectors using lookup table like common learn distributed word embeddings lookup table trainable learn kind representation generate training. learned dimensional representation optimized minimizing annotation error. provide four orders dictionary order random order rare-ﬁrst order frequent-ﬁrst order. dictionary order sorts tags image alphabetically; random order generates random sequence image name suggests; rare-ﬁrst order rarer frequent ones frequent-ﬁrst order frequent less frequent ones. section ﬁrst present dataset used experiments describe different experimental settings evaluation measures experiments. finally explain training details experiments. adopt three image annotation datasets used previous work corel game iapr table shows statistics training sets three datasets described mean maximum manner. first compare model different sequence orders task arbitrary length annotation. explore image embedding submodule also compare models trained different kinds features. second compare model existing methods three datasets top- evaluation measures. fair comparison especially want compare state-ofthe-art methods features adopt model. top- annotation arbitrary length annotation precision recall f-measure averaged classes main evaluation measures. another widely used measure represents number classes non-zero recall value also reported. three different ways obtain visual features last fully-connected layer pre-trained denoted last convolutional layer pre-trained denoted conv output jointly trained cnn. speciﬁc model used vgg- sequence prediction module dimension hidden states input ﬁnally choose number hidden layers exhaustive validations. table shows features achieve better performance conv features model. ﬁned-tuned features similar performance features need much training time. thus following experiments compare models using features methods. also rare-ﬁrst order outperforms orders almost evaluation measures. figure observe models using rare-ﬁrst order converge faster others difference even signiﬁcant larger datasets game iapr random order slight advantage orders precision terms recall poor performance. f-measure dictionary random order similar performance. frequent-ﬁrst order worst performance recall f-measure. compare experimental results expectation first though dictionary order actually assigns tags training examples rule almost meaningless since provide semantic information images tags thus leads poor performance. second though random order provides possible proper orders training example follow rule makes model confused noisy orders also result recall rate. third rare-ﬁrst order considers frequency tags extent help handle rare tags problem important improving per-class measures. besides uses rule sort tags training examples hence makes easy model learn. finally frequent-ﬁrst order worse performance expected. analyze reasons frequent-ﬁrst order performs poorly especially large datasets frequent tags usually easier predict rare tags frequent-ﬁrst order puts frequent tags ﬁrst easy work becomes easier hard work becomes difﬁcult causes extremely per-class mean recall rate. lowest score also indicates frequentﬁrst order harms ability model correctly predict rare tags. experiments show order sequence crucial sequence generation. however note using several naive approaches decide order believe better ways choose learn optimal order task. shown table conventional top- annotation task model outperforms several state-of-the-art methods features. although methods multiple hand-crafted features metric learning better performance advantage using deep features avoid complexity hand-crafted features expensiveness metric learning. besides comparable performance several state-of-the-art methods model also runs extremely fast testing speed image nvidia titan gpu. difﬁcult based methods achieve especially large scale practical problems. testing time based methods increasing linearly size training examples testing time model constant i.e. affected dataset size. transformed image annotation task sequence generation problem proposed novel recurrent image annotator model receives image input predicts sequence tags recursively. evaluated model traditional top- evaluation setting three different image annotation datasets. experimental results show model achieve comparable performance state-ofthe-art methods. condition using deep features without expensive metric learning model outperforms several state-of-the-art methods. also evaluated model arbitrary length annotation task model decide appropriate annotation length automatically. explore inﬂuence sequence order used training phase evaluated several order candidates experiments conﬁrmed importance proper order sequence generation problem. empirical experimental results conclude model capable image annotation task since start adopting sequence generation techniques simonyan zisserman very deep convolutional networks large-scale image recognition arxiv preprint arxiv. deep residual learning image recognition arxiv", "year": 2016}