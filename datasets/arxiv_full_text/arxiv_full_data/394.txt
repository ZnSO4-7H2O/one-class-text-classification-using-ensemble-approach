{"title": "Vote3Deep: Fast Object Detection in 3D Point Clouds Using Efficient  Convolutional Neural Networks", "tag": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.NE"], "abstract": "This paper proposes a computationally efficient approach to detecting objects natively in 3D point clouds using convolutional neural networks (CNNs). In particular, this is achieved by leveraging a feature-centric voting scheme to implement novel convolutional layers which explicitly exploit the sparsity encountered in the input. To this end, we examine the trade-off between accuracy and speed for different architectures and additionally propose to use an L1 penalty on the filter activations to further encourage sparsity in the intermediate representations. To the best of our knowledge, this is the first work to propose sparse convolutional layers and L1 regularisation for efficient large-scale processing of 3D data. We demonstrate the efficacy of our approach on the KITTI object detection benchmark and show that Vote3Deep models with as few as three layers outperform the previous state of the art in both laser and laser-vision based approaches by margins of up to 40% while remaining highly competitive in terms of processing time.", "text": "fig. result applying votedeep unseen point cloud kitti dataset corresponding image reference. cnns apply sparse convolutions natively voting. model detects cars pedestrians cyclists even long range assigns bounding boxes sized class. best viewed colour. linear support vector machine consequently achieves previous state performance processing speed detecting cars pedestrians cyclists point clouds object detection task popular kitti vision benchmark suite inspired propose exploit feature-centric voting build efﬁcient cnns detect objects point clouds natively without projecting input lower-dimensional space ﬁrst constraining search space detector enables apabstract— paper proposes computationally efﬁcient approach detecting objects natively point clouds using convolutional neural networks particular achieved leveraging feature-centric voting scheme implement novel convolutional layers explicitly exploit sparsity encountered input. examine trade-off accuracy speed different architectures additionally propose penalty ﬁlter activations encourage sparsity intermediate representations. best knowledge ﬁrst work propose sparse convolutional layers regularisation efﬁcient large-scale processing data. demonstrate efﬁcacy approach kitti object detection benchmark show votedeep models three layers outperform previous state laser laser-vision based approaches margins remaining highly competitive terms processing time. point cloud data ubiquitous mobile robotics applications autonomous driving efﬁcient robust object detection pivotal planning decision making. recently computer vision undergoing transformation convolutional neural networks methods process point clouds however experienced comparable breakthrough. attribute lack progress computational burden introduced third spatial dimension. resulting increase size input intermediate representations renders naive transfer cnns vision applications native perception point clouds infeasible large-scale applications. result previous approaches tend convert data representation ﬁrst nearby features necessarily adjacent physical space requiring models recover geometric relationships. contrast image data however typical point clouds encountered mobile robotics spatially sparse regions unoccupied. fact exploited authors propose voted feature-centric voting algorithm leveraging sparsity inherent point clouds. computational cost proportional number occupied cells rather total number cells grid. proves equivalence voting scheme dense convolution operation demonstrates effectiveness discretising point clouds grids performing exhaustive sliding window detection proach named votedeep learn high-capacity non-linear models providing constant-time evaluation test-time contrast non-parametric methods. furthermore order enhance computational beneﬁts associated sparse inputs throughout entire stack demonstrate beneﬁts encouraging sparsity inputs intermediate layers imposing model regulariser training. best knowledge ﬁrst work propose sparse convolutional layers based voting regularisation efﬁcient processing full point clouds cnns scale. particular contributions paper summarised follows construction efﬁcient convolutional layers basic building blocks cnn-based point cloud processing leveraging voting mechanism exploit inherent sparsity input data; rectiﬁed linear units sparsity penalty speciﬁcally encourage data sparsity intermediate representations order exploit sparse convolutional layers throughout entire stack. demonstrate votedeep models three layers achieve state-of-the-art performance amongst purely laser-based approaches across classes considered popular kitti object detection benchmark. votedeep models exceed previous state point cloud based object detection average precision margin running slightly slower terms detection speed. number works attempted apply cnns context point cloud data. cnn-based approach obtains comparable performance kitti detection projecting point cloud depth additional channel height point ground. model predicts detection scores regresses bounding boxes. however projection speciﬁc viewpoint discards valuable information particularly detrimental example crowded scenes. also requires network ﬁlters learn local dependencies regards depth information readily available representation efﬁciently extracted sparse convolutions. dense occupancy grids obtained point clouds processed cnns minimum cell size reports speed classify single crop grid-size cells. similarly processing time landing zone detection reported point clouds often larger would result processing time frame comply speed requirements typically encountered robotics applications. alternative approach takes advantage sparse representations found sparse convolutions applied comparatively small crops respectively. convolutional kernels applied sparse feature locations presented algorithm still consider neighbouring values take value either zero constant bias leading unnecessary operations memory consumption. another method performing sparse convolutions introduced make permutohedral lattices consider comparatively small inputs opposed work. cnns also applied dense data biomedical image analysis equivalent residual networks utilised brain image segmentation. cascaded model stages proposed detecting cerebral microbleeds. combination three cnns suggested processes different plane three streams joined last layer. systems relatively small inputs cases take minute processing single frame acceleration. section describes application convolutional neural networks prediction detection scores sparse input grids variable sizes. input network point cloud discretised sparse grid cell contains non-zero number points feature vector extracted based statistics points cell. feature vector holds binary occupancy value mean variance reﬂectance values three shape factors. cells empty space stored leads sparse representation. employ voting scheme perform sparse convolution across native representation followed relu non-linearity returns sparse representation. process repeated stacked traditional output layer predicting detection scores. similar applied point cloud different angular orientations parallel threads handle objects different orientations minimal increase computation time. duplicate detections pruned nonmaximum suppression space. better able handle objects behind bounding boxes overlap less projections. based premise bounding boxes space similar size object instances class assume ﬁxed-size bounding class eliminates need regress size bounding box. select bounding dimensions class interest based percentile ground truth bounding size training set. receptive ﬁeld network least large bounding object excessively large would waste computation time. therefore employ several class-speciﬁc networks parallel test time different total receptive ﬁeld size depending object class. principle possible compute detection scores multiple classes single network; task left future work. subsection. crucially biases constrained nonpositive single positive bias would return output grid almost every cell occupied feature vector hence eliminating sparsity. bias therefore needs added non-empty output cell. sparse voting scheme ﬁlter needs applied occupied cells input grid rather convolved entire grid. algorithm described detail including formal proof feature-centric voting equivalent exhaustive convolution. ability perform fast voting layers predicated assumption sparsity input individual layer. input point cloud sparse regions non-empty cells dilated successive convolutional layer approximately receptive ﬁeld size corresponding ﬁlters layer. therefore critical select non-linear activation function helps maintain sparsity inputs convolutional layer. achieved applying rectiﬁed linear unit advocated sparse convolutional layer. relu activation written case features value greater zero allowed cast votes next sparse convolution layer. addition enabling network learn non-linear function approximations therefore increasing representational capacity relus effectively perform thresholding operation discarding negative feature values helps maintain sparsity intermediate representations. lastly advantage relus compared non-linearities fast compute. ﬁxed-size bounding boxes networks directly trained crops positive negative examples whose dimensions equal receptive ﬁeld size speciﬁed architecture. negative training examples obtained performing hard negative mining periodically ﬁxed number training epochs. class-speciﬁc networks binary classiﬁers choose linear hinge loss training maximum margin property. fig. illustration voting procedure sparse example input without bias. voting weights obtained ﬂipping convolutional weights along dimension. whereas standard convolution applies ﬁlter every location input equivalent voting procedure needs applied non-zero location compute result. instead grid single feature votedeep applies voting procedure inputs several feature maps. full mathematical justiﬁcation reader referred best viewed colour. running dense convolution across discretised point cloud computation time wasted majority operations multiplications zero. additional third spatial dimension makes process even computationally expensive compared convolutions form basis image-based cnns. using insight meaningful computation takes place features non-zero introduce feature-centric voting scheme. basis algorithm idea letting non-zero input feature vector cast votes weighted ﬁlter weights surrounding cells output layer deﬁned receptive ﬁeld ﬁlter. voting weights obtained ﬂipping convolutional ﬁlter kernel along spatial dimension. ﬁnal convolution result obtained accumulating votes falling cell output procedure formally stated follows. without loss generality assume convolutional ﬁlter odd-valued kernel dimensions network layer operating single input feature ﬁlter weights denoted r××. then input grid rl×m×n convolution result location given bias value applied cells grid. operation needs applied locations input grid regular dense convolution. contrast this given cell indices non-zero cells convolution recast feature-centric voting operation input cell casting votes increment values neighbouring cell locations according well-known kitti vision benchmark suite training evaluating detection models. dataset consists synchronised stereo camera lidar frames recorded moving vehicle annotations eight different object classes showing wide variety road scenes different appearances. point cloud data train test models. frames kitti test whose labels publicly available. labelled training data consist frames split sets training validation object detection benchmark considers three classes evaluation cars pedestrians cyclists training labels respectively. benchmark evaluation ofﬁcial kitti test performed image space. therefore project detections image plane using provided calibration ﬁles discard detections fall outside image. kitti benchmark differentiates easy moderate hard test categories depending bounding size object truncation occlusion. hard test case considers largest number positives whereas difﬁcult examples subsequently ignored moderate easy test cases. ofﬁcial rankings based average precision moderate cases. describing training procedure present results three experiments. firstly conduct model comparison validation secondly based results model comparison select model class report results ofﬁcial kitti test lastly compare timing results models trained without sparsity penalty networks trained crops positive negative examples. number positives negatives initially balanced negatives extracted randomly training data locations overlap positives. order improve generalisation compensate fact input discretised spatially well terms angular resolution training data augmented translating original front-facing positive training examples distance smaller size grid cells randomly rotating angle smaller resolution angular bins. hard negative mining performed every epochs running current model across full point clouds training set. round hard negative mining highest scoring false positives frame added training set. fig. illustration model architecture table input intermediate representations layer sparse grids occupied spatial location holds feature vector sparse convolutions ﬁlter weights performed natively compute predictions best viewed colour. loss zero positive samples score negative samples score such hinge loss drives sample scores away margin given interval standard cnns hinge loss backpropagated network training. sparsity penalty relu non-linearity helps maintain sparsity intermediate representations propose include additional regulariser incite network discard uninformative features increase sparsity throughout entire stack. sparse representations values exactly zero precisely requirement model. whereas sparsity output layer tuned detection threshold encourage sparsity intermediate layers incorporating penalty term using norm feature activation. normalise loss respect spatial dimensions feature layer. renders inﬂuence sparsity penalty less dependent size input given parameter setting. fig. model comparison architecture table showing average precision moderate difﬁculty level. non-linear models three layers consistently outperform linear baseline model internal validation considerable margin three classes. performance continues improve number ﬁlters hidden layers increased gains incremental compared large margin linear baseline smallest multi-layer models. best viewed colour. fig. precision-recall curves evaluation results kitti test set. model cars model pedestrians cyclists eight ﬁlters hidden layers trained without sparsity penalty used submission ofﬁcial test server. best viewed colour. ﬁlter weights initialised networks trained epochs stochastic gradient descent momentum term batchsize constant learning rate weight decay model epoch highest validation selected model comparison test submission. timing experiments observed selecting models epoch highest validation tends favour models comparatively sparsity intermediate representations. thus models full epochs training used timing experiments enable fair comparison. implemented custom library training testing. largest models training takes three days cluster node cores example batch processed separate thread. fast detection speeds particularly important context robotics. larger expressive models come higher computational cost consequently slower speeds section investigates trade-off model capacity detection performance validation set. five architectures summarised table three layers different ﬁlter conﬁgurations benchmarked other. model architecture illustrated example figure small kernels used lower layers followed relu non-linearity. architectures designed total receptive ﬁeld slightly larger class-speciﬁc bounding boxes. network output computed linear layer implemented convolutional ﬁlter whose kernel size gives desired receptive ﬁeld size given object class. non-linear multi-layer networks clearly outperform linear baseline comparable first foremost demonstrates increasing complexity expressiveness models extremely helpful detecting objects point clouds. resulting gains increasing number convolutional ﬁlters hidden layers moderate compared large improvement baseline achieved eight ﬁlters. similarly increasing receptive ﬁeld ﬁlter kernels keeping total receptive ﬁeld networks same indicate signiﬁcant improvement performance. possible larger models sufﬁciently regularised. another potential explanation easy interpretability data enables even relatively small models capture variation input representation informative solving task. model comparison shows increasing number ﬁlters kernel size signiﬁcantly improve accuracy inevitably deteriorating detection speed. consequently choose limit eight ﬁlters hidden layers test submission. models parallel deployment ideally approximately detection speed. larger physical size cars compared pedestrians cyclists corresponding networks need larger ﬁlter kernel output layer achieve required total receptive ﬁeld negative effect detection speed. submission kitti test server therefore select model layers cars model three layers pedestrians cyclists. curves models kitti test shown figure performance votedeep compared leading approaches object detection point clouds time writing table votedeep establishes state-of-the-art performance category three classes three difﬁculty levels. performance boost particularly signiﬁcant cyclists margin almost easy test case doubling test cases. also compare votedeep methods utilise point cloud image data time writing table iii. despite using point cloud data votedeep still performs better majority test cases slightly worse remaining ones considerably faster detection speed. three object overall compared deep networks used vision relatively shallow networks trained without recently developed tricks expressive enough achieve signiﬁcant performance gains. interestingly cyclist detection beneﬁts expressiveness cnns even though class least number training examples. conjecture cyclists distinctive shape compared pedestrians cars easily confused poles vertical planes respectively votedeep models exploit complexity particularly well despite small number positive training examples. three models test submission also trained different values sparsity penalty examine effect penalty detection speed accuracy moderate test cases validation table mean standard deviation detection time frame measured frames. independent whether sparsity penalty employed pedestrians fastest detection speed receptive ﬁeld networks smaller compared classes. two-layer model cars runs faster three-layer model cyclists. imposing sparsity penalty training detection speed test time improved almost cars negligible decrease accuracy. applying large penalty activations pedestrian cyclists models collapse zero training. smaller penalty detection speeds improve fastest cyclist model average precision decreases compared baseline. pedestrians however noted model without penalty starts overﬁt training full epochs. case sparsity penalty helps regularise model beneﬁcial effect model’s accuracy. notably sparsity penalty proves useful increasing detection speed cars larger penalty applied. conjecture reduced number intermediate layers well larger receptive ﬁeld help model learn signiﬁcantly sparser still highly informative intermediate representations. sparsity penalty beneﬁcial effect detection speed rigorous investigation statistics gain would useful given stochastic nature training algorithm. leave investigation future work. work performs object detection point clouds fast speeds cnns constructed sparse convolutional layers based voting scheme introduced ability learn hierarchical representations non-linear decision boundaries state established kitti benchmark detecting objects point clouds. votedeep also outperforms methods utilise information point clouds images test cases. possible future directions include low-level input representation well implementation voting algorithm. authors would like acknowledge support work epsrc grant number leadership fellowship grant intelligent workspace acquisition studentship; google studentship; advanced research computing services university oxford. szegedy sermanet reed anguelov erhan vanhoucke rabinovich going deeper convolutions proceedings ieee computer society conference computer vision pattern recognition vol. --june geiger lenz urtasun ready autonomous driving? kitti vision benchmark suite proceedings ieee computer society conference computer vision pattern recognition jampani kiefel gehler learning sparse high dimensional filters image filtering dense crfs bilateral neural networks ieee conf. computer vision pattern recognition chen p.-a. heng voxresnet deep voxelwise residual networks volumetric brain segmentation arxiv preprint arxiv. available http //arxiv.org/abs/. chen zhao wang heng automatic detection cerebral microbleeds images convolutional neural networks ieee transactions medical imaging vol. available http//ieeexplore.ieee.org prasoon petersen igel lauze nielsen deep feature learning knee cartilage segmentation using triplanar convolutional neural network lecture notes computer science vol. lncs part zhang delving deep rectiﬁers surpassing human-level performance imagenet classiﬁcation arxiv preprint arxiv. available https//arxiv.org/abs/. behley steinhage cremers laser-based segment classiﬁcation using mixture bag-of-words ieee international conference intelligent robots systems gonzalez villalonga vazquez amores lopez multiview random forest local experts combining lidar data pedestrian detection ieee intelligent vehicles symposium proceedings vol. -augus", "year": 2016}