{"title": "Dynamic Steerable Blocks in Deep Residual Networks", "tag": ["cs.CV", "stat.ML"], "abstract": "Filters in convolutional networks are typically parameterized in a pixel basis, that does not take prior knowledge about the visual world into account. We investigate the generalized notion of frames designed with image properties in mind, as alternatives to this parametrization. We show that frame-based ResNets and Densenets can improve performance on Cifar-10+ consistently, while having additional pleasant properties like steerability. By exploiting these transformation properties explicitly, we arrive at dynamic steerable blocks. They are an extension of residual blocks, that are able to seamlessly transform filters under pre-defined transformations, conditioned on the input at training and inference time. Dynamic steerable blocks learn the degree of invariance from data and locally adapt filters, allowing them to apply a different geometrical variant of the same filter to each location of the feature map. When evaluated on the Berkeley Segmentation contour detection dataset, our approach outperforms all competing approaches that do not utilize pre-training. Our results highlight the benefits of image-based regularization to deep networks.", "text": "filters convolutional networks typically parameterized pixel basis take prior knowledge visual world account. investigate generalized notion frames designed image properties mind alternatives parametrization. show frame-based resnets densenets improve performance cifar-+ consistently additional pleasant properties like steerability. exploiting transformation properties explicitly arrive dynamic steerable blocks. extension residual blocks able seamlessly transform ﬁlters pre-deﬁned transformations conditioned input training inference time. dynamic steerable blocks learn degree invariance data locally adapt ﬁlters allowing apply different geometrical variant ﬁlter location feature map. evaluated berkeley segmentation contour detection dataset approach outperforms competing approaches utilize pre-training. results highlight beneﬁts image-based regularization deep networks. deep convolutional neural networks state-of-the-art solution many vision tasks however known data-inefﬁcient require millions training samples achieve powerful performance work propose formulation cnns efﬁciently learns exploit generic regularities known present data priori. images well sensory data cnns typically learn ﬁlters individual pixel values. paper show alternatives pixel basis natural formulations learning models locally well-understood data like images. show increased classiﬁcation performance state-of-the-art resnets densenets highly competitive cifar- classiﬁcation task replacing pixel basis basis suitable natural images. further show replacement naturally leads powerful extensions residual blocks dynamic steerable interpolators steer copyright document resides authors. distributed unchanged freely print electronic forms. figure left classical residual block used vanilla resnets outputs previous block combined additively output small stack convolutional layers form ﬁnal output augment formulation ways achieve dynamic block formulation right. first apply change steerable frame input second replace addition operation multiplication. permits interpret pose estimating network directly outputs linear projection coefﬁcients transforming basis subsequently effective ﬁlters adaptively dynamic desired location dependent manner. ﬁlters conditioned input respect pre-deﬁned continuous geometric transformations like rotations scalings. proposed block allows network adaptively learn degree local invariance required ﬁlter decoupling ﬁlter learning local geometrical pose adaption. show effectiveness approach boundary detection task precise adaptive local invariances key. outperform competing non-pretrained methods approach. contributions introduce notion frame bases cnns show classically used frames computer vision optimization compared commonly used pixel basis. illustrate improving classiﬁcation performance cifar-+ multiple resnet densenet architectures mere substitution pixel basis frame only. exploiting steerability properties frames further derive dynamic steerable blocks able continuously transform features locally adaptive manner illustrate approach synthetic tasks highlight advantages competing approaches. evaluate practicality proposed approach apply dynamic steerable block networks bsds- contour detection task achieve increased performance among competing methods utilize pre-training. paper organized follows. first review related literature alternative parametrizations incorporation prior geometrical knowledge cnns. secondly introduce theoretical framework frame-based cnns steerable two-factor blocks work rests upon. third show careful reparametrization cnns increase performance natural image classiﬁcation. lastly show extend framebased resnet blocks dynamic steerable blocks ability dynamically adapt ﬁlters several advantages promising results berkeley contour detection dataset. convolutional networks alternative bases proposed various degrees ﬂexibility. number works utilizes change basis stabilize training increase convergence behavior another line research concerned complex-valued cnns either learned fully designed like scattering networks scattering well complex-valued networks rest upon direct connection between signal processing literature cnns. inspired former structured receptive field networks learned overcomplete multi-scale frame effectively improving performance small datasets restricted feature spaces closely related another line recent promising work group-equivariant steerable cnns latter build steerable representations appropriately chosen basis functions illustrating cnns well-chosen geometrical inductive biases consistently outperform state-of-the-art approaches multiple domains. however approaches rely hand-engineered types representations none considers locally adaptive ﬁltering learned degree invariance bridge gap. inspired cnns learned alternative bases introduce general principle frame-based convolutional networks allow non-orthogonal overcomplete steerable feature spaces. steerable frames concept established early signal processing. initially introduced concept extended steerable pyramid lie-group formulation further steerability recently related tight frames presenting simoncelli’s steerable pyramid multiple wavelets arising special case non-orthogonal riesz transform steerable pyramids applied cnns pre-processing step learnable. incorporate steerable frames cnns increase facto expressiveness allow learn conﬁgurations rather picking priori. another impose structure onto representations subsequently increase data-efﬁciency pre-deﬁning possible transformations done transforming autoencoders inputs image pose space neural network. spatial transformer networks learn global deformable convolutional networks local transformation parameters similar applying nonlinear co-registration feature stack estimated pose. dynamic filter networks move step estimate ﬁlters location conditioned input. approaches dynamic sense condition parameters input appearance. proposed dynamic residual block interpreted middle ground combines idea dynamic filter networks explicit pose prediction blocks locally estimate ﬁlter poses continuous input space. such overcome difﬁculty estimating local ﬁlter pose able separate pose feature learning globally without need differentiable samplers locally connected layers. general viable bases learn ﬁlters called frames frames natural generalization orthogonal bases spanning sets span space functions orthogonal basis does allowing overcomplete representations hence densely sampled parameter spaces. figure orthonormal basis linearly independent span space example represents ﬁlter convolutional network coefﬁcients {uu}. tight frame linearly dependent. example represents convolutional ﬁlter coefﬁcients {uuu}. frame overcomplete representation spanning preserving norm. note ﬁlter coefﬁcients represented unique. thus even obstructed noisy updates measurements ﬁlter still robust. frames seen superset orthogonal bases sense every basis frame reverse ﬁgure frames three main advantages frames spell signal properties explicitly facilitating optimization good frames type data known case many types signals like images video frames allow overcomplete representations signal adding robustness regularization optimization procedure stable measurements updates noisy. many frames steerable thus provide signal representation dynamically steered simple linear projections i.e. ability linearize group actions. properties illustrated experiment merely replace standard pixel bases alternative frames evaluate effect. property illustrated experiments leverage steerability property frames explicitly. standard convolutional network ﬁlter kernel linear combination standard basis pixel basis composed delta functions every dimension ﬁlter network parameters without loss generalization orthonormal standard basis replaced frame include steerability non-orthogonality overcompleteness increased symmetries representation. changing pixel arbitrary frame simple replacing pixel basis frame choice elements follows ﬁlter coefﬁcients learned. note optimization overcomplete frame done resulting network rewritten terms standard pixel basis. therefore frames regularizer training increase effective parameter cost network. practice cnns working images investigate four typical choices frames vanilla orthogonal pixel basis gaussian derivatives widely used overcomplete frames computer vision literature iii) framelets non-orthogonal overcomplete basis designed images \"naive\" frame form xpyq derived steerability requirements image properties mind. ﬁgure plots frames experiments section performance. figure illustrative plot multiple spanning sets pixel-basis gaussian derivatives non-orthogonal framelet naive frame. note increased symmetries three latter. many frames steerable means equivariant respect group transformation linearize action transformation groups. formally weights ﬁlter transformation input basis steerable transformation linear mapping that means instead steering effective ﬁlters represented sufﬁcient steer basis effective ﬁlters transformed accordingly. thus change steerable basis makes possible dynamically adapt ﬁlters linear projections also opening ways learn local global invariants efﬁciently. show below property permits dynamically transform ﬁlters directly learn degree invariance variabilities like rotation scaling others depending type basis used. steerability allows separate feature’s pose canonical appearance. equation follows steerable version arbitrary ﬁlter k-parameter group expressed thus sufﬁcient determine group action ﬁxed frame steering separate canonical feature k-parameter variants i.e. frame coefﬁcients underlying feature steering functions governing transformation acting whole. following section connect insight frame-based static residual blocks turn dynamic two-factor blocks perform geometrically regularized locally adaptive ﬁltering. achieve precise geometrical regularization derive steering equations particular steerable frame hand resulting trigonometric functions activation functions suitable learning cnn. activation functions omitted general tasks like classiﬁcation demand local transformations precisely deﬁned show serve important regularizers tasks precise geometric adaption needed exampliﬁed boundary detection experiments. brevity moved steering equation derivation steerability proofs supplementary material. deep residual networks among best performing current approaches convolutional networks. instead optimizing single layers consist convolutional blocks skip connections output block deﬁned typically stack convolution layers batch normalizations nonlinearities residual blocks overcome vanishing gradients facilitate optimization leading simple deep networks need pooling fully connected layers. following sections introduce extensions residual blocks two-factor models overcome static nature typical cnns leveraging previously introduced steerable frames. simple extension transforms static residual blocks dynamic modules able change geometrical pose ﬁlters conditioned input training inference time locally adaptive fashion. here factor represents canonical feature represents pose. function estimates local pose. space possible poses pre-conditioned choosing suitable frame steerable pre-deﬁned sets deformations thus span invariant subspace transformed versions basis itself. advantage proposed dynamic steerable block common methods achieving local invariance method goes beyond maximum search local pose estimation thus overcomes inherent ambiguity local maximum search many natural images. achieved allowing include context around current ﬁlter location estimation enabling stable task-dependent pose estimation. figure illustrates instance problem maximum response solve task learned pose estimation ﬁnding poses neither maxima minima necessary. note however invariance harmful task hand model also learn fall back standard representations well. blocks used boundary detection experiments based gaussian derivatives steerable respect continuous rotations small ranges isotropic scalings dynamic two-factor block consists four processing steps. change input frame space convolving frame interpolator network estimates local pose invariant subspace outputting pose variables location image input/output channel interpolator network used small network units three layers tanh nonlinearities seemed suitable approximate trigonometric steering equation solutions. scalings found softplus relu nonlinearities work well. optional steering functions derived section applied pose variable maps effectively nonlinear pose-parametrized activation functions regularize interpolation network output explicitly interpretable pose space. table results frames cifar-+ reported average runs standard deviation. compare models standard pixel-basis steerable frame basis designed natural images naive steerable frame example frame take natural image statistics account. natural image statistics based frame outperforms pixel-basis consistently naive frame consistently performs worse baseline highlighting beneﬁt frame suitable type input data. experimental section organized parts. experiment illustrates mere replacement pixel basis frames outperforms highly optimized ﬂexible approaches like resnets densenets domains excel given good frame data hand known. note part explicitly make steerability focuses illustrating effect various frame choices according equation experiment makes explicit steerability according equation illustrating dynamic steerable block mechanism applying difﬁcult real-world task boundary detection outperform pre-trained methods among rotation invariant. show effect replacing commonly used pixel-basis frames compare different frames multiple state-of-the-art deep residual network densenet architectures cifar- dataset moderate data augmentation crops ﬂips. evaluated approach different network sizes still comfortably train night each. setup used resnet described batch size chosen train epochs described learning rate decrease. resnet architectures used without bottlenecks layers. densenets follow evaluate models. experiments keras tensorﬂow ﬁrst experiment models standard pixel basis viable baseline. results line better numbers reported authors. secondly replace pixel-basis widely-used frames take natural image statistics account namely non-orthogonal overcomplete gaussian derivatives non-orthogonal framelets alternating fashion yielding superior performance compared pixel-basis replacement only. also show naively derived xpyq frame performs consistently worse choices take natural image properties account. frames used shown ﬁgure results reported table fact pixel-basis replaced steerable frames well-understood properties performance improves remarkable. frame-based cnns approximately runtime vanilla cnns. evaluate proposed dynamic steerable two-factor blocks boundary detection natural task locally adaptive ﬁltering. ﬁrst part illustrate properties proposed mechanism second part apply challenging real-world problem outperform competing approaches. figure results boundary detection experiment illustrate workings proposed mechanism ability solutions well beyond simple maximumguided pose invariance overcomes inherent ambiguity present natural textures. left right input network; gradient magnitude equivalent pooling rotations ﬁlter location; pixel-wise predictions network pose variables discovered pose estimation network pixel-wise targets. perfectly discovers simple maximum-guided invariance rule recover target. complex local relationships solved simple invariants recovered. note small blobs right barely visible input gradient magnitude still correctly segmented. iii) challenging scenario blobs backgrounds hardly distinguished gradient magnitude contain much useful visible information task either. note learns alternating pattern rotation overcomes irregular local gradients recovers targets successfully. experiment empirically validate effectiveness approach single dynamic steerable block showing indeed learns adaptive non-trivial invariants conditioned local neighborhoods image. show this create artiﬁcial dataset random blobs whose boundaries detected dynamic steerable block pixel-wise classiﬁcation task. dataset inﬁnite created ﬁrst case blob background binary task solved simple gradient magnitude invariant presents challenge algorithm. fully convolutional network baseline size achieves almost performance. second third example sample textures tips dataset blobs well background different textures each. here gradient magnitude either gives weak clues many cases unable outline given target. cases fully convolutional baseline fails converge. remarkably even though dynamic steerable block receive gaussian derivative gradient ﬁlters input still manages highly non-linear steering patterns recover boundaries. results shown ﬁgure show unseen inputs alongside manually calculated gradient magnitude predictions associated pose maps estimated dynamic steerable block. even hard cases dynamic block manages largely recover labeled boundaries. results evidence ability proposed method learn adaptive invariants conditioned local context image ways beyond simple maximum response guided steering. figure results pre-trained state-of-the-art models alongside currently best performing approach pre-training bsd. show results dynresnet left right input image; prediction different ground truth labels. dynamic steerable resnet outperforms methods including model static blocks pre-training performed. also outperform fully rotation invariant h-net accordance ﬁndings texture experiments found stable nonmaximum guided invariance likely superior ambiguous cases. note kivinen non-pretrained re-implementations reported pre-trained dcnn outperform non-pretrained approaches. brevity report state-of-the-art pre-trained dcnn. experiment apply dynamic steerable blocks real task adaptive invariance desirable. recently fully equivariant engineered output locally rotation invariant predictions performed well task. show learned adaptive invariance even powerful even though ﬁnal edge prediction rotation invariant intermediate processing beneﬁts context dependent degree invariance. evaluate method contour detection task berkeley segmentation dataset. dataset consists images divided train/val/test split. tune hyperparameters validation report results test following protocol image labelled human annotators resulting multiple ground truth maps image. follow merge different labels majority vote one. minimize pixelwise binary cross-entropy loss ground truth prediction class balancing classes heavily imbalanced resnet model designed segmentation reduce size drastically limited data-scenario face. eventually network following structure convd->dynresblock->statresblock->dynresblock>statresblock->convd. thus alternate static dynamic blocks found setup stabilizes training considerably validation set. dynamic blocks based gaussian derivatives exact setup described appendix. report metrics based f-scores. subjective aspect contour segmentation task ambiguous network implicitly estimate level detail segment boundaries. cases network’s prediction agrees least human annotators sometimes segments boundaries high level detail results show outperform state-of-the-art approaches pre-trained imagenet according re-implementations including static resnet baseline explicitly rotation invariant harmonic networks approach however pretrained imagenet dcnn holistically nested edge detection clearly outperform non-pre-trained approaches. conclusion show learned piece-wise invariance superior compared hand-crafted maximum response invariance applied harmonic networks supporting ﬁndings texture experiments. however semantic high-level knowledge models acquire imagenet pre-training still seems include forms knowledge geometrical regularization overcome making results especially interesting domains large datasets pre-training available summary introduced framework opens range novel efﬁcient ways incorporate geometrical priors regularization deep networks without restricting theoretical expressiveness. introduced notion frame-based cnns derived dynamic steerable blocks frame-based residual networks. summary shown cnns based frames speciﬁcally designed data hand facilitate optimization consistently even data abundant. hand proposed dynamic steerable blocks achieve superior performance data limited superior ﬁlters precisely dynamically adapt local patterns non-trivial ways needed.", "year": 2017}