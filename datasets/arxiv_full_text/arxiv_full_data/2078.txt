{"title": "K-NS: Section-Based Outlier Detection in High Dimensional Space", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "Finding rare information hidden in a huge amount of data from the Internet is a necessary but complex issue. Many researchers have studied this issue and have found effective methods to detect anomaly data in low dimensional space. However, as the dimension increases, most of these existing methods perform poorly in detecting outliers because of \"high dimensional curse\". Even though some approaches aim to solve this problem in high dimensional space, they can only detect some anomaly data appearing in low dimensional space and cannot detect all of anomaly data which appear differently in high dimensional space. To cope with this problem, we propose a new k-nearest section-based method (k-NS) in a section-based space. Our proposed approach not only detects outliers in low dimensional space with section-density ratio but also detects outliers in high dimensional space with the ratio of k-nearest section against average value. After taking a series of experiments with the dimension from 10 to 10000, the experiment results show that our proposed method achieves 100% precision and 100% recall result in the case of extremely high dimensional space, and better improvement in low dimensional space compared to our previously proposed method.", "text": "doesn’t meet exact description anomaly data normal data longer. distinguished point difference distributions normal data anomaly data. existing methods insist finding outliers distance even high dimensional space. find anomaly data obviously normal data ignore anomaly data inside range normal data. therefore give definition anomaly data high dimensional space approach most data conform distribution normal distribution small part data conforms another different distribution distribute randomly. rare data called anomaly data detected specific measures. paper reconsider concept outliers explain section space concept propose algorithm called kns. main features contributions paper summarized follows analyze connection data distribution different dimensions. this high dimensional problem transformed dimensional-loop problem. problem easily solved statistic method. proposed method uses k-nn concept section calculation puts forward novel k-ns concept. hence proposal better evaluate disperse degree points neighbor points projected dimension. execute series experiments range dimensions evaluate proposed algorithm. experiment results clearly show proposed algorithm significant advantages algorithms stably precisely large volumes data dimension increases extremely high. even dimensional data experiment algorithm easily achieves precision recall result compared ever-proposed anomaly detection algorithms. also point difference outliers noisy data. outliers obviously different high dimensional space noisy data. concepts confusing mixed together dimensional space even considered identical researchers. furthermore analyze feature data distribution high dimensional space. study high dimensional space provides view solve anomaly data detection issue. paper organized follows. section give brief overview related works high dimensional outlier detection. section introduce concept novel approach also describe proposal discuss optimizations. section evaluate proposed method experiments abstract finding rare information hidden huge amount data internet necessary complex issue. many researchers studied issue found effective methods detect anomaly data dimensional space. however dimension increases existing methods perform poorly detecting outliers high dimensional curse. even though approaches solve problem high dimensional space detect anomaly data appearing dimensional space cannot detect anomaly data appear differently high dimensional space. cope problem propose k-nearest sectionbased method section-based space. proposed approach detects outliers dimensional space section-density ratio also detects outliers high dimensional space ratio k-nearest section average value. taking series experiments dimension experiment results show proposed method achieves precision recall result case extremely high dimensional space better improvement dimensional space compared previously proposed method. categories subject descriptors database applicationsdata mining. outlier detection. general terms algorithms experimentation performance keywords anomaly detection outlier detection high dimension data projection k-ns. introduction seeking meaningful information large database always significant issue data mining field. valued data called anomaly data different rest normal data based measures. also called outliers distance density view. many definitions outliers proposed according different perspectives. widely accepted definition outlier hawkins’ outlier observation deviates much observations arouse suspicion generated different mechanism definition describes difference data observation also points essential difference data mechanism. dimensional space outliers considered points normal points based distance. however high dimensional space distance ermission make digital hard copies part work personal classroom granted without provided copies made distributed profit commercial advantage copies bear notice full citation first page. copy otherwise republish post servers redistribute lists requires prior specific permission and/or fee. different dimensional artificial dataset real dataset. conclude findings section related works important sub-tree data mining field anomaly data detection developed years many study results achieved large scale database. categorize following five groups introduce methods clearly. distance density based outlier detection distance based outlier detection classic method comes original outlier definition i.e. outliers points points based distance measures e.g. hilout. algorithm detects point k-nearest neighbors distance uses space-filling curve high dimensional space. well-known uses k-nn density based algorithm detects outlier locally knearest distance neighbor points measures outliers algorithm runs smoothly dimensional space still effective relative high dimensional space. loci improved algorithm based sensitive local distance lof. however loci performs worse high dimensional space. subspace clustering based outlier detection since difficult find outliers high dimensional space find points behaving abnormally dimensional space. subspace clustering feasible method applied outlier detection high dimensional space. approach assumes outliers always deviated others dimensional space different high dimensional space. aggarwal uses equi-depth ranges dimension expected fraction deviation points k-dimensional cube given method detects outliers calculating sparse coefficient cube outlier detection dimension deduction another method dimension deduction high dimensional space dimensional space mapping several dimensions dimensions detecting outliers dimensional space. findout detects outliers removing clusters deducts dimensions wavelet transform multidimensional data. however method cause information loss dimension reduced. result robust expected seldom applied outlier detection. information-theory based outlier detection distribution points dimension coded data compression hence high dimensional issue changes information statistic issue dimension. christian bohm proposed coco method outlier detection also applies method clustering issue e.g. robust information-theory clustering. outlier detection methods besides four groups detection measurements also distinctive useful. notable approach called abod based concept angle vector product scalar product. outliers usually smaller angles normal points. methods reduced high dimensional cures moderately correct results special cases. however high dimensional curse problem still exists affects point’s detection. christian bohm’s information-based method similar subspace clustering methods applied detect outliers dimensional space. summary seeking general approach detect outliers high dimensional space still issue needs solved. proposed method well known euclidean distance points high dimensional space becomes obscure immeasurable. high dimensional curse. moreover outlier detection subspace dimension reduction cause information lost valid specific dataset. still need find suitable outlier detection high dimensional space. general idea learning subspace outlier detection methods know high dimensional issue transformed statistical issue loop detection different subspaces. also noticed points’ positions change differently different dimensions. observation analysis points found outliers placed cluster normal points dimensions deviated points dimensions. otherwise another situation outliers clustered differently different dimensions normal points normal points always clustered dimensions. therefore proposed method needs solve issue conditions whether points density dimensional space; whether points deviated points section dimension points projected dimensions. proposal divided four steps. first divide entire range data small regions dimension. here call small region section. based section divisions construct data structure called section space different traditional euclidean space. second compare point’s scattering others different sections dimension computing section density value. third compare point’s dispersing section dimension projecting dimensions. last results point compare points statistic measure. outliers points whose values obviously higher points. section data structure proposed method based section data structure. mechanism compose section structure transform euclidean data space proposed section space necessarily introduced detail below. divide space number sections dimension space looks like grid. conventional data space information composed points dimensions proposed data structure represents data distribution point dimension section. structure overcomes shortcomings distance measurement conventional space easy observe distribution changes points section sections dimensions varied different situations. data structure described pointinfo sectioninfo follows number points section called section density. means average section density dimension. means section density dimension. means section density point dimension. section distance used evaluating section difference among points projected dimensions defined equation point deviation value dimension defined equation section density presents different meanings different cases. case section points section section density means section density value dimension section. points section dimension value. case section density used compare average value dimension. section density ratio average section density dimension. means average section density dimension. case section density point needed expression include point. means section density value point dimension. different subscriptions express specific meaning point section dimension although expressed dimension projection concept needs clarified. point coordinate value different dimensions. dimensions equal relations. however observe change points different dimensions need points section certain dimension first compare distance change points different dimensions. initial dimension called original dimension different dimensions called projected dimension. means project points original dimension dimensions. k-ns outlier detection method section space different method conventional data space. existing methods using distance density among points cannot applied section space directly. section space point gets values different sections dimensions example dimensional data explain transforming process original dataset section space shown figure example dataset includes points dimensions shown figure original data placed data space conventional method shown figure proposed section-based structure construct pointinfo structure illustrated figure sectioninfo shown figure range dimension divided five sections. section division sample shown data space blue lines figure sectioninfo figure notice range dimension different. largest range dimensions must many blank sections small range dimensions blank sections produce meaningless values would affect result markedly following calculations. therefore range minimum coordinate maximum coordinate dimension. order avoid sections larger density sections loose border enlarge original range taking data figure example explain generate range data dimension. original range dimension length range enlarging length therefore length is.. original range dimension length range length length section dimension dimension. definitions provide explicit explanation proposed method definitions formulated follows information point. refers point points. refers point dimension. range data dimension divided number equi-width parts called sections. width section determined section density range dimension. needs evaluated dimension projected dimensions first step. section density ratio comparison dimension outlier points always appear sparsely normal points detected dimensions. therefore density outliers lower average density dimension. section density ratio points average section density reflect sparsity dimension also compare points different dimensions. definition noticed secval section density value ratio section density average value dimension. reason point different sparsity different dimensions. points section density compare value easily affected different dimensions cannot accurate result. ratio section density overcomes shortcoming independent among dimensions decided distribution points dimension. another noticed aspect secval correspond point actually presents section’s density value. hence points section share secval values. k-nearest section comparison projected dimensions outliers don’t appear farther dimensions cannot detected first step. since hide among normal points similar distance density others. nevertheless points still found different points section projected dimensions. step aims find outliers normal points projecting points different dimensions. section distance measurement effective method compare points. based section distance concept referring k-nearest neighbor concept ratio nearest sections point projected dimensions. definition values decide whether points outliers not. propose novel method effective high dimensional space called k-nearest sections k-ns. proposed method statistical approach detects outliers dimension projected dimensions. introduce k-ns definition dists need clarified advance. noted section distance defined paper different general definition distance. definition original dimension section. dimension change section compare section difference dists absolute difference value secid points. minimum dists point different conventional euclidean distance concept. frequency points section points coordinate must many minimum sections distance. neighbor points minimum dists point gets value neighbor point’s dists. case easily cause illegal computation invalid compare points. minimum dists solve question perfectly. k-ns mathematic definition based dists find outliers different situations. definition points section dimension point anyone k-nearest points give dists neighbor points compare points original section projecting dimensions. k-ns gives effective method dists discriminate points section projecting dimension original others statistical value summarizing values point dimension projected dimension means could used whole result finding outliers impossible found certain dimensions. k-ns definition outliers satisfy either conditions first condition guarantees outliers detected second condition guarantees outliers still detected neighbor points’ dists projected dimensions point appear abnormal dimensional space. proposed method uses loop calculation dimensions instead calculation euclidean distance. therefore point value definition point output outliers points three points need clarified algorithm. first point decide average section density dimension. value easily obtained calculation means dimension. however case points distribute small parts sections point exists sections becomes even close outlier’s section density. count sections points don’t count sections without points calculating subsequently reflects average section density points dimension also varies different dimensions. hence ratio section density definition measure sparsity points different sections dimension. point’s value distinct among different points outlier’s value obviously different normal point’s value. different dataset changing weight values could bring better result. however clarifying effective statistic method considered order give sharp boundary compare points. evaluating different methods performance choose simple clear calculation method. here reciprocal value average secval secvalp. outliers obviously larger normal points’. definition equation simply sums secval secvalp dimensions. whether getting point’s value dimension projected dimensions point’s values ratio average value respective dimensions. time normal points around average value dimension. hence value normal points close outlier’s value obviously larger however true high dimensional space. normal points’ getting smaller dimension increasing values always much lower well outlier’s values also lower nevertheless outlier’s still obviously higher normal points’. therefore outliers easily found sorting points values. algorithm section focus implement k-ns method language. pointinfo sectioninfo effectively different sections dimensions issue needs considered detail. proposed algorithm shown figure accuracy loss reduced computing time greatly. third point number points section. three different cases. case point section. case algorithm passes section goes next section. case many points section. case nearest section method used detect points. case points section. case point distribution difficult judged several points. section density ratio step must low. therefore points already detected previous step. here secvalp=. threshold value separate case case related large less projection dimension step experiments serious values find suitable value threshold number points section solution could adapted situations. distinction outliers noisy data concept outlier noisy data proposed years. according that outlier regarded abnormal data generated different mechanism contains important information noisy data regarded side product clustering points useful information affect correct result greatly. data space outliers points farther others measures noisy points always appear around outliers. since noisy points also away normal points dimensional space difficult make distinct boundary outliers noisy points. based frustrated observations researchers even consider noisy data kind outliers. difference detecting abnormal data methods. hence meaningful issue make distinction outliers noisy points concept also detection measures. paper explain distinction outliers noisy points aspects. first point different data generation processes. outliers generated different distribution normal points. noisy points distribution normal points. second point appear abnormal different dimensional space. noisy points appear abnormally several dimensions appear normal dimensions. whole dimensions’ view noisy data also conform distribution normal data. outlier appear dimensional space conform different distribution mechanism normal points’. therefore conclusion points outliers noisy points detected dimensional space outliers found high dimensional space. example noisy data sample shown figure data retrieved dataset introduced section contains points dimensions. outliers placed middle region found differently normal points. noisy points labeled cloud different projected dimensional space. another example shown figure outliers obvious twodimensional space noisy points distribute marginal area dimensions likely abnormal points. evaluation implemented algorithm applied several high dimensional datasets made comparison among k-ns previous proposed methods. order compare algorithms fair conditions performed algorithms language book .ghz intel core memory. issue outlier detection high dimensional space proposed algorithms called rpgs rpgs statistic method uses ratio section density dimension center section function projected dimensions. definition center section function shown definition rpgs effective cluster data distribution high dimensional space cannot work well clustered data distributions. definition minsec minimum section maxsec maximum section secid>seccenter equation used else equation used. another proposed algorithm detects outliers effectively high dimensional space. quite similar k-ns algorithm also includes three-step detection method. psd’s peculiarity second step estimating outliers projected dimension employs sectionfigure dataset projected two-dimensional space dimensional space. data distribution example shown figure dataset projected two-dimensional space outliers labeled color. clearly shown figure outliers distributed within range normal points show difference normal points two-dimensional space. noisy points placed margin distributed area likely regarded abnormal points. hence different distributions outliers normal data cannot found straight observation. outliers designed loosely distributed scattered fixed regions small probability. nevertheless outliers still within range normal points. effectiveness evaluated thoroughly series experiments compared previous proposed methods. order measure performance algorithms find likely outliers least false rate outliers reprieved one. therefore could provide clear figures describe effectiveness points checked extent founded detected outliers. case dimensional dataset test precision recall better measurement outlier detection efficiency among three algorithms. since recall percentage outliers dataset found correctly precision figures clearly show trend effectively outliers could identified attained points. contrast result affected increasing dimension also precision recall measurement evaluate experiment results dataset processing eight dataset experiments evaluate performance algorithms f-measure increasing dimension dataset experiment obtained precisions recall results respectively. f-measure values obtained dataset test. pick best f-measure dataset better demonstrating experiment performance kns. beginning need appropriate parameters three algorithms eight experimental datasets shown table parameters shown table best ones prepared datasets changed according size data number dimensions etc. parameter clulenj cluster length according section dimension number points section point projected dimension dimension changing number points section pij. denominator average value points product clulen dimension compared rpgs improved algorithm detect outlier case different data distributions. paper normal points test dataset conform five clusters gaussian mixture model. rpgs performs poorly experiments. therefore show experiment result k-ns. synthetic dataset critical issue evaluating outlier detection algorithms benchmark datasets found real world satisfy explicit division outliers normal points. points found outliers real dataset impossible provide reasonable explanation points picked outliers. hand learned statistical knowledge helpful generate artificial dataset points distributions apparently different normal points points regarded outliers. hence generate synthetic data based assumption. high since algorithm aims dimensional space generate eight synthetic datasets points dimensions normal points conform normal distributions outliers conform random distributions fixed region. normal points equally distributed five clusters outliers distributed randomly middle normal points’ range. details parameters dataset shown table large value experiments dataset size around points. reasonable ratio neighbor points whole dataset size. algorithm parameters inverse other. product almost equal total points number. little larger combinations parameters shown better experiment results. parameters k-ns similar previous algorithms verified applicable experiments. since dataset design outliers placed inside range normal data prevent points easily found dimensional space. reason difficult find exact outliers dimensional space. dimensional experiment result shown figure performs best dimensional test. especially detect outliers high precision. nevertheless precision falls sharply increasing recall last result precision worst among three algorithms detecting outliers correctly. k-ns synthesize algorithms’ advantage performance k-ns psd. noticed k-ns’s precision always higher recall rate. conclusion experiment result seen figure gets high precision recall gets precision high recall gets worst precision recall. k-ns precision recall; lower precision increased recall. k-ns achieves double precision better psd’s recall still better increased recall. number dimension increases precision recall evaluation dataset clearly shown effectiveness three algorithms. distinctly first dataset k-ns achieve precision recall time. obviously reduces precision increasing recall shown figure fact k-ns keep perfect result dimensions performs much poorer increasing number dimensions terms precision recall. show whole results effectiveness three algorithms datasets different number dimensions also f-measure dataset. f-measure provide clear simple evaluation index precision recall contrast k-ns different datasets. experiment datasets evaluate effectiveness three algorithms shown figure achieves best f-measure dataset k-ns need pick largest f-measure first dataset. since f-measures always datasets clearly shown k-ns perform perfectly number dimensions works well around dimensional dataset. dimension increasing suffers high dimensional curse greatly fmeasure less dataset learning dataset size test dataset three algorithms better accuracy increasing dataset size. efficiencies subsection compare three algorithms running-time. language running time includes user time system time total time. user time compare them. shown figure fastest algorithm experiments. runs little faster k-ns. average running-time k-ns times times lof. three algorithms take time number dimensions increases data size enlarged. reason dimension-loop calculation processes distance point neighbors. however proposed algorithms k-ns calculate values dimensions different projected dimensions. k-ns gets calculation neighbor points around point takes time process psd. performance real world data subsection compare three algorithms realworld dataset publicly available machine learning repository. arcene dataset provided arcece group. task group distinguish cancer versus normal patterns mass-spectrometric data. two-class classification problem continuous input variables. dataset five datasets nips feature selection challenge. original dataset includes total instances attributes. datasets training dataset validating dataset test dataset. sub-dataset labeled positive negative. order compare algorithms clearly without distraction unnecessary data pick positive test dataset evaluation target. dataset true labeled outliers. therefore evaluate results value points find number points points. experimental result shown table point commonly detected three algorithms. k-ns detect common points points detects different points. possible reason k-ns section-space framework uses neighbor points’ distance. another possible reason runs poor performance high dimensional space. result also proves find outliers limited way. conclustions paper introduce outlier detection method called k-ns designed efficiently detect outliers large high dimensional dataset. basic idea three-step statistical method calculates section density ratio dimension; computes nearest sections ratio projected dimensions summarizes values point comparison points. proposed k-ns algorithm following advantages adapt various outlier distributions outstanding performance large scale dataset high experimental evaluation demonstrated k-ns performs significantly better dimensional space achieves equally excellent results high dimensional space. also provide evidence effectiveness compared high dimensional space. difference outliers noisy data also discussed paper. issue difficult solved dimensional space since data always mixed together. experiments noisy data separated outliers projecting points high dimensional space two-dimensional space. interesting point noisy data seem abnormal outliers projected dimensional space. ongoing future work continue design improve algorithms section-space framework. experiments need tested order seek perfect solution outlier detection high dimensional space. another issue expensive cost processing time high dimensional data tests. solution reduce processing time needs investigated. approaches parallel processing. k-ns method also applied data mining technology clustering high dimensions classifications etc. references markus m.breunig hans-peter kriegel raymond t.ng jorg sander. indetify density-based local outliers. proceedings sigmod international conference management data. christian bohm katrin haegler. coco coding cost parameter-free outlier detection. proceedings sigkdd international conference knowledge discovery data mining. hans-peter kriegel matthias schubert arthur zimek. angle-based outlier detection high dimensional data. sigkdd international conference knowledge discovery data mining christian bohm christos faloutsos etc. robust information theoretic clustering. sigkdd international conference knowledge discovery data mining. spiros papadimitriou hiroyuki kitagawa phillip b.gibbons. loci fast outlier detection using local correlation international conference data integral. engineering christian bohm christos faloutsos etc. outlier-robust clustering using independent components. proceedings sigmod conference management data. feng chen chang-tien arnold boedihardjo. glssod generalized local statistical approach spatial outlier detection. proceedings sigkdd international conference knowledge discovery data mining. naoki bianca zadrozny john langford. outlier detection active learning. proceedings sigkdd international conference knowledge discovery data mining zhang qiang etc. detecting projected outliers high dimensional data streams. proceedings international conference database expert systems applications aaron ceglar john f.roddick david m.w.powers. curio fast outlier outlier cluster detection algorithm larger datasets. aidm proceedings international workshop integrating artificial intelligence data mining vol. australia", "year": 2014}