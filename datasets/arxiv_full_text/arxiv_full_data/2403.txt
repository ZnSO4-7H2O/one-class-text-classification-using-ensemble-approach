{"title": "Distributed Clustering of Linear Bandits in Peer to Peer Networks", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "We provide two distributed confidence ball algorithms for solving linear bandit problems in peer to peer networks with limited communication capabilities. For the first, we assume that all the peers are solving the same linear bandit problem, and prove that our algorithm achieves the optimal asymptotic regret rate of any centralised algorithm that can instantly communicate information between the peers. For the second, we assume that there are clusters of peers solving the same bandit problem within each cluster, and we prove that our algorithm discovers these clusters, while achieving the optimal asymptotic regret rate within each one. Through experiments on several real-world datasets, we demonstrate the performance of proposed algorithms compared to the state-of-the-art.", "text": "provide distributed conﬁdence ball algorithms solving linear bandit problems peer peer networks limited communication capabilities. ﬁrst assume peers solving linear bandit problem prove algorithm achieves optimal asymptotic regret rate centralised algorithm instantly communicate information peers. second assume clusters peers solving bandit problem within cluster prove algorithm discovers clusters achieving optimal asymptotic regret rate within one. experiments several real-world datasets demonstrate performance proposed algorithms compared state-of-the-art. nels. solution propose gossip-based information sharing protocol allows information diffuse across network small cost also providing robustness. set-up would beneﬁt example small start-up provides recommendation system service limited resources. using architecture enables agents exchange data directly corresponding computations could signiﬁcantly decrease infrastructural costs company. time without central server communicating information instantly agents would demand bandwidth. multi-agent linear bandits simplest setting consider agents trying solve underlying linear bandit problem. particular nodes indexed representing ﬁnite agents. time introduction bandits class classic optimisation problems fundamental several important application areas. prominent recommendation systems also arise generally networks consider settings network agents trying solve collaborative linear bandit problems. sharing experience improve performance whole network agent simultaneously also increasing robustness. however want avoid putting much strain communication channels. communicating every piece information would overload chanxi∗t xtθ. agents minimise rate increase cumulative regret. also wish sharing protocol impose much strain information-sharing communication channel. gossip protocol gossip protocol round overlay protocol assigns every agent another agent share information. sharing agents aggregate information based that make corresponding decisions next round. many areas distributed learning computation gossip protocols offered good compromise low-communication costs algorithm performance. using protocol multi-agent bandit setting faces major challenges. first information sharing perfect since agent acquires information agent round. introduces bias unavoidable doubling data points. solution mitigate using delay time information gathered used. delay information sufﬁciently mixed among agents bias vanishes. second order realize delay necessary store information buffer make decisions delay passed. achieved introducing epoch structure algorithm emptying buffers epoch. distributed conﬁdence ball algorithm gossip-based information sharing protocol produce distributed variant generic conﬁdence ball algorithm approach similar authors produced distributed \u0001-greedy algorithm simpler multi-armed bandit problem. however results generalise easily thus signiﬁcant analysis needed. reason linear setting introduces serious complications analysis delay effect mentioned previous paragraphs. additionally algorithm epoch-based whereas using natural simpler algorithmic structure. downside size buffers algorithm grow time. however analyses easily transfer epoch approach too. rate growth logarithmic algorithm still efﬁcient long timescale. clustered linear bandits proposed recently proved successful model recommendation problems massive numbers users. comprises multi-agent linear bandit model agents’ θ-vectors allowed vary across clustering. clustering presents additional challenge groups agents sharing underlying bandit problem information sharing accelerate learning process. formally k}k=...m clustering assume coefﬁcient vector agent reward action given distributed clustering conﬁdence ball algorithm paper proposes initial centralised approach problem clustering linear bandits. approach begin single cluster incrementally prune edges available information suggests agents belong different clusters. show gossip-based protocol give distributed variant algorithm call dccb. main contributions theorems show algorithms dccb achieve multi-agent clustered setting respectively near-optimal improvements regret rates. particular order linear bandits algorithm generic conﬁdence ball algorithm designed single agent linear bandit problem k=...t typically covariance mak= rkxk sufﬁcient statistics characterise conﬁdence ball. then given current action agent selects optimistic action assuming true parameter sits i.e. max)∈dt×ct{xtθ}. pseudocode given appendix result overlay protocol’s uniformly random choice identically distributed ﬁxed information sharing perfect time step current covariance matrix could computed using information gathered agents would algorithm oful algorithm improvement conﬁdence ball algorithm assumes conﬁdence balls characterised algorithm agent maintains conﬁdence ball unknown parameter oful algorithm calculated chooses satisfy buffer buffer initially active objects used algorithm sufﬁcient statistics calculate conﬁdence balls summarise information gathered time arbitrary monotonically increasing function satisfying buffers initially agent shares updates buffers follows buffer remains size contains information gathered time result that rounds sharing current covariance matrices b-vectors used algorithm make decisions form step deﬁne modiﬁed conﬁdence ellipsoids. first need version conﬁdence ellipsoid theorem given incorporates bias introduced random weights proposition max{wi step control bias. norm differences inside square brackets regret decomposition bounded terms matrices would like instead regret decomposition terms matrix give lemmas showing using matrices almost using lemmas involve elementary matrix analysis crucial understanding impact imperfect information sharing ﬁnal regret bounds. agents communicate information round without central server every agent would need communicate chosen action reward every agent round giving communication cost order per-round. call algorithm cbinstsharing. gossip protocol propose agent requires od|v bits communicated round. therefore signiﬁcant communication cost reduction gained logd using epoch-based approach per-round communication cost gossip protocol becomes improves efﬁciency horizon requiring proofs regret performance simple modiﬁcations dcb. however comparison growing buffers issue number rounds typically large. clear communication advantage cb-instsharing potential approaches problem. example instead randomised neighbour sharing deterministic protocol roundrobin communication costs dcb. however regret bound suffers naturally larger delay network dcb. moreover attempting track potential doubling data points using gossip protocol instead employing delay leads back communication cost order round. detail included appendix analysis show bias introduced imperfect information sharing mitigated delaying inclusion data estimation parameter proof builds analysis emphasis show handle extra difﬁculty stemming imperfect information sharing results inﬂuence various rewards step control bias coming delay. next need control bias introduced leaving last time steps conﬁdence ball estimation calculation proposition pairs dccb algorithm pretty much algorithm except also applies pruning protocol described. particular agent sharing information another three possible actions proved theorem below sharing pruning mechanism high probability ﬁnite time agent ﬁnds true cluster i.e. moreover since algorithm resets local information time pruning occurs true clusters identiﬁed cluster shares information gathered within cluster thus avoiding introducing bias sharing information gathered outside cluster before clustering identiﬁed. full pseudo-code dccb algorithm given algorithm differences algorithm highlighted blue. figure plot performance dccb comparison club cb-nosharing cb-instsharing. plots show ratio cumulative rewards achieved algorithms cumulative rewards achieved random algorithm. examines \u0001-greedy strategies peer peer network provided initial inspiration current work. paper examines extreme case communication channel across agents communicate communication must performed observation action choices alone. another approach multi-armed bandit case directly incorporates communication cost regret. second several recent advances regarding state-of-the-art methods clustering bandits. work faster variant adopt strategy boosted training stage. authors cluster users also cluster items collaborative ﬁltering case sharp regret analysis. finally paper treats setting similar agents attempt solve contextual bandit problems distributed setting. present algorithms distributed version approach taken show achieve least good asymptotic regret performance distributed approach centralised algorithm achieves. however rather sharing information across limited communication channel allow agent another agent choose action them. difference settings reﬂected worse regret bounds order best. discussion analysis tailored adapt proofs generic conﬁdence ball algorithms distributed setting. however many elements proofs including propositions could reused provide similar asymptotic regret guarantees distributed versions bandit algorithms e.g. thompson sampling algorithms dccb synchronous algorithms. work distributed computation gossip algorithms could alleviate issue. current pruning algorithm dccb guarantees techniques applied algorithms. however results powerful could used even agents identify sub-network true clustering. furthermore existing interesting algorithms performing clustering bandits recommender systems cofiba would interesting understand general techniques applied club are. theorem assume holds denote smallest distance bandit parameters exists constant probability total cumulative regret cluster agents employ dccb bounded analysis follows following scheme true clusters correctly identiﬁed nodes within cluster algorithm thus analysis reduces case section adapt results show long true clusters identiﬁed high probability. proof deferred appendices experiments discussion experiments closely implemented experimental setting dataset construction principles used detailed description refer reader evaluated dccb three real-world datasets centralised counterpart club benchmarks used therein cbnosharing cb-instsharing. lastfm dataset comprises users appear least times. delicious dataset users appear least times. movielens dataset contains users appears least times. performance measured using ratio cumulative reward algorithm predictor chooses random action time step. plotted figure experimental results clear dccb performs comparably club practice outperform cb-nosharing cb-instsharing. relationship existing literature several strands research relevant complimentary work. first large literature single agent linear bandits more less complicated bandit problem settings. already work distributed approaches multi-agent multi-armed bandits least kempe dobra gehrke gossip-based computation aggregate information. proc. annual ieee symposium foundations computer science ieee computer society lihong langford john schapire robert contextual-bandit approach personalized news article recommendation. proceedings international conference world wide shuai hee-cheol. medicine rating prediction recommendation mobile social networks. proceedings international conference grid pervasive computing sz¨or´enyi bal´azs busa-fekete r´obert heged˝us istv´an orm´andi r´obert jelasity m´ark k´egl bal´azs. gossip-based distributed stochastic bandit algorithms. icml acknowledgments would like thank anonymous reviewers helpful comments. would also like thank gergley useful discussions. thanks support epsrc autonomous intelligent systems project ep/i. thanks support miur qcrihbku amazon research grant tsinghua university. research leading results received funding european research council european union’s seventh framework programme grant agreement shuai geyong hee-cheol stephen yang laurence efﬁcient approach generating location-sensitive recommendations adhoc social network environments. ieee transactions services computing kaufmann emilie korda nathaniel munos r´emi. thompson sampling asymptotically optimal ﬁnitetime analysis. algorithmic learning theory springer first recall agents want communicate information round without central server every agent would need communicate chosen action reward every agent round giving communication cost bits per-round. agent requires od|v bits communicated round. therefore signiﬁcant communication cost reduction gained logd recall also using epoch-based approach reduce per-round communication cost gossip-based approach makes algorithm efﬁcient time horizon requiring proofs regret performance simple modiﬁcations proofs dcb. comparison growing buffers issue number rounds typically large. choose exhibit growing-buffer approach current work. instead relying combination diffusion delay handle potential doubling data points randomised gossip protocol could attempt keep track observations shared agents thus simply stop doubling occurring. however per-round communication complexity least quadratic whereas approach linear. reason former order efﬁcient agent sending information agent needs know latest observations gathered agent agent already knows about. communication cost order since every agent shares information somebody round gives round communication complexity order network. simple alternative approach gossip protocol round-robin protocol agent passes information gathered previous rounds next agent pre-deﬁned permutation. implementing protocol leads agents performing distributed version cb-instsharing algorithm delay size least linear rather logarithmic dependence quantity gossip protocol achieves. indeed time agent lacking observations. using observation cumulative regret bound achieved using proposition arrives asymptotic dependence gossip protocol additive constant worse multiplicative factor makes difference performance network large. moreover protocols offer simple generalisability robustness gossip protocols offer. note pruning protocol dccb requires sharing estimated θ-vectors agents adds communication cost algorithm. hence per-round communication cost dccb remains od|v figure table gives summary theoretical results multi-agent linear bandit problem. note sharing cannot beneﬁt fact agents solving bandit problem instant sharing large communicationcost dependency size network. succesfully achieves near-optimal regret performance simultaneously reducing communication complexity order magnitude size network. moreover dccb generalises regret performance extra cost order communication complexity. conditioned values weights statement proposition follows substituting appropriate quantities above taking probability distribution subgaussian random rewards. however since statement holds uniformly values weights holds also probability taken distribution weights. cthresh hold assumptions theorem probability agent cluster suppose hold. know time moreover since sharing protocol chooses agent uniformly random independently history time follows time upper bounded constant probability follows exists constant event holds probability step consider properties weights clustering. event know cluster performing algorithm within cluster therefore would like directly apply analysis proof theorem point. order need show weights properties time required proof theorem lemma suppose agent cluster then event ﬁnal property weights required prove theorem variance diminishing geometrically iteration. analysis provided lemma using lemma prove result weights time lemma suppose agent cluster then event step apply results analysis dcb. apply argument theorem bound regret time regret time simply upper bound k|cθ. include modiﬁed sections bellow needed. proof lemma recall whenever pruning procedure cuts edge agents reset buffers local information scaled size current neighbour sets. furthermore according pruning procedure agent share information another agent local neighbour set. event time agent time agent resets information local information local neighbour becomes local cluster i.e. time agent share information agents also local neighbour local cluster. proves statement part", "year": 2016}