{"title": "A Theoretical Analysis of Deep Neural Networks for Texture  Classification", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "We investigate the use of Deep Neural Networks for the classification of image datasets where texture features are important for generating class-conditional discriminative representations. To this end, we first derive the size of the feature space for some standard textural features extracted from the input dataset and then use the theory of Vapnik-Chervonenkis dimension to show that hand-crafted feature extraction creates low-dimensional representations which help in reducing the overall excess error rate. As a corollary to this analysis, we derive for the first time upper bounds on the VC dimension of Convolutional Neural Network as well as Dropout and Dropconnect networks and the relation between excess error rate of Dropout and Dropconnect networks. The concept of intrinsic dimension is used to validate the intuition that texture-based datasets are inherently higher dimensional as compared to handwritten digits or other object recognition datasets and hence more difficult to be shattered by neural networks. We then derive the mean distance from the centroid to the nearest and farthest sampling points in an n-dimensional manifold and show that the Relative Contrast of the sample data vanishes as dimensionality of the underlying vector space tends to infinity.", "text": "investigate deep neural networks classiﬁcation image datasets texture features important generating class-conditional discriminative representations. ﬁrst derive size feature space standard textural features extracted input dataset theory vapnik-chervonenkis dimension show hand-crafted feature extraction creates low-dimensional representations help reducing overall excess error rate. corollary analysis derive ﬁrst time upper bounds dimension convolutional neural network well dropout dropconnect networks relation excess error rate dropout dropconnect networks. concept intrinsic dimension used validate intuition texture-based datasets inherently higher dimensional compared handwritten digits object recognition datasets hence diﬃcult shattered neural networks. derive mean distance centroid nearest farthest sampling points n-dimensional manifold show relative contrast sample data vanishes dimensionality underlying vector space tends inﬁnity. texture recipe various object recognition tasks involve texture-based imagery data like brodatz vistex drexel uiuctex well forest species datasets texture characterization also shown useful addressing object categorization problems like brazilian forensic letter database later converted textural representation similar approach used textural representation latin music dataset last decade deep neural networks gained popularity ability learn data representations supervised unsupervised settings generalize unseen data samples using hierarchical representations. notable contribution deep learning deep belief network formed stacking restricted boltzmann machines another closely related approach gained much traction last decade convolutional neural network cnn’s shown outperform classical object recognition tasks like mnist cifar despite advances ﬁeld deep learning limited success learning textural features using deep neural networks. mean inherent limitation existing neural network architectures learning algorithms? paper answer question investigating deep neural networks classiﬁcation texture datasets. first derive size feature space standard textural features extracted input dataset. theory vapnikchervonenkis dimension show hand-crafted feature extraction creates low-dimensional representations help reducing overall excess error rate. corollary analysis derive ﬁrst time upper bounds dimension convolutional neural network well dropout dropconnect networks relation excess error rate dropout dropconnect networks. concept intrinsic dimension used validate intuition texture-based datasets inherently higher dimensional manifold compared handwritten digits object recognition datasets hence diﬃcult classiﬁed/shattered neural networks. highlight issues associated curse dimensionality texture datasets provide theoretical results mean distance centroid nearest farthest sampling points n-dimensional manifolds show relative contrast sample data vanishes dimensionality underlying vector space tends inﬁnity. theoretical results empirical analysis show order classify texture datasets using deep neural networks need either integrate handcrafted features devise novel neural architectures learn features input dataset resemble dimension ﬁrst proposed later applied neural networks noted dimension proposed neural networks also applicable deep neural networks. shown neural nets sigmoidal activation function vc-dimension loosely upper-bounded number free parameters network. given classiﬁcation model vc-dimension maximum number samples shattered estimate size sample space composed various features extracted textural co-occurrence matrices following proposed theory dimension show texture feature extraction creates dimensional representations help reducing overall excess error rate. sake simplicity consider intensity image single channel gray-level co-occurrence matrix easily extended multi-channel images color co-occurrence matrices without loss generality. features also shown useful descriptors proposition seen general case number distinct haralick features given deep neural networks dimension upper bounded according pick number adjustable parameters possible distinct values glcm based feature vectors much lower dimension network. eﬀectively argue vc-dimension deep neural network adjustable parameters shatter metrics formed using glcm prerequisite select network number adjustable parameters upper bound input data dimensionality number distinct gray levels color channel. hand order shatter image vectors eﬀective dimension network least order glcm based features need neural networks smaller dimension compared vectors. also next section show increase dimension network excess error rate increases. composite learning model formed integration glcm based features deep neural networks lower excess error rate compared deep neural networks combined image pixels. section derive relation input data dimensionality upper bound excess error rate deep neural network. validates fact lower dimensional representations haralick feature space help minimizing test error rate. corollary analysis derive ﬁrst time upper bounds dimension convolutional neural network well dropout dropconnect networks show upper bound excess error rate dropout networks lower dropconnect. number cells dimension gives number divisions model space along dimension approximated c/d. turn equal number class labels therefore given classiﬁcation problem class labels have hence proof. statement follows dimension bounds deep neural network deep convolutional neural network dimension deep neural network upper bounded dimension convolutional neural network upper parameterized class arithmetic operations exponential operation jumps based evaluations real numbers output vcdim here number operations dimensionality adjustable parameter space. input size kernel size sampling factor assume convolution argue object recognition datasets much lower dimensional manifold texture datasets. hence even deep neural networks effectively shatter feature space object recognition datasets dimensionality texture datasets without explicit texture-feature extraction networks cannot shatter them. order estimate dimensionality datasets concept intrinsic dimension. intrinsic dimension dataset represents minimum number variables required represent data. maximum likelihood algorithm proposed estimate intrinsic dimension table intrinsic dimensionality texture datasets much higher object recognition datasets without explicit texture-feature extraction deep neural network cannot shatter texture datasets intrinsically high dimensionality. however seen table features extracted texture datasets much lower intrinsic dimensionality much lower dimensional manifold vectors hence shattered/classiﬁed even networks relatively smaller architectures. once validated fact texture-based datasets higher dimensional manifold compared handwritten digit object recognition datasets highlight issues associated high dimensionality texture datasets. curse dimensionality refers phenomenon classiﬁcation power model decreases increase dimensionality input feature space. following sections derive theoretical results curse dimensionality high-dimensional texture data. mean distance centroid nearest sampling point useful metric quantifying hardness classiﬁcation compute mean distance ﬁrst state result computing expected value non-negative random variable compute mean distance centroid nearest sample point. median distance computed however accurate estimate distance metrics compute mean paper. lemma consider samples distributed uniformly p-dimensional hypersphere radius center origin consider nearest neighbor estimate mean distance origin proof. ball radius volume given ωprp denoted probability point sampled uniformly unit ball lying within distance origin ratio volume ball volume unit ball. common factors cancel cumulative distribution function probability density function andf pxp− table shows mean distance origin nearest sampling point various datasets. table according data points texture datasets nearer feature space boundary data point. makes prediction particularly diﬃcult datasets cannot interpolate data points need extrapolate. next propose result expected distance origin farthest data point derive relation relative contrast data points underlying dimensionality vector space highlighted section lemma consider samples distributed uniformly p-dimensional hypersphere radius center origin consider nearest neighbor estimate mean distance origin farthest shown dimensionality increases distance nearest neighbor approaches farthest neighbor i.e. contrast between points vanishes while shown relative contrast varies sample points dimensionality paper generalize case data points also provide exact estimate relative contrast instead providing approximation bounds also eliminate arbitrary constant used vary signiﬁcantly change parameters resulting ﬂuctuating bound. noted assume norm distance metric euclidean space deriving algebra. validate theory error rate networks haralick features lower vectors performed experiments benchmark texture classiﬁcation datasets brodatz vistex drexel kth-tips kthtips uiuctex. extracted features based glcm metrics presented section without loss generality select image size number color levels also datasets multiple color channels converted grayscale. deep neural networks trained stacking restricted boltzmann machines denoising autoencoders models discriminatively note extract sliding window blocks various texture datasets ﬁne-tuned supervised backpropagation. figures show ﬁnal test error backpropagation algorithm labeled test data using sdae unsupervised pre-training. table shows ﬁnal test error various texture datasets using cnn. conlearning rate initially decreased inverse power gamma parameter authors proposed architecture texture classiﬁcation. however paper focus architecture proposed maintain uniformity theoretical analysis. comparing results figure table texture datasets haralick feature based networks outperform networks based pixels. experiments substantiate theoretical claim extraction haralick features create low-dimensional representations enable deep neural networks achieve lower test error rate. figure test error texture datasets haralick features stacked restricted boltzmann machines norm regularization dropout dropconnect obtained varying number adjustable parameters. figure test error texture datasets haralick features stacked denoising autoencoders norm regularization dropout dropconnect obtained varying number adjustable parameters. deep neural networks texture recognition seen signiﬁcant impediment lack thorough understanding limitations existing neural architectures. paper provide theoretical bounds deep neural networks texture classiﬁcation. first using theory vc-dimension establish relevance handcrafted feature extraction. corollary analysis derive ﬁrst time upper bounds dimension well dropout dropconnect networks relation excess error rates. concept intrinsic dimension show texture datasets higher dimensionality color/shape based data. finally derive important result relative contrast generalizes proposed theoretical empirical analysis conclude texture data need redesign neural architectures devise learning algorithms learn glcm haralick-like features input data. research supported nasa carbon monitoring system grant nnhzda-n-cms cooperative agreement number nasannxada cfda number project identiﬁed ames research center cooperative research earth science technology opinions ﬁndings conclusions recommendations expressed material authors necessarily reﬂect nasa united states government.", "year": 2016}