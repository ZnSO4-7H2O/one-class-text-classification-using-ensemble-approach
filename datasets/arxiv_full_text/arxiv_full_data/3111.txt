{"title": "Compact Relaxations for MAP Inference in Pairwise MRFs with Piecewise  Linear Priors", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Label assignment problems with large state spaces are important tasks especially in computer vision. Often the pairwise interaction (or smoothness prior) between labels assigned at adjacent nodes (or pixels) can be described as a function of the label difference. Exact inference in such labeling tasks is still difficult, and therefore approximate inference methods based on a linear programming (LP) relaxation are commonly used in practice. In this work we study how compact linear programs can be constructed for general piecwise linear smoothness priors. The number of unknowns is O(LK) per pairwise clique in terms of the state space size $L$ and the number of linear segments K. This compares to an O(L^2) size complexity of the standard LP relaxation if the piecewise linear structure is ignored. Our compact construction and the standard LP relaxation are equivalent and lead to the same (approximate) label assignment.", "text": "label assignment problems large state spaces important tasks especially computer vision. often pairwise interaction labels assigned adjacent nodes described function label diﬀerence. exact inference labeling tasks still diﬃcult therefore approximate inference methods based linear programming relaxation commonly used practice. work study compact linear programs constructed general piecwise linear smoothness priors. number unknowns pairwise clique terms state space size number linear segments compares size complexity standard relaxation piecewise linear structure ignored. compact construction standard relaxation equivalent lead label assignment. determining maximum a-posteriori solution graphical models discrete states equivalently ﬁnding minimizer corresponding energy fundamental tools machine learning computer vision. work focus problems pairwise cliques graphical model. following terms pairwise potential prior synonymously. since exact inference graphical models generally tractable research focused tractable high-quality approximate inference algorithms linear programming relaxation discrete inference tasks received much attention. cases relaxation solves inference problem exactly i.e. relaxation tight certain problem classes. speciﬁc structure resulting linear program generic methods solve linear programs ineﬃcient therefore many specialized algorithms minimizer proposed literature. since primal linear program estimation pairwise problems quadratic number unknowns terms state space size dual program linear number unknowns appealing. belief propagation inspired message passing methods optimize dual program block-coordinate schedule block-coordinate methods applied non-smooth strictly concave problem approaches iteratively increase dual objective guaranteed global maximizer problem. well known literature validate occasional early stopping behavior experimental section. supergradient methods appropriate stepsize rule guaranteed converge maximizer therefore prohibitively expensive large state spaces. variable smoothing methods non-smooth problems convergence rate require unknowns applied dual problem practice show slow convergence experience natural question whether size primal program reduced pairwise potentials arbitrary useful structure. particular pairwise potentials l-norm label diﬀerences truncated priors answer aﬃrmative. generalize particular results pairwise potentials piecewise linear terms label diﬀerence. many computer vision related inference problems state space numeric values employed smoothness prior naturally based label value diﬀerences. potentials addressed work illustrated fig. show pairwise potentials reformulate primal linear programs order reduce number primal variables number linear pieces deﬁning pairwise potential. number dual unknowns increases meaning overall problem size. speciﬁcally consider pairwise potentials written pointwise minimum convex ones. since construction reformulation correspondence minimizers original ones reduced program. thus construction weaken relaxation inference. manuscript organized follows introducing relevant notations brieﬂy reviewing approximate inference section state main result section corresponding proof constructive main ingredients presented sections respectively. since underlying techniques useful right provide material separate sections. section discuss extensions proposed reformulations enable isotropic behavior solutions relevant image processing applications. section experimentally verify message passing methods stop early demonstrate approach image denoising experiment. domain considered label assignment task graph node edge computer vision image processing applications node typically regular pixel grid induced e.g. -connected -connected neighborhood structure. respectively. convention denote nodes indicate states also sets elements seen discrete probability densities denote corresponding extend indices integral also interpreted superlevel function main occur frequently notations write constraint extended valued function i.e. otherwise. convex function denote convex conjugate l.s.c. extension perspective deﬁned throughout manuscript assume recession function ı{}). achieved adding redundant bounds constraints since unknowns convex problems usually restricted section make following fact unary pairwise potentials respectively. local nature modeled interactions means label assignment problem instance markov random field note respect inference conditional random ﬁelds completely equivalent mrfs term includes crfs proper mrfs. work focus problems pairwise interactions labels. general labeling problems diﬃcult solve exactly np-hardness many instances. tractable approximation elabeling obtained lifting problem higher dimensional setting introduced denote soft one-hot encodings labels assigned node result obtains following linear programming relaxation enabling tractable approximate inference number unknowns make inference many labels costly. certain pairwise potentials number unknowns reduced e.g. potentials work show number primal unknowns reduced piecewise linear potentials consisting segments. section state main result generically shows piecewise linear pairwise potentials allow compact reformulation elp-mrf section sketch proof since based general constructions described detail sections theorem pairwise potential piecewise linear function respect consisting segments breakpoints integral values exists reformulation requires primal unknowns linear constraints edge graph. allow compact reformulation using primal unknowns constraints section shown minimum potentials leads combined reformulation unknowns constraints remark counting constraints corresponds number dual variables needs introduce order obtain convenient saddle-point formulation suitable straightforward optimization e.g. primal-dual method therefore need introduce dual variables whenever closed-form proximal steps available. particular include simple bounds constraints counting constraints always introduce enough dual variables avoid non-trivial proximal steps. remark want emphasis rewriting piecewise linear potentials minimum bounded linear functions also allows eﬃcient updates message passing algorithms eﬃcient methods addressing quadratic regularization already presented easily generalize result assume pairwise potentials written minimum simple convex potentials lower envelope computation instance min-ﬁlter problem solved time interestingly easily implementable online algorithm min-ﬁltering proposed clearly resembles lower envelope algorithm quadratic costs construction diﬀerent ishikawa’s graph approach solving mrfs convex symmetric priors seen generalization earlier construction main beneﬁts proposed construction summarized follows ﬁrst intuitive understand; second naturally allows asymmetric convex potentials; ﬁnally immediately enables extensions isotropic regularizers relevant image processing applications. weighted graph. node graph source sink respectively. edge contains inﬁnity links absorbed unary potentials graph construction thus focus ﬁrst expression below. assumption integral breakpoints without loss generality. corresponds one-sided regularizer solved adding lateral directed edges graph temporarily reinterpret label value obtain asymmetric l-type smoothness prior label directed encodes whether node sink note explicitly state contribution linear part unaries. order keep equations simple introduce convention out-of-bounds values subject observe edge enforces l+kl constraints inequality constraint). course extra unknowns constraints discarded immediately applying e.g. constraint stated important section overall depending values optimization ecvx-lp potentially requires less memory optimizing generic relaxation elp-mrf particular section show minimum compactly representable pairwise potentials leads compact representation corresponding linear program. applies e.g. pairwise potentials minimum l-type pairwise priors well-known l-type priors lead linear programs unknowns edge apply result previous section). corollary construction presented following minimum l-type priors requires primal unknowns without loosening convex relaxation compared elp-mrf. call pointwise minimum pairwise elementary potentials min-potential following. order show equivalence compact linear program min-potentials ones discussed section substitute elementary potentials corresponding compact reformulation. section equivalence resulting reformulation shown relevant examples provided. following derivations make repeated lemma allows rewrite minimum convex functions convex minimization problem general. application lemma terms representing elementary potentials order obtain min-potentials leads non-convex bilinear constraints shown below. following lemma states general setting bilinear constraints induced application lemma linearized without aﬀecting minimum. following repeatedly apply lemma obtain compact convex reformulations min-potentials. node variables involved pairwise potentials marginalization constraints attain role lemma. since node variables subject optimization well lemma important replace occuring bilinear constraints linear ones. expressions plugged edge-speciﬁc unknowns etc. augmented respective edge subscript obtains energy given specialize express terms constraints resulting program. practical implementations beneﬁcial implement specializations emin-prior rather emin-linear. instance smoothness prior minimum l-type potentials generic implementation based emin-cvx requires twice number unknowns constraints speciﬁc formulation emin-l derived emin-prior restricted exposition labeling tasks underlying discrete domains. cases continuously inspired label assignment formulations assume solver directly cope case e.g. proximal methods-based implepreferable image processing computer vision problems reduced metrication artifacts. pointed ﬁnite diﬀerence discretization continuous formulations closely related standard relaxations inference elp-mrf nutstxij elp-mrf) nonlinear euclidean-norm based terms order achieve better counting grid-aligned discontinuities. follow existing literature forward diﬀerence stencil following. expect slightly improved visual results discretization image plane based e.g. staggered grid uses discrete calculus formulation ﬁnite diﬀerence setting image domain represented regular grid horizontal vertical edges pixels. index horizontal edges subscripts vertical ones thus e.g. variables st→s depending whether horizontal vertical edge. notational simplicity assume homogeneous symmetric pairwise potentials following simplest isotropic extension shown replaces separate l-type counting horizontal vertical discontinuities e.g. terms choice isotropic extension reduces approaches presented literature isotropic potentials potts smoothness prior truncated priors construction described image domains obviously extended higher dimensional image domains. remark order reduce metrication artifacts min-potentials options ﬁrst option convert anisotropic formulation e.g. behave less anisotropic. approach presented above. option isotropic formulations elementary potentials subsequently apply construction described section obtain minimum potential. focus minimum l-type potentials employ standard forward-diﬀerence discretization underlying elementary potential given leads convex program observed resulting constraints formulation e.g. elementary potential needs selected horizontal vertical direction. further constants counted diﬀerently eisotr. min-l-b. currently prefer eisotr. min-l since reduces potts truncated models presented literature deeper analysis subject future research. unless otherwise noted straightforward openmp-parallelized implementation ﬁrst order primal-dual method described minimizers respective convex program. proximal methods algorithm leaves freedom convex problem splitted employed splitting often signiﬁcant impact convergence behavior. general eliminate objective introduce lagrange multipliers remaining constraints. also introduce bounds-constrained dual variables terms ﬁrst experiment verify claim early stopping occur frequently dual block coordinate methods inference mplp follow setup similar experiment described replace -label spin glass model considered problem instances many labels piecewise linear smoothness priors. setup follows used. solve random instances using mplp compare energy globally optimal obtained minimizing elp-mrf using primal-dual algorithm. problem instances mplp stops early energy diﬀerence recent developments accelerated gradient methods appear appealing order optimize non-smooth dual program e.g. elp-mrf method proposed guarantees convergence rate iteration count requires tuning parameter. fig. illustrated parameter chosen carefully achieve competitive performance. conclusion variable smoothing methods cannot replace compact reformulations proposed previous sections. realistic application compare memory requirements evolution energies. compact reformulation emin-l smaller problem size elp-mrf clear whether complicated problem structure lead slower convergence. chose simple image denoising application demonstration. piecewise linear approximation depicted fig. gradient statistic natural images unary potential induced directly image corruption procedure follows random containing percent pixels considered outliers clean intensity values replaced uniform random value remaining figure energy evolution label denoising problem utilizing compact potential three pieces. preconditioned primal dual algorithm outperforms variable smoothing algorithm diﬀerent tuning parameters discretize continuous state space labels. memory used minimize elp-mrf problem almost optimizing emin-l requires memory. hence latter formulations graphics memory therefore leverage gpus acceleration. evolution objective displayed fig. primal dual unknowns initialized explain initial increase objective value. compact reformulations emin-l /eisotr. min-l clear advantage exhaustive model elp-mrf. continuous approach described addresses labeling problems convex smoothness priors arbitrary data ﬁdelity term. shown continuum global solution obtained thresholding minimizer underlying convex relaxation. result general hold discretizing continuous functional. interesting example convex smoothness prior considered choose figs. depict result discretized model label space discretized states figs. display result specialized lipschitz terms psnr result much closer true minimizer preserves image details. small experiment indicates often care required working discretized problems continuous labeling functionals. show pairwise potentials written piecewise linear functions terms respective label diﬀerence allow compact reformulations relaxation inference. reformulations weaken relaxation modify returned minimizer. resulting savings memory consumption signiﬁcant many-label problems. construction also extends formulations aiming reduce grid bias often used image processing.", "year": 2013}