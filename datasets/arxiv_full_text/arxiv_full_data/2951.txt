{"title": "Tracking using explanation-based modeling", "tag": ["cs.LG", "cs.AI", "cs.CV"], "abstract": "We study the tracking problem, namely, estimating the hidden state of an object over time, from unreliable and noisy measurements. The standard framework for the tracking problem is the generative framework, which is the basis of solutions such as the Bayesian algorithm and its approximation, the particle filters. However, the problem with these solutions is that they are very sensitive to model mismatches. In this paper, motivated by online learning, we introduce a new framework -- an {\\em explanatory} framework -- for tracking. We provide an efficient tracking algorithm for this framework. We provide experimental results comparing our algorithm to the Bayesian algorithm on simulated data. Our experiments show that when there are slight model mismatches, our algorithm vastly outperforms the Bayesian algorithm.", "text": "study tracking problem namely estimating hidden state object time unreliable noisy measurements. standard framework tracking problem generative framework basis solutions bayesian algorithm approximation particle ﬁlters. however problem solutions sensitive model mismatches. paper motivated online learning introduce framework explanatory framework tracking. provide efﬁcient tracking algorithm framework. provide experimental results comparing algorithm bayesian algorithm simulated data. experiments show slight model mismatches algorithm vastly outperforms bayesian algorithm. study tracking problem numerous applications control ﬁnance. tracking given noisy measurements time problem estimate hidden state object. challenge reliably combining measurements multiple time steps prior knowledge state dynamics goal tracking produce estimates close true states possible. popular solutions tracking problem kalman ﬁlter particle ﬁlter numerous extensions variations based generative framework tracking problem. suppose want track state object time given measurement vectors times generative approach think state measurements random variables. represent knowledge regarding dynamics states using transition process pr|x) knowledge regarding relationship states observations measurement process pr|x). then given observations goal tracking estimate hidden state sequence done calculating likelihood state sequence using estimate either sequence highest posterior probability expected value state respect posterior distribution practice uses particle ﬁlters approximation bayesian algorithm. problem generative framework practice difﬁcult precisely determine distributions measurements. moreover bayesian algorithm sensitive model mismatches using model slightly different model generating measurements lead large divergence estimated states true states. address this introduce online-learning-based framework tracking. framework called explanatory framework given state sequences paths state space; instead assuming observations generated measurement model path think path mechanism explaining observations. emphasize done regardless observations generated. suppose path proposed explanation observations measure quality explanatory path using predeﬁned loss function depends measurements tracking algorithm selects explanatory path taking weighted average best explanatory paths according past observations. theoretical guarantee provide loss explanatory path generated online tracking algorithm close explanatory path minimum loss; here loss measured according loss function supplied algorithm. guarantees analogous competitive analysis used online learning important note guarantees hold uniformly sequence observations regardless probabilistic assumptions. next contribution provide online-learning-based algorithm tracking explanatory framework. algorithm based normalhedge general online learning algorithm. normalhedge instantiated loss function. supplied bounded loss function guaranteed produce path loss close path minimum loss candidate paths. inefﬁcient directly apply normalhedge tracking derive sequential monte carlo approximation normalhedge show approximation efﬁcient. demonstrate robustness tracking algorithm perform simulations simple onedimensional tracking problem. evaluate tracking performance measuring average distance states estimated algorithms true hidden states. instantiate algorithm simple clipping loss function. simulations show algorithm consistently outperforms bayesian algorithm high measurement noise wide range levels model mismatch. note bayesian algorithm also interpreted explanatory framework. particular loss path negative log-likelihood measurement model then bayesian algorithm shown produce path log-loss close path minimum log-loss. tempted think tracking solution follows approach; however point paper loss functions different log-loss particular show scenario using loss functions produces better tracking performance bayesian algorithm rest paper organized follows. section explain detail explanatory model tracking. section present normalhedge tracking algorithm based. section provide tracking algorithm. section presents experimental comparison algorithm bayesian algorithm. finally discuss related work section detailed bounds proofs normalhedge provided supplementary material. feel algorithm normalhedge general interest hence details normalhedge submitted nips companion paper. section describe detail setup tracking problem explanatory framework tracking. tracking time given input measurements goal estimate hidden state object using measurements prior knowledge state dynamics. explanatory framework given paths state space time assign path loss function loss function parts dynamics loss observation loss dynamics loss captures knowledge state dynamics. simplicity dynamics loss written path words dynamics loss time depends states time common express knowledge dynamics terms dynamics function deﬁned paths small dynamics loss. example consider object moving constant velocity. here state position velocity would interested paths cases dynamics loss typically growing function distance second component loss function observation loss given path measurements observation loss function quantiﬁes well path explains measurements. again simplicity restrict loss functions written words observation loss path time depends state time measurements time total loss path dynamics observation losses. note loss path depends particular path measurements true hidden state. result loss path always evaluated algorithm given time. algorithmic framework consider model analogous motivated decisionp theoretic framework online learning time algorithm assigns weight path estimated state time weighted mean states weight state total weight paths state. loss algorithm time weighted loss paths theoretical guarantee look loss algorithm close loss best path hindsight thus small fraction paths loss loss functions successfully capture tracking performance then sequence states estimated algorithm good tracking performance. problem decision-theoretic online learning follows. round learner access actions; purposes action method provides prediction round. learner maintains distribution action time time period witit. notice framework general assumption made nature actions distribution losses. goal learner maintain distribution actions cumulative loss time compared cumulative loss action lowest cumulative loss. cases particularly number experts large interested acheiving cumulative loss compared \u0001-quantile actions. here \u0001-quantile actions fraction actions lowest cumulative loss. starting seminal work littlestone warmuth problem decision-theoretic online learning well-studied literature common algorithm problem hedge exponential weights assigns action weight exponentially small total loss. paper however consider different algorithm normalhedge problem algorithm forms basis tracking algorithm. bayesian averaging algorithm shown variant hedge loss function log-loss case normalhedge different algorithm. signiﬁcant advantage using normalhedge parameters tune acheives performance comparable best performance previous online learning algorithms optimally tuned parameters. normalhedge algorithm action time denote normalhedge weight assigned action time time deﬁne regret algorithm action difference cumulative loss algorithm cumulative loss action. also real number notation denote max. normalhedge algorithm presented below. performance guarantees normalhedge algorithm shown stated follows. theorem normalhedge access actions loss sequences ln+ln regret algorithm \u0001-quantile actions ot−tit. using discounted losses common reinforcement learning intuitively makes tracking algorithm ﬂexible allows easily recover past mistakes. however direct application normalhedge prohibitively expensive terms computation cost. therefore sequel show derive sequential monte-carlo based approximation normalhedge approximation experiments. observation behind approximation weights actions generated normalhedge algorithm induce distribution states time therefore random sample states round approximate distribution. thus particle ﬁlters approximate posterior density states induced bayesian algorithm tracking algorithm approximates density induced states normalhedge tracking. main difference normalhedge tracking algorithm normalhedge always maintains weights actions delete action action list weight falls replace action resampling procedure chooses another action currently region state space actions losses. thus spend resources maintaining updating weights actions perform well. another difference normalhedge tracking algorithm approximation explicitly impose dynamics loss actions. instead resampling procedure considers actions dynamics loss. also avoids spending resources actions high dynamics loss anyway. tracking algorithm speciﬁed algorithm action algorithm path state space however maintain entire path explicitly action; rather step algorithm computes xit+ using dynamics function need maintain current state action. recall applying dynamics function ensure path incurs little dynamics loss start actions initially positioned states uniformly distributed uniform weighting actions. round like normalhedge action incurs loss determined current state tracker incurs expected loss determined current weighting actions. using losses update cumulative regrets action. however unlike normalhedge delete actions zero negative regret replace using resampling procedure. procedure replaces poorly performing actions actions currently high density regions thereby providing better approximation intended weights. resampling procedure explained detail algorithm main idea sample regions state space high weight. done sampling action proportional weight previous round. choose state randomly ellipsoid around current state selected action; action inherits history selected action current state different selected action. latter step makes state distribution smoother previous round supported states actions losses. note resampling procedure samples actions dynamics simulations consider task tracking object simple one-dimensional state space. evaluate algorithm measure distance estimated states true states object. experimental setup inspired application tracking faces videos using standard face detector case state location face measurement corresponds score output face detector region current video frame. goal predict location face across several video frames using scores produced detector. detector typically returns high scores several regions around true location face also erroneously produce high scores elsewhere. though cases detection score probabilistic interpretation often difﬁcult accurately characterize distribution noise. precise setup simulations follows. object tracked remains stationary moves velocity interval measurements correspond -dimensional vector true state position locations grid generated additive noise process parameter represents noisy measurements relative signal parameter represents fraction outliers. experiments vary total number time steps track generative framework dynamics object represented transition model observations represented measurement process thus observations generated according measurement process supplied generative framework; fraction observations outliers. explanatory framework expected state dynamics function identity function observation loss path time given table experimental results. root-mean-squared-errors predicted positions time steps algorithm bayesian algorithm particle ﬁlter reported values averages standard deviations simulations. min) clips measurements range observation loss respect negative thresholded measurement values interval width around given observation vectors three different methods estimate true underlying state sequence ﬁrst bayesian algorithm recursively applies bayes’ rule update posterior distribution using transition observation model. posterior distribution maintained location discretization bayesian algorithm actual value used generate observations value obtained tuning measurement vectors generated true state sequence independently generated noise values. prior distribution states assigns probability true value zero elsewhere. second algorithm algorithm described section algorithm parameters parameters also obtained tuning range values also compare algorithm particle ﬁlter uses parameters bayesian algorithm predicts using expected state posterior distribution. algorithm actions particle ﬁlter particles. experiments implementation particle ﬁlter figure shows true state states predicted algorithm bayesian algorithm different values independent simulations. table summarizes performance algorithms different values parameter different values noise parameter report average standard deviation rmse true state predicted state. rmse computed state predictions single simulation rmse values averaged independent simulations. experiments show bayesian algorithm performs well supplied correct noise model; however performance degrades rapidly increases becomes poor even hand performance algorithm suffer appreciably increases. degradation performance bayesian algorithm even pronounced noise high respect signal particle ﬁlter suffers even higher degradation performance poor performance even results indicate bayesian algorithm sensitive model mismatches. hand algorithm equipped clipped-loss function extremely robust model mismatches. particular algorithm provides rmse value even high noise high additional experiments algorithm included supplementary appendix; illustrate performance algorithm varies parameters tabulates performance algorithm higher values figure predicted paths simulations. first column noise second column high noise blue lines correspond algorithm lines correspond bayesian algorithm dashed black line represents true states. generative approach tracking roots control estimation theory starting seminal work kalman popular generative method used tracking particle ﬁlter numerous variants. literature vast many exciting developments recent years refer reader detailed survey results. suboptimality bayesian algorithm model mismatch investigated contexts classiﬁcation view bayesian algorithm online learning algorithm log-loss well-known various communities including information theory computational learning theory work look beyond bayesian algorithm log-loss consider loss functions algorithms appropriate task. paper introduce explanatory framework tracking based online learning broadens space designing algorithms need conform standard bayesian approach tracking. propose algorithm tracking framework deviates signiﬁcantly bayesian approach. experimental results show algorithm signiﬁcantly outperforms bayesian algorithm even observations generated distribution deviating slightly model supplied bayesian algorithm. work reveals interesting connection decision theoretic online learning bayesian ﬁltering. cesa-bianchi lugosi. prediction learning games. cambridge university press freund schapire. decision-theoretic generalization on-line learning application freitas. matlab codes particle ﬁltering www.cs.ubc.ca/˜nando/software/upf demos.tar.gz. klaas freitas doucet. toward practical monte carlo marginal particle ﬁlter. peter gr¨unwald. minimum description length principle. press yoav freund. predicting binary sequence almost well optimal biased coin. colt pages sham kakade andrew online bounds bayesian algorithms. nips herbster warmuth. tracking best expert. machine learning koolen rooij. combining expert advice efﬁciently. colt", "year": 2009}