{"title": "Experimental Comparison of Classification Uncertainty for Randomised and  Bayesian Decision Tree Ensembles", "tag": ["cs.AI", "cs.LG"], "abstract": "In this paper we experimentally compare the classification uncertainty of the randomised Decision Tree (DT) ensemble technique and the Bayesian DT technique with a restarting strategy on a synthetic dataset as well as on some datasets commonly used in the machine learning community. For quantitative evaluation of classification uncertainty, we use an Uncertainty Envelope dealing with the class posterior distribution and a given confidence probability. Counting the classifier outcomes, this technique produces feasible evaluations of the classification uncertainty. Using this technique in our experiments, we found that the Bayesian DT technique is superior to the randomised DT ensemble technique.", "text": "abstract. paper experimentally compare classification uncertainty randomised decision tree ensemble technique bayesian technique restarting strategy synthetic dataset well datasets commonly used machine learning community. quantitative evaluation classification uncertainty uncertainty envelope dealing class posterior distribution given confidence probability. counting classifier outcomes technique produces feasible evaluations classification uncertainty. using technique experiments found bayesian technique superior randomised ensemble technique. uncertainty classifiers used safety-critical applications crucial importance. general uncertainty triple trade-off amount data available training classifier diversity classification accuracy interpretability classifiers also produce useful information experts responsible making reliable classification making decisions trees attractive scheme. required diversity classifiers achieved basis approaches ensemble technique averaging technique based bayesian markov chain monte carlo methodology techniques match requirements well revealed promising results applied real-world problems definition consist splitting nodes terminal nodes also known tree leaves. said binary splitting nodes specific question divide data points disjoint subsets called left right branch. terminal node assigns data points falling node class whose points prevalent. within bayesian framework class posterior distribution observed data calculated terminal node paper experimentally compare classification uncertainty randomised ensemble technique bayesian technique restarting strategy synthetic dataset domain problems machine learning repository provide quantitative evaluations classification uncertainty uncertainty envelope dealing class posterior distribution given confidence probability counting classifier outcomes technique produces feasible evaluations classification uncertainty. sections briefly describe randomised bayesian techniques used experiments. section briefly describe uncertainty envelope technique used quantitatively evaluate uncertainty classification techniques. experimental results presented section section concludes paper. performance single improved averaging outputs involved ensemble improvement achieved correctly classify data points misclassified single clearly required diversity classifier outcomes achieved involved ensemble independently induced data. achieve required independence dietterich suggested randomising splits technique best terms information gain partitions node calculated randomly selected uniform probability. class posterior probabilities calculated involved ensemble averaged. pruning factor specified fewest number data points falling terminal nodes affect ensemble performance. however within randomised technique effect insignificant pruning exceed number training examples strongly pruning factor affects average size consequently reasonably. number randomised ensemble dependent classification problem assigned user manner. technique permits user evaluate diversity ensemble comparing performances ensemble best predefined validation data subset. required diversity achieved ensemble outperforms best single involved ensemble. therefore ensemble technique requires n-fold crossvalidation. experiments described section used randomised ensemble technique. domain problems ensembles consist dts. keep size acceptable pruning factor dependent number training examples. particular value problems many training examples; otherwise performance randomised ensembles evaluated folds problem. integral analytically calculated simple cases. moreover part integrand posterior density cannot evaluated except simple cases. however draw values basis mcmc technique approximating integrals perform approximation need generate random samples running markov chain converged stationary distribution. draw samples markov chain calculate predictive posterior density integration models dimension varies mcmc methods permit reversible jumps described hierarchical structures changes nodes located upper levels cause drastic changes location data points lower levels. reason small probability changing accepting located near root node. therefore rjmcmc algorithms tend explore splitting nodes located root node changed. nodes typically contain small numbers data points. consequently value likelihood changed much moves always accepted. result rjmcmc algorithms cannot explore full posterior distribution. space explored extended using restarting strategy chipman suggested idea behind restarting strategy based multiple runs rjmcmc algorithm short intervals burn-in post burn-in. algorithm creates initial random parameters starts exploring tree model space. running short intervals prevents getting stuck particular structure. important however multiple runs allow exploring model space starting different dts. averaging improve performance rjmcmc algorithm. disadvantage course multiple short chains short burn-in runs seldom reach stationary distribution. restarting strategy limit sizes explicitly would done restricting strategy reason restarting strategy seems practical. section strategy comparative experiments. quantitative comparison classification uncertainty done within uncertainty envelope technique described next. consider simple example classifier system consisting classifiers classifiers give conflicting classification. given datum posterior probability case conclude multiple classifier system trained well and/or datum lies class boundaries. datum data point appearing neighbourhood datum classification uncertainty probability misclassification expected data points values differ range pmin easy pmin value close pmin classification uncertainty highest datum misclassified probability assume value probability classifier outcome expected confident probability given datum could misclassified small enough acceptable. given value specify confidence vice versa uncertainty classifier outcomes statistical terms. classification outcome said confidently correct probability misclassification acceptably small additionally confidently correct output specify confidently incorrect output referring case almost classifiers assign datum wrong class i.e. definition evaluation tells classifiers fail manner classify datum happen different reasons example datum could mislabelled corrupted classifiers within predefined scheme cannot properly distinguish data points. remaining cases regarded uncertain classifications. cases classifier outcomes cannot accepted given confidence probability multiple classifier system labels outcomes uncertain. three characteristics confidently correct confidently incorrect uncertain outcomes seem provide good evaluating different types multiple classifier systems data. comparing values characteristics quantitatively evaluate classification uncertainty systems. depending costs types misclassifications real applications specify value confidence probability first conduct experiments synthetic dataset domain problems taken repository. dimensional synthetic dataset generated mixture five gaussians. data points drawn first three gaussians belong class data points remaining gaussians class ripley data classes overlap bayes error data data points drawn mixture form training dataset. another data points drawn mixture form testing data. randomised ensemble bayesian techniques synthetic data. pruning factor equal synthetic data ensemble output quickly converges stabilizes averaging dts. mean size standard deviation folds respectively. averaged classification performance within uncertainty envelope rates confidently correct uncertain confidently incorrect outcomes respectively. widths intervals outcomes respectively. values intervals calculated confidently correct uncertain outcomes large. happens randomised ensemble technique produces mostly uncertain outcomes folds. using restarting strategy bayesian times; time samples taken burn-in post burn-in. probabilities birth death change variable change rule respectively. uniform priors number inputs nodes used resultant average classification performance mean size standard deviation respectively. rates confidently correct uncertain confidently incorrect outcomes respectively. first synthetic data bayesian much shorter randomised ensemble. second randomised ensemble technique cannot provide reliable classifier outcomes. course fold data partition used randomised technique makes additional contribution classification uncertainty. however practically effect disappears domain problems including data points. table lists characteristics domain problems used experiments; train test numbers classes input variables training testing examples respectively. table also provides performances bayesian technique data. incorrect performances randomised technique shown table table shows also classification performance best single selected validation subsets averaged folds. table randomised ensemble technique always outperforms best single dts. comparing randomised bayesian ensembles conclude datasets bayesian shorter times randomised ensembles. ensembles performance image votes vehicle pima datasets. however remaining datasets bayesian technique slightly outperforms randomised ensemble technique. interesting note bayesian ensemble method always makes smaller proportion confidently correct classifications likewise proportion confidently incorrect classifications always higher randomised ensemble. indeed synthetic data randomised ensemble classifiers average make confidently incorrect classifications bayes error rate whereas bayesian ensemble makes confidently incorrect classifications. fact table shows bayesian seldom make confident incorrect classifications though make uncertain classifications. although unrealistic expect confidently incorrect rate approach bayes error rate small datasets results suggest randomised ensemble tends produce over-confident ensembles bayesian ensembles make confident incorrect classifications. hand exemplified ionosphere sonar datasets bayesian ensemble yield accurate classifications majority uncertain. sonar ionosphere data features respectively relatively data points unsurprising sparsity data points high-dimensional datasets leads uncertain classifications. experimentally compared classification uncertainty randomised ensemble technique ensembles sampled bayesian posterior using rjmcmc restarting strategy. ensemble techniques outperform best single similar average classification rates. fewer confidently incorrect classifications made bayesian ensemble. clearly desirable property classifiers safety-critical applications confidently made incorrect classifications fatal.", "year": 2005}