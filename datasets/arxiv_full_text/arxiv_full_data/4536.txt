{"title": "Learning Nonlinear Dynamic Models", "tag": ["cs.AI", "cs.LG"], "abstract": "We present a novel approach for learning nonlinear dynamic models, which leads to a new set of tools capable of solving problems that are otherwise difficult. We provide theory showing this new approach is consistent for models with long range structure, and apply the approach to motion capture and high-dimensional video data, yielding results superior to standard alternatives.", "text": "present novel approach learning nonlinear dynamic models leads tools capable solving problems otherwise diﬃcult. provide theory showing approach consistent models long range structure apply approach motion capture highdimensional video data yielding results superior standard alternatives. notion hidden states appears many nonstationary models world hidden markov models discrete states kalman ﬁlters continuous states. figure shows general dynamic model observation unobserved hidden state system characterized state transition probability state observation probability method predicting future events dynamic model maintain posterior distribution hidden state based observations time posterior updated using formula hidden state based dynamic models wide range applications time series forecasting ﬁnance control robotics video speech processing. detailed dynamic models application examples found clear beneﬁt using hidden state dynamic model information contained observation captured relatively small hidden state yt+. therefore order predict future previous observations state representation yt+. principle contain ﬁnite history length xt−k. although notation considers ﬁrst order dependency incorporates higher order dependency considering representation form standard trick. kalman ﬁlter transition observation functions linear maps. reasonable algorithms learn linear dynamic models. example addition classical approach recently shown global learning certain hidden markov models achieved polynomial time moreover linear models posterior update rule quite simple. therefore model parameters estimated models readily applied prediction. however many real problems system dynamics cannot approximated linearly. problems often necessary incorporate nonlinearity dynamic model. standard approach problem nonlinear probability modeling prior knowledge required deﬁne sensible state representation together parametric forms transition observation probabilities. model parameters learned using probabilistic methods learned model applied prediction purposes necessary maintain posterior using update formula unfortunately nonlinear systems maintaining generally diﬃcult posterior become exponentially complex increases. computational diﬃculty signiﬁcant obstacle applying nonlinear dynamic systems practical problems. traditional approach address computational diﬃculty approximation methods. example particle ﬁltering approach uses ﬁnite number samples represent posterior distribution samples updated observations arrive. another approach maintain mixture gaussians approximate posterior also regarded mixture kalman ﬁlters although exponential number mixture components needed accurately represent posterior practice ﬁxed number mixture components approximate distribution. leads following question even posterior well-approximated computationally tractable approximation family design good approximate inference method guaranteed good quality approximation? complex techniques required design reasonable approximation schemes makes non-trivial apply nonlinear dynamic models many practical problems. paper introduces alternative approach start diﬀerent representation linear dynamic model call suﬃcient posterior representation. shown recover underlying state representation using prediction methods necessarily probabilistic. allows model nonlinear dynamic behaviors many available nonlinear supervised learning algorithms neural networks boosting support vector machines simple uniﬁed fashion. compared traditional approach several distinct advantages require design explicit state representation probability model using prior knowledge. instead representation implicitly embedded representational choice underlying supervised learning algorithm regarded black power learn arbitrary representation. prior knowledge simply encoded input features learning algorithms signiﬁcantly simpliﬁes modeling aspect. require come speciﬁc representation posterior corresponding approximate bayesian inference schemes posterior updates. instead issue addressed incorporating posterior update part learning process. again posterior representation implicitly embedded representational choice underlying supervised learning algorithm. sense scheme learns optimal representation posterior approximation corresponding update rules within representational power underlying supervised algorithm. possible obtain performance guarantees algorithm terms learning performance underlying supervised algorithm. performance latter heavily investigated statistical learning theory literature. results thus applied obtain theoretical results methods learning nonlinear dynamic models. instead starting probability model approach directly attacks problem predicting yt+k based clearly prediction depends posterior distribution therefore solve prediction problem long estimate update posterior distribution. approach assumed posterior approximated family distributions parameterized deterministic parameter depends suﬃcient statistic posterior updating posterior equivalent updating suﬃcient statistic st+. augmented model incorporates suﬃcient statistics shown fig. model integrated leaves model containing therefore dynamics model fig. determined posterior initialization rule posterior update rule moreover prediction system completely determined function observation approach functions deterministic require probability assumption. fully captures correct dynamics underlying probabilistic dynamic model. however removing probability assumption obtain general ﬂexible model. particular required start speciﬁc forms transition model observation model posterior sufﬁcient statistic model required standard approach. instead embed forms models functional approximation forms standard learning algorithms neural networks kernel machines tree ensembles. universal learning machines well studied learning theory literature. approach essentially replaces stochastic hidden state representation actual state deterministic representation posterior sufﬁcient statistic although corresponding representation become complex problem approach know explicit representation. instead complexity incorporated underlying learning algorithm allows take advantage sophisticated modern supervised learning algorithms handle complex functional representations. moreover unlike traditional approach designs speciﬁc form hand derives approximate update rule hand using bayesian inference methods here simply learning come best possible representation update believe approach also robust less sensitive model mis-speciﬁcations non-optimal approximate inference algorithms commonly occur practice. changing standard probabilistic dynamic model fig. suﬃcient posterior representation fig. deﬁne goal learning problem. since removed formulation following shall refer suﬃcient posterior statistic simply state. deﬁnition suﬃcient posterior representation dynamic model given observed sequence {xt} unobserved hidden state {st} characterized state initialization state update state prediction maps figure left panel state deﬁning prediction. training time known. essential goal predict given using bottleneck hidden variables distinct mappings learned middle panel state evolution prediction. training time used predict operator reproduced right panel state projection prediction. training time st−j used predict reproduced .... ⌊log essential idea algorithm bottlenecking approach construct implicit deﬁnition state along state space evolution projection operators answer various natural questions might pose. parts understanding training process. ﬁrst architecture trained second exact method training architecture. note architecture essentially functional rather representational. graphically order recover system dynamics solve distinct kinds prediction problems. understand graphs essential understand arrows represent graphical models. instead depiction information used predict information. distinguish observations hidden state double circles circles respectively make clear observed not. ﬁrst prediction problem solved fig. left panel provides initial deﬁnition state. essentially state that information summarizes ﬁrst observation predicting second observation. compared conventional dynamic model quantity suﬃcient statistic state posterior integrating posterior integrating evolving step intermediate mixture. ambiguity fundamental inessential. second prediction problem state evolution shown fig. middle panel. here state observation predict next state reusing prediction state observation ﬁrst without loss generality notation fig. consider denote alternative interpretation distinguish paper learn probability distribution xt+. understood algorithm applied choices learning diagrams used obtain system dynamics learned system dynamics learn prediction rules function interest. here consider problem predicting xt+k diﬀerent ranges gives state projection operator st+j without observing future sequence learning state projection presented fig. right panel. idea state projection want build predictor observation future. this we’ll chain together several projection operators current state. make system computationally eﬃcient learn ⌊log operators specialized cover diﬀerent timespans. note state evaluation provides eﬃcient learn xt+k based simultaneously multiple combination projection operators. computation issue also learn xt+k based separately training straightforward. training complicated fact samples appear multiple timesteps otherwise straightforward given components. deal multiple timesteps important correctness proof section diﬃcult thing train since alteration cascade multiple timesteps. method chose takes advantage local global information provide fast near-optimal solution. starting timestep conditioning previous learned value. multitask learning initialization prior solutions applied improve convergence here. experiments initialize average parameter values previous timesteps stochastic gradient descent techniques learning. conditional training learn alteration optimizes performance given existing used every time step. since computational performance issue backprop time gradient descent style algorithm. timestep compute change squared loss future observations using chain rule update according negative gradient. iteration update using stochastic mixing according stochastic mixing parameter. precise method stochastic mixing used experiments equivalent applying derivative update probability update probability computational representational improvement searn prove method step alone consistent. steps used force convergence single retaining performance gained step intuition behind step high probability executed once implying need perform well respect learning problem induced rest system improve overall system. approach ﬁrst described conservative policy iteration known time done using using evolve state time interval broken factors corresponding state projection operators applied state resulting prediction st′−. transformed prediction using operator computational requirements depend exact training method used. initialization step training requires examples. training done examples. iterative methods extra factor generally required iteration learning show appropriate assumptions spr-dm model learned inﬁnite sample limit using algorithm. space limitation consider non-agnostic situation spr-dm model exact. functions used learning algorithm contains correct functions. agnostic setting spr-dm model approximately correct analyzed using perturbation techniques although analysis useful fundamental insight identical non-agnostic analysis considered here. consider following constraints spr-dm model. assume model invertible distribution suﬃcient statistic state generates nontrivial limitation state based dynamic models retains ability capture long range dependencies. invertibility natural assumption it’s important understand invertible dynamic systems subset dynamic systems shown following hidden markov model example example hidden markov model invertible suppose observations ﬁrst observation uniform random second given ﬁrst always third ﬁrst. setting valid sequences hidden markov model invertible express sequence. particular suppose state state conditional observation however invertible hidden markov model induce distribution sequences distribution always implying speciﬁcation state impossible lack information. example invertible hidden markov model long range dependencies suppose observations states ﬁrst observation always ﬁrst state uniform random states self-transition according observations according following distribution given observation probability state observations respectively. given observations probability state converges exponentially fast using bayes chernoﬀ bound. examples illustrate intuition behind invertibility. extend concept incorporating look aheads instead taking probability given probability xtt+k given broadens class invertible models. notation invertibility means states induce short range behavior xttk identical sense induce behavior future observations xt+∞. generally speaking non-invertible models cannot eﬃciently learned algorithm suﬃcient information recover states diﬀerent long range dynamics identical behavior short ranges. fact well-known hardness results learning models theoretical analysis hidden markov models. known eﬃcient methods capture non-trivial long-range eﬀects. implies restriction necessary also signiﬁcant limitation comparison known eﬃcient learning algorithms. next prove algorithm recover invertible hidden markov model given suﬃciently powerful prediction inﬁnitely many samples. analogous similar inﬁnite-sample consistency results supervised learning. base case holds assumption prediction problem solved perfectly. inductive case deﬁne assume ˆci. invertibilˆ inductive assumption implies exists that consequently exists ˆci+ ˆbi+ that section present experimental results datasets involve high-dimensional highlystructured sequence data. ﬁrst dataset motion capture data comes graphics motion capture database. second dataset weizmann dataset contains video sequences nine human subjects performing various actions. figure left panel compares average squared test error function prediction horizon three models linear autoregressive models conditioning previous time steps nonlinear model uses -dimensional hidden state. right panel compares nonlinear model -state -state models. average predictor always predicts vector zeros. proceeds minimizing squared loss using stochastic gradient descent. time step parameter updates learning rate used iterations stochastic mixing using gradients obtained backpropagation time. stochastic mixing rate gradually annealed towards zero. experimented various values learning rate various annealing schedules mixing rate results fairly robust variations parameters. experiments conditioning previous time steps predict next. human motion capture data consists sequences joint angles plus body orientation translation. dataset preprocessed invariant isometries contains various walking styles including normal drunk graceful gangly sexy dinosaur chicken strong. split random data training test sequences length training data split random training validation sequences. time step represented vector real-valued numbers. dataset also normalized zero mean scaled single number variance across dimension average equal dimensionality hidden state figure shows average test prediction errors using squared loss prediction horizon ranges nonlinear model compared simple autoregressive linear models operate directly input space. ﬁrst linear model linear- makes predictions ˆxt+k model parameters ridge regression. second model linear- makes predictions conditioning previous time steps. note number model parameters simple autoregressive linear models grows linearly input information. hence faced high-dimensional sequence data learning linear operators directly input space unlikely perform well. interesting observe autoregressive linear models perform quite well terms making shortrange predictions. probably fact locally motion capture data linear. however nonlinear model performs considerably better compared linear models making long-range predictions. figure shows proposed nonlinear model performs considerably better -state hmm’s. hmm’s gaussian distribution observation model. obvious simple model unable cope complex nonlinear dynamics. even state unable generalize. results motion capture dataset show nonlinear model outperform linear models making long-range predictions. section present results weizmann dataset considerably diﬃcult motion capture dataset. figure left panel compares average squared test error three models linear autoregressive models nonlinear model uses -dimensional hidden state. right panel compares nonlinear model -state -state models. nine human subjects performing various actions including waving hand waving hands jumping bending. video sequence preprocessed placing bounding around person performing action. dataset downsampled images hence time step represented vector real-valued numbers. split random data training test sequences length dataset also normalized zero mean variance dimension hidden state figure shows nonlinear model consistently outperforms linear autoregressive models particularly making long-range predictions. interesting observe dataset nonlinear model outperforms autoregressive model even making short-range predictions. paper introduced approach learning nonlinear dynamical systems showed performs well rather hard high-dimensional time series datasets compared standard models hmms linear predictors. believe presented framework opens entirely devices nonlinear dynamic modeling. removes several obstacles traditional approach requires heavy human design allows well-established supervised learning algorithms used automatically nonlinear dynamic models.", "year": 2009}