{"title": "RESIDE: A Benchmark for Single Image Dehazing", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "In this paper, we present a comprehensive study and evaluation of existing single image dehazing algorithms, using a new large-scale benchmark consisting of both synthetic and real-world hazy images, called REalistic Single Image DEhazing (RESIDE). RESIDE highlights diverse data sources and image contents, and is divided into five subsets, each serving different training or evaluation purposes. We further provide a rich variety of criteria for dehazing algorithm evaluation, ranging from full-reference metrics, to no-reference metrics, to subjective evaluation and the novel task-driven evaluation. Experiments on RESIDE sheds light on the comparisons and limitations of state-of-the-art dehazing algorithms, and suggest promising future directions.", "text": "earlier works consider multiple images scene available dehazing single image dehazing proves realistic setting practice thus gained dominant popularity. atmospheric scattering model classical description hazy image generation state-of-the-art single image dehazing methods exploit physical model estimate parameters either physically grounded data-driven ways. performance methods continuously improved especially latest models embracing deep learning given atmospheric scattering model dehazing methods follow similar three-step methodology estimating transmission matrix hazy image estimating using methods; estimating clean image computing noteworthy portion dehazing methods exploited natural image priors depth statistics. imposed locally constant constraints albedo values together decorrelation transmission local areas estimated depth value using albedo estimates original image. constrain scenes depth structure thus often leads inaccurate estimation color depth. discovered dark channel prior reliably calculate transmission matrix followed many successors. however prior found unreliable scene objects similar atmospheric light enforced boundary constraint contextual regularization sharper restorations. developed color attenuation prior abstract—in paper present comprehensive study evaluation existing single image dehazing algorithms using large-scale benchmark consisting synthetic real-world hazy images called realistic single image dehazing reside highlights diverse data sources image contents divided subsets serving different training evaluation purposes. provide rich variety criteria dehazing algorithm evaluation ranging full-reference metrics no-reference metrics subjective evaluation novel task-driven evaluation. experiments reside sheds light comparisons limitations stateof-the-art dehazing algorithms suggest promising future directions. images captured outdoor scenes often suffer poor visibility reduced contrasts fainted surfaces color shift presence haze. caused aerosols dust mist fumes existence haze adds complicated nonlinear data-dependent noise images making haze removal highly challenging image restoration enhancement problem. moreover many computer vision algorithms work well scene radiance haze-free. however dependable vision system must reckon entire spectrum degradations unconstrained environments. taking autonomous driving example hazy foggy weather obscure vision on-board cameras create confusing reﬂections glare leaving state-of-the-art self-driving cars struggle dehazing thus becoming increasingly desirable technique computational photography computer vision tasks whose advance immediately beneﬁt many blooming application ﬁelds video surveillance autonomous/assisted driving. boyi feng wuhan national laboratory optoelectronics huazhong university science technology wuhan china. email boyilicsgmail.com dfenghust.edu.cn. dacheng centre quantum computation intelligent systems department engineering information technology university technology sydney sydney australia. email dacheng.taosydney.edu.au. created linear model scene depth hazy image learned model parameters supervised way. jointly estimated scene depth recover clear latent image foggy video sequence. proposed non-local prior based assumption color cluster clear image became haze-line space. view prevailing success convolutional neural networks computer vision tasks several dehazing algorithms relied various cnns directly learn fully data order avoid often inaccurate estimation physical parameters single image. dehazenet proposed trainable model estimate transmission matrix hazy image. came multi-scale ﬁrst generated coarsescale transmission matrix gradually reﬁned despite promising results inherent limitation training data becoming increasingly severe obstacle booming trend section discussions. besides efforts made beyond suboptimal procedure separately estimating parameters cause accumulated even ampliﬁed errors combining together calculate instead advocate simultaneous uniﬁed parameter estimation. earlier works modeled hazy image factorial markov random ﬁeld statistically independent latent layers. another line researches make retinux theory approximate spectral properties object surfaces ratio reﬂected light. recently presented re-formulation integrate variable. result. dehazing model fully end-to-end directly generated without intermediate parameter estimation step. idea later extended video dehazing despite prosperity single image dehazing algorithms hurdles development ﬁeld large-scale realistic benchmark dataset image dehazing; current metrics evaluating comparing image dehazing algorithms neither convincing sufﬁcient. detailed discussions presented section introduce ﬁrst-of-its-kind benchmark called realistic single image dehazing dataset. overview reside could found tables image examples displayed figure compared exiting synthetic training testing sets unrealistic indoor scenes includes large diversity indoor outdoor scene images training well real-world hazy images addition synthetic ones evaluation. specially annotate real-world hazy images object bounding boxes. widely adopted psnr ssim employ no-reference metrics human subjective scores evaluate dehazing results especially real-world hazy images without clean groundtruth. importantly recognize image dehazing practice usually serves preprocessing step mid-level high-level vision tasks. thus propose exploit object detection performance dehazed images brand-new task-speciﬁc evaluation criterion dehazing algorithms. conduct extensive systematic range experiments quantitatively compare nine state-of-the-art single image dehazing algorithms using reside dataset proposed variety evaluation criteria. evaluation analysis demonstrate performance limitations state-of-the-art algorithms. ﬁndings experiments conﬁrm commonly believed also suggest research directions single image dehazing. reside dataset made publicly available soon research purposes project’s website. manuscript periodically updated include benchmarking results. many image restoration enhancement tasks beneﬁt continuous efforts standardized benchmarks allow comparison different proposed methods conditions comparison common large-scale benchmark long missing dehazing owing signiﬁcant challenge collecting creating realistic hazy images clean groundtruth references. generally impossible capture visual scene without haze environment conditions stay identical. therefore recent dehazing models typically generate training sets creating synthetic hazy images clean ones ﬁrst obtain depth maps clean images either utilizing available depth maps depth image datasets estimating depth generate hazy images computing data-driven dehazing models could trained regress clean images hazy ones. fattal’s dataset provided synthetic images. frida produced synthetic images evaluating performance automatic driving systems various hazy environments. small train effective dehazing models. form large-scale training sets used ground-truth images depth meta-data indoor depth database middlebury stereo database recently generated foggy cityscapes dataset images cityscapes dataset using despite positive driving effects development dehazing algorithms synthetic images training inevitably brought limitations. hand many depth image datasets used generate synthetic images collected indoor scenes dehazing applied outdoor environments. content training data thus signiﬁcantly diverges target subjects real dehazing applications. mismatch undermine practical effectiveness trained dehazing models. hand limited number outdoor datasets utilized depth information either incomplete inaccurate often leading unrealistic hazy images artifacts synthesis. multiple dehazing algorithms available becomes pivotal appropriate evaluation criteria compare dehazing results. dehazing algorithms rely fullreference psnr ssim metrics assuming synthetic testing known clean groundtruth too. discussed above practical applicability jeopardy even promising testing performance achieved large content divergence synthetic real hazy images. objectively evaluate dehazing algorithms real hazy images without reference no-reference image quality assessment models possible candidates. tested no-reference objective models among several dehazing approaches self-collected hazy images compare latest cnn-based dehazing models. psnr/ssim well objective metrics often align poorly human perceived visual qualities many papers visually display dehazing results result differences state-of-the-art dehazing algorithms often subtle people reliably judge. suggests necessity conducting subjective user study towards efforts made recognized performance high-level computer vision tasks object detection recognition deteriorate presence various degradations thus largely affected quality image restoration enhancement. dehazing could used pre-processing many computer vision tasks executed wild resulting task performance could turn treated indirect indicator dehazing quality. task-driven evaluation received little attention despite great implications outdoor applications. relevant preliminary effort presented authors compared cnn-based dehazing models placing object detection pipeline tests synthetic hazy data bounding boxes. created dataset real-world images depicting foggy driving scenes came ground truth annotations evaluating semantic segmentation object detection. besides relatively small dataset cannot used evaluating dehazing perceptual quality either objectively subjectively image dehazing dataset large-scale dataset benchmarking single image dehazing algorithms. reside built comprehensive diverse data sources contents evaluation options fig. visual comparison synthetic hazy images directly generated maked ots. ﬁrst second rows synthesized hazy images based maked dataset respectively. synthetic images distinct sources synthesis ways. contains synthetic hazy images generated using images existing indoor depth datasets middlebury stereo optional split training validation provided. contains images synthesized collected real world outdoor scenes without depth information. estimate depth image synthesize outdoor hazy images. generating synthetic sets different atmospheric lights choosing channel uniformly select thus contains paired clean hazy images clean groundtruth image leads multiple pairs whose hazy images generated different parameters straightforward option would utilize existing depth datasets collected outdoor scene maked kitti however outdoor depth maps tend unreliable. limitations rgb-based depth cameras maked dataset suffer least meters average root mean squared error predicted depths kitti dataset least meters average error comparison average depth errors indoor datasets e.g. nyu-depth-v usually small meter. outdoor depth maps also contain large amount artifacts large holes renders inappropriate direct haze simulation. comparison observed produce accurate depth maps lead artifact-free hazy images. visual comparisons synthetic hazy images directly generated maked included figure another possible alternative adopt recent approaches depth denoising in-painting leave future exploration. driven testing hybrid subjective testing corresponding different evaluation viewpoint. sots selects indoor images outdoor scenes internet follow process synthesize hazy images. specially create challenging dehazing cases testing e.g. white scenes added heavy haze. hsts picks synthetic outdoor hazy images generated together real-world hazy images combined human subjective review. rtts collects real-world hazy images crawled covering mostly trafﬁc driving scenarios. image annotated object categories bounding boxes rtts organized form currently focus trafﬁc-related categories bicycle motorbike person bus. obtain annotated bounding boxes marked difﬁcult used paper’s experiments. class details rtts show iii. additionally also collect unannotated real-world hazy images exploited paper potentially used domain adaption future etc. despite popularity full-reference psnr/ssim metrics evaluating dehazing algorithms inherently limited unavailability clean groundtruth images practice well often poor alignment human perception quality thus refer no-reference models spatialspectral entropy-based quality blind image integrity notator using statistics complement shortness psnr/ssim. note score sseq bliinds used range reverse score make correlation consistent full-reference metrics. apply psnr ssim sseq bliinds-ii dehazed results sots examine consistent resulting ranking dehazing algorithms also apply four metrics hsts compare objective measures subjective ratings. investigated various choices full-reference noreference models found limited predicting quality dehazed images. conduct subjective user study quality dehazing results produced different algorithms gain previous survey participant scored dehazing result image integer best reﬂects perceptual quality. make important innovations asking participants give pairwise comparisons rather individual ratings former often believed robust consistent subjective surveys; decomposing perceptual quality dimensions dehazing clearness authenticity former deﬁned thoroughly haze removed latter deﬁned realistic dehazed image looks like. disentangled dimensions motivated observations algorithms produce naturally-looking results unable fully remove haze others remove haze price unrealistic visual artifacts. shown dehazed result pairs obtained using different algorithms hazy image. pair participant needs decide better terms clearness better authenticity. image pairs drawn competitive methods randomly images winning pairwise comparison compared next round best selected. bradley-terry model estimate subjective scores dehazing algorithm ranked. details subjective survey included supplementary. since dehazed images often subsequently automatic semantic analysis tasks recognition detection argue optimization target dehazing tasks neither pixel-level perceptual-level quality utility dehazed images given semantic analysis task thus propose task-driven evaluation dehazing algorithms study problem object detection presence haze example. notice investigated detection segmentation problems hazy images well dehazing evaluation purpose. specially used pre-trained faster r-cnn model detect objects interests dehazed results rtts various algorithms rank algorithms mean average precision achieved. based rich resources provided reside evaluate representative state-of-the-art algorithms dark-channel prior boundary constrained context regularization artifact suppression gradient residual minimization color attenuation prior non-local image dehazing dehazenet multi-scale all-in-one dehazing network last three belong latest cnn-based dehazing algorithms. data-driven algorithms trained entire reside training ots. recruit participants different educational backgrounds subjective survey described section using hsts contains synthetic outdoor realworld hazy images. bradley-terry model estimate subjective score method ranked. bradley-terry model probability object favored assumed element winning matrix representing number times method favored method newton-raphson method solve note synthetic image winning matrix including ground truth nine dehazing methods results. real-world image winning matrix absence ground truth. general since learning-based methods optimized directly minimizing loss output ground truth pairs maximizing likelihood large-scale data clearly outperform earlier algorithms based natural statistical priors terms psnr ssim. especially indoor outdoor synthetic images dehazenet achieves highest psnr value aod-net obtains best ssim score obtains suboptimal psnr ssim indoor outdoor images respectively. however comes no-reference metrics results become less consistent. aod-net still maintains competitive performance obtaining best bliinds-ii result indoor images best sseq result outdoor images. hand several prior-based methods bccr also show competitiveness ranks ﬁrst term sseq indoor images bccr wins outdoor images term bliinds-ii. visually observe results bccr tend produce sharp edges highly contrasting colors explains preferred bliinds-ii sseq. inconsistency fullno-reference evaluations aligns figures show qualitative examples dehazed results synthetic real-world image respectively. quantitative results found table trends visualized figure also compute fullno-reference metrics synthetic images examine consistency subjective scores. interesting observations could drawn subjective qualities various algorithms’ results show different trends synthetic real hazy images. synthetic images hsts receives best clearness score dehazenet best authenticity score. real images cnnbased methods rank top- terms clearness authenticity mscnn achieves best according scores. clearness authenticity scores image often aligned. seen figure subjective scores hardly correlated synthetic images; correlation shows better real images. reﬂects complexity multi-facet nature subjective perceptual evaluation. table observe divergence subjective objective evaluation results. best performer subjective evaluation mscnn psnr/ssim results synthetic indoor images quite sseq/bliinds-ii synthetic outdoor images moderate. another example receives highest sseq/bliinds-ii scores real hsts images. however subjective scores rank ﬁfth among nine algorithms set. adopt commonly used faster r-cnn ﬁxed model detect objects dehazed results rtts images. figure compares object detection results rtts hazy image applying nine different dehazing algorithms. table compares results bccr mscnn best performers implying traditional cnn-based methods good potential contribute object detection. hand comparing ranking detection no-reference results observe weak correlation. example bccr achieves highest bliinds-ii value mscnn lower sseq bliinds-ii scores competitors. manifests necessity evaluating task-driven way. discussion optimizing detection performance haze? ﬁrst time reported promising performance detecting objects haze concatenating jointly tuning aod-net faster-rcnn uniﬁed pipeline following authors trained detection pipeline using annotated dataset synthetic hazy images generated absence annotated realistic hazy images reported quantitative performance separate synthetic annotated images. goal different scope rtts interested explore whether could boost detection rtts realistic hazy images using joint pipeline. developing photo-realistic simulation approaches generating hazy images clean ones would resolve bottleneck handle-labeling supply large-scale annotated training data little mismatch. technique haze severity estimation also help synthesis ﬁrst estimating haze level testing images generating training images accordingly. view synthetic hazy images source domain realistic ones target domain unsupervised domain adaption performed reduce domain low-level features exploiting unannotated realistic hazy images. example provided example pre-training robust low-level ﬁlters using unannotated data source target domains leading much improved robustness applied testing target domain data. purpose included unannotated realistic hazy images reside might help build models. apparently discussions straightforwardly applied high-level vision tasks uncontrolled outdoor environments tracking recognition semantic segmentation etc. methods implemented matlab except aod-net pycaffe. however fair compare aod-net methods since matlab implementation superior efﬁciency pycaffe shown aod-net shows clear advantage others efﬁciency thanks lightweight feed-forward structure. paper propose reside benchmark systematically evaluate state-of-the-arts single image dehazing. results presented seems singlebest dehazing model criteria aod-net dehazenet favored psnr ssim; bccr kore competitive terms no-reference metrics; mscnn shows appreciated subjective quality; bccr mscnn lead superior detection performance real hazy images; ﬁnally aod-net efﬁcient among all. highly complicated nature dehazing problem real-world generalization evaluation criteria. future research advocate evaluate optimize dehazing algorithms towards dedicated cafeterias rather solely psnr/ssim found poorly aligned metrics used. particular correlating dehazing high-level computer vision problems likely lead innovative robust computer vision pipelines many immediate applications. another blank developing no-reference metrics better correlated human perception evaluating dehazing results. progress accelerate needed shift current fullreference evaluation synthetic images realistic evaluation schemes ground truth. schechner narasimhan nayar instant dehazing images using polarization computer vision pattern recognition cvpr proceedings ieee computer society conference vol. kopf neubert chen cohen cohen-or deussen uyttendaele lischinski deep photo model-based photograph enhancement viewing transactions graphics vol. mccartney optics atmosphere scattering molecules particles york john wiley sons inc. narasimhan nayar chromatic framework vision weather computer vision pattern recognition proceedings. ieee conference vol. ieee meng wang duan xiang efﬁcient image dehazing boundary constraint contextual regularization ieee international conference computer vision chen wang robust image video dehazing visual artifact suppression gradient residual minimization european conference computer vision tang yang wang investigating haze-relevant features learning framework image dehazing proceedings ieee conference computer vision pattern recognition nair kumar sankaran effective surround ﬁlter image dehazing proceedings international conference interdisciplinary advances applied computing. agustsson timofte ntire challenge single image super-resolution dataset study ieee conference computer vision pattern recognition workshops vol. shen reid learning depth single monocular images using deep convolutional neural ﬁelds ieee transactions pattern analysis machine intelligence vol. j.-p. tarel hautiere caraffa cord halmaoui gruyer vision enhancement homogeneous heterogeneous ieee intelligent transportation systems magazine vol. scharstein szeliski high-accuracy stereo depth maps using structured light computer vision pattern recognition proceedings. ieee computer society conference vol. ieee i–i. wang yang gong stereoscopic inpainting joint color depth completion stereo images computer vision pattern recognition cvpr ieee conference ieee cheng wang zhang yang huang robust emotion recognition quality rate video deep learning approach proceedings conference affective computing intelligent interaction barnes photo-realistic simulation road scene data-driven methods weather proceedings ieee conference computer vision pattern recognition worksho huang using user generated online photos estimate monitor pollution major cities proceedings international conference internet multimedia computing service.", "year": 2017}