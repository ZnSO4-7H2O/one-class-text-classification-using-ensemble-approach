{"title": "A systematic study of the class imbalance problem in convolutional  neural networks", "tag": ["cs.CV", "cs.AI", "cs.LG", "cs.NE", "stat.ML"], "abstract": "In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that totally eliminates the imbalance, whereas undersampling can perform better when the imbalance is only removed to some extent; (iv) as opposed to some classical machine learning models, oversampling does not necessarily cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest.", "text": "study systematically investigate impact class imbalance classiﬁcation performance convolutional neural networks compare frequently used methods address issue. class imbalance common problem comprehensively studied classical machine learning limited systematic research available context deep learning. study three benchmark datasets increasing complexity mnist cifar- imagenet investigate eﬀects imbalance classiﬁcation perform extensive comparison several methods address issue oversampling undersampling two-phase training thresholding compensates prior class probabilities. main evaluation metric area receiver operating characteristic curve adjusted multi-class tasks since overall accuracy metric associated notable diﬃculties context imbalanced data. based results experiments conclude eﬀect class imbalance classiﬁcation performance detrimental; method addressing class imbalance emerged dominant almost analyzed scenarios oversampling; oversampling applied level totally eliminates imbalance whereas undersampling perform better imbalance removed extent; opposed classical machine learning models oversampling necessarily cause overﬁtting cnns; thresholding applied compensate prior class probabilities overall number properly classiﬁed cases interest. convolutional neural networks gaining signiﬁcance number machine learning application domains currently contributing state ﬁeld computer vision includes tasks object detection image classiﬁcation segmentation. also widely used natural language processing speech recognition replacing improving classical machine learning models cnns integrate automatic feature extraction discriminative classiﬁer model main diﬀerence traditional machine learning techniques. property allows cnns learn hierarchical representations standard built fully connected layers number blocks consisting convolutions activation function layer pooling complex nature cnns requires signiﬁcant computational power training evaluation networks addressed help modern graphical processing units common problem real life applications deep learning based classiﬁers classes signiﬁcantly higher number examples training classes. diﬀerence referred class imbalance. plenty examples domains like computer vision medical diagnosis fraud detection others issue highly signiﬁcant frequency class times less another class established class imbalance signiﬁcant detrimental eﬀect training traditional classiﬁers including multi-layer perceptrons aﬀects convergence training phase generalization model test set. issue likely also aﬀects deep learning systematic study topic available. methods dealing imbalance well studied classical machine learning models straightforward common approach sampling methods. methods operate data increase balance. widely used proven robust oversampling anoption undersampling. na¨ıve version called random majority undersampling simply removes random portion examples majority classes issue class imbalance also tackled level classiﬁer. case learning algorithms modiﬁed e.g. introducing diﬀerent weights misclassiﬁcation examples diﬀerent classes explicitly adjusting prior class probabilities previous studies showed results cost sensitive learning deep neural networks kinds loss function neural networks training also developed recently method cnns introduced trains network two-phases network trained balanced data ﬁrst output layers ﬁne-tuned little systematic analysis imbalance methods deal available deep learning researchers employ methods might addressing problem likely based intuition internal tests systematic results available traditional machine learning. based review literature method commonly applied deep learning oversampling. rest paper organized follows. section gives overview methods address problem imbalance. section describe experimental setup. provides details compared methods datasets models used evaluation. then section present results experiments compare methods. finally section concludes paper. methods addressing class imbalance divided main categories ﬁrst category data level methods operate training change class distribution. alter dataset order make standard training algorithms work. category covers classiﬁer level methods. methods keep training dataset unchanged adjust training inference algorithms. moreover methods combine categories available. section give overview commonly used approaches classical machine learning models deep neural networks. oversampling. commonly used method deep learning basic version called random minority oversampling simply replicates randomly selected samples minority classes. shown oversampling eﬀective lead overﬁtting advanced sampling method aims overcome issue smote augments artiﬁcial examples created interpolating neighboring data points. extensions technique proposed example focusing examples near boundary classes another type oversampling approach uses data preprocessing perform informed oversampling. cluster-based oversampling ﬁrst clusters dataset oversamples cluster separately reduces between-class within-class imbalance. databoost-im hand identiﬁes diﬃcult examples boosting preprocessing uses generate synthetic data oversampling approach speciﬁc neural networks optimized stochastic gradient descent class-aware sampling main idea ensure uniform class distribution mini-batch control selection examples class. undersampling. another popular method results number examples class. however opposed oversampling examples removed randomly majority classes classes number examples. might appear intuitive evidence situations undersampling preferable oversampling signiﬁcant disadvantage method discards portion available data. overcome shortcoming modiﬁcations introduced carefully select examples removed. e.g. one-sided selection identiﬁes redundant examples close boundary classes general approach undersampling data decontamination involve relabeling examples thresholding. also known threshold moving post scaling adjusts decision threshold classiﬁer. applied test phase involves changing output class probabilities. many ways network outputs adjusted. general threshold minimize arbitrary criterion using optimization algorithm however basic version simply compensates prior class probabilities estimated class frequency imbalanced dataset sampling applied. shown neural networks estimate bayesian posteriori probabilities given datapoint output class implicitly corresponds cost sensitive learning. method assigns diﬀerent cost misclassiﬁcation examples diﬀerent classes respect neural networks implemented various ways. approach threshold moving post scaling applied inference phase classiﬁer already trained. similar strategy adapt output network also backward pass backpropagation algorithm another adaptation neural network cost sensitive modify learning rate higher cost examples contribute update weights. ﬁnally train network minimizing misclassiﬁcation cost instead standard loss function results approach equivalent oversampling described therefore method implemented study. one-class classiﬁcation. context neural networks usually called novelty detection. concept learning technique recognizes positive instances rather discriminating classes. autoencoders used purpose trained perform autoassociative mapping i.e. identity function. then classiﬁcation example made based reconstruction error input output patterns e.g. absolute error squared errors euclidean mahalanobis distance method proved work well extremely high imbalance classiﬁcation problem turns info anomaly detection hybrid methods. approach combines multiple techniques abovementioned categories. widely used example ensembling. viewed wrapper methods. easyensemble balancecascade methods train committee classiﬁers undersampled subsets smoteboost hand combination boosting smote oversampling recently introduced successfully applied training brain tumor segmentation two-phase training even though task image segmentation approached pixel level classiﬁcation. method involves network pre-training balanced dataset ﬁne-tuning last output layer softmax original imbalanced data. class imbalance take many forms particularly context multiclass classiﬁcation typical cnns. problems class might underrepresented overrepresented every class diﬀerent number examples. study deﬁne investigate types imbalance believe representative real-world cases. ﬁrst type step imbalance. step imbalance number examples equal within minority classes equal within majority classes diﬀers majority minority classes. type imbalance characterized parameters. fraction minority classes deﬁned example type imbalance situation among total classes training examples another case shown figure dataset number examples total smaller imbalance ratio corresponding parameter classes minority presented figure second type imbalance call linear imbalance. deﬁne parameter ratio maximum minimum number examples among classes equation imbalance ratio step imbalance. however number examples remaining classes interpolated linearly diﬀerence consecutive pairs classes constant. example linear imbalance distribution shown figure examine variants two-phase training method. oversampled undersampled dataset. second phase keep hyperparameters learning rate decay policy ﬁrst phase. base learning rate selected methods representative available approaches. sampling used explicitly incorporate cost examples appearance. makes many implementations cost-sensitive learning thresholding another applying cost-sensitiveness moving output threshold higher cost examples harder misclassify. ensemble methods require training multiple classiﬁers. considerable time needed train deep models often practical even infeasible train multiple deep neural networks. one-class methods limited application datasets extremely high imbalance. moreover applied anomaly detection problem beyond scope study. importantly focused methods widely used relatively straightforward implement draw conclusions practical serve guidance large number deep learning researchers engineers. study used three benchmark datasets mnist cifar- imagenet large scale visual recognition challenge provided split training test labelled. dataset choose diﬀerent model hyperparameters used training known perform well based literature. datasets together corresponding models increasing complexity. allows draw conclusions simple task verify scale complex ones. keep number weights’ updates constant. also networks trained random initialization weights pretraining applied. overview information datasets corresponding models given table experiments implemented deep learning framework caﬀe table summary used datasets. number images class refers perfectly balanced subsets used experiments. provided image dimensions imagenet given rescaling. corresponding digits number examples class original training dataset ranges class class artiﬁcially imbalanced versions uniformly random subsample class contain examples. model mnist modern version lenet- network architecture presented table networks dataset trained iterations. optimization algorithm stochastic gradient descent momentum value learning rate decay policy deﬁned decay parameters current iteration. furthermore used batch size weight decay value network weights initialized randomly uniform distribution xavier variance whereas biases initialized zero. data augmentation used. test error model trained described original mnist dataset experiment combination parameters repeated times. every time subset minority classes randomized. created artiﬁcially imbalanced training sets step imbalance linear imbalance. evaluated four methods require training model total number trained networks including baseline natural imbalance all. exactly training test examples class. data augmentation follow standard preprocessing comprising global contrast normalization whitening networks trained iterations using momentum base learning rate multiplied ﬁxed multiplier iterations. number examples batch weight decay value network weights initialized xavier procedure biases zero. test error model trained described original cifar- dataset found network training quite sensitive initialization choice base learning rate. sometimes network gets stuck poor local minimum. also imbalanced datasets training required lower base learning rate train all. therefore case searching best network architecture fully connected layers. therefore ﬁne-tuning two-phase training method update weights last convolutional layers kernels size imbalance parameters space used cifar- experiments considerably sparser used mnist signiﬁcantly longer time required train network. tested values narrowed make experiment reacorresponds eight minority classes respectively. cases classes chosen minority ones lowest label value. means ﬁxed number minority classes classes always picked minority. also included larger minority classes. total trained networks dataset. evaluation ilsvrc- competition subset imagenet widely used benchmark compare classiﬁers’ performance. number examples majority classes reduced classes less cases always chosen minority ones imbalanced subsets. data preprocessing applied resizing smaller dimension pixels long aspect ratio model architecture employed dataset resnet- i.e. residual network batch normalization layers known accelerate deep networks training consists four residual blocks give nine convolutional layers fully connected. ﬁrst residual block outputs data tensor depth increases factor two. fully connected layer outputs values softmax transforms class probabilities. architecture residual block presented figure networks trained iterations using momentum base learning rate decays linearly last iteration. number examples batch weight decay network weights initialized kaiming initialization procedure top- test error model trained described original ilsvrc- dataset multi-class single centered crop. chosen relatively small resnet sake faster training without loss generality test case small cases large step imbalance baseline undersampling oversampling methods. speciﬁcally three step imbalanced subsets deﬁned correspond minority classes imbalance ratio minority classes imbalance minority classes imbalance ratio respectively. moreover highest imbalance train three networks method randomized selection minority classes subsampled examples class. done order estimate variability performance methods. total gives resnet- networks trained artiﬁcially imbalanced subsets ilsvrc-. metric widely used evaluate classiﬁer performance context multiclass classiﬁcation cnns overall accuracy proportion test examples correctly classiﬁed. however signiﬁcant long acknowledged limitations particularly context imbalanced datasets speciﬁcally test imbalanced accuracy favor classes overrepresented cases leading highly misleading assessment. example situation majority class represents cases classiﬁer assigns label majority class test cases. misleading accuracy assigned classiﬁer limited use. another issue might arise test balanced training imbalanced. might result situation decision threshold moved reﬂect estimated class prior probabilities cause accuracy measure test true discriminative power classiﬁer change. widely used evaluation metric classiﬁers. also used compare performance classiﬁers trained imbalanced datasets. since basic version suitable binary classiﬁcation multi-class modiﬁcation averaging aucs binary classiﬁcation task distinguishing given class classes test used datasets equal number examples class. usually assumed class distribution test follows training set. change test match artiﬁcially imbalanced training set. reason score achieved classiﬁer test comparable largest number cases classes provides accurate performance estimation. results showing impact class imbalance classiﬁcation performance comparison methods addressing imbalance shown figures figure shows results respect multi-class ﬁxed number minority classes mnist cifar-. figure presents result perspective ﬁxed ratio imbalance i.e. parameter datasets. regarding eﬀect class imbalance classiﬁcation performance observed following. first deterioration performance class imbalance substantial. expected increasing ratio examples majority minority classes well number minority classes negative eﬀect performance resulting classiﬁers. furthermore comparing results mnist cifar- observed eﬀect imbalance signiﬁcantly stronger task higher complexity. similar drop performance mnist cifar- corresponded approximately times stronger level imbalance mnist dataset. regarding performance diﬀerent methods addressing imbalance almost situations oversampling emerged best method. also showed notable improvement performance baseline majority situations never showed considerable decrease performance datasets analyzed section making clear recommendation tasks similar mnist cifar-. undersampling showed generally poor performance. large number analyzed scenarios undersampling showed decrease performance compared baseline. scenarios large proportion minority classes undersampling showed improvement baseline never notable advantage oversampling datasets case imbalance ratio undersampling oversampling biggest smaller number minority classes decreases number minority classes shown figure expected since classes minority methods become equivalent. two-phase training methods undersampling oversampling tend perform baseline corresponding method baseline better methods ﬁne-tuning improves original method. otherwise performance deteriorates. however baseline better still gain using two-phase training method. oversampling almost always better baseline ﬁne-tuning always gives lower score. figure show results linear imbalance mnist cifar- datasets. highest possible linear imbalance ratio mnist dataset means example underrepresented class. however even case decrease performance according multi-class score baseline model signiﬁcant shown figure nevertheless oversampling improves score datasets tested values whereas score undersampling decreases approximately linearly imbalance ratio. results experiments performed imagenet dataset conﬁrm impact imbalance classiﬁer’s performance. table compares methods respect multi-class auc. drop performance largest tested imbalance terms multi-class auc. results conﬁrm oversampling approach performs consistently better undersampling approach across scenarios. small decrease performance compared baseline observed oversampling extreme imbalances. please note however results treated caution strong evidence oversampling inferior highly complex tasks extreme imbalance. absolute diﬀerence performance three runs respect multi-class even higher therefore diﬀerences might variability results diﬀerent runs neural networks. moreover highest tested imbalanced training original ilsvrc- introducing confounding issues optimal training hyperparameters signiﬁcantly changed dataset. therefore results indicate caution taken sampling technique applied highly complex tasks extreme imbalances needs extensive study devoted speciﬁc issue. important question needs considered context study whether decrease performance imbalanced datasets merely caused fact imbalanced datasets simply fewer training examples truly caused fact datasets imbalanced. first notice oversampling method uses amount data baseline. eliminates imbalance enough improve performance almost cases. still reach performance classiﬁer trained original dataset. indication eﬀect imbalance trivial. second cases undersampling reduces total number cases performs better baseline moreover even cases undersampling perform oversampling. means that sampling methods eliminate imbalance even using fewer data comparable. addition value parameter equal number examples training linear imbalance step imbalance corresponds half classes minority. drop performance much higher step imbalance. additionally demonstrates total number examples matters also distribution classes. focus also provide evaluation methods based overall accuracy measure results step imbalance shown figure explained section accuracy known limitations scenarios reﬂect discriminative power classiﬁer rather prevalence classes training test set. nevertheless still commonly used evaluation score therefore provide results according metric. please note thresholding actual eﬀect ability classiﬁer discriminate given class another rather helps threshold network output guarantees large number correctly classiﬁed cases. terms multiplying decision variable positive number change area curve. however ﬁnding optimal operating point curve important overall number correctly classiﬁed cases interest. default version oversampling increase number cases minority classes number matches majority classes. similarly default undersampling decrease number cases majority classes match minority classes. however moderate version algorithms could applied. case mnist imbalance ratio tried gradually decrease imbalance oversampling undersampling. results shown figure shown figure undersampling cases moderate number minority classes intermediate levels undersampling performed better full undersampling baseline. moreover comparing undersampling oversampling reduced level imbalance notice case oversampling level apply undersampling achieve equivalent performance. however level known priori rendering oversampling still method choice. cases undersampling oversampling perform similarly. cases would probably prefer model generalizes better. classical machine learning models shown oversampling cause overﬁtting especially minority classes repeat small number examples multiple times trained model well. thus according prior knowledge undersampling would better choice. results experiments conﬁrm conclusion convolutional neural networks. figure compare convergence baseline sampling methods cifar- experiments respect accuracy. methods helped train better classiﬁer terms performance generalization. also made training stable. however case true oversampling leads overﬁtting. accuracy decrease training progresses accuracy training test sets smaller oversampling figure undersampling figure observation also holds mnist imagenet datasets cases imbalance. study examined impact class imbalance classiﬁcation performance convolutional neural networks investigated eﬀectiveness diﬀerent methods addressing issue. deﬁned parametrized representative types imbalance i.e. step linear. subsampled mnist cifar- imagenet datasets make artiﬁcially imbalanced. compared common sampling methods basic thresholding two-phase training.", "year": 2017}