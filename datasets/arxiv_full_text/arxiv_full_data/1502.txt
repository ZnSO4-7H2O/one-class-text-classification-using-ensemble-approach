{"title": "Are You Talking to Me? Reasoned Visual Dialog Generation through  Adversarial Learning", "tag": ["cs.CV", "cs.AI", "cs.CL"], "abstract": "The Visual Dialogue task requires an agent to engage in a conversation about an image with a human. It represents an extension of the Visual Question Answering task in that the agent needs to answer a question about an image, but it needs to do so in light of the previous dialogue that has taken place. The key challenge in Visual Dialogue is thus maintaining a consistent, and natural dialogue while continuing to answer questions correctly. We present a novel approach that combines Reinforcement Learning and Generative Adversarial Networks (GANs) to generate more human-like responses to questions. The GAN helps overcome the relative paucity of training data, and the tendency of the typical MLE-based approach to generate overly terse answers. Critically, the GAN is tightly integrated into the attention mechanism that generates human-interpretable reasons for each answer. This means that the discriminative model of the GAN has the task of assessing whether a candidate answer is generated by a human or not, given the provided reason. This is significant because it drives the generative model to produce high quality answers that are well supported by the associated reasoning. The method also generates the state-of-the-art results on the primary benchmark.", "text": "visual dialogue task requires agent engage conversation image human. represents extension visual question answering task agent needs answer question image needs light previous dialogue taken place. challenge visual dialogue thus maintaining consistent natural dialogue continuing answer questions correctly. present novel approach combines reinforcement learning generative adversarial networks generate human-like responses questions. helps overcome relative paucity training data tendency typical mle-based approach generate overly terse answers. critically tightly integrated attention mechanism generates humaninterpretable reasons answer. means discriminative model task assessing whether candidate answer generated human given provided reason. signiﬁcant drives generative model produce high quality answers well supported associated reasoning. method also generates state-of-the-art results primary benchmark. combined interpretation vision language enabled development range applications made interesting steps towards artiﬁcial intelligence including image captioning visual question answering referring expressions example requires agent answer previously unseen question previously unseen image recognised ai-complete problem visual dialogue represents extension problem whereby agent required engage figure human-like machine-like responses visual dialog. human-like responses clearly answer questions comprehensively help maintain meaningful dialogue. dialogue image. signiﬁcant demands agent able answer series questions predicated previous questions answers dialogue. visual dialogue thus reﬂects challenges robotics enable agent capable acting upon world might collaborate dialogue. similarity visual dialog tasks methods directly applied solve visual dialog problem. fact visual dialog challenge requires ongoing conversation however demands taking consideration state conversation thus far. ideally agent engaged participant conversation cooperating towards larger goal rather generating single word answers even easier optimise. figure provides example distinction type responses agent might generate involved responses human likely generate engaged conversation. human-like responses longer provide reasoning information might even though speciﬁcally asked for. previous visual dialog systems follow neural translation mechanism often used predicting response given image dialog history using maximum likelihood estimation objective function. however over-simpliﬁed training objective focus measuring word-level correctness produced responses tend generic repetitive. example simple response ‘yes’‘no’ don’t know’ safely answer large number questions lead high objective value. generating comprehensive answers deeper engagement agent dialogue requires engaged training process. good dialogue generation model generate responses indistinguishable human might produce. paper introduce adversarial learning strategy motivated previous success adversarial learning many computer vision sequence generation problems. particularly frame task reinforcement learning problem jointly train sub-modules sequence generative model produce response sentences basis image content dialog history discriminator leverages previous generator’s memories distinguish humangenerated dialogues machine-generated ones. generator tends generate responses fool discriminator believing human generated output discriminative model used reward generative model encouraging generate human-like dialogue. although proposed framework inspired generative adversarial networks several technical contributions lead ﬁnal success visual dialog generation task. first propose sequential co-attention generative model aims ensure attention passed effectively across image question dialog history. co-attended multi-modal features combined together generate response. secondly signiﬁcantly within structure propose discriminator access attention weights generator used generating response. note attention weights seen form ‘reason’ generated response. example indicates region focused dialog pairs informative generating response. structure important allows discriminator assess quality response given reason. also allows discriminator assess response context dialogue thus far. finally sequence generation problems quality response assessed whole sequence. follow apply monte carlo search calculate intermediate rewards. evaluate method visdial dataset show outperforms baseline methods large margin. also outperform several state-of-the-art methods. speciﬁcally adversarial learned generative model outperforms strong baseline model recall improving previous best reported results recall recall. qualitative evaluation shows generative model generates informative responses human study shows responses pass turing test. additionally implement model discriminative setting achieve state-of-the-art performance. related work visual dialog latest succession vision-andlanguage problems began image captioning includes visual question answering however contrast classical vision-and-language tasks involve single natural language interaction visual dialog requires machine hold meaningful dialogue natural language visual content. mostafazadeh propose image grounded conversation dataset task requires model generate natural-sounding conversations shared image. vries propose guesswhat game style dataset person asks questions image guess object selected second person answers questions yes/no/na. propose largest visual dialog dataset visdial pairing subjects amazon mechanical turk chat image. formulate task ‘multi-round’ task evaluate individual responses round retrieval multiplechoice setup. recently propose learn policies ‘questioner-bot’ ‘answererbot’ based goal selecting right images agents talking visdial dataset. concurrent work propose similar generative-discriminative model visual dialog. however differences. first discriminative model requires receive list candidate responses learns sort list training dataset means model trained information available. second discriminator considers generated response provided list candidate responses. instead measure whether generated figure adversarial learning framework proposed model. model composed components ﬁrst sequential co-attention generator accepts input image question dialog history tuples uses co-attention encoder jointly reason them. second component discriminator tasked labelling whether answer generated human generative model considering attention weights. output discriminator used reward push generator generate responses indistinguishable human might generate. response valid given attention weights reﬂect reasoning model history dialogue thus far. show experiments sec. procedure results generator producing suitable responses. dialog generation text-only dialog generation studied many years natural language processing literature leaded many applications. recently popular ‘xiaoice’ produced microsoft ‘its alive’ chatbot created facebook attracted signiﬁcant public attention. dialog generation typically viewed sequence-to-sequence problem formulated statistical machine translation problem inspired success seqseq model machine translation build end-to-end dialog generation models using encoder-decoder model. reinforcement learning also applied train dialog system. simulate virtual agents handcraft three rewards train response generation model. recently works make effort integrate seqseq model example introduce real users combining neural generation. ﬁrst introduce gans dialogue generation alternative human evaluation. jointly train generative model produce response sequences discriminator distinguish between human machine-generated responses. although also introduce adversarial learning framework visual dialog generation work signiﬁcant differences need consider visual content generative discriminative components system previous work requires textual information. thus designed sequential co-attention mechanism generator attention memory access mechanism discriminator jointly reason visual textual information. critically proposed tightly integrated attention mechanism generates human-interpretable reasons answer. means discriminative model task assessing whether candidate answer generated human given provided reason. signiﬁcant drives generative model produce high quality answers well supported associated reasoning. details generator discriminator found sections respectively. learning generative adversarial networks adversarial enjoyed great successes wide range applications computer vision especially image generation tasks learning process formulated adversarial game generative model trained generate outputs fool discriminator discriminator trained fooled. models jointly trained end-to-end. recent works applied adversarial learning sequence generation example backpropagate error discriminator sequence generator using policy gradient reinforcement learning. model shows outstanding performance several sequence generation problems speech generation poem generation. work extended tasks image captioning dialog generation work also inspired success adversarial learning carefully extend according application i.e. visual dialog. speciﬁcally redesign generator discriminator order accept multi-modal information also apply intermediate reward generation step generator details found sec. section describe adversarial learning approach generating natural dialog responses based image. several ways deﬁning visual based dialog generation task follow image ‘ground truth’ dialog history ...) pair utterance question given. visual dialog generation model required return response sentence question length response answer. types models used produce response generative discriminative. generative decoder word sequence generator trained ground truth answer word sequences. discriminative decoder additional candidate response vocabulary provided problem re-formulated multi-class classiﬁcation problem. biggest limitation discriminative style decoder produce response exists ﬁxed vocabulary. approach based generative model ﬁxed vocabulary undermines general applicability model also offers better prospect extensible problem generating meaningful dialogue future. terms reinforcement learning response sentence generation process viewed sequence prediction actions taken according policy deﬁned sequential co-attention generative model. model critical allows attention pass across image question dialogue history equally. discriminator trained label whether response human generated machine generated conditioned image question dialog attention memories. considering take dialog image whole account actually measuring whether generated response ﬁtted visual dialog. output discriminative model used reward previous generator pushing generate responses figure sequential co-attention encoder. input feature coattend features sequential fashion using eq.-. number function indicates sequential order ﬁnal attended features ˜u˜v form output encoder. ﬁtting dialog history. order consider reward local level monte carlo search strategy reinforce algorithm used update policy gradient. overview model found fig. following sections introduce component model separately. employ encoder-decoder style generative model widely used sequence generation problems. contrast text-only dialog generation problem needs consider dialog history however visual dialog generation additionally requires model understand visual information. distinct round questioning visual dialog multiple rounds dialog history need accessed understood. suggests encoder combine multiple information sources required. naive represent inputs image history question separately concatenate learn joint representation. contend however powerful model selectively focus regions image segments dialog history according question. based this propose sequential co-attention mechanism speciﬁcally ﬁrst pre-trained extract image features convolutional layer number image regions. question features hidden state lstm step given input word question. length question. history composed sequence utterance extract utterance feature separately make dialog history features i.e. number rounds utterance last hidden state lstm accepts given encoded image dialog history question feature co-attention mechanism generate attention weights feature type using guidance sequential style. coattention operation denoted coatten expressed follows representation three features embedded together sent -way softmax function returns probability distribution whether whole visual dialog human-natural input feature sequence represent guidances outputs previous attention modules. feature dimension. rh×d learnable parameters. denotes size hidden layers attention module. input sequence length corresponding different feature inputs. shown fig. proposed process initial question feature ﬁrst used attend image. weighted image features initial question representation combined attend utterances dialog history produce attended dialog history attended dialog history weighted image region features jointly used guide question attention finally image attention again guided attended question dialog history complete circle. three co-attended features concatenated together embedded ﬁnal feature concatenation operator. finally vector representation lstm compute probability generating token target using softmax function forms response whole generation process denoted discriminative model attention memodiscriminative model binary classiﬁer trained distinguish whether input dialog generated humans machines. order consider visual information dialog history allow discriminator access attention memories generator. speciﬁcally discriminator takes input attended image dialog history features produced generative model given question generated response generator. pair sent lstm obtain vector adversarial learning encourage generator generate responses close human generated dialogs case want generated response visual dialog good possible. policy gradient methods used achieve goal. probability visual dialog recognised humangenerated dialog discriminator used reward generator trained maximize expected reward generated response using reinforce algorithm given input visual information question dialog history utterances generator generates response answer sampling policy. attended visual dialog memories generated answer concatenated together discriminator. likelihood ratio trick approximate gradient probability generated responses words k-th word response. denotes baseline value. following train critic neural network estimate baseline value given current state under current generation policy critic network takes visual content dialog history question input encodes vector representation co-attention model maps representation scalar. critic neural network optimised based mean squared loss estimated reward real reward obtained discriminator. entire model trained end-to-end discriminator updating synchronously. human generated dialog history answers positive examples machine generated responses negative examples. sample real data sample genπ compute reward using evaluate depends whether intermediate reward used update parameter using update baseline parameters teacher-forcing update using evaluate model recently published visual dialog generation dataset visdial images visdial coco contain multiple objects everyday scenes. dialogs visdial collected pairing works chat image. make dialog measurable image remains hidden questioner task questioner questions hidden image imagine scene better. answerer sees image task answer questions asked questioner. hence conversation like multi-rounds visual based question answering ended rounds. dialogs coco training split validation split totally pairs visdial latest available version thus far. following dialogs train test. intermediate reward issue vanilla reinforce considers reward value ﬁnished sequence reward associated sequence used actions i.e. generation token. however sequence generation problem rewards intermediate steps necessary. example given question ‘are adults babies?’ human-generated answer would adults’ machine-generated answer can’t tell’. reinforce model give reward tokens machinegenerated answer proper reward assignment give reward separately i.e. high reward token rewards token ‘can’t’ ‘tell’. considering discriminator trained assign rewards fully generated sentences intermediate ones propose monte carlo search roll-out policy sample tokens. n-time search represented sampled based roll-out policy current state. roll-out policy starting current state till sequence times generated answers share common preﬁx ˆak. sequences discriminator average score teacher forcing although reward returned discriminator used adjust generation process still important feed human generated responses generator model updating. hence apply teacher forcing strategy update parameters generator. speciﬁcally training iteration ﬁrst update generator using reward obtained sampled data generator policy. sample data real dialog history update generator standard maximum likelihood estimation objective. whole training process reviewed alg. different previous language generation tasks normally bleu mentor rouge score evaluation follow retrieval setting evaluate individual responses round dialog. speciﬁcally test time besides image ground truth dialog history question list candidates answers also given. model evaluated retrieval metrics rank human response existence human response top-k ranked responses i.e. recallk mean reciprocal rank human response. since focus evaluating generalization ability generator simply rank candidates generative model’s log-likelihood scores. question color bathroom? people there? towels hanging? soap sink? color towels? kind bathtub anything bathroom window? curtains window? bathroom light anything else sink? color motorcycle? busy street shops people? daylight night time? photo color? color cars? people walking? tell shops businesses are? trafﬁc lights? think motorcycle parked sidewalk? signs? photo color? appear color wetsuit? color surfboard? rocks appear smooth sharp? close water? appear beach private section? color water dark light blue? shoes appear dry? pre-process data ﬁrst lowercase texts convert digits words remove contractions tokenizing. captions questions answers truncated ensure longer respectively. construct vocabulary words appear least times training split giving vocabulary words. words represented one-hot vector embeddings words learned. word embeddings shared across question history decoder lstms. lstms model -layered hidden states. adam optimizer used base learning rate decreasing -time monte carlo search token. co-attention generative model pretrained using ground-truth dialog history epochs. also pre-train discriminator positive examples sampled ground-truth dialog negative examples sampled dialog generated generator. discriminator updated every generator-updating steps. baselines comparative models compare model number baselines state-of-the-art models. answer prior naive baseline encodes answer options lstm scored linear classiﬁer captures ranking frequency answers training set. ﬁnds nearest neighbor images questions test question related image. options ranked mean-similarity answers questions. late fusion encodes image dialog history question separately later concatenated together linearly transformed joint representation. applies hierarchical recurrent encoder encode dialog history hrea additionally adds attention mechanism dialogs. memory network maintains previous question answer ‘fact’ memory bank learns refer stored facts image answer question. concurrent work proposes hciae attend image dialog features. table ﬁnal generative model coatt-gan-w/ rinte-tf performs best evaluation metrics. comparing previous state-of-the-art model model outperforms also produce better results hciae model previous best results without using discriminative knowledges. figure shows qualitative results model. results found supplementary material. ablation study model contains several components. order verify contribution component evaluate several variants model. coatt-g-mle generative model uses co-attention mechanism shown sec. model trained objective without adversarial learning strategies. hence used baseline model variants. coatt-gan-w/o rinte extension coatt-g model adversarial learning strategy. reward discriminator used guide generator training global reward calculate gradient shown equ. coatt-gan-w/ rinte uses intermediate reward coatt-gan-w/ rinte-tf ﬁnal model adds ‘teacher forcing’ adversarial learning. baseline coatt-g-mle model outperforms previous attention based models shows co-attention mechanism effectively encode complex multi-source information. coatt-gan-w/o rinte produces slightly better results baseline model using adversarial learning network improvement limited. intermediate reward mechanism contributes improvement i.e. proposed coattgan-w/ rinte model improves baseline average additional teacher-forcing model brings improvement average achieving best results. discriminative setting additionally implement model discriminative task visdial dataset discriminative setting need generate string instead pre-deﬁned answer given problem formulated classiﬁcation problem. modify model replacing response generation lstm single-step classiﬁer. hciae-np-att original hciae model n-pair discriminative loss self-attention mechanism. amem applies advanced memory network model dependency current question previous attention. additional models used comparison. table shows model outperforms previous baseline stateof-the-art models evaluation metrics. human study randomly sample results test dataset length generated ﬁnal model different baseline model coatt-g-mle memory network model. human subjects guess whether last response dialog human-generated machine-generated least agree generated human passed truing test. table summarizes percentage responses dialog passes turing test model outperforms baseline model model. also apply discriminator model sec. samples recognizes nearly percent human-generated responses suggests ﬁnal generator successfully fool discriminator adversarial learning. additionally record percentage responses evaluated better equal human responses according human subjects’ manual evaluation. shown table responses fall case. visual dialog generation interesting topic requires machine understand visual content natural language dialog ability multi-modal reasoning. importantly human-computer interaction interface robotics apart correctness human-like level generated response signiﬁcant index. paper proposed adversarial learning based approach encourage generator generate human-like dialogs. technically combining sequential co-attention generative model jointly reason image dialog history question discriminator dynamically access attention memories intermediate reward ﬁnal proposed model achieves state-of-art visdial dataset. turing test fashion study also shows model produce human-like visual dialog responses.", "year": 2017}