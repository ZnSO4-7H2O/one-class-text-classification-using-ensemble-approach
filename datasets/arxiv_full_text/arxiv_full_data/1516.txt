{"title": "Video Question Answering via Attribute-Augmented Attention Network  Learning", "tag": ["cs.CV", "cs.AI", "cs.CL"], "abstract": "Video Question Answering is a challenging problem in visual information retrieval, which provides the answer to the referenced video content according to the question. However, the existing visual question answering approaches mainly tackle the problem of static image question, which may be ineffectively for video question answering due to the insufficiency of modeling the temporal dynamics of video contents. In this paper, we study the problem of video question answering by modeling its temporal dynamics with frame-level attention mechanism. We propose the attribute-augmented attention network learning framework that enables the joint frame-level attribute detection and unified video representation learning for video question answering. We then incorporate the multi-step reasoning process for our proposed attention network to further improve the performance. We construct a large-scale video question answering dataset. We conduct the experiments on both multiple-choice and open-ended video question answering tasks to show the effectiveness of the proposed method.", "text": "achieved promising performance image question answering task still ineﬀective applied problem video question answering lack modeling temporal dynamics video contents video content often contains evolving complex interactions simple extension image question answering thus ineﬀectively provide satisfactory answers. because relevant video information usually scattered among entire frames. furthermore number frames video redundant irrelevant question. give simple example video question answering figure demonstrate answering question \"what woman boiling water?\" requires collective information multiple video frames. recently temporal attention mechanisms shown eﬀectiveness critical frame extraction video representation learning thus employ temporal attention mechanisms model temporal dynamics video contents. hand utilization high-level semantic attributes demonstrated eﬀectiveness visual understanding tasks furthermore observe detected attributes able enhance performance video question answering figure thus leveraging temporal dynamic modeling semantic attributes critical learning eﬀective video representation video question answering. paper study problem video question answering modeling temporal dynamics semantic attributes. specifically propose attribute-augmented attention network learning framework enables joint frame-level attribute detection uniﬁed video representation learning video question answering. incorporate multi-step reasoning process proposed attribute-augmented attention network improve performance named r-anl. certain question issued r-anl return relevant answer based referenced video content. main contributions paper follows video question answering challenging problem visual information retrieval provides answer referenced video content according question. however existing visual question answering approaches mainly tackle problem static image question ineﬀectively video question answering insuﬃciency modeling temporal dynamics video contents. paper study problem video question answering modeling temporal dynamics frame-level attention mechanism. propose attributeaugmented attention network learning framework enables joint frame-level attribute detection uniﬁed video representation learning video question answering. incorporate multi-step reasoning process proposed attention network improve performance. construct largescale video question answering dataset. conduct experiments multiple-choice open-ended video question answering tasks show eﬀectiveness proposed method. visual information retrieval information delivery mechanism enables users post queries obtain answers visual contents emerging kind recommender system visual question answering important problem sites automatically returns relevant answer referenced visual contents according users’ posted question currently existing visual question answering methods mainly focus problem static image question answering although existing methods permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights components work owned others must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. request permissions permissionsacm.org. sigir august shinjuku tokyo japan association computing machinery. isbn ----//. https//doi.org/./. using notations above problem video question answering formulated follows. given videos questions attributes goal learn attribute-augmented attention network certain question issued ranl return relevant answer based referenced video content. present details attribute-augmented attention network learning framework figure section propose attribute-augmented attention network learn joint representation multimodal video content detected attributes according question multiple choice open-ended video question answering tasks. ﬁrst employ pre-trained attribute detectors obtain visual attributes frame video denoted attribute corresponds entry vocabulary obtain representation attribute embedding matrix attribute representation size attribute i-th frame. thus learn joint representation multimodal attributes frame representation element-wise product bidirectional layer time inspired temporal attention mechanism introduce attribute-augmented attention network learn attributeaugmented video representation according question video question answering. given question i-th frame video temporal attention score given parameter matrices bias vector. denotes latent representation question attribute-augmented latent representation i-th frame bidirectional lstm networks respectively. frame activations temporal dimension softmax function given proposed attention networks enable progressive joint representation learning multimodal temporal attentional video semantic attributes textual question further improve performance video question answering. construct large-scale dataset video question answering. evaluate performance method multiple choice open-ended video question answering tasks. presenting method ﬁrst introduce basic notions terminologies. denote question video attributes respectively. framelevel representation video given length video denote frame-level representation attribute video attributes i-th frame. denote vocabulary dictionary one-hot word representation. since video question content sequential data variant length natural choose variant recurrent neural network called long-short term memory network speciﬁcally learn feature representation video question bidirectional lstm consists forward lstm backward lstm backward lstm network structure forward input sequence reversed. denote hidden state forward attention score. thus temporally attended video representa= i❕vi incorporate multi-step reasoning process proposed attribute-augmented attention networks improve performance question-oriented video representation video question answering. given attribute-augmented attention network video question attribute-augmented attention network learning multi-step reasoning process given recursively updated. joint question-oriented video representation returned r-th reasoning process update given learning process reasoning attributeaugmented attention networks case illustrated figure next present objective function method multiple-choice open-ended video question answering tasks. training model multiple-choice task model video question answering classiﬁcation problem pre-deﬁned classes. given updated joint question-oriented video representation softmax function employed classify possible answers video. split generated dataset three parts training validation testing sets. three types video question-answering pairs used experiments summarized table dataset provided later. preprocess video question-answering dataset follows. ﬁrst sample frames video resize frame extract visual representation frame pretrained resnet take dimensional feature vector frame employ pretrained wordvec model extract semantic representation questions answers speciﬁcally size vocabulary dimension word vector training model open-ended video question answering task token <eos> mark answer phrase take token <unk> out-of-vocabulary word. evaluate performance proposed r-anl method multiple-choice open-ended video question answering tasks using evaluation criteria accuracy. given testing question video groundtruth answer denote predicted answer r-anl method introduce evaluation criteria accuracy below accuracy means generated answer ground-truth ones exactly same accuracy means opposite. performance multiple-choice video question answering task value mean-pooling layer obtains joint video representation resnet-based frame features computes joint representation question embedding video representation element-wise multiplication generating open-ended answers. unlike previous visual question answering works r-anl method learns question-oriented video question multiple reasoning process problem video question answering. study eﬀectiveness attribute-augmented mechanism parameter matrix bias vector. hand training model open-ended video question answering employ lstm decoder generate freeform answers based updated joint question-oriented video representation given video question ground-truth answer generated answer loss function given indicator function. denote model coeﬃcients including neural network parameters result embeddings therefore objective function learning process given construct dataset video question-answering youtubetext data natural language descriptions consists videos descriptions. following state-of-the-art question generation method generate questionanswer pairs video descriptions. following existing visual question answering approaches generate three types questions related what queries attention network evaluate method without attributes denoted r-anl. exploit eﬀect reasoning process denote r-anl method reasoning steps r-anl. input words method initialized pretrained word embeddings size weights lstms randomly gaussian distribution zero mean. table shows overall experimental results methods open-ended multiple-choice video question answering tasks diﬀerent types questions. hyperparameters parameters achieve best performance validation chosen conduct testing evaluation. report average value methods three evaluation criteria. give example experimental results method figure paper study problem video question answering viewpoint attribute-augmented attention network learning. ﬁrst propose attribute-augmented method learns joint representation visual frame textual attributes. develop attribute-augmented attention network learn question-oriented video representation question answering. next incorporate multi-step reasoning process proposed attention network improve performance method problem. construct large-scale video question answering dataset evaluate eﬀectiveness proposed method extensive experiments. work supported national natural science foundation china grant no.. also supported fundamental research funds central universities zhejiang natural science foundation under grant china knowledge centre engineering sciences technology. references stanislaw antol aishwarya agrawal jiasen margaret mitchell dhruv batra lawrence zitnick devi parikh. visual question answering. iccv. sergio guadarrama niveda krishnamoorthy girish malkarnenkar subhashini venugopalan raymond mooney trevor darrell kate saenko. youtubetext recognizing describing arbitrary activities using semantic hierarchies zero-shot recognition. iccv. xiangnan ming min-yen dingxian wang. birank towards ranking bipartite graphs. ieee trans. knowl. data eng. xiangnan lizi liao hanwang zhang liqiang tat-seng meng wang richang hong guangda zheng-jun shuicheng tat-seng chua. event driven video summarization localization key-shot identiﬁcation. ieee trans. multimedia hanwang zhang xindi shang huanbo luan meng wang tat-seng chua. learning collective intelligence feature learning using social images tags. ieee trans. multimedia hanwang zhang zheng-jun yang yang shuicheng tatseng chua. attribute-augmented semantic hierarchy towards bridging semantic intention image retrieval. zhou zhao hanqing vincent zheng deng xiaofei yueting zhuang. community-based question answering asymmetric multifaceted ranking network learning. aaai.", "year": 2017}