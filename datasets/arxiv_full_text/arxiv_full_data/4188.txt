{"title": "Algorithms for Semantic Segmentation of Multispectral Remote Sensing  Imagery using Deep Learning", "tag": ["cs.CV", "cs.AI"], "abstract": "Deep convolutional neural networks (DCNNs) have been used to achieve state-of-the-art performance on many computer vision tasks (e.g., object recognition, object detection, semantic segmentation) thanks to a large repository of annotated image data. Large labeled datasets for other sensor modalities, e.g., multispectral imagery (MSI), are not available due to the large cost and manpower required. In this paper, we adapt state-of-the-art DCNN frameworks in computer vision for semantic segmentation for MSI imagery. To overcome label scarcity for MSI data, we substitute real MSI for generated synthetic MSI in order to initialize a DCNN framework. We evaluate our network initialization scheme on the new RIT-18 dataset that we present in this paper. This dataset contains very-high resolution MSI collected by an unmanned aircraft system. The models initialized with synthetic imagery were less prone to over-fitting and provide a state-of-the-art baseline for future work.", "text": "deep convolutional neural networks used achieve state-of-the-art performance many computer vision tasks thanks large repository annotated image data. large labeled datasets sensor modalities e.g. multispectral imagery available large cost manpower required. paper adapt state-of-the-art dcnn frameworks computer vision semantic segmentation imagery. overcome label scarcity data substitute real generated synthetic order initialize dcnn framework. evaluate network initialization scheme rit- dataset present paper. dataset contains very-high resolution collected unmanned aircraft system. models initialized synthetic imagery less prone over-ﬁtting provide state-of-the-art baseline future work. semantic segmentation pixel-wise classiﬁcation image i.e. every pixel assigned label. remote sensing semantic segmentation non-rgb imagery numerous applications land-cover classiﬁcation vegetation classiﬁcation urban planning semantic segmentation heavily studied remote sensing computer vision. recent years performance semantic segmentation algorithms scenes rapidly increased deep convolutional neural networks dcnns semantic segmentation typically ﬁrst trained large image classiﬁcation datasets million labeled training images. then pre-trained networks adapted semantic segmentation task. two-step procedure necessary dcnns process high-resolution color images millions parameters e.g. vgg- million parameters semantic segmentation datasets computer vision small good settings randomly initialized dcnn parameters over-ﬁtting would likely occur without pre-trained networks. example evaluate semantic segmentation method pascal datasets state-of-the-art methods dcnn pre-trained imagenet ﬁne-tune semantic segmentation coco dataset ﬁne-tune pascal utilizing pre-trained networks prevent overﬁtting works well imagery massive labeled datasets available; non-rgb domain label scarcity greater problem. example existing semantic segmentation benchmarks hyperspectral imagery consist single image mosaic. therefore pre-training dcnns hand-labeled datasets consisting real images currently possible non-rgb domains. paper explore alternative approach using vast quantities automatically-labeled synthetic multispectral imagery pre-training dcnn-based systems semantic segmentation. propose digital imaging remote sensing image generation modeling software generate large quantities synthetic corresponding label maps. dirsig build large diverse scene model simulate various weather lighting conditions. capture synthetic aerial images scene sensor model. synthetic data initialize dcnn object recognition combine pre-trained dcnn diﬀerent fully-convolutional semantic segmentation models using real msi. past researchers used dcnns pre-trained imagenet yield state-of-the-art results semantic segmentation high-resolution multispectral aerial imagery widely used benchmarks single non-rgb band. happens spectral range dataset increases? real used evaluate network initialization scheme comes semantic segmentation dataset built called rit-. rit- consists high-resolution acquired unmanned aircraft system primary dataset evaluating semantic segmentation frameworks designed non-rgb remote sensing imagery. dataset shown fig. split training validation testing folds provide standard state-of-the-art comparison demonstrate feasibility deploying algorithms realistic setting. baseline results demonstrate large spatial variability commonly associated high-resolution imagery large sample size small hidden objects unbalanced class distribution make diﬃcult dataset perform well making excellent dataset evaluating dcnn frameworks semantic segmentation. contributions paper makes three major contributions ﬁrst adapt recent fully-convolutional dcnns semantic segmentation multispectral remote sensing imagery; demonstrate pretraining networks synthetic imagery signiﬁcantly improve performance; describe rit- dataset evaluating semantic segmentation algorithms. paper pixel-wise classiﬁcation semantic segmentation synonymous. semantic segmentation term commonly used computer vision becoming increasingly used remote sensing. stateof-the-art semantic segmentation frameworks imagery trained end-to-end consist convolution segmentation sub-networks. convolution network usually pre-trained dcnn designed classify images imagenet current state-of-the-art performers vgg- resnet segmentation network appended convolution network designed reconstruct feature response spatial dimensions input assigning semantic labels. resulting semantic segmentation network ﬁne-tuned orders magnitude fewer training images convolutional network already trained. describe ﬁrst fully-convolutional network designed semantic segmentation used vgg- network approximately million parameters. vgg- trained image classiﬁcation imagenet rather directly semantic segmentation. model used coarse upsampling deconvolution segmentation network classify pixel. net’s major disadvantage vgg-’s max-pooling layers shrunk original image factor resulting coarse label proposed improve model building symmetric network using spatial unpooling deconvolution layers. increased performance classifying objects multiple resolutions however still produced coarse label map. post-processing step authors used conditional random ﬁeld sharpen classiﬁcation boundaries major downside deconvolution network required memory time train compared deeplab semantic segmentation network built resnet dcnn. deeplab mitigates downsampling issues makes segmentation boundaries sharper replacing conventional convolution layers atrous convolutions. atrous convolution ﬁlter ﬁlled zeros sample points; although eﬀective size ﬁlter increases number trainable parameters remains constant. ﬁlters convolved image preserve original dimensions. authors found using atrous ﬁlters throughout entire network ineﬃcient used conventional atrous ﬁlters reducing image factor eight. dense used post-processing step make predicted label sharper. many earlier models used post-processing step sharpen classiﬁcation masks better allow network directly optimize towards creating sharper label mask. recent models this sharpmask reﬁnenet used skip-connections incorporate image reﬁnement end-to-end model. sharpmask used reﬁnement module combine features convolution network upsampled features segmentation network. reﬁnenet improved sharpmask model multi-resolution fusion combine features diﬀerent scales chained residual pooling capture background context residual convolutional units improve end-toend training. paper adapt sharpmask reﬁnenet models multispectral remote sensing imagery evaluate proposed initialization procedure. dcnn algorithms described detail sections deep learning approaches classify analyze remote sensing imagery advanced considerably thanks deep learning including dcnns pre-trained imagenet unsupervised feature extraction deep-learning frameworks semantic segmentation multispectral hyperspectral images explored remote sensing community; however paucity annotated data available sensor modalities pushed researchers embrace unsupervised feature extraction methods. deep features extracted every pixel labeled data used classiﬁer often support vector machine generate pixel-wise classiﬁcation map. authors determined spatial information inﬂuenced classiﬁcation performance most current state-of-theart methods extract spatial-spectral features image data. early spatial-spectral feature extractors hyperparameters required tuning gabor sparse coding extended morphological attribute proﬁles etc). hand-crafted features could fail generalize well across multiple datasets replaced learned features automatically tuned data itself. arguably successful learned feature extraction methods remote sensing imagery stacked autoencoder autoencoder unsupervised neural network learns eﬃcient encoding training data. autoencoders stacked together learn higher feature representations. stacked sparse autoencoders used learn feature extracting ﬁlters hyperspectral image ﬁlters used classify image well diﬀerent target image. ssae features learned dataset failed properly transfer andataset features failed generalize well. possible overcome limitation would unsupervised training idea explored authors showed training large quantities unlabeled hyperspectral data known self-taught learning improved classiﬁcation performance. authors proposed diﬀerent frameworks semantic segmentation used selftaught learning multi-scale independent component analysis stacked convolutional autoencoders scae outperformed mica experiments approaches advanced state-of-the-art across three benchmark datasets showing self-taught features work well multiple images. resolution available image data increased researchers explored geographic object based image analysis deal high spatial variability image data. according geobia involves development automated methods partition remote sensing imagery meaningful image-objects assessing characteristics spatial spectral temporal scales generate geographic information gis-ready format. model generate superpixels clustering segmenting techniques extrapolate information superpixel information assign appropriate label superpixel. clustering/segmenting image superpixels could prevent salt-and-pepper misclassiﬁcation errors characteristic high-resolution imagery. another strategy mitigating type error post-processing classiﬁcation markov random field classifying superpixels also older semantic segmentation strategy found computer vision literature development ﬁrst end-to-end semantic segmentation framework. fully-convolutional neural network require time-consuming segmentation technique could trained end-to-end increased classiﬁcation performance reduced time required make prediction. also used tighten classiﬁcation boundaries classiﬁcation maps. addition skip-connections pass low-level features segmentation network shown tighten classiﬁcation boundaries reduce salt-andpepper errors end-to-end semantic segmentation frameworks. remote sensing semantic segmentation datasets imaged airborne satellite platforms. existing publicly available datasets shown table gold-standard benchmark semantic segmentation visual near-infrared vaihingen potsdam datasets hosted international society photogrammetry remote sensing datasets comparably high spatial resolution classes. newer datasets zurich evlab-ss sacriﬁced spatial resolution include additional labeled classes. additional competitions hosted ieee geoscience remote sensing society kaggle involve fusion multi-modal imagery captured diﬀerent ground sample distances rit- vnir spectral bands including additional bands included isprs benchmarks. additional bands increase discriminative power classiﬁcation models vegetation heavy scenes table benchmark semantic segmentation datasets year released sensor collected ground sample distance meters number labeled object classes rit- dataset bold. synthetic data used increase amount training data systems deep neural networks done many applications including object detection pose estimation face hand-writing recognition semantic segmentation past work used various methods generate large quantities synthetic data including geometric/color transformations modeling virtual reality emulators. major upside synthetic imagery normally cheaper easier obtain images manually annotated humans; however diﬀerence feature-space distributions also known synthetic make diﬃcult transfer features synthetic real imagery. researchers adopted domain adaptation techniques mitigate phenomenon including training autoencoders shift distribution synthetic data distribution real data allow classiﬁer trained using synthetic images make predictions real data. network ﬁne-tuning widely-adopted computer vision community re-purposing dcnns trained image classiﬁcation variety alternative applications semantic segmentation. typically portion network pre-trained large image classiﬁcation dataset adapted dataset diﬀerent class labels feature distributions. however possible synthetic data instead. authors built synthetic dataset using virtual reality generator semantic segmentation autonomous driving datasets combined synthetic real imagery train semantic segmentation model. paper initialized resnet- dcnn classify synthetic ﬁne-tuned weights perform semantic segmentation real msi. section ﬁrst describe generated synthetic imagery pre-training dcnns classify data. describe fully convolutional semantic segmentation algorithms adapt imagery. lastly describe simple baseline state-of-the-art algorithms semantic segmentation remote sensing imagery serve comparison models. publicly-available imagenet sized datasets nonrgb sensor modalities used dirsig build large synthetic labeled dataset semantic segmentation aerial scenes. dirsig software tool used heavily remote sensing industry model imaging sensors prior development. used simulate imaging platforms sensor designs including monochromatic multispectral hyperspectral thermal light detection ranging dirsig images object/scene using physics-based radiative transfer/ propagation modeling realistic object deﬁned dirsig environment geometry textures bi-directional reﬂection distribution function surface temperature predictions etc. custom sensor platform deﬁned dirsig environment ﬂy-over scene image position sun/moon atmosphere proﬁle ﬂight plan modiﬁed generate realistic data well provide pixel-wise classiﬁcation map. used synthetic scene shown fig. resembles trona unincorporated area southern california. industrial residential scene containing labeled classes including buildings vehicles swimming pools terrain desert plant life. times higher; however trona available scene suﬃciently large enough object classes accurate ground truth map. mitigate problem forced networks learn scaleinvariant features generating multiple gsds accomplished ﬂying simulated diﬀerent elevations. drone across entire synthetic scene overlap make sure objects located edges images located near center images. varied time-of-year time-of-day corresponding atmospheric conditions semantic label pixel dominant class lies within instantaneous ﬁeld view pixel. built ﬁnal synthetic dataset breaking scene smaller image patches resulting million training thousand validation msi. label image majority category present. several ways sharpen object boundaries classiﬁcation map. post-processing techniques fully-connected used eliminate small errors sharpen object boundaries. geobia methods superpixel boundaries help sharpen output mask. authors combined features superpixel features increase detail object boundaries reduce salt-and-pepper noise. crfs geobia methods require additional step sharpen output mask adds additional processing time; many cases requires tuning additional hyperparameters. paper adapted recent fully-convolutional deep neural networks semantic segmentation sharpmask reﬁnenet produced state-ofthe-art results standard semantic segmentation benchmarks computer vision. sharpmask reﬁnenet models designed learn mask sharpening operation respective end-to-end frameworks withpost-processing clustering/segmenting image. done passing lower level features dcnn parts segmentation network responsible upsampling feature map. restores high spatial frequency information lost feature downsampled. proved network architecture scheme proposed batch-normalization relu applied prior convolution. models implemented using theano/keras trained computers nvidia geforce titan graphical processing unit intel core processor ram. goal compare performance algorithms baseline state-of-the-art methods semantic segmentation remote sensing imagery measure beneﬁt pre-training synthetic imagery. sharpmask model used paper illustrated fig. network broken convolution bridge segmentation subnetworks. note sharpmask resnet- model. shown fig. uses ﬁrst four macro-layers. macro-layer contains convolution batch-normalization relu activation layers right feature down-sampled factor corresponds ﬁrst resnet- convolution layers. sharpmask developed facebook lightweight fast possibly deployment platform size weight power constraints limited tested compared classiﬁcation figure sharpmask model. spatial dimensions module’s output provided illustrate reﬁnement layer combines features feed-forward network upsampled features reverse network restore original image dimensions. output class probability matrix pixel. performance prediction time models various capacities including models used ﬁrst three four resnet macro-layers. trade-oﬀ study showed sharpmask four macro-layers provided desired classiﬁcation accuracy also providing speed-up previous state-of-the-art deepmask model. slightly modiﬁed sharpmask model retain batch normalization layers regularization. volution segmentation networks selected trade-oﬀ between performance speed. main goal network variability features segmentation network reﬁnement module value worked well preliminary experiments. segmentation network uses reﬁnement modules restore bridge layer output original dimensionality input data. instead using fully-connected segmentation sharpening learned part end-to-end network. reﬁnement module merges low-level spatial features convolution network high-level semantic content segmentation network illustrated fig. reﬁnement module uses convolution sum-wise merge layers prior upsampling feature response. upsampled feature response reﬁnement module next higher dimension. number reﬁnenet model used paper follows basic structure sharpmask model minor changes. reﬁnement block fig. replaced complex block called reﬁnenet broken three main components residual convolution units multi-resolution fusion chained residual pooling model uses batch normalization regularization. convolutional network uses resnet- macro-layers using every convolution layer resnet- except softmax classiﬁer. rcus used propagate gradient across shortlong-range connections makes end-to-end training eﬀective eﬃcient. used combine features multiple scales paper two. module pools features across multiple window sizes capture background context important discriminating classes spatially spectrally similar. fig. uses window sizes illustrate works; however model pools features across four window sizes. rit- dataset compared models number classic classiﬁcation approaches including classifying individual mean-pooled pixels. also used spatial-spectral feature extraction methods mica scae recently achieved state-of-the-art performance semantic segmentation hyperspectral imagery. methods unsupervised learning acquire spatial-spectral feature representations making sample eﬃcient. simple approach semantic segmentation widely used remote sensing running classiﬁer directly individual pixel. using approach establish baseline results using three diﬀerent classiﬁers k-nearest neighbor linear support vector machine multilayer perceptron also used spatial mean-pooling simple incorporating neighboring spatial information classiﬁer. linear used liblinear implementation works well large datasets. training uses regularization adopts one-vs-rest paradigm multi-class classiﬁcation. input scaled zero-mean/unit-variance mean standard deviation computed using training data. used rit-’s validation implementation fully-connected neural network single hidden-layer units chosen cross-validation. hidden layer preceded batch-normalization layer followed relu activation. compensate class unbalance assign class distinct weights given class classes tunable parameter. trained using nadam optimizer batch size regularization value convolution batch normalization layers class weighted update equation running classiﬁers individual pixels ignores neighboring pixel information. negatively impact performance high spatial variability commonplace high resolution imagery. address this also mica achieved excellent performance semantic segmentation data baseline algorithms. mica uses unsupervised learning algorithm independent component analysis learn spatial-spectral ﬁlter bank images captured sensor. ﬁlters acquires exhibit color opponency resemble gabor-type ﬁlters. ﬁlters convolved image like single layer convolutional neural network responses normalized using non-linear activation function. responses pooled incorporate translation invariance classiﬁer applied pooled responses. original paper used rbf-svm classify responses feasible size rit-. instead responses classiﬁer. excellent results semantic segmentation hyperspectral imagery scae extracts features using stacked convolutional autoencoders pre-trained using unsupervised learning. scae deeper neural network architecture mica capable extracting higher-level semantic information. scae model used paper almost identical training validation datasets. increase receptive ﬁeld size done compensate higher imagery assisted model learning local relationships object classes. second network capacity convolutional autoencoder decreased compensate reduced dimensionality rit- units ﬁrst convolution block units second convolution block units third mean-pooling ﬁlter reduced original variance using whitened principal component analysis ﬁnal feature response passed classiﬁer architecture used mica model section rit- high-resolution benchmark designed evaluate semantic segmentation collected uas. collection nonrgb imagery grown popularity especially precision agriculture cost eﬀective manned ﬂights provides better spatial resolution satellite imagery. cost savings allows user collect data frequently increases temporal resolution data well. applications payloads include crop health sensing variable-rate nutrient application prescription irrigation engineering crop-ﬁeld variability imagery dataset collected hamlin beach state park located along coast lake ontario hamlin training validation data collected location test data collected diﬀerent location park. locations unique equipment used build dataset information ﬂight listed table tetracam micro-mca sensor independent optical systems bandpass ﬁlters centered across vnir spectrum. micro-mca used on-board uass perform vegetation classiﬁcation orthomosaic imagery assess crop stress measuring variability chlorophyll ﬂuorescence acquisition biophysical parameters fig. shows image micro-mca mounted on-board dji-s octocopter. rit- dataset split training validation testing folds. fold contains orthomosaic image corresponding classiﬁcation map. orthomosaic contains six-band image described section appendix along mask image data valid. table lists class labels rit-. orthomosaic handannotated using region-of-interest tool envi. several individuals took part labeling process. information classes found appendix proximately million dirsig training images. network trained using mini-batch size weight-decay weights randomly initialized zero-mean normal distribution. labels provided dirsig class-label pixel; however resnet- dcnn trained perform image classiﬁcation. assigned label image patch based common label. compute channel-mean standard-deviation using entire dirsig training parameters used scale image zero-mean/unit-variance. training images shuﬄed epoch random horizontal vertical ﬂips data augmentation. class distribution dirsig data unbalanced class-weights entire training build sample weights. class-weights assigned using equation optimized network using nadam initial learning rate dropped learning rate validation loss plateaued. trained semantic segmentation frameworks using randomly initialized dcnns dcnn pre-trained dirsig dataset. high-resolution orthomosaic data broken initialized models trained end-to-end stage ﬁlters dcnn need tuned. weights come pre-trained dcnn randomly initialized zero-mean gaussian distribution. models pre-training initial learning rate used learning rate dropped factor four times validation loss plateaued. models pre-trained dcnn train stages. first pre-trained portion model frozen remaining layers trained adapt weights segmentation network pre-trained weights convolution network. initial learning rate used stage dropped factor validation loss plateaus. second ﬁne-tune pre-trained portion segmentation network jointly using initial learning rate again drop factor four times validation loss plateaued. models optimized using nadam optimizer batch size weight decay class-weight parameter optimizes plots training validation accuracy loss models provided appendix observed pre-trained models especially reﬁnenet saturated peak accuracy quickly randomly initialized networks weights close ﬁnal solution. ﬁne-tuned models continue make minor improvements longer period time employs lower learning rate prevent completely overwriting pre-trained dirsig weights; whereas random weight initialization stops training quickly attempting preserve pre-trained weights. results algorithms rit- test listed table table shows classiﬁcation performance dcnn segmentation models without initializing network using synthetic data. pretraining resnet- dcnn synthetic imagery required three weeks gpu. number batch updates performed higher number performed network ﬁne-tuning operation took hours sharpmask hours reﬁnenet. algorithm evaluated per-class accuracy mean-class accuracy used primary metric disparity class distribution algorithms except trained compensate class unbalance. random chance assigning class given pixel models perform poorly classes especially classes perform worse chance over-ﬁt perform better classes training samples. synthetic image initialization used sharpmask reﬁnenet outperform algorithms mean-class accuracy performance demonstrating advanced techniques used computer vision eﬀectively used remote sensing data. mean-class accuracy best performing model reﬁnenet-sim. models pre-training perform better classes samples mean-class accuracy shows models discriminative counterparts initialized synthetic data. reﬁnenet-rdm overﬁt classes samples whereas reﬁnenet-sim discriminative pre-trained resnet- weights. reﬁnenet-sim’s results greater reﬁnenet-rdm. discrepancy likely reﬁnenet times many trainable parameters compared sharpmask. sharpmask relatively shallow semantic segmentation framework uses early layers resnet- million trainable parameters. comparison reﬁnenet million trainable parameters. parameters model greater capacity parameters also mean labeled data needed prevent overﬁtting. suspect deeper pre-trained network used e.g. resnet- would even greater diﬀerences pre-trained randomly initialized models. comparing baseline models mica yielded percent increase mean-class accuracy simpler experiment demonstrating unsupervised feature extraction boost classiﬁcation performance high-resolution imagery. unlike earlier work mica outperformed scae showing low-level features larger receptive ﬁeld could important higher-level features smaller spatial extent. models failed classify black panel low-level vegetation pond. according confusion matrices black-panel predominantly misclassiﬁed asphalt likely black-panel training samples shared similar spatial/spectral characteristics vnir spectrum. low-level vegetation misclassiﬁed trees pond water misclassiﬁed grass/lawn similar reasons. large portions pond especially test image contain vegetation on-top water could confused grass. possible solution correcting problem initialize dcnn dirsig imagery replicates conditions fig. shows sample predictions made sharpmask-sim reﬁnenet-sim frameworks. sharpmask better classifying road road markings vehicles; reﬁnenet fewer classiﬁcation artifacts beach area. shows certain model architectures robust illumination invariance rough surfaces caused brdf eﬀects. reﬁnenet likely robust extracts features deeper convolutional layers chained residual pooling aids capturing background context. models good classifying grass part lake; however low-level vegetation area seemed road markings tree building vehicle person lifeguard chair picnic table black panel white panel orange buoy rocks vegetation grass/lawn sand/beach water water asphalt table per-class accuracies well mean-class accuracy rit- test set. initializations used sharpmask reﬁnenet models include random initialization network initialized synthetic data compare results benchmark classiﬁcation frameworks listed section mis-classiﬁed trees orders magnitude training samples. sharpmask reﬁnenet would also tend mis-classify parts lake ontario wave-crest whiter rest body water rocks. likely rocks rit- dominantly surrounded darker lake water dcnn models trained associate relatively brighter patches lake rocks. could remedied training revisiting areas lake higher spatial variability collecting additional examples white wavecrests occur. first trained model diﬀerent channels. analysis shown table includes bands three bands false-color image four band rgbnir band used svm-cir svmvnir experiments. road markings tree building vehicle person lifeguard chair picnic table black panel white panel orange buoy rocks vegetation grass/lawn sand/beach water water asphalt performance; consistent fact scene vegetation. test hypothesis pre-trained resnet- using -band dirsig data used ﬁne-tune reﬁnenet ﬁrst four spectral channels rit-. results -band model compared full -band model shown table results indicate micro-mca increase classiﬁcation performance compared simpler band systems. -band solution overﬁts dominant classes rit-. type sensor could future provide option ﬁne-grained classiﬁcation various plant life. paper demonstrated utility architectures semantic segmentation remote sensing msi. end-to-end segmentation model uses combination convolution pooling operations capable learning global relationships object classes eﬃciently traditional classiﬁcation methods. table showed end-toend semantic segmentation framework provided superior classiﬁcation performance fourteen eighteen classes rit- demonstrating learned features supervised dcnn frameworks discriminative features built unsupervised learning methods. showed generated synthetic imagery used eﬀectively initialize dcnn architectures oﬀset absence large quantities annotated image data. models initialized randomly showed degraded mean-class accuracy good metric datasets unbalanced class distributions. dirsig could used generate large custom datasets imaging modalities multispectral hyperspectral lidar combination above. types scenes could developed thanks increase collection remote sensing data. work could adapted sensors. evolving multispectral hyperspectral data likely require modiﬁcations current models order deal higher dimensionality. initializing networks using dirsig could improve semantic segmentation also networks tasks object detection target tracking hyperspectral imagery. finally introduced rit- dataset benchmark semantic segmentation msi. dataset beneﬁts higher spatial resolution large number object classes wider spectral coverage improve performance vegetation-heavy scenes. datasets built platforms could practical commercial research purpose. orthomosaic generation pipeline provided appendix could utilized quickly generate remote sensing products little intervention. absolute accuracy orthomosaic images rit- limited feet accuracy on-board gps. keeps able overlay dataset imagery; however aﬀect semantic segmentation results since images registered relative another. recently acquired higher-accuracy inertial navigation system make overlaying multiple sensors possible future collections. addition ability quickly accurately register multi-modal remote sensing data could enable construction larger dirsig scenes improved spatial spectral resolution. increase quantity quality synthetic imagery could improve network initialization scheme proposed paper sensor modality. shown synthetic imagery used assist training end-to-end semantic segmentation frameworks enough annotated image data. network initialization scheme shown increase semantic segmentation performance compared traditional classiﬁers unsupervised feature extraction techniques. features learned synthetic data successfully transfered real-world imagery prevented reﬁnenet-sim model overﬁtting training. work enable remote sensing researchers take advantage advancements deep-learning previously available lack annotated image data. addition introduced rit- dataset improved challenging benchmark semantic segmentation msi. make data available ieee grss evaluation server order standardize evaluation semantic segmentation frameworks. although largest rit- practical platforms easier/cheaper rit- diﬃcult perform well high-spatial variability unbalanced class distribution. future hope improve model exploring deeper resnet models; using newer state-of-the-art convolution segmentation models; improving inherent dirsig scene; including additional diverse classes synthetic data. techniques development discriminative frameworks yield superior performance. would like thank nina raqueno paul sponagle timothy bausch michael mcclelland members signature interdisciplinary research area research laboratory supported data collection. would also like thank michael gartley dirsig support.", "year": 2017}