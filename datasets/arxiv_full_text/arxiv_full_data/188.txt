{"title": "Synthesizing the preferred inputs for neurons in neural networks via  deep generator networks", "tag": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "abstract": "Deep neural networks (DNNs) have demonstrated state-of-the-art results on many pattern recognition tasks, especially vision classification problems. Understanding the inner workings of such computational brains is both fascinating basic science that is interesting in its own right - similar to why we study the human brain - and will enable researchers to further improve DNNs. One path to understanding how a neural network functions internally is to study what each of its neurons has learned to detect. One such method is called activation maximization (AM), which synthesizes an input (e.g. an image) that highly activates a neuron. Here we dramatically improve the qualitative state of the art of activation maximization by harnessing a powerful, learned prior: a deep generator network (DGN). The algorithm (1) generates qualitatively state-of-the-art synthetic images that look almost real, (2) reveals the features learned by each neuron in an interpretable way, (3) generalizes well to new datasets and somewhat well to different network architectures without requiring the prior to be relearned, and (4) can be considered as a high-quality generative method (in this case, by generating novel, creative, interesting, recognizable images).", "text": "deep neural networks demonstrated state-of-the-art results many pattern recognition tasks especially vision classiﬁcation problems. understanding inner workings computational brains fascinating basic science interesting right—similar study human brain—and enable researchers improve dnns. path understanding neural network functions internally study neurons learned detect. method called activation maximization synthesizes input highly activates neuron. dramatically improve qualitative state activation maximization harnessing powerful learned prior deep generator network algorithm generates qualitatively state-of-the-art synthetic images look almost real reveals features learned neuron interpretable generalizes well datasets somewhat well different network architectures without requiring prior relearned considered high-quality generative method understanding human brain works long-standing quest human history. neuroscientists discovered neurons human brains selectively response speciﬁc abstract concepts halle berry bill clinton shedding light question whether learned neural codes local distributed neurons identiﬁed ﬁnding preferred stimuli highly excite speciﬁc neuron accomplished showing subjects many different images recording target neuron’s activation. neurons multifaceted example halle berry neuron responds different stimuli related actress—from pictures face pictures costume word halle berry printed text inspired neuroscience research interested shedding light inner workings dnns ﬁnding preferred inputs neurons. neuroscientists could simply show network large images record images highly activate neuron however method disadvantages synthesizing preferred stimuli requires distribution images similar used train network known even dataset many informative images would activate neuron exist image space vast real images unclear features neuron learned example neuron activated picture lawn mower grass unclear figure images synthesized scratch highly activate output neurons caffenet deep neural network learned classify different types imagenet images. examples showcasing sample quality comparison real images fig. ‘cares about’ grass image synthesized highly activate lawn mower neuron contains grass conﬁdent neuron learned attention context. synthesizing preferred stimuli called activation maximization starts random image iteratively calculates backpropagation color pixel image changed increase activation neuron. previous studies shown without biasing images produced creates unrealistic uninterpretable images possible images vast possible produce ‘fooling’ images excite neuron resemble natural images neuron learned detect. instead must constrain optimization generate synthetic images resemble natural images attempting accomplished incorporating natural image priors objective function shown substantially improve recognizability images generated many handdesigned natural image priors experimentally shown improve image quality gaussian blur α-norm total variation jitter data-driven patch priors center-bias regularization initializing mean images instead hand-designing priors paper propose superior learned natural image prior akin generative model images. prior allows synthesize highly human-interpretable preferred stimuli giving additional insight inner functioning networks. rigorously measure human-interpretability problem also makes quantitatively assessing generative models near-impossible cease scientiﬁc work improving qualitative results simply humans must subjectively evaluate them. learning generative models natural images long-standing goal machine learning many types neural network models exist including probabilistic auto-encoder stochastic recurrent networks however typically limited relatively low-dimensional images narrowly focused datasets. recently advances network architectures training methods enabled generation high-dimensional realistic images works based generative adversarial networks trains models simultaneously generative model capture data distribution discriminative model estimates probability sample came training data rather training objective maximize probability making mistake. recently dosovitskiy brox trained networks capable generating images highly compressed feature representations combining auto-encoder-style approach gan’s adversarial training. harness image generator networks priors produce synthetic preferred images. generator networks close true generative models trained without imposing prior hidden distribution variational auto-encoders gans without addition noise denoising auto-encoders thus natural sampling procedure implicit density function data space. image generator prior trained take code output synthetic image looks close real images imagenet dataset possible. produce preferred input neuron given want visualize figure synthesize preferred input target neuron optimize hidden code input deep image generator network produce image highly activates example shown network trained invert feature representations layer caffenet. target visualized different network gradient information ﬂows layer containing target image back input code layer dgn. note target visualized ﬁxed parameters optimization changes input code optimize input code space image generator outputs image activates neuron interest method restricts search images drawn prior provides strong biases toward realistic visualizations. algorithm uses deep generator network perform activation maximization call dgn-am. networks visualize. demonstrate visualization method variety different networks. reproducibility pretrained models freely available caffe caffe model caffenet googlenet resnet represent different convnet architectures trained ∼.-million-image imagenet dataset default caffenet minor variant common alexnet architecture similar performance last three fully connected layers -layer caffenet called last layer outputs imagenet class. image generator network. denote want visualize instead previous works directly optimized image highly activates neuron optionally satisﬁes hand-designed priors embedded cost function optimize input code image generator network outputs image highly activates networks made publicly available trained principles gans reconstruct images hidden-layer feature representations within caffenet trained includes important differences original conﬁguration brieﬂy summarize training procedure; please details. training process involves four convolutional networks ﬁxed encoder network inverted generator network ﬁxed comparator network discriminator trained invert feature representation extracted network satisfy three objectives feature vector synthesized image close original image features output image close real image unable distinguish real images. objective discriminate synthetic images real images original paper encoder caffenet truncated different layers. denote caffenet truncated layer network trained invert comparator caffenet layer pool. convolutional network convolutional fully connected layers. upconvolutional architecture upconvolutional fully connected layers. detailed architectures provided synthesizing preferred images neuron. intuitively search input code space image generator model code image produces high activation target neuron want visualize recall generator network trained reconstruct images l-th layer features caffenet. formally including regularization term pose activation standard deviation around mean activation clipping acts primitive prior code space substantially improves image quality. future work plan learn prior generative model. true goal activation maximization generate interpretable preferred stimuli neuron performed random search hyperparameter space consisting weight number iterations learning rate. chose hyperparameter settings produced highest quality images. note found correlation activation neuron recognizability visualization. code parameters available http//evolvingai.org/synthesizing. since generator model could trained invert feature representations arbitrary layer sampled explore impact choice identify qualitatively produces best images. here visualize encoder different networks network chose hyperparameter settings random sample gave best qualitative results. optimizing codes convolutional layers typically yields highly repeated fragments whereas optimizing fully-connected layer codes produces much coherent global structure interestingly previous studies shown trained invert lower-layer codes results better reconstructions higher-layer codes explained low-level codes come natural images contain information image details abstract high-level codes. activation maximization however synthesizing entire layer code scratch. hypothesize process works worse priors smaller feature low-level codes small local receptive ﬁeld. optimization thus independently tune features throughout image without knowing global structure. example image four robins? fully-connected layers information areas image represent information number location size etc. object thus pixels optimized toward agreed upon structure. orthogonal non-mutually-exclusive hypothesis code space convolutional layer much high-dimensional making harder optimize. found optimizing code space produces best visualizations thus default prior experiments rest paper. addition images qualitatively appear realistic-looking compared visualizations previous methods result reveals great amount detail global structure captured even last output layer. ﬁnding contrast previous hypothesis dnns trained supervised learning often ignore object’s global structure learn discriminative features class section provides evidence global structure come prior. test whether method memorizes training images retrieved closest images training sample synthetic images. speciﬁcally synthetic image output neuron image among class lowest euclidean distance pixel space done previous works also code spaces encoder dnn. much harder test comparing nearest neighbor found among entire dataset found evidence method memorizes training images believe evaluating similarity spaces deep representations better capture semantic aspects images informative approach compared evaluating pixel space. test whether prior trained inverting feature representations imagenet images generalizes enable visualizing dnns trained different datasets. speciﬁcally target output neurons dnns downloaded caffe model alexnet trained .-million-image places dataset classify types places accuracy hybrid architecture caffenet network created classify actions videos processing frame video separately. dataset consists videos categorized human action classes. prior trained imagenet images generalizes well completely different places dataset result suggests prior trained imagenet generalize natural image datasets least architecture visualized architecture encoder network generator model trained invert feature representations. prior generalizes produce decent results; however images qualitatively sharp clear orthogonal hypotheses happens heavily modiﬁed version types images different primarily object-centric imagenet dataset ucf- dataset focuses humans performing actions. sec. returns ﬁrst hypothesis regarding similarity affects image quality overall prior trained caffenet encoder generalizes well visualizing dnns caffenet architecture trained different datasets. figure preferred stimuli output units alexnet trained places dataset showing imagenet-trained prior generalizes well dataset comprised images scenes. shown visualized encoder resultant visualizations quite realistic recognizable visualize different network architecture could train invert feature representations. however training every want visualize computationally costly. here test whether prior trained caffenet used visualize state-of-the-art dnns architecturally different caffenet trained imagenet dataset. downloaded caffe model similar accuracy scores googlenet -layer network top- accuracy resnet type deep architecture skip connections visualize -layer resnet top- accuracy dgn-am produces best image quality visualization quality tends degrade architecture becomes distant here optimize single preferred image neuron classiﬁes single frames architecture caffenet resnet) alternative hypothesis network depth impairs gradient propagation activation maximization. case training general prior activation maximization generalizes well different network architectures would enable comparative analysis networks remains important open challenge. visualizing hidden neurons imagenet dnn. previous visualization techniques shown low-level neurons detect small simple patterns corners textures mid-level neurons detect single objects like faces chairs visualizations hidden neurons fully-connected layers alien difﬁcult interpret since trained invert feature representations real full-sized imagenet images possibility prior generalize producing preferred images hidden neurons often smaller different theme resemble real objects. synthesized preferred images hidden neurons layers compare images produced multifaceted feature visualization method harnesses hand-designed priors total variation mean image initialization. visualized side-by-side comparison shows methods often agree features neuron learned detect. however overall dgn-am produces realistic-looking color texture despite requiring optimization seeded averages real images thus improving ability learn feature hidden neuron learned. exception faces human animals dgn-am visualize well visualizing hidden neurons deep scene dnn. recently zhou found object detectors automatically emerge intermediate layers train classify scene categories. identify hidden neuron cares given image densely slide occluding patch across image record activation drops. activation changes aggregated segment exact region leads high neural activation identify semantics segmentations humans shown collection segmented images speciﬁc neuron asked label types image features activate neuron here compare method alexnet trained classify categories scenes places dataset prior learned imagenet generalizes visualizing hidden neurons trained places dataset interestingly visualizations produce similar results method requires showing neuron large external dataset images discover feature neuron learned detect sometimes dgn-am reveals additional information unit ﬁres screens also ﬁres people overall dgn-am thus generalizes well different dataset also produces visualizations qualitatively fall within human-provided categories type image features neuron responds figure visualizations example hidden neurons layer alexnet trained classify categories scenes unit compare visualizations produced method visualizations produced method left images real images highlighting region highly activates neuron humans provide text labels describing common theme highlighted regions. synthetic images enable conclusion regarding feature hidden neuron learned. extended version ﬁgure units fig. best viewed electronically zoom. visualizing neurons trained unseen modiﬁed images. shown dgn-am generate preferred image stimuli realistic colors coherent global structures harnessing dgn’s strong learned natural image prior extent global structure natural colors sharp textures reﬂect features learned brambling neuron preferred prior? investigate that train different dnns images less global structure images non-realistic colors blurry images. test whether dgn-am prior produces visualizations reﬂect modiﬁed unrealistic features. speciﬁcally train different dnns following caffenet architecture discriminate classes. ﬁrst classes contain regular imagenet images classes contain modiﬁed imagenet images. perform types modiﬁcations image quarters re-stitch back random order convert regular images blur images gaussian blur radius visualize groups output neurons visualizations neurons trained regular images often show coherent global structures realistic-looking colors sharpness. contrast visualizations neurons trained modiﬁed images indeed show cut-up objects images color space objects washed details results show dgn-am visualizations closely reﬂect features learned neurons data properties exclusively produced prior. visualizations neurons show canonical images? many dgn-am visualizations show global structure others otherwise non-canonical sec. describes experiments investigating whether shortcoming method whether non-canonical visualizations reﬂect property neurons. results suggest dgn-am accurately visualize class images images mostly canonical reason visualizations neurons lack global structure canonical images neuron learned detect often diverse instead canonical pose. research needed multifaceted feature visualization algorithms separately visualize type image activates neuron dgn-am also useful variety important tasks. brieﬂy describe experiments tasks refer reader supplementary section information. advantage synthesizing preferred images watch features evolve training better understand occurs deep learning. also tests whether learned prior generalizes visualizing underﬁt overﬁt networks. results suggest visualization quality indicative dnn’s validation accuracy extent learned prior overly specialized well-trained encoder dnn. sec. details. method synthesizing preferred images could naturally applied synthesize preferred videos activity recognition better understand works. example found state-of-the-art classiﬁes videos without paying attention temporal information across video frames method extended produce creative original synthesizing images activate neurons time shown activation maximization—synthesizing preferred inputs neurons neural networks—via learned prior form deep generator network fruitful approach. dgnproduces realistic-looking thus interpretable preferred images date making qualitatively state activation maximization. visualizations synthesizes scratch improve ability understand features neuron learned detect. images closely reﬂect features learned neuron visually interesting. explored variety ways dgn-am help understand trained dnns. future work dgn-am learned prior could dramatically improve ability synthesize image text description create realistic deep dream images. additionally prior used paper generalize equally well dnns different architectures motivates research train general prior. successfully could enable informative comparative analyses information transformations occur within different types dnns. authors would like thank yoshua bengio helpful discussions bolei zhou providing images study. jeff clune supported career award hardware donation nvidia corporation. jason yosinski supported nasa space technology research fellowship grant alexey dosovitskiy thomas brox acknowledge funding starting grant videolearn nguyen yosinski clune. multifaceted feature visualization uncovering different types features learned neuron deep neural networks. visualization deep learning workshop icml conference visualizations many neurons appear great-looking showing canonical images class many others investigate whether shortcoming method non-canonical visualizations actually reﬂecting property neurons. experiment visualize trained pairs classes contain canonical images visualizations reﬂect classes. speciﬁcally take classes {ci} found visualizations show canonical images school irish terrier tabby hartebeest move canonical images class class images classes. resultant classes back imagenet training train classify classes. method indeed generates canonical visualizations neurons trained canonical images result shows evidence method reﬂects well features learned neurons. result neurons trained non-canonical images appear similar many non-canonical visualizations found previously fact training classes contain small percentage images canonical school tabby irish terrier hartebeest numbers classes visualizations often show canonical images often much higher table lamp brambling lipstick joystick beacon overal evidence suggests method reﬂects well features learned neurons. seems visualizations neurons show canonical images simply features neuron learned detect diverse canonical. test visualizations under-trained well-trained overﬁt networks look image quality reﬂects generalization ability dnn. this train caffenet training hyperparameters provided caffe framework. method visualize preferred stimuli output hidden neurons network snapshots taken every iterations. resultant videos experiment available review https//www.youtube.com/watch?v=qyiwiyhfq https//www.youtube.com/watch?v=gatatmsts. result shows accuracy seems correlate visualization quality ﬁrst iterations. features appear blurry initially evolve clearer clearer accuracy increases. method used learn features learned. example looking images activate swimming trunks neuron video seems concept swimming trunks associated people blue ocean background early iterations gradually changes actual clothing item around iterations. also interested ﬁnding whether image quality would appear better worse overﬁts training data. check this re-train dnns –one original imagenet images top- training accuracy validation accuracy respectively. visualizations dnns appear recognizable worse well-trained validation accuracy training accuracy three dnns given number training updates. overall evidence supports hypothesis visualization quality correlate dnn’s validation accuracy. note true class accuracy visualizations output neurons lowest class accuracy scores still beautiful recognizable suggesting accuracy scores result confused pairs similar classes dataset result also shows learned prior overﬁt much well-trained encoder visualizations under-trained overﬁt networks still sensible. method synthesizing preferred images could naturally applied synthesize preferred videos activity recognition dnn. here synthesize videos lrcn—an activity recognition model made available donahue model combines convolutional neural network lstm recurrent network trained classify videos classes human activities ucf- dataset. synthesize video frames output neurons. resultant videos available review https//www.youtube. com/watch?v=ioyniknbg. videos appear qualitatively sensible great best images main text. explanation convolutional network lrcn model caffenet instead hybrid different popular convnet architectures interesting ﬁnding inner working speciﬁc activity recognition model care frame order explaining non-smooth transition frames synthetic videos. fact tested shufﬂing frames real video also substantially change classiﬁcation decision dnn. researchers could tool discover property given improve necessary. example could re-train lrcn make learn correct temporal consistency across frames real videos natural extension method synthesizing images activate multiple neurons time instead one. found optimizing code activate neurons time simply adding additional objective second neuron often leads neuron dominating search. example bell pepper neuron happens easier activate candle neuron ﬁnal image purely image bell pepper candles. here produce interesting results experiment encouraging neurons similarly activated. speciﬁcally additional penalty distance activations. formally pose activation maximization problem activating units weight additional penalty term. found resultant visualizations interesting diverse vary depending pair neurons activated. following cases observed activating neurons uncovering visualization unique facet either neuron. examples fig. combining american lobster candles leads image people eating lobster plate combining prison candles results outside scene prison night. judging subjective thus leave many images reader make conclusion overall found result two-fold method activating multiple neurons time could used generate creative images image generation domain; uncover unique facets neuron learned detect—a class multifaceted feature visualization introduced better understanding dnns. figure experiment take classes school irish terrier tabby hartebeest split class classes containing canonical images containing images. classes back imagenet training train classify classes. show result experiment pairs classes pair row. left panels shows random images training class right panels shows visualizations output neuron. method indeed generates canonical visualizations neurons trained canonical images. result shows evidence method reﬂects well features learned neurons. also suggests visualizations neuron show canonical images it’s likely features neuron learned detect diverse canonical figure looking visualizations output neurons found many pairs images appear similar sometimes indistinguishable human eyes hartebeest impala baboon macaque. investigate whether phenomenon reﬂecting training images shortcoming method. show pairs similar classes. pair shows training images activate neuron most bottom shows synthetic images produced method. activation score provided image. result shows preferred images closely reﬂect training images neurons trained classify. cases difference classes noticed real synthetic images bullfrog often darker rough skin compared treefrog; impala longer horns yellow skin hartebeest. cases almost indistinguishable real synthetic images indian african elephant. also attempted produce visualizations discriminative features optimizing softmax probability output layer instead activation make sure visualizations similar classes different. preliminary result shows indeed obtain distinctive patterns however future work still required fully interpret figure visualizations output neurons three dnns trained imagenet images respectively. training validation accuracy scores dnns respectively neuron show images starts different random initializations. result shows image quality somewhat reﬂects generalization ability images overﬁt dnns worse well-trained learned prior overﬁt much well-trained encoder visualizations still recognizable. dnns given number training updates. figure visualizations output neurons classes obtains highest lowest class accuracy scores. neuron show montage images starts different random initializations. montage class label class accuracy score. visualization quality neurons lowest scores still look qualitatively good neurons highest scores. suggests accuracy scores result confused pairs similar classes dataset figure visualizations optimizing image activates neurons time. panel visualizations activating single neurons. bottom panel visualizations activating brambling neuron corresponding neuron shown panel. found many combinations interesting artistically scientiﬁcally. words method novel generating images image generation domain also used uncover types preferred images neuron shedding light figure visualizations optimizing image activates neurons time. panel visualizations activating single neurons. bottom panel visualizations activating candles neuron corresponding neuron shown panel. words method novel generating images image generation domain also used uncover types preferred images neuron shedding light figure comparison results running optimization framework different priors trained invert different layer encoder network priors trained invert features fully-connected layers encoder caffenet produces better coherent global structures priors trained invert convolutional layers networks downloaded hypothesis neuron lower convolutional layer small receptive ﬁeld size input image learns detect low-level features thus optimizing code convolutional layer results repeated fragments compared optimizing fully-connected layer neurons learned care global structures another orthogonal hypothesis code space convolutional layer much high-dimensional making harder codes produces realistic-looking images. figure visualization example neuron feature detectors eight layers caffenet images reﬂect true sizes receptive ﬁelds different layers. neuron show different visualizations images previous work harnesses hand-designed prior called mean image initialization bottom images method. side-by-side comparison shows method often agree features neuron learned detect. overall method produces realistic-looking color texture. however comparison also suggests method visualize well animal faces best viewed electronically color zoom. figure visualization example neuron feature detectors eight layers alexnet trained classify categories places images reﬂect true sizes receptive ﬁelds different layers. neuron show different visualizations. similarly results method also reveals hidden neurons layer learn detect objects automatically result training classify images scenes. example unit layer ﬁres water towers fountains respectively. interesting also found neurons layer appear blend different objects together—a similar ﬁnding different trained imagenet dataset also shown fig. best viewed electronically color zoom. figure visualizations hidden neurons layer trained classify categories places left images highlights region causes high neural activation real image. highlighted region also given semantic label humans study right images visualizations method produced different random initialization. method leads conclusions neuron learned detect method zhou figure comparing previous activation maximization results method proposed paper fair comparison categories cherry-picked showcase best images instead selected based images available previous papers overall subjective judgement readers decide themselves believe method synthesizing preferred images image generator network prior produces recognizable images natural colors realistic global structure. figure comparison visualizations neurons trained regular imagenet images neurons trained cut-up images. result shows evidence learned prior strong always generates beautiful images. instead visualizations seem reﬂect closely features learned neurons features cut-up objects. figure comparison visualizations neurons trained regular imagenet images neurons trained images. result shows evidence learned prior strong always generates beautiful images. instead visualizations seem reﬂect closely features learned neurons features images completely different color space. figure comparison visualizations neurons trained regular imagenet images neurons trained blurred images. result shows evidence learned prior strong always generates beautiful images. instead visualizations seem reﬂect closely features learned neurons visualizations blurred neurons often sharp textures details washed best viewed zoom. figure test whether method memorizes training images retrieved closest images training sample synthetic images. speciﬁcally synthetic image output neuron image among images class lowest euclidean distance pixel space done previous works also code spaces encoder synthetic images result optimizing input code prior. comparing nearest neighbor among class much harder test comparing nearest neighbor among entire dataset found evidence method memorizes training images. believe evaluating similarity code spaces deep representations better capture semantic aspects images informative approach compared evaluating pixel space. figure side-by-side comparison real synthesized images. neuron show validation images highest activate given neuron synthetic images produced method dgn-am note synthetic images size", "year": 2016}