{"title": "A Useful Motif for Flexible Task Learning in an Embodied Two-Dimensional  Visual Environment", "tag": ["cs.LG", "cs.AI", "q-bio.NC", "stat.ML"], "abstract": "Animals (especially humans) have an amazing ability to learn new tasks quickly, and switch between them flexibly. How brains support this ability is largely unknown, both neuroscientifically and algorithmically. One reasonable supposition is that modules drawing on an underlying general-purpose sensory representation are dynamically allocated on a per-task basis. Recent results from neuroscience and artificial intelligence suggest the role of the general purpose visual representation may be played by a deep convolutional neural network, and give some clues how task modules based on such a representation might be discovered and constructed. In this work, we investigate module architectures in an embodied two-dimensional touchscreen environment, in which an agent's learning must occur via interactions with an environment that emits images and rewards, and accepts touches as input. This environment is designed to capture the physical structure of the task environments that are commonly deployed in visual neuroscience and psychophysics. We show that in this context, very simple changes in the nonlinear activations used by such a module can significantly influence how fast it is at learning visual tasks and how suitable it is for switching to new tasks.", "text": "animals amazing ability learn tasks quickly switch ﬂexibly. brains support ability largely unknown neuroscientiﬁcally algorithmically. reasonable supposition modules drawing underlying general-purpose sensory representation dynamically allocated per-task basis. recent results neuroscience artiﬁcial intelligence suggest role general purpose visual representation played deep convolutional neural network give clues task modules based representation might discovered constructed. work investigate module architectures embodied two-dimensional touchscreen environment agent’s learning must occur interactions environment emits images rewards accepts touches input. environment designed capture physical structure task environments commonly deployed visual neuroscience psychophysics. show context simple changes nonlinear activations used module signiﬁcantly inﬂuence fast learning visual tasks suitable switching tasks. course everyday functioning animals constantly faced realworld environments required shift unpredictably multiple sometimes unfamiliar tasks nonetheless able ﬂexibly adapt existing decision schemas build ones response challenges brains support ﬂexible learning task switching largely unknown neuroscientiﬁcally algorithmically reasonable supposition problem solved modular fashion simple modules specialized individual tasks dynamically allocated largely-ﬁxed general-purpose underlying sensory representation general-purpose representation likely large complex learned comparatively slowly signiﬁcant amounts training data. contrast task modules reading deploying information base representation lightweight easy learn. case visually-driven tasks results neuroscience computer vision suggest role general purpose visual representation played ventral visual stream modeled deep convolutional neural network wide variety relevant visual tasks read-out simple often linear decoders based features combinations levels networks however putative ventral-stream representation might deployed efﬁcient dynamic fashion remains obvious. figure touchstream environment. touchstream environment simple guilike testbed posing visual tasks continual reinforcement learning agent. consists interacting components screen server emits images rewards agent accepts images rewards emits touch actions e.g. positions two-dimensional grid shape input image. agent neural network ﬁxed visual backbone modules drawing backbone learn interact touchstream maximize long-term reward received. timestep agent produces estimate rewards next several timesteps conditional action chooses timestep recent past form reward heatmap. using simple exploration policy agent chooses next action based heatmap. work goal evaluate types module architectural motifs enable agent efﬁciently learn touchstream tasks. work lifelong learning reinforcement learning neural modules decision making addressed many aspects questions including learn tasks without destroying ability solve older tasks parse novel task familiar subtasks determine task ﬁrst place. work investigate somewhat different question namely local architectural motifs deployed module inﬂuence efﬁcient system learning switching tasks. simple motifs signiﬁcantly outperform standard neural network nonlinearities needing fewer training examples fewer neurons achieve high levels performance. work situated embodied system designed capture physical structure task environments commonly deployed visual neuroscience psychophysics. speciﬁcally model two-dimensional touchscreen agent’s learning must occur interactions environment emits images rewards accepts touches input. shown mice rats macaques humans operate touchscreens learn operant behaviors building work success mapping neural networks real neural data context static visual representations goal produce models dynamic task learning sufﬁciently concrete help build bridges general theories architectures artiﬁcial intelligence speciﬁc experimental results empirically measurable animal behaviors neural responses. touchstream environment consists components screen server agent interacting extended temporal sequence timestep screen server emits image non-negative reward conversely agent accepts images rewards input next timestep emits action response. action space available agent consists pixel grid shape input image. screen server runs program computing function history agent actions at−} images it−} rewards rt−}. agent neural network composed visual backend ﬁxed weights together recurrent module whose parameters learned interaction touchstream setup meant mimic touch-based gui-like environment used visual psychology neuroscience experiments involving humans non-human animals screen server stand-in experimentalist showing visual stimuli using rewards figure tasks. illustration taskstream environment captures variety tasks commonly used visual psychophysics experiments. shows image output screen server bottom illustrates reward task indicating high reward blue indicating reward. binary stimulus-response task reward function deﬁned associating left half screen ﬁrst class right hand side screen second class. agent recieves image frame containing classes must respond touching image correct side receive reward. type task generalized classes e.g. sectioning screen. match-to-sample task displays sample stimulus screen single class instance agent touched anywhere proceed following match screen. next screen displays several smaller images depicts class sample screen rest distractor classes. agent rewarded touching within correct class box. localization single image containing instance unique class. agent rewarded ﬁrst touching opposing corners object deﬁnes bounding box. correct touch second screen depends action chosen ﬁrst screen indicated small yellow elicit behavior subject response stimuli. agent analogous experimental subject participant cannot receive verbal instructions assumed want maximize aggregate reward receives environment. principle screen server program anything encoding wide variety two-dimensional visual tasks dynamically-switching sequences tasks. work evaluate small tasks analogous used simple human monkey experiments including stimulus-response match-to-sample categorization tasks object localization tasks. stimulus-response tasks stimulus-response paradigm simple physically embody discrete categorization tasks commonly used animal neuroscience literature touchstream environment n-way task assumes input images divided classes screen correspondingly divided regions reward returned agent’s touch inside region associated class identity shown image otherwise. example two-way discrimination task agent might rewarded touches left half screen shown right half shown image butterﬂy. task dialed difﬁculty increasing number image classes complexity class regions. multiple classes introduced once curricularization could achieved slowly interleaving classes corpus reward boundaries morphed accordingly. present study examines following three variants two-way binary classiﬁcation left/right decision boundaries four-way double-binary classiﬁcation pairs classes deﬁne independent left/right decision boundaries four-way classiﬁcation reward surface splits touchstream quarters. image categories used drawn image-net ilsvr classiﬁcation challenge dataset class unique training instances unique validation instances. match-to-sample tasks another common approach assessing visual categorization abilities match-to-sample paradigm trial pair image frames trial begins presenting agent unique ‘sample’ screen depicting image single class instance. agent allowed touch anywhere within advance next frame receives reward frame. presented next ’match’ screen displays agent multiple small images blank background containing ﬁxed template image classes class shown sample screen. frame server returns reward agent touches somewhere inside rectangular region occupied image class shown ﬁrst image otherwise. paradigm incorporates need working memory localized structure. along standard binary discrimination consider variants task make match screen less stereotypical either distractor classes random vertical translations match images random interchanging lateral placement classes perturbations simultaneously localization tasks tasks reward value given action independent actions taken previous steps. beyond situation also explore two-step localization task using synthetic images containing single main salient object placed complex background trial task steps agent rewarded second step amount proportionate intersection union value implied agent’s touches relative ground truth bounding box. reward dispensed ﬁrst touch sequence. bounded memory horizon tasks described require bounded memory ﬁxed horizon. perfect solution always exists within timesteps point requires knowledge previous past steps complex visual tasks object segmentation numbers larger vary complex trials present work avoid complications. module architectures follows denote two-dimensional pixel grid action space deﬁne module neural network whose inputs history timesteps agent’s actions activations ﬁxed visual backbone model; outputs reward prediction maps across action space next timesteps. history outputs backbone visual model history previously chosen actions map) action space reward space. learnable parameters module network. work chose visual backbone model output layer vgg- network pretrained imagenet parameters modules learned stochastic gradient descent reward prediction error compared true reward timesteps action taken. produced reward prediction agent chooses action next timestep normalizing predictions across action space timesteps separate probability distributions sampling distribution frame maximum variance chose policy lead better ﬁnal results large action space comparison large variety standard reinforcement learning policy alternatives although rank order comparison results reported appeared robust choice action policy. although minimimal required values different various tasks work investigations below take maximum values across tasks require architectures learn safe ignore information past irrelevant predict past certain point future. obvious solutions main question seek address architectural motif module considerations module easy learn parameters requiring comparatively training examples easy learn from meaning task related able quickly build module reusing components ones general e.g. properties tasks interest. structure found? intuition-building example it’s useful note many tasks address obvious solutions easily written-down analytic expressions correctly solve task. consider case -way task like fig. given verbal instructions describing task human might solve task allocating module compute following function x-component action length-|c| vector expressing dog/butterfuly class boundary since task formula doesn’t depend previous action history all. given ability recall long-term memory formula allow human solve task nearly instantly. fact even weight matrix known imposing structure allows learned quickly illustrated learning curve shown black line fig. narrowing decision surface considerably right decision structure learnable parameters module must simply construct category boundary which good visual feature representation comparatively trivial converges nearly-perfect solution extremely quickly. agents modeled present work language capabilities receive verbal instruction direct allocation obvious task-speciﬁc layout structures ﬂexibly. nonetheless possible glean basic ideas example generally useful first module early bottleneck; highdimensional general feature representation reduced small number dimensions combined action parameter second module multiplicative interaction between action features visual features involves multiplication operfigure obvious solution two-way task using ation. thirdly module formula leads black line learning curve shown above. sign-symmetric terms accounting results generic early-bottleneck modules motifs symmetry action-reward shown comparison. relationship across vertical axis. turns early bottlenecks multiplication signsymmetry built simple general design learned entirely scratch leading efﬁcient learning binary task variety visual decision problems. generic motifs deﬁne several possible generic motifs implement three basic ideas. speciﬁcally module standard using nonlinearity concatenates multiplicative denotes vector concatenation. thus layer features form relu tensors layers motif crossproducts emerge elements original input deﬁne -lrs module network bottlenecks input dimension combines actions performs layers size respectively. figure late bottleneck module concatenates actions directly visual features. early bottleneck module reduces number visual dimensions action concatenation. modules comparison control deﬁne modules module activation function replaced various other mostly standard nonlinear activation functions example test squaring nonlinearity without relu concatenated denoted module. also test relu nonlinearity alone denoted module well tanh nonlinearity sigmoid nonlinearity additionally also test recently explored activations concatenated relu tested. modules late-bottleneck modules using nonlinearities above except actions combined visual features bottlenecking done. standard actions concatenated onto visual features beginning. visual backbone model output size input module size timestep since action space crez-lrs module module relu nonlinearity bottleneck layer replaced crelu nonlinearity deﬁned relu⊕relu. motivating addition motif symmetric nature obvious architecture captured explicitly sign-symmetric transformation visual features. crez-cres module uses crelu bottleneck nonlinearity above except activations following layers replaced nonlinearity concatenates squares crelu components e.g. point universal approximation theorem motifs equivalent expressivity could approximate square non-linearity sufﬁciently large module. however makes guarantees learning efﬁciency network size. crucially results paper types nonlinearities needed capture task demands touchstream environment make motifs signiﬁcantly efﬁcient others. compared crez-lrs crez-cres modules twelve variants localization tasks. weights initialized using xavier algorithm learned using adam optimizer parameters learning rates optimized per-task per-architecture basis cross-validated fashion. architecture task optimizations different weight initializations obtain mean standard error initial condition variability. modules measured performance modules three different sizes throughout small version equivalent size small early bottleneck modules whereas medium large versions much larger. main results that small early-bottleneck modules using squaring operation nonlinearity learn tasks substantially quickly architectures comparable larger sizes often attain higher ﬁnal performance levels. small early-bottleneck module sign-symmetric early nonlinearity less efﬁcient modules square nonlinearity substantially better architectures neither early bottleneck square nonlinearity. crez-cres module combines early bottleneck squaring nonlinearity sign-symmetric concatenation efﬁcient task crez-lrs module generally second efﬁcient wins task small margin. words main features lead obvious architecture well binary task individually helpful combine usefully across variety visual tasks. experiment details task crez-cres crez-lrs small architectures units layer medium large units respectively. stimulus-response tasks left versus right decision boundaries models aside smallest eventually achieve reasonably high maximum reward. typically non-squaring modules performance better medium-sized worse large-sized modules except case four-way quadrant variant task non-squaring fail converge solution within alotted timeframe contrast small-sized crez-cres crez-lrs modules however learn task training examples resulting reward prediction maps fig. experiment details task crez-cres crez-lrs small architectures units layer medium large units respectively. fig. offers glimpse characteristic learning curves observed challenging tasks crez-cres seen achieve peak performance within initial stages learning whereas modules follow sigmoid-like trajectory. non-sterotyped match screens observed present difﬁculties small medium modules contrast squaring modules solve efﬁciently stationary versions maintaining high degree precision note heatmaps beginning trial conﬁdent ability receive reward time zero knowledge next frame localization experiment details task crez-cres crez-lrs small architectures units layer medium large units respectively. curves fig. show little difference models despite size models consistently achieve crez-cres crez-lrs give context values note earlybottlenecked modules able equal outperform baseline trained using supervised methods directly regress bounding boxes using features inspecting prediction heatmaps module task shows reward uncertainty frontier well-localized. basic task-switching next tested modules basic task-switching conditions determine suitability redeployment. chose contrast performance largest modules initially trained two-way task. repurposed solve task class boundaries reversed task entirely categories four-way double binary version. repeat experiment using two-way task well. switching hold output weights ﬁxed models. layer weights ﬁxed whereas tested without holding second fully-connected layer constant. cases immediately able adapt class boundaries learn tasks quicker trained scratch consistent results contexts module however unable easily prior experience learning task holding second layer constant actually hinders ability learn tasks. patterns maintained complex switch double binary task match-to-sample task large model even failing converge within short timeframe needed study switching behavior. conclusion mapping functions developed figure learning curves. reward obtained course training modules two-way stimulus-response four-way four-way four randomly ordered match options localization. solid lines represent mean shaded area represents standard errors taken training runs different weight initializations. clarity subset tested nonlinearities displayed. area learning curve twelve task variants task implemented normalized value obtained highest performing model. modules shown ordered mean performance across tasks. heatmaps current next time steps learned module two-way stimulus-response four-way two-shown match-to-sample random vertical motion localization figure basic task switching tasks class boundaries either reversed classes introduced. binary task. binary task blue line module’s original training curve green line indicates training curve module reversed-class boundary task switching line indicates training curves module category boundary. also shown reversed boundary task switching results late-bottleneck relu module either layers module relearned ﬁrst layer relearned second layer held ﬁxed analogous results -way task; note reversed condition exists task. analogous results binary task. base task rapidly transfered modules learning tasks similar reward functions. tested crez-cres crez-lrs modules task switching context performed experiments task-switching context localization task. plan experiments near future. work introduced two-dimensional embodied framework mimics physical setup experimental touchscreen environment eventual goal allowing direct comparison learning characteristics embodied models real animals neuroscience experiments necessarily embodied. showed simple module structures building ﬁxed visual backbone learn selection tasks posed typical visual neuroscience experiments using basic reinforcement learning scheme. moreover found choice nonlinearity module signiﬁcant effects ability module learn quickly switch tasks efﬁciently. fundamentally because task space many natural interactions action space visual features multiplicative. allow module structures remain small useful natural multiplicative interaction directly available module architecture. fact squared concatenated sign-symmetric nonlinearities superior nonlinearities experiments likely tied spatial structure two-dimensional embodied environment situated. real neuroscience psychophysics experiments actually embodied results suggest nature embodiment might important consideration making detailed models real experimental data. however relevance results general task-learning switching situations token limited extent decision task switching processes embodied spatial-like environments. likely architectures even better crez-cres. instance plausible modules generate convolutional weights applied across images might lead better localization results. general expanding module structures would interest. finding incorporate text inputs would also signiﬁcant interest early blue black learning curves fig. illustrates important linguistic advantage remains ﬁnding better module motifs important task equally crucial future step purely computational point view integrate insights work full-stack continuallearning procedure. speciﬁcally future work need address issues sophisticated robust task-switching beyond simple tests we’ve done here; declare module needed grow modules efﬁcient manner relative existing modules consolidate modules appropriate though crez-cres effective motifs metrics measure necessarily mean better description really happens brains. determine core goal core future work need involve obtaining behavioral data human animals comparing predictions made various motifs seeing best predicts learning rate curve shape patterns data using techniques like deployed match non-embodied model behavior monkey human behavior and/or obtaining neural data animals comparing response patterns internal states model learning time extending techniques like used modeling ventral visual stream especially interesting compare data species obviously differential levels task learning ﬂexibility e.g. mice rats monkeys humay whether differences local computational circuit architecture might explain intraspecies differences. charles cadieu hong daniel yamins nicolas pinto diego ardila ethan solomon najib majaj james dicarlo. deep neural networks rival representation primate cortex core visual object recognition. plos computational biology alexa horner christopher heath martha hvoslef-eide brianne kent simon nilsson johan alsiö charlotte oomen andrew holmes lisa saksida touchscreen operant platform testing learning memory rats mice. nature protocols jaderberg volodymyr mnih wojciech marian czarnecki schaul joel leibo david silver koray kavukcuoglu. reinforcement learning unsupervised auxiliary tasks. corr abs/. james kirkpatrick razvan pascanu neil rabinowitz joel veness guillaume desjardins andrei rusu kieran milan john quan tiago ramalho agnieszka grabska-barwinska demis hassabis claudia clopath dharshan kumaran raia hadsell. overcoming catastrophic forgetting neural networks. corr abs/. lane mcintosh niru maheswaranathan aran nayebi surya ganguli stephen baccus. deep learning models retinal response natural scenes. advances neural information processing systems pages razavian hossein azizpour josephine sullivan stefan carlsson. features off-the-shelf astounding baseline recognition. computer vision pattern recognition workshops ieee conference pages ieee rogerson maxey jercog eisman ahanonu grewe schnizter. hippocampal ensemble neural activity reveals associative representations hippocampus mice acquiring bi-conditional learning task. society neuroscience andrei rusu neil rabinowitz guillaume desjardins hubert soyer james kirkpatrick koray kavukcuoglu razvan pascanu raia hadsell. progressive neural networks. corr abs/. anthony wagner daniel schacter michael rotte wilma koutstaal anat maril anders dale bruce rosen randy buckner. building memories remembering forgetting verbal experiences predicted brain activity. science jane wang kurth-nelson dhruva tirumala hubert soyer joel leibo rémi munos charles blundell dharshan kumaran matt botvinick. learning reinforcement learn. corr abs/. yamins hong cadieu solomon seibert dicarlo. performance-optimized hierarchical models predict neural responses higher visual cortex. proceedings national academy sciences four unique object classes taken image-net ilsvr classiﬁcation challenge dataset used stimulus-response match-to-sample experiments boston terrier monarch butterﬂy race panda bear. two-way classiﬁcation tasks uses boston terriers monarch butterﬂies except switching experiments models repurposed classify race cars versus panda bears. synthetic dataset containing unique training images unique validation images generated localization task. consisted unique classes objects rendered complex natural scene backgrounds. image generated using objects randomly sampled size spatial translation orientation respect random background. images preprocessed taking randomly cropped segment subtracting mean pixel values ilsvr classiﬁcation challenge dataset. class template images match screen held ﬁxed pixels. contain stereotypical face-centered centrally-located example class question. variants task keep pixel buffer edges screen match images twelve pixel buffer adjascent edges match images themselves. variants without vertical motion match images vertically centered screen. two-way classiﬁcation make task challenging three ways. consider translating match image random number pixels randomly ﬂipping horizontal location match images trials tandem. four-way classiﬁcation variants either show four class options match screen. match screen contains classes always randomized horizontally addition task also study challenging variant introducing similar vertical motion above. four-shown variants increase complexity randomly permuting match screen orderings trials. five runs model conducted task. every training trials model’s performance tasks taken average reward obtained validation set. localization calculates reward intersection union value ground truth bounding predicted bounding reward given agent value rewards ious averaged across runs model area curve values calculated using trapezoidal integration routine valitidation reward trajectories. table lists total number learable parameters model across three base task paradigms. architechtures include squaring relu tanh sigmoid actvations. crelu different number parameters concatenation. modules presented actions features point within architecture predict reward timesteps conditioned actions. timestep agent provided random subsample complete pixel action space tasks agent receives unique action samples increased localization. subsamples participate reward prediction action sampling timestep. sampled action stored future time steps appear gradient updates. models learn minimizing cross entropies predicted rewards. output network time reward maps contstructed computing expected reward obtained subsampled action given current visual input history action choice history ensures probability distribution varargmax operator chooses input largest variance. experimenting different exploration policies found sampling procedure empirically superior. random \u0001-greedy instance inefﬁcient large-action spaces becomes efﬁcient learning rather beginning alternate version \u0001-greedy devised defaulted sampling policy rather random choice performance still lacked. sampling policies also attempted paramaterizing boltzmann distribution rather weighted uniform although resulted poor sampling since larger proportion probability mass devoted poor action choices. crez-cres crez-lrs lsig lcre lbr-small lbr-med lbr-large lbt-small lbt-med lbt-large lbsig-small lbsig-med lbsig-large lbe-small lbe-med lbe-large lbcre-small lbcre-med lbcre-large learning trajectories eight additional tasks provided figure modules capable convergence task achieved values given task calculated point time majority models converge. figure learning curves. four-way double binary two-way stationary two-way random vertical motion two-way random horizontal match image ﬂips two-way random vertical motion horizontal ﬂips four-way two-shown four-way two-shown vertical motion four-way four-shown stationary ordering.", "year": 2017}