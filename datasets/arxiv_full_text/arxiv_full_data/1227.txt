{"title": "Automatic Moth Detection from Trap Images for Pest Management", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Monitoring the number of insect pests is a crucial component in pheromone-based pest management systems. In this paper, we propose an automatic detection pipeline based on deep learning for identifying and counting pests in images taken inside field traps. Applied to a commercial codling moth dataset, our method shows promising performance both qualitatively and quantitatively. Compared to previous attempts at pest detection, our approach uses no pest-specific engineering which enables it to adapt to other species and environments with minimal human effort. It is amenable to implementation on parallel hardware and therefore capable of deployment in settings where real-time performance is required.", "text": "monitoring number insect pests crucial component pheromone-based pest management systems. paper propose automatic detection pipeline based deep learning identifying counting pests images taken inside ﬁeld traps. applied commercial codling moth dataset method shows promising performance qualitatively quantitatively. compared previous attempts pest detection approach uses pest-speciﬁc engineering enables adapt species environments minimal human eﬀort. amenable implementation parallel hardware therefore capable deployment settings real-time performance required. monitoring crucial component pheromone-based pest control systems. widely used trap-based pest monitoring captured digital images analysed human experts recognizing counting pests. manual counting labour intensive slow expensive sometimes error-prone precludes reaching real-time performance cost targets. goal apply state-of-the-art deep learning techniques pest detection counting eﬀectively removing human loop achieve completely automated real-time pest monitoring system. plenty previous work considered insect classiﬁcation. past literature grouped along several dimensions including image acquisition settings features classiﬁcation algorithms. terms image sources many previous methods considered insect specimens specimens usually well preserved imaged ideal environment. thus specimen images consistent captured high resolution. less ideal practical scenario works attempt classify insects collected wild imaged laboratory conditions case image quality usually worse specimen case researchers still typically chance adjust settings control image quality imaging insects standard orientation lighting. algorithmic perspective various types features used insect classiﬁcation including wing structures colour histogram features morphometric measurements local image features global image features diﬀerent classiﬁers also used various feature extraction methods including support vector machines artiﬁcial neural networks k-nearest neighbours ensemble methods general however proposed methods tested real application scenarios example images real traps deployed pest monitoring. object detection involves also localizing objects addition classiﬁcation. attempts made respect insect detection. option perform sliding window approach classiﬁer scans patches diﬀerent locations image. technique applied inspection bulk wheat samples local patches original image represented engineered features classiﬁed discriminant analysis. another work bulk grain inspection employed diﬀerent customized rule-based algorithms detect diﬀerent objects respectively. performing detection ﬁrst propose initial detection candidates performing image segmentations. candidates represented engineered features classiﬁed insect detection methods heavily engineered work speciﬁc species speciﬁc environments likely directly eﬀective pest monitoring setting. main challenges detecting pests trap images. ﬁrst challenge image quality constraints cost imaging sensor power consumption speed images transmitted. makes previous work impractical based high image quality structures. second challenge comes inconsistencies driven many factors including illumination movement trap movement moth camera focus appearance objects decay damage insect appearance non-pest insects etc. make hard design rule-based systems. therefore ideal detection method capable ﬂexible enough adapt diﬀerent varying factors minimal amount additional manual eﬀort manually labelled data daily pest monitoring program. apart insect classiﬁcation/detection community general visual object category recognition detection mainstay computer vision long time. various methods datasets proposed last several decades push area forward. recently convolutional neural networks variants emerged eﬀective method object recognition detection achieving state-of-the-art performance many well recognized datasets winning diﬀerent object recognition challenges inspired line research adopt popular sliding window detection pipeline convolutional neural networks image classiﬁer. first images preprocessed colour correction. then trained convnets applied densely sampled image patches predict patch’s likelihood containing pests. patches ﬁltered non-maximum suppression probabilities higher neighbours preserved. finally remaining patches thresholded. patches whose probability meet threshold considered proposed detections. paper makes main contributions. first develop convnet-based pest detection method accurate fast easily extendable pest species requires minimal pre-processing data. second propose evaluation metric pest detection borrowing ideas pedestrian detection literature. colour images captured pheromone traps installed multiple locations commercial provider pheromone-based pest control solutions whose name withheld request. trap contains pheromone lure adhesive liner digital camera radio transmitter. pheromone attracts pest interest trap become stuck adhesive surface. digital images stored jpeg format resolution transmitted remote server ﬁxed time point daily. codling moths identiﬁed labelled bounding boxes technicians trained entomology. image temporal sequence labelled used study labelled images temporal correlation other. result labelled moths unique. figure shows trap image codling moth labelled blue bounding boxes. figure shows image containing moths cluttered types insects. high resolution individual image patches shown later figure characteristics analysed section collected images split randomly sets training validation test set. splitting statistics roughly entire dataset including ratio number images without moths number moths image. table provides speciﬁc statistics entire dataset three splits subsequently constructed. trap images collected real production environments leads diﬀerent imaging conditions diﬀerent points time. apparent illumination seen figure eliminate potential negative eﬀects illumination variability detection performance perform colour correction using variant grey-world method. algorithm assumes average value green blue channels equal other. speciﬁcally image gain channels follows µred µgreen µblue original average intensities green blue channels respectively. gred gblue multiplicative gains applied pixel intensity values blue channels respectively. figure shows images processed grey-world algorithm. images white-balanced similar illumination still maintain rich colour information useful detection downstream. paper images white-balanced prior detection. automatic detection pipeline involves several steps shown figure take sliding window approach trained image classiﬁer applied local windows diﬀerent locations entire image. classiﬁer’s output single scalar represents probability particular patch contains codling moth. patches regularly densely arranged image thus largely overlapping. therefore perform non-maximum suppression retain windows whose respective probability locally maximal. remaining boxes thresholded patches certain probability kept. location sliding window approach detection problem breaks classifying local patch performed image classiﬁer mapping image probability adopt convolutional neural network image classiﬁer popular best performing classiﬁer image recognition large scale small scale problems. also fast deploy amenable parallel hardware. speciﬁcally used network structure similar lenet shown figure network contains convolutional layers max-pooling layers fully connected layers applying convnet dimension input patch normalized zero mean unit variance. convolutional layer applies linear ﬁlterbank element-wise nonlinearity input feature maps transforming diﬀerent feature maps. applying convolutional layers several times extract increasingly high-level feature representations input time preserving spatial relationship. ﬁrst layer input feature maps simply channels input. subsequent layers represent abstract transformations image. convolutional layer special case fully connected layer introduced subsection local connections non-zero values weights tied locations. local connectivity implemented eﬃciently applying convolution layer index; index input feature maps; index output feature maps; input feature layer output bias term; choose element-wise nonlinearity rectiﬁed linear unit function. convolutional layer followed max-pooling layer. layer applies local pooling operations input feature maps preserving maximum value within local receptive ﬁeld discarding values. similar convolutional layer sense operate locally. applying max-pooling layers major beneﬁts reducing number free parameters introducing small amount translational invariance network. last layers convnet fully connected. kind layers found standard feedforward neural networks. ﬁrst fully connected layer ﬂattens feature maps last max-pooling layer treating one-dimensional vector feature representation whole image. second fully connected layer parameterized like linear classiﬁer. mathematically fully connected layer written layer index; input vector representation layer output layer weight matrix; bias vector; element-wise nonlinear function choose relus fully connected hidden layer softmax output layer. applying convnet sliding window fashion obtain probabilities associated densely sampled patch. simply applied thresholding point would many overlapping detections. problem commonly solved using non-maximum suppression aims retain patches locally maximal probability. adopted strategy similar speciﬁcally ﬁrst sort detections according probability. then high probability look detection remove bounding boxes overlap least current detection. greedy process generate ﬁnal detection outputs shown figure later section classiﬁer trained generated patches diﬀerent sizes detailed section minibatch stochastic gradient descent momentum used train convnet. gradient estimated well known back-propagation algorithm used ﬁxed learning rate ﬁxed minibatch size ﬁxed momentum coeﬃcient validation used monitoring training process selecting hyperparameters. report performance using classiﬁer whose parameters chosen according best observed validation accuracy. ﬁlters fully-connected weight matrices convnets initialized values selected uniform random distribution interval function number pre-synaptic postsynaptic units detail). sliding window classiﬁcation pipeline classiﬁer takes local window input. therefore need extract small local patches original high-resolution train classiﬁer. performed memoryeﬃcient manner using pointer arithmetic create views data opposed storing patches memory. here positive patch refers patches derived manually labelled bounding boxes represents codling moth. convnet processes square inputs ignored original aspect ratio manually labelled bounding boxes took square region centre original rectangular bounding box. figure shows positive patches extracted training set. would diﬃcult cover kinds false positives arise simply sampling regions covered labelled bounding boxes. area regions containing moths much larger area covered bounding boxes. images cluttered negative area uninteresting thus obtain negative training examples intentionally take hard patches meaning contain texture. speciﬁcally apply canny edge detector patches negative images i.e. contain moths. threshold number negative patches roughly matches number labelled moths. figure shows random sample negative patches. initial negative patches extracted bootstrapping approach useful negative training patches make classiﬁer discriminative. ﬁrst round training initially generated patches used train classiﬁer. test time false positive patches training collected isolate negative patches highest probability assigned classiﬁer. merged initially generated patches form dataset second stage training. could potentially rounds bootstrapping collect informative negative patches found including training stages improve performance. figure shows randomly sampled patches collected test phase stage training. validation number patches collect proportional number images validation set. machine learning-based methods usually case larger dataset better generalization performance. case amount training data represented number training patches much smaller standard small-scale image classiﬁcation datasets frequently used deep learning community order training examples. therefore performed data augmentation increase number images training also incorporate invariance basic geometric transformations classiﬁer. based top-view nature trap images certain patch change class label slightly translated ﬂipped rotated. therefore apply simple geometric transformations original patches increase number training examples. patch create translated copies shifting pixels horizontally vertically diagonally. also create versions ﬂipped across horizontalvertical-axes. finally create rotated copies rotating original degrees. produces augmented patches original. figure shows augmented versions produced single example. detection stage need stride means distance adjacent sliding windows. smaller stride means denser patch coverage lead better localization moths also requires computation. trade-oﬀ stride pest detection still relatively niche area computer vision therefore standard evaluation protocol deﬁned. decided adopt protocol inspired standardization within pedestrian detection community. complete overview provided summarize below. evaluate detection performance based statistics misdetections correct detections false positives. here misdetection refers manually labelled region missed algorithm false positive refers bounding proposed algorithm correspond manually labelled region. determine bounding proposed detector correct detection misdetection determine correspondence manually labelled bounding calculating intersection-over-minimum heuristic bbdt represents bounding proposed algorithm bbgt represents ground truth bounding box. consider speciﬁc ground truth bounding correctly detected exists detection otherwise ground truth bounding considered misdetection. multiple bbdt’s satisfy condition highest probability classiﬁer chosen. performed bbgt remaining unmatched bbdt considered false positives. evaluation metric diﬀers used pedestrian detection iomin place popular jaccard index also called intersection-over-union potential shape mismatches ground truth detections. ground truth bounding boxes rectangles classiﬁer outputs probabilities square patches. case ground truth rectangle nearly square works well. case ground truth rectangle tall wide however tends small matter good detection contrary iomin heuristic performs well cases. based statistics correct detections misdetections false positives could evaluate performance levels object level focus performance detecting individual moths; image level focus determining whether image contains moths. pairs metrics measure trade-oﬀ reducing misdetections reducing false positives miss rate fppi precision recall. miss rate fppi common performance measure pedestrian detection community gives estimate system accuracy certain tolerances speciﬁed score simply measure aims weight importance precision recall single operating point along precision-recall curve. larger better performance. parameter adjusts importance precision recall. paper consider detecting moths important reducing false positives therefore heavily weight recall setting reported results. course score operating point system. summarize information conveyed miss rate fppi precision recall plots single value employ scalar performance measures log-average miss rate fppi range area precisionrecall curve image level performance evaluation considered scenario semi-automatic detection algorithm proposes images technician inspect safely ignores images contain moths. setting algorithm simply needs make proposal moths moths image regardless many moths believes present. call true moth image image contains least moth moth image image contains moths. similar object level evaluation threshold-dependent measures sensitivity speciﬁcity precision score deﬁned similar object level evaluation also pairs trade-oﬀs sensitivity speciﬁcity precision recall. scalar performance measures calculate curves. figure shows example detector operation. panels image left shows manually annotated bounding boxes green proposals detector magenta. image right shows results matching annotations proposals. misdetections false positives correct detections shown blue yellow boxes respectively. figure thresholds maximize f-score object level image level respectively. figures show examples detection results full-sized images. domain cost responding potential pest problem outweighs unnecessarily applying treatment. also tried popular vision pipeline local feature descriptors followed visual words support vector machine figure visual example detection results. panel shows best-performing classiﬁer object level. panel shows best-performing classiﬁer image level. best viewed colour. convnet input size achieved best performance object level convnet input size best performance image level. accordingly figure shows diﬀerent performance curves comparing best performing convnet logistic regression object image level. apparent figure convnet achieved nearly perfect results image level. precision-recall curve usually expects precision decrease recall increases. here figure precision sometimes increases recall increases. threshold decreasing possible newly included detections true detections results increase precision recall. understand eﬀect data augmentation detector performance performed experiments convnet input size either using rotational translational augmentation; rotational augmentation; translational augmentation; augmentation. results shown table observed translational rotational augmentation improved performance compared augmentation all. using translational rotational augmentation improved performance object level image level single type augmentation suﬃcient. also evaluated performance proposed method limited training data shown table algorithm maintains reasonable performance even training data removed. also indicates eﬀectiveness data augmentation strategy. table performance convolutional neural networks compared logistic regression diﬀerent input sizes. bold values represent best performance per-method per-metric. completely remove occlusion dataset removing occluded ground truths detections overlapping occluded ground truths evaluation achieve slight performance improvement object level. here precision-recall increases log-average miss rate decreases indicates algorithm perform even better well-managed sites trap liners changed often resulting less occlusions. figure shows various image patches diﬀerent detection outcomes including figure shows correct detections shows misdetections shows false positives. patches resolution. extracted based detection results using input size moth images show high degree variability multiple factors including diﬀerent wing poses occlusion objects diﬀerent decay conditions diﬀerent illumination conditions diﬀerent background textures diﬀerent blurring conditions. moths successfully detected distorting factors ignored detector. figure also inside window considered classiﬁer false positives extent visually similar image patches actually moths. although human reader seems easier distinguish moth non-moth looking entire patch suggests incorporating information peripheral region could help improve detection performance. compared majority previous work proposed method relies data less human knowledge. knowledge codling moths considered design approach. network learned identify codling moths based positive negative training examples. characteristic makes easier system adapt pest species environments without much manual eﬀort long relevant data provided. errors caused diﬀerent factors analysed section many related time. moth could diﬀerent wing poses levels occlusion illumination decay conditions time. visual texture also related time. example decaying insects could make originally white trap liner become dirty reduce contrast moths background. errors caused time-related factors could largely avoided real production systems temporal image sequences provided reasonable frequency. leads possible future research direction reason image sequences detecting moths single image exploiting temporal correspondence. errors caused blurry images could potentially solved adding deblurring ﬁlters preprocessing pipeline. non-moth objects contribute certain amount false positives. address problem train detectors common non-moth objects combine moth detector. common objects include pheromone lures ﬂies leaves. would also require dataset richer labelled information. preliminary attempt automatic pest detection trap images methods introduced paper many possible future extensions besides mentioned based error analysis. deeper convolutional networks could applied provide accurate image patch classiﬁcation. detecting classifying multiple types insects would natural extension closely related ﬁne-grained image classiﬁcation problem location information detections could potentially reﬁned proposing rectangular bounding boxes polygons parameterized curves representing insect shapes. paper describes automatic method monitoring pests trap images. propose sliding windowbased detection pipeline convolutional neural network applied image patches diﬀerent locations determine probability containing speciﬁc pest type. image patches ﬁltered non-maximum suppression thresholding according locations associated conﬁdences produce ﬁnal detections. qualitative quantitative experiments demonstrate eﬀectiveness proposed method codling moth dataset. also analysed detection errors corresponding inﬂuences real production systems potential future directions improvements. work funded natural sciences engineering research council industry partner whose name withheld request. would also like thank rebecca hallett jordan hazell industry partner assistance data collection.", "year": 2016}