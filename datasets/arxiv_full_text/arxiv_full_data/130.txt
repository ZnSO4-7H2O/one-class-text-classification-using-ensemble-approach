{"title": "Deep Embedding for Spatial Role Labeling", "tag": ["cs.CL", "cs.CV", "cs.LG", "cs.NE"], "abstract": "This paper introduces the visually informed embedding of word (VIEW), a continuous vector representation for a word extracted from a deep neural model trained using the Microsoft COCO data set to forecast the spatial arrangements between visual objects, given a textual description. The model is composed of a deep multilayer perceptron (MLP) stacked on the top of a Long Short Term Memory (LSTM) network, the latter being preceded by an embedding layer. The VIEW is applied to transferring multimodal background knowledge to Spatial Role Labeling (SpRL) algorithms, which recognize spatial relations between objects mentioned in the text. This work also contributes with a new method to select complementary features and a fine-tuning method for MLP that improves the $F1$ measure in classifying the words into spatial roles. The VIEW is evaluated with the Task 3 of SemEval-2013 benchmark data set, SpaceEval.", "text": "continuous vector representation word extracted deep neural model trained using microsoft coco data forecast spatial arrangements visual objects given textual description. model composed deep multilayer perceptron stacked long short term memory network latter preceded embedding layer. view applied transferring multimodal background knowledge spatial role labeling algorithms recognize spatial relations objects mentioned text. work also contributes method select complementary features ﬁne-tuning method improves measure classifying words spatial roles. view evaluated task semeval- benchmark data spaceeval. essential functions natural language describe location translocation objects space. spatial language convey complex spatial relations along polysemy ambiguity inherited natural language. therefore formal spatial model required focus particular spatial aspects. paper address layer linguistic conceptual representation called spatial role labeling predicts existence spatial information sentence level identifying words play particular spatial role well spatial relationship kordjamshidi moens issue extracting spatial semantics natural language lack annotated data machine learning employed learn extract spatial relations. current sprl algorithms rely strongly feature engineering advantage encoding human knowledge thus compensating lack annotated training data. work preserves previous contributions feature engineering kordjamshidi moens adding features learned multimodal data i.e. visually informed embedding word dinov uses deep boltzmann machines representing joint multimodal probability distributions images sentences karpathy embed fragments images fragments sentences common space bidirectional retrieval images sentences kiros unify joint imagetext embedding models multimodal neural language models rank images sentences using long short term memory network process text deep convolutional network process images. similar work kiros model learns embedding multimodal data applies lstm process textual information. however unlike works multimodal representation learning jointly visual textual information common embedding space work aims providing embeddings words encoding spatial information extracted image annotations. idea learn view pipelining embedding layer deep architecture trained back propagation predict spatial arrangement visual objects annotated pictures given respective textual descriptions. sense unlike karpathy kiros don’t need spatial information relevant purpose provided directly position bounding boxes containing visual objects annotated images detailed section view used vehicle transfer spatial information multimodal data sprl algorithms. paper organized follows. section describe model setting annotation style modeling deep neural network whose training algorithm described section section describes spatial embedding applied sprl well algorithm developed select best complementary embedding features ﬁne-tuning method able deal tradeoﬀ precision recall aiming largest section reports discusses experiments section summarizes major ﬁndings. sprl algorithm recognizes spatial objects language spatial relation signaled spatial indicator. trajector spatial role label assigned word phrase denotes object spatial scene speciﬁcally object moves. landmark spatial role label assigned word phrase denotes location trajector object spatial scene. spatial indicator spatial role label assigned word phrase signals spatial relation trajector landmark. work apply sprl algorithm developed work kordjamshidi moens models problem structured prediction task taskar jointly recognizes spatial relation word sentence part spatial relation described vector local features denoted φword including linguistically motivated lexical syntactical semantical features words lexical surface form semantic role part-of-speech lexical surface form words neighborhood. feature vector used relate word spatial role i.e. spatial indicator trajector landmark hence represented respectively. encoding linguistically motivated features pairs words relational features relative position sentence distance terms number words path obtained syntactic parser. sprl model trained training sentences annotated output labels. following training system outputs spatial relations found sentence test composed sentences corresponding spatial roles. main research question approached paper regards possibility improving quality φword concatenating view feature vector. derives secondary research question possibility encoding visual information coco images word embeddings learning model able captions simpliﬁed representation visual objects annotated corresponding image relative position. assume necessary condition correctly forecast visual output given textual description embedding layer successfully encoding spatial information textual description assuring suitable word embedding speciﬁc task related sprl. another research question regards importance feature selection order discard embedding features directly related sprl task since data derived coco created sprl; therefore features noise sprl. microsoft coco data collection images featuring complex everyday scenes contain common visual objects natural context. coco contains photos object types total million labeled instances images. image written caption descriptions. visual objects within image tight-ﬁtted bounding boxes annotated segmentation masks seen fig.. boxes containing visual objects given coco’s annotation coordinates bounding boxes. annotation style ruled predicates alone below beside visual objects fig.. information encoded sparse target vector ﬁrst three positions encode predicate one-hot vector style ensuing positions encode index visual objects also one-hot vector style i.e. positions encode predicates plus positions encode index ﬁrst argument plus positions second argument totalizing positions target vector. predicate alone i.e. single visual object annotated image last positions zeros. despite large number annotated objects image ms-coco several objects belonging category image small number categories image. average ms-coco data contains categories image yielding instances image annotation system based assumptions learning spatial arrangement visual objects belonging category useful objects placed center image salient likely present captions. therefore system ranks bounding boxes centered least centered starts selecting centered bounding ﬁrst visual object. then searches second higher ranked bounding lower rank reaches visual object belonging diﬀerent category list instances i.e. system selects pair visual objects belonging diﬀerent categories. summary system learns captions spatial relation salient pair objects belonging diﬀerent categories. instance fig. system selects centered sheep generate target output captions yielding training examples. notice cited captions. input deep model textual information provided coco’s captions i.e. sequence words encoded k-dimensional one-hot vectors vocabulary size assumed words. since coco’s captions shorter words system cuts texts limit words; therefore data pair caption composed sparse matrix dimension target vector dimensions model implemented keras pipeline composed linear embedding layer original version lstm network proposed hochreiter schmidhuber deep multilayer perceptron fig.. embedding layer receives sparse input representing sentence encodes one-hot vector representation words dense vectors dimensions provided sequentially lstm extracts ns-dimensional vector sentence vector representation sentence mapped sparse spatial representation mlp. also evaluated architecture lstm directly predicts sparse output vector result better using mlp. latent representation sentences i.e. sentence-level embedding makes possible choice suitable dimension lstm output rather forcing lstm output sparse -dimensional target vector. i.e. maps -dimensional one-hot vector representation words nw-dimensional continuous vector representation system calculates state variables lstm starting input gate point word-level sentence-level embeddings given respectively. ns-dimensional sentence embedding produced iteration lstm ready processed mlp. therefore lstm output sub-sampled rate yielding i.e. input adopted sigmoidal hidden layers sigmoidal output layer. optimal number hidden layers empirically determined based performance ms-coco. model given evaluating diﬀerent objective functions combined diﬀerent activity weight regularizers available keras decided implement custom objective function gathering ideas support vector learning. training method yields following constrained optimization problem objective function hinge loss position intended output vector caption scaled shifted assume values cardinality training data embedding adjustable lstm parameters adjustable parameters position output vector estimated model caption vector synaptic weights neuron layer keras allows constraints network parameters optimization. adopted constraints regularizes model upper bounding norm vector synaptic weights neurons. note adopted loss function penalizes examples violate given margin misclassiﬁed i.e. estimated output smaller response positive example estimated output larger response negative example training examples ignored optimization i.e. don’t participate deﬁning decision surface. method introduced section requires scalar random variable target output. however target output semeval -dimensional one-hot vector indicating spatial roles i.e. therefore convert binary number binary digits decimal number i.e. scalar. even assuming discrete approximation joint density e.g. normalized histograms calculation several random variables computationally unfeasible. therefore adopt indirect approach applying principle max-relevance min-redundancy peng according principle possible maximize jointly solving following problems idea indexes simultaneously maximize relevance minimize redundancy notice procedure requires calculation matrix rn×n whose elements mutual information values however naive approach since method doesn’t take account redundancy embedding features original sprl features φword. computational cost increases signiﬁcantly considering whole problem. xsprl original feature φword complete problem modeled constant relation manipulated indexes i.e. mutual information original sprl features output well mutual information pairs sprl features don’t matter optimization problem alleviating computational cost. therefore simpliﬁed follows issues observe applying trained sprl data unbalanced relation precision recall worsens embedding resulting damage issue usually solved manipulating threshold; however larger gain obtained manipulating parameters output layer. therefore propose ﬁne-tuning output layer maximizing approximation squared. start analyzing simplest approach sign returns according sign argument number examples number positive negative examples respectively outputs hidden layer positive example negative example respectively. unfortunately sign function suitable gradient based optimization methods; therefore approximate function hyperbolic tangent yielding approximate whose relation given section methods evaluated means experiments semeval- benchmark data task spaceeval. start evaluating embedding model coco evaluate contribution spatial-speciﬁc embedding multiclass classiﬁcation words spatial roles ﬁnally structured prediction spatial triplets using algorithm kordjamshidi moens subsection reports performance indexes deep model described section predicting annotation coco testing data. model trained captions evaluated test composed captions. according experiments deep model best performance test data -dimensional word embedding dimensional sentence embedding meaning embedding matrix ditraining word embedding extracted enables clustering words classes seen fig. shows projection ﬁrst eigen directions embedding representing visual objects. fig. shows projection sentence-level embedding four pairs sentences describing scene diﬀerent manners except pair sentences whose spatial meaning changed order check sensitivity model spatial information i.e. plotted larger dispersion pairs. experiments multiclass classiﬁcation trained classify words spatial roles. adopted single sigmoid hidden layer neurons linear output layer neurons encode output one-hot vector trained using sentences evaluated using sentences compose train test data sets semeval task spaceeval. results summarized tables gains obtained using view improved selecting complementary features embedding employing method explained section seen table table presents results application tuning method mance view usual wordvec embedding mikolov trained skip-gram model coco captions trained view concatenated original sprl features generate results table view yields performance gains experiments structured prediction used original sprl algorithm kordjamshidi moens predict spatial role words also compose words triplets i.e. structured paper introduces approach transferring spatial knowledge multimodal data view. experiments provide evidence eﬀectiveness method transferring information useful improving performance sprl algorithms specially classifying words spatial roles. experiments also provide evidence eﬀectiveness algorithms complementary feature selection maximization introduced sections improving gains obtained using view. believe results reported paper improve increasing amount annotated data. notice despite large cardinality coco data small variety visual objects gold standard i.e. object categories", "year": 2016}