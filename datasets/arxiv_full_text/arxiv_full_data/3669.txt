{"title": "Yeah, Right, Uh-Huh: A Deep Learning Backchannel Predictor", "tag": ["cs.CL", "cs.CV", "cs.HC", "cs.LG", "cs.SD"], "abstract": "Using supporting backchannel (BC) cues can make human-computer interaction more social. BCs provide a feedback from the listener to the speaker indicating to the speaker that he is still listened to. BCs can be expressed in different ways, depending on the modality of the interaction, for example as gestures or acoustic cues. In this work, we only considered acoustic cues. We are proposing an approach towards detecting BC opportunities based on acoustic input features like power and pitch. While other works in the field rely on the use of a hand-written rule set or specialized features, we made use of artificial neural networks. They are capable of deriving higher order features from input features themselves. In our setup, we first used a fully connected feed-forward network to establish an updated baseline in comparison to our previously proposed setup. We also extended this setup by the use of Long Short-Term Memory (LSTM) networks which have shown to outperform feed-forward based setups on various tasks. Our best system achieved an F1-Score of 0.37 using power and pitch features. Adding linguistic information using word2vec, the score increased to 0.39.", "text": "abstract using supporting backchannel cues make human-computer interaction social. provide feedback listener speaker indicating speaker still listened expressed different ways depending modality interaction example gestures acoustic cues. work considered acoustic cues. proposing approach towards detecting opportunities based acoustic input features like power pitch. works ﬁeld rely hand-written rule specialized features made artiﬁcial neural networks. capable deriving higher order features input features themselves. setup ﬁrst used fully connected feed-forward network establish updated baseline comparison previously proposed setup. also extended setup long short-term memory networks shown outperform feed-forward based setups various tasks. best system achieved f-score using power pitch features. adding linguistic information using wordvec score increased robin ruede robin.ruedestudent.kit.edu markus m¨uller m.muellerkit.edu sebastian st¨uker sebastian.stuekerkit.edu karlsruhe institute technology institute anthropomatics robotics germany alex waibel alexander.waibelkit.edu karlsruhe institute technology institute anthropomatics robotics germany carnegie mellon university interact pittsburgh social. humanoid robots interactive toys virtual assistants even virtual psychiatrists pets attempt emotional social dimension human interaction beyond improving user experience existing dialog systems thus require increasingly skillful adept social interaction. social dialogs however much less well understood goal directed ones. particular outcome indirect goals growing mutual understanding empathizing bonding entertaining humans. present paper proposing neural network based system generate social response. ﬁrst attempt regard aims predict suitable social response human speakers take ﬂoor sharing thoughts experiences. so-called backchannel involves short phrases whose role signal another speaker listening paying attention. extensions also empathize conﬁrm approve disapprove. conversational speech complement turn taking rapid questions responses exchanged. despite simple function however surprisingly complex must chosen properly timed correctly placed appropriate intervals. also responds content emotion discourse state. paper describe neural network approach learning production proper cues. focus short phrasal cues longer stretches conversational speech another speaker taken ﬂoor. appropriate prediction backchanneling learned human conversation includes acoustic linguistic features. work recurrent neural networks learn choice placement appropriate cues conversational data special attention given producing causal backchanneling i.e. generation produced real-time systems information past. paper organized follows next section provide overview related work. section describe approach detail followed overview experimental setup section results experiments presented section paper concludes outlook future work section different approaches towards prediction proposed past. based different types predictors wide variety input modalities. modalities include acoustic features like pause pitch also visual cues like head movement. addition direct features additional information sources like language models part speech tagging exist. many approaches rule based. proposed method uses acoustic features. authors state important acoustic phenomena prediction occur right features used pause information well pitch conducted experiments dutch corpus report important feature work duration pause. proposed similar approach triggering pitch pause regions english japanese. building rule based system might prove difﬁcult rules manually created time-consuming difﬁcult generalize. works included data-driven methods classiﬁer trained output classiﬁer post-processed. proposes approach incorporates sequential probabilistic models like hidden markov models conditional random fields. used features including gaze several features derived audio signal e.g. downslopes pitch certain types volume changes. another approach predicting different types attempted detecting real-time also proposed past. exists another category systems make artiﬁcial neural networks data-driven method require handwritten rules. shown versatile tool ability learn relevant features automatically. ﬁrst approach towards detecting speech acts proposed ries used combination hmm. stolcke also proposed based methods modelling dialogue acts past also proposed based approach mainly data-driven requiring minimal post-processing network outputs. ﬁrst approach used basic based setup reﬁned. objective evaluation systems prediction difﬁcult behaviour speaker-dependent subjective. objective measurement f-score established. provides comparison different approaches evaluation. addition objective measures user studies also possibility evaluate systems like past general study occurrence respect role facilitating attentive listening also exists different kinds phrasal non-committal positive negative questioning cetera. simplify problem predicting predict trigger times type ignoring distinction different kinds responses. neural network able learn advantageous feature representations own. hence feeding absolute pitch power values given time context enables network automatically extract relevant information pitch slopes pause triggers used related research addition pitch power also evaluated using acoustic features fundamental frequency variation mel-frequency cepstral coefﬁcients finally tried adding encoding speakers’ word history listener backchannel using wordvec assess whether setup beneﬁts multimodal input features. assumed separate synchronized audio channels corresponding transcripts speaker listener. needed decide areas audio train network. wanted predict online fashion without using future information needed train network detect segments audio speaker track would potentially cause listener track. chose beginning utterance anchor used ﬁxed context positive prediction area. also needed choose negative examples network would biased always predict selecting range seconds area listener explicitly decided give backchannel response yet. resulted fully balanced training dataset. initially used feed forward network architecture. input layer consists chosen features previously selected ﬁxed time context. output layer softmax neurons representing categories used back-propagation train network outputs non-bc prediction areas. need consider outputs softmax function guarantees one. evaluated multiple different combinations network depths neuron counts. example architecture hidden layers seen figure placement future dependent timing previous bcs. probability increases longer periods without listener feedback. accommodate this want network also take previous internal state outputs account. modifying architecture long-short term memory layers instead feed forward layers. used switchboard dataset consists english telephone conversations minutes hours total. pairs participants across united states encouraged talk speciﬁc topic chosen randomly possibilities. conversation partners topics selected people would talk other every person would discuss speciﬁc topic once. telephone conversations annotated transcriptions word alignments total utterances million words. split dataset randomly conversations training validation evaluation. used annotations switchboard dialog corpus decide utterances classify bcs. swda contains categorical annotations utterances half data switchboard corpus. chose common unique utterances marked swda. swda incomplete identify utterances text. manually included additional utterances missing swda transcriptions present original transcriptions going common utterances manually selecting seemed relevant ‘um-hum yeah’ ‘absolutely’. common data select utterances categorized used training ﬁrst ﬁltered noise markers laughter transcriptions. utterances speech disﬂuencies chose either silence another them. method total utterances words labelled bcs. used janus recognition toolkit parts feature extraction features extracted frame windows frame shift resulting samples feature dimension second. data change much every also test different context strides extracting every n-th frame. example context stride corresponds data frames. wordvec chose also emit frame every consistency containing encoding last non-silent word ended time frame. used theano lasagne rapid prototyping testing different parameters. evaluate different hyperparameters trained multiple network conﬁgurations various context lengths context strides network depths layer sizes activation functions optimization methods weight initialization methods layer types lstm networks tested prone overﬁtting quickly. tried methods regularization overcome this. ﬁrst dropout training randomly dropped speciﬁc portion neuron outputs layer training batch evaluated dropout layer combinations increasing layer sizes proportionately improve results. second adding l-regularization constant factor greatly reduced overﬁtting slightly improved results. interpret output value neural networks probability occurring given time. output noisy ﬁrst apply low-pass ﬁlter. ensure prediction future information gaussian ﬁlter code extraction training postprocessing evaluation available https//github.com/phiresky/backchannel-prediction. repository also contains script reproduce results paper. asymmetrically multiple standard deviation side would range future offset last frame prediction target time. means latency prediction increases choose complete right half bell curve keeping latency cost accuracy ﬁlter. low-pass ﬁlter select every area value exceeds given threshold. trigger either beginning areas ﬁrst local maximum depending largest acceptable latency. varies depending chosen allowed margin error deﬁned subsection example postprocessing process seen figure determined optimal postprocessing hyperparameters network conﬁguration allowed margin error automatically using bayesian optimization validation f-score utility function. margin error resulting standard deviation ranged ﬁlter cut-off ranged margin error prediction happen delay second ground truth. choosing margin error allows smaller delay selected standard deviation ranged ﬁlter cut-off ranged causing predicted trigger happen earlier. training data contains two-sided conversations. output predictor relevant segments person talking evaluation monologuing segments. deﬁne monologuing segment maximum possible time range person continuously talking person continuously talking least seconds. person continuously talking emitting utterances silence bcs. consider segments minimum length seconds exclude sections alternating conversation. segments participant talking producing backchannels without taking turn. deﬁne prediction time correct within given margin error onset correct utterance. testing predictions error margin also provide results margins used related research. comparison also evaluated random predictor baseline. predictor knows correct count audio returns uniformly distributed trigger times. denote network layer conﬁguration input neurons neurons output. tested different context widths. context width means range beginning backchannel utterance. results improved increasing context width initial value performance peaked context seen table longer contexts tended cause predictor trigger late. tested using every n-th frame input data. even though initially performance reasons noticed training every single frame worse performance skipping every second frame overﬁtting. taking every fourth frame seems miss much information performance peaks context stride seen table tested different combinations features using solely power ﬁrst approach. adding prosodic features gives great improvements. using prosodic feature performs worse together absolute pitch value. adding mfccs seem improve performance meaningful also using pitch table details. note using wordvec performs reasonably well method indirectly encodes time since last utterance similar power feature. table shows comparison feed forward lstm networks. parameter count number connection weights network learns training. note lstms higher performance even similar parameter counts. compared different layer sizes lstm networks shown table network depth hidden layers worked best results adequate single hidden layer three hidden layers. table ﬁnal results given completely independent evaluation data set. compared results system. used dataset focused ofﬂine predictions meaning network future information available evaluated performance whole corpus including segments silence alternating conversation. adjusted baseline evaluation system match setup removing monologuing constraint described subsection changing margin error seen table predictor performs better. related research used different languages datasets evaluation methods rendering direct comparison difﬁcult slightly different tasks. table shows results presented evaluation method. provide scores different margins error used research. subjectively missing trigger acceptable false positive also provide result balanced precision recall. note later margin center margin width higher performance allows latency predictions means choose better postprocessing parameters described subsection presented approach predict using neural networks. reﬁned methods network training well different network architectures could improve f-score contrast previous experiments. addition evaluating different hyperparameter conﬁgurations also experimented lstm networks lead improved results. best system achieved f-score used linguistic features wordvec basic assuming availability instant speech recognizer using reference transcripts. low-latency speech recognition possible next steps would combine systems. work needed evaluate methods adding word vectors input features analyze problems approach. tested feed forward neural networks lstms architectures like timedelay neural networks also called convolutional neural networks also give interesting results. approach choosing training areas optimal delay last utterance speaker backchannel vary signiﬁcantly. possible solution would align training area last speaker utterance instead backchannel start. backchannels largely subjective phenomenon user study would helpful subjectively evaluate performance predictor compare human performance chosen evaluation method. another method would consensus backchannel triggers combining predictions multiple human subjects single speaker channel described huang parasocial consensus sampling table results validation set. results following setup otherwise stated lstm conﬁguration input features power pitch ffv; context width context frame stride margin error precision recall f-score given validation data set.", "year": 2017}