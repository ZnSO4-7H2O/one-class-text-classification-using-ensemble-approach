{"title": "Nonparametric Bayesian Double Articulation Analyzer for Direct Language  Acquisition from Continuous Speech Signals", "tag": ["cs.AI", "cs.CL", "cs.LG", "stat.ML"], "abstract": "Human infants can discover words directly from unsegmented speech signals without any explicitly labeled data. In this paper, we develop a novel machine learning method called nonparametric Bayesian double articulation analyzer (NPB-DAA) that can directly acquire language and acoustic models from observed continuous speech signals. For this purpose, we propose an integrative generative model that combines a language model and an acoustic model into a single generative model called the \"hierarchical Dirichlet process hidden language model\" (HDP-HLM). The HDP-HLM is obtained by extending the hierarchical Dirichlet process hidden semi-Markov model (HDP-HSMM) proposed by Johnson et al. An inference procedure for the HDP-HLM is derived using the blocked Gibbs sampler originally proposed for the HDP-HSMM. This procedure enables the simultaneous and direct inference of language and acoustic models from continuous speech signals. Based on the HDP-HLM and its inference procedure, we developed a novel double articulation analyzer. By assuming HDP-HLM as a generative model of observed time series data, and by inferring latent variables of the model, the method can analyze latent double articulation structure, i.e., hierarchically organized latent words and phonemes, of the data in an unsupervised manner. The novel unsupervised double articulation analyzer is called NPB-DAA.  The NPB-DAA can automatically estimate double articulation structure embedded in speech signals. We also carried out two evaluation experiments using synthetic data and actual human continuous speech signals representing Japanese vowel sequences. In the word acquisition and phoneme categorization tasks, the NPB-DAA outperformed a conventional double articulation analyzer (DAA) and baseline automatic speech recognition system whose acoustic model was trained in a supervised manner.", "text": "abstract—human infants discover words directly unsegmented speech signals without explicitly labeled data. main problem paper develop computational model estimate language acoustic models discover words directly continuous human speech signals unsupervised manner. purpose propose integrative generative model combines language model acoustic model single generative model called hierarchical dirichlet process hidden language model hdp-hlm obtained extending hierarchical dirichlet process hidden semi-markov model proposed johnson inference procedure hdp-hlm derived using blocked gibbs sampler originally proposed hdp-hsmm. procedure enables simultaneous direct inference language acoustic models continuous speech signals. based hdp-hlm inference procedure develop novel machine learning method called nonparametric bayesian double articulation analyzer directly acquire language acoustic models observed continuous speech signals. assuming hdp-hlm generative model observed time series data inferring latent variables model method analyze latent double articulation structure i.e. hierarchically organized latent words phonemes data unsupervised manner. also carried evaluation experiments using synthetic data actual human continuous speech signals representing japanese vowel sequences. word acquisition phoneme categorization tasks npbdaa outperformed conventional double articulation analyzer baseline automatic speech recognition system whose acoustic model trained supervised manner. main contributions develop probabilistic generative model integrates language acoustic models i.e. hdp-hlm. derive inference method this propose npb-daa. show npb-daa discover words directly continuous human speech signals unsupervised manner. order acquire language continuous speech signals exposed. word segmentation problem identifying word boundaries continuous speech. speech signals given infants isolated words task easy them. however known graduate school information science engineering ritsumeikan university noji higashi kusatsu shiga japan s.nagasaka nakashima}em.ci.ritsumei.ac.jp relatively small number infant-directed utterances consist isolated word infants knowledge words phonemes innately problem could solved relatively easily. contrary fact language different lists phonemes words clearly shows infants acquire developmental processes. learning problem language acquisition continuous speech signals difﬁcult infants access truth labels speech recognition results. words language acquisition process must completely unsupervised.the main problem paper develop computational model estimate language acoustic models discover words directly continuous human speech signals. modern automatic speech recognition systems language model represents knowledge words distributional probabilities well acoustic model represents knowledge phonemes acoustic features e.g. usually trained using large transcribed speech datasets linguistic corpora supervised learning. however infants access explicitly labeled datasets. acquire language acoustic models acoustic speech signals unsupervised manner. question kind cues human infants utilize discover words continuous speech signals arises. saffran listed three types cues word segmentation prosodic distributional co-occurrence prosodic cues rely acoustic information postutterance pauses stressed syllables acoustically distinctive ﬁnal syllables. distributional cues represent statistical relationships pairs neighboring speech sounds. co-occurrence cues used children learn words detecting sounds co-occur certain entities environment. although many researchers considered distributional cues complex infants saffran reported word segmentation ﬂuent speech accomplished -month-old infants based solely distributional cues also reported distributional cues seem used infants months earlier cues results imply infants fundamental mechanism estimate word segments using distributional cues. addition fundamental segmentation mechanism using distributional cues prosodic co-occurrence cues believed help word segmentation task supplemental cues viewpoint phonemic category acquisition distributional patterns sounds considered provide infants clues phonemic structure language based ﬁndings paper focus distributional cues. explore fundamental computational mechanism discover words speech signals using distributional cues develop unsupervised machine learning method discover phonemes words directly unsegmented speech signals paper propose unsupervised learning method called nonparametric bayesian double articulation analyzer automatically estimate double articulation structures i.e. hierarchically organized latent words phonemes embedded speech signals. propose computationally valid explanation simultaneous acquisition language acoustic models. develop npbdaa introduce probabilistic generative model called hierarchical dirichlet process hidden language model well inference algorithm. remainder paper organized follows. section describes background proposed method. section presents hdp-hlm extending hierarchical dirichlet process-hidden semi-markov model proposed johnson hdp-hlm probabilistic generative model integrates acoustic language models continuous speech signals. section describes inference procedure hdp-hlm proposed npbdaa. sections evaluate effectiveness proposed method using synthetic data actual sequential vowel speech signals. section concludes paper. statistical computational models many kinds unsupervised machine learning methods word segmentation proposed last decades brent proposed model-based dynamic programming recovering deleted word boundaries natural-language text. mbdp- presumes information source generating text explicitly segments target text maximize text’s probability. venkataraman proposed statistical model segmentation word discovery phoneme sequences improving brent’s algorithm. recently bayesian nonparametrics including hierarchical dirichlet process hierarchical pitman-yor process enabled sophisticated methods word segmentation. models fully bayesian generative models make possible calculate appropriately smoothed n-gram probability word long context. theoretically treat inﬁnite number possible words. goldwater proposed hdp-based word segmentation method showed taking context account important statistical word segmentation. mochihashi proposed nested pitman-yor language model letter n-gram model based hierarchical pitman-yor language model embedded word n-gram model. also developed forward ﬁltering however mentioned word segmentation methods presume transcribed phoneme sequences text data without recognition errors obtained learning system. practice acquiring language model containing inventory words learning system i.e. infant recognize speech signals without knowledge words knowledge phonemes and/or syllables acoustic model. recognition task phoneme recognition error rate inevitably becomes high. overcome problem several researchers proposed word discovery methods utilizing co-occurrence cues. ambitiously implemented computational model enables robot autonomously discover words multimodal sensory input. results imperfect compared recent state-of-art results. however results showed possible develop cognitive models process sensor data acquire lexicon without need human transcription labeling. iwahashi implemented interactive learning method robot acquire spoken words humanrobot interaction using audio-visual interfaces. learning process carried on-line incrementally actively unsupervised manner. iwahashi also proposed method enables robot learn linguistic knowledge human-robot communication unsupervised manner. model combines speech visual behavioral information probabilistic framework. though performance still limited model considered sophisticated model proposed al.’s previous study viewpoint statistical machine learning. basis work iwahashi developed integrated online machine learning system combining speech visual tactile information obtained interaction. enabled robots learn beliefs regarding speech units words concepts objects motions grammar pragmatic communicative capabilities. called system lcore. araki built robot formed object categories acquired names combining multimodal latent dirichlet allocation npylm. showed iterative learning mlda npylm increases word segmentation performance using distributional cues co-occurrence cues simultaneously reported prediction accuracy decreases phoneme recognition error rate increases. overcome problem nakamura integrated statistical models word segmentation multimodal categorization. showed robot autonomously form object categories related words continuous speech signals continuous visual auditory haptic information updating language categorization models iteratively information pairs consist spoken utterances mobile robot’s estimated current location without prior linguistic knowledge phoneme acoustic model. optimized word list using model selection method based description length criterion. word segmentation using distributional cues noisy input using cooccurrence cues mitigate effects phoneme recognition errors word discovery task. however whether word discovery task achieved solely speech signals still open question. neubig extended unsupervised morphological analyzer proposed mochihashi enabled analyze phoneme lattices. heymann modiﬁed neubig al.’s algorithm proposed suboptimal two-stage algorithm. heymann reported proposed method outperformed original method experiment used lattice input generated artiﬁcially text input. addition used discovered language model phoneme recognition iterative manner reported recognition performance improved elsner proposed computational model jointly performs word segmentation learns explicit model phonetic variation. however start acoustic sound dictated noisy text i.e. recognized phoneme sequences errors. model include acoustic model learning. showed effect phoneme recognition errors mitigated extent using distributional information appropriately. however methods except iwahashi used acoustic model previously trained supervised manner. therefore models insufﬁcient constructive model language acquisition speech signals. hence unsupervised learning acoustic model also important problem. contrast word segmentation task acquisition acoustic model basically categorization task feature vectors transformed continuous speech signals. mixture models including hidden markov models gaussian mixture models used model phoneme category acquisition. example lake used online mixture estimation model vowel category learning. model originally proposed vallabha however phoneme acquisition proven complex categorization task feature space. distribution feature vectors phoneme overlap other actual sound phoneme depends context. feldman pointed feedback information segmented words important phonetic category acquisition. demonstrated effect simulations using bayesian models. proposed hierarchical bayesian model discover proper sub-word units acoustic model unsupervised manner. however model estimate language model. also proposed hierarchical bayesian model simultaneously discovering phonetic inventory letter-to-sound mapping rules basis transcribed data only. method completely unsupervised learning method speech signals automatically determine relations sounds transcribed alphabets forms acoustic model unsupervised manner. several studies simultaneous unsupervised learning acoustic language models. however small number statistical learning methods simultaneously acquire integrated acoustic language models proposed. brandl attempted develop unsupervised learning method enables robot simultaneously obtain phonemes syllables words acoustic speech. successfully build system reported preliminary results. walter proposed word discovery method uses hmm-based method ﬁnding acoustic unit descriptors parallel dynamic time warping technique ﬁnding word segments. however model still heuristic viewpoint probabilistic computational models. feldman pointed word segmentation phonetic category acquisition undoubtedly mutually dependent. therefore theoretically integrated probabilistic generative model simultaneous acquisition language acoustic models desirable. recently kamper proposed probabilistic computational models achieved unsupervised direct word discovery continuous speech signals. however provide explicit integrated probabilistic generative model unsupervised simultaneous learning language acoustic models. develop integrated theoretical model authors introduced general concept double articulation analysis. general point view unsupervised word discovery speech signals regarded double articulation analysis time series data representing speech signal. double articulation structure well-known two-layer hierarchical structure i.e. word sequence generated language model word sequence phonemes phoneme outputs observation data period persists. word discovery problem becomes general problem analyzing time series data potentially double articulation structure estimating latent acoustic model well latent language model. taniguchi proposed double articulation analyzer combining sticky hdp-hmm npylm. sticky hdp-hmm proposed nonparametric bayesian extension applied human motion data extract unit motion unsegmented human motion data. however simply used nonparametric bayesian methods sequentially. integrate models single generative model. therefore many recognition categorization errors result ﬁrst latent letter recognition process i.e. segmentation process sticky hdp-hmm performance subsequent process i.e. unsupervised chunking npylm deteriorates. terminology latent letter latent word basically correspond phoneme word speech signals respectively. paper call method conventional order differentiate newly proposed paper i.e. npb-daa. conventional successfully applied human motion data driving behavior data also considered potentially double articulation structure. conventional used various purposes e.g. segmentation prediction data mining topic modeling video summarization conventional owes successful result respect driving behavior data fact driving behavior data continuous smooth compared speech signals. driving letter corresponds phoneme continuous speech signals recognition error rate still low. however expected straightforward application conventional speech signals inevitably turn badly. therefore based background mentioned above paper propose integrated probabilistic generative model hdp-hlm representing latent double articulation structure contains language model acoustic model. assuming hdp-hlm generative model observed time series data inferring latent variables model analyze latent double articulation structure data unsupervised manner. novel double articulation analyzer developed basis hdp-hlm inference algorithm. hdp-hlm-based double articulation analysis method called npb-daa. section propose novel generative model hdp-hlm time series data potentially double articulation structure extending hdp-hsmm indicated name hdp-hlm latently contains language model. contrast conventional case latent state transits next state basis markov process hdp-hmm latent word hdp-hlm transits next latent word basis language model. illustrative overview proposed method target task shown fig. naturally derive inference procedure hdp-hlm based blocked gibbs sampler. first brieﬂy describe hdp-hsmm. describe hdp-hlm. hdp-hsmm nonparametric bayesian extension conventional hidden semi-markov model unlike hdp-hmm nonparametric bayesian extension conventional hidden markov model hdp-hsmm explicitly models duration time hidden state. graphical model hdp-hsmm shown fig. generative process hdp-hsmm efﬁcient sampling inference procedure based backward ﬁltering forward sampling technique proposed constructing blocked gibbs sampler similar algorithm proposed hdp-hmm algorithm derived weak-limit approximation number hidden super states. computational cost message passing algorithm reduced length observed data state cardinality dmax maximal duration super state truncation. order almost backward ﬁltering forward sampling algorithm hdphmm except constant factor dmax. generative model time series data potentially double articulation structure obtained extending hdp-hsmm. graphical model proposed hdp-hlm shown fig. generative model hdp-hlm super state corresponds word spoken language fundamental idea extension. i-th super state phoneme sequence length i-th word generative process hdp-hlm described follows. represent stick breaking process dirichlet process respectively parameters hyperparameters global transition probability becomes base measure transition probability distributions transition probability distribution related i-th super state. variable s-th super state sequence super states frame duration variables hidden state observation time frame respectively. parameters emission distribution duration distribution super state described additionally base measures emission distribution duration distribution. function represent emission duration distributions respectively. time frames frames corresponding start point point segment corresponding contrast case assumes hidden state transits next hidden state according markov process hidden semi-markov model assumes hidden super state transits next hidden super state probabilistically determined duration time sampled duration distribution super state sampled categorical distribution related previous super state zs−. super latent letter sequences. furthermore outputs representing transition probability latent letter next latent letter. contrast base measure hyperparameters language model outputs representing transition probability latent word next latent word. superscripts indicate language model word model respectively. latent letters contained i-th latent word sequentially sampled wik−. k-th latent letter i-th latent word represented wik. emission distribution duration distribution parameters j-th latent letter respectively. base measures generate respectively. variable s-th latent word sequence latent words corresponds super state hdphsmm frame duration wzsk latent letter s-th latent word frame duration lsk. variable hidden state observation time frame rspectively. time frames frames corresponding start point point segment corresponding respectively. contrast hmms duration distribution explicitly determined latent letter hdp-hlm. hdp-hlm inherits property hdp-hsmm duration time latent letter k-th latent letter s-th latent word sampled word sequence drawn duration distribution duration parameter latent letter lsk. duration latent word becomes dsk. assume poisson distribution duration distribution latent word also follows poisson distribution. case poisson parameter duration distribution becomes relation owes reproductive property poisson distributions. hdp-hlm latent word determines latent letter sequence wzsk based determined sequence duration drawn observations drawn emission distribution corresponding lsk. maps represent indices words letters respectively latent word sequence time using generative model continuous time series data latent double articulation structure generated. paper assume observed time series data represents feature vector speech signal time generated way. generally hdp-hlm applied kind time series data double articulation structure. viewpoint language acquisition review generative model. conventional composed separated machine learning methods i.e. sticky hdp-hmm encoding observation data letter sequences npylm chunking letter sequences represents probability latent super state transitions different super state next time step. probability obtained marginalizing super states time step variable represents probability latent super state becomes time step probability obtained marginalizing duration variable probability idt+ shows emission probability observed data yt+t+d given condition duration hdp-hsmm time steps super state share emission distribution. therefore likelihood super state i.e. calculated easily. surprisingly hdp-hlm exact procedure calculating backward messages hdp-hsmm used. obtain message passing algorithm hdphlm replacing super state hdp-hsmm latent word hdp-hlm. likelihood latent word i.e. idt+ different message passing algorithms. likelihood occurrence latent word becomes calculation looks complicated ﬁrst glance. however value efﬁciently calculated using dynamic programming. deﬁne forward message probability k-th latent letter relevant latent word time emitting observations forward message recursively calculated follows result idt+ applying calculation formula shown above backward messages calculated. using calculation procedure backward messages forward sampling procedure proposed hdp-hsmm employed. backward ﬁltering forward sampling procedure enables blocked gibbs sampler directly sample latent words observation data without explicitly sampling latent letters hdp-hlm. word sequences. hand transition probabilities correspond word bigram letter bigram models npylm respectively. therefore contains information regarding language model. hand contains information regarding acoustic model corresponds sticky hdp-hmm conventional daa. hdp-hlm assumes language model consists word bigram model. mochihashi compared bigram trigram language models showed trigram assumption hardly improved word segmentation performance although computational cost complexity increased therefore bigram assumption must appropriate word segmentation word discovery task. derive efﬁcient inference procedure twolayer hierarchical generative model inference procedure infer acoustic model language model simultaneously. section derive approximated blocked gibbs sampler hdp-hlm. sampler simultaneously infer latent letters latent words language model acoustic model. concurrently inference procedure estimate overall double articulation structure continuous time series data. therefore propose unsupervised machine learning method npb-daa. overall inference procedure shown algorithm hdp-hsmm backward ﬁltering forward sampling procedure adopted instead direct assignment procedure. latent state strongly depends neighboring latent states direct assignment procedure naive implementation gibbs sampler results poor mixing rate johnson showed blocked gibbs sampler using backward ﬁltering forward sampling procedure simultaneously sample hidden states observed sequence outperforms direct-assignment gibbs sampler. extending backward ﬁltering forwardsampling procedure making applicable hdp-hlm obtain inference procedure hdp-hlm. sampling latent words {zs} observation data sampling letter sequences latent words parameters updated. parameters language model i.e. updated basis latent word sequences. parameters word model i.e. updated basis sampled letter sequences latent words. parameters acoustic model i.e. updated hidden state determined process sampling letter sequence algorithm subsidiarily obtained. accelerate mixing rate subsidiary sampling results obtained used updating acoustic model parameters. parameters sampled hdp-hsmm. details refer original paper hdp-hsmm introduced finally overall sampling procedure obtained described algorithm based generative model hdp-hlm inference algorithm shown algorithm proposed npb-daa obtained ﬁnally. assuming hdp-hlm generative model observed time series data inferring latent variables model analyze latent double articulation structure i.e. hierarchically organized latent words phonemes data unsupervised manner. call novel unsupervised double articulation analyzer npb-daa. validate ability proposed method infer latent double articulation structure time series data applied proposed npb-daa based hdp-hlm synthetic time series data. conventional employed comparative method. time series data generated using letters four words {w}w∈w letters words. four words generated randomly. sequence represents word generated combining {wiwi wili sequentially denotes k-th letter durations letters assumed follow poisson distributions parameters drawn gamma distribution whose parameters emission distribution assumed gaussian distribution whose parameters {...} represents index latent letters. variance emission distribution changed stages inference results compared. forty time series data items generated types latent word sequences. sixteen pairs words e.g. four sampled index latent word. concrete letter sequences latent word sampled according correspondence sub-sequence latent word. time series data latent word given generative model observation range latent word regarded hdp-hsmm whose super states correspond latent letters. therefore proposed model subsequence observation data corresponding latent word considered observed sequence generated hdp-hsmm. single sub-sequence observations corresponds latent word latent letter sequence could sampled using ordinal sampling procedure hdphsmm. however observations containing latent word share latent letter sequence therefore latent letter sequences observations latent word simultaneously sampled given latent letter sequence. employ approximate sampling procedure based sampling importance resampling also procedure hdp-hsmm. probability given. hdpj). hsmm also provides sampling procedure proposed distribution therefore consider weight procedure speciﬁcally sampled ﬁnal proposed distribution sample word model sampled word inventory {wi}i=...n. parameters npb-daa follows hyperparameters latent language model maximum number words weak-limit approximation. hyperparameters latent word model maximum number letters seven weak-limit approximation. hyperparameters duration distributions emission distributions gibbs sampling procedure iterated times. hyperparameters npb-daa heuristically given top-down manner referring size state space approximate duration phoneme. pitman-yor language model default values software. average log-likelihood shown fig. error bars represent standard deviation trials. results show proposed inference procedure worked appropriately gradually sampling probable latent variables iterations increased. contrast ordinal speech recognition tasks target task unsupervised learning task. speciﬁcally clustering task. therefore difﬁcult evaluate methods’ performance viewpoint precision recall estimated index cluster label corresponding ground truth data usually different. evaluated obtained result using adjusted rand index quantiﬁes performance clustering task data items clustered randomly cluster becomes contrast results clustering ground truth data becomes table shows estimated latent letters. estimated latent letters shows accurately method estimated latent letters correspond phonemes speech signals. table shows estimated latent words. estimated latent words shows accurately method estimated latent letters correspond words speech signals. tables column shows aris different higher implies accurate estimation latent variables. although latent letters obtained conventional decreases variance increases npb-daa decrease much. aris latent words show performance word segmentation conventional poor even latent letters larger contrast latent words estimated npb-daa conditions. shows npb-daa mitigate effects phoneme recognition errors word segmentation task obtained knowledge words improve phoneme recognition performance using contextual information. fig. shows change iterations case shows also increased gradually likelihood increases fig. results suggest npb-daa appropriate generative model better word segmentation performance corresponded higher likelihood model. check effects limit weak-limit approximation experiment maximum number letters weak-limit approximation. estimated latent words {...} estimated latent letters {...} estimated number latent letters {...} average {...}. result shows model work appropriately estimate number latent states owing nature bayesian nonparametrics limit sufﬁciently large. example estimated latent variables shown fig. shows results time series data generated latent word sequence input time series data shown ﬁgure. panel shows true latent letters latent words whereas panel beneath shows inferred results. vertical axes represent iteration gibbs sampling. fig. ﬁgure middle shows latent word sequence estimated using proposed method ﬁgure bottom shows estimated boundaries latent words. results show inference procedure works consistently estimate adequate boundary latent words given data. fig. example inference results sample data observation data latent letters latent words boundaries latent words. different colors denote different states. second experiment evaluated proposed method using japanese vowel speech signals test applicability proposed method actual human continuous speech signal. prepared four datasets. dataset corresponds speaker consisted audio data items. asked male female japanese speakers read artiﬁcial sentences aloud times natural speed recorded his/her voice. sentences prepared using words {aioi consisted japanese vowels representing phonetic symbols respectively. reordering words prepared two-word sentences e.g. aioi aioi aioi three-word sentences i.e. aioi two-word sentences consisted types word pairs three-word sentences generated randomly. recorded data encoded -dimensional melfrequency cepstrum coefﬁcient time series data using toolkit frame size shift respectively. twelve-dimensional mfcc data obtained input data eliminating power information original -dimensional mfcc data. result dimensional time series data frame rate obtained. hyperparameters latent language model maximum number words seven weak-limit approximation. hyperparameters latent word model maximum number letters seven weak-limit approximation. hyperparameters duration distributions conventional hyperparameters sticky hdp-hmm similar npbdaa possible. hyperparameters npylm used conventional gibbs sampling procedure iterated times. different random number seeds trials performed. parameters npb-daa given top-down manner heuristically referring size state space approximate duration phoneme. pitman-yor language model default values software. baseline method employed open-source continuous speech recognition engine julius widely used japanese speech recognition tasks. julius’s acoustic model trained using large number speech data supervised manner. prepared four conditions julius. ﬁrst called julius condition used julius phoneme recognition system preparing phoneme dictionary containing japanese vowels moreover julius’s dictionary also contains silb sile represent silence system requirements. encoding continuous speech signals phoneme sequences using julius phoneme recognizer unsupervised morphological analysis based npylm conducted discover words language model. second condition called julius condition also used latticelm unsupervised morphological analyzer lattice output system. method proposed neubig extension mochihashi’s npylm condition latticelm software used too. third fourth conditions called julius julius respectively prepared complete word dictionary contained words appeared target speech signal i.e.{aioi julius. condition provides almost upper bound performance task. except julius julius uses monophone-based acoustic model contained dictation kit. acoustic model trained supervised manner using large number labeled speech data. julius used triphone-based acoustic model comparison. julius http//julius.sourceforge.jp/. linux binary dictation-kit-v..-linux.tgz used experiment. software encodes recorded data -dimensional mfcc data including dynamic features uses speech recognition. respectively. letter shows phoneme clustering. high letter means accurate phoneme acquisition recognition. word shows word clustering. higher word means accurate word discovery recognition. corresponds method explained conditions. results npb-daa conventional show averaged trials. contrast npb-daa obtained maximum posteriori probability trials. advantage npb-daa method calculate posterior probability given dataset learning phase npb-daa derived generative model i.e. hdphlm integrates language acoustic models. contrast conventional similar methods appropriate generative models npb-daa obtain appropriate learning result referring probability. rows table show probability adequate criterion selecting learning result. results show npb-daa outperformed conventional also julius-based word discovery systems whose acoustic models trained supervised manner. reason acoustic models daas trained participant’s speech signals contrast julius’s acoustic model trained speech signals many speakers. words npbdaa acquired speaker-dependent acoustic model contrast julius used speaker-independent acoustic model. adaptation acoustic model speaker must increased npb-daa’s performance. results show naive application npylm recognized phoneme sequences results poor word acquisition performance especially conventional daa. because theory npylm presume letter sequences recognition errors existence phoneme recognition error deteriorates word segmentation performance. methods simply apply npylm obtained phoneme sequences i.e. conventional julius output results word compared letter ari. however latticelm presumes phoneme recognition errors extent could dramatically improve performance contrast julius improved word performance respect letter performance. julius also kept performance high respect word recognition task compared phoneme recognition task. note word error rate phoneme error rate julius research ﬁeld widely known good language model improves word phoneme recognition performance. npb-daa could improve performance word respect letter performance. however obtained adequate language model prevented score word becoming worse letter ari. achieve error-proof word acquisition direct inference latent words important npb-daa. inference procedure described section latent words sampled directly without sampling latent letters marginalizing possible latent letter sequences. achieves effect similar given language model inference process typical examples estimation results shown table npb-daa conventional daa. number parentheses represents estimated phoneme label space represents phoneme boundary number bold style represents sampled index word represents boundary successive words. example divided words i.e. npb-daa results word indices table sampled letters corresponding word underlined. although conventional could estimate single word npb-daa could estimate single word conventional results several phoneme recognition errors found. errors completely deteriorated following chunking process i.e. unsupervised morphological analysis using npylm past research frequently pointed out. shown table npb-daa phoneme recognition errors. however npb-daa latent words sampled basis marginalized phoneme distribution sampling concrete phoneme sequences. property sampling procedure seemed improve performance npb-daa. example estimated latent variables shown fig. shows results time series data corresponding vowel sequence input time series data i.e. -dimensional mfcc time series data shown ﬁgures. middle bottom ﬁgures show inference process. ﬁgure shows true latent letters latent words whereas bottom shows inferred result. vertical axes represent number gibbs sampling iterations. shows inference procedure worked human vowel sequence data could estimate adequate unit word. examine characteristics segmentation results npb-daa. table shows estimated latent words latent letter head tail. latent letter represents silence observed transition vowel another. silence speech signals transitional sounds observed phonemes treated manner uttered sounds model. question whether signals treated sounds generative model calls investigation. model phoneme simply represented single gaussian distribution although many past speech recognition systems assign richer structure phoneme e.g. three-state left-to-right emission distributions. room investigating whether phoneme model i.e. latent letter complex structure double articulation hierarchy sufﬁcient viewpoint unsupervised word discovery tasks. interesting result represents characteristic npb-daa latent word estimated aioi. speech signals corresponding kind transitional sound observed following aioi. npb-daa directly inferred latent word marginalizing latent letters. case seems likely latent words npb-daa hence generated result. regarded side effect approach i.e. marginalization latent letter sequences latent word. conﬁdent marginalization latent letters direct inference word sequences important improving performance unsupervised word segmentation continuous speech signals room consider side effect. npb-daa performed unsupervised word discovery condition training data consisted speech signals uttered speaker contrast julius whose acoustic model trained using many speakers’ speech signals. speaker-independent unsupervised word discovery continuous speech signals remains challenging problem acoustic features phonemes heavily depend speaker. gave four speakers’ speech signals npb-daa time letter word decreased respectively. contrast produced julius triphone acoustic model true word dictionary respectively. experiment audio data items recorded asking male female japanese speakers read artiﬁcial sentences used i.e. half data items used main experiment computational cost. observed speaker dependent phoneme models obtained npb-daa i.e. speech signals representing phoneme uttered deferent persons tended clustered different latent letters. develop machine learning method enables robot obtain language acoustic models independent speakers automatically adapting different speakers future challenges. paper proposed npb-daa direct simultaneous acquisition language acoustic models continuous speech signals unsupervised manner. purpose proposed integrative generative model called hdp-hlm extending hdp-hsmm. based generative model derived inference procedure extending blocked gibbs sampler originally proposed hdp-hsmm. method expected enable developmental robot simultaneously obtain language acoustic models directly continuous speech signals. evaluate performance proposed method experiments performed. ﬁrst experiment proposed method applied synthetic data shown method successfully infer latent words embedded time series data unsupervised manner. second experiment applied proposed method actual human japanese vowel sequences. result showed proposed method outperformed conventional two-stage sequential method conventional baseline method. important challenges future work achieve complete human language acquisition speech signals. achieve complete language acquisition speech signals includes consonants well vowels study. language acquisition natural speech signals like child-directed speech human parents also part future work. achieve aims still main problems feature extraction computational cost. address problems sophisticated feature extraction methods needed. deep learning gained attention recently impressive feature extraction performance. integrating deep learning method npbdaa improve performance. computational cost another problem. even though size dataset used experiment small took approximately minutes iterations using intel xeon cores cpu. particular computational cost blocked gibbs sampler lmax maximum number latent letters word dmax maximum duration word nmaxis maximum number words. aslin woodward lamendola bever models word segmentation ﬂuent maternal speech infants signal syntax bootstrapping speech grammar early acquisition morgan demuth eds. psychology press saffran newport aslin word segmentation role distributional cues journal memory language vol. saffran aslin newport statistical learning -month-old infants. science vol. thiessen saffran when cues collide stress statistical cues word boundaries -month-old infants. developmental psychology vol. venkataraman statistical model word discovery transcribed speech computational linguistics vol. goldwater grifﬁths johnson grifﬁths contextual dependencies unsupervised word segmentation proceedings international conference computational linguistics annual meeting association computational linguistics mochihashi yamada ueda bayesian unsupervised word segmentation nested pitman-yor language modeling proceedings joint conference annual meeting international joint conference natural language processing afnlp johnson goldwater improving nonparameteric bayesian inference experiments unsupervised word segmentation adaptor grammars proceedings human language technologies annual conference north american chapter association computational linguistics magistry unsupervized word segmentation case mandarin chinese proceedings annual meeting association computational linguistics short papers vol. sakti finch isotani kawai nakamura unsupervised determination efﬁcient korean lvcsr units using bayesian dirichlet process model ieee international conference acoustics speech signal processing iwahashi sugiura taguchi nagai taniguchi robots learn communicate developmental approach personally physically situated human-robot conversations dialog robots papers aaai fall symposium araki nakamura nagai nagasaka taniguchi iwahashi online learning concepts words using multimodal hierarchical pitman-yor language model ieee/rsj international conference intelligent robots systems oct. fig. example inference results mfcc feature vectors plotted panel. middle bottom panels show inference results latent letters latent words respectively. different colors denotes different states. currently accuracy language acquisition still limited shown table iii. paper focused language acquisition method based distributional cues proposed mathematical model language acquisition. obviously distributional cues enough accurate language acquisition. suggested several computational robotic studies making co-occurrence cues improves accuracy language acquisition proposed hdp-hlm fully probabilistic generative model. therefore introducing factors consideration relatively easier heuristic models. also advantage approach. combining prosodic nakamura nagai funakoshi nagasaka taniguchi iwahashi mutual learning object concept language model based mlda npylm ieee/rsj international conference intelligent robots systems taniguchi taniguchi inamura lexical acquisition related places mobile robot based ambiguous syllable recognition ieee/rsj international conference intelligent robots systems submitted. heymann walter haeb-umbach iterative bayesian word segmentation unsupervised vocabulary discovery phoneme lattices ieee international conference acoustics speech signal processing elsner goldwater feldman wood joint learning model word segmentation lexical acquisition phonetic variability proceedings conference empirical methods natural language processing seattle washington brandl wrede joublin goerick self-referential childlike model acquire phones syllables words acoustic speech ieee international conference development learning aug. walter korthals haeb-umbach hierarchical system word discovery exploiting dtw-based initialization ieee workshop automatic speech recognition understanding taniguchi nagasaka double articulation analyzer unsegmented human motion using pitman-yor language model inﬁnite hidden markov model ieee/sice international symposium system integration takenaka bando nagasaka taniguchi hitomi contextual scene segmentation driving behavior based double articulation analyzer. ieee/rsj international conference intelligent robots systems taniguchi nagasaka hitomi chandrasiri bando semiotic prediction driving behavior using unsupervised double articulation analyzer ieee intelligent vehicles symposium taniguchia nagasaka hitomi takenaka bando unsupervised hierarchical modeling driving behavior prediction contextual changing points ieee transactions intelligent transportation systems vol. press. nagasaka taniguchi yamashita hitomi bando finding meaningful robust chunks driving behavior based double articulation analyzer ieee/sice intl symposium system integration", "year": 2015}