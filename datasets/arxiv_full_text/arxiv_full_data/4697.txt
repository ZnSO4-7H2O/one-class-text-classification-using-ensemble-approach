{"title": "Stochastic gradient descent algorithms for strongly convex functions at  O(1/T) convergence rates", "tag": ["cs.LG", "cs.AI"], "abstract": "With a weighting scheme proportional to t, a traditional stochastic gradient descent (SGD) algorithm achieves a high probability convergence rate of O({\\kappa}/T) for strongly convex functions, instead of O({\\kappa} ln(T)/T). We also prove that an accelerated SGD algorithm also achieves a rate of O({\\kappa}/T).", "text": "weighting scheme proportional traditional stochastic gradient descent algorithm achieves high probability convergence rate strongly convex functions instead also prove accelerated algorithm also achieves rate smooth strongly-convex function. requirement smoothness simpliﬁes analysis. objective function nonsmooth satisﬁes lipschitz continuity stochastic gradient descent algorithms replace gradients subgradients analysis introduce additional term order variance term. nonsmooth cases studied assume domain bounded i.e. supxy∈x stochastic gradient function random variable gradient assume g−g∗ lx−y assume stochastic gradients bounded i.e. exists supξ interested conditional number deﬁned l/µ. conditional number could number samples reference case regularized linear classiﬁers reference case bridges convergence rate strongly convex functions without strongly convex condition. note assume big-o notation term hide factors besides constants. coeﬃcients informal argument weighting scheme equalizes variance iteration since ctct assuming theorem assume underlying function strongly convex i.e. l/µ. remark studies high probability convergence rate stochastic algorithm strongly convex functions convergence rate usefully here prove convergence rate scheme takes advantage sequence variance decay rate informally investigate sequence homogeneous variance constant weighting scheme i.e. averaged variance exponential weighting scheme i.e. αt−t averaged variance translated number eﬀective tail samples constant translated eﬀective tail samples. trade-oﬀ sample eﬃciency recency. make trade-oﬀs generalized scheme averaged variance approximately", "year": 2013}