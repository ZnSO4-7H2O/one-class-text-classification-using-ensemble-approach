{"title": "Understanding image representations by measuring their equivariance and  equivalence", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Despite the importance of image representations such as histograms of oriented gradients and deep Convolutional Neural Networks (CNN), our theoretical understanding of them remains limited. Aiming at filling this gap, we investigate three key mathematical properties of representations: equivariance, invariance, and equivalence. Equivariance studies how transformations of the input image are encoded by the representation, invariance being a special case where a transformation has no effect. Equivalence studies whether two representations, for example two different parametrisations of a CNN, capture the same visual information or not. A number of methods to establish these properties empirically are proposed, including introducing transformation and stitching layers in CNNs. These methods are then applied to popular representations to reveal insightful aspects of their structure, including clarifying at which layers in a CNN certain geometric invariances are achieved. While the focus of the paper is theoretical, direct applications to structured-output regression are demonstrated too.", "text": "figure equivariant transformation ﬁlters. conv conv ﬁlters convolutional neural network visualised method rows geometrically warped ﬁlters reconstructed equivariant transformation network output learned using method sect. horizontal vertical rotation function. focus particular three properties ﬁrst equivariance looks representation changes upon transformations input image. demonstrate representations including layers deep neural networks change easily predictable manner input show equivariant transformations learned empirically data that importantly amount simple linear transformations representation output case convolutional networks obtain introducing learning transformation layer. analysing learned equivariant transformations also able characterise invariances representation second property. allows quantify invariance show builds depth deep models. third property equivalence looks whether information captured heterogeneous representations fact same. models particular contain millions redundant parameters that non-convex optimisation learning differ even retrained data. question whether resulting differences genuine apparent. answer question learn stitching layers allow swapping parts different networks. equivalence obtained resultdespite importance image representations histograms oriented gradients deep convolutional neural networks theoretical understanding remains limited. aiming ﬁlling investigate three mathematical properties representations equivariance invariance equivalence. equivariance studies transformations input image encoded representation invariance special case transformation effect. equivalence studies whether representations example different parametrisations capture visual information not. number methods establish properties empirically proposed including introducing transformation stitching layers cnns. methods applied popular representations reveal insightful aspects structure including clarifying layers certain geometric invariances achieved. focus paper theoretical direct applications structured-output regression demonstrated too. image representations focus research computer vision least decades. notable examples include textons histogram oriented gradients visual words sparse local coding super vector coding vlad fisher vectors latest generation deep convolutional networks however despite popularity theoretical understanding representations remains limited. generally believed good representation combine invariance discriminability characterisation rather vague; example often unclear invariances contained representation obtained. work propose approach study image representations. look representation abstract function mapping image vector empirically establish mathematical properties rest paper organised follows. sect. discussed methods learn empirically representation equivariance invariance equivalence. sect. present experiments shallow deep representation equivariance respectively sect. representation equivalence. sect. demonstrates practical application equivariant representations structured-output regression. finally sect. summarises ﬁndings. related work. problem designing invariant equivariant features widely explored computer vision. example popular strategy extract invariant local descriptors equivariant detectors various authors also looked incorporating equivariance explicitly representations deep cnns including krizhevsky related state-of-the-art architecutres deemed build increasing amount invariance layer layer. even explicit scattering transform sifre mallat examples invariance design achieved given architecture. contrast propose another mechanism learn invariances rather method systematically tease invariance equivariance properties given representation have. best knowledge limited work conducting type analysis. perhaps contributions come closer study invariances neural networks speciﬁc image transformations however believe ﬁrst functionally characterise quantify properties systematic manner well ﬁrst investigate equivalence different representations. image representations sift cnns thought functions mapping image vector section describes three notable properties representations equivariance invariance equivalence gives algorithms establish empirically. equivariance. representation equivariant transformation input image transformation transferred representation output. formally equivariance obtained exists that existence also structure mapping interest. particular simple example linear function. important representation often used simple predictors linear classiﬁers case cnns processed linear ﬁlters. furthermore requiring mapping work input image intrinsic geometric properties representations captured. nature transformation principle arbitrary; practice paper focus geometric transformations afﬁne warps ﬂips image. invariance. invariance special case equivariance obtained acts simplest possible transformation i.e. identity map. invariance often regarded property representations since goals computer vision establish invariant properties images. example category objects contained image invariant viewpoint changes. studying invariance systematically possible clarify representation achieves equivalence. equi/invariance look representation affected transformations image equivalence studies relationship different representations. heterogenous representations equivalent exist eφ→φ invertible eφ→φ satisﬁes condition; hence mapping before interest existence also structure mapping eφ→φ. example equivariant transformations. denote feature extractor. case interpreted vector ﬁeld d-dimensional feature vectors cells. denotes image ﬂipping around vertical axis related well deﬁned permutation feature components. permutation swaps cells horizontal direction within cell swaps components corresponding symmetric orientations gradient. hence mapping permutation exactly mgφ. true horizontal ﬂips rotations approximately rotations. implementations fact explicitly provide permutations. example translation equivariance convolutional representations. densely-computed sift convolutional networks examples convolutional representations sense obtained local translation invariant operators. barring boundary denotes neighbour size indexes identiﬁed triplets neighbourhood deﬁned input feature sites closer back-projection output feature practice combined order limit number regression coefﬁcients activated neighbourhood. loss. empirically shown sect. choice loss important. similar histogram-like features hellinger’s distances work well. however sophisticated features deep layers cnns found target-oriented losses perform substantially better certain cases. understand concept target-oriented loss consider trained end-to-end categorisation problem ilsvrc image classiﬁcation task common approach ﬁrst several layers general-purpose feature extractor. suggests alternative objective preserves quality equivariant features original problem formally denote coordinates pixel input image afﬁne function mapping feature index centre corresponding receptive ﬁeld input image. denote feature sites closer deﬁne neighbourhood back-transformed site nk). studying equivariance equivalence transformation eφ→φ usually available closed form must estimated data. section discusses number algorithms discussion focuses equivariant transformations dealing equivalence transformations eφ→φ similar. given representation transformation goal mapping satisfying simplest case rd×d afﬁne transformation choice restrictive initially seem examples permutation hence implemented corresponding permutation matrix estimating naturally formulated empirical risk minimisation problem. given data sampled natural images learning amounts optimising regularised reconstruction error regulariser regression loss whose choices discussed below. objective adapted equivalence problem replacing regularisation. choice regulariser particularly important rd×d parameters. since quite large regularisation essential. standard regulariser found inadequate; instead sparsityinducting priors work much better problem encourage similar permutation matrix. second sparsity-inducing regulariser similar exploits convolutional structure many representations. convolutional features obtained translation invariant local operators representation interpreted feature ﬁeld spatial indexes channel index locality representation component predictable corresponding neighfigure equivariant classiﬁcation using features. classiﬁcation performance hog-based classiﬁer trained discriminate heads test images gradually rotated scaled effect compensated equivariant maps learned using table regression cost. cost learning equivariant regressors fig. size arrays becomes larger optimisation cost increases signiﬁcantly unless structured sparsity considered setting small number. experiments begin sect. studying problem learning equivariant mappings shallow representations. sect. move deep convolutional representations examining equivariance equivalence respectively. sect. equivariant mappings applied structure-output regression. section applies methods sect. learn equivariant maps shallow representations features particular. ﬁrst method evaluated sparse regression followed structured sparsity. finally learned equivariant maps validated example recognition tasks. sparse regression. ﬁrst experiment explores variants sparse regression formulation goal learn mapping predicts effect selected image transformations features image. transformation mapping learned training images minimising regularised empirical risk performance measured average hellinger’s distance mgφhell. case learned compensate image transformation therefore formulation restricted cnns applies representation given target classiﬁcation regression task corresponding pre-trained predictor equivariance cnns transformation layers method sect. substantially reﬁned case convolutional representations certain transformation classes. structured sparsity regulariser encourages match convolutional structure representation. afﬁne transformation said sampling artefacts equivariant transformation local translation invariant i.e. convolutional. reason afﬁne acts uniformly image domain true advantages reduces dramatically number parameters learn implemented efﬁciently additional layer cnn. transformation layer consists permutation layer maps input feature sites output feature sites followed bank linear ﬁlters dimension m×m×d. corresponds size neighbourhood sect. intuitively main purpose ﬁlters permute interpolate feature channels. note general fall integer coordinates. case permutation layer assigns closest lattice site rounding also distributed nearest sites using bilinear interpolation. equivalence cnns stitching layers previous section looked equivariance studied efﬁciently cnns; section equivalence. following task-oriented loss formulation sect. consider representations predictor learned solve reference task using representation example could obtained decomposing cnns trained imagenet ilsvcr data seen stitching transforeφ→φ perform well mation allowing original classiﬁcation task. hence trans formation learned minimizing loss objective similar eφ→φ interpreted stitching layer. furmap eφ→φ thermore given convolutional structure representhis means better accuracy could obtained using image warping techniques. example sub-pixel accuracy obtained upsampling permutation layer allowing transformation ﬁlter translation variant figure regression methods. ﬁgure reports feature reconstruction error achieved learned equivariant mapping setting different image rotations scalings different learning strategies constraint imposed right panel experiment repeated rotation time imposing structured sparsity different values neighbourhood size expected prediction error zero rotation transformation exact note fail recover might expect errors smaller transformations close identity although case error remains small throughout range. structured sparse regression. conclusion previous experiments sparsity essential achieve good generalisation. however learning directly e.g. forward-selection regularisation quite expensive even solution ultimately sparse. next evaluate using structured sparsity regulariser output feature predicted prespeciﬁed neighbourhood input features dependent image transformation fig. repeats experiment fig. rotation time limited neighbourhoods input cells. able span larger intervals array cells used. since spatial sparsity imposed a-priori perform nearly equivalently best result achieved small neighbourhood cells. also signiﬁcant computational advantage structured sparsity limits effective size regression problems solved. conclude structured sparsity highly preferable generic sparsity. regression quality. results given term reconstruction error features; paragraph relates measure practical performance learned mappings. ﬁrst experiment qualitative uses hoggle technique visualise transformed features. shown fig. visualisations indeed nearly identical validating mapping second experiment evaluates instead performance transformed features quantitatively classiﬁcation problem. classiﬁer trained discriminate faces using data progressively larger rotation scaling applied input image effect compensated computing score performance compensated classiﬁer nearly identical original classiﬁer angles figure qualitative evaluation equivariant hog. visualisation features using hoggle inverse. learned using rotation up/down-scaling respectively. dashed boxes show support reconstructed features. experiment focuses predicting small array cells allows train full regression matrices even naive baseline regression algorithms. furthermore array predicted larger input array avoid boundary issues images rotated rescaled. restrictions relaxed later. fig. compares following methods learn choosing identity transformation learning optimising objective without regularisation frobenius norm regulariser different values sparsity-inducing regulariser different number regression coefﬁcients output dimension. seen fig. overﬁts badly surprising given contains parameters even small arrays. performs signiﬁcantly better easily outperformed conﬁrming sparse nature solution best result obtained figure comparison regression methods cnn. regression error equivariant learned vertical image ﬂips different layers cnn. task-oriented objective evaluated number training samples. task loss feature reconstruction error reported. task loss green dashed line performance original classiﬁer original images dashed line performance classiﬁer transformed images second reconstruction error cell visualised together baseline average distance representation zero vector. pares different methods learn equivariant mappings cnn. ﬁrst method computed different neighbourhood sizes sparsity second task oriented formulation sect. using transformation layer. reconstruction error features classiﬁcation error reported. sect. latter classiﬁcation error compensated network imagenet ilsvcr data ﬁgure reports evolution loss training samples used. purpose experiment vertical image ﬂip. fig. repeats experiments task-oriented objective rotations degrees several observations made. first methods perform substantially better nothing recovering performance original classiﬁer demonstrates linear equivariant mappings learned successfully cnns too. second shallower features conv better requires less training samples smaller reconstruction error comparable classiﬁcation error task-oriented loss. compared sect. however best setting substantially less sparse. however conv onwards task-oriented loss better converging much lower classiﬁcation error still achieves signiﬁcantly smaller reconstruction error showing feature reconstruction always predictive classiﬁcation performance. third classiﬁcation error increases somewhat depth matching intuition deeper layers contain specialised information such perfectly transforming layers figure learning equivariant mappings image rotations. setting similar fig. extended several rotations limted task-oriented regression method. solid dashed lines report respectively errors ilsvrc validation set. scales whereas uncompensated classiﬁer rapidly fails particularly rotation. conclude equivariant transformations encode visual information effectively. equivariance deep representations previous section validated learning equivariant transformations shallow representations hog. section extends results deep representations using alexn reference state-of-theart deep feature extractor using matconvnet framework alexn composition twenty functions grouped convolutional layers three fully-connected layers experiments look convolutional layers conv conv right linear ﬁlters regression methods. ﬁrst experiment comtesting transformations. next investigate geometric transformations represented different layers considering particular horizontal vertical ﬂips rescaling half rotation first transformations horizontal ﬂips scaling learning equivariant mappings better leaving features unchanged reason implicitly learned invariant factors. vertical ﬂips rotations however learned equivariant mapping substantially reduce error. particular ﬁrst layers easily transformable conﬁrming generic nature. quantifying invariance. mapping identiﬁcation invariant features representation. ones best predicted after transformation. practice transformation layer identiﬁes invariant feature channels since transformation ﬁlters applied uniformly spatial locations. practice invariance almost never achieved exactly; instead degree invariance feature channel scored ratio euclidean norm corresponding suppressing diagonal component row. then rows highest invariance score replaced rows identity matrix. finally performance modiﬁed transformation evaluated accepted classiﬁcation performance deteriorate relative corresponding feature channels largest possible considered approximately invariant. table reports result analysis horizontal vertical ﬂips rescaling rotation alexn cnn. several notable observations. first transformations network overall invariant horizontal ﬂips rescaling invariance obtained largely conv conv. second invariance always increasing depth example conv tends invariant conv. possible because even feature channels layer invariant spatial pooling subsequent layer third number invariant features signiﬁcantly smaller unexpected transformations vertical ﬂips rotations validating approach. previous sections studied equivariance representations section looks equivalence. goal clarify whether heterogeneous representations fact capture visual information replacing part representation another using methods sect. sect. table equivariance. performance ilsvrc validation compensated classiﬁer using learned equivariant mappings selected transformations. reference top- top- error unmodiﬁed alexn respectively. table equivalence. performance ilsvrc validation several franken-cnns obtained stitching ﬁrst portion imnet plcs plcs-h certain convolutional layer last portion alexn. alexn swapped layers imnet also trained ilsvrc data plcs trained places data plcs-h trained mixture places ilsvrc images. representations similar identical structure entirely different parametrisations. table shows top- performance hybrid models equivalence eφ→φ eφ→φ learned stitching layer ilsvrc training images. number notable facts. first setting eφ→φ identity top- error matching intuition different parametrisations make feature channels directly compatible. second good level equivalence established conv alexn imnet slightly less good alexn plcs-h; however plcs deeper layers substantially less compatible. speciﬁcally conv conv interchangeable cases whereas conv fully interchangeable particularly plcs. corroborates intuition conv conv generic image codes whereas conv task-speciﬁc. note however that conv bsln time/tf speedup table equivariant regression. table reports prediction errors head rotation/afﬁne pose direct/equivariant structured regressors. error measured expected degrees residual rotation average keypoint distance normalised face frame respectively. baseline method predicts constant transformation. figure equivariant regression examples. rotation afﬁne pose prediction faces parts data. estimated afﬁne pose represented eyes nose location. ﬁrst four columns contain examples successful regressions last failure case. regression uses conv features computed within green dashed box. paper introduced idea studying representations learning equivariant equivalence properties. shown shallow representations ﬁrst several layers deep state-of-the-art cnns transform easily predictable manner image warps interchangeable hence equivalent different architectures. deeper layers share properties lesser degree task-speciﬁc. addition analytical tools methods practical applications accelerating structured-output regressors classiﬁer simple elegant manner. complement theoretical investigation section shows direct practical application learned equivariant mappings sect. structuredoutput regression structured regression input image mapped label function argmaxyzφ optional latent variable joint feature map. and/or include geometric parameters joint feature partially fully rewritten myzφ reducing inference maximisation computational advantages representation needs computed vectors idea demonstrated task pose estimation geometric transformation class possible poses object. example consider estimating pose faces pascal data using either rotations afﬁne transformations rotations sampled uniformly every degrees groundtruth rotation face deﬁned line connecting nose midpoints eyes. keypoints obtained center gravity corresponding regions part annotations afﬁne transformations obtained instead clustering vecn containing location eyes nose tors example faces data. clusters obtained using gmm-em training data used test data pose classes evaluation. contains afﬁne transformations mapping canonical frame keypoints cluster center. matrices pre-learned using sect. since faces data usually upright second challenging version data augmented random image rotations considered well. direct equivariant scoring functions learned using training samples evaluated test ones. table reports accuracy speed obtained conv conv conv features direct equivariant regression. latter generally good nearly good direct regression times faster validating mappings fig. shows cumulative error curves different regressors. chen mottaghi fidler urtasun yuille. detect detecting representing objects using holistic models body parts. ieee conference computer vision pattern recognition krizhevsky sutskever hinton. imagenet classiﬁcation deep convolutional neural networks. proc. nips leung malik. representing recognizing visual appearance materials using three-dimensional textons. ijcv russakovsky deng krause satheesh huang karpathy khosla bernstein berg fei-fei. imagenet large scale visual recognition challenge schimdt roth. learning rotation-aware features", "year": 2014}