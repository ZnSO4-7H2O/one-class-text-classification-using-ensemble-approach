{"title": "ShapeWorld - A new test methodology for multimodal language  understanding", "tag": ["cs.CL", "cs.AI", "cs.CV"], "abstract": "We introduce a novel framework for evaluating multimodal deep learning models with respect to their language understanding and generalization abilities. In this approach, artificial data is automatically generated according to the experimenter's specifications. The content of the data, both during training and evaluation, can be controlled in detail, which enables tasks to be created that require true generalization abilities, in particular the combination of previously introduced concepts in novel ways. We demonstrate the potential of our methodology by evaluating various visual question answering models on four different tasks, and show how our framework gives us detailed insights into their capabilities and limitations. By open-sourcing our framework, we hope to stimulate progress in the field of multimodal language understanding.", "text": "introduce novel framework evaluating multimodal deep learning models respect language understanding generalization abilities. approach artiﬁcial data automatically generated according experimenter’s speciﬁcations. content data training evaluation controlled detail enables tasks created require true generalization abilities particular combination previously introduced concepts novel ways. demonstrate potential methodology evaluating various visual question answering models four different tasks show framework gives detailed insights capabilities limitations. opensourcing framework hope stimulate progress ﬁeld multimodal language understanding. deep learning methods major impact research natural language processing raised performance substantially many standard evaluations. moreover multimodal tasks like image captioning visual question answering tackled great success. systems seem solve problems entirely sub-symbolic level based image input whereas previous approaches required hand-crafted combination various higher-level components. nguyen zhang shown surprising behavior different would expected surpassing human-level performance deep networks language tasks exhibit similarly behavior moreover recently found datasets instance contain various unexpected biases peculiarities systems exploit answer complex questions sometimes even without looking image results cast doubt whether deep learning systems actually acquire appropriate generalizations. however given recursive nature language potentially enormous problem space similar tasks acquiring ability reliable generalization eventually essential. theoretical issue ability network architectures principle learn certain classes structure. instance shown lstms possess ability handle long-range dependencies however formal experiments done along lines limited particularly multimodal domain vision language. recent work indicates information encoded image embeddings might rich enough good captioning results open question whether current architectures able principle combine visual information effectively handle full range linguistic constructions. paper introduces test methodology multimodal deep learning models. shapeworld framework specifying vqa-style datasets. instance consists image caption evaluated model decide agreement hence form yes/no figure example instances task require system judge whether caption consistent image. moreover sequences outline kind generalization capability evaluating previously seen concepts recombined novel ways. shapeworld dataset differs standard evaluation datasets three main ways. firstly shapeworld dataset deﬁnes process generating artiﬁcial data consisting abstract colored shapes randomly sampled training/testing according constraints speciﬁed experimenter. secondly evaluation focus linguistic understanding capabilities type investigated formal semantics. visual complexity open-class vocabulary size reduced minimum potentially allowing indeﬁnitely complex syntactic constructions. finally distribution evaluation data deliberately kept different training distribution. controlled data generation enables introduce previously unseen instance conﬁgurations evaluation require system recombine learned concepts able understand novel instances hence form zero-shot learning. think shapeworld tasks unit-testing multimodal systems speciﬁc linguistic generalization capabilities similar babi tasks text-only understanding. also present results various models four shapeworld datasets targeting different multimodal language understanding abilities. artiﬁcial data allows detailed analysis models’ strengths weaknesses reveals unexpected shortcomings. such offers significantly different interesting resource complement standard evaluation practice. exposing problematic instance patterns systems fail providing conﬁgurable extensible testbed systematic detailed comparable evaluation hope stimulate progress ﬁeld. increasing popularity deep learning approaches artiﬁcial data various kinds seen valuable tool experimentation. recently simulation paradigm argued promising driver artiﬁcial intelligence research various platforms following paradigm released mostly aimed reinforcement learning arcade learning environment atari games openai deepmind project malmo name popular. important advantage simulated data inﬁnite availability particularly light need many deep learning models huge amounts data. automatically generating data greatly reduces cost time human effort. moreover allows researchers focus speciﬁc problem situations isolated noisy complex real-world environment. focusing language tasks simulation paradigm faces problem interesting language generation difﬁcult task right difﬁculty increases complexity underlying world. babi tasks generated internally simulating short scene extracting simple sentences similar approach taken narasimhan simulation complex comprising text-based role-playing game. mazebase game environment uses language mean represent game world. however descriptions abstract formulaic format focus simulation much planning language component. long-term research proposal mikolov also simulates world agent learns solve tasks communication teacher module. least start module supposed scripted automatically generate appropriate responses given internal knowledge world state. automatically generated data common tasks speciﬁcally focusing ability efﬁciently process data certain formal structure. here data deliberately stripped realworld connection create abstract capability check. recent work context deep learning investigated sequence patterns combinatorial problems executing programming language code amongst others. kind task particularly common neural network models twenty years ago). reason interest abstract capability checks learning process decisions deep networks difﬁcult interpret shallower machine learning methods. bowman sorodoc similar work focusing speciﬁc linguistic aspects. generate artiﬁcial data automatically based abstract models tasks targeting logical semantics quantiﬁers respectively. multimodal tasks image captioning closely related evaluation goal usually consist repurposed real-world photos human-written descriptions. however experiments parts data artiﬁcial and/or generated automatically instance automatic question generation annotation systematic modiﬁcation captions abstract clipart scenes used image captioning balance existing datasets similar shapeworld framework clevr dataset contains images rendered abstract -dimensional scenes complex questions generated variety templates. work propose artiﬁcial dataset complements evaluation real-world datasets. ically designed address single structural problem testbed able cover whole range linguistic phenomena. fact generation system closely resembles classical work formal semantics statement corresponds logical expression evaluated abstract world model utilize semantic representations based minimal recursion semantics broad-coverage grammarbased realization driven english resource grammar make internal world model compatible language. however shapeworld uses abstract representations internally external representation presented system evaluation involve abstract formalization visual textual input. nevertheless presents intended problems clearly without uncontrolled noise biases hidden correlations obfuscate results using real-world images text shapeworld framework based microworlds small self-contained artiﬁcial scenarios guide data creation process. shapeworld microworlds simply consist colored shapes. closed-world domain allows exhaustive coverage space possible microworlds associated captions. vocabulary used emphasis closed-class words open-class vocabulary currently less words. following explain details data generation process inside shapeworld framework. schematic illustration process shown ﬁgure shapeworld code written python available github generated data returned numpy arrays possible integrate python-based deep learning projects using common frameworks like tensorflow theano etc. experiments tensorflow provide models paper part package. internal dmrs-based python package pydmrs well reduced version english resource grammar packard’s answer constraint engine included. compared classic image captioning task emphasizes understanding rather synthesis part language use. therefore avoid problem evaluating appropriateness caption. setup allows control content modalities consequently force system cope difﬁcult types captions obtaining clear indicator successful understanding. although similar setup neither requires evaluated model generate answers rephrase problem classiﬁcation task sort instance common answers common practice recently closely corresponds work jabri present binary classiﬁcation image-question-answer triples. motivation task human performance could measured using setup. would expect close-to-perfect human performance tasks described here assuming time tightly constrained. interesting comparisons potentially possible human performance depends presentation e.g. quantiﬁers however discuss current paper. microworld simply list entities given records containing primary attributes position shape color considered high-level semantic aspects reﬂected captions. addition entity secondary attributes methods control instance details visual appearance visual noise infusion collision-free placement entities. importantly ways infusing noise controlled well useful particularly since noise often seen important successful training deep models. generator module automatically generates world model randomly sampling attributes available values. values aspects generation process speciﬁed adjusted appropriately dataset. internal abstract representation used basis extract concrete microworld instance consisting image caption. image straightforward visualization world model. table gives overview primary secondary attributes together value ranges sampling details used experiments paper figure example dmrs graph corresponding complex caption compositional components colored. logical formula gives formal semantic interpretation world model. caption generation currently provide implementation shapeworld captioner interface using grammar-based approach. speciﬁcally dependency minimal recursion semantics abstract semantic graph representation designed highprecision grammars distributed delph-in consortium. semantic representation like dmrs particularly suited shapeworld framework since essentially mirrors internal world model hence acts like languagespeciﬁc annotation. here noun nodes correspond entities adjective nodes attributes verb phrase nodes/sub-graphs specify relations entities. semantics words like square interpreted iteratively ﬁltering subset agreeing entities transitive relations like left similarly pairs entity sets quantiﬁers compare cardinality entity sets. example dmrs semantic graph compositional components colored compositionality semantic representation useful property important reason dmrs. given compositionality enough specify semantics words precisely linguistic atoms shapeworld context potentially sub-graphs multiple nodes inner link structure able obtain corresponding semantics composed sub-graphs generate wide range different captions. figure shows example complex compositional caption contains dmrs graph sub-graph. also illustrates various details automatically inferred english resource grammar including number-agreement subject verb quantiﬁer noun realization adjective relative clause. greatly facilitates generation combinatorially large amount captions makes dmrs graph patterns reusable. finally ﬁgure gives formal semantic interpretation caption meaning logical formula world model. indicates agreement caption microworld computed shapeworld framework. similar generator module captioner module randomly samples datasetspeciﬁc dmrs graph patterns applied world model construct agreeing caption object dmrs graph turned representation corresponding english sentence generated bi-directional grammar like english resource grammar parser-generator like packard’s answer constraint engine. captioner module’s ability check whether another world model would agree semantics caption important generation negative instances i.e. caption/microworld pairs agree. instances obtained either sampling second false world model producing false caption object modiﬁcation agreeing caption. either case system ensures false microworld caption object accidentally agree. since shapeworld datasets actually data generation processes training evaluation work differently classic datasets. usually ﬁxed instances models trained tested ﬁxed higher-level generator conﬁguration constraints. particular constraints evaluation differ training constraints hence requiring true generalization abilities. instance certain shapecolor-combination speciﬁc number objects spatial location caption type heldnever generated training concepts need recombined test time. thus possible system achieve optimal performance training completely fail evaluation. another important property shapeworld datasets particularly future extensions compositionality. instead deﬁne dataset scratch every time specify atomic datasets combine mixer dataset tests various different aspects multimodal language understanding simultaneously. reusability fact applies even component hierarchy. instance generic world generator module four datasets. also useful caption generation where instance logical combinator dataset reuse different world captioner modules generate simple statements merged logical connectives. datasets paper look four datasets designed investigate aspect capability understand language multimodal setup. figure gives information datasets. note since ﬁrst sample microworld model subsequently caption cannot always easily control generation process sample possible caption perfectly uniformly. particular case focusing speciﬁc captions might apply microworld hence require resampling. network architecture evaluate several multimodal deep neural network architectures recently proposed figure shows general architecture underlying models. implementations tensorflow adapted task included part github repository. model trained end-to-end task including module word embeddings opposed using pre-trained general-purpose versions. train iterations batch size using adam optimization learning rate lstm-only cnn-only simple unimodal cnn+{bowlstmgru}mult obbaselines. tain caption embedding lstm respectively fuse visual textual information pointwise multiplication. cnn+lstmadd cnn+lstmconcat i.e. pointwise addition concatenation alternative basic ways combining image caption embeddings. instead concatenating image embedding output lstm cnnlstm concatenated word embedding processed lstm. finally hierarchical co-attention combines visual information word- phrasesentence-level language input processed cnn. cnn+cnnhca-{paralt} implements approach proposed co-attention mechanisms parallel alternating. near future plan also adapt technique multimodal compact bilinear pooling neural module networks potentially also relation networks task upload implementations github repository. results figure reports train/validation/test performance four models. addition overaccuracy contains detailed analysis models’ ability handle certain instance types. accuracies dataset partitions obtained restricting dataset generator sample evaluation instance type. space limitations report detailed numbers models. essentially show behavior lstm-only model apart cnn+grumult similar cnn+lstmmult. models quantification dataset indicate quantiﬁers fully learned. approximated rough number/existence/majority estimate something plan investigate further. unsurprisingly lstm-only cnn-only also cnn+bowmult able learn actual multimodal understanding contrast good performance real-world data data failure learning clearly shows tendency models fall back always-correct always-incorrect predictions. dataset conﬁguration oneshape hypernyms hypernyms changed shape changed color changed multishape correct instances random attr. random existing attr. spatial hypernyms hypernyms swapped direction object random attr. subject random attr. quantification correct instances incorrect instances instances instances instances instances instances instances figure accuracy four selected models datasets detailed evaluation ability correctly understand speciﬁc instance types. cell color indicates whether corresponding instances relatively harder easier comparison overall accuracy dataset whether tendency inconsistent across train/validation/test accuracies. many interesting aspects could discussed including learning curves transfer learning however main point detailed investigation error analysis like ﬁgure would difﬁcult impossible conduct realworld data. consequently shows potential artiﬁcial data basis complementary evaluation methodology multimodal language understanding systems. basic shapeworld framework elaborated many ways. plan datasets addressing aspects language well integrating options enhance language generation module providing varied natural image descriptions. instance expect integrate subsequent step applying paraphrase rules caption generation copestake describe implemented level dmrs graphs. presented evaluation methodology framework shapeworld multimodal deep learning models focus formalsemantic style generalization capabilities. framework artiﬁcial data automatically generated according predeﬁned speciﬁcations. controlled data generation makes possible introduce previously unseen instance conﬁgurations evaluation consequently require system recombine learned concepts novel ways i.e. true generalization. evaluated various models four image caption agreement datasets system decide whether statement applies image. showed shapeworld framework used investigate detail models learn respect multimodal language understanding. exposing speciﬁc multimodal scenarios current multimodal systems fail providing conﬁgurable extensible testbed systematic detailed comparable evaluation hope stimulate progress ﬁeld multimodal language understanding. references aishwarya agrawal dhruv batra devi parikh. analyzing behavior visual question answering models. proceedings conference empirical methods natural language processing. austin texas emnlp pages jacob andreas marcus rohrbach trevor darrell klein. learning compose neural networks question answering. proceedings conference north american chapter association computational linguistics. naacl jacob andreas marcus rohrbach trevor darrell klein. neural module networks. proceedings ieee conference computer vision pattern recognition. cvpr stanislaw antol aishwarya agrawal jiasen margaret mitchell dhruv batra lawrence zitnick devi parikh. visual question answering. proceedings ieee international conference computer vision. iccv akira fukui dong park daylen yang anna rohrbach trevor darrell marcus rohrbach. multimodal compact bilinear pooling visual question answering visual grounding. proceedings conference empirical methods natural language processing. austin texas emnlp pages philip arthur graham neubig satoshi nakamura. incorporating discrete translation lexicons conference neural machine translation. empirical methods natural language processing austin texas usa. yash goyal tejas khot douglas summers-stay dhruv batra devi parikh. making matter elevating role image understanding visual question answering. corr abs/.. beattie leibo teplyashin ward wainwright k¨uttler lefrancq green vald´es sadik schrittwieser anderson york cant cain bolton gaffney king hassabis legg petersen. deepmind lab. arxiv e-prints marc bellemare yavar naddaf joel veness michael bowling. arcade learning environment evaluation platform general agents. journal artiﬁcial intelligence research samuel bowman christopher potts christopher manning. recursive neural networks learn logical semantics. proceedings workshop continuous vector space models compositionality. association computational linguistics beijing. copestake emerson michael goodman matic horvat alexander kuhnle muszy´nska. resources building applications dependency minimal recursion seproceedings international mantics. kaiming xiangyu zhang shaoqing jian sun. delving deep rectiﬁers surpassing human-level performance imagenet classiﬁcation. proceedings ieee international conference computer vision santiago chile pages micah hodosh julia hockenmaier. focused evaluation image description binary forcedchoice tasks. proceedings workshop vision language. berlin germany. justin johnson bharath hariharan laurens maaten fei-fei lawrence zitnick ross girshick. clevr diagnostic dataset compositional language elementary visual reasoning. computer vision pattern recognition matthew johnson katja hofmann hutton david bignell. malmo platform artiﬁcial intelligence experimentation. proceedings international joint conference artiﬁcial intelligence aaai press palo alto california pages ionut sorodoc angeliki lazaridou gemma boleda aur´elie herbelot sandro pezzelle raffaella bernardi. look green circles learning quantify images. proceedings workshop vision language. berlin germany. christian szegedy wojciech zaremba ilya sutskever joan bruna dumitru erhan goodfellow fergus. intriguing properties neural networks. corr abs/.. oriol vinyals meire fortunato navdeep jaitly. pointer networks. proceedings international conference neural information processing systems. press montreal canada nips’ pages chiyuan zhang samy bengio moritz hardt benjamin recht oriol vinyals. understanding deep learning requires rethinking generalization. international conference learning representations peng zhang yash goyal douglas summers-stay dhruv batra devi parikh. yang balancing answering binary visual questions. conference computer vision pattern recognition lawrence zitnick devi parikh. bringing semantics focus using visual abstraction. proceedings ieee conference computer vision pattern recognition. cvpr pages lawrence zitnick ramakrishna vedantam devi parikh. adopting abstract images ieee transacsemantic scene understanding. tions pattern analysis machine intelligence andrej karpathy fei-fei deep visualsemantic alignments generating image descripproceedings ieee conference tions. computer vision pattern recognition. cvpr pages douwe kiela luana bulat anita vero stephen clark. virtual embodiment scalable long-term strategy artiﬁcial intelligence research. corr abs/.. jiasen jianwei yang dhruv batra devi parikh. hierarchical question-image coattention visual question answering. advances neural information processing systems annual conference neural information processing systems barcelona spain nips pages karthik narasimhan tejas kulkarni regina barzilay. language understanding textbased games using deep reinforcement learning. proceedings conference empirical methods natural language processing. association computational linguistics lisbon portugal pages nguyen jason yosinski jeff clune. deep neural networks easily fooled high conﬁdence predictions unrecognizable images. proceedings ieee conference computer vision pattern recognition. cvpr david raposo adam santoro david barrett razvan pascanu timothy lillicrap peter battaglia. discovering objects relations entangled scene representations. international conference learning representations", "year": 2017}