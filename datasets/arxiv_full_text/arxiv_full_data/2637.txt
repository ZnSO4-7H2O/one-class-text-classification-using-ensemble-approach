{"title": "Contextual Multi-armed Bandits under Feature Uncertainty", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "We study contextual multi-armed bandit problems under linear realizability on rewards and uncertainty (or noise) on features. For the case of identical noise on features across actions, we propose an algorithm, coined {\\em NLinRel}, having $O\\left(T^{\\frac{7}{8}} \\left(\\log{(dT)}+K\\sqrt{d}\\right)\\right)$ regret bound for $T$ rounds, $K$ actions, and $d$-dimensional feature vectors. Next, for the case of non-identical noise, we observe that popular linear hypotheses including {\\em NLinRel} are impossible to achieve such sub-linear regret. Instead, under assumption of Gaussian feature vectors, we prove that a greedy algorithm has $O\\left(T^{\\frac23}\\sqrt{\\log d}\\right)$ regret bound with respect to the optimal linear hypothesis. Utilizing our theoretical understanding on the Gaussian case, we also design a practical variant of {\\em NLinRel}, coined {\\em Universal-NLinRel}, for arbitrary feature distributions. It first runs {\\em NLinRel} for finding the `true' coefficient vector using feature uncertainties and then adjust it to minimize its regret using the statistical feature information. We justify the performance of {\\em Universal-NLinRel} on both synthetic and real-world datasets.", "text": "study contextual multi-armed bandit problems linear realizability rewards uncertainty features. case identical noise features across actions propose algorithm coined nlinrel regret bound rounds actions d-dimensional feature vectors. next case non-identical noise observe popular linear hypotheses including nlinrel impossible achieve sub-linear regret. instead asregret bound sumption gaussian feature vectors prove greedy algorithm respect optimal linear hypothesis. utilizing theoretical understanding gaussian case also design practical variant nlinrel coined universal-nlinrel arbitrary feature distributions. ﬁrst runs nlinrel ﬁnding ‘true’ coefﬁcient vector using feature uncertainties adjust minimize regret using statistical feature information. justify performance universal-nlinrel synthetic real-world datasets. multi-armed bandit problem received much attention wide range applications e.g. clinical trials thompson economics schlag routing awerbuch kleinberg ranking radlinski problems sequential decision problems round learner selects action candidates receives reward selected action. learner makes decisions based observations sequence past rewards selected actions would like maximize cumulative reward equivalently minimize regret deﬁned difference cumulative reward achieved always playing best arm/action. learner often access contextual information addition rewards selected actions referred contextual langford zhang examples include personalized recommendation bouneffouf server defense jung information retrieval hofmann instance learner feature vectors associated arms every round address problem assume hypothesis consisting functions feature vectors action give best expected reward. linear hypothesis simple widely used hypothesis deﬁned coefﬁcient vector predicts optimal action max≤i≤k ziθ. linear hypothesis assumes expected reward action round deﬁned hidden coefﬁcient vector referred linear payoff also called linear realizability. online linear regression task balancing trade-off exploration exploitation. paper study contextual problems linear payoffs assuming uncertainty noise features. speciﬁcally assume learner cannot observe true feature vector noisy vector random noise independently drawn distribution. incorporate statistical uncertainties linear hypotheses relax strong linear assumption rewards i.e. enhance power linear models. furthermore incorporate recent remarkable progresses bayesian deep learning techniques ghahramani estimate feature uncertainties i.e. knowledge noise distributions. therefore need redesign learning policies considering noisy feature vectors. best knowledge ﬁrst work aims solve contextual problems assuming uncertainties features. contribution. ﬁrst study simplest non-trivial case every action identical noise vector i.e. eliminates issue learner best action extracting hidden coefﬁcient vector since however issue remains e.g. linrel might furthermore design conﬁdence interval noise balancing exploration exploitation trade-off. address them propose noisy version linrel coined nlinrel regret bound rounds. regret analysis tail inequalities random matrices induced noise vectors bound random matrix perturbation. next consider non-identical noise vectors assume feature vector round independently drawn distribution dfeature. underlying reasoning statistical assumption ﬁnding eliminates issue speciﬁcally dfeature gaussian derive closed form formula optimal coefﬁcient vector using bayesian analysis. somewhat interestingly optimal equal true cannot occur noiseless settings. design simple greedy algorithm achieves regret bound respect optimal linear hypothesis. here easily observe linear hypothesis including greedy algorithm nlinrel cannot achieve sub-linear regret respect optimal sequence actions thus analyze ‘relative’ regret. study gaussian features naturally motivates question whether also optimal general feature distributions. derive optimization formulation optimal coefﬁcient vector general possibly non-gaussian setting numerically found longer optimal case. finally design algorithm coined universal-nlinrel arbitrary distributions features searches true using nlinrel adjusts parameter gradient direction optimization objective. experiments universal-nlinrel outperforms linucb representing known linear hypothesis designed noiseless contextual problem noisy synthetic real-world datasets. related works. although name contextual multi-armed bandit ﬁrst appeared langford zhang problem setting studied different names e.g. bandit covariates woodroofe sarkar associative reinforcement learning kaelbling associative bandit auer strehl bandit expert advice auer paper particular focuses linear hypothesis linear payoff model originally introduced long developed auer algorithm design nlinrel actually motivated linrel auer linucb linrel linucb algorithms compute expected rewards conﬁdence intervals controlling exploration exploitation trade-off. thompson sampling also studied linear payoff model agrawal goyal stochastic linear bandit optimization problem studied dani many following works special cases contextual bandit linear payoff model inﬁnitely many arms. however studies assume feature vectors noiseless cannot directly apply algorithms noise setting. discretize linear hypothesis ε-net ε-net possible exp-type algorithms auer beygelzimer noisy contextual problem studied paper. however computation costs update weights elements ε-net every round. also possibly epoch-greedy langford zhang gaussian setting mentioned earlier also requires huge amount computations memory space computing likelihood hypothesis among hypothesis set. uses ε-net epoch-greedy issue exp-type algorithms sequence observations memorized compute maximum likelihood. study noisy version contextual multi-armed bandit problem linear payoffs. time possible actions learner observes feature vector possible action i.e. dimension features number arms assume observed features noisy sense true hidden feature vector action time denoted independent random vector learner selects action observe reward selected action time assume independent sub-gaussian random variables ﬁnite variance distribution determined true feature vector selected learner uses algorithm policy selecting action time given current observed feature vectors action past information time maxt= time learner knows hidden information best choice action maximize cumulative reward would max≤i≤k ziθ. deﬁne regret function algorithm compared oracle algorithm follows objective learner’s algorithm minimize regret. notation. here deﬁne necessary matrix notation used throughout paper. matrix rm×n denote transpose inverse respectively. i-th eigenvalue i-th singular value denoted respectively. denote i-th column mean i-th diagonal value diagonal matrix consisting section assume every action shares noise feature vector i.e. also assume {ε}t≥ i.i.d. random vectors covariance denoted known learner. auer analysis assume feature vectors satisfy rewards bounded ﬁnite constant. furthermore assume distribution ﬁnite support. hence best action terms expected reward ﬁnding even noises feature vectors. namely reduce regret learning hidden coefﬁcient vector accurately. however could increase quickly spend much time learn popular exploitation-exploitation trade-off issue bandit problem. noise feature vectors linrel auer controls exploitation-exploitation tradeoff efﬁciently guarantees sub-linear resect executes following procedures round/time selection rule words uncertainties observed arms increases sub-linearly. nlinrel better estimation playing actions high uncertainties. intuitively amount information revealed playing action note removed thus independent noise. exploration exploitation tradeoff controlled wij. candidate generated exists then selected uniformly random proof strategy theorem nlinrel indicates uncertainty best selected uncertainty roughly proportional amount revealed information playing that ﬁrst bound expected uncertainties follows non-identical feature uncertainty noise feature vectors identical i.e. algorithm based linear hypothesis impossible guarantee sub-linear regret function. regret function grow linearly even though know hidden coefﬁcient vector exactly. suppose drawn normal distribution. then exists constant given feature vectors {zi}≤i≤k probability max≤i≤k max≤i≤k xiθ. coefﬁcient vector corresponding expected regret function learner decides actions follows section designing algorithm sub-linear regret respect optimal sequence {a}t≥ study optimal linear hypotheis minimizes somewhat interestingly found choice always best i.e. could exist order describe intuition optimal choice ﬁrst consider noisy gaussian contextual model section model minimizes represented closed form prove simple algorithm ‘relative’ sub-linear regret bound respect optimal linear hypothesis. optimal closed form gaussian models might longer true non-gaussian ones discussed section section consider following noisy gaussian contextual model. true feature vectors i.i.d. random vectors drawn normal distribution σfeature positive-deﬁnite matrix. noises deﬁned i.i.d. multivariate gaussian random vectors well follows positivedeﬁnite matrix σnoise. since σfeature σnoise positive-deﬁnite matrices inverse matrices σfeature σnoise also optimal linear hypothesis. would like proof theorem provided appendix provide high-level sketch. round learner receives noisy feature vectors knows distributions optimal decision given feature vectors computed greedy algorithm. propose simple greedy algorithm operates observations accurately. simple greedy algorithm consists parts exploration exploitation stated formally follows. observe algorithm utilize information σfeature σnoise nevertheless indeed show ﬁnds optimal sub-linear regret theorem noisy gaussian contextual model simple greedy algorithm probability proof theorem provided appendix provide high-level sketch. exploration part time instance learner selects action uniformly random selection noisy feature vectors become independent. then i.i.d. random vectors following also i.i.d. random vectors following therefore section consider true feature vectors drawn arbitrary possibly non-gaussian distribution case proof theorem longer true easy analyze whether deﬁned optimal sense. formally assume i.i.d. random vectors drawn distribution mean covariance σfeature σfeature positive-deﬁnite matrix. noise model gaussian contextual model previous section. focus verifying numerically whether deﬁned optimal non-gaussian setting. solution optimization might given closed form like unless gaussian/normal. furthermore computing gradient non-trivial task depending knowledge might given practical scenarios. hence estimate following monte carlo method randomly generated samples distribution real feature vectors observed practice. elementary check gradient expressed integral form respect probability density function several different choices feature distribution compute conﬁrm whether optimal not. experiments number dimension feature number samples element feature vector i.i.d. random variable. also choose element uniformly random interval i.e. uniform. distribution noise numerical results reported table implies might optimal unless gaussian. above ucb-like constant like linucb main idea algorithm design runs nlinrel estimating true coefﬁcient vector update current stochastic gradient direction replacing estimation although nlinrel theoretical value universal-nlinrel uses practical variant nlinrel introducing parameter since many initial explorations might hurt regret unless extremely large enough number time instances allowed. following section measure regret performance universal-nlinrel. section report experimental results comparing regret performances univeral-nlinrel following algorithms. first linucb represents known algorithms designed noiseless contextual problem. seocnd oracle-gd identical univeral-nlinrel except using true coefﬁcient vector instead estimated finally oracle-tc oracle-cf linear hypotheses choosing min≤i≤k consider true coefﬁcient vector closed form deﬁned respectively. synthetic dataset. follow synthetic setups described section experimental figure comparisons algorithms synthetic real-world datasets. measured choices feature distributions gaussian uniform uniform respectively. report cumulative regrets algorithms deducted oracle-tc. report cosine distances coefﬁcient vectors maintained algorithms true yahoo mushroom datasets respectively. comparisons among universal-nlinrel linucb oracle-gd oracle-tc oracle-cf reported figure case gaussian distribution reported figure observe linucb univeral-nlinrel close optimal oracle-cf setting. near-optimality linucb explained similarity simple greedy algorithm section case mixture uniform distribution reported figure observe linucb worst regret signiﬁcantly outperformed univeral-nlinrel. figure show nlinrel ﬁnds true coefﬁcient vector well gaussian non-gaussian setups. explains univeral-nlinrel perform well yahoo dataset. yahoo webscope dataset contains history yahoo front page module. featured module highlights article human edited candidate size contains user context context candidate chosen reward consider article arm. pre-processing step removed lines incomplete then clustered lines user. then user observe several candidate arms whose rewards calculated empirical ctrs example user observed times clicked times assumed reward context vector m/n. consider users whose candidates/arms size larger number users pruning processing algorithm iterated without duplication. user article represented six-dimensional real vector. used inner product features context linucb nlinrel universal-nlinrel pre-processed yahoo dataset. compared synthetic setting computing gradients universal-nlinrel becomes expensive larger number candidate arms. hence estimate integral gradients monte carlo samples. addition since knowledge noise feature distributions current context random sample universal-nlinrel noise variance sample variance contexts entire dataset. yahoo data universal-nlinrel linucb nlinrel perform better orders reported figure mushroom dataset. mushroom dataset bache lichman used contextual experiment blundell mushroom categorical features labeled edible poisonous. blundell used dimensional binary vectors features. round sample edible mushroom poisonous ones. thus learner searches edible mushroom candidate mushrooms. agent chooses edible mushroom regret change agent chooses poisonous regret increases experimented different settings. ﬁrst uses data assumes noise context sample variance second added artiﬁcial noise features similar synthetic experiment. dimension added gaussian noise mean variance results reported figure ﬁrst experiment without noise observe linucb performs quite well almost zero regret since data almost linearly separable i.e. best setting linucb. however second experiment artiﬁcial noise universal-nlinrel deﬁnitely outperforms linucb. experiment shows scenarios important learn/know statistical information noise performance universal-nlinrel. leave exploration future. paper study contextual multi-armed bandit problems assuming linear payoffs uncertainty features. based theoretical understandings special cases identical noise gaussian features could develop universal-nlinrel general scenarios. believe utilizing model uncertainties addressed paper would provide important direction designing practical algorithms bandit task.", "year": 2017}