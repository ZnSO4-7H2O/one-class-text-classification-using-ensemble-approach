{"title": "Inference for Belief Networks Using Coupling From the Past", "tag": ["cs.AI", "cs.LG"], "abstract": "Inference for belief networks using Gibbs sampling produces a distribution for unobserved variables that differs from the correct distribution by a (usually) unknown error, since convergence to the right distribution occurs only asymptotically. The method of \"coupling from the past\" samples from exactly the correct distribution by (conceptually) running dependent Gibbs sampling simulations from every possible starting state from a time far enough in the past that all runs reach the same state at time t=0. Explicitly considering every possible state is intractable for large networks, however. We propose a method for layered noisy-or networks that uses a compact, but often imprecise, summary of a set of states. This method samples from exactly the correct distribution, and requires only about twice the time per step as ordinary Gibbs sampling, but it may require more simulation steps than would be needed if chains were tracked exactly.", "text": "inference belief sampling produces served variables distribution since convergence occurs asymptotically \"coupling actly correct gibbs sampling ally) running ulations starting time enough past runs reach state time state plicitly tractable propose net­ works uses compact cise summary states. samples correct requires step ordinary require needed chains time differs amount. error greatest chain generally phase felt burn-in within desired usually rate convergence markov chain known theoretically. possible underestimate desired might greatly minimize overcome wilson introduced known perfect simulation using pling past\" obtain states desired arbitrary chains enough back chains coalesce single comes correct pling begin time zero bias state probabilities pmt. represented distribution godic markov chain invariant reached distribution noisy-or ditional bilities variables. parent variable able turned gibbs sampling entries conditional able taking values distribution propp wilson proposed coupling error using finite-length godic markov chain reach equilibrium tion infinite amount time. there­ fore willing sure correct reached. necessary howeverthat least state space finite find exact result propp wilson's time past starting sible state. dependencies make coalesce time said matter state started time state time results. coalescence time procedure minimum initial chains arriving pseudo-random quent transitions. first coalesce. coalescence single pendencies chains invalidate sitions paper consider sampling updated required updated according single cient making random choice dependencies random number chains. chains pseudo-random times coalescence cient chain started step time efficient times ···until coalescence finally occurs. scheme optimal four times total number simulation steps note coalesced obtain state correct usually coalescence occurs state time used bias introduced toward conditions chains. dependence occurs. coalesce start chains chains pseudo-random already bias introduced numbers keeping state generally space exponential network. propp past implemented states chains states. tonic chains convergence past quite attractive coupling performed variables pseudo-random exactly independent tion. time procedure starting procedure running amounts coalesce). tempts result attempts period past independent later however reasonable minate using gibbs sampling state invariant coupling dinary gibbs sampling states exactly able coupling eral times invariant chains follow tial states them since completely other past. time following less valuable states cost markov chain transition. address simplify belief attempt chain whose states original summary chain transitions original chain ables network method track chains slow detection result similar techniques applied random fields huber haggstrom transitions true chains duced. example consider transition mary chain changes last variable original states states different last variable state states rather previous spurious possible determine conditional search without exhaustive chosen states examining probability minimum maximum value. parents children required max­ conditional imized minimizing show single summary chain simulated chains none true chains lost though spu­ coalescence. rious chains transitions gibbs sampling chain like original time. summary chain change variable updated state variable given conditional probability variables state. states state summary chain maps condi­ maximum tional probability minimum value used determine transition using fact chains coupled using assume uni­ pseudo-random formly distributed original able updated less conditional probability summary chain determined summary chain started variables state possible states. network show early enough summary chain reached state representing single network state i.e. none variables approximation coalesced spurious started chains tracked explicitly. coalescence time past sufficient simulation propp wilson show expected around times coalescence simulation tional probability minimum maximum. therefore pected computational terms com­ putations similar times expected sition matrix reviewed example thal eigenvector invariant eigenvalue eigenvalue nitude less closer slower convergence markov chain. transition matrix summary chain eigenvectors chain including sponding chains converge summary chain also eigenvectors eigenvalues states vari­ ables value eigen­ values larger magnitude second chain. therefore largest original summary chain cannot converge faster chains summarizes below examine simple diagnostic layer variables various \"symptoms\" bottom layer. interest diseases summary chain method used coales­ chains tracked cence time greater explicitly. coalescence times small problems calculating summary chains eigenvalues tion matrices. chain bounded terms expected coa­ lescence general indicative transitions chains coupled types past perfectly networks. example one-disease network symptoms known. variable summary state exact representation network unknowns also perfectly summarized. although possible summary chain exactly states true chains summary chain summarizes variable variables tion starting possible true chains coalesce therefore values). absent produce interactions diseases independent network effectively sub­ states whose transitions sections. inde­ pendent single-disease sub-networks sampling converge uations discovered run-time symptoms instantiated. example two-disease original disease chain states non-zero transition matri­ associated shown table largest eigenvalue largest eigenvalue using summary chain coalescence chains quick explicitly possible indeed experimental initial states show methods perform identically. simple networks great inter­ themselves exist sub-networks within larger network. noisy-or symptoms diseases general summarized variables summary chain original moderate non-zero summary chain transition matrix net­ work shown table transition additional ponents states ?-valued variables eigenvalue eigenvalues compared indicates summary chain. experiments detecting chain requires past compared time steps every state tracked probabilities work extreme worse tracking work coalesces explicitly ordinary long time needed detected mary chain's pared original apriori symptom probability chains coalesce quickly explanations diseases networkeffect lost sets states approximately explicitly gibbs sampling less calculations erties known coupling putationally error tolerance. ties known however \"burn-in\" eliminates tribution tive whenever", "year": 2013}