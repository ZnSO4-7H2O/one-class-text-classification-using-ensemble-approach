{"title": "Counterfactual Estimation and Optimization of Click Metrics for Search  Engines", "tag": ["cs.LG", "cs.AI", "stat.AP", "stat.ML", "G.3; H.3.3"], "abstract": "Optimizing an interactive system against a predefined online metric is particularly challenging, when the metric is computed from user feedback such as clicks and payments. The key challenge is the counterfactual nature: in the case of Web search, any change to a component of the search engine may result in a different search result page for the same query, but we normally cannot infer reliably from search log how users would react to the new result page. Consequently, it appears impossible to accurately estimate online metrics that depend on user feedback, unless the new engine is run to serve users and compared with a baseline in an A/B test. This approach, while valid and successful, is unfortunately expensive and time-consuming. In this paper, we propose to address this problem using causal inference techniques, under the contextual-bandit framework. This approach effectively allows one to run (potentially infinitely) many A/B tests offline from search log, making it possible to estimate and optimize online metrics quickly and inexpensively. Focusing on an important component in a commercial search engine, we show how these ideas can be instantiated and applied, and obtain very promising results that suggest the wide applicability of these techniques.", "text": "standard approach evaluating ranking quality search engine evaluate ranking results human-labeled examples compute relevance metrics like mean average precision normalized discounted cumulative gain approach highly successful facilitating easy comparison improvement ranking functions however oﬄine relevance metrics limitations. first mismatch users’ actual information need relevance judgments human labelers. example query cruise natural judge give high relevance score actor’s oﬃcial website http//tomcruise.com. however search commercial search engine suggests opposite—users issue query often interested news actor oﬃcial website. second applications like personalized search recency search judges simply lack information provide sensible labels. third user experience search engine relies ranking function modules like user interfaces. relevance labels query-document pairs reﬂect aspect search engine’s overall quality. finally important factor nowadays search engine monetization performance cannot easily judged human labelers. challenges imply strong need considering user feedback evaluating potentially optimizing search engine. example user behavior like clicks used infer personalized relevance evaluation purposes compare ranking systems interleaving unfortunately metrics depend user feedback hard estimate oﬄine counterfactual nature. example suppose interested measuring time-to-ﬁrst-click metric. change part search engine ﬁnal search engine result page particular query diﬀerent hence users’ click behavior change well. based search often challenging infer user would done serp diﬀerent log. prediction errors state-of-the-art user click models variants) likely much larger usual improvements click-based metrics nowadays commercial search engines already highly optimized. therefore oﬄine evaluaoptimizing interactive system predeﬁned online metric particularly challenging metric computed user feedback clicks payments. challenge counterfactual nature case search change component search engine result diﬀerent search result page query normally cannot infer reliably search users would react result page. consequently appears impossible accurately estimate online metrics depend user feedback unless engine serve users compared baseline test. approach valid successful unfortunately expensive time-consuming. paper propose address problem using causal inference techniques contextual-bandit framework. approach effectively allows many tests oﬄine search making possible estimate optimize online metrics quickly inexpensively. focusing important component commercial search engine show ideas instantiated applied obtain promising results suggest wide applicability techniques. practice common solution controlled experiment speciﬁcally randomly splits users statistically identical groups known control treatment respectively. users control group served baseline search engine users treatment group modiﬁed engine experiment last days weeks online metrics systems calculated. reaches conclusion whether modiﬁed engine better baseline certain statistically signiﬁcance level. controlled experiments proved successful practice allowing engineering business decisions made data-driven manner. however experiments usually require nontrivial engineering resources time-consuming since experiments real users signiﬁcant eﬀorts needed avoid surprises experiments. furthermore trying optimize online click metric often takes guess-then-check approach easy-to-compute proxy metric used oﬄine obtain modiﬁed engine hoped well later controlled experiment terms click metric real interest. approximation nature proxy metric misleading determining modiﬁed system experiment. combined long turnaround time tests indirect optimization procedure rather ineﬃcient. paper advocate causal inference techniques statistics perform unbiased oﬄine evaluation click metrics search engines. compared tests oﬄine evaluation allows multiple models evaluated search without need online. eﬀectively technique makes possible many tests simultaneously leading substantial increase experimentation agility even optimize online metrics directly. best knowledge work ﬁrst validate possibility oﬄine evaluation live commercial search engine oﬄine evaluation subroutine oﬄine optimization. rest paper organized follows. section describes contextual bandit general framework capture number interactive problems including many search. section describes basic technical idea oﬄine evaluation discusses solutions important issues arise practice. section gives details case study commercial search engine. section discusses related work. finally section concludes paper. contextual-bandit formalism generalizes classic multi-armed bandits introducing contextual information interaction loop learner environment situated proved useful model many important applications interaction present online advertising content recommendation environment chooses contextual information reward signal action possible contextual information. reward vector. revealed learner. assumed drawn i.i.d. unknown distribution value policy measures much per-round reward receives average. choose actions rounds observe corresponding reward every round value estimated averaging observed reward estimate converges almost surely increases. example consider federated search search engine needs decide given query whether include vertical search results like news images ﬁnal serp here context contains submitted query user proﬁle possibly information. actions combine vertical search result search results. reward often click-through vertical results. finally basic problem federate search optimize policy decides vertical search results given current context order maximize average reward. section study details another important component search engine. important observation contextual bandits that rewards chosen actions observed. onlinelearning algorithm must therefore good exploration/exploitation tradeoﬀ deﬁning challenge bandit problems. oﬄine policy evaluation partial observability raises related diﬃculty. data contextual bandit often form action chosen context collecting data corresponding reward. data used evaluate policy chooses diﬀerent action simply observed previously oﬄine policy evaluation interpreted causal inference problem important research topic statistics. here infer average reward policy used choose actions bandit problem approach take paper relies randomized data colend process containing data form call kind data exploration data since actions nonzero probability explored collection process. statistics probabilities also known propensity scores. equality show unbiasedness oﬄine estimator provided every component nonzero. words long randomize action selection construct unbiased estimate policy without even running users. beneﬁt highly desirable since oﬄine evaluator allows simulate many tests fast inexpensive way. unbiasedness guarantee holds probability distribution long none component zero. however variance oﬄine evaluator depends critically distribution. evaluator gives accurate estimates variance lower. therefore variance smaller place probability mass actions chosen policy reality however typically know ahead time data collected multiple policies evaluated exploration data. natural choice adopted authors minimize least limitations choice. first choosing action uniformly random risky user experience unless knows priori every action reasonably good. second improving existing policy already working reasonably well likely improvement diﬀer much minimizing worst-case variance yield best variance reduction reality. concerns imply conservative data collection procedure eﬀective uniform random distribution. intuitively given baseline policy inject randomization generate randomized actions close baseline policy. precise depends problem hand. section describe sensible approach worked well expected useful scenarios. shown equation necessary compute propensity scores errors calculation and/or logging scores lead bias ﬁnal oﬄine estimator. furthermore since reciprocal score used estimate even small error score lead much larger bias oﬄine estimator close solution obtain randomization seed whenever action chosen. speciﬁcally round data collection choose seed reset internal state pseudo-random number generator. then generator select random action multinomial distribution ﬁnal data form containing information facilitate oﬄine veriﬁcation. want verify propensity scores simply seed reproduce randomized data collection process check consistency among round data collection. instead runs simple statistical tests detect inconsistency. approach quite useful experience although note detects data issues. pears data expected number occurrences conditioned logged propensity scores. concentration inequalities like hoeﬀding’s used estimate whether quantities statistically signiﬁcant not. signiﬁcant indicates errors randomized data collection process. therefore compare mean random variable data verify close expected value again statistical signiﬁcance estimated concentration inequalities. since condition uses harmonic means propensity scores called harmonic mean test. equation gives point-estimate useful without considering variance information compare oﬄine estimates policies’ values must resort reliable conﬁdence intervals infer whether diﬀerence point-estimates signiﬁcant not. based various concentration inequalities bottou developed series interesting conﬁdence intervals. widths intervals used gain helpful insights data collection process. results interesting necessarily best candidate empirically worst-case nature. suggested authors reality better normal approximation theory obtain conﬁdence intervals. approach take work. speller critical component search engine enabling translate queries typing phonetic errors correct forms match rank relevant results instant answers even user-typed query misspelt. spelling correction queries hard problem particularly absence dictionary terms words entities emerging reading this. further person’s typo could anperson’s correct query. example given user typed possibility wanting type ending making typo really intent type ccn. typically noisy channel models applied address computing probabilities true intents given typed using popularities well likely user make exact typo. additional features machine learning used rank candidates problem focus train model select subset candidates already computed rewritten queries given input query. idea select multiple candidates mitigate risk picking correction early lifetime query fetching results formulations would either predict single best rewrite merge results multiple rewrites. training ranker rewritten query candidates human-labeled corrections works large number queries cases above judge complete loss users’ real intent predicting likelihood intents cnn. hence desirable learn spelling correction actually serves user’s intent implicitly user behavior. furthermore approach much cheaper human judging queries oﬄine. given spelling correction algorithm user’s satisfaction measured modeling user interacted search engine real search session. using terminology section context includes user-typed query rewritten candidates action decide candidate use; reward metric derived user clicks ﬁnal search result page. business sensitivity metric revealed although suﬃces metric measures goodness ﬁnal serp present user. metric referred target parameters tuned yield good balance aggressiveness exploration potential negative user experience. case parameters chosen path-selection probabilities fell oﬄine metric based judge labels severely aﬀected. probabilities propensity scores actions computed. beneﬁts using randomization scheme. first always including ﬁnal serp usually reasonably good users included datacollection process would notice much decrease relevance quality. second scheme motivated intuition candidates higher scores tend better likely chosen good policy. biasing data collection towards promising candidates likely reduce variance following discussion section data collected arithmetic harmonic mean tests described section found major issues. worth mentioning tests able help detect data issues earlier versions data collection leading ﬁxes eventually improved data quality. section advocate asymptotic normal approximation construct conﬁdence intervals. underlying assumption that amount data large estimator equation almost normally distributed. here verify assumption empirically bootstrapping. them computed unbiased oﬄine estimate clickrate ﬁxed policy finally estimates policy. since dealing large data implemented online bootstrap essentially identical standard bootstrap size data. result thus validates form conﬁdence intervals given section given size data conﬁdence intervals computed tiny usually order less. therefore include tiny intervals plots. accuracy ground truths period time collected also another candidate selection policy online statistics could used ground truth used validate accuracy oﬄine estimator using exploration data first examine estimate target metric week. figure scatter plot online oﬄine values. expected ofﬂine estimates highly accurate centering around online ground truth values. also included plot biased version oﬄine estimate labeled oﬄine uses following variant equation look metric closely. figure plots daily varies within week. again oﬄine estimates match online values accurately. curves statistically signiﬁcant conﬁdence intervals’ widths roughly figure gives fraction clicks contributed urls diﬀerent positions serp. figure measures many clicks received within given time user submitted query. results show high accuracy oﬄine evaluator. also done comparison metrics observed similar results. used diﬀerent data similarly collected fall split randomly training evaluation training extracted training data whose labels determined based whether sent candidate contributed positively target metric. obtained binary classiﬁcation problem tries predict whether rewritten query contribute target metric conditioned original query. boosted logistic regression used learn model. learning model meta-parameters chosen balance target metric improvement capacity constraints. could used prediction accuracy hold-out select them accuracy necessarily correlated target metric optimize eventually. fortunately reliable oﬄine evaluator used select parameters optimize target metric directly respecting capacity constraints. based oﬄine evaluation results picked model test. two-week experiment done late model show statistically signiﬁcant improvement existing baseline demonstrating power oﬄine evaluator. below demonstrate successful cases model improves upon baseline. ﬁrst example user-typed query umecka zinc. policy successfully identiﬁed corrected query umcka zinc medical treatments cold symptoms relief. serp included amazon page product customer reviews comparing zinc supplements analyzing user clicks serp suggested user found needed information. contrast baseline well similar commercial search engines appeared miss correction showed results contained exact match umecka. second example original query submitted user catalina left attorney. policy correctly suggested catalina attorney appeared right correction attorney diego whose long history evaluation methodology research information retrieval community dominant approach collect relevance judgments collection query-document pairs compare diﬀerent retrieval/ranking functions metrics like mean average precision normalized discounted cumulative gains approach successful low-cost evaluation scheme. however several authors argued several limitations addition ones discussed sections alternative user-centered evaluation emphasizes interaction user search engine. challenge user-centered approach relatively high cost system evaluation comparison. work therefore provides promising solution shown success actual search engine. industry people also measured various online metrics monitor compare systems running serve users. randomized control experiments standard measure compare online metrics. recently interleaving become attractive technique quickly identify winner comping systems techniques requires running system real users oﬄine approach eﬃcient less expensive. mentioned earlier oﬄine evaluation technique closely related causal inference statistics aims infer observational data counterfactual eﬀect measurement changing policy counterfactual methods shown promise important applications recently like advertising content recommendation work formulate problem contextual bandit framework natural model interactive machine learning problems. furthermore although oﬄine evaluation applied recency search past best knowledge work ﬁrst demonstrate eﬀectiveness counterfactual analytic techniques search including head-to-head comparisons oﬄine optimization commercial search engine. work formulate class optimization problems search engines contextual bandit problem focus oﬄine policy evaluation problem. approach uses counterfactual analytic techniques obtain unbiased estimate true policy value without need policy real users. using data collected commercial search engine veriﬁed reliability evaluation also showed successful application oﬄine policy evaluation. speller tractably small consider short list candidates. actions ranking problem deﬁned naively consists permutations urls. exponentially large cause variance large. would interesting leverage successful ideas related work address issue. another direction worth investigating direct optimization policies based exploration data with instance oﬀset tree algorithm qui˜nonero-candela denis xavier charles chickering elon portugaly dipankar patrice simard snelson. counterfactual reasoning learning systems example computational advertising. journal machine learning research lazier matt deeds nicole hamilton gregory hullender. learning rank using gradient descent. proceedings twenty-second international conference machine learning pages diane lambert. evaluating online campaigns pipeline causal models scale. proceedings sixteenth sigkdd conference knowledge discovery data mining pages jing ruiqiang zhang karolina buchner ciya liao fernando diaz. towards recency ranking search. proceedings third international conference search data mining pages sun. large scale ranker-based system search query spelling correction. proceedings twenty-third international conference computational linguistics pages agarwal. automatic format selection contextual bandits. proceedings twenty-second international conference information knowledge management pages chapelle keke chen gordon sun. general boosting method application learning ranking functions search. advances neural information processing systems pages schapire. contextual-bandit approach personalized news article recommendation. proceedings nineteenth international conference world wide pages wang. unbiased oﬄine evaluation contextual-bandit-based news article recommendation algorithms. proceedings fourth international conference search data mining pages", "year": 2014}