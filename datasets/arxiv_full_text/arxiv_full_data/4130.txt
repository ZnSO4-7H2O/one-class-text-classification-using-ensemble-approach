{"title": "SR-Clustering: Semantic Regularized Clustering for Egocentric Photo  Streams Segmentation", "tag": ["cs.AI", "cs.CV"], "abstract": "While wearable cameras are becoming increasingly popular, locating relevant information in large unstructured collections of egocentric images is still a tedious and time consuming processes. This paper addresses the problem of organizing egocentric photo streams acquired by a wearable camera into semantically meaningful segments. First, contextual and semantic information is extracted for each image by employing a Convolutional Neural Networks approach. Later, by integrating language processing, a vocabulary of concepts is defined in a semantic space. Finally, by exploiting the temporal coherence in photo streams, images which share contextual and semantic attributes are grouped together. The resulting temporal segmentation is particularly suited for further analysis, ranging from activity and event recognition to semantic indexing and summarization. Experiments over egocentric sets of nearly 17,000 images, show that the proposed approach outperforms state-of-the-art methods.", "text": "wearable cameras becoming increasingly popular locating relevant information large unstructured collections egocentric images still tedious time consuming process. paper addresses problem organizing egocentric photo streams acquired wearable camera semantically meaningful segments hence making important step towards goal automatically annotating photos browsing retrieval. proposed method ﬁrst contextual semantic information extracted image employing convolutional neural networks approach. later vocabulary concepts deﬁned semantic space relying linguistic information. finally exploiting temporal coherence concepts photo streams images share contextual semantic attributes grouped together. resulting temporal segmentation particularly suited analysis ranging event recognition semantic indexing summarization. experimental results egocentric nearly images show prominence proposed approach state-of-the-art methods. among advances wearable technology last years wearable cameras speciﬁcally gained popularity small lightweight devices allow capture high quality images hands free fashion figure example temporal segmentation egocentric sequence based camera wearer sees. addition segmentation method provides semantic attributes characterize segment. ﬁrst-person point view. wearable video cameras gopro looxcie relatively high frame rate ranging mostly used recording user activities hours. instead wearable photo cameras narrative clip sensecam capture therefore mostly used image acquisition longer periods time images collected continuously recording user’s life used understanding user’s lifestyle hence potentially beneﬁcial prevention non-communicative diseases associated unhealthy trends risky proﬁles addition images used important tool prevention hindrance cognitive functional decline elderly people however egocentric photo streams generally appear form long unstructured sequences images often high degree redundancy abrupt appearance changes even temporally adjacent frames harden extraction semantically meaningful content. temporal segmentation process organizing unstructured data homogeneous chapters provides large potential extracting semantic information. indeed photo stream divided homogeneous manageable segments segment represented small number key-frames indexed semantic features providing basis understanding semantic structure event. state-of-the-art methods temporal segmentation broadly classiﬁed works focus what-the-camera-wearer-sees whatthe-camera-wearer-does example what-camera-wearerperspective camera wearer spending time considered unique event what-the-camera-wearer-sees perspective situation considered several separated events distinction aforementioned points view crucial leads diﬀerent deﬁnitions event. respect proposed method what-the-camera-wearer-sees category. early works egocentric temporal segmentation focused camera wearer sees purpose authors used image representation low-level features capture basic characteristics environment around user color texture information acquired diﬀerent camera sensors. recently works used convolutional neural network features extracted using alexnet model trained imagenet ﬁxed feature extractor image representation. recent methods infer images camera wearer castro used features together metadata color histogram methods image representation ego-motion closely related user motion-based activity cannot reliably estimated photo streams. authors combined trained egocentric data posterior random decision forest late-fusion ensemble obtaining promising results single user. however approach lack generalization since requires re-train model user implying manually annotate large amount images. best knowledge except work castro doherty tavalera state-of-the-art methods designed tested videos.in previous work proposed unsupervised method called r-clustering aiming segment photo streams what-the-camera-wearer-see perspective. proposed methods relies combination agglomerative clustering usually high recall leads temporal over-segmentation statistically founded change detector called adwin despite high precision usually leads temporal under-segmentation. approaches integrated graph-cut framework obtain trade-oﬀ adwin complementary properties. graph-cut relies cnn-based features extracted using alexnet trained imagenet ﬁxed feature extractor order detect segment boundaries. paper extend previous work adding semantic level image representation. free motion camera frame rate abrupt changes visible even among temporally adjacent images conditions motion low-level features color image layout prone fail event representation hence urges need incorporate higher-level semantic information. instead representing images simply contextual features capture basic environment appearance detect segments temporally adjacent images contextual representation terms semantic visual concepts. nonetheless semantic concepts image equally discriminant environment classiﬁcation objects like trees buildings discriminant objects like dogs mobile phones since former characterizes speciﬁc environment forest street whereas latter found many diﬀerent environments. paper propose method called semantic regularized clustering takes account semantic concepts image together global image context event representation. manuscript organized follows section provides description proposed photo stream segmentation approach discussing semantic contextual features clustering graph-cut model. section presents experimental results ﬁnally section summarizes important outcomes proposed method providing concluding remarks. visual overview proposed method given fig. input long photo stream contextual semantic features extracted. initial clustering performed adwin. later applied look trade-oﬀ adwin approaches. binary term imposes smoothness similarity consecutive frames terms image features. output proposed method segmented photo stream. section introduce semantic contextual features sr-clustering provide detailed description segmentation approach. assume consecutive images belong segment described similar image features. refer features image usually consider low-level image features global representation environment however objects concepts semantically represent event also high importance photo stream segmentation. below detail features semantically describe egocentric images. given image consider tagging algorithm returns objects/tags/concepts detected images associated conﬁdence value. conﬁdence values concept form semantic feature vector used photo streams segmentation. usually number concepts detected sequence images large additionally redundancies detected concepts quite often presence synonyms semantically related words. manage semantic redundancy rely wordnet lexical database groups english words sets synonyms providing additionally short deﬁnitions word relations. given day’s lifelog cluster concepts relying synset wordnet compute similarity meaning following apply clustering obtain clusters. result semantically describe image terms concepts associated fig. simpliﬁed example result obtained clustering procedure shown. instance purple cluster similar concepts like ’writing’ ’document’ ’drawing’ ’write’ etc. grouped cluster ’writing’ chosen representative term. cluster choose representative concept highest similarities rest elements cluster. semantic feature vector r|c| image -dimensional array component vector represents conﬁdence j-th concept detected image. conﬁdence value concept representing cluster obtained conﬁdences concepts included also detected image concepts detected image concepts cluster conﬁdence associated concept image ﬁnal conﬁdence values normalized interval taking account camera wearer continuously moving even single environment objects appearing temporally adjacent images diﬀerent. apply parzen window density estimation method matrix obtained concatenating semantic feature vectors along sequence obtain smoothed temporally coherent conﬁdence values. additionally discard concepts variability conﬁdence values along sequence correspond non-discriminative concepts appear environment. variability conﬁdence value concept correspond constantly high conﬁdence value environments. fig. matrix concepts associated egocentric sequence shown displaying classes. column matrix corresponds frame indicates conﬁdence concept detected frame. ﬁrst ground truth temporal segmentation shown comparison purposes. representation repeated patterns along continuous images correspond concepts characterizes event. instance ﬁrst frames figure simpliﬁed graph obtained calculating similarities concepts day’s lifelog clustering them. color corresponds diﬀerent cluster edge width represents magnitude similarity concepts nodes size represents number connections showed small subset clusters. graph drawn using graphtool figure example ﬁnal semantic feature matrix obtained egocentric sequence. concepts shown images sequence additionally matrix shows ground truth segmentation dataset. ltd. imagga’s auto-tagging technology uses combination image recognition based deep learning cnns using large collections human annotated photos. advantage imagga’s auto tagging directly recognize diﬀerent objects addition return abstract concepts related analyzed images. addition semantic features represent images feature vector extracted pre-trained cnn. model computing images representation alexnet detailed features computed removing last layer corresponding classiﬁer network. used deep learning framework caﬀe order cnn. fact weights trained imagenet database made images containing single objects expect features extracted images containing multiple objects representative environment. worth remark weights obtained using pre-trained scenes places database since narrative camera’s ﬁeld view narrow means mostly ﬁeld-of-view restricted characterize whole scene. instead usually objects foreground. detailed reduce large variation distribution features results problematic computing distances vectors used signed root normalization produce uniformly distributed data concatenation semantic contextual features hierarchical agglomerative clustering method applied following bottom-up clustering procedure. iteration method merges similar pair clusters based distances among image features updating elements similarity matrix. done exhausting possible consistent combinations. cutoﬀ global parameter deﬁnes consistency merged clusters. cosine similarity samples suited high-dimensional positive spaces shortcoming method tends over-segment photo streams. compensate over-segmentation produced proposed model egocentric sequence multi-dimensional data stream detect changes mean distribution adaptive learning method called adwin provides rigorous statistical guarantee performance terms false positive rate. method based hoeﬀding’s inequality tests recursively diﬀerence averages temporally adjacent windows data larger threshold. value threshold takes account sub-windows large enough distinct enough k−dimensional signal computed indicates p−norm user deﬁned conﬁdence parameter harmonic mean lengths words given predetermined conﬁdence adwin statistically guarantees major change data means. given conﬁdence value higher dimension samples bound needs reach assuming value \u0001cut. higher norm used less important dimensionality since model sequence high dimensional data stream adwin unable predict changes involving relatively small number samples often characterizes temporal resolution egocentric data leading under-segmentation. moreover since considers mean change able detect changes statistics variance. graph-cuts framework integrate previously described approaches adwin compromise naturally leads temporally consistent result. energy-minimization technique works ﬁnding minimum energy function usually composed terms unary term also called data term describes relationship variables possible class binary term also called pairwise regularization term describes relationship neighboring samples according feature similarity. binary term smooths boundaries similar frames unary term keeps cluster membership sequence frame according likelihood. problem deﬁned unary term parts uadw). expresses likelihood image represented features belong segments coming corresponding previously applied segmentation methods. energy function minimized following weighting terms respectively. improve segmentation outcome deﬁning much weight give likelihood unary term balancing trade-oﬀ unary pairwise energies respectively. minimization achieved max-cut algorithm leading temporal segmentation similar frames large likelihood possible belong segment maintaining segment boundaries temporally neighboring images high feature dissimilarity. section discuss datasets statistical evaluation measurements used validate proposed model compare state-of-the-art methods. apply following methodology validation table table summarizing main characteristics datasets used work frame rate spatial resolution number users number days number images huji egoseg dataset subsampled detailed main text. edub-seg dataset acquired people narrative clip takes picture every seconds. narrative dataset named edub-seg contains total images captured diﬀerent users overall days. ensure diversity users wearing camera diﬀerent contexts attending conference holiday weekend week. edub-seg dataset extension dataset used previous work call edub-seg distinguish newly added paper edub-seg camera wearers well researchers involved work required sign informed written consent containing moral principles moreover researchers team signed publish image identifying person photo stream without his/her explicit permission except unknown third parties. aihs subset subset daily images database called seen recorded sensecam camera takes picture every seconds.the original aihs dataset timestamp metadata. manually divided dataset days guided pictures authors show website project based daylight changes observed photo streams. days total images. comparing cameras remark diﬀerence respect cameras’ lens quality images record. moreover sensecam acquires images larger ﬁeld view signiﬁcant deformation blurring. manually deﬁned dataset following criteria used edub-seg photo streams. huji egoseg lack publicly available datasets event segmentation also test temporal segmentation method ones provided dataset huji egoseg dataset acquired gopro camera captures videos temporal resolution fps. considering signiﬁcant diﬀerence frame rate camera compared narrative sensecam applied sub-sampling data keeping images minute make comparable datasets. dataset several short videos recorded diﬀerent users provided. consequently sub-sampling videos merged resulting images short videos construct dataset user consists total number images. images merged following numbering order provided authors videos. also manually deﬁned dataset following used criteria edub-seg dataset. summary evaluate algorithms days total images recorded diﬀerent users. datasets contain mixture highly variable indoor outdoor scenes large variety objects. make public edub-seg dataset together segmentations datasets huji egoseg aihs subset. additionally release sr-clustering readyto-use complete code. precision deﬁned recall deﬁned number true positives false positives false negatives detected segment boundaries photo stream. deﬁne consider images model detects boundaries event close boundary image deﬁned annotator images detected events delimiters deﬁned lost boundaries model indicated lower values represent wrong boundary detection higher values indicate good segmentation. ideal maximum value segmentation correlates completely deﬁned user. annotation temporal segmentations photo streams subjective task. fact diﬀerent users usually perform annotating lead bias evaluation performance. problem subjectivity deﬁning ground truth previously addressed context image segmentation authors proposed measures compare diﬀerent segmentations image. measures used validate performed segmentations diﬀerent users consistent thus served objective benchmark evaluation segmentation performances. fig. report visual example illustrates urge employing measure temporal segmentation egocentric photo streams. instance ﬁrst segment fig. split diﬀerent segments analyzed diﬀerent subjects although degree consistency among segments. inspired work re-deﬁne local reﬁnement error temporal segments follows temporal segment proper subset other images interval reﬁnement results local error zero. however subset relationship regions overlap inconsistent manner results non-zero local error. based deﬁnition local reﬁnement provided above error measures deﬁned combining values local reﬁnement error entire sequence. ﬁrst error measure called global consistency error forces local reﬁnements direction shows part day. examples segmentation performed three diﬀerent persons. reﬁnements segmentation performed three results considered correct subjective intrinsic task. consequence segmentation consistency metric penalize diﬀerent consistent results segmentation. segments segmentation second error measure local consistency error allows reﬁnements diﬀerent directions diﬀerent parts sequence measures deﬁned follows verify consistency among diﬀerent people task temporal segmentation asked three diﬀerent subjects segment sets edub-seg dataset events. subjects instructed consider event semantically perceptual unit inferred visual features without prior knowledge camera wearer actually doing. instructions given subjects number segments annotate. process gave rise diﬀerent segmentations. number possible pairs segmentations figure normalized histograms error values distributions showing mean variance. ﬁrst graphs represent distribution errors comparing segmentations diﬀerent sequences second graphs show distribution error comparing segmentations including segmentation camera wearer. figure pairs segmentations diﬀerent sequences pairs segmentations sequence diﬀerences w.r.t. dashed line show stricter measure lce. represents mean cloud values including segmentation camera wearer. figure normalized histograms error values distributions showing mean variance. ﬁrst graphs represent distribution errors comparing segmentations diﬀerent sequences second graphs show distribution errors comparing segmentations excluding segmentation camera wearer. figure pairs segmentations diﬀerent sequences pairs segmentations sequence diﬀerences w.r.t. dashed line show stricter measure lce. represents mean cloud values excluding segmentation camera wearer. sequence then considered rest possible pairs segmentations dataset. ﬁrst graphics fig. show comparing segmentations segmentations applied rest sets. graphics second show distribution error analyzing diﬀerent segments describing video. expected distributions compare segmentations photo stream center mass left graph means mean error segmentations belonging lower mean error segmentations describing diﬀerent sets. fig. compare pair segmentations measures produced diﬀerent datasets segmentations measures produced segmentations dataset cases plot gce. expected average error segmentations photo stream lower average error segmentations diﬀerent photo streams moreover indicated shape distributions second fig. peak close zero. therefore conclude given task segmenting egocentric photo stream events diﬀerent people tend produce consistent valid segmentation. fig. show segmentation comparisons three diﬀerent persons asked temporally segment photo stream conﬁrm statement diﬀerent people tend produce consistent segmentations. since interpretation events biased personal experience segmentation done camera wearer could diﬀerent segmentations done third persons. quantify diﬀerence fig. fig. evaluated including also segmentation performed camera wearer. comparison observe error mean vary degree local global consistency higher annotators include camera wearer appreciated fact distributions slightly shifted left thinner. however since variation order conclude event segmentation egocentric photo streams objectively evaluated. comparing diﬀerent segmentation methods w.r.t. obtained applied grid-search choosing best combination hyper-parameters. hyper-parameters tested following figure illustration sr-clustering segmentation results subset pictures narrative set. line represents diﬀerent segment. segment show found concepts pictures segment shown. table show results obtained diﬀerent segmentation methods diﬀerent datasets. ﬁrst columns correspond datasets used aihs-subset edub-seg third column corresponds edub-seg introduced paper. finally fourth column corresponds results whole edub-seg. ﬁrst part table presents comparisons state-of-the-art methods. second part table shows comparisons diﬀerent components proposed clustering method without semantic features. finally third part table shows results obtained using diﬀerent variations method. table average results state-of-the-art works egocentric datasets components method variations method last line shows results complete method. stands agglomerative clustering adwin imaggad proposal semantic features stands density estimation. method motion-based segmentation algorithm proposed bola˜nos seen average results obtained sr-clustering. explained type features used method suited applying motion-based segmentation. kind segmentation oriented recognize activities thus always fully aligned event segmentation labeling consider furthermore obtained score narrative datasets lower sensecam’s several reasons narrative lower frame rate compared sensecam handicap computing motion information narrower ﬁeld view decreases semantic information present image. also evaluated proposal grauman apply agglomerative clustering segmentation using color histograms. case algorithm even obtained results agglomerative clustering algorithm used contextual features instead colour histograms. main reason performance difference comes high diﬀerence features expressiveness supports necessity using rich features correctly segmenting highly variable egocentric data. last ﬁrst section table shows results obtained previously published method able outperform state-of-the-art egocentric segmentation using contextual features aihs-subset edub-seg set. another possible method compare would castro although authors provide trained model applying comparison. second part table compare results obtained using adwin without semantic features. proposed semantic features leads improved performance indicating features rich enough provide improvements egocentric photo stream segmentation. finally third part table compared segmentation methodology using diﬀerent deﬁnitions semantic features. sr-clusteringlsda case used simpler semantic features description formed using weakly supervised concept extraction method proposed namely lsda. last lines tested model using proposed semantic methodology either without density estimation sr-clustering-nod ﬁnal density estimation respectively. comparing results sr-clustering r-clustering ﬁrst datasets method able outperform results adding points improvement score keeping nearly value sensecam dataset. improvement achieved using semantic information also corroborated comparing scores obtained second half edub-seg dataset complete version data table report score obtained applying proposed method sub-sampled huji egoseg dataset comparable cameras. proposed method achieves high performance sr-clustering using proposed semantic features. improvement results using gopro camera respect narrative sensecam explained factors diﬀerence ﬁeld view captured gopro compared sensecam narrative better image quality achieved head mounted camera. addition score could consider measures compare consistency automatic segmentations ground truth since methods lead number segments much larger number segments ground truth therefore measures would descriptive enough. fact segmentation reﬁnement segment entire sequence image segment reﬁnement segmentation. consequently trivial segmentations segment entire sequence image segment achieve error zero gce. however observed average number segments obtained method grauman times bigger number segments obtained sensecam dataset times bigger narrative datasets. indeed achieve higher score respect method grauman since produces considerable over-segmentation. experimental results detailed section shown advantages using semantic features temporal segmentation egocentric photo streams. despite common agreement inability low-level features providing understanding semantic structure present complex events need semantic indexing browsing systems high level features context egocentric temporal segmentation summarization limited. mainly diﬃculty dealing huge variability object appearance illumination conditions egocentric images. works doherty grauman temporal segmentation still based level features. addition diﬃculty reliably recognizing objects temporal segmentation egocentric photo streams cope lack temporal coherence practice means motion features cannot reliably estimated. work castro relies visual appearance single images predict activity class image meta-data week hour regularize time. however huge variability appearance timing daily activities approach cannot easily generalized diﬀerent users implying user re-training model thus labeling thousand images required. method proposed paper oﬀers advantage needless cumbersome learning stage oﬀers better generalization. employed concept detector proved oﬀer rich vocabulary describe environment surrounding user. rich characterization useful better segmentation sequences meaningful distinguishable events also serves basis event classiﬁcation activity recognition among others. example aghaei employed temporal segmentation method extract select segments trackable people processed. however incorporating semantic temporal segmentation proposed paper would allow example classify events social non-social events. moreover using additional existing semantic features scene used diﬀerentiate diﬀerent types social event ranging oﬃcial meeting friendly coﬀee break moreover semantic temporal segmentation proposed paper useful indexing browsing. paper proposed unsupervised approach temporal segmentation egocentric photo streams able partition day’s lifelog segments sharing semantic attributes hence providing basis semantic indexing event recognition. proposed approach ﬁrst detects concepts image separately employing approach later clusters detected concepts semantic space hence deﬁning vocabulary concepts day. semantic features combined global image features capturing generic contextual information increase discriminative power. relying semantic features technique used integrate statistical bound produced concept drift method adwin methods complementary properties temporal segmentation. evaluated performance proposed approach diﬀerent segmentation techniques sets acquired three diﬀerent wearable devices showed improvement proposed method respect stateof-the-art. additionally introduced consistency measures validate consistency ground truth. furthermore made publicly available dataset edub-seg together ground truth annotation code. demonstrated semantic information egocentric data crucial development high performance method. research devoted exploit semantic information characterizes segments event recognition social events special interest. additionally interested using semantic attributes describe camera wearer context. hence opening opportunities development systems take beneﬁt contextual awareness including systems stress monitoring daily routine analysis. work partially founded tin--c- grant research project maite garolera funders role study design data collection analysis decision publish preparation manuscript. dimiccoli supported beatriu pin´os grant radeva partly supported icrea academia’ grant.", "year": 2015}