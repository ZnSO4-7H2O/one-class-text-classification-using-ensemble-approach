{"title": "Likelihood-based semi-supervised model selection with applications to  speech processing", "tag": ["stat.ML", "cs.CL", "cs.LG", "stat.AP"], "abstract": "In conventional supervised pattern recognition tasks, model selection is typically accomplished by minimizing the classification error rate on a set of so-called development data, subject to ground-truth labeling by human experts or some other means. In the context of speech processing systems and other large-scale practical applications, however, such labeled development data are typically costly and difficult to obtain. This article proposes an alternative semi-supervised framework for likelihood-based model selection that leverages unlabeled data by using trained classifiers representing each model to automatically generate putative labels. The errors that result from this automatic labeling are shown to be amenable to results from robust statistics, which in turn provide for minimax-optimal censored likelihood ratio tests that recover the nonparametric sign test as a limiting case. This approach is then validated experimentally using a state-of-the-art automatic speech recognition system to select between candidate word pronunciations using unlabeled speech data that only potentially contain instances of the words under test. Results provide supporting evidence for the utility of this approach, and suggest that it may also find use in other applications of machine learning.", "text": "abstract—in conventional supervised pattern recognition tasks model selection typically accomplished minimizing classiﬁcation error rate so-called development data subject ground-truth labeling human experts means. context speech processing systems large-scale practical applications however labeled development data typically costly difﬁcult obtain. article proposes alternative semi-supervised framework likelihood-based model selection leverages unlabeled data using trained classiﬁers representing model automatically generate putative labels. errors result automatic labeling shown amenable results robust statistics turn provide minimax-optimal censored likelihood ratio tests recover nonparametric sign test limiting case. approach validated experimentally using state-of-the-art automatic speech recognition system select candidate word pronunciations using unlabeled speech data potentially contain instances words test. results provide supporting evidence utility approach suggest also applications machine learning. index terms—likelihood ratio tests pronunciation modeling robust statistics semi-supervised learning sign test speech recognition spoken term detection. ratio framework enables unlabeled development data model selection system optimization context large-scale speech processing. within speech engineering community acoustic likelihoods long played prominent role training criterion objective function system development. log-likelihood ratios turn featured ever prominently areas speech speaker language recognition; instance common practice target model likelihoods compared universal background model part many large-scale speech processing systems white human language technology center excellence johns hopkins university statistics information sciences laboratory harvard university oxford street cambridge khudanpur center language speech processing johns hopkins university charles baltimore wolfe statistics information sciences laboratory harvard university work completed white hlt-coe graduate fellow. conditional likelihoods observed data given labels orthographic transcriptions speech waveforms previous work assumed orthographic labels correctly assigned human experts hence known exactly. however labeled data come free; acquisition requires time expertise trained linguist hence limiting scalability large sample sizes necessary succeed practical speech engineering tasks. article thus posits framework likelihoods evaluated using labels automatically assigned competing systems serve proxies likelihoods based ground-truth labeling. yields methodologically sound algorithmic framework incorporate unlabeled data likelihood-based model selection process also practical engineering strategies selecting competing models order optimize large-scale systems. experiments select candidate word pronunciations context state-of-the-art speech processing systems using well-known corpora standard metrics serve demonstrate beneﬁt unlabeled development data context large-scale speech processing. construct framework insights robust statistics used formulate resultant semi-supervised model selection problem manner permits principled analysis efﬁcient effective algorithms derived. considering automatic labeling procedure mixture correct incorrect assignments inﬂuence incorrect labeling limited known censored likelihood ratio evaluation. well-known nonparametric sign test arises natural limiting procedure setting technical development article shows optimality properties derived huber applied semi-supervised setting ensure maximal model selection error induced automatic labeling minimized. thusly arrives algorithmic procedure compares relative performance competing systems order test signiﬁcance performance differences them hence select model closest true data-generating distribution. clarify notions supervised/semi-supervised learning labeled/unlabeled data speech processing context hand brieﬂy recall standard machine learning paradigm follows. fundamentally assumes existence unknown joint probability distribution pxpy number independent identically distributed samples available; termed training data used model predicts values taken based observed instances classiﬁcation tasks discrete random variable range possible values comprises labels—corresponding example orthographic transcript word phrase represented instance acoustic waveform data goal traditional supervised learning scenario devise algorithms strike balance ﬁdelity labeled examples effective generalization as-of-yet unseen test data comprising additional observations classical bias-variance trade-off model goodness-of-ﬁt generalization properties. trade-off typically optimized calculating empirical error rates additional held-out labeled data ground truth known manner similar parameter estimation cross-validation. fitting model accomplish goal thus mathematically equivalent building system speaks training model-building stage testing application stage system subsequently deployed practical use—and assumes training test data drawn probability distribution. assumption satisﬁed clear speech engineering systems beneﬁt directly ever-greater amounts labeled training data. time money expertise however typically limit amount data available given application scenario interest. thus much interest develop algorithms built using amount labeled training data whose performance improved careful unlabeled data—the so-called semi-supervised learning paradigm thus application semi-supervised methods speech processing limited ideas data augmentation self-training involves reﬁtting models consideration—and hence rebuilding corresponding speech engineering systems. approaches shown promise extreme re-ﬁtting desirable—or even possible—in certain settings instance large-scale system already deployed must adapted test conditions. speech engineering thus ripe introduction semi-supervised learning approaches; nearly limitless amounts acoustic waveform data acquired variety digital sources also many algorithms matured point performance improvements often driven simply increasing amount labeled training data. employing unlabeled data directly improve existing approaches however requires inferring labels—and context natural unsolved problem understand whether automatically labeled data taken output current systems used effect. indicated above article brings ideas robust statistics likelihood-based model selection bear problem introduces framework analyze errors resulting article organized follows. section develops likelihood-based semi-supervised model selection techniques ﬁrst considering case labeled data subsequently unlabeled case. section formulates semisupervised framework speech processing context selecting amongst competing pronunciation models optimize system performance. large-scale experiments well-known data sets section demonstrate approach achieves state-of-the-art performance context speech recognition spoken term detection phonemic similarity given reference even compared conventional supervised method forced alignments reference orthographic transcripts. section concludes article discussion results implication improving speech processing unlabeled development data. viewed machine learning perspective parametric statistical models directly instantiated large-scale speech processing systems. labeled data used model parameters manner described above; e.g. estimate state transition matrix hidden markov model. addition must also typically modest number parameters alter structure function model class consideration; instance automatic speech recognition marginal acoustic likelihood utterance typically depends model pronunciation given word— setting return section iii. training test conditions match exactly parameters ﬁtted simultaneously training stage using principled efﬁcient procedures expectation-maximization algorithm. practice however case small amount labeled training data well matched conditions prevail test—precluding even cross-validation option—or deployed system must adapted test conditions absence original training data. cases typical aside small amount development data purposes model selection follows. recall setting represents acoustic waveform data hence continuous random variable. true unknown data-generating model then takes form conditional probability density function interpreted ﬁxed function unknown label density thus evaluates acoustic likelihood given candidate label practice access given pairs training samples must proceed absence direct knowledge true model. speech processing system turn generate putative acoustic likelihoods thus natural conditional distribution given achieved vuong shows central limit theorem setting force number training samples grows large appropriately standardized version test statistic tlab asymptotically distributed unit normal. necessary normalization given sample standard deviation log-likelihood ratio evaluations times root number training samples; fails force value statistic diverges result test model selection ﬁxing signiﬁcance level yields corresponding critical value according standard normal distribution. normalized test statistic evaluates greater select model evaluates less −zα/ decide favor model otherwise conclude insufﬁcient evidence reject hypothesis model equivalence conclude models cannot distinguished basis given training data chosen signiﬁcance level. semi-supervised case unlabeled development data suppose competing models already trained ﬁtted maximum-likelihood estimation obtain wish leverage additional unlabeled data examples accomplish model selection task described section ii-a above. lacking corresponding class labels data thus seek employ automatically generated labels ﬁtted respectively maximum-likelihood systems replace conditional log-likelihood ratio generalized log-likelihood ratio course maximum-likelihood labeling given incurs error hence natural conditions replace tlab labeleddata model selection task section ii-a since corresponds labels taken output trained systems—i.e. estimated competing models p—this procedure inevitably suffer misclassiﬁcation errors respect estimated labels; systems exhibit reasonable performance however corresponding marginal error rate small. limit tends zero course recover precisely setting labeled data encountered section ii-a above. case small nonzero assuming true data-generating model either show below principled model selection procedure obtained adapting results labeled-data setting follows. individual likelihood ratio instead censored bounding range order limit inﬂuence misclassiﬁcation seek likelihood function closest true datagenerating model hopes yield best overall system performance. leads model selection problem training samples hand proxy choose amongst competing models build system predict given minimal misclassiﬁcation error. assume then several competing sets candidate models dependent distinct parameter sets whose quality wish evaluate respect true model natural approach evaluate kullback-leibler divergence best representative maximum-likelihood estimate parameter determined training data. thus seek assumption independent identically distributed pairs training examples form empirical estimate cross-entropy simply evaluating respective data log-likelihoods respect pair training samples forming corresponding arithmetic averages. assuming necessary technical conditions follows formulate multi-way hypothesis test amongst models later consider multi-way setting detail; however clarity exposition ﬁrst consider case competing models admits three possible outcomes natural test statistic labeled data setting given log-ratio likelihoods described above evaluated respect training data—possibly even training data used maximum-likelihood model parameter estimates careful reader note regime expectations deﬁned respect unknown distribution fact working potentially misspeciﬁed models properties maximumlikelihood estimation parameter sets setting; purposes sufﬁces note estimators still possess requisite technical properties. errors overall model selection procedure. limit recovers well-known nonparametric sign test simply tabulates every sign log-likelihood ratio rather actual value. formulate section ii-c below approach sacriﬁces degree statistical efﬁciency enhanced robustness turn enables inﬂuence errors {ˆyi} automatically generated labels limited. approach intuitively reasonable also provably optimal minimax sense describe. account misclassiﬁcation errors induced automatic labeling model consequence inexact labeling procedure replacing exact conditional densities mixtures densities contaminating distributions represent aggregate effects misclassiﬁcation. misclassiﬁcation error rate moreover serves mixture weight respective contaminating density—the so-called \u0001-contaminated case rather seeking determine contaminating distributions directly natural exists least favorable case form contamination that ﬁxed would serve maximize probability selecting incorrect model answer afﬁrmative amongst possible contaminating densities guaranteed least favorable pair exists whenever likelihood ratio monotone small enough ensure corresponding sets admissible \u0001-contaminated mixtures remain disjoint. case result obtained huber context robust statistics applied show that minimize maximal risk error model selection sufﬁces consider speciﬁc form contamination vice-versa. precise mixture form required huber’s result obtained partitioning range space manner depends follows noted huber limiting case occurs sufﬁciently large sets \u0001-contaminated mixture densities cease disjoint begin overlap; setting corresponds limit approach unity. approach unity log-likelihood ratio reﬂects term comparison larger yielding sign test model selection described above apply discussion model selection above best test case labeled development data accumulates log-likelihood ratios example given correct label case unlabeled development data corresponding minimax test accumulates signs ratios evaluated respect automatically generated label ˆyi. compare statistical efﬁcacy testing procedures compute asymptotic relative efﬁciency general assumptions regarding limiting distributions test statistics tlab tunlab obtained null hypothesis. asymptotic relative efﬁciency expresses limiting ratio sample sizes necessary respective tests achieve power level common alternative; test asymptotic efﬁciency relative another former requires twice many samples achieve performance. computation requires knowledge asymptotic distributions test statistics null hypothesis describe. recall comparing strictly non-nested models using labeled data limit theorem holds null; denote associated density function corresponding variance so-called efﬁcacy labeled-data test turn given suitable regularity conditions unlabeled-data sign test given tunlab appropriately standardized corresponding asymptotic relative efﬁciency turn given squared ratio test efﬁcacies evaluates quantity result implies tlab asymptotically normal sign test corresponding efﬁcient labeled-data test corresponding since considering so-called generalized gaussian iii. application selecting pronunciation models prototype application semi-supervised model selection approach derived section consider task evaluating candidate pronunciations spoken words large-scale speech processing tasks. select amongst competing pronunciations consider speech recognition systems differ pronunciation particular word show employ conventional test using transcribed audio data sign test using untranscribed audio data. selection pronunciation models crucial several including large-vocabulary speech processing applications continuous speech recognition spoken term detection speech synthesis requires knowledge pronunciation word interest. setting admissible pronunciations forms termed pronunciation lexicon comprises mappings tornados) orthographic form given word conventional means creating pronunciation lexicon employ trained linguist. however case examples requiring data hand-labeled experts process expensive inconsistent even times impossible individuals lack sufﬁciently broad expertise create pronunciations words interest turn several approaches automatically generating pronunciations forward inevitably model selection decision must made choose candidate pronunciations. however approaches relied upon labeled training data form spoken examples given word corresponding orthographic transcripts. addition initial creation lexicon pronunciation models also necessary maintain vocabulary speech processing systems time although pronunciation lexicon given system created large vocabulary possible deployment lexicon must extended time incorporate out-of-vocabulary words. terms words names come common usage rare foreign words simply words deemed signiﬁcantly important time system’s lexicon constructed. dynamically adjusting changing vocabularies thus requires generation pronunciations time thereby reinforcing need efﬁcient effective means automatically selecting amongst candidate pronunciations much effort date focused area automatic pronunciation modeling—i.e. grapheme-to-phoneme letter-to-sound rules. previous work including attempted simultaneously generate pronunciations select them. also work including augments possible pronunciations building larger fig. asymptotic relative efﬁciency tests semi-supervised versus supervised settings test statistic latter converges generalized gaussian distribution exponent horizontal line divides range cases sign test less efﬁcient conventional likelihood ratio test case normal vice-versa. thus consider expression asymptotic relative efﬁciency follows relation that function exponent asymptotic relative efﬁciency case generalized gaussian distribution exponent pγ/]. result illustrated figure conﬁrms that asymptotic distribution tlab approach laplacian density rather normal sign test would twice efﬁcient large-sample limit. demonstrated above case competing hypotheses yields theoretical performance guarantees; however practice often necessary select amongst models. optimality longer necessarily retained problem sufﬁcient practical interest generated large contemporary literature machine learning many approaches described e.g. several feature pairwise comparisons so-called method model assigned real-valued score relative others model highest overall score selected. possibly approaches include tournamentstyle following initial pairwise comparisons case latter approach suggested case sign test currently remains common practice within machine learning community despite multi-class procedures tailored speciﬁc learning methods such employ select amongst competing pronunciation models experiments below. semi-supervised pronunciation selection conventional method pronunciation selection described requires transcribed audio data whose production difﬁcult time-consuming laborious task. many applications external information potentially alleviate need transcriptions identifying recorded speech segments priori likely contain instances given word turn used select candidate pronunciations. examples include news items television shows provides rich source untranscribed speech could serve improve selection pronunciations. furthermore often case that transcript corresponding spoken examples word unavailable knowledge occurred particular audio archive. example know weather records broadcast news episode recently aired natural disasters giving degree conﬁdence instances words like tornados likely appear. know many times word occurs particular audio segment still entire broadcast help choose candidate pronunciations tornados examples given table absence labeled examples proposed recognition system outputs themselves—unconstrained forced alignment reference transcript—to select candidate pronunciations. speech recognition system every candidate data segment likely contain given word interest results corresponding acoustic likelihoods evaluated respect entire data leading selection candidate pronunciation yielding highest overall likelihood. recalling notation competing models speech samples linguistic rules combination these. focus previous work pronunciation variation common words note practice concerns dictate choices competing pronunciations scenario considered highlighting trade-offs word accuracy overall word error rate current setting however agnostic pronunciations generated; goal simply choose them. consider setting example utterances corresponding transcripts {yi} trained speech recognition systems identical except word models different pronunciations corresponds case strictly nonnested models outlined section subsequently describe compare supervised semi-supervised method select candidate pronunciations hence models settings candidate words analyzed time supervised selection pronunciations conventional mechanism choosing reference pronunciations word examples shown table acquire spoken utterances contain word along orthographic transcription utterances compute forced alignment acoustic waveform data transcripts ﬁrst using pronunciation using pronunciation assigned higher score alignment chosen. word ﬁxed number candidate pronunciations least reference pronunciation word although several cast notation section conventional supervised method pronunciation selection proceeds follows sequence words comprising reference tranutterance compute candidate must selected. sensitivity threshold depends distance models well number observations. experiments supervised pronunciation model selection threshold τlab zero candidate higher loglikelihood chosen. accomplish experiments large-vocabulary continuous speech recognition system built using speech recognition toolkit acoustic models trained hours data. around hours used test recognition word error rate spoken term detection experiments. language model lvcsr system trained words various text sources. lvcsr system’s word error rate standard broadcast news test lvcsr system also used lattice generation spoken term detection task. openfst-based spoken term detection system described used index lattices search words interest. additional details regarding experimental procedures data sets reader referred summarize experimental procedure alternative pronunciations generated different letter-to-sound systems selected words. also reference pronunciation words handcrafted pronunciation lexicon. assume purposes experiments reference pronunciation available task choosing alternative pronunciations word evaluated respect three different metrics discussed below. choice pronunciations made either supervised method section iii-b semi-supervised method section iii-b example words interest accumulated test statistics shown table word number true speech samples listed along accumulated loglikelihood ratios accordance corresponding present experimental validation semisupervised model selection approach presented preceding sections consisting selecting candidate pronunciations context three prototypical large-scale speech processing tasks. different words forced alignment recognition outputs produced every pair pronunciation candidates. recognition performed hour speech every word corresponding candidate making sure include somewhere data recognized speech utterances used forced-alignment setting yielding total hours recognized speech. quality selected pronunciations evaluated three different ways decision-error trade-off curves spoken term detection phone error rates relative hand-crafted pronunciation lexicon word error rates large-vocabulary continuous speech recognition. experiments conducted using well-known data sets state-of-the-art recognition indexing retrieval systems. order evaluate performance semi-supervised pronunciation selection suitability variety applications variety word types selected speech english-language broadcast news corpus identiﬁed single words interest. common english words removed consideration ensure words interest would often absent lexicons thus would require pronunciation selection words interest featured least acoustic instances. selected words interest veriﬁed absent recognition system’s vocabulary speech utterances containing words removed consideration acoustic model training stage. word interest candidate pronunciations considered generated different letter-to-sound systems furthermore chosen words property letter-tosound systems produced different pronunciations them. subsequent experiments semi-supervised pronunciation model selection threshold τunlab τunlab half loglikelihood ratios evaluated positive corresponding pronunciation model chosen threshold reﬂects priori belief equally likely candidates enforcing practical goal note supervised method requires acoustic samples word semisupervised method requires instances word recognized—correctly incorrectly—by lvcsr system. insufﬁciently many instances recognized choice alternative pronunciations cannot made. therefore depending accuracy system subset words resolved semi-supervised method. consequently employed three different levels language model pruning yield three levels system quality deﬁned terms word error rate standard data set. resultant error rates data report corresponding phone error rates table observe additional words indeed resolved system accuracy increases. comparison system setting oracle method anti-oracle also observed table that words resolved semi-supervised method chooses candidates smaller edit distance reference pronunciations hand-crafted lexicon. large-vocabulary continuous speech recognition ﬁnal experiment four methods described section iv-b selecting candidate pronunciations used recognize hours speech contained words interest. table shows comparison results terms standard word error rates. note alternative pronunciations smaller phoneme edit distance reference pronunciation necessarily results lower word error rate. overall however range one-half percent observed best worst candidates considered; note table supervised selection pronunciations based forced alignment yields slightly lower error rate instance phoneme edit distance. finally note semi-supervised method well supervised method. shown table words resolved supervised method semi-supervised method selected candidate them. details remaining words presented table candidate pronunciations listed second third columns better-performing candidate bold columns detail differing errors selecting candidate pronunciation bold terms substitution errors insertion/deletion errors. many words methods chose different pronunciations impact word error rate—and hence neither bold— candidate pronunciations similar enough neither results lower wer. fig. decision-error trade-off curves spoken term detection task generated hours speech data using chosen pronunciations queries phonetic/word-fragment index. note semi-sup oracle overlap nearly operating points. illustrate notion recall earlier examples featured table lists words hypothesized oracle pronunciations. case examples pronunciation selection method would select entries ax/’ z/’. spoken term detection experimental results showing result competing approaches selecting between candidate pronunciations purposes spoken term detection shown fig. lattices generated lvcsr system -hour test indexed used spoken term detection experiments openfstbased architecture described chosen pronunciations used queries spoken term detection system. results openfst-based indexing system computed using standard formulas national institute standards technology scoring functions/tools nist spoken term detection evaluation. note decision-error trade-off curves demonstrate semisup performs better supervised method detection nearly operating points. phone error rate experiment measures method—supervised semi-supervised—selects pronunciations smaller edit distance reference pronunciation. referring table example bolded pronunciations selected based observed speech data would errors phones respect closest reference pronunciation guerilla morphologically rich languages dictate consideration alternative pronunciations given orthographic form. demonstrate techniques remain appropriate comparisons performed case approach every unordered pair candidate pronunciations evaluated using criteria described antioracle semi-sup oracle methods. pairwise comparisons completed candidate chosen greatest number times selected; noted section ii-d variety alternative approaches also possible. results follow words interest additional third candidate pronunciation considered taken reference pronunciation lexicon. word error rate results three-way comparison shown table anti-oracle method remains two-way case every additional candidate deﬁnition candidates included anti-oracle set. similar fashion oracle contained entirely reference pronunciations. relative earlier two-way comparison reported table semi-sup sets contained pronunciations respectively. remaining results summarized table validate trends observed two-way comparison namely semi-sup perform comparably other well oracle. also expected combining third pronunciation high quality resulted lower error rates methods affected. showing censored likelihood ratios applied context large-scale speech processing developed article semi-supervised method selecting pronunciations using unlabeled data demonstrated performs comparably conventional supervised method. empirical evidence support conclusion exhibited across three distinct speech processing tasks depend upon pronunciation model selection decision-error trade-off curves spoken term detection phone error rates respect hand-crafted reference lexicon word error rates speech recognition. observed results consistent note limitations method however context pronunciation selection. first neither candidate ever recognized unconstrained recognition step required semi-supervised setting fail choose candidate pronunciation word. also approach requires seen textual examples word interest words like seems reasonable requirement given word comes fashion widely noticed. finally false alarms recognition process degrade performance— example word interest sounds like common word— experiments vary system quality indicated problem arise chosen words interest setting. supervised method system-level model selection optimizes empirical performance labeled development set. instead focused article leveraging unlabeled data choose amongst trained systems likelihood-ratio-based model selection. showed generalize conditional likelihood framework automatically generated labels proxy labels generated human experts. answered question well resultant censored likelihoods likely perform methodological applied perspective. ﬁnal note current research direction much interest speech community attempts utilize untranscribed utterances self-training acoustic model parameters main interest general problem non-nested model selection using unlabeled data appealing direction future work take ideas forward within acoustic modeling context. gratefully acknowledge assistance colleagues research attila speech recognition system well support assistance colleagues sub-team center language speech processing summer workshop johns hopkins university helped necessary systems plan experiments abhinav sethy bhuvana ramabhadran erica cooper sethy ulinski khudanpur riley jansche ghoshal saraclar cooper ramabhadran white derived pronunciations spoken term detection proc. ann. intl. sigir conf. soltau kingsbury mangu povey saon zweig conversational telephony system rich transcription proc. ieee intl. conf. acoust. speech signal process. parlak saraclar spoken term detection turkish broadcast news proc. ieee intl. conf. acoust. speech signal process. white sethy ramabhadran wolfe cooper saraclar baker unsupervised pronunciation validation proc. ieee intl. conf. acoust. speech signal process. murat saraclar james baker also would like acknowledge colleagues workshop providing pronunciation candidates namely michael riley martin jansche arnab ghoshal. riley byrne finke khudanpur ljolje mcdonough nock saraclar wooters zavaliagkos stochastic pronunciation modelling hand-labeled phonetic corpora speech commun. vol. lucassen mercer information theoretic approach automatic determination phonemic baseforms proc. ieee intl. conf. acoust. speech signal process. vinyals deng acero discriminative pronunciation learning using phonetic decoder minimum-classiﬁcation-error criterion proc. ieee intl. conf. acoust. speech signal process. ramabhadran bahl desouza padmanabhan acoustics-only based automatic phonetic baseform generation proc. ieee intl. conf. acoust. speech signal process. beaufays sankar williams weintraub learning name pronunciations automatic speech recognition systems proc. ieee intl. conf. tools artiﬁc. intell. teppermann silva kazemzadeh alwan narayanan pronunciation veriﬁcation children’s speech automatic literacy assessment proc. intl. conf. spoken lang. process. mamou ramabhadran siohan vocabulary independent spoken term detection proc. ann. intl. sigir conf. burget schwarz matejka hannemann rastrow white khudanpur hermansky cernocky combination strongly weakly constrained recognizers reliable detection oovs proc. ieee intl. conf. acoust. speech signal process. white zweig burget schwarz hermansky conﬁdence estimation detection language using phoneto-word transduction phone-level alignments proc. ieee intl. conf. acoust. speech signal process.", "year": 2009}