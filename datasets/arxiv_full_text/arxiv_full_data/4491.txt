{"title": "Master Algorithms for Active Experts Problems based on Increasing Loss  Values", "tag": ["cs.LG", "cs.AI", "I.2.6; G.3"], "abstract": "We specify an experts algorithm with the following characteristics: (a) it uses only feedback from the actions actually chosen (bandit setup), (b) it can be applied with countably infinite expert classes, and (c) it copes with losses that may grow in time appropriately slowly. We prove loss bounds against an adaptive adversary. From this, we obtain master algorithms for \"active experts problems\", which means that the master's actions may influence the behavior of the adversary. Our algorithm can significantly outperform standard experts algorithms on such problems. Finally, we combine it with a universal expert class. This results in a (computationally infeasible) universal master algorithm which performs - in a certain sense - almost as well as any computable strategy, for any online problem.", "text": "specify experts algorithm following characteristics uses feedback actions actually chosen applied countably inﬁnite expert classes copes losses grow time appropriately slowly. prove loss bounds adaptive adversary. this obtain master algorithms active experts problems means master’s actions inﬂuence behavior adversary. algorithm signiﬁcantly outperform standard experts algorithms problems. finally combine universal expert class. results universal master algorithm performs certain sense almost well computable strategy online problem. expert algorithms popular since ﬁfteen years appropriate online prediction repeated decision making repeated game playing based class experts. round expert gives recommendation. this derive master decision. that losses assigned expert environment also called adversary. goal perform almost well best expert hindsight long run. words minimize regret. know losses expert after round. analysis holds worst case environment fully adversarial tries maximize regret long run. later gave worst-case analysis bandit setup master algorithm knows loss decision round. generalized label-eﬃcient prediction partial monitoring recently introduced strategic experts algorithm performs well broader class environments. algorithm still asymptotically optimal properties worst-case adversary. additionally perform much better standard experts algorithm favorable situations actions inﬂuence behavior environment. refer active experts problems. example repeated prisoner’s dilemma opponent willing cooperate certain conditions however give asymptotic guarantees convergence rate. paper introduce diﬀerent algorithm active experts problems asymptotic guarantees addition convergence rate shown. algorithm analysis assembled standard toolkit basing basic idea following bandit experts algorithm allow losses increase time allows give control expert increasing period time steps. secondly generalize analysis case inﬁnitely many experts basing master algorithm stays computable since ﬁnite number experts involved. allowing inﬁnitely many experts also permits deﬁne universal expert class means programs universal turing machine. thus obtain universal master algorithm show perform certain sense almost well computable strategy online problem. thus introduce approach universal artiﬁcial intelligence sense dual aixi model based bayesian learning although master algorithm computable resulting universal agent since experts non-responsive. paper structured follows. section introduces problem setup notation algorithm. sections give analysis ﬁnite inﬁnite expert classes. implications active experts problems universal master algorithms given section section contains discussion conclusions. task online decision problem. make sequence decisions results certain loss incur. abbreviation master algorithm designed. concreteness imagine task playing game repeatedly. round i.e. time step access recommendations depend known move loss selected expert revealed. bandit setup opposed full information game know losses experts. goal perform nearly well best available strategy terms cumulative loss number time steps known advance. diﬀerence loss loss expert also termed regret. consider general case adaptive adversary assign losses depending past decisions. ﬁnite number experts strategies common give prior preferences them. formally deﬁne prior weights moreover deﬁne complexity expert −lnwi. arises full observation game regret bounded function best expert’s complexity. hand reasons trust strategies equally beginning non-uniform prior mandatory inﬁnitely many experts. algorithm follow explore builds mcmahan blum’s online geometric optimization algorithm. bandit version follow perturbed leader experts algorithm. approach online prediction playing repeated games pioneered full observation game gave elegant analysis distinct standard analysis exponential weighting schemes. particularly handy learning rate dynamic rather ﬁxed advance. dynamic learning rate necessary target time known advance. algorithm composed standard ingredients exploration follow leader. since playing bandit game need explore suﬃciently. otherwise could strategy think poor reality good. time step decide randomly explore not. choose expert according uniform distribution case non-uniform priors). after observing loss selected expert want give unbiased estimate true loss vector. achieve dividing observed loss probability exploring expert estimate unobserved losses experts zero. call resulting loss vector ˆℓt. instead introsary could fool case. duce perturbation expert follow advice strategy best perturbed score. order assign score expert note access estimated losses ˆℓt. estimated cumulative past loss expert complexity-penalized score deﬁned i.e. high scores bad. here learning rate. perturbed score given chosen independently exponentially distributed. ensures convenient analysis. algorithms follow explore follow perturbed leader fully speciﬁed figures note time randomness used assumed independent past randomness. note also algorithms occurring paper work estimated losses evaluate performance terms true estimated losses speciﬁed notation. e.g. true loss including time write lfpl ℓfpl section assume uniform prior next section.) assume sequence upper bounds true losses sequence exploration rates decreasing sequence learning rates. symbol used informally cumulative loss means bound quantity left quantity right plus additive terms. ﬁrst last expressions losses algorithm best expert respectively. intermediate quantities belong diﬀerent algorithms namely third called ifpl infeasible ifpl except access oracle providing current estimated loss vector assigns scores instead assume ifpl uses randomization arguments rely conditional expectations expectations also understood conditional. particular often need conditional expectations respect past ranx random variable. at−-measurable random variable meaning value determined ﬁxed past randomness at−. note particular estimated loss vectors random vectors depend randomnext lemma relating elfpl ˆlfpl technical intuitively clear. states expectation real loss suﬀered estimated loss. simply loss estimate unbiased. combination previous lemma shown following lemma relates losses ifpl. repeat proof since crucial step analysis careful upper loss bound denote upper bound instantaneous estimated losses. denotes distribution density e−kxk∞ perturbations i.e. idea action selected exponentially distributed perturbation high probability also selected ifpl. next lemma relates losses ifpl best action hindsight. oblivious adversary proof given additional step necessary adaptive adversary. omit proof here reader reconstruct proof lemma following considerations valid ﬁnitely inﬁnitely many experts arbitrary prior weights notational convenience write latter case. admitting inﬁnitely many experts diﬃculties arise since prior weights experts thus become arbitrarily small estimated losses obtained dividing weights would possibly arbitrarily large. therefore introduce expert denote active experts time experts entered game given estimated loss ˆbt. also solves computability problem since every time ﬁnite number experts involved computable algorithms fplτ speciﬁed figures proof. ﬁrst high probability bound follows summing excess terms lemmas observing =bt. second bound expectation take expectations lemmas lemma used. lemma statement expectation obtained follows fails w.p. choice achieve asymptotic optimality losses grow unboundedly. asymptotic optimality sometimes termed hannan-consistency particular limit equals zero. show upper bound. sampling perturbations independently equivalent expectation sampling once. assume sampled independently i.e. ifplτ played oblivious adversary remains valid. last step argue also holds adaptive adversary. true because future actions ifplτ depend past actions therefore adversary cannot gain deciding seen ifplτ decisions. note subtlety future actions would depend past actions.) corollary assume plays repeated game bounded instantaneous losses choose case arbitrary prior ⌈−⌉. experts suppressing dependence prior expert means performs broadly spoken asymptotically well best expert. asymptotic guarantees strategic experts algorithm derived results approve upon providing rate convergence. give corollaries e.g. terms ﬂexibility deﬁned also possible specify universal experts algorithm. expert derived program ﬁxed universal turing machine. program well-deﬁned e.g. representing programs binary strings lexicographically ordering expert consulted relevant input written input tape corresponding program. program halts appropriate number ﬁrst bits interpreted expert’s recommendation. e.g. decision binary ﬁrst suﬃces. expert assigned prior weight −length length length corresponding program assume program tape binary. construction parallels deﬁnition solomonoﬀ’s universal prior used deﬁne universal agent aixi quite diﬀerent note like universal prior aixi universal adversary’s goal maximize regret well known achieve interested different situations. example repeated playing prisoner’s dilemma tit-for-tat strategy strategies experts namely always cooperate always defect clear always cooperating better long-term reward. also clear standard expert advice bandit master algorithm discover this since compares losses step always lower defecting expert. therefore propose give control selected expert periods increasing length. precisely introduce time scale single games losses ˜ℓ˜t. master’s time scale coincide instead master gives control selected expert single games prisoner’s dilemma players decide independently cooperating defecting play small loss play large loss. however plays cooperating player gets large loss defecting player loss all. thus defecting dominant strategy. tit-for-tat player play ﬁrst move afterwards opponent’s respective preceding move. pucci farias megiddo. combine expert advice actions impact environment? sebastian thrun lawrence saul bernhard sch¨olkopf editors advances neural information processing systems press cambridge hutter poland. prediction expert advice following perturbed leader general weights. international conference algorithmic learning theory pages hutter. universal artiﬁcial intelligence sequential decisions based algorithmic probability. pages http//www.idsia.ch/∼ marcus/ai/uaibook.htm. kalai vempala. eﬃcient algorithms online decision. proc. annual conference learning theory lecture notes artiﬁcial intelligence pages berlin springer. littlestone warmuth. weighted majority algorithm. annual symposium foundations computer science pages research triangle park north carolina ieee. mcmahan blum. online geometric optimization bandit setting adaptive adversary. annual conference learning theory volume lecture notes computer science pages springer agent computable since cannot check program halts. however straightforward impose bound computation time instance increases rapidly used computable experts algorithm computationally feasible. universal master algorithm performs well respect computable strategy. corollary assume universal experts speciﬁed last paragraph. foeτ applied performs asymptotically least good computable expert rate convergence exponential complexity proportional large inﬁnite expert classes bounds proven irrelevant practice although asserting alsure optimality even convergence rate exponential complexity huge. imagine instance moderately complex task good strategy coded mere bits. weight constant distinguishable zero practical situations. thus seems bounds relevant small expert classes uniform prior. general shortcoming bandit experts algorithms uniform prior lower bound expected loss bounds practically relevant maybe algorithms leave interesting question unanswered. intuitively might seem algorithms proposed much tailored towards worst-case bounds fully adversarial setups. example exploration rate quite high. master algorithms less cautious might perform better many practical problems. finally would nice investigate diﬀerences proposed expert style approach deﬁnitions universal agents", "year": 2005}