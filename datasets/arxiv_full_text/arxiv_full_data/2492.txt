{"title": "Ensembles of Random Sphere Cover Classifiers", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "We propose and evaluate alternative ensemble schemes for a new instance based learning classifier, the Randomised Sphere Cover (RSC) classifier. RSC fuses instances into spheres, then bases classification on distance to spheres rather than distance to instances. The randomised nature of RSC makes it ideal for use in ensembles. We propose two ensemble methods tailored to the RSC classifier; $\\alpha \\beta$RSE, an ensemble based on instance resampling and $\\alpha$RSSE, a subspace ensemble. We compare $\\alpha \\beta$RSE and $\\alpha$RSSE to tree based ensembles on a set of UCI datasets and demonstrates that RSC ensembles perform significantly better than some of these ensembles, and not significantly worse than the others. We demonstrate via a case study on six gene expression data sets that $\\alpha$RSSE can outperform other subspace ensemble methods on high dimensional data when used in conjunction with an attribute filter. Finally, we perform a set of Bias/Variance decomposition experiments to analyse the source of improvement in comparison to a base classifier.", "text": "abstract—we propose evaluate alternative ensemble schemes instance based learning classiﬁer randomised sphere cover classiﬁer. fuses instances spheres bases classiﬁcation distance spheres rather distance instances. randomised nature makes ideal ensembles. propose ensemble methods tailored classiﬁer; αβrse ensemble based instance resampling αrsse subspace ensemble. compare αβrse αrsse tree based ensembles datasets demonstrates ensembles perform signiﬁcantly better ensembles signiﬁcantly worse others. demonstrate case study gene expression data sets αrsse outperform subspace ensemble methods high dimensional data used conjunction attribute ﬁlter. finally perform bias/variance decomposition experiments analyse source improvement comparison base classiﬁer. propose evaluate alternative ensemble schemes simple instance based learning classiﬁer randomised sphere cover classiﬁer ﬁrst introduced creates spheres around subset instances training data bases classiﬁcation distance spheres rather distance instances. nearest neighbour based classiﬁers remain popular wide range ﬁelds image processing. strength lies fact robust changes training data. however feature classiﬁers means less observable beneﬁt using conjunction resampling ensemble schemes bagging aims overcome problem using randomised heuristic select subset instances represent spheres used classiﬁcation. seen form data reduction hence scales well large data sets. data reduction algorithms search training data subset cases and/or attributes classify instances achieve maximum compression minimum reduction accuracy. described compression scheme method compression scheme proposed explain generalisation performance sparse algorithms. general algorithms called sparse keep subset training part learning process. large number algorithms fall category support vector machines perceptron algorithm recently compression scheme rejuvenated explore similar algorithm covering machine proposed shaw-taylor younsi examined relationships accuracy cardinality sphere cover classiﬁer using existing probabilistic bound based compression scheme. although clear sphere cover accuracy synonymous covering compression scheme shown degradation accuracy possible heavily pruning spheres. suggests sphere cover classiﬁer indeed strong candidate exploring accuracy/diversity dilemma found ensemble design process creates spheres controlled parameters minimum number cases sphere must contain order retained part classiﬁer; number misclassiﬁed instances sphere contain. investigate parameters utilised diversify ensemble. propose ensemble methods tailored classiﬁer; ensemble based resampling αrsse subspace ensemble. demonstrate resulting ensemble classiﬁers least comparable often better than state ensemble techniques. perform case study high dimensional gene expression data sets demonstrate αrsse works well attribute ﬁlters outperforms subspace ensemble methods data sets. finally perform bias/variance decomposition experiments analyse source improvement comparison base classiﬁer. structure rest paper follows section provide background motivation classiﬁer overview relevant ensemble literature brief summary domingos decomposition technique section formally describe classiﬁer section deﬁne classiﬁer constructs decision rule based training examples represents vector observations explanatory variables associated case indicates class example belongs. call range possible values explanatory variables range discrete response variable cr}. assume dissimilarity measure deﬁned function classiﬁer function attribute space response variable space. sphere covering mechanism stems class covering approach classiﬁcation ﬁrst introduced sphere associated particular class deﬁned centre radius practice also include sphere deﬁnition instances within it’s boundary. hence sphere deﬁned -tuple union spheres called cover. cover contains examples called proper consisting spheres contain examples class said pure. class cover problem involves ﬁnding pure proper cover minimum number spheres possible pure proper covers. solution proposed involves constructing class cover catch digraph directed graph based proximity training cases. however ﬁnding optimal covering cccd np-hard hence proposed number greedy algorithms approximately optimal covering. however algorithms still slow pure covers. constraint pure proper covers tend lead classiﬁer overﬁts training data. algorithm relaxes requirement class purity proposed algorithm introduces parameters alleviate constraint requiring pure proper cover. parameter relaxes proper requirement allowing spheres contain least cases retained classiﬁer. parameter reduces purity constraint allowing sphere contain cases wrong class. authors admit resulting algorithms infeasible large data hence limited experimental evaluation based classiﬁers. furthermore resulting classiﬁers sensitive parameters. particular constant spheres crude mechanism relaxing purity constraint. section describe ensemble base classiﬁer derived algorithm proposed randomised retains single parameter ensemble classiﬁers base classiﬁers whose individual decisions combined process fusion classify examples concept ensemble design requirement inject diversity ensemble broadly speaking diversity achieved ensemble either adaboost involves iteratively re-weighting sampling distribution training data based training accuracy base classiﬁers iteration. weights either embedded classiﬁer algorithm used weighting cost function classiﬁer selection inclusion. lection unpruned trees. test node optimal split derived searching random subset size candidate attributes selected without replacement candidate attributes. random forest random combines attribute sampling bootstrap case sampling. rotation forests involve partitioning attribute space transforming principal components space. classiﬁer given entire data trains different component space. section brieﬂy describe decomposition using domingos framework framework applicable loss function simplicity sake restrict class classiﬁcation problem loss function. label class values generalisation error classiﬁer deﬁned expected error given loss function entire attribute space. loss function measures close predicted value actual value observation response variable generally stochastic class problem expected loss deﬁned optimal prediction prediction mimimizes expected loss. optimal bayes classiﬁer minimizes expected loss possible values attribute space i.e. y∗∀x expected loss attribute space bayes classiﬁer bias caused systemic errors classiﬁcation resulting algorithm capturing underlying complexity true decision boundary variance describes mean variation within predictions main prediction given instance i.e. result variability classiﬁcation function caused ﬁnite training sample size hence inevitable variation across training samples noise unavoidable component loss incurred independently learning algorithm. noise term bias variance averaged examples case domingos calls average bias average average noise ex). expected loss examples expected value expected loss examples decomposed practice classiﬁers constructed ﬁnite data expected loss given instance vary depending data classiﬁer given. i=}. predictions element prediction classiﬁer deﬁned training data given explanatory deconstructed biased variance unbiased variance average variance within classiﬁer estimates main prediction correct variance main prediction incorrect. variance difference unbiased biased variance hence unbiased principle beneﬁt performing bias-variance decomposition ensemble algorithm address question whether observed reduction expected loss reduction bias reduction unbiased variance increase biased variance usually combination factors. without unlimited data statistics generally estimated resampling. section describe experimental design perform decomposition assess ensemble algorithms propose section conjunction base classiﬁer described section reason designing αrsc algorithm develop instance based classiﬁer ensembles. hence design criteria randomised fast comprehensible αrsc algorithm single integer parameter speciﬁes minimum size sphere. informally αrsc works follows. formal algorithmic description given algorithm experiments euclidean distance metric although algorithm work distance function. attributes normalised onto range parameter allows smooth decision boundary shown provide better generalisation mitigating noise outliers figure provides example smoothing effect removing small spheres decision boundary. case covered rule generally outlier boundary class distribution. therefore preferable spheres over-covering areas cases occur. areas either close decision boundary speciﬁcally high overlap classes exist areas noisy cases within dense areas examples different target class. αrsc method compressing sphere covering smoothing boundary setting ﬁrst proposed shown provides robust simple classiﬁer competitive commonly used classiﬁers paper focus best base classiﬁer ensemble. basic design criteria αrsc randomise cover mechanism could create diversity ensemble. hence ﬁrst ensemble algorithm αrse simply majority voting ensemble αrsc classiﬁers. ensembles denote number classiﬁers ensemble members ensemble. classiﬁer built using algorithm using entire training data. basic question experimentally assess whether original motivation classiﬁers derived class cover catch digraph described section classiﬁers parameters parameter used improve generalisation. parameter meant ﬁlter outliers. cccd parameters chosen advance. cross validation. however setting problematic; global value arbitrary local value sphere impractical. propose automatic method implicitly setting iteratively. deﬁne border case sphere closest data negative class given dataset. border cases particular instance halts growth sphere hence crucial construction αrsc classiﬁer. design principle diversiﬁcation ensemble iteratively remove border cases process ensemble construction. informally algorithm proceeds follows initialise current training whole formal description given algorithm cases classiﬁed majority vote classiﬁers. principle idea re-weight training data removing border cases thus facilitating spheres pure original data continue focus harder cases inserting possible duplicates border uncovered misclassiﬁed cases thus implicitly re-weighting training data. data previously removed training data replaced misclassiﬁed current iteration. data driven iterative approach strong analogies constructive algorithms boosting. tive approach diversiﬁcation present base classiﬁer different attributes train. random subspace sphere cover ensemble builds base classiﬁers using random subsets attributes sampling without replacement original full attribute set. base classiﬁer number attributes attributes used classiﬁer also stored attributes used classify test example. majority vote employed ﬁnal hypothesis. accuracy comparisons base classiﬁer αrsc competitive classiﬁer right achieving accuracy results comparable naive bayes naive bayes tree k-nearest neighbour non-nested generalised hyper rectangle classiﬁers wish compare performance αrsc based ensembles equivalent tree based ensemble techniques. experimental aims assess relative performance classiﬁers adopt procedure described based stage rank test. ﬁrst test freidman test non-parameteric equivalent anova tests null hypothesis average rank classiﬁers data sets alternative least classiﬁer’s mean rank different. friedman test results rejection null hypothesis demˇsar recommends post-hoc pairwise nemenyi test discover differences lie. performance classiﬁers signiﬁcantly different corresponding average ranks differ least critical difference number classiﬁers number problems based studentised range statistic. results post-hoc nemenyi test shown critical difference diagrams graphs show mean rank order algorithm linear scale bars indicating cliques within signiﬁcant difference rank alternatively classiﬁers considered control powerful test difference mean rank classiﬁer based bonferonni adjustment. null hypothesis difference mean rank classiﬁer statistic dataset abalone waveform satimage ringnorm twonorm image german wdbc yeast diabetes ionosphere sonar heart cancer winsconsin ecoli breast cancer prostate lung cancer ovarian colon tumor central nervous evaluate performance ensembles used sixteen datasets data repository benchmark gene expression datasets datasets summarised table selected vary numbers training examples classes attributes thus provide diverse testbed. addition continuous attributes allows distance measure experiments euclidean distance. features normalised onto scale. ﬁrst sixteen data used classiﬁcation experiments sections gene expression data sets used experiments presented section evaluate subspace based ensembles perform conjunction feature selection ﬁlter problem high dimensional feature space. basic sanity check start showing ensemble outperforms base classiﬁer comparing αβrse base classiﬁers average αrsc classiﬁers. figure shows graphs classiﬁcation accuracy four different datasets. ensemble accuracies better averaged classiﬁers pattern consistent across data sets. addition notice curves follow similar evolution relation values returned best classiﬁcation accuracy similar single classiﬁer. motivation model selection method adopt section tables show classiﬁcation accuracy αrse αβrse adaboost bagging multiboost trained base classiﬁers respectively. adaboost bagging multiboost used default settings decision tree ensemble parameters trained full training split. αrse αβrse quick form model selection using optimal training cross validation values single classiﬁer. form quick off-line model selection possible fact controlled single parameter little impact overall time taken build ensemble classiﬁer. described section parameter αβrse implicitly sampling scheme. firstly although αβrse highest rank cannot reject null hypothesis signiﬁcant difference mean ranks classiﬁers. performance simple majority vote ensemble αrse comparable bagging decision secondly αβrse outperforms αrse data sets bases classiﬁers base classiﬁers. performing single comparison classiﬁers difference would signiﬁcant. whilst multiple classiﬁer comparisons mean cannot make claim results indicate allowing misclassiﬁcation guiding sphere creation process directed resampling improve performance simple ensemble best utilise base classiﬁer. thirdly αβrse highest average rank algorithms infer performs least comparably adaboost multiboost performs better bagging. experiments demonstrate re-weighting based ensemble αβrse least comparable widely used tree based sampling and/or re-weighting ensembles. classiﬁcation accuracy standard deviation αrsse rotation forest random subspace random forest random committee randc) using average results different runs independent train/test splits αβrse αrsse parameters cross validation third training set. optimal value estimated ﬁrst best value found ensembles trained entire training default parameters. figure shows critical difference diagram subspace methods base classiﬁers. signiﬁcant difference average rank classiﬁers difference described clear cliques random subspace random committee random forest signiﬁcantly outperformed clique αrsse rotation forest. signiﬁcant. note difference performance rotation forest αrsse reduces increase number base classiﬁers. table shows classiﬁcation accuracy αrsse various sizes ensemble varying base classiﬁers. general ensembles perform better size ensemble large. however many ensemble methods increasing ensemble size dramatically results training hence lower testing accuracy. table demonstrates performance αrsse actually improves base classiﬁers indicating αrsse tendency data sets large ensemble sizes. figure shows combined critical difference diagram ensembles. increase number ensembles means much larger critical difference required detect signiﬁcant difference. however similar pattern ranking apparent. free lunch theorem convinces single dominant algorithm classiﬁcation problems. instance based approaches still popular range problem domains particularly research areas relating image processing databases. αβrse αrsse offer instance based approaches classiﬁcation problems highly competitive best tree based subspace non-subspace ensemble techniques. following section propose type problem domain think αrsse outperforms tree based ensembles. gene expression proﬁling helps identify genes responsible cancerous tissue. gene expression data generally characterised large number attributes relatively cases. instance based learners k-nn often perform poorly high dimensional attribute space. demonstrate subspace ensemble αrsse overcome inherent problem fact outperform ensemble techniques. broadly speaking three types approach problems large number attributes employ ﬁlter uses scoring method rank attributes independently classiﬁer; wrapper score subsets attributes using classiﬁer produce model; embed attribute selection part algorithm build classiﬁer focus three simple commonly used ﬁlter measures information gain relief used select ﬁxed number attributes ranking well split training data terms response variable. compare αrsse adaboost bagging random comittee multiboost random subspaces random forest rotation forest. methodology ﬁlter best ranked attributes three ranking measures. model selection αrsse conducted described section ensembles classiﬁers. adaboost bagging base decision tree classiﬁers ensembles default parameters. tables show relative performance eight ensemble classiﬁers best attribute ﬁlter setting ﬁlter techniques. note αrsse ranked highest overall using information gain ranked third relief. infer used conjunction ﬁltering αrsse overcome inherent problem instance based learners high dimensional attribute spaces produce results better state tree based ensembles classiﬁers. purpose bias/variance analysis ensembles αβrse αrsse identify whether reduction generalisation error comparison base classiﬁer reduction bias unbiased variance increase biased variance. followed similar experimental framework found standard experimental design decomposition estimate bias variance using small training sets large test sets. used bootstrapping sample eight datasets. data divided training test test entire set. separate training bootstrap samples size taken uniformly sampling replacement training set. compute main prediction bias unbiased biased variance netvariance test sets. figure showing bias variance relation four datasets. observe strong relationship averaged error bias small increases variance contributes larger component error. increasing seems higher inﬂuence unbiased variance reduction biased variance. compare αrsc αβrse αrsse perform bias/variance experiment conclude results αβrse cases reduces variance comparison single classiﬁer decrease unbiased variance. however straight forward relation bias. might bias reduction depends geometrical complexity sample chosen values pruning parameter interaction case ﬁnding method systematically reduces bias keeping unbiased variance reduce ensemble average error. experiments reinforce preconception effectiveness ensembles αβrse introduces diversity ensemble allowing misclassiﬁed instances within spheres. major effect reduce variance resulting classiﬁer. hand subspace ensemble reduces inherent bias commonly observed instance based classiﬁers used conjunction euclidean distance metric redundant attributes result overﬁtting. conclusion described instance based classiﬁer αrsc several interesting properties used successfully ensemble design. described three different ensemble methods could used demonstrated resulting ensembles competitive best tree based ensemble techniques wide range standard datasets. further investigated reasons improvement performance ensembles relation base classiﬁer using bia/variance decomposition. ensemble based resampling accuracy increased primarily reduction variance. hence conclude diversity introduced proposed technique mostly beneﬁcial resulting ensemble classiﬁer robust. also demonstrated bia/variance decomposition subspace ensemble αrsse improves performance primarily decrease bias. obvious next step would embed resampling technique within random subspace ensemble. however found employing mechanism subspace make signiﬁcant difference αrsse ensemble. implies attribute selection important stage ensembling αrsc model selection setting lead investigating embedding attribute selection ensemble promising preliminary results. believe αrsc useful edition family instance based learners since easy understand quick train test effectively employed ensembles achieve classiﬁcation accuracy comparable popular comparing bias/variance αrscαβrse αrsse. stand unbiased biased variance. stands percentage difference algorithms. arrow means increase arrow means dataset waveform αrsc αβrse αrsse diff diff diabetes αrsc αβrse αrsse diff diff heart αrsc αβrse αrsse diff diff wdbc αrsc αβrse αrsse diff diff image αrsc αβrse αrsse diff diff twonorm αrsc αβrse αrsse diff diff ringnorm αrsc αβrse αrsse diff diff cannon mark ettinger hush scovel machine learning data dependent hypothesis classes journal machine learning research vol. demˇsar statistical comparisons classiﬁers multiple data sets. journal machine learning research vol. t.g. dietterich experimental comparison three methods constructing ensembles decision trees bagging boosting randomization machine learning vol. domingos uniﬁed bias-variance decomposition zero-one squared loss proceedings seventeenth national conference artiﬁcial intelligence twelfth conference innovative applications artiﬁcial intelligence james variance bias general loss functions machine learning vol. s.w. b.j. oommen brief taxonomy ranking creative prototype reduction schemes pattern anal. appl. vol. l.i. kuncheva elusive diversity classiﬁer ensembles lecture notes computer science l.i. kuncheva diversity multiple classiﬁer systems information fusion vol. motoda issues instance selection data mining knowledge discovery vol. j.j. rodriguez l.i. kuncheva c.j. alonso rotation forest classiﬁer ensemble method ieee transactions pattern analysis machine intelligence vol. valentini t.g. dietterich bias-variance analysis support vector machines development svm-based ensemble methods journal machine learning research vol.", "year": 2014}