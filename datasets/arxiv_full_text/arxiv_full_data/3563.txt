{"title": "Visual Explanation by Interpretation: Improving Visual Feedback  Capabilities of Deep Neural Networks", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Learning-based representations have become the defacto means to address computer vision tasks. Despite their massive adoption, the amount of work aiming at understanding the internal representations learned by these models is rather limited. Existing methods aimed at model interpretation either require exhaustive manual inspection of visualizations, or link internal network activations with external \"possibly useful\" annotated concepts. We propose an intermediate scheme in which, given a pretrained model, we automatically identify internal features relevant for the set of classes considered by the model, without requiring additional annotations. We interpret the model through average visualizations of these features. Then, at test time, we explain the network prediction by accompanying the predicted class label with supporting heatmap visualizations derived from the identified relevant features. In addition, we propose a method to address the artifacts introduced by strided operations in deconvnet-based visualizations. Our evaluation on the MNIST, ILSVRC 12 and Fashion 144k datasets quantitatively shows that the proposed method is able to identify relevant internal features for the classes of interest while improving the quality of the produced visualizations.", "text": "figure visual explanations generated method. predicted class labels enriched heatmaps indicating pixel locations associated features contributed prediction. note features come object well context. heatmap indicate number layer features come from. layer type colorcoded capabilities -based methods. goal bridge methods aiming model interpretation i.e. understanding given pre-trained model actually learned methods aiming model explanation i.e. justifying decisions made model. model interpretation dnns commonly achieved ways either manually inspecting heatmap visualizations every single ﬁlter every layer network recently exhaustively matching internal activations produced given model w.r.t. dataset pixel-wise annotations possibly relevant concepts paths provided useful insights internal representations learned dnns however weaknesses. ﬁrst case manual inspection ﬁlter responses introduces subjective bias recently evidenced addition inspection every ﬁlter every layer becomes cognitiveexpensive practice deeper models lends noise. second case stated interprelearning-based representations become defacto means address computer vision tasks. despite massive adoption amount work aiming understanding internal representations learned models rather limited. existing methods aimed model interpretation either require exhaustive manual inspection visualizations link internal network activations external possibly useful annotated concepts. propose intermediate scheme which given pretrained model automatically identify internal features relevant classes considered model without requiring additional annotations. interpret model average visualizations features. then test time explain network prediction accompanying predicted class label supporting heatmap visualizations derived identiﬁed relevant features. addition propose method address artifacts introduced strided operations deconvnet-based visualizations. evaluation mnist ilsvrc fashion datasets quantitatively shows proposed method able identify relevant internal features classes interest improving quality produced visualizations. recent years methods learning-based representations based deep neural networks achieved impressive results several computer vision tasks e.g. image classiﬁcation object detection image generation etc. this combined general trend computer vision community developing methods focus high quantitative performance motivated massive adoption methods based dnns produce impressive quantitatively accurate predictions despite black-box characteristics. work visually-descriptive predictions propose means improve quality visual feedback tation capabilities network limited concepts annotation available. moreover cost adding annotations concepts quite high pixel-wise nature. third weakness cases share inherited generate spatial ﬁlter-wise responses i.e. either deconvolutionbased heatmaps up-scaling activation maps given layer/ﬁlter image space hand deconvolution-based methods able produce heatmaps high level detail ﬁlter network. however seen fig. suffer artifacts introduced strided operations backpropagation process. hand up-scaled activation maps signiﬁcantly lose details displaying response ﬁlters large receptive ﬁeld deeper layers. moreover weakness computable convolutional layers. order alleviate issues start hypothesis empirically proven previous work internal ﬁlters network encode features important task network addresses. based assumption propose method given trained model automatically identify relevant internal ﬁlters whose encoded features serve indicator class interest predicted. ﬁlters originate type internal layer network i.e. convolutional fully connected etc. formulated u-lasso optimization problem sparse ﬁlter-wise responses linearly combined order predict class interest. test time given test image identiﬁed relevant ﬁlters class prediction accompany predicted class label heatmap visualizations top-responding relevant ﬁlters predicted class fig. addition improving resampling operations within deconvnet-based methods able address artifacts introduced back-propagation process. code models used generate visual explanations released upon publication manuscript. overall proposed method removes requirement additional expensive pixel-wise annotation relying annotation used train initial model. moreover using variant deconvolution-based method method able consider spatial response ﬁlter layer still providing visually pleasant feedback. allows method reach level explanation interpretation. practical point view algorithms capable communicating part output train thought taken reach particular prediction likely trusted adopted users systems operate black-box fashion. moreover ﬁndings techniques developed direction assist overhaul required figure visualization comparison. note heatmaps attenuate grid-like artifacts introduced deconvnet-based methods lower layers. likewise method able produce detailed visual feedback upsampled activation maps. current machine learning technology order meet recently approved legislation i.e. general data protection regulation legislation requires automated decision-making processes provide logic involved i.e. explanation followed reach particular decision. main contributions work automatic non-exhaustive method based relevant feature selection identify network-encoded features important prediction given class. alleviates requirement manual inspection additional expensive pixel-wise annotations required existing methods. proposed method able provide visual feedback higher-level detail up-scaled activation maps improved quality recent deconvolution-based methods guided backpropagation paper organized follows section position work respect existing work. section presents pipeline inner-workings proposed method. section conduct series experiments evaluating different aspects proposed method performance application case discussing observations ﬁndings made throughout evaluation. finally section conclude paper. work lies intersection model interpretation explanation dnns groups work constitute axes along position work. interpretation. input modiﬁcation methods earlier attempts towards interpretation recent time. methods network black-box. designed visualize properties function black-box represents systematically covering input image measuring difference activations. assumption occlusion important parts input lead signiﬁcant drop performance. procedure applied test time identify regions image important classiﬁcation. however precision explanation depend region size inversely increase computation cost. apply assumption made group work evaluation order verify relevance internal network features selected method. recent group works focuses linking internal activations semantic concepts. proposed feature selection method neuron activations trained object categories linearly combined predict object attribute classes. following similar idea proposed exhaustively match internal activations every ﬁlter convolutional layers dataset pixel-wise annotated concepts. methods provide important insights semantic concepts encoded ﬁlters network limited concepts annotation available. similar discover relevant internal ﬁlters feature selection method. different link internal network activations directly annotations used train initial model. effectively removes expensive requirement additional annotations. third line works aims discovering frequent midlevel visual patterns occurring image collections. constraints enforced mining mid-level elements empowers high semantic coverage making effective training classiﬁers address computer vision problems means summarization. adopt idea using visualizations mid-level elements means reveal relevant features encoded internally precisely average visualizations used works order interpret visually network actually learned. explanation. sake brevity ignore methods generate explanations bounding boxes text focus methods capable generating visualizations pixel-level precision. works belonging group activity given layer/ﬁlter back input image space. proposed multi-layered deconvolutional network uses activations given layer reverses path excitatory stimuli reveal visual patterns input image responsible observed activations. parallel proposed variation deconvnet information lower layers input image used estimate image regions responsible activations seen layers. similar direction aims decomposing classiﬁcation decision pixel-wise contribution enforcing layer-wise conservation principle propagated quantity preserved neurons adjacent layers. later extended introducing guided back-propagation technique removes effect units negative activations during forward pass negative contributions backwards pass. resulted improvements sharpness clarity generated visualizations. despite terminology used main difference lies relu operation handled during backwards pass order introduce desired effect. proposes ignore fully connected layers uses global average pooling operation last convolutional layer. operation weighted spatial locations activations ﬁlters last convolutional layer results class activation map. finally heatmap generated upsampling class activation size input image. here take deconvnet-based methods starting point given maturity ability produce visual feedback pixel-level precision. addition replace internal operations backward pass goal reducing visual artifacts introduced strided operations maintaining network structure. proposed method consists parts. training time relevant layer/ﬁlter pairs identiﬁed every class interest thus producing relevance weight associated class every ﬁlter-wise response computed internally network. test time image pushed network producing class prediction ˆj=f then taking account internal reponses relevance weights predicted class generate visualizations indicating image regions contributed prediction strengths deep models ability learn abstract concepts simpler ones. example pushed model conclusion concerning speciﬁc task reached function results intermediate operations different levels model. intermediate results hint semantic concepts model taking account making decision. observation make assumption internal ﬁlters network encode features important task network addresses. follow procedure similar aiming reconstruct class linear combination wj∈rm internal activations compute internal ﬁlter-wise response vector following procedure presented above. compute represents weighted response element-wise product vectors. features layer/ﬁlter pairs strongest contribution i.e. prediction selected maximum finally feed information response deconvnet-based method guided backpropagation visualize important features deﬁned layer/ﬁlter pairs following visualization method given ﬁlter layer input image ﬁrst push forward input image network storing activations ﬁlter layer reaching layer then backpropagate activations ﬁlter layer inverse operations reaching back input image space. result part output heatmaps associated relevant features deﬁned indicating relative inﬂuence pixels contributed prediction. fig. example visual feedback provided method. please refer further details regarding deconvnet-based methods. improving visual feedback quality deep neural networks addressing computer vision tasks commonly push input visual data sequence operations. common trend sequential processing input data internally resampled reaching desired prediction space. mentioned sec. methods aiming interpretation/explanation start internal point network backwards reaching input space producing heatmap. however resampling process heatmaps generated backwards process tend display grid-like artifacts. precisely grid effect caused internal resampling introduced network operations stride larger alleviate effect backwards pass stride compensate change modifying input accordingly. result backwards process executed maintaining network structure. formally given network operation block deﬁned convolution mask size stride padding relationship size input output characterized following equation method starts input encodes contributions input image carried higher layer deconvnet backward pass. order enforce cleaner resampling backward pass figure example visual feedback provided method. input image accompany predicted class label heatmaps indicating pixel locations associated relevant features contributed prediction. note relevant features come object well context. heatmap indicate number layer features come from. layer type colorcoded i.e. convoluvional fully connected initial step extract image-wise response computing norm channel within layer produce -dimensional descriptor concatenating responses different channels. descriptor l-normalized order compensate difference length among different layers. finally produced concatenating layer-speciﬁc descriptors. consider last layers whose output directly related classes interest. following procedure above construct matrix x∈rm×n passing training images network collecting internal responses such image dataset represented vector xi∈rm deﬁned ﬁlter-wise responses different layers. furthermore possible classes image belongs organized binary vector li∈{ total number classes interest. putting annotations images together produces binary label matrix l∈rc×n. terms place resort solving equation parameter allows controlling sparsity. matrix form µ-lasso problem. problem efﬁciently solved using spectral gradient projection method solving µ-lasso problem matrix w∈rm×c. impose sparsity enforcing constraints norm i.e. ||wj||≤µ result non-zero element represents pair network layer ﬁlter index relevance. generating visual feedback training time identiﬁed features relevance weights classes interest. test time generate feedback visualizations taking account effect relevant features content tested images. size input operation block feature produced forward pass stride equal i.e. d=b|s=. according resampled =b|s==a resampling nearest-neighbor interpolation algorithm given proven fast computation time makes optimal real-time processing. moreover since setting changes scale relatively minor known weaknesses avoided. introducing step network perform backwards pass stride grid effect disappear. fig. examples improvements introduced method. conduct three sets experiments. ﬁrst experiment verify importance identiﬁed relevant features task addressed network. second experiment qualitatively evaluate improvements visual quality provided method. finally third experiment verify potential proposed method application case. evaluation protocol. evaluate proposed method image recognition task. towards goal conduct experiments standard image recognition datasets i.e. mnist imagenet additionally conduct experiments subset images imagenet mnist contains classes hand-written digits composed images total. these used training/validation rest images testing. imagenet dataset composed classes. following standard practice measure performance validation set. class contains validation images. imagenet -cats subset consists different classes implementation details. experiments pre-trained models provided part matconvnet framework mnist imagenet datasets. mnist employ network composed layers total convolutional fully connected. last softmax layer. full imagenet employ model composed layers convolutional followed fully connected. last softmax layer. finally case imagenet -cats subset ﬁnetune model trained full imagenet set. experiment verify importance relevant features identiﬁed method training time sec. given identiﬁed features evaluate inﬂuence network measuring changes classiﬁcation performance. iteratively remove speciﬁc features network setting corresponding layer/ﬁlter zero. perform removal decreasing order relevance. expected behavior features higher relevance produce stronger drop performance ablated. fig. show changes classiﬁcation performance tested datasets. report performance three sets features selected considering whole internal network architecute onlyconv selected considering convolutional layers network random selection features network. note onlyconv method makes assumption relevant features present convolutional layers. similar assumption made state-of-the-art methods performing feature selection sparsity parameter mnist imagenet-cats complete imagenet. produces subsets relevant features all|onlyconv methods respective datasets. differences number selected features attributed possibly redundant missing predictive information initial pools ﬁlter requick inspection fig. shows indeed classiﬁcation performance drops remove identiﬁed features onlyconv. moreover noticeable random removal features minimal effects classiﬁcation accuracy. demonstrates relevance identiﬁed features classes interest. addition visible method considers complete internal structure i.e. suffers stronger drop performance compared onlyconv considers features produced convolutional layers. suggests indeed important information encoded fully connected layers convolutional layers good source features focussing reveal full story. but... make sense? order qualitative insight type information features encode compute average visualization considering image patches features high response. towards goal given identiﬁed relevant features every class select images higher responses. then take input image location maximum response given ﬁlter crop considering receptive corresponding layer/ﬁlter figure generated visual explanations. accompany predicted class label heatmaps indicating pixel locations associated features contributed prediction. note features come object well context. mnist examples features support existence gaps avoid confusion another class. heatmap indicate number layer features come from. layer type color-coded i.e. convolutional fully connected notice imagenet-cats identiﬁed features cover descriptive characteristics considered classes. example dark head siamese nose/mouth cougar ﬂuffy-white body shape persian cat. likewise effectively identiﬁes descriptive patterns jaguar leopard tiger classes colors related background. similar effect selection objects rest imagenet dataset. instance scene-type classes i.e. coast castle church identiﬁed features focus outline scenes. similarly notice different viewpoints animal-type classes i.e. golden-retriever robin magpie finally fig. show examples visual explanations produced method. aggregate predicted class label heatmap visualizations indicating pixel locations associated relevant features contributed prediction. case ilsvrc examples notice relevant features come object well context. case mnist examples addition features ﬁring object features support existence emphasize object ﬁlled avoid confusion another class. example class speaks goes section verify visual quality visualizations generated proposed method part prediction feedback. towards goal compare visualizations upsampled activation maps internal layers output deconvnet combined guided-backpropagation fig. present qualitative examples showing heatmap visualization different methods. show visualization different layers-ﬁlters locations throughout network. quick inspection reveals that method attenuate grid-like artifacts introduced deconvnet methods indeed produces noticeable improvements lower layers. fig. additional examples presenting difference lower layers. likewise case higher layers proposed method provides precise visualization compared upsampled activation maps. fact rough output produced activation maps higher layers saliency-like behavior gives impression network focusing larger region image. could possible contribution earlier works manual inspection network activations suggested network focusing semantic parts. please in-depth discussion observation. finally case layers using upsampled activation maps applicable. please refer supplementary material additional examples. figure pixel effect visualization different methods. note lower layers method attenuates grid-like artifacts introduced deconvnet methods. likewise higher layers method provides precise visualization compared upsampled activation maps. case layers using upsampled activation maps applicable. application case visual geolocation section test capabilities proposed method realistic application setting. towards goal focus image-based geolocation task. similar approach task classiﬁcation problem given image goal predict location class image taken. test method subset fashion dataset composed images covering city classes. notable characteristic dataset consists images whose content mostly focused single individual. moreover many images taken indoors thus providing reduced contextual information. makes application different previous geolocation works focus streetview-like images. order reference related difﬁculty geolocation task conducted survey asking people determine given photo taken. time image presented participant participant asked select city list possibilities. participants survey. conduct experiments using ﬁnetuned model pretrained imagenet perform feature identiﬁcation sparsity produced relevant features. similar sec. fig. show quantitative results regarding effect ablating identiﬁed relevant features network classiﬁcation performance. addition absolute mean performance achieved participants survey fig. shows qualitative results experiments. discussion quick glance fig. reveals methods outperform human wide margin. moreover human achieves performance slightly random guess further motivates look deeper cues dnns used overlooked humans. also fig. trends seen previous experiments classiﬁcation accuracy signiﬁcantly drops ablate identiﬁed features setting important information gains taking account layers convolutional layers alone. shows relevance features beyond convolutional layers average visualizations notice ’los angeles’ ’miami’ classes features related uncovered legs skin color importance. similarly classes e.g. melbourne vegetation seems quite common hence high correlation green color. ’london’ ’paris’ relevant features seem focus covered legs others focus upper body part. north europe region color white seems strong feature present walls natural landscapes. region dressing dark colors seems also descriptive feature. interesting average images depict upper body parts focus persons dark long hair short hair light hair. thus describing geographic trends. average visualization provides clear answer question what network actually learned?. shows model effectively exploits human-related features well background-related features considered irrelevant surveyed participants. visual explanations show model effectively uses type features reach decision. could possible cause computer outperformed surveyed participants margin. visual explanation capabilities. method identiﬁes features internally encoded network relevant task originally addressed network. moreover allows interpretation features generation average feature-wise visualizations. addition proposed method attenuate artifacts introduced strided operations visualizations made deconvnetbased methods empowers method richer visual feedback pixel-level precision without requiring additional annotations supervision. future work focus linking identiﬁed relevant features textbased representations goal enriching visual explanations human-readable text explanations.", "year": 2017}