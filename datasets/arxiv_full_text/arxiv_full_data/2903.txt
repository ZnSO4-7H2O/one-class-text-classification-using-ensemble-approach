{"title": "Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning  and Large-Scale Data Collection", "tag": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "abstract": "We describe a learning-based approach to hand-eye coordination for robotic grasping from monocular images. To learn hand-eye coordination for grasping, we trained a large convolutional neural network to predict the probability that task-space motion of the gripper will result in successful grasps, using only monocular camera images and independently of camera calibration or the current robot pose. This requires the network to observe the spatial relationship between the gripper and objects in the scene, thus learning hand-eye coordination. We then use this network to servo the gripper in real time to achieve successful grasps. To train our network, we collected over 800,000 grasp attempts over the course of two months, using between 6 and 14 robotic manipulators at any given time, with differences in camera placement and hardware. Our experimental evaluation demonstrates that our method achieves effective real-time control, can successfully grasp novel objects, and corrects mistakes by continuous servoing.", "text": "feedback controller exceedingly challenging. techniques visual servoing perform continuous feedback visual features typically require features speciﬁed hand open loop perception feedback requires manual automatic calibration determine precise geometric relationship camera robot’s end-effector. paper propose learning-based approach hand-eye coordination demonstrate robotic grasping task. approach data-driven goalcentric method learns servo robotic gripper describe learning-based approach handeye coordination robotic grasping monocular images. learn hand-eye coordination grasping trained large convolutional neural network predict probability task-space motion gripper result successful grasps using monocular camera images independently camera calibration current robot pose. requires network observe spatial relationship gripper objects scene thus learning hand-eye coordination. network servo gripper real time achieve successful grasps. train network collected grasp attempts course months using robotic manipulators given time differences camera placement hardware. experimental evaluation demonstrates method achieves effective real-time control successfully grasp novel objects corrects mistakes continuous servoing. humans animals engage object manipulation behaviors interaction inherently involves fast feedback loop perception action. even complex manipulation tasks extracting single object cluttered performed hardly advance planning relying instead feedback touch vision. contrast robotic manipulation often relies heavily advance planning analysis relatively simple feedback trajectory following ensure stability execution part reason incorporating complex sensory inputs vision directly poses likely produce successful grasps endto-end training directly image pixels task-space gripper motion. continuously recomputing promising motor commands method continuously integrates sensory cues environment allowing react perturbations adjust grasp maximize probability success. furthermore motor commands issued frame robot known model test time. means model require camera precisely calibrated respect end-effector instead uses visual cues determine spatial relationship gripper graspable objects scene. method consists components grasp success predictor uses deep convolutional neural network determine likely given motion produce successful grasp continuous servoing mechanism uses continuously update robot’s motor commands. continuously choosing best predicted path successful grasp servoing mechanism provides robot fast feedback perturbations object motion well robustness inaccurate actuation. grasp prediction trained using dataset grasp attempts collected using cluster similar robotic manipulators shown figure course several months. although hardware parameters robot initially identical unit experienced different wear tear course data collection interacted different objects used slightly different camera pose relative robot base. differences provided diverse dataset learning continuous hand-eye coordination grasping. main contributions work method learning continuous visual servoing robotic grasping monocular cameras novel convolutional neural network architecture learning predict outcome grasp attempt large-scale data collection framework robotic grasps. experimental evaluation demonstrates convolutional neural network grasping controller achieves high success rate grasping clutter wide range objects including objects large small hard soft deformable translucent. supplemental videos grasping system show robot employs continuous feedback constantly adjust grasp accounting motion objects inaccurate actuation commands. also compare approach openloop variants demonstrate importance continuous feedback well hand-engineering grasping baseline uses manual hand-to-eye calibration depth sensing. method achieves highest success rates experiments. dataset available here https //sites.google.com/site/brainrobotdata/home robotic grasping widely explored areas manipulation. complete survey grasping outside scope work refer reader standard surveys subject complete treatment broadly grasping methods categorized geometrically driven data-driven. geometric methods analyze shape target object plan suitable grasp pose based criteria force closure caging methods typically need understand geometry scene using depth stereo sensors matching previously scanned models observations data-driven methods take variety different forms including human-supervised methods predict grasp conﬁgurations methods predict ﬁnger placement geometric criteria computed ofﬂine types data-driven grasp selection recently incorporated deep learning feedback incorporated grasping primarily achieve desired forces force closure dynamic grasping criteria well form standard servoing mechanisms including visual servoing servo gripper pre-planned grasp pose method proposed work entirely data-driven rely human annotation either training test time contrast prior methods based grasp points. furthermore approach continuously adjusts motor commands maximize grasp success providing continuous feedback. comparatively little prior work addressed direct visual feedback grasping requires manually designed features track effector approach closely related recent work self-supervised learning grasp poses pinto gupta prior work proposed learn network predict optimal grasp orientation given image patch trained self-supervised data collected using heuristic grasping system based object proposals. contrast prior work approach achieves continuous handeye coordination observing gripper choosing best motor command move gripper toward successful grasp rather making open-loop predictions. furthermore approach require proposals crops image patches importantly require calibration robot camera since closed-loop servoing mechanism compensate offsets differences camera pose continuously adjusting motor commands. trained method using grasp attempts large variety objects order magnitude larger prior methods based direct self-supervision double dataset size prior methods based synthetic grasps scans order collect grasp dataset parallelized data collection across separate robots. aside work pinto gupta prior large-scale grasp data collection efforts focused collecting datasets object scans. example dex-net used dataset models combined learning framework acquire force closure grasps work oberlin tellex proposed autonomously collecting object scans using baxter robot. oberlin tellex also proposed parallelizing data collection across multiple robots. broadly ability robotic systems learn quickly pooling collective experience proposed number prior works referred collective robot learning instance cloud robotics another related area method visual servoing addresses moving camera end-effector desired pose using visual feedback contrast approach visual servoing methods typically concerned reaching pose relative objects scene often rely manually designed speciﬁed features feedback control photometric visual servoing uses target image rather features several visual servoing methods proposed directly require prior calibration robot camera best knowledge prior learningbased method proposed uses visual servoing directly move pose maximizes probability success given task order predict optimal motor commands maximize grasp success convolutional neural networks trained grasp success prediction. although technology behind cnns known decades achieved remarkable success recent years wide range challenging computer vision benchmarks becoming facto standard computer vision systems. however applications cnns robotic control problems less prevalent compared applications passive perception tasks object recognition localization segmentation several works proposed cnns deep reinforcement learning applications including playing video games executing simple task-space motions visual servoing controlling simple simulated robotic systems performing variety robotic manipulation tasks many applications simple synthetic domains focused relatively constrained environments small datasets. approach learning hand-eye coordination grasping consists parts. ﬁrst part prediction network accepts visual input task-space motion command outputs predicted probability executing command produce successful grasp. second part servoing function uses prediction network continuously control robot servo gripper success grasp. describe components below section formally deﬁnes task solved prediction network describes network architecture section describes servoing function prediction network perform continuous control. breaking hand-eye coordination system components train grasp predictor using standard supervised learning objective design servoing mechanism utilize predictor optimize grasp performance. resulting method interpreted type reinforcement learning discuss interpretation together underlying assumptions section order train prediction network collected grasp attempts using similar robotic manipulators shown figure discuss details hardware setup section discuss data collection process section ensure generalization learned prediction network speciﬁc parameters robot varied terms camera pose relative robot providing independence camera calibration. furthermore uneven wear tear robot resulted differences shape gripper ﬁngers. although accurately predicting optimal motion vectors open-loop possible degree variation demonstrated experiments continuous servoing method correct mistakes observing outcomes past actions achieving high success rate even without knowledge precise camera calibration. figure example input image pair provided network overlaid lines indicate sampled target grasp positions. colors indicate probabilities success green grasp positions projected onto image using known calibration visualization. network receive projections poses onto image offsets current gripper position frame robot. section discuss component approach including description neural network architecture servoing mechanism conclude interpretation method form reinforcement learning including corresponding assumptions structure decision problem. grasp prediction network trained predict whether given task-space motion result successful grasp based current camera observation order make accurate predictions must able parse current camera image locate gripper determine whether moving gripper according position closing ﬁngers pick object. complex spatial reasoning task requires ability parse geometry scene monocular images also ability interpret material properties spatial relationships objects strongly affect success given grasp. pair example input images network shown figure overlaid lines colored accordingly inferred grasp success probabilities. importantly movement vectors provided network transformed frame camera means method require hand-to-eye camera calibration. however also means network must infer outcome task-space motor command determining orientation position robot gripper. figure diagram grasp sample setup. grasp consists time steps time step corresponding pose image ﬁnal dataset contains samples consist image vector producing label grasp attempt results training sample samples given following pooling. layer provide vector input network. vector represented values translation vector sine-cosine encoding change orientation figure architecture grasp predictor. input image well pregrasp image convolution stride followed max-pooling convolutions. followed max-pooling layer. motor command processed fully connected layer pointwise added point response pool tiling output special dimensions. result processed convolutions max-pooling convolutions fully connected layers units network outputs probability successful grasp sigmoid. convolution followed batch normalization. gripper vertical axis. provide vector convolutional network pass fully connected layer replicate spatial dimensions response layer concatenating output pooling layer. concatenation convolution pooling operations applied described figure followed small fully connected layers output probability grasp success trained cross-entropy loss match causing network output input matches pixels randomly crop images region training provide translation invariance. trained network predict probability success given motor command independently exact camera pose. next section discuss grasp success predictor used continuous servo gripper graspable object. section describe servoing mechanism uses grasp prediction network choose motor commands robot maximize probability success grasp. basic operation servoing mechanism perform inference grasp predictor order determine motor command given image simplest randomly sample candidate motor commands evaluate taking command highest probability success. however obtain better results running small optimization perform using cross-entropy method simple derivative-free optimization algorithm samples batch values iteration gaussian distribution samples samples batch gaussian. implementation perform three iterations determine best available command thus evaluate motor commands issued soon optimization completes controller runs around appealing property sampling-based approach easily impose constraints types grasps sampled. used example incorporate user commands require robot grasp particular location keep robot grasping outside workspace obey joint limits. also allows servoing mechanism control height gripper move. often desirable raise gripper objects scene reposition location example objects move errors lack camera calibration produce motions position gripper favorable conﬁguration grasping. predicted grasp success produced network inform heuristic raising lowering gripper well choose stop moving attempt grasp. heuristics particular ﬁrst close gripper whenever network predicts corresponds motion succeed probability least best inferred motion rationale behind stop grasp early closing gripper nearly likely produce successful grasp moving second heuristic raise gripper table probability success less rationale behind choice that closing gripper substantially worse moving gripper likely positioned good conﬁguration large motion required. therefore raising gripper table minimizes chance hitting objects way. heuristics somewhat ad-hoc found effective successfully grasping wide range objects highly cluttered situations discussed section pseudocode servoing mechanism presented algorithm details servoing mechanism presented appendix interesting conceptual question raised approach relationship training grasp prediction network reinforcement learning. case decision made servoing mechanism grasp network regarded approximating q-function policy deﬁned servoing mechanism reward function grasp succeeds otherwise. repeatedly deploying latest grasp network collecting additional data reﬁtting regarded ﬁtted iteration however happens case ﬁtted iteration would correspond learning predict ﬁnal probability success tuples form substantially harder since doesn’t tell gripper closing using action representation ﬁtted iteration therefore implies additional assumption form dynamics. assumption actions induce transitive relation states moving equivalent moving directly. assumption always hold case grasping since intermediate motion might move objects scene reasonable approximation found works quite well practice. major figure diagram single robotic manipulator used data collection process. unit consisted degree freedom -ﬁnger gripper camera mounted shoulder robot. camera recorded monocular depth images though monocular images used grasp success prediction. advantage approximation ﬁtting function reduces prediction problem avoids usual instabilities associated iteration since previous function appear regression. interesting promising direction future work combine approach standard reinforcement learning formulations consider effects intermediate actions. could enable robot example perform nonprehensile manipulations intentionally reorient reposition objects prior grasping. order collect training data train prediction network used robots given time. illustration data collection setup shown figure section describes robots used data collection process well data collection procedure. dataset available here https //sites.google.com/site/brainrobotdata/home robotic manipulator platform consists lightweight degree freedom compliant underactuated twoﬁnger gripper camera mounted behind looking shoulder. illustration single robot shown figure underactuated gripper provides degree compliance oddly shaped objects cost producing loose grip prone slipping. interesting property gripper uneven wear figure images cameras robots training robot holding joint conﬁguration. note variation location difference lighting conditions difference pose camera relative robot variety training objects. started random motor command selection executing completely random motor commands robots successful grasp attempts depending particular objects front them. half dataset collected using random grasps rest used latest network ﬁtted data collected far. course data collection updated network times increased number steps beginning end. objects grasping chosen among common household ofﬁce items ranged length along longest axis. objects shown figure objects placed front robots metal bins sloped sides prevent objects becoming wedged corners. objects periodically swapped increase diversity training data. grasp success evaluated using methods ﬁrst marked grasp successful position reading gripper greater indicating ﬁngers closed fully. however method often missed thin objects also included drop test robot picked object recorded image dropped object gripper. comparing image drop could determine whether object picked evaluate continuous grasping system conducted series quantitative experiments novel objects seen training. particular objects used evaluation shown figure objects presents challenging cross section common ofﬁce last command always corresponds figure grippers robots used data collection experiments. different robots experienced different degrees wear tear resulting signiﬁcant variation gripper appearance geometry. tear course data collection lasted several months. images grippers various robots shown figure illustrating range variation gripper wear geometry. furthermore cameras mounted slightly varying angles providing different viewpoint robot. views cameras robots data collection shown figure collected grasp attempts course months using robots given point time without manual annotation supervision. human intervention data collection process replace object bins front robots turn system. data collection process table failure rates method evaluation condition. evaluating without replacement report failure rate ﬁrst grasp attempts averaged repetitions experiment. jects. address shortcoming replacement condition also tested system without replacement shown figure remove objects bin. condition refer without replacement repeated experiment times report success rates ﬁrst grasp attempts. results presented table success rate continuous servoing method exceeded baseline prior methods cases. evaluation without replacement method cleared completely grasps attempts object left attempts hand-engineered baseline struggled accurately resolve graspable objects clutter since camera positioned meter away table performance also dropped non-replacement case emptied leaving small objects could resolved depth camera. many practical grasping systems wrist-mounted camera address issue contrast approach require special hardware modiﬁcations. open-loop baseline also substantially less successful. although beneﬁted large dataset collected parallelized data collection setup order magnitude larger prior work unable react perturbations movement objects variability actuation gripper shape. figure previously unseen objects used testing setup grasping without replacement test included heavy light large small rigid soft translucent objects. goal evaluation answer following questions continuous servoing signiﬁcantly improve grasping accuracy success rate? well learning-based system perform compared alternative approaches? answer question compared approach open-loop method observes scene prior grasp extracts image patches chooses patch highest probability successful grasp uses known camera calibration move gripper location. method analogous approach proposed pinto gupta uses network architecture method training set. refer approach open loop since make continuous visual feedback. answer question also compared approach random baseline method well hand-engineered grasping system uses depth images heuristic positioning ﬁngers. hand-engineered system described appendix note method requires fewer assumptions either alternative methods unlike pinto gupta require knowledge camera hand calibration unlike handengineered system require either calibration depth images. evaluated methods using experimental protocols. ﬁrst protocol objects placed front robot allowed grasp objects attempts placing grasped object back attempt. grasping replacement tests ability system pick objects cluttered settings also allows robot repeatedly pick easy obtable failure rates method varying dataset sizes speciﬁes number images training datasets correspond roughly ﬁrst eighth quarter half full dataset used method. note performance continues improve amount data increases. table evaluate performance model replacement condition varying amounts data. trained grasp prediction models using roughly ﬁrst grasp attempts dataset simulate effective performance model eighth quarter half data collection process. table shows size dataset terms number images. note length trajectories changed course data collection increasing beginning later datasets substantially larger terms total number images. furthermore success rate later grasp attempts substantially higher increasing beginning around nonetheless results informative understanding data requirements grasping task. first results suggest grasp success rate continued improve data accumulated high success rate observed least halfway data collecqualitatively method exhibited interesting behaviors. figure shows grasps chosen soft hard objects. system preferred grasp softer objects embedding ﬁnger center object harder objects grasped placing ﬁngers either side. method also able grasp variety challenging objects shown figure interesting grasp strategies corrections mistakes seen supplementary video https//youtu.be/cxaic_kum presented method learning hand-eye coordination robotic grasping using deep learning build grasp success prediction network continuous servoing mechanism network continuously control robotic manipulator. training grasp attempts distinct robotic manipulators variation camera pose achieve invariance camera calibration small variations hardware. unlike grasping visual servoing methods approach require calibration camera robot instead using continuous feedback correct errors resulting discrepancies calibration. experimental results demonstrate method effectively grasp wide range different objects including novel objects seen training. results also show method continuous feedback correct mistakes reposition gripper response perturbation movement objects scene. data distribution training resembles distribution test-time. assumption reasonable large diverse training used work structural regularities data collection limit generalization test time. example although method exhibits robustness small variations gripper shape would readily generalize robotic platforms differ substantially used training. furthermore since training grasp attempts executed surfaces proposed method unlikely generalize well grasping shelves narrow cubbies drastically different settings. issues mitigated increasing diversity training setup plan explore future work. exciting aspects proposed grasping method ability learning algorithm discover unconventional non-obvious grasping strategies. observed example system tended adopt different approach grasping soft objects opposed hard ones. hard objects ﬁngers must placed either side object successful grasp. however soft objects grasped simply pinching object easily accomplished placing ﬁnger middle side. observed strategy objects paper tissues sponges. future work plan explore relationship self-supervised continuous grasping approach reinforcement learning order allow methods learn wider variety grasp strategies large datasets robotic experience. general level work explores implications large-scale data collection across multiple robotic platforms demonstrating value type automatic large dataset construction real-world robotic tasks. although robots experiments located controlled laboratory environment long term class methods particularly compelling robotic systems deployed real world therefore naturally exposed wide variety environments objects lighting conditions wear tear. self-supervised tasks grasping data collected shared robots real world would representative test-time inputs would therefore best possible training data improving real-world performance system. particularly exciting avenue future work explore method would need change apply large-scale data collection across large number deployed robots engaged real world tasks including grasping manipulation skills. would like thank kurt konolige mrinal kalakrishnan additional engineering insightful discussions hewitt jordan aaron weiss help maintaining robots bajracharya nicolas hudson providing baseline perception pipeline vincent vanhoucke jeff dean support organization. girshick donahue darrell malik rich feature hierarchies accurate object detection semantic segmentation. ieee conference computer vision pattern recognition goldfeder ciocarlie peretzman dang allen data-driven grasping partial sensor data. ieee/rsj international conference intelligent robots systems hebert hudson howard fuchs bajracharya burdick combined shape appearance silhouette simultaneous manipulator object tracking. ieee international conference robotics automation ieee hudson howard jain bajracharya myint matthies backes hebert end-to-end dexterous manipulation deliberate ieee international conferinteractive estimation. ence robotics automation ioffe szegedy batch normalization accelerating deep network training reducing internal cointernational conference machine variate shift. learning j¨agersand fuentes nelson experimental evaluation uncalibrated visual servoing precision manipulation. ieee international conference robotics automation kehoe matsukawa candido kuffner goldberg cloud-based robot grasping google object recognition engine. ieee international conference robotics automation lampe riedmiller acquiring visual servoing reaching grasping skills using neural reinforceinternational joint conference ment learning. neural networks ieee leeper hsiao salisbury j.k. using near-field stereo vision robotic grasping cluttered environments. experimental robotics springer berlin heidelberg mahler pokorny roderick laskey aubry kohlhoff kr¨oger kuffner goldberg dex-net cloud-based network objects robust grasp planning using multi-armed bandit model correlated rewards. ieee international conference robotics automation vahrenkamp wieland azad gonzalez asfour dillmann visual servoing humanoid grasping manipulation tasks. ieee-ras international conference humanoid robots watter springenberg boedecker riedmiller embed control locally linear latent dynamics model control images. advances neural information processing systems wilson hulls williams bell relative end-effector control using cartesian position based visual servoing. ieee transactions robotics automation implementation performed inference using three iterations cross-entropy method iteration consists sampling sample grasp directions gaussian distribution mean covariance selecting best grasp directions reﬁtting best grasps. ﬁrst iteration samples zero-mean gaussian centered current pose gripper. samples constrained keep ﬁnal pose gripper within workspace avoid rotations vertical axis. general constraints could used control scene robot attempts grasp example impose user constraints command grasps particular locations. since trained predict success grasps sequences always terminated gripper table surface project grasp directions table height passing network although actual grasp direction executed move gripper table shown algorithm servoing algorithm commands gripper motion table choose height uniformly random prototype dimensions position workspace manually moving corner workspace setting corner coordinates. practice height table spatial extents workspace could obtained automatically example moving contact user higherlevel planning mechanism. employ mechanisms determine whether grasp attempt successful. first check state gripper grasp attempt determine whether ﬁngers closed completely. simple test effective detecting large objects miss small thin objects. supplement success detector also image subtraction test record image scene grasp attempt another image attempting drop grasped object bin. object grasped images usually identical. object picked images different. hand-engineered grasping system baseline results reported table obtained using perception pipeline made depth sensor instead monocular camera required extrinsic calibration camera respect base arm. grasp conﬁgurations computed follows first point clouds obtained depth sensor accumulated voxel map. second voxel turned graph segmented using standard graph based segmentation; individual clusters segmented bottom graspable objects based width height region. finally best grasp computed aligns ﬁngers centrally along longer edges bounding represents object. grasp conﬁguration used target pose taskspace controller identical controller used open-loop baseline.", "year": 2016}