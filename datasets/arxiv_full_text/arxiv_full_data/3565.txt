{"title": "Learning to Write Stylized Chinese Characters by Reading a Handful of  Examples", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Automatically writing stylized Chinese characters is an attractive yet challenging task due to its wide applicabilities. In this paper, we propose a novel framework named Style-Aware Variational Auto-Encoder (SA-VAE) to flexibly generate Chinese characters. Specifically, we propose to capture the different characteristics of a Chinese character by disentangling the latent features into content-related and style-related components. Considering of the complex shapes and structures, we incorporate the structure information as prior knowledge into our framework to guide the generation. Our framework shows a powerful one-shot/low-shot generalization ability by inferring the style component given a character with unseen style. To the best of our knowledge, this is the first attempt to learn to write new-style Chinese characters by observing only one or a few examples. Extensive experiments demonstrate its effectiveness in generating different stylized Chinese characters by fusing the feature vectors corresponding to different contents and styles, which is of significant importance in real-world applications.", "text": "figure illustration chinese character generation task based method. given examples speciﬁed styles infer latent vectors corresponding different styles. afterwards generate stylized chinese characters recognizing contents transferring corresponding styles characters beyond limited provided examples ters reading handful examples good testbed machine intelligence humans ﬁnish task effectively still highly challenging state-of-the-art machine learning methods. though great efforts made synthesizing simple english latin characters little exploration done chinese character generation. surprising chinese characters pose challenges complexity diversity. first chinese characters much larger dictionary compared alphabetic writings english latin includes tens letters. instance unique characters ofﬁcial dataset. even daily used characters recently zhang propose chinese character generation model based recurrent neural networks learns dimensional embedding character label solve issue large dictionary. however method heavily dependent temporal information strokes cannot generalize off-line applications. meanwhile results show visual appearance without style information. automatically writing stylized chinese characters attractive challenging task wide applicabilities. paper propose novel framework named style-aware variational auto-encoder ﬂexibly generate chinese characters. speciﬁcally propose capture different characteristics chinese character disentangling latent features content-related style-related components. considering complex shapes structures incorporate structure information prior knowledge framework guide generation. framework shows powerful one-shot/lowshot generalization ability inferring style component given character unseen style. best knowledge ﬁrst attempt learn write newstyle chinese characters observing examples. extensive experiments demonstrate effectiveness generating different stylized chinese characters fusing feature vectors corresponding different contents styles signiﬁcant importance real-world applications. reading writing essential linguistic skills human beings counterparts artiﬁcial intelligence character recognition generation. though long history automatic recognition characters signiﬁcant achievements ﬁeld character generation remains relatively under-explored. unbalanced progress disadvantageous development information processing languages especially chinese widely used languages characters incorporated many asian languages japanese korean. moreover learning write stylized chinese characlatin alphabets. attempts made chinese character generation assembling components radicals strokes however stroke-based models heavily rely preceding parsing requires character clear structure. therefore cannot deal joined-up writing style strokes connected cursive. finally generation stylized chinese characters also challenged complexity writing styles. writing styles typically inﬂuenced various aspects including thickness strokes angle strokes corner relationship strokes. recent zizi method implements chinese characters’ style transfer based pixpix learns mapping source style another target style training thousands character pairs. however target style substantially different source style generation usually blurry since essentially learns imitate source font. case lacks ﬂexibility handle diversity character styles. consequence observing chinese characters style canre-utilize knowledge learned before; instead re-train model scratch. address challenges propose novel framework named style-aware variational auto-encoder conduct stylized chinese character generation. method generalize styles contents without need retraining view decomposition recombination styles contents characters. technically achieved intercross pairwise training method different components character effectively disentangled. besides considering complex shapes structures incorporate conﬁguration chinese characters prior knowledge guide generation process. variational auto-encoder prominent deep generative models compared popular deep generative models generative adversarial networks naturally ability posterior inference reveal underlying factors styles provided observations. besides practice usually yields better inference effects inference extensions therefore method based framework make feature-disentangled extension detailed sec. general would like learn writing style characters able extract pure correct style feature characters. thus drives disentangle style content feature given character samples ﬁrst. existing disentangling methods using supervised unsupervised ways cannot deal issues task needs exactly specify want disentangle writing styles chinese characters complicated abstract. therefore model level design style inference network content recognition network encode style content chinese characters separately. meanwhile algorithm level propose intercross pair-wise optimization method solve problem implicitly using supervision dataset enforce encoded style embeddings pure reliable. discussed before chinese character generation also challenged large dictionary complex structures. unlike general image generation task like faces bedrooms generation lead completely confusing incorrect results even small bias introduced chinese character generation. address issue integrate character knowledge framework propose hashing encoding method considering conﬁguration radicals information chinese characters guide generation. model easily expand large dictionary. meanwhile unlike previous stroke-based methods model performs well dealing handwritten styles. address challenge style inference i.e. generate characters unseen style training phase collect many styles including printing styles handwritten styles style bank. relying powerful generalization capabilities model make reasonable inference allow efﬁcient generalization styles without need retrain model comparison methods. extensive experiments demonstrate method generate stylized chinese characters reading samples including printing styles handwritten styles. best knowledge ﬁrst attempt learn write chinese characters style one-shot/few-shot setting. major contributions three-fold propose novel intercross pair-wise optimization method style feature extraction also general technique solve disentanglement problems weak supervision. figure proposed sa-vae framework mainly consist three subnets including content recognition network style inference network character generation network extract style feature content feature separately combine features conduct generation. besides introduce domain knowledge chinese characters informative content representation. training process executed intercross pair-wise way. section ﬁrst formally present task architecture whole framework. then present intercross pair-wise optimization method detail. finally show conduct one-shot/few-shot stylized chinese character generation model. based assumption one-shot/few-shot chinese character generation task treated inferring style representation observing characters style combining style existing content generate characters style. however observed samples explicit separation style content thus reverseengineering— recognize content disentangle style information given character combine style contents generate stylized chinese characters. number styles total number unique chinese characters training dataset then build content recognition network style inference network respectively disentangled features content style chinese character xij. deﬁne generation network generate chinese characters given style content one-shot/few-shot setting observe characters style denoted +kll+m} based characters style feature inferred combined content {cn} generate desirable stylized chinese character model architecture mentioned above model mainly consists three subnets including content recognition network style inference network character generation network illustrated fig. whole process separated phases inference generation. inference stage ﬁrst learn disentangle latent features content-related style-related components based content recognition network style inference network respectively. knowledge character conﬁgurations radicals integrated content vectors informative content code. generation stage take content style vectors inputs deconvolutional network stylized characters well-reconstructed style feature appropriately captured inference stage. training process executed intercross pair-wise reliable disentanglement means generated character extracts style feature content recognition network. content recognition essential part model aims recognize content every chinese character image provide correct content label style inference network generation network. fulﬁlled learning network encodes deterministic mapping input output follows inspired previous works state-of-the-art character recognition adopt network architecture change fully-connected layers satisfy need. found network sufﬁcient task although deeper networks like resnet densenet also easily applied framework even complex recognition tasks. character structure knowledge. utilizing domain knowledge chinese characters develop compact model improve generation quality. speﬁcially although recognize content label content recognition network high accurarcy large dictionary still challenge chinese character generation task. previous deep generative models usually label category one-hot embedding concatenate feature maps every layer. method works well small datasets mnist svhn tens classes fail solve chinese character generation thousands classes lead explosive growth model parameters. address issue propose informative character encoding method introducing conﬁguration radical information chinese characters framework build corresponding index table compared one-hot embedding encoding method reuse conﬁguration information radical information shared among chinese characters. one-hot embedding every character transformed unique content code index table encoding hash code bits shown fig. much shorter one-hot embedding ﬁrst bits used identify common conﬁgurations chinese characters including up-down left-right left-middle-right half surroundings middle bits used identify frequently used radicals case missing radicals. fig. fig. illustrations conﬁgurations radicals respectively. last bits binary index former parts same. proved experimental results proposed encoding method compresses embedding dimension harm model’s capacity compared one-hot embedding. style inference network. style inference network module make framework capacity achieving accurate style inference. build network mainly based convolutional layers convolutional ﬁlters extract local features chinese character images exactly satisfy expectation style representation. moreover automatically disentangle style feature content information besides character image content code also input network. besides contrast deterministic network writing style full uncertainty therefore stochastic network model realized diagonal gaussian distribution parameterized convolutional neural network. hence formulate style inference network requires style inference network provide posterior distribution given different characters common style. target implicitly ensures style inference network extract style information content information inputs different. property important main purpose disentangle content style information. explain achieve intercross pair-wise optimization method detail sec. character generation network. order generate different characters diverse styles ﬂexibly character generation network takes content code style feature independent inputs disentangled factors jointly decide generated characters. like style inference network character generation network also built stochastic network intuition write characters exactly alike. bernoulli distribution parameterized deconvolutional neural network model binary image chinese characters formulated style inference network character generation network corresponding encoder decoder vanilla well-trained content recognition network provides accurate character labels class condition. three sub-nets form basic skeleton sa-vae framework details networks shown supplementary material. generally latent variable generative models usually trained maximizing marginal log-likelihood. however direct optimization likelihood often intractable. variational inference method deﬁne parameterized variational distribution optimize variational lower bound instead log-likelihood chinese character generation task assumption mentioned style content chinese characters independent. meanwhile content code obtained well-trained therefore denotes kullback leibler divergence true posterior generative model. practically directly optimizing cannot ensure characters font share similar style embedding. vanilla variational inference treats character separately strong correlation different characters especially style. want disentangle style information content propose objective still lower bound log-likelihood. speciﬁcally consider pair characters share style different contents deﬁne objective function ideally optimized zero point equilibrium arrived holds substituting eq.. therefore derivation explains objective function achieve reliable disentanglement. denotes prior distribution form explicit derive training algorithm ﬁrst term means reconstruction loss second term means regularization. instead reconstructing input vanilla objective function tries produce target character based characters number observed characters corresponding characters observed content code xij. independent random variables correspondingly obey posterior distribution qφ.with means obtain stable estimation style information averaging multiple characters. figure chinese characters provide style feature style inference network combined content codes dataset together input generation network generate desirable chinese characters style. section present experimental results. ﬁrst introduce dataset build. present one-shot/few-shot generation results. meanwhile also present experimental results verify model strong ability style generalization disentanglement. finally show necessity advantage using proposed encoding method human knowledge. data preparation main purpose generalize styles based learning sufﬁcient support styles need enough styles model learn. existing datasets satisfy goal build one. dataset consists chinese characters styles collected style information different contents generated character obtains style information another character style. fig. illustration. call optimization method intercross pair-wise. based intuition design intercross pair-wise optimization algorithm alg. algorithm training algorithm input chinese characters dataset {xij} output model parameters randomly initialize pre-train content recognition network repeat randomly select mini-batch randomly select mini-batch correspondingly shares font content code using content code using ∇θφl update parameters using gradients notice proposed intercross pair-wise optimization method restricted task stylized chinese character generation. general technique applied disentanglement problems weak supervision like existing style information task. one-shot/few-shot character generation figure generation results one-shot few-shot setting. generated chinese characters lines sa-vae framework compared ground truth even lines. printing styles handwritten styles bottom. characters dotted frame given style provider. internet including printing styles handwritten styles. randomly select styles used style-bank training rest used test. choose frequently used chinese characters style style-bank build training set. sufﬁcient training evaluate model’s capacity generalization test styles. detailed experimental setting supplementary material. fig. shows one-shot few-shot generation results. results presented printing style handwritten style demonstrates model capacity dealing diverse styles. generation results shown supplementary material. style generalization point sa-vae framework proves model capacity learning style. show model achieve goal interpolation disparate styles results shown fig. besides also nearest neighbors oneshot generalization results show method ﬁnding similar style training shown fig. experimental results indicate sa-vae inherits advantage generalization deep generative models. figure choose disparate styles large thick small thin. interpolation results show large thick style gradually change small thin means model learn meaningful representation latent space. figure nearest neighbor one-shot generation. ﬁrst characters dotted frame style sources second ones generated using ﬁrst characters’ style. third forth nearest neighbors generated characters training set. successfully disentangling style information content information another necessity achieve oneshot generation given styles. show signiﬁcance purity style embedding here. based intuition meaningful style embedding contains enough information represent style little information represent content choose auxiliary classiﬁcation tasks using style embedding. speciﬁcally train -layers style embedding different methods including sa-vae vanilla vae-gan encoder network decoder network vanilla vae-gan setting sa-vae. simplify training unique characters style training data style classiﬁcation styles character character content classiﬁcation test prediction accuracy rest samples. results shown table compared models style embedding extracted sa-vae contains little content information style information means sa-vae mainly extract style features characters lead better result one-shot generation. fig. provides powerful proof intercross pair-wise optimization method provides powerful ability disentanglement. except sa-vae generation results produced methods meaningful characters since carry much content information style speciﬁed characters. figure show one-shot generation results produced three models. style speciﬁed characters left dotted frame content speciﬁed characters blue dotted frame. dictionary issue chinese characters. show effectiveness knowledge guidance compare converge speed three encoding methods content code one-hot embedding binary embedding. results shown fig. figure training curves three encoding methods using different numbers unique characters y-axis shows negative lower bound x-axis shows number epochs training. notice character numbers model parameters using one-hot embedding explode cannot show corresponding curve. depending cost expanding model capacity one-hot embedding provide comparable converge speed knowledgeable content code. however embedding method make model parameters exploded larger chinese characters dictionary. binary embedding consumes shorter length bits hardly converges matter numerous characters characters. presented novel style-aware framework ﬁrst achieves stylized chinese character generation reading characters. model disentangles style information content information intercross pair-wise optimization method shows powerful one-shot few-shot generalization ability unseen styles. finally present impressive generation results printing styles handwritten styles.", "year": 2017}