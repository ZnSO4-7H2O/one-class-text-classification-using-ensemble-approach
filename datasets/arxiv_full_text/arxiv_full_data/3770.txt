{"title": "Bayesian image segmentations by Potts prior and loopy belief propagation", "tag": ["cs.CV", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "stat.ML"], "abstract": "This paper presents a Bayesian image segmentation model based on Potts prior and loopy belief propagation. The proposed Bayesian model involves several terms, including the pairwise interactions of Potts models, and the average vectors and covariant matrices of Gauss distributions in color image modeling. These terms are often referred to as hyperparameters in statistical machine learning theory. In order to determine these hyperparameters, we propose a new scheme for hyperparameter estimation based on conditional maximization of entropy in the Potts prior. The algorithm is given based on loopy belief propagation. In addition, we compare our conditional maximum entropy framework with the conventional maximum likelihood framework, and also clarify how the first order phase transitions in LBP's for Potts models influence our hyperparameter estimation procedures.", "text": "denotes neighbouring pixels pixel quantities z{ij} eqs. correspond normalization constants approximate representations marginal probabilities lbp. {λj→i|i∈v j∈∂i ξ∈q} messages lbp) prior probability pr{a a|u} free figs. correspond u)u) step solid lines various values also given fig.. table show estimatesu cases images fig.. segmentation d···ma|v| terms average vectors estimate labelinga. ﬁrst order phase transition. addition free energy |v|lny pixel least singular point derivative discontinuous respect although useful procedures realizing valued function corresponds internal energy δzizj pr{a z|u} regarded inverse temperature system. success iterative inference algorithm estimating average vectors covariance matrices eqs.- shown figs. diﬀerence eq.. mentioned above diﬀerentiable therefore extremum condition respect cannot considered maximization equal hand equal consider extremum condition reduce deterministic equation eq.. equation equivalent", "year": 2014}