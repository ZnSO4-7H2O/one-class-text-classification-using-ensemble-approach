{"title": "On the importance of single directions for generalization", "tag": ["stat.ML", "cs.AI", "cs.LG", "cs.NE"], "abstract": "Despite their ability to memorize large datasets, deep neural networks often achieve good generalization performance. However, the differences between the learned solutions of networks which generalize and those which do not remain unclear. Additionally, the tuning properties of single directions (defined as the activation of a single unit or some linear combination of units in response to some input) have been highlighted, but their importance has not been evaluated. Here, we connect these lines of inquiry to demonstrate that a network's reliance on single directions is a good predictor of its generalization performance, across networks trained on datasets with different fractions of corrupted labels, across ensembles of networks trained on datasets with unmodified labels, across different hyperparameters, and over the course of training. While dropout only regularizes this quantity up to a point, batch normalization implicitly discourages single direction reliance, in part by decreasing the class selectivity of individual units. Finally, we find that class selectivity is a poor predictor of task importance, suggesting not only that networks which generalize well minimize their dependence on individual units by reducing their selectivity, but also that individually selective units may not be necessary for strong network performance.", "text": "despite ability memorize large datasets deep neural networks often achieve good generalization performance. however differences learned solutions networks generalize remain unclear. additionally tuning properties single directions highlighted importance evaluated. here connect lines inquiry demonstrate network’s reliance single directions good predictor generalization performance across networks trained datasets different fractions corrupted labels across ensembles networks trained datasets unmodiﬁed labels across different hyperparameters course training. dropout regularizes quantity point batch normalization implicitly discourages single direction reliance part decreasing class selectivity individual units. finally class selectivity poor predictor task importance suggesting networks generalize well minimize dependence individual units reducing selectivity also individually selective units necessary strong network performance. recent work demonstrated deep neural networks capable memorizing extremely large datasets imagenet despite capability dnns practice achieve generalization error tasks ranging image classiﬁcation language translation observations raise question networks generalize others not? answers questions taken variety forms. variety studies related generalization performance ﬂatness minima pac-bayes bounds though recent work demonstrated sharp minima also generalize others focused information content stored network weights still others demonstrated stochastic gradient descent encourages generalization here ablation analyses measure reliance trained networks single directions. deﬁne single direction activation space activation single unit feature linear combination units response input. networks memorize training substantially dependent single directions difference preserved even across sets networks identical topology trained identical data different generalization performance. moreover found networks begin overﬁt become reliant single directions suggesting metric could used signal early stopping. also show networks trained batch normalization robust cumulative ablations networks trained without batch normalization batch normalization decreases class selectivity individual feature maps suggesting alternative mechanism batch normalization encourage good generalization performance. finally show that despite focus selective single units analysis dnns class selectivity single units poor predictor importance network’s output. study perturbation analyses examine relationship network’s generalization performance reliance upon single directions activation space. neuroscience-inspired measure class selectivity compare selectivity individual directions across networks variable generalization performance examine relationship class selectivity importance. analyzed three models -hidden layer trained mnist -layer convolutional network trained cifar- -layer residual network trained imagenet. experiments relu nonlinearities applied layers output. unless otherwise noted batch normalization used convolutional networks imagenet resnet top- accuracy used cases. partially corrupted labels zhang used datasets differing fractions randomized labels ensure varying degrees memorization. create datasets given fraction labels randomly shufﬂed assigned images distribution labels maintained true patterns broken. ablations measured importance single direction network’s computation asking network’s performance degrades inﬂuence direction removed. remove coordinate-aligned single direction clamped activity direction ﬁxed value ablations performed either single units mlps entire feature convolutional networks. brevity refer ‘units.’ critically ablations performed activation space rather weight space. generally evaluate network’s reliance upon sets single directions asked network’s performance degrades inﬂuence increasing subsets single directions removed clamping ﬁxed value analysis generates curves accuracy function number directions ablated reliant network low-dimensional activation subspaces quickly accuracy drop single directions ablated. interestingly found clamping activation unit empirical mean activation across training testing damaging network’s performance clamping activation zero therefore clamped activity zero ablation experiments. addition noise analyses perturb units individually measure inﬂuence coordinate-aligned single directions. test networks’ reliance upon random single directions added gaussian noise units zero mean progressively increasing variance. scale variance appropriately unit variance noise added normalized empirical variance unit’s activations across training set. quantify class selectivity individual units used metric inspired selectivity indices commonly used systems neuroscience cifar- imagenet units layers ablated feature maps last three layers ablated. error bars represent standard deviation across random orderings units ablate. µmax representing highest class-conditional mean activity µ−max representing mean activity across classes. convolutional feature maps activity ﬁrst averaged across elements feature map. metric varies meaning unit’s average activity identical classes meaning unit active inputs single class. note metric perfect measure information content single units; example unit little information every class would class selectivity index. however measure discriminability classes along given direction. selectivity index also identiﬁes units class tuning properties highlighted analysis dnns however addition class selectivity replicate results using mutual information which contrast class selectivity highlight units information multiple classes qualitively similar outcomes also note class viewed highly abstract feature implying results generalize feature selectivity examine feature selectivity work. here provide rough intuition network’s reliance upon single directions might related generalization performance. consider networks trained large labeled dataset underlying structure. networks simply memorizes labels input example will deﬁnition generalize poorly learns structure present data generalizes well minimal description length model larger memorizing network structureﬁnding network. result memorizing network capacity structure-ﬁnding network extension single directions. therefore random single direction perturbed probability perturbation interfere representation data higher memorizing network structure-ﬁnding network. figure memorizing networks sensitive random noise. networks trained mnist cifar- noise scaled empirical variance unit training set. error bars represent standard deviation across runs. x-axis scale. figure networks generalize poorly reliant single directions. networks identical topology trained unmodiﬁed cifar-. cumulative ablation curves best worst networks generalization error. error bars represent standard deviation across models random orderings feature maps model. area cumulative ablation curve function generalization error. test whether memorization leads greater reliance single directions trained variety network types datasets differing fractions randomized labels evaluated performance progressively larger fractions units ablated deﬁnition curves must begin network’s training accuracy fall chance levels directions ablated. rule variance speciﬁc order unit ablation experiments performed mutliple random ablation orderings units. many models trained datasets corrupted labels deﬁnition cannot generalize training accuracy used evaluate model performance. consistent intuition found networks trained varying fractions corrupted labels signiﬁcantly sensitive cumulative ablations trained datasets comprised true labels though curves always perfectly ordered fraction corrupted labels next asked whether effect present networks perturbed along random bases. test this added noise unit again found networks trained corrupted labels substantially consistently sensitive noise added along random bases trained true labels results apply networks forced memorize least portion training solve task. however unclear whether results would apply networks trained uncorrupted data. words solutions found networks topology data different generalization performance exhibit differing reliance upon single directions? test this trained networks cifar- evaluated generalization error reliance single directions. networks topology trained dataset individual networks differed random initialization data order used training. found networks best generalization performance robust ablation single directions networks worst generalization performance quantify further measured area ablation curve networks plotted function generalization error interestingly networks appeared undergo discrete regime shift reliance upon single directions; however effect might caused degeneracy solutions found optimization procedure note also negative correlation present within clusters results demonstrate relationship generalization performance single direction reliance merely side-effect training corrupted labels instead present even among sets networks identical training data. relationship raises intriguing question single direction reliance used estimate generalization performance without need held-out test set? might used signal early stopping hyperpameter selection? proof-of-principle experiment early stopping trained mnist measured area cumulative ablation curve course training along train test loss. interestingly found point training began drop point train test loss started diverge furthermore found test loss negatively correlated proof-of-principle experiment hyperparameter selection trained cifar- models different hyperparemeter settings found test accuracy highly correlated performing random subselections hyperparameter settings selected settings time respectively average difference test accuracy best model selected optimal model results suggest single direction reliance serve good proxy hyperparameter selection early stopping work necessary evaluate whether results hold complicated datasets. dropout experiments reminiscent using dropout training time upon ﬁrst inspection dropout appear discourage networks’ reliance single directions however dropout encourages networks robust cumulative ablations dropout fraction used training discourage reliance single directions past point. given enough capacity memorizing network could effectively guard dropout merely copying information stored given direction several directions. however network encouraged make minimum number copies necessary guard dropout fraction used training more. case network would robust dropout long redundant directions simultaneously removed still highly reliant single directions past dropout fraction used training. test whether intuition holds trained mlps mnist dropout probabilities corrupted unmodiﬁed labels. consistent observation arpit found networks dropout trained randomized labels required epochs converge converged worse solutions higher dropout probabilities suggesting dropout indeed discourage memorization. however networks trained corrupted unmodiﬁed labels exhibited minimal loss training accuracy single directions removed dropout fraction used training past point networks trained randomized labels much sensitive cumulative ablations trained unmodiﬁed labels interestingly networks trained unmodiﬁed labels different dropout fractions similarly robust cumulative ablations. results suggest dropout serve effective regularizer prevent memorization randomized labels prevent over-reliance single directions past dropout fraction used training. figure single direction reliance signal hyperparameter selection early stopping. train test loss along normalized area cumulative ablation curve course training mnist mlp. loss y-axis cropped make train/test divergence visible. test loss cifar- convnet negatively correlated course training. test accuracy positively corrleated across hyperparameter sweep figure impact regularizers networks’ reliance upon single directions. cumulative ablation curves mlps trained unmodiﬁed fully corrupted mnist dropout fractions colored dashed lines indicate number units ablated equivalent dropout fraction used training. note curves networks trained corrupted mnist begin drop soon past dropout fraction trained. cumulative ablation curves networks trained cifar- without batch normalization. error bars represent standard deviation across model instances random orderings feature maps model. figure batch normalization decreases class selectivity increases mutual information. distributions class selectivity mutual information networks trained without batch normalization distribution comprises model instances trained uncorrupted cifar-. batch normalization contrast dropout batch normalization appear discourage reliance upon single directions. test this trained convolutional networks cifar- without batch normalization measured robustness cumulative ablation single directions. networks trained batch normalization consistently substantially robust ablations trained without batch normalization result suggests addition reducing covariate shift proposed previously batch normalization also implicitly discourages reliance upon single directions. results thus suggest networks less reliant single directions exhibit better generalization performance. result appear counter-intuitive light extensive past work neuroscience deep learning highlights single units feature maps selective particular features classes here test whether class selectivity single directions related importance directions network’s output. first asked whether batch normalization found discourage reliance single directions also inﬂuences distribution information class across single directions. used selectivity index described quantify discriminability classes based activations single feature maps across networks trained without batch normalization. interestingly found networks trained without batch normalization exhibited large fraction feature maps high class selectivity class selectivity feature maps networks trained batch normalization substantially lower contrast found batch normalization increases mutual information present feature maps results suggest batch normalization actually discourages presence feature maps concentrated class information rather encourages presence feature maps information multiple classes raising question whether highly selective feature maps actually beneﬁcial. next asked whether class selectivity given unit predictive impact network’s loss ablating said unit. since experiments performed networks trained unmodiﬁed labels test loss used measure network impact. mlps trained mnist found slight minor correlation unit’s class selectivity impact ablation many highly selective units minimal impact ablated analyzing convolutional networks trained cifar- imagenet found that across layers ablation highly selective feature maps impactful ablation non-selective feature maps fact cifar- networks actually negative correlation class selectivity feature importance test whether relationship depth-dependent calculated correlation class selectivity importance separately layer found vast majority negative correlation driven early figure selective non-selective directions similarly important. impact ablation function class selectivity mnist cifar- convolutional network imagenet resnet show regression lines layer separately. layers later layers exhibited relationship class selectivity importance interestingly three networks ablations early layers impactful ablations later layers consistent theoretical observations additionally performed experiments mutual information place class selectivity found qualitatively similar results ﬁnal test compared class selectivity l-norm ﬁlter weights metric found successful predictor feature importance model pruning literature consistent previous observations found class selectivity largely unrelated l-norm ﬁlter weights anything negatively correlated taken together results suggest class selectivity good predictor importance imply class selectivity actually detrimental network performance. work necessary examine whether class and/or feature selectivity harmful helpful network performance. much work directly inspired zhang replicate results using partially corrupted labels cifar- imagenet. demonstrating memorizing networks reliant single directions also provide answer questions posed empirical difference networks memorize generalize? work also related work linking generalization sharpness minima studies argue minima generalize better sharp minima recently found sharp minima also generalize well). consistent work minima correspond solutions perturbations along single directions little impact network output. another approach generalization contextualize information theory. example achille soatto demonstrated networks trained randomized labels store information weights trained unmodﬁed labels. notion also related shwartz-ziv tishby argues training networks proceed ﬁrst loss minimization phase followed compression phase. again work consistent networks information stored weights reliant upon single directions compressed networks. recently arpit analyzed variety properties networks trained partially corrupted labels relating performance time-to-convergence capacity. also demonstrated dropout properly tuned serve effective regularizer prevent memorization. however found dropout discourage memorization discourage reliance single directions past dropout probability. found class selectivity poor predictor unit importance. observation consistent variety recent studies neuroscience. line work beneﬁts neural systems robust coordinate-aligned noise explored montijn another studies demonstrated presence neurons multiplexed information many stimuli shown task information decoded high accuracy populations neurons individual class selectivity rigotti mante raposo morcos harvey zylberberg perturbation analyses performed variety purposes. model pruning literature many studies removed units goal generating smaller models similar performance recent work explored methods discovering maximally important directions variety studies within deep learning highlighted single units selective features classes additionally agrawal analyzed minimum number sufﬁcient feature maps achieve given accuracy. however none studies tested relationship unit’s class selectivity information content necessity network’s output. quantiﬁed related metric concept selectivity across layers networks ﬁnding units concept-selective depth consistent observations regarding class selectivity however also observed correlation number concept-selective units performance action dataset across networks architectures. difﬁcult compare results directly data used substantially different method evaluating selectivity. nevertheless note measured absolute number concept-selective units across networks different total numbers units depths. relationship number concept-selective units network performance therefore arise result larger number total units increased depth work taken empirical approach understand differentiates neural networks generalize not. experiments demonstrate generalization capability related network’s reliance single directions networks trained corrupted uncorrupted data course training single network. also show batch normalization highly successful regularizer seems implicitly discourage reliance single directions. clear extension work observations construct regularizer directly penalizes reliance single directions. happens obvious candidate regularize single direction reliance dropout which shown appear regularize single direction reliance past dropout fraction used training interestingly results suggest able predict network’s generalization performance without inspecting held-out validation test set. observation could used several interesting ways. first situations labeled training data sparse testing networks’ reliance single directions provide mechanism assess generalization performance without sacriﬁcing training data used validation set. second using computationally cheap empirical measures single direction reliance evaluating performance single ablation point sparsely sampling ablation curve metric could used signal early-stopping hyperparameter selection. shown metric viable simple datasets work necessary evaluate viability complicated datasets. another interesting direction research would evaluate relationship single direction reliance generalization performance across different generalization regimes. work evaluate generalization train test data drawn distribution stringent form generalization test drawn unique overlapping distribution train set. extent single direction reliance depends overlap train test distributions also worth exploring future research. work makes potentially surprising observation role individually selective units dnns. found class selectivity single directions largely uncorrelated ultimate importance network’s output also batch normalization decreases class selectivity individual feature maps. result suggests highly class selective units actually harmful network performance. addition implies methods understanding neural networks based analyzing highly selective single units ﬁnding optimal inputs single units activation maximization misleading. importantly measured feature selectivity unclear whether results generalize featureselective directions. work necessary clarify points. devansh arpit stanisław jastrze¸bski nicolas ballas david krueger emmanuel bengio maxinder kanwal tegan maharaj asja fischer aaron courville yoshua bengio simon lacoste-julien. closer look memorization deep networks. issn http//arxiv.org/abs/.. bruno averbeck peter latham alexandre pouget. neural correlations population coding computation. nature reviews. neuroscience issn ./nrn. http//dx.doi.org/./nrn. david bolei zhou aditya khosla aude oliva antonio torralba. network dissection quantifying interpretability deep visual representations. ./cvpr.. http//arxiv.org/abs/.. olivier bousquet andr´e elisseeff. stability generalization. journal machine learning research jmlr issn http//www.jmlr.org/ papers/volume/bousqueta/bousqueta.pdf. kenneth britten michael shadlen william newsome anthony movshon. analysis visual motion comparison neuronal psychophysical performance. journal neuroscience adam coates andrej karpathy andrew emergence object-selective features unsupervised feature learning. nips’ ./elps.. http//www.stanford.edu/{˜}acoates/papers/ coateskarpathyng{_}nips.pdf. gintare karolina dziugaite daniel roy. computing nonvacuous generalization bounds deep neural networks many parameters training data. http//arxiv.org/abs/.. david freedman john assad. experience-dependent representation visual categories parietal cortex. nature issn ./nature. http//www.ncbi.nlm.nih.gov/pubmed/. sergey ioffe christian szegedy. batch normalization accelerating deep network training reducing internal covariate shift. arxiv http//arxiv.org/abs/. nitish shirish keskar dheevatsa mudigere jorge nocedal mikahail smelyanskiy ping peter tang. large-batch training deep learning generalization sharp minima. iclr quoc marc’aurelio ranzato rajat monga matthieu devin chen greg corrado jeff dean andrew building high-level features using large scale unsupervised learning. international conference machine learning issn ./msp.. valerio mante david sussillo krishna shenoy william newsome. context-dependent computation recurrent dynamics prefrontal cortex. nature november issn ./nature. http//dx.doi.org/ ./nature. jorrit montijn guido meijer carien lansink cyriel pennartz. population-level neural codes robust single-neuron variability multidimensional coding perspective. cell reports issn ./j.celrep.... http//dx.doi.org/./j.celrep.... morcos christopher harvey. history-dependent variability population dynamics evidence accumulation cortex. nature neuroscience october issn ./nn.. http//www.nature.com/articles/ nn.. maithra raghu justin gilmer jason yosinski jascha sohl-dickstein. svcca singular vector canonical correlation analysis deep understanding improvement. http//arxiv.org/abs/.. david raposo matthew kaufman anne churchland. category-free neural population supports evolving demands decision-making. nature neuroscience november issn ./nn.. http//www.nature. com/doifinder/./nn.. mattia rigotti omri barak melissa warden xiao-jing wang nathaniel earl miller stefano fusi. importance mixed selectivity complex cognitive tasks. nature issn ./nature. http//dx.doi. org/./nature. nitish srivastava geoffrey hinton alex krizhevsky ilya sutskever ruslan salakhutdinov. dropout simple prevent neural networks overﬁtting. journal machine learning research issn ashia wilson rebecca roelofs mitchell stern nathan srebro benjamin recht. marginal value adaptive gradient methods machine learning. http//arxiv.org/abs/.. yonghui mike schuster zhifeng chen quoc mohammad norouzi wolfgang macherey maxim krikun yuan klaus macherey google’s neural machine transarxiv preprint lation system bridging human machine translation. arxiv. chiyuan zhang samy bengio moritz hardt benjamin recht oriol vinyals. understanding deep learning requires rethinking generalization. http//arxiv.org/abs/ remove inﬂuence given direction value ﬁxed otherwise modiﬁed longer dependent input. however choice ﬁxed value substantial impact. example value clamped highly unlikely given distribution activations across training network performance would likely suffer drastically. here compare methods ablating directions ablating zero ablating empirical mean training set. using convolutional networks trained cifar- performed cumulative ablations either ablating zero feature map’s mean found ablations zero signiﬁcantly less damaging ablations feature map’s mean interestingly corresponds ablation strategies generally used model pruning literature mnist mlps class selectivity generalization early stopping dropout experiments layer contained units respectively. networks trained epochs exception dropout networks trained epochs. cifar- convnets convolutional networks trained cifar- epochs. layer sizes were strides respectively. kernels hyperparameter sweep used section learning rate batch size evaluated using grid search. imagenet resnet -layer residual networks trained imagenet using distributed training workers batch size steps. blocks structured follows training partially corrupted labels data augmenhere evaluate distribution class selectivity function depth. networks trained cifar- imagenet selectivity increased function depth. result consistent show concept-selectivity increases depth. also consistent alain bengio show depth increases linear decodability class information importantly results lack relationship class selectivity importance suggest directions less important network’s output suggest directions predictable; merely suggest class selectivity good predictor importance. ﬁnal test this compared class selectivity l-norm ﬁlter weights metric found strongly correlated impact removing ﬁlter model pruning literature since l-norm ﬁlter weights predictive impact feature map’s removal class selectivity also good predictor metrics correlated. imagenet network found correlation l-norm ﬁlter weights class selectivity cifar- network found actually negative correlation figure mutual information good predictor unit importance. impact ablation function mutual information mnist cifar- convolutional network imagenet resnet show regression lines layer separately. examine whether mutual information which contrast class selectivity highlights units information multiple classes good predictor importance performed experiments section mutual information place class selectivity. found results little less consistent mutual information generally poor predictor unit importance", "year": 2018}