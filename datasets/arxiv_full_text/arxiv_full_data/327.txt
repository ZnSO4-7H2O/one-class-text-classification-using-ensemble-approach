{"title": "Data-Efficient Learning of Feedback Policies from Image Pixels using  Deep Dynamical Models", "tag": ["cs.AI", "cs.CV", "cs.LG", "stat.ML"], "abstract": "Data-efficient reinforcement learning (RL) in continuous state-action spaces using very high-dimensional observations remains a key challenge in developing fully autonomous systems. We consider a particularly important instance of this challenge, the pixels-to-torques problem, where an RL agent learns a closed-loop control policy (\"torques\") from pixel information only. We introduce a data-efficient, model-based reinforcement learning algorithm that learns such a closed-loop policy directly from pixel information. The key ingredient is a deep dynamical model for learning a low-dimensional feature embedding of images jointly with a predictive model in this low-dimensional feature space. Joint learning is crucial for long-term predictions, which lie at the core of the adaptive nonlinear model predictive control strategy that we use for closed-loop control. Compared to state-of-the-art RL methods for continuous states and actions, our approach learns quickly, scales to high-dimensional state spaces, is lightweight and an important step toward fully autonomous end-to-end learning from pixels to torques.", "text": "data-efﬁcient reinforcement learning continuous state-action spaces using high-dimensional observations remains challenge developing fully autonomous systems. consider particularly important instance challenge pixels-to-torques problem agent learns closed-loop control policy pixel information only. introduce data-efﬁcient model-based reinforcement learning algorithm learns closed-loop policy directly pixel information. ingredient deep dynamical model learning low-dimensional feature embedding images jointly predictive model low-dimensional feature space. joint learning crucial longterm predictions core adaptive nonlinear model predictive control strategy closed-loop control. compared state-of-the-art methods continuous states actions approach learns quickly scales high-dimensional state spaces lightweight important step toward fully autonomous end-to-end learning pixels torques. vision fully autonomous intelligent systems learn inspired artiﬁcial intelligence robotics research many decades. pixels torques problem identiﬁes aspects autonomous system autonomous thinking decision making using sensor measurements only intelligent exploration learning mistakes. consider problem efﬁciently learning closed-loop policies pixel information end-to-end. although problem falls general class reinforcement learning challenging following reasons state-space enormous many practical applications need solutions data efﬁciently working real systems e.g. robots cannot perform millions experiments time hardware constraints. using data efﬁciently therefore reducing number experiments learn predictive forward models underlying dynamical system used internal simulations policy learning. ideas successfully applied control robotics instance. however often rely heuristics demonstrations engineered low-dimensional features easily scale data-efﬁcient using pixel information only. common dealing high-dimensional data learn low-dimensional feature representations. deep learning architectures deep neural networks stacked auto-encoders convolutional neural networks current state-of-the-art learning parsimonious representations high-dimensional data. since deep learning produced outstanding empirical results image text audio tasks related work last months signiﬁcant progress context pixels-to-torques problem. ﬁrst working solution presented agent automatically learned play atari games purely based pixel information. idea embed high-dimensional pixel space lower-dimensional space using deep neural networks apply q-learning compact feature space. potential issue approach data-efﬁcient learning policies i.e. impractical apply robotic scenario. data inefﬁciency speciﬁc q-learning general problem model-free methods increase data efﬁciency model-based methods learn model transition dynamics system/robot subsequently model surrogate simulator. recently idea learning predictive models images pixel information available exploited approach taken follows idea deep dynamical models instead learning predictive models images directly detour low-dimensional feature space taken embedding images lower-dimensional feature space e.g. deep autoencoder. detour promising since direct mappings high-dimensional spaces require large data sets. whereas wahlstr¨om consider deterministic systems nonlinear model predictive control techniques online control watter variational autoencoders local linearization locally linear control methods aico model dynamical behavior system pixels current previous frame used. watter concatenate input pixels discover features whereas wahlstr¨om concatenate processed low-dimensional embeddings states. latter approach requires least fewer parameters makes promising candidate data-efﬁcient learning. nevertheless properties local linearization attractive. however complex architecture proposed watter based large neural network models million parameters learning swing single pendulum. vast number training parameters results higher model complexity thus decreased statistical efﬁciency. hence excessive number training samples might available required learn underlying system taking several days trained. properties make dataefﬁcient learning complicated. therefore propose relatively lightweight architecture address pixels-to-torques problem data-efﬁcient manner. contribution propose data-efﬁcient model-based algorithm addresses pixelsto-torques problem. devise data-efﬁcient policy learning framework based approach learning predictive models images. state-of-the-art optimization techniques training ddm. model proﬁts concatenation low-dimensional features model dynamical behavior yielding times fewer model parameters faster training time complex architecture practice model requires hours training requires days. introduce novel training objective encourages consistency latent space paving towards accurate long-term predictions. overall efﬁcient model architecture learn tasks complex non-linear dynamics. consider n-step ﬁnite-horizon setting agent attempts solve particular task trial error. particular objective closed-loop policy minimizes denotes immediate cost learning agent faces following additional challenges agent access true state perceives environment high-dimensional pixel information good control policy required trials. setting practically relevant e.g. agent robot monitored video camera based robot learn solve tasks fully autonomously. therefore setting instance pixels-to-torques problem. solve problem three steps detailed following sections using deep auto-encoder architecture high-dimensional pixel information lowdimensional embedding/feature combine features control signal learn predictive model system dynamics predicting future features zt+. form deep dynamical model apply adaptive nonlinear model predictive control strategy optimal closed-loop control end-to-end learning pixels torques. approach solving pixels-to-torques problem based deep dynamical model figure jointly embeds high-dimensional images low-dimensional feature space deep auto-encoders learns predictive forward model feature space based work wahlstr¨om particular consider control signals high-dimensional observations time-step assume relevant properties compactly represented feature variable furthermore reconstructed high-dimensional measurement. components i.e. lowdimensional feature predictive model predicts future features ˆzt+ observations based past observations control signals detailed following sections. elements together construct ddm. architecture takes images input maps low-dimensional features respectively using fenc latent features concatenated together control signal used predict ˆzt+ fpred finally predicted feature ˆzt+ passed decoder network fdec compute predicted image ˆxt+. overall architecture depicted figure neural networks fenc fdec fpred compose parameterized θenc θdec θpred respectively. parameters consist weights perform linear transformations input data neuron. training introduce novel training objective encourages consistency latent space paving toward accurate long-term predictions. speciﬁcally training objective deﬁne following cost functions squared deep auto-encoder reconstruction error squared prediction error operating image space. note ˆxt+ fdec fenc ut)) depends parameters decoder predictive model encoder. additionally introduce enforces consistency latent spaces encoder fenc prediction model fpred. big-data regime additional penalty latent space necessary much data available additional term increases data efﬁciency prediction model forced make predictions ˆzt+ fpred close next embedded feature fenc. overall training objective current dataset given training jointly leads good predictions facilitates extraction separation features describing underlying dynamical system features creating good reconstructions neural networks fenc fdec fpred composed linear layers ﬁrst followed rectiﬁed linear unit activation functions demonstrated relu non-linearities allow network train faster conventional tanh units evaluated cifar- dataset. furthermore similar watter adam train considered state-of-the-art among latest methods stochastic gradient optimization. finally evaluating different weight optimization methods uniform random gaussian weights initialized using orthogonal weight initialization demonstrated efﬁcient training performance leading decoupled weights evolve independently other. objective control system state certain target frame xref without prior knowledge system hand. accomplish learning closed-loop policy means nonlinear model predictive control nmpc ﬁnds optimal sequence control signals minimizes k-step loss function typically smaller full horizon. choose control low-dimensional embedded space reduce complexity control problem. nmpc formulation relies target feature zref allows predict future features. target feature computed encoding target frame zref fenc provided model. further future features predicted based sequence future controls initial encoded features assuming current feature denoted using dynamical model nmpc determines optimal possible results objective zref cost associated deviation predicted features ˆzk− reference feature zref penalizes amplitude control signals. here tuning parameter adjusting importance objectives. control sequence applied system. observing next feature nmpc repeats entire optimization turns overall policy closed-loop control strategy. turn describe adaptive nmpc used together address pixels-to-torques problem learn scratch. core nmpc formulation lies used predict future features sequence control signals. quality nmpc controller inherently bound prediction quality dynamical model typical model-based learn models controllers scratch apply control scheme allows update data arrives. particular nmpc controller adaptive fashion gradually improve model collected data feedback loop without speciﬁc prior knowledge system hand. data collection performed closed-loop divided multiple sequential trials. trial data recent trajectory data model re-trained using data collected far. ence value poor model cannot extrapolate well unseen states. would turn imply data collected unexplored regions including region interested solutions problem either probabilistic dynamical model explicitly account model uncertainty implied natural exploration follow explicit exploration strategy ensure proper excitation system. paper follow latter approach. particular choose \u0001-greedy exploration strategy optimal feedback time step selected probability random action selected probability algorithm summarizes adaptive online nmpc scheme. initialize random trial. learned \u0001-greedy policy using predicted features within nmpc. happens online collected data added data updated trial. section empirically assess components proposed methodology autonomous learning high-dimensional synthetic image data learning underlying dynamics single planar double pendulum. main lines evaluation quality learned overall learning framework. experiments consider following setting take screenshots simulated pendulum system sampling frequency pixel component measurement takes continuous gray-value interval control signals torques applied system. access underlying dynamics state available i.e. dealing high-dimensional continuous time series. challenge data-efﬁciently learn good dynamical model good controller pixel information only. speed training process applied prior model learning pre-processing step reduce dimensionality original problem. inputs -layer auto-encoder employed dimensionality features optimal model periodic angle pendulums. features later passed -layer predictive feedforward neural network generating ˆzt+. furthermore training parameter encouraging consistent latent space predictions experiments. while adaptive nmpc tuning parameter penalizes amplitude control signals ﬁrst experiment evaluates performance planar pendulum assembled -link robot length weight friction coefﬁcient m/rad.the screenshots consist pixels input dimension reduced using pca. inputs processed encoder fenc architecture relu relu low-dimensional features order model periodic angle pendulum. capture dynamic properties angular velocity concatenate consecutive features control signal pass predictive model fpred architecture relu relu note dimensionality ﬁrst layer given finally predicted feature ˆzt+ mapped back ˆxt+ using decoder architecture relu relu performance illustrated figure test data set. shows true images bottom shows ddm’s long-term predictions. model yields good predictive performance onestep ahead prediction multiple-step ahead prediction consequence jointly learning predictor autoencoder concatenating features instead images model dynamic behavior. figure show learned feature space different pendulum angles learned generate features represent angle pendulum mapped circlelike shape accounting wrap-around property angle. finally figure report results learning policy moves pendulum start position upright target position reference signal screenshot pendulum target position. nmpc controller used planning horizon steps control penalty \u0001-greedy exploration strategy used figure shows learning stages system i.e. different trials nmpc controller. starting randomly initialized model images appended dataset trial. seen starting already ﬁrst controlled trial system managed control pendulum successfully bring position less target position. means solution found data efﬁciently especially consider problem learned pixels information without access true state. experiment planar double pendulum considered assembled -link robot length respectively weight friction coefﬁcients m/rad. torques applied joints. screenshots consist pixels input dimension reduced prior model learning using speed figure results learning policy moves single double pendulum systems time-steps. horizontal axis shows learning stages corresponding image frames available learner. vertical axis shows absolute error target state averaged last time steps test trajectory. dashed line shows error indicates good solution. training process. encoder architecture relu relu decoder vice versa. low-dimensional embeddings architecture predictive model relu relu predictive performance shown figure test data set. performance controller depicted figure used trials downward initial position upward target angle inner outer pendulums. ﬁgure shows error trial clearly indicates three controlled trials good solution found brings pendulums within range target angles. despite high complexity dynamical system learning framework manages successfully control pendulums third trial nearly cases. experiments executed employing pilco state policy search method following settings pilco access true state i.e. angle angular velocity deep auto-encoder used learn two-dimensional features images used pilco policy learning. ﬁrst setting pilco managed successfully reach target second third trial experiments respectively. however setting pilco manage learn anything meaningful all. reason pilco could learn auto-encoder features features trained minimize reconstruction error. however auto-encoder attempt similar images similar features zig-zagging around feature space making model learning part feature space incredibly hard modeled controlled equally complex models time requires fewer neural network parameters pre-processing step within reason lies efﬁcient processing dynamics model feature space instead image space. number increases fewer parameters without pre-processing step. number parameters directly translated reduced training time increased data efﬁciency. employing adaptive model predictive control proposed model requires signiﬁcantly less data samples efﬁciently focuses learning latent space towards reference target state. furthermore control performance model gradually improved respect number trials. proved experimental evaluation successfully control complex dynamical system planar double pendulum less samples. adaptive learning approach essential problems time hardware constraints. proposed data-efﬁcient model-based algorithm learns closed-loop policies continuous state action spaces directly pixel information. components solution deep dynamical model used long-term predictions compact feature space novel training objective encourages consistency latent space paving toward accurate long-term predictions nmpc controller uses predictions determine optimal actions without need value function estimation. success algorithm crucial learns feature mapping predictive model feature space jointly capture dynamical behavior high-quality long-term predictions. compared state-of-the-art algorithm learns fairly quickly scales high-dimensional state spaces facilitates learning pixels torques. schmidhuber. on-line algorithm dynamic reinforcement learning planning reactive environments. international joint conference neural networks pages ieee bagnell schneider. autonomous helicopter control using reinforcement learning policy search methods. proceedings ieee international conference robotics automation volume pages vincent hugo bengio p.-a. manzagol. extracting composing robust features denoising autoencoders. international conference machine learning pages isbn ----. todorov generalized iterative method locally-optimal feedback control constrained nonlinear stochastic systems. american control conference pages ieee rumelhart hinton williams. learning internal representations error propagation. rumelhart mcclelland editors parallel distributed processing volume pages press", "year": 2015}