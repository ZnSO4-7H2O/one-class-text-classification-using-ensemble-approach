{"title": "End-to-end Phoneme Sequence Recognition using Convolutional Neural  Networks", "tag": ["cs.LG", "cs.CL", "cs.NE"], "abstract": "Most phoneme recognition state-of-the-art systems rely on a classical neural network classifiers, fed with highly tuned features, such as MFCC or PLP features. Recent advances in ``deep learning'' approaches questioned such systems, but while some attempts were made with simpler features such as spectrograms, state-of-the-art systems still rely on MFCCs. This might be viewed as a kind of failure from deep learning approaches, which are often claimed to have the ability to train with raw signals, alleviating the need of hand-crafted features. In this paper, we investigate a convolutional neural network approach for raw speech signals. While convolutional architectures got tremendous success in computer vision or text processing, they seem to have been let down in the past recent years in the speech processing field. We show that it is possible to learn an end-to-end phoneme sequence classifier system directly from raw signal, with similar performance on the TIMIT and WSJ datasets than existing systems based on MFCC, questioning the need of complex hand-crafted features on large datasets.", "text": "phoneme recognition state-of-the-art systems rely classical neural network classiﬁers highly tuned features mfcc features. recent advances deep learning approaches questioned systems attempts made simpler features spectrograms stateof-the-art systems still rely mfccs. might viewed kind failure deep learning approaches often claimed ability train signals alleviating need hand-crafted features. paper investigate convolutional neural network approach speech signals. convolutional architectures tremendous success computer vision text processing seem past recent years speech processing ﬁeld. show possible learn end-to-end phoneme sequence classiﬁer system directly signal similar performance timit datasets existing systems based mfcc questioning need complex hand-crafted features large datasets. state-of-the-art systems phoneme recognition system tend follow approach task divided several sub-tasks optimized independent manner. ﬁrst step data transformed features usually composed dimensionality reduction phase information selection phase based task-speciﬁc knowledge phenomena. steps carefully hand-crafted leading state-of-the-art features mfccs plps. second step likelihood sub-sequence units estimated using generative discriminative models making several assumptions example units form markov chain. ﬁnal step dynamic programming techniques used recognize sequence constraints. recent advances machine learning made possible systems trained end-toend manner i.e. systems every step learned simultaneously taking account steps ﬁnal task whole system. usually referred deep learning mainly architectures usually composed many layers compared classical shallow systems. opposed divide conquer approaches presented previously deep learning approaches often claimed potential lead optimal systems advantage alleviate need right features given task interest. good success record approaches computer vision text processing ﬁelds speech systems still rely complex features mfccs including recent advanced deep learning approaches contradicts claim techniques end-to-end learning potential. paper propose end-to-end phoneme sequence recognition system taking directly speech signal inputs outputs phoneme sequence. system composed parts convolutional neural networks perform feature learning classiﬁcation stages simple version conditional random field used decoding stage trained end-to-end manner. show system fact lead competitive phoneme recognition systems even trained signals. framework hybrid hmm/ann system compare proposed approach conventional approach extracting spectralbased acoustic feature extraction modeling ann. experimental studies conducted timit corpus show proposed approach yield phoneme recognition system similar better system based conventional approach. remainder paper organized follows. section presents brief survey related literature. section presents classical hmm/ann system. section presents architecture proposed system. section presents experimental setup section presents results discussion. section concludes paper. deep learning architectures successfully applied wide range application characters recognition object recognition natural language processing image classiﬁcation speech ﬁrst phoneme recognition system based neural network time delay neural network extended isolated word recognition time hybrid hmm/ann architecture approach developed leading scalable systems. recently deep belief network approach found yield good performance phone recognition also extend context-dependent phonemes however systems used complex hand-crafted features mfcc. later growing interests using short-term spectrum features. intermediate representations successfully used speech recognition applications example unsupervised feature learning acoustic modeling large vocabulary speech recognition convolutional neural networks also yield stateof-the-art results phoneme recognition although systems able learn efﬁcient representations features still used input hybrid systems. work presented successfully investigates features learning speech phoneme recognition. also features used input different system. finally convolutional neural networks shown capability learning features speech estimate phoneme conditional probabilities single system hybrid hmm/ann system common system phoneme recognition presented figure composed three parts features extraction classiﬁcation decoding. ﬁrst step features extracted signal transformation ﬁltering. common ones frequency cepstrum coefﬁcients perceptual linear prediction usually ﬁrst second derivative representations computed several surrounding frames used additional features. given input artiﬁcial neural network along frames left frames right context. network usually feed-forward composed hidden layer output layer computes conditional probabilities class. probabilities used emission probabilities hidden markov model framework decodes sequence. proposed system composed three stages feature learning stage modeling stage performs classiﬁcation decoding sequence presented figure cnns used ﬁrst stages. convolutional aspect make particularly suitable handling temporal signals speech. moreover addition max-pooling layers classical layers deep architecture brings robustness temporal distortion system helps control network capacity. third stage decoder based crfs proposed learn transition different classes. back-propagation algorithm used training whole system end-to-end manner. network given sequence input signal split frames outputs score classes frame. type network architectures composed several ﬁlter extraction stages followed classiﬁcation stage. ﬁlter extraction stage involves convolutional layer followed temporal pooling layer non-linearity optimal architecture included stages ﬁlter extraction signal coming stages classiﬁcation stage case linear layers large number hidden units. classical linear layers standard mlps accept ﬁxed-size input vector convolution layer assumed sequence vectors/frames xt}. convolutional layer applies linear transformation successive windows frames. transformation frame formally written consider simple version crfs deﬁne graph nodes frame input sequence label. allows discriminatively train simple duration model network output scores. transition scores assigned edges phonemes network output scores assigned nodes. given input data sequence label path graph matrix describing transitions labels network score input class time illustrated figure note approach particular case forward training graph transformer network path score deﬁned number term logadd operation grows exponentially length input sequence. using recursive algorithm logadd computed linear time presented likelihood maximized using stochastic gradient ascent algorithm timit acoustic-phonetic corpus consists training utterances speakers excluding sentences. cross-validation consists utterances speakers. core test used report results. contains utterances speakers excluding validation set. three different sets phoneme used ﬁrst composed phonemes presented second classes last uses classes labels last cases decoding classes mapped phonemes evaluation. corpus selected experiments. contains sequences representing around hours speech. percent taken validation set. selected test set. contains sequences speakers. phoneme sequences extracted transcript segmented using trained gmm. phoneme containing classes used. baseline system standard hmm/ann system features mfcc used. computed using hamming window speech signal shift signal represented using th-order coefﬁcients along ﬁrst second derivatives computed frames context. classiﬁer two-layer mlp. decoding sequence performed standard decoder constrained duration states considering phoneme equally probable. hyper-parameters network input window size corresponding context taken along example number sample example kernel width shift convolutions number ﬁlters dout width hidden layer pooling width. tuned early-stopping cross-validation set. ranges considered grid search reported table worth mentioning given input window size signal size output ﬁlter extraction stage strongly depend number max-pooling layers dividing output size ﬁlter stage chosen pooling kernel width. result adding pooling layers reduces input size classiﬁcation stage returns reduces number parameters network best performance timit corpus cross-validation ﬁrst phoneme found with duration example context frames kernel width frames shift ﬁlters hidden units pooling width. second duration example context frames kernel width frames shift ﬁlters hidden units pooling width. third duration example context frames kernel width frames shift ﬁlters hidden units pooling width. corpus duration example context frames kernel width frames shift ﬁlters hidden units pooling width. baseline early stopping cross-validation also used determine optimal number nodes experiments implemented using torch toolbox results given term phoneme recognition accuracy levenstein distance reference inference phoneme sequence. presented table timit corpus three phoneme sets along number parameters network. comparison purposes accuracy using larger phoneme computed mapping classes ﬁrst phoneme set. proposed system yields better performance baseline timit database. using larger number classes three states phoneme also improves performance. results larger database corpus presented table proposed system also yields similar performances baseline showing scalability capacities. difference systems that proposed system almost prior knowledge data used still achieve similar performances. suggest deep network learn relevant features thus questioning complex hand-crafted features. moreover learning transition phoneme able learn duration model directly training data without external constraints. end-to-end aspect proposed system makes interesting stand-alone implementation phoneme recognizer system takes sequences speech input outputs phoneme paper proposed end-to-end phoneme recognition system able learn feature taking speech data input yield similar performances baseline systems. future work plan improve current system investigating deeper architectures constrained crf. also extend context-dependent phonemes therefore classes might lead better performances table suggests. there focus developing speciﬁc applications spoken term detection. work partly supported hasler foundation grant universal spoken term detection deep learning swiss swiss national center competence research interactive multimodal information management lecun huang bottou learning methods generic object recognition invariance pose lighting proceedings ieee computer society conference computer vision pattern recognition vol. ii–. collobert weston uniﬁed architecture natural language processing deep neural networks multitask learning proceedings international conference machine learning waibel hanazawa hinton shikano lang phoneme recognition using time-delay neural networks acoustics speech signal processing ieee transactions vol. bottou fogelman souli´e blanchet lienard experiments time delay networks dynamic time warping speaker independent isolated digit recognition proceedings eurospeech vol. paris france pham largman unsupervised feature learning audio classiﬁcation using convolutional deep belief networks advances neural information processing systems dahl deng acero context-dependent pre-trained deep neural networks large-vocabulary speech recognition audio speech language processing ieee transactions vol. hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath deep neural networks acoustic modeling speech recognition shared views four research groups signal processing magazine ieee vol. davis mermelstein comparison parametric representations monosyllabic word recognition continuously spoken sentences acoustics speech signal processing ieee transactions vol.", "year": 2013}