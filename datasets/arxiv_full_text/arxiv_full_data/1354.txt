{"title": "Deep Attributes from Context-Aware Regional Neural Codes", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Recently, many researches employ middle-layer output of convolutional neural network models (CNN) as features for different visual recognition tasks. Although promising results have been achieved in some empirical studies, such type of representations still suffer from the well-known issue of semantic gap. This paper proposes so-called deep attribute framework to alleviate this issue from three aspects. First, we introduce object region proposals as intermedia to represent target images, and extract features from region proposals. Second, we study aggregating features from different CNN layers for all region proposals. The aggregation yields a holistic yet compact representation of input images. Results show that cross-region max-pooling of soft-max layer output outperform all other layers. As soft-max layer directly corresponds to semantic concepts, this representation is named \"deep attributes\". Third, we observe that only a small portion of generated regions by object proposals algorithm are correlated to classification target. Therefore, we introduce context-aware region refining algorithm to pick out contextual regions and build context-aware classifiers.  We apply the proposed deep attributes framework for various vision tasks. Extensive experiments are conducted on standard benchmarks for three visual recognition tasks, i.e., image classification, fine-grained recognition and visual instance retrieval. Results show that deep attribute approaches achieve state-of-the-art results, and outperforms existing peer methods with a significant margin, even though some benchmarks have little overlap of concepts with the pre-trained CNN models.", "text": "figure schematic comparison traditional method proposed method models visual recognition tasks. instead representing images neural codes middle-layers adopt semantic neural codes combination region proposals. semantic neural codes different regions aggregating cross-regionpooling. classiﬁer feedback context-aware region reﬁning researches adopt pre-trained models feature extractor various visual recognition tasks like object detection object recognition image retrieval etc. features usually different layer activations outputs. achieve advanced robust performance people either ﬁne-tune pre-trained models tasks make extensively data augmentation robust classiﬁers. developed techniques shown promising results comparison conventional methods using standard feature representations like bag-of-words sparse-coding etc. however limitations kind methods. first neural codes middle-layer difﬁcult explain. second neural code extraction whole image deﬁnitely loss many context information. summarized well-known semantic meanwhile region features appealing recognition task. instance employ mid-level features like contour shape edge shape color texture describe region visual recognition tasks. well known region features naturally preserve mid-level semantic information like materials textures shapes objects however traditional region representations either highly depend segmentation algorithm lack generic semantic representation regions various visual recognition tasks. recently many researches employ middle-layer output convolutional neural network models features different visual recognition tasks. although promising results achieved empirical studies type representations still suffer well-known issue semantic gap. paper proposes so-called deep attribute framework alleviate issue three aspects. first introduce object region proposals intermedia represent target images extract features region proposals. second study aggregating features different layers region proposals. aggregation yields holistic compact representation input images. results show cross-region max-pooling soft-max layer output outperform layers. softmax layer directly corresponds semantic concepts representation named deep attributes. third observe small portion generated regions object proposals algorithm correlated classiﬁcation target. therefore introduce context-aware region reﬁning algorithm pick contextual regions build contextaware classiﬁers. apply proposed deep attributes framework various vision tasks. extensive experiments conducted standard benchmarks three visual recognition tasks i.e. image classiﬁcation ﬁne-grained recognition visual instance retrieval. results show deep attribute approaches achieve state-of-the-art results outperforms existing peer methods signiﬁcant margin even though benchmarks little overlap concepts pre-trained models. since breakthrough work krizhevsky imagenet researches convolutional neural networks exploding. among them ∗this work done ﬁrst author working intern figure flowchart deep attributes. models pre-trained categories ilsvrc. cross-region-pooling performed proposals within image. note features region sparse cross-region-pooling representation portion large elements corresponds context categories. learned classiﬁers relative large value weight coefﬁcients. inspires classiﬁer feedback pick context regions. richness semantics types feature representations paper propose integrate semantic output i.e. output soft-max layer models well region proposals achieve compact effective visual representations namely deep attribute since soft-max layer neural codes probability response categories cnns trained fairly compact semantic sparse insigniﬁcant responses categories. brieﬂy proposed method contains four components. observe small portion region proposals correlated classiﬁcation target thus impose learned classiﬁer feedback pick contextual regions re-pooling context-aware classiﬁer. major difference traditional off-the-shelf methods illustrated figure proposed approach illustrated details figure capture context information related scale also study different pooling layout schemes like multi-scale-pooling spatial pyramid-pooling extensions. demonstrate capacity robustness proposed technique employ deep attributes three visual recognition tasks image classiﬁcation ﬁne-grained object recognition visual instance retrieval. experimental results several standard benchmark datasets show deep attributes achieve state-of-the-arts performance. especially context-aware region reﬁning algorithm clearly outperforms peer methods signiﬁcant margin. summary major contributions paper include propose deep attribute approach visual recognition tasks equipped semantic power outputs pre-trained models well compactness region proposals. experimental results three different visual recognition tasks clearly show superiority proposed method well generalization ability different vision tasks. rest paper ﬁrst give brief survey related works section present details proposed deep attribute approach section section conduct experiments study different aspects setting impact performance algorithm. show experimental results three visual recognition tasks section conclusions discussions given section methods. since breakthrough success models imagenet large scale visual recognition challenge employing models vision tasks becomes popular computer vision community. razavian evaluate performance features several vision tasks including object recognition ﬁne-grained object recognition image retrieval. meanwhile decaf also shows features work surprisingly well image classiﬁcation. subsequently babenko present similar idea image retrieval ﬁne-tuning self-collected datasets improve retrieval accuracy. addition adopt compress neural-codes efﬁcient search. methods adopt neural code activation ﬁrst full-connected layer. attribute methods attribute methods adopt discriminative outputs multi-class classiﬁers mid-level features visual recognition tasks. face recognition kuma consider labels reference faces facecomponents attributes describe faces. farhadi describe objects using explicitly semantic attribute classiﬁers. however remains open challenge exploit discriminative output cnns solve generic vision tasks. pooling strategy pooling general strategy augment features. well known work spatial pyramid matching performs pooling pyramid regular grids gong encodes activations fully connected layer vlad concatenates encoded features windows three scale levels. pooling methods simply concatenate features different grids scales. contrary decision-level cross-region pooling applied multiple region/patch candidates work since semantic output cnns regional features fairly straightforward perform pooling across different region proposals. region proposals methods detecting region proposal used object detection avoid exhaustive sliding window search across images speed detection without noticeable loss recall rates general region proposal detection based low-level features visual cues measure objectness local regions generate relatively fewer candidate windows. past years extensive studies topic many techniques invented including selective search edge-boxes bing multiscale combinatorial grouping recently hosang evaluates region proposal methods selective search edge-boxes achieved consistently better performance terms ground truth recall repeatability detection speed. hence employ produce region proposals ﬁrst step deep attribute method. region proposals extraction advanced techniques like selective search edge-boxes extract semantical regions show satisfactory performance benchmarks computing neural codes region proposals models trained categories ilsvrc produce dimensional semantic output extracted region proposals. computed neural codes serve semantic input next pooling stage. cross-region-pooling make pooling dimension across extracted regions -dimensional holistic representations. different pooling layout schemes applicable possible performance improvement. context-aware region reﬁning classiﬁer build linear classiﬁer trained deep attribute representations visual recognition tasks. observed small portion regions correlated classiﬁcation targets. thus impose classiﬁer feedback pick contextual regions re-pooling context-aware classiﬁer. region proposals extracted region detection algorithms like regions wrapped feed models. region thus represented output soft-max layer k-th dimensional neural code computed neural codes regions aggregated pooling operation construct holistic representation input image pooling could either maxpooling average-pooling. practice maxpooling works better average-pooling pooling region proposals. thus ﬁnal code k-th i={fik}. figure dimension obtained maxn illustrates details pooling scheme. since models trained categories derive dimensional deep attribute pooling procedure. single-scale cross-region-pooling consider layout regions across scales enhance different pooling layout scheme. paper studies layschemes multi-scale pooling scheme spatial pyramid pooling scheme. multi-scale pooling divide regions different scale-interval groups perform pooling regions within group independently concatenate deep attributes group together yielding ﬁnal holistical representation image. particularly scale region deﬁned ratio area proportional area whole image area image bounding available. experiments scale-intervals therefore ﬁnal divides whole image grids make cross-regionsentations. procedure iteratively reﬁne context regions linear classiﬁers. suppose procedure iterations thus classiﬁers intu. howitively directly ﬁnal classiﬁer ever classiﬁer ensemble bring accuracy gains. fuse weight coefﬁcient t-th classiﬁer. empirically estimated grid search crossvalidation manner. since fusion similar boosting give estimation followed adaboost rule section study performance pascal image classiﬁcation benchmark standard protocol. pascal challenging benchmark object recognition. contains images categories including animals handmade objects natural objects. objects different locations scales hourse figure context region illustration. classiﬁcation target green region target region blue region context region regions background clutter/noise regions. region proposal algorithms usually produce thousands regions input images ensure high recall rate certain classiﬁcation task observed extracted regions could divided three categories. first regions directly related classiﬁcation target. second regions viewed useful context information. third regions belong background clutter little relationship classiﬁcation task. instance horse classiﬁcation figure horse region target region human region viewed context region region certainly background noise. improve accuracy maximally exploit context information suppress clutter information. note background clutter regions category speciﬁc. figure classiﬁcation horse region background noise. inspires imposing classiﬁer feedback information pick category-speciﬁc context regions. therefore propose context-aware region reﬁning algorithm based observation. suppose linear classiﬁer trained features cross-region-pooling category given image region proposal algorithm extracted regions region represented semantical neural codes deﬁne score region practice image category rank regions according score pick top-k regions contextual regions apply cross-region-pooling top-k regions holistic representation category separately. reﬁned linear classiﬁer category learned updated reprepaper adopt models trained imagenet dataset contains million images associated semantic categories. make experiments based caffe deep learning framework highlighted make data augmentation all. region feed single center cropping computing neural-codes output. besides ﬁne-tune model given datasets. deep attribute feature extracted process feature rootsift trick normalization linear classiﬁer trained choosing best cost parameter train/val split. ﬁrst compare models alex’s vgg’s several different models public available used layer model. study apply single-scale crossproposal max-pooling without context reﬁning. adopt selective search region proposal generation algorithms. alex’s achieves categories vgg’s achieves map. obvious vgg’s outperforms alex’s margin. consistent factor vgg’s performs better alex’s imagenet. hence adopt vgg’s remaining studies. compare best region proposal generation algorithms according i.e. selective search edge-box figure illustrates recall rate respect number top-regions pascal selective search edge box. graph generated following way. since pascal dataset gives object bounding annotations employ selective search edge-box generate region proposals sort according region scores. then pick topk regions compute intersection-over-union rate using top-k regions ground truth. region counted recall larger changing value graph. graph edge-box works slightly better selective search. single scale vgg’s adopted study max-pooling region aggregation. generated region proposals used cross-region-pooling. selective search achieves edge achieves map. shows edge works slightly better selective search consistent results figure specially edge times faster selective search. therefore adopt edge remaining studies. also compare different pooling schemes. first compare pooling layout schemes cross-proposal maxpooling. single-scale makes cross-region-pooling whole image. spatial-pyramid-pooling divides whole image grids grids plus center grid. makes grid concatenates features grid together. multi-scale-pooling makes different region scales according region size proportion image size. features different scales concatenated together holistic representation. study adopt vgg’s max-pooling. experiments show single-scale achieves spatialpyramid-pooling achieves multi-scale pooling achieves map. hence multi-scale pooling outperforms pooling scheme margin. spatial-pyramid-pooling show advantages multi-scale case take consideration future studies. figure recall rate number regions edgebox selective search. regions opted order scores. comparison accuracy different number region proposals used order region score. single-scale layout multi-scale layout. single-scale case max-pooling achieves average-pooling achieves map. multi-scale case max-pooling achieves average pooling achieves map. means max-pooling worse average-pooling single-scale case better average-pooling multi-scale case. aggregate output soft-max layer crossregion-pooling feature representations. used output layers features? study compare different layers performance cross-region-pooling. figure illustrates results single-scale case multi-scale case. conclude multiscale case max-pooling consistently outperform averagingpooling different layers layer achieves beats layers max-pooling average-pooling; single-scale case max-pooling outperforms averaging-pooling layers except soft-max layer. soft-max layer average-pooling performs best layers case. people doubt whether cross-proposal pooling useful many regions enough? study answer questions. edge-box generate region proposals. pick top-k regions according region score multi-scale cross-region-pooling. different value accuracy results shown figure shows regions better number regions exceed figure combining different layers reﬁning step. global step adopts max-pooling features reﬁning step pool features max-pooling average-pooling. green horizontal line indicate result multi-scale deep attributes without region reﬁning. context-aware region reﬁning need determine parameter number iterations. instead rectly deﬁne context region ratio total number region proposals extracted. figure illustrates curves different different iteration number. shows gives best results. number total regions usually larger means usually context regions picked image category. besides observed iteration context region reﬁning bring accuracy improvement single scale deep attributes bring accuracy improvement multi-scale case iterations bring notable gains. therefore iteration number remaining experiments. using layers reﬁning? table classiﬁcation results comparison state-of-the-art approaches indicates methods ﬁne-tuning dataset. da+fc∗ trained combined training set. study layers reﬁning step. compared da+da da+pool da+fc da+fc da+fc ﬁrst indicates global step item indicates layer used region reﬁning step. also study impact max-pooling average-pooling reﬁning step. figure illustrates comparison results. obvious average-pooling works better maxpooling reﬁning step. different global step. reason global step contains regions contain many background clutter noise regions; reﬁning step noise regions suppressed. also da+fc works best fusion steps still adopted rule given eq.. according previous study ﬁxed parameters proposed framework vgg- model edge-box region extraction multi-scale pooling layout carr step β=.. report results da+fc recognition tasks. of-the-art methods w.r.t category table shows per-category results note listed results da+fc∗ trained combination training listed cnn-related methods training conﬁgurations table benchmarks. method fairly simple without ﬁne-tuning data augmentation. outperforms current state-of-the-art method large margin. specially mention methods here. first very-deep method result verydeep fusion vgg- model vgg- models sophisticated multi-scale multi-crop data augmentation. proposed approach based vgg- model center-crop region proposal inputs yielding margin very-deep. second multiview multi-instance framework takes layers output region proposals feature view ground truth bounding label view combine fisher-vector framework. method achieves accuracy. comparison proposed approach outperforms fv+lv--vd margin using ground-truth bounding-box information without ﬁne-tuning. ﬁne-grained recognition task evaluated oxford ﬂower dataset contains categories ﬂowers. category contains images. ﬂowers appear different scales pose lighting conditions. dataset provides segmentation images. however information experiment. table method comparison pascal benchmarks detailed settings. indicates methods bounding information. specially hcp-c trained categories dataset imagenet. da+fc∗ trained combined training set. benchmark. report mean accuracy oxford ﬂowers dataset table achieve accuracy signiﬁcantly higher existing methods. replacing reﬁning step feature achieved accuracy. note results obtained without using segmentation information ﬁne-tuning networks. interestingly ﬂower dataset little concepts overlap pre-trained category models. visual instance retrieval task evaluated datasets holidays consists vacation photographs distributed among groups based object scene. image selected group acted query image. dataset challenge viewpoint scale variations. university kentucky benchmark dataset includes indoor photographs uniformly objects image used query rest. challenging viewpoint variations. experiment cosine similarity metric. report mean average precision holidays dataset accuracy top- retrieval results dataset according standard evaluation protocol datasets. note task image retrieval require train classiﬁer. adopt single-scale multi-scale max-pooling features retrieval without special tricks. table illustrates comparison results datasets. shows handle semantic global feature representation paper propose deep attribute framework alleviate issue three aspects. first introduce semantic region proposals intermedia represent images. second show aggregating soft-max output region proposals cross-region max-pooling yields best accuracy among different feature layers. soft-max output interpretable compact. third introduce context-aware region reﬁning algorithm pick classiﬁcation target related regions build context-aware classiﬁers. corroborate effectiveness deep attribute generic feature representation various vision tasks. empirical studies show proposed approach outperforms competing methods large margin. reason success least three factors. first region proposals good alignment target objects. second cross-region max-pooling suppress noise regions keep meaningful regions. third context region reﬁning keep highly correlated regions suppress possible background noise regions. deep attributes several good properties. discussion them. first deep attribute representation easily interpreted. backtrack attribute region proposal produce attribute aggregation done maxpooling. also identify discriminant region figure examples discriminative part category shown pascal dataset oxford ﬂower dataset. discriminative part region ﬁres classiﬁer obtained backtracking tricks. second deep attribute applied wide range compute vision tasks. especially even deep attribute obtained model trained imagenet employed tasks fairly different object concepts imagenet. instance experiment grained ﬂower recognition ﬂower dataset little category overlap imagenet categories; well holiday dataset image retrieval task. discussed above figure illustrates discriminative region associated semantic category samples pascal ﬂower datasets. obvious regions pascal samples reﬂect semantic meanings true ﬂower samples. fact pascal semantic concepts overlap imagenet ﬂowers dataset. phenomenon also inspires explore things behind deep attributes. instance many attributes sufﬁcient support generic visual recognition tasks? could minimum supporting attribute visual recognition? future works make exploration third figures extracted deep attribute representation somewhat sparse. could make representation even sparse shrinking deep attribute pre-deﬁned threshold. property extremely useful large-scale vision system sparse representation bring beneﬁts storage execution speed. proved. first large space execution efﬁciency improvement. currently runs image nvidia titan gpu. second accuracy robustness could improved ﬁne-tuning given dataset. interesting future direction design uniﬁed framework consider points together.", "year": 2015}