{"title": "Recent Advances in Zero-shot Recognition", "tag": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "stat.ML"], "abstract": "With the recent renaissance of deep convolution neural networks, encouraging breakthroughs have been achieved on the supervised recognition tasks, where each class has sufficient training data and fully annotated training data. However, to scale the recognition to a large number of classes with few or now training samples for each class remains an unsolved problem. One approach to scaling up the recognition is to develop models capable of recognizing unseen categories without any training instances, or zero-shot recognition/ learning. This article provides a comprehensive review of existing zero-shot recognition techniques covering various aspects ranging from representations of models, and from datasets and evaluation settings. We also overview related recognition tasks including one-shot and open set recognition which can be used as natural extensions of zero-shot recognition when limited number of class samples become available or when zero-shot recognition is implemented in a real-world setting. Importantly, we highlight the limitations of existing approaches and point out future research directions in this existing new research area.", "text": "knowledge across domains tasks distributions similar same. transfer learning refers problem applying knowledge learned auxiliary tasks/domains/sources develop effective model target task/domain. recognize zero-shot categories target domain utilize information learned source domain. unfortunately difﬁcult existing methods domain adaptation directly applied tasks since training instances available target domain. thus challenge learn domain-invariant generalizable feature representation and/or recognition models usable target domain. rest paper organized follows give overview zero-shot recognition sec. semantic representations common models zero-shot recognition reviewed sec. sec. respectively. next discuss recognition tasks beyond zero-shot recognition sec. including generalized zero-shot recognition openset recognition one-shot recognition. commonly used datasets discussed sec. also discuss problems using datasets conduct zero-shot recognition. finally suggest future research directions sec. conclude paper sec. viii. zero-shot recognition used variety research areas neural decoding fmri images face veriﬁcation object recognition video understanding natural language processing tasks identifying classes without observed data called zero-shot learning. speciﬁcally settings zero-shot recognition recognition model leverage training data source/auxiliary dataset/domain identify unseen target/testing dataset/domain. thus main challenge zero-shot recognition generalize recognition models identify novel object categories without accessing labelled instances categories. idea underpinning zero-shot recognition explore exploit knowledge unseen class semantically related seen classes explore relationship seen unseen classes sec. intermediatelevel semantic representations. semantic representation typically encoded high dimensional vector space. common semantic representations include semantic attributes semantic word vectors encoding linguistic context. semantic representation assumed shared auxiliary/source target/test dataset. given pre-deﬁned semantic representation class name abstract—with recent renaissance deep convolution neural networks encouraging breakthroughs achieved supervised recognition tasks class sufﬁcient training data fully annotated training data. however scale recognition large number classes training samples class remains unsolved problem. approach scaling recognition develop models capable recognizing unseen categories without training instances zero-shot recognition/ learning. article provides comprehensive review existing zero-shot recognition techniques covering various aspects ranging representations models datasets evaluation settings. also overview related recognition tasks including one-shot open recognition used natural extensions zeroshot recognition limited number class samples become available zero-shot recognition implemented real-world setting. importantly highlight limitations existing approaches point future research directions existing research area. humans distinguish least basic object categories many subordinate ones also create categories dynamically examples purely based high-level description. contrast existing computer vision techniques require hundreds thousands labelled samples object class order learn recognition model. inspired humans’ ability recognize without seeing examples research area learning learn lifelong learning received increasing interests. studies intelligently apply previously learned knowledge help future recognition tasks. particular major topic research area building recognition models capable recognizing novel visual categories associated labelled training samples training examples recognizing visual categories ‘open-set’ setting testing instance could belong either seen unseen/novel categories. yu-gang jiang school computer science shanghai intelligent information processing fudan university. email ygjfudan.edu.cn; yu-gang jiang corresponding author. semantic representations universal shared exploited knowledge transfer source target datasets order enable recognition novel unseen classes. projection function mapping visual features semantic representations typically learned auxiliary data using embedding model unlabelled target class represented embedding space using class ‘prototype’. projected target instance classiﬁed using recognition model measuring similarity projection class prototypes embedding space additionally open setting test instances could belong either source target categories instances target sets also taken outliers source data; therefore novelty detection needs employed ﬁrst determine whether testing instance manifold source categories; classiﬁed target categories. zero-shot recognition considered type life-long learning. example reading description ‘ﬂightless birds living almost exclusively antarctica’ know recognize referring penguin even though people never seen penguin life. cognitive science studies explain humans able learn concepts extracting intermediate semantic representation high-level descriptions transferring knowledge known sources unknown target reason humans able understand concepts training samples ability termed learning learn. interestingly humans recognize newly created categories examples merely based high-level description e.g. able easily recognize video event named germany world winner celebrations which deﬁnition exist july teach machines recognize numerous visual concepts dynamically created combining multitude existing concepts would require exponential training instances supervised learning approach. such supervised approach would struggle one-off novel concepts germany world winner celebrations because positive video samples would available july germany ﬁnally beat argentina cup. therefore zero-shot recognition crucial recognizing dynamically created novel concepts composed combinations existing concepts. zero-shot learning possible construct classiﬁer germany world winner celebrations transferring knowledge related visual concepts ample training samples e.g. bayern munich champions europe spain world winner celebrations section review semantic representations used zero-shot recognition. representations categorized categories namely semantic attributes beyond. brieﬂy review relevant papers table attribute refers intrinsic characteristic possessed instance class indicates properties annotations image object attributes describe class instance contrast typical classiﬁcation names instance. farhadi learned richer attributes including parts shape materials etc. another commonly used methodology attribute object-based modeling take attribute labels latent variables training dataset e.g. form structured latent model objective minimize prediction loss. attribute description instance category useful semantically meaningful intermediate representation bridging level features high level class concepts attribute learning approaches emerged promising paradigm bridging semantic addressing data sparsity transferring attribute knowledge image video understanding tasks. advantage attribute learning provide intuitive mechanism multi-task learning transfer learning particularly attribute learning enables learning zero instances class attribute sharing i.e. zero-shot one-shot learning. speciﬁcally challenge zero-shot recognition recognize unseen visual object categories without training exemplars unseen class. requires knowledge transfer semantic information auxiliary classes example images unseen target classes. broader sense attribute taken special type subjective visual property indicates task estimating continuous values representing visual properties observed image/video. properties also examples attributes including image/video interestingness memorability aesthetic human-face estimation image interestingness studied gygli showed three cues contribute interestingness aesthetics unusualness/novelty general preferences; last refers fact people general certain types scenes interesting others example outdoornatural indoor-manmade. jiang evaluated different features video interestingness prediction crowdsourced pairwise comparisons. international conference multimedia retrieval published special issue applications multimedia analysis subjective property understanding detection retrieval. subjective visual properties used intermediate representation zero-shot recognition well visual recognition tasks e.g. people recognized description pale skin complexion and/or chubby face looks next subsections brieﬂy review different types attributes. user-deﬁned attributes user-deﬁned attributes deﬁned human experts concept ontology different tasks also necessitate contain distinctive attributes facial clothes attributes attributes biological traits product attributes shape attributes attributes transcend speciﬁc learning tasks typically pre-learned independently across different categories thus allowing transference knowledge essentially attributes either serve intermediate representations knowledge transfer zero-shot one-shot multi-task learning directly employed advanced applications clothes recommendation ferrari studied elementary properties colour and/or geometric pattern. human annotations proposed generative model learning simple color texture attributes. attribute either viewed unary binary ‘unary’ attributes simple attributes whose characteristic properties captured individual image segments contrast ‘binary’ attributes complex attributes whose basic element pair segments relative attributes attributes discussed sinstrength attribute value represent possessed instance/class; indicate properties annotations images objects. contrast relative information form relative attributes used informative express richer semantic meaning thus better represent visual information. relative attributes directly used zero-shot recognition relative attributes ﬁrst proposed order learn ranking function capable predicting relative semantic strength given attribute. annotators give pairwise comparisons images ranking function learned estimate relative attribute values unseen images ranking scores. relative attributes learned form richer representation corresponding strength visual properties used number tasks including visual recognition sparse data interactive image search semi-supervised active learning visual categories. kovashka proposed novel model feedback image search users interactively adjust properties exemplar images using relative attributes order best match his/her ideal queries. extended relative attributes subjective visual properties proposed learning-to-rank model pruning annotation outliers/errors crowdsourced pairwise comparisons. given weakly-supervised pairwise image comparisons singh developed end-toend deep convolutional network simultaneously localize rank relative visual attributes. localization branch adapted spatial transformer network data-driven attributes attributes usually deﬁned extra knowledge either expert users concept ontology. better augment user-deﬁned attributes parikh proposed novel approach actively augment vocabulary attributes help resolve intra-class confusions attributes coordinate name-ability discriminativeness candidate attributes. however user-deﬁned attributes enough model complex visual data. deﬁnition process still either inefﬁcient and/or insufﬁcient tackle problems necessary automatically discover discriminative intermediate representations visual data i.e. data-driven attributes. data-driven attributes used zero-shot recognition tasks despite previous efforts exhaustive space attributes unlikely available expense ontology creation simple fact semantically obvious attributes humans necessarily correspond space detectable discriminative attributes. method collecting labels large scale problems amazon mechanical turk however even excellent quality assurance results collected still exhibit strong label noise. thus label-noise serious issue learning either existing social meta-data. subtly even exhaustive ontology subset concepts ontology likely sufﬁcient annotated training examples portion ontology effectively usable learning much smaller. inspired works automatically mining attributes data. data-driven attributes explored previous works. employed information theoretic approach infer data-driven attributes training examples building framework based latent formulation. directly extended attribute concepts images comparable action attributes order better recognize human actions. attributes used represent human actions videos enable construction descriptive models human action recognition. augmented user-deﬁned attributes data-driven attributes better differentiate existing classes. farhadi also learned user-deﬁned data-driven attributes. attributes separately rather jointly framework. therefore data-driven attributes re-discover patterns exist user-deﬁned attributes. second data-driven attributes mined data know corresponding semantic attribute names discovered attributes. reasons usually data-driven attributes directly used zero-shot learning. limitations inspired works addressed tasks understanding multimedia data sparse incomplete labels. particularly studied videos social group activities proposing novel scalable probabilistic topic model learning semi-latent attribute space. learned multi-modal semi-latent attributes enable multi-task learning one-shot learning zero-shot learning. habibian proposed type video representation learning videostory embedding videos corresponding descriptions. representation also interpreted data-driven attributes. work best paper award multimedia video attributes existing studies attributes focus object classiﬁcation static images. another line work instead investigates attributes deﬁned videos i.e. video attributes important corresponding video related tasks action recognition activity understanding. video attributes correspond wide range visual concepts objects indoor/outdoor scenes actions events compared static image attributes many video attributes computed image sequences complex often involve multiple objects. video attributes closely related video concept detection multimedia community. video concepts video ontology taken video attributes zero-shot recognition. depending ontology models used many approaches video concept detection snoek hauptmann therefore seen addressing sub-task video attribute learning solve zero-shot video event detection. works automatically expand tang enrich video tags given search query. case expanded/enriched tagging space constrained ﬁxed concept ontology large complex example vocabulary space tags semantic entity typically composed multiple concepts/video attributes. example birthday party event consists multiple concepts e.g. blowing candle birthday cake. semantic correlation video concepts also utilized help predict video event interest weakly supervised concepts pairwise relationships concepts general video understanding object scene semantics attributes note full survey recent works zero-shot video event detection beyond scope paper. besides attributes many types semantic representations e.g. semantic word vector concept ontology. representations directly learned textual descriptions categories also investigated wikipedia articles sentence descriptions knowledge graphs concept ontology concept ontology directly used semantic representation alternative attributes. example wordnet widely studied concept ontologies. large-scale semantic ontology built large lexical dataset english. nouns verbs adjectives adverbs grouped sets cognitive synonyms indicate distinct concepts. idea semantic distance deﬁned wordnet ontology also used rohrbach transferring semantic information zero-shot learning problems. thoroughly evaluated many alternatives semantic links between auxiliary target classes exploring linguistic bases wordnet wikipedia yahoo yahoo image flickr image. additionally wordnet used many vision problems. fergus leveraged wordnet ontology hierarchy deﬁne semantic distance categories sharing labels classiﬁcation. costa model exploits co-occurrences visual concepts images knowledge transfer zero-shot recognition. semantic word vectors recently word vector approaches based distributed language representations gained popularity zero-shot recognition user-deﬁned semantic attribute space pre-deﬁned dimension space speciﬁc semantic meaning according either human experts concept ontology contrast semantic word vector space trained linguistic knowledge bases wikipedia umbcwebbase using natural language processing models result although semantic vectors embedding learned known classes novel classes recognized based similarity prototype representations predicted representations instances embedding space. recognition model matches projection image features unseen class prototypes addition discussing models recognition methods sec. iv-a sec. iv-b respectively also discuss potential problems encountered zero-shot recognition models sec. iv-c. bayesian models embedding models learned using bayesian formulation enables easy integration prior knowledge type attribute compensate limited supervision novel classes image video understanding. generative model ﬁrst proposed ferrari zisserman learning simple color texture attributes. lampert ﬁrst study problem object recognition categories training examples available. direct attribute prediction indirect attribute prediction ﬁrst models zeroshot recognition algorithms single model ﬁrst learns embedding using support vector machine recognition using bayesian formulation. inspired later works employ generative models learn embedding including topic models random forests brieﬂy describe models follows model. assume relation known classes unseen classes descriptive attributes given matrix binary associations values matrix encodes presence/absence attribute given class. extra knowledge applied deﬁne association matrix instance leveraging human experts consulting concept ontology semantic relatedness measured class attribute concepts training stage attribute classiﬁers trained attribute annotations known classes test stage posterior probability inferred individual attribute image predict class label object class model. model directly learns attribute classiﬁers known classes model builds attribute classiﬁers combining probabilities associated known classes. also introduced direct similarity-based model rohrbach training step learn probabilistic multiclass classiﬁer estimate training classes relative positions different visual concepts semantic meaning e.g. would closer sofa dimension space speciﬁc semantic meaning. language model used project class’ textual name space. projections used prototypes zero-shot learning. socher learned neural network model embed image -dimensional word vector semantic space obtained using unsupervised linguistic model trained wikipedia text. images either known unknown classes could mapped word vectors classiﬁed ﬁnding closest prototypical linguistic word semantic space. distributed semantic word vectors widely used zero-shot recognition. skip-gram model cbow model trained large scale text corpora construct semantic word space. different unsupervised linguistic model distributed word vector representations facilitate modeling syntactic semantic regularities language enable vector-oriented reasoning vector arithmetics. example much closer +vec semantic space. possible explanation intuition underlying syntactic semantic regularities distributional hypothesis states word’s meaning captured words cooccur frome scaled ideas recognize large-scale datasets. proposed deep visualsemantic embedding model images rich semantic embedding space large-scale zero-shot recognition. showed reasoning could used synthesize different label combination prototypes semantic space thus crucial multi-label zero-shot learning. recent work using semantic word embedding includes interestingly vector arithmetics semantic emotion word vectors matching psychological theories emotion ekman’s pan-cultural basic emotions plutchik’s emotion. example close vec; close vec. since usually thousands words describe emotions zero-shot emotion recognition also investigated help semantic representations zero-shot recognition usually solved ﬁrst learning embedding model recognition best knowledge general ‘embedding’ formulation zero-shot recognition ﬁrst introduced larochelle embedded handwritten character typed representation helped recognize unseen classes. semantic embedding semantic embedding learns mapping visual feature space semantic space various semantic representations. discussed sec. iii-a attributes introduced describe objects; learned attributes optimal recognition tasks. akata proposed idea label embedding takes attribute-based image classiﬁcation label-embedding problem minimising compatibility function image label embedding. work modiﬁed ranking objective function derived wsabie model object-level attributes suffer problems partial occlusions scale changes images proposed learning extracting attributes segments containing entire object; joint learning simultaneous object classiﬁcation segment proposal ranking attributes. thus learned embedding max-margin empirical risk class label well segmentation quality. semantic embedding algorithms also investigated semi-supervised max-margin learning framework latent multi-task learning embedding common spaces besides semantic embedding relationship visual semantic space learned jointly exploring exploiting common intermediate space. extensive efforts made towards direction. akata learned joint embedding semantic space attributes text hierarchical relationships. employed text features predict output weights convolutional fully connected layers deep convolutional neural network dataset exist many different types semantic representations. type representation contain complementary information. fusing potentially improve recognition performance. thus several recent works studied different methods multi-view embedding. employed semantic class label graph fuse scores different semantic representations. similarly label relation graphs also studied signiﬁcantly improved large-scale object classiﬁcation supervised zero-shot recognition scenarios. number successful approaches learning semantic embedding space reply canonical component analysis hardoon proposed general kernel method learning semantic embedding images associated text. embedding enables direct comparison text images. many works focused modeling images/videos associated text multi-view often exploited provide unsupervised fusion different modalities. gong also investigated problem modeling internet images associated text tags proposed three-view embedding framework retrieval tasks. additional view allows framework outperform number two-view baselines retrieval tasks. proposed embedding model jointly exploring functional relationships text image features transferring inter-model intra-model labels help annotate images. inter-modal label transfer generalized zero-shot recognition. deep embedding recent zero-shot recognition models rely state-of-the-art deep convolutional models extract image features. ﬁrst works devise extended deep architecture learn visual semantic embedding; identify visual objects using labeled image data well semantic information gleaned unannotated text. conse constructed image embedding approach mapping images semantic embedding space convex combination class label embedding vectors. devise conse evaluated large-scale datasets imagenet imagenet dataset. combine visual textual branches deep embedding different loss functions considered including margin-based losses euclidean distance loss least square loss zhang employed visual space embedding space proposed endto-end deep learning architecture zero-shot recognition. networks branches visual encoding branch uses convolutional neural network encode input image feature vector semantic embedding branch encodes input semantic representation vector class corresponding image belonging embedding model learned testing instances projected embedding space. recognition carried using different recognition models. common used nearest neighbour classiﬁer classify testing instances assigning class label term nearest distances class prototypes projections testing instances embedding space. proposed semi-latent zero-shot learning algorithm update class prototypes step self-training. manifold information used recognition models embedding space. proposed hypergraph structure multi-view embedding space; zero-shot recognition addressed label propagation unseen prototype instances unseen testing instances. changpinyo synthesized classiﬁers embedding space zero-shot recognition. multi-label zeroshot learning recognition models consider cooccurrence/correlations different semantic labels latent structure also used recognition models wang treated object attributes latent variables learnt correlations attributes undirected graphical model. hwang utilized kernelized multi-task feature learning framework learn sharing features objects presence ‘universal’ neighbors hubs space. radovanovic ﬁrst study hubness problem; hypothesis made hubness inherent property data distributions high dimensional vector space. nevertheless challenged hypothesis showed evidence hubness rather boundary effect generally effect density gradient process data generation. interestingly experiments showed hubness phenomenon also occur low-dimensional data. causes hubness still investigation recent works noticed regression based zero-shot learning methods suffer problem. alleviate problem dinu utilized global distribution feature instances unseen data i.e. transductive manner. contrast yutaro addressed problem inductive embedding class prototypes visual feature space. conventional supervised learning tasks taken granted algorithms take form closed testing classes known training time. zero-shot recognition contrast assumes source target classes cannot mixed; testing data coming unseen classes. assumption course greatly unrealistically simpliﬁes recognition tasks. relax settings zero-shot recognition investigate recognition tasks generic setting several tasks advocated beyond conventional zero-shot recognition. particular generalized zero-shot recognition open recognition tasks discussed recently generalized zero-shot recognition proposed broke restricted nature conventional zero-shot recognition also included training classes among testing data. chao showed nontrivial ineffective directly extend current zero-shot learning approaches solve generalized zero-shot recognition. generalized setting practical nature recommended evaluation settings zero-shot recognition tasks open-set recognition contrast developed independently zero-shot recognition. initially open recognition aimed breaking limitation closed recognition setup. speciﬁcally task open recognition tries identify class name image large classes includes limited training classes. open recognition roughly divided subgroups. conventional open recognition first formulated conventional open recognition identiﬁes whether testing images come training classes unseen classes. category methods explicitly predict unseen fig. illustrating projection domain shift problem. zero-shot prototypes annotated stars predicted semantic attribute projections shown blue. zebra share ‘hastail’ attribute different visual appearance ‘tail’. ﬁgure comes attributes. additionally long employed attributes synthesize unseen visual features training stage; thus zero-shot recognition solved conventional supervised classiﬁcation models. projection domain shift problems projection domain shift problem zero-shot recognition ﬁrst identiﬁed problem explained follows since source target datasets different classes underlying data distribution classes also differ. projection functions learned source dataset visual space embedding space without adaptation target dataset cause unknown shift/bias. figure gives intuitive illustration problem. plots attribute space representation spanned feature projections learned source data class prototypes binary attribute vectors. zebra auxiliary target classes respectively; ’hastail’ semantic attribute means different visual appearance zebra. attribute space directly using projection functions learned source datasets target datasets lead large discrepancy class prototype target class predicted semantic attribute projections. alleviate problem transductive learning based approaches proposed utilize manifold information instances unseen classes nevertheless transductive setting assumes testing data accessed once obviously invalid unseen classes appear dynamically unavailable learning models. thus inductive learning base approaches also studied methods usually enforce additional constraints information training data. generalized open recognition difference conventional open recognition generalized open recognition also needs explicitly predict semantic meaning testing instances even unseen novel classes. task ﬁrst deﬁned evaluated tasks object categorization. generalized open recognition taken general version zero-shot recognition classiﬁers trained training instances limited training classes whilst learned classiﬁers required classify testing instances large open vocabulary class vocabulary conceptually similar vast variants generalized open-set recognition tasks studied research community open-vocabulary object retrieval open-world person re-identiﬁcation searching targets open vocabulary scene parsing closely-related problem zero-shot learning one-shot few-shot learning problem instead of/apart textual description classes one-shot learning assumes training samples class. similar zero-shot recognition one-shot recognition inspired fact humans able learn object categories examples existing one-shot learning approaches divided groups direct supervised learning based approaches transfer learning based approaches. direct supervised learning-based approaches early approaches assume exist auxiliary classes related and/or ample training samples whereby transferable knowledge extracted compensate lack training samples. instead target classes used trained standard classiﬁer using supervised learning. simplest method employ nonparametric models restricted number training samples. however without learning distance metric used often inaccurate. overcome problem metric embedding learned used classiﬁcation approaches attempt synthesize training samples augment small training dataset however without knowledge transfer classes performance direct supervised learning based approaches typically weak. importantly models cannot meet requirement lifelong learning unseen classes added learned classiﬁer still able recognize seen existing classes. transfer learning-based one-shot recognition category approaches follow similar setting zero-shot learning assume auxiliary training data different classes exist. explore paradigm learning learn meta-learning transfer knowledge auxiliary dataset target dataset examples class. approaches differ knowledge transferred knowledge represented. speciﬁcally knowledge extracted shared form model prior generative model features semantic attributes contextual information many approaches take similar strategy existing zero-shot learning approaches transfer knowledge shared embedding space. embedding space typically formulated using neural networks discriminative metric learning kernel embedding methods. particularly common embedding ways semantic embedding normally explored projecting visual features semantic entities common space. projections take various forms corresponding loss functions wsabie devise recently deep meta-learning received increasing attention few-shot learning wang proposed idea one-shot adaptation automatically learning generic category agnostic transformation models learned samples models learned large enough sample sets. model-agnostic meta-learning framework proposed finn trains deep model auxiliary dataset objective learned model effectively updated/ﬁne-tuned classes gradient steps. note similar generalised zero-shot learning setting recently problem adding classes deep neural network whilst keeping ability recognise classes attempted however problem lifelong learning progressively adding classes few-shot remains unsolved problem. section summarizes datasets used zero-shot recognition. recently increasing number proposed zero-shot recognition algorithms xian compared analyzed signiﬁcant number state-of-the-art methods depth deﬁned benchmark unifying evaluation protocols data splits. details datasets listed tab. animal attribute dataset consists osher-son/kemp animal category images collected online. images least examples class. seven different feature types provided color histograms sift rgsift phog surf local self-similarity histograms decaf dataset deﬁnes classes animals associated attributes consistent evaluation attribute-based object classiﬁcation methods dataset deﬁned test classes chimpanzee giant panda hippopotamus humpback whale leopard raccoon seal. images classes taken test data whereas images remaining classes used training. since images available public license xian introduced another zero-shot learning dataset animals attributes dataset publicly licensed released images classes attributes awa. apascal-ayahoo dataset apascal-ayahoo -image subset pascal data object classes images collected using yahoo image search engine object classes. image data annotated binary attributes characterize visible objects. cub-- dataset cub-- contains images bird classes. challenging dataset designed ﬁne-grained recognition classes fewer images. images annotated bounding boxes part locations attribute labels. images annotations ﬁltered multiple users amazon mechanical turk. cub-- used benchmarks dataset multi-class categorization part localization. class annotated binary attributes derived bird species ontology. typical setting classes auxiliary data holding target data setting adopted akata outdoor scene recognition dataset consists images categories attributes average labelled pairs attribute training images. graphs constructed thus extremely sparse. pairwise attribute annotation collected pair labelled workers average comparisons majority voting. image also belongs scene type. public figure face database pubfig large face dataset images people collected internet. parikh selected subset pubfig consisting images people attributes annotate subset pubfig-sub. pairwise attribute annotation collected amazon mechanical turk pair labelled workers. total training images pubfig-sub respectively labelled. average number compared pairs attribute attribute dataset subset database ﬁne-grained scene categorization images classes image annotated binary attributes describe scenes’ material surface properties well lighting conditions functions affordances general image layout. unstructured social activity attribute dataset usaa ﬁrst benchmark video attribute dataset social activity video classiﬁcation annotation. groundtruth attributes annotated semantic class videos columbia consumer video dataset select videos per-class training testing respectively. classes selected complex social group activities. referring existing work video ontology attributes divided broad classes actions objects scenes sounds camera movement. directly using ground-truth attributes input videos come classiﬁcation accuracy. illustrates challenge usaa dataset attributes informative sufﬁcient intra-class variability attribute-space even perfect knowledge instance-level attributes also insufﬁcient perfect classiﬁcation. imagenet datasets imagenet used several different papers relatively different settings. original imagenet dataset proposed full imagenet contains million labeled high-resolution images belonging roughly categories labelled human annotators using amazon’s mechanical turk crowd-sourcing tool. starting part pascal visual object challenge annual competition called imagenet large-scale visual recognition challenge held. ilsvrc uses subset imagenet roughly images categories. robhrbach split ilsvrc data classes source/target data. employed training data ilsvrc source data; testing part ilsvrc well data ilsvrc target data. full sized imagenet data used oxford flower dataset oxford collection groups ﬂowers ﬂower images total images total. ﬂowers chosen common ﬂower species united kingdom. elhoseiny generated textual descriptions class dataset. dataset another popular benchmark human action recognition videos consists video clips annotated classes. recently thumos- action recognition challenge created benchmark extending upon ucf- dataset additional videos collected internet including background videos validation test videos. fcvid contains videos annotated manually categories. categories cover wide range topics social events procedural events object appearances scenic videos standard split consists videos training videos testing. activitynet dataset activitynet another largescale video dataset human activity recognition understanding released consisted video clips annotated activity classes totaling hours video. comparing existing dataset activitynet ﬁne-grained action categories activitynet settings trimmed untrimmed videos classes. tab. roughly divide datasets three groups general image classiﬁcation ﬁne-grained image classiﬁcation video classiﬁcation datasets. datasets employed widely benchmark datasets many previous works. however believe making comparison existing methods datasets several issues discussed. features renaissance deep convolutional neural networks deep features images/videos used zero-shot recognition. note different types deep features vgg- resnet varying level semantic abstraction representation ability; even type deep features ﬁne-tuned different dataset slightly different parameters also different representative ability. thus obvious without using type features possible conduct fair comparisons among different methods draw meaningful conclusion. importantly improved performance zero shot recognition could largely attributed better deep features used. auxiliary data mentioned zero-shot recognition formulated transfer learning setting. size quality auxiliary data important overall performance zero-shot recognition. note auxiliary data include auxiliary source image/video dataset also refer data extract/train concept ontology semantic word vectors. example semantic word vectors trained large-scale linguistic articles general better semantically distributed trained small sized linguistic corpus. similarly glove reported better skip-gram cbow models therefore make fair comparison existing works another important factor auxiliary data. generalized realistic setting detailed review existing zero-shot learning methods clear overall existing efforts focused rather restrictive impractical setting classiﬁcation required object classes unseen classes though training sample present assumed known. reality wants progressively classes existing classes. importantly needs achieved without jeopardizing ability model recognize existing seen classes. furthermore cannot assume samples come known unseen classes. rather assumed belong either existing seen classes known unseen classes unknown unseen classes. therefore foresee generalized setting adopted future zero-shot learning work. combining zero-shot few-shot learning mentioned earlier problems zero-shot few-shot learning closely related result many existing methods similar models. however somewhat surprising note serious efforts taken address problems jointly. particular zero-shot learning would typically consider possibility training samples few-shot learning ignores fact textual description/human knowledge class always exploited. existing zeroshot learning methods included few-shot learning experiments. however typically naive approach class prototype treated training sample together k-shot becomes k+-shot recognition problem. however shown existing zero-shot learning methods prototype worth training sample; thus treated differently. thus expect future direction extending existing few-shot learning methods incorporating prototype ‘super’-shot improve model learning. beyond object categories current zero-shot learning efforts limited recognizing object categories. however visual concepts complicated relationships object categories. particular beyond objects/nouns attributes/adjectives important visual concepts. combined objects attribute often different meaning e.g. concept ‘yellow’ yellow face yellow banana clearly differs. zero-shot learning attributes associated objects thus interesting future research direction. curriculum learning lifelong learning setting model incrementally learn recognise classes whilst keep capacity existing classes. related problem thus select suitable classes learn given existing classes. shown sequence adding different classes clear impact model performance. therefore useful investigate incorporate curriculum learning principles designing zero-shot learning strategy. paper reviewed recent advances zero shot recognition. firstly different types semantic representations examined compared; models used zero shot learning also investigated. next beyond zero shot recognition one-shot open recognition identiﬁed important related topics thus reviewed. finally common used datasets zero-shot recognition reviewed number issues existing evaluations zero-shot recognition methods discussed. also point number research direction believe focus future zero-shot recognition studies. pentina lampert pac-bayesian bound lifelong learning international conference machine learning thrun mitchell lifelong robot learning robotics kumar berg belhumeur nayar attribute simile classiﬁers face veriﬁcation iccv vi-a lampert nickisch harmeling attribute-based classiﬁcation zero-shot visual object categorization ieee tpami iii-a iii-a iii-a iv-a farhadi endres hoiem forsyth describing objects attributes cvpr iii-a iii-a iii-a vi-a wang zhang clothes search consumer photos color matching attribute learning international conference multimedia available http//doi.acm.org/./ iii-a iii-a iii-a salakhutdinov torralba tenenbaum learning share visual appearance multiclass object detection ieee conference computer vision pattern recognition iii-a kovashka parikh grauman whittlesearch image search relative attribute feedback ieee conference computer vision pattern recognition iii-a iii-a iii-a vi-a vi-a dhar ordonez berg high level describable attributes predicting aesthetics interestingness ieee conference computer vision pattern recognition iii-a ehrlich shields almaev amer facial attributes classiﬁcation using multi-task representation learning proceedings ieee conference computer vision pattern recognition workshops iii-a iii-a vaquero feris tran brown hampapur turk attribute-based people search surveillance environments ieee workshop applications computer vision dec. iii-a iii-a parikh grauman interactively building discriminative vocabulary nameable attributes ieee conference computer vision pattern recognition iii-a iii-a tang hong g.-j. t.-s. chua inferring semantic concepts community-contributed images noisy tags international conference multimedia available http//doi.acm.org/./. iii-a iii-a hauptmann w.-h. christel wactlar high-level concepts semantic video retrieval? case study broadcast news ieee transactions multimedia vol. aug. iii-a iii-a toderici aradhye pasca sbaiz yagnik finding meaning youtube recommendation category discovery ieee conference computer vision pattern recognition iii-a iii-a tang x.-s. wang g.-j. correlative linear neighborhood propagation video annotation ieee transactions systems cybernetics part vol. iii-a iii-a g.-j. x.-s. tang h.-j. zhang correlative multi-label video annotation international conference multimedia available http//doi.acm. org/./. iii-a mensink gavves snoek costa co-occurrence statistics zero-shot classiﬁcation ieee conference computer vision pattern recognition iii-a iii-b iv-b norouzi mikolov bengio singer shlens frome corrado dean zero-shot learning convex combination semantic embeddings iclr iii-a iii-b iv-a vi-a zhang saligrama zero-shot learning joint latent simi huang socher manning improving word representations global context multiple word prototypes association computational linguistics conference iii-a iii-b wang chen shao beyond semantic attributes discrete latent attributes learning zero-shot recognition ieee signal processing letters vol. iii-a elhoseiny saleh elgammal write classiﬁer zeroshot learning using purely textual descriptions ieee international conference computer vision december iii-b vi-a mikolov chen corrado dean efﬁcient estimation word representation vector space proceedings workshop international conference learning representations iii-b mikolov sutskever chen corrado dean distributed representations words phrases compositionality neural information processing systems iii-b vi-b mahajan sellamanickam nair joint learning framework attribute models object descriptions ieee international conference computer vision iv-a xiang kodirov gong zero-shot object recognition socher fei-fei connecting modalities semi-supervised segmentation annotation images using unaligned text corpora ieee conference computer vision pattern recognition iv-a dinu lazaridou baroni improving zero-shot learning mitigating hubness problem iclr workshop iv-c shigeto suzuki hara shimbo matsumoto ridge regression hubness zero-shot learning ecml/pkdd iv-c guadarrama rodner saenko darrell understanding object descriptions robotics open-vocabulary object retrieval detection journal international journal robotics research bart ullman cross-generalization learning novel classes single example feature replacement cvpr hertz hillel weinshall learning kernel function quattoni collins darrell transfer learning image classiﬁcation sparse prototype representations ieee conference computer vision pattern recognition fink object classiﬁcation single example utilizing class finn abbeel levine model-agnostic meta-learning fast adaptation deep networks proceedings international conference machine learning ser. proceedings machine learning research precup eds. vol. international convention centre sydney australia pmlr available http//proceedings.mlr.press/v/ﬁnna.html donahue vinyals hoffman zhang tzeng darrell decaf deep convolutional activation feature generic visual recognition international conference machine learning vi-a patterson hays attribute database discovering annotating recognizing scene attributes. ieee conference computer vision pattern recognition vi-a y.-g. jiang s.-f. chang ellis loui consumer video understanding benchmark database evaluation human machine performance international conference multimedia retrieval vi-a z.-j. wang x.-s. building comprehensive ontology reﬁne video concept detection proceedings international workshop workshop multimedia information retrieval ser. york available http//doi.acm.org/./. vi-a m.-e. nilsback zisserman automated ﬂower classiﬁcation large number classes proceedings indian conference computer vision graphics image processing vi-a idrees zamir y.-g. jiang gorban laptev sukthankar shah thumos challenge action recognition videos wild\" computer vision image understanding vi-a yanwei received degree information computing sciences nanjing university technology meng degree department computer science technology nanjing university china. pursuing vision group eecs queen mary university london. research interest attribute learning topic model learning rank video summarization image segmentation. shaogang gong received dphil degree keble college oxford university. professor visual computation queen mary university lonsince fellow institution electrical engineers fellow british computer society. research interests include computer vision machine learning video analysis. xiang received ph.d. degree electrical computer engineering national university singapore currently reader school electronic engineering computer science queen mary university london. research interests include computer vision machine learning data mining. published papers international journals conferences. leonid sigal associate professor university british columbia. prior senior research scientist disney research. completed ph.d. brown university received m.a. boston university m.sc. brown university leonid’s research interests areas computer vision machine learning computer graphics. leonid’s research emphasis machine learning statistical approaches visual recognition understanding analytics. published papers venues journals ﬁelds yu-gang jiang professor school computer science fudan university china. video data analytics conducts research aspects extracting high-level information video data video event recognition object/scene recognition large-scale visual search. work many awards including inaugural china rising star award sigmm rising star award. xiangyang xiangyang received b.s. m.s. ph.d. degrees communication engineering xidian university xi’an china respectively. currently professor computer science fudan university shanghai china. research interests include multimedia information processing machine learning.", "year": 2017}