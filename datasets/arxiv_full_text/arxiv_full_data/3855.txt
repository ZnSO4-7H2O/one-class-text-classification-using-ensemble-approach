{"title": "Learning with Latent Language", "tag": ["cs.CL", "cs.NE"], "abstract": "The named concepts and compositional operators present in natural language provide a rich source of information about the kinds of abstractions humans use to navigate the world. Can this linguistic background knowledge improve the generality and efficiency of learned classifiers and control policies? This paper aims to show that using the space of natural language strings as a parameter space is an effective way to capture natural task structure. In a pretraining phase, we learn a language interpretation model that transforms inputs (e.g. images) into outputs (e.g. labels) given natural language descriptions. To learn a new concept (e.g. a classifier), we search directly in the space of descriptions to minimize the interpreter's loss on training examples. Crucially, our models do not require language data to learn these concepts: language is used only in pretraining to impose structure on subsequent learning. Results on image classification, text editing, and reinforcement learning show that, in all settings, models with a linguistic parameterization outperform those without.", "text": "figure example approach binary image classiﬁcation task. assume access pretrained language interpretation model outputs probability image matches given description. learn visual concept search space natural language descriptions maximize interpretation model’s score chosen description used interpretation model classify images language provide useful scaffold acquiring speciﬁcally propose language latent parameter space few-shot learning problems kinds including classiﬁcation transduction policy search. show linguistic parameterization produces models accurate interpretable direct approaches few-shot learning. frameworks multitaskmeta-learning approach consists three phases pretraining phase concept-learning phase evaluation phase. here product pretraining language interpretation model maps descriptions predictors thesis language learning powerful generalpurpose kind pretraining even tasks directly involve language. concepts learned searching directly space natural language strings minimize loss incurred language interpretation model especially tasks require named concepts compositional operators present natural language provide rich source information kinds abstractions humans navigate world. linguistic background knowledge improve generality efﬁciency learned classiﬁers control policies? paper aims show using space natural language strings parameter space effective capture natural task structure. pretraining phase learn language interpretation model transforms inputs outputs given natural language descriptions. learn concept search directly space descriptions minimize interpreter’s loss training examples. crucially models require language data learn concepts language used pretraining impose structure subsequent learning. results image classiﬁcation text editing reinforcement learning show that settings models linguistic parameterization outperform without. structure natural language reﬂects structure world. example fact easy communicate concept left circle comparatively difﬁcult communicate mean saturation ﬁrst pixels third column reveals something kinds abstractions useful interpreting navigating environment machine learning efﬁcient automatic discovery reusable abstract structure remains major challenge. paper investigates whether background knowledge figure formulation learning problem. ultimately care model’s ability learn concept small number training examples successfully generalize held-out data paper concept learning supported language learning phase makes natural language annotations learning problems. annotations provided real target task learner successfully model high-level compositional structure shared training examples natural language hypotheses serve threefold purpose make easier discover compositional concepts harder overﬁt examples easier understand inferred patterns. approach implemented using standard neural components simple general. variety settings structure imposed natural-language parameterization helpful efﬁcient learning exploration. approach outperforms multitaskmeta-learning approaches directly training examples outputs realvalued parameterization well approaches make natural language annotations additional supervisory signal rather explicit latent parameter. natural language concept descriptions inferred approach often agree human annotations correct provide interpretable debugging signal incorrect. short equipping models ability think loud learning become comprehensible accurate. present work particularly interested few-shot learning problems number pairs small—on order examples. conditions directly solving equation risky proposition—any model class powerful enough capture true relation inputs outputs also likely overﬁt. few-shot learning successful extra structure must supplied learning algorithm. existing approaches obtain structure either carefully structuring hypothesis space providing learning algorithm additional kinds training data. approach present paper combines elements both begin review existing work. program synthesis approaches reduce effective size parameter space moving optimization problem continuous space weight vectors discrete space formal program descriptors domain-speciﬁc structure like version space algebras type systems brought bear search problem bias inherent syntax formal language provides strong prior. program synthesis techniques powerful also limited application human designer must hand-engineer computational primitives necessary compactly describe every learnable hypothesis. reasonable applications challenging impossible others alternative class multitask learning approaches attempt import relevant structure learning problems rather deﬁning manually since know priori learning problems approaches discrete rich compositional operators comes equipped natural description length prior. also considerably ﬂexible semantics. crucially plentiful annotated data exists learning semantics cannot hand-write computer program recognize small learn image captions. basically primitive operators available language provides strong prior kinds abstractions useful natural learning problems. concretely replace pretraining phase language-learning phase. assume language-learning time additionally access natural-language descriptions parameters place task-speciﬁc parameters θ—that learn language interpretation model uses weights turn description function inputs outputs. example figure might image rating model outputs scalar judgment well image matches caption last step presents something challenge. solving corresponding optimization problem synthesis techniques exploit algebraic structure formal language end-to-end learning approaches take advantage differentiability. can’t either—the language strings discrete whatever structure interpretation function wrapped inside black inspired related techniques aimed making synthesis efﬁcient work interested developing learning method enjoys beneﬁts approaches. particular seek intermediate language task representations that like program synthesis expressive compact like multitask approaches learnable directly training data without domain engineering. propose natural language intermediate representation. call approach learning latent language maxλ approximation distribution descriptions given task data. running example proposal distribution essentially image captioning model sampling expect obtain candidate descriptions likely obtain small loss. ultimate inference criterion still true model evaluation time perform minimization equation drawing ﬁxed number samples selecting hypothesis obtains lowest loss using make predictions. described generic procedure equipping collections related learning problems natural language hypothesis space. sections describe procedure turned concrete algorithm supervised classiﬁcation sequence prediction. section describe extend techniques reinforcement learning. figure few-shot image classiﬁcation task. learners shown four positive examples visual concept must determine whether ﬁfth image matches pattern natural language annotations provided language learning must inferred concept learning. classiﬁcation. focus visual reasoning tasks like shown figure problems learner presented four images positive examples visual concept like blue shape near yellow triangle must decide whether ﬁfth held-out image matches concept. kinds visual reasoning problems well-studied visual question answering settings version problem input output feature text data natural language explanation must inferred similar spirit battery visual reasoning problems proposed raven bongard apply recipe section need specify implementation interpretation model proposal model begin computing representations input images start pre-trained -layer vggnet spatial information important tasks extract feature representation ﬁnal convolutional layer network. initial featurization passed fully-connected layers form ﬁnal image representation follows interpretation model outputs probability assigned positive class label trained maximize log-likelihood. positive examples provided language learning proposal model deﬁned terms inputs alone. details regarding training hyperparameters implementations etc. found appendix evaluation aims answer questions. first addition language learning process provide beneﬁt ordinary multitask meta-learning? second speciﬁcally better language hypothesis space concept report results dataset derived shapeworld corpus kuhnle copestake dataset held-out image matches target concept time. validation test folds half learning problems feature concept also appears language learning half feature images concept. images feature three distractor shapes unrelated objects deﬁne target concept. captions dataset generated dmrs representations using grammar dataset contains total pretraining tasks validation test tasks. dataset statistics provided appendix seen provides consistent improvements baselines improvements present identifying instances previouslylearned concepts discovering ones. example model predictions shown figure model often succeeds making correct predictions even though inferred descriptions rarely match ground truth. sometimes inherent ambiguity description many state-of-the-art approaches meta-learning classiﬁcation well-deﬁned possibly-overlapping evaluation classes positive examples provideded. attempted provide robust implementation close possible systems evaluation. table denote subsets validation contain previously-used novel visual concepts respectively. consistently outperforms alternative learning methods based multitask learning metalearning meta-learning jointly trained predict descriptions last table shows results model given ground-truth concept description rather infer examples. figure example predictions image classiﬁcation. model achieves high accuracy even though predicted descriptions rarely match ground truth. high-level structure like presence certain shapes spatial relations consistently recovered. best viewed color. next explore whether technique applied tasks involve binary similarity judgments. focus structured prediction speciﬁcally family string processing tasks. tasks model presented strings transformed according rule; must apply appropriate transformation sixth learning proceeds less previous section following deﬁnitions string editing tasks kind shown figure popular programming demonstration literature semantic parsing literature unaware datasets support learning paradigms time. thus created dataset string editing tasks sampling random regular transducers applying transducers collections dictionary words showing collected examples mechanical turk users asking provide natural language explanation best guess underlying rule. dataset thus features multi-example learning problems well structured unstructured annotations target concept. tasks language learning tasks valitable results string editing. reported number percentage cases predicted string exactly matches reference. best performing system; using language data joint training rather hypothesis space provides little beneﬁt. dation testing. human-generated data exhibits comparatively diverse explanatory strategies word choices; details appendix annotations included code release paper. experiments models descriptions trained natural language supplied human annotators. meta+joint model converges considerably faster others ﬁnal performance somewhat lower baseline meta model. before outperforms alternative approaches learning directly examples without descriptions. transduction rules dataset generated known formal descriptors tasks provide opportunity perform additional analysis comparing natural language structured forms annotation conventional synthesis-based methods additionally investigate effect number samples drawn profigure example string editing task. learners presented examples strings transformed according rule must apply appropriate transformation sixth string languagelearning annotations take form either natural language descriptions regular expressions. table inference representation experiments string editing. italicized numbers correspond entries table allowing model multiple samples rather -best decoder output substantially improves performance. full model better inferred natural language descriptions either regular expressions ground-truth natural language. amples readily accessible. section move reinforcement learning problems learning signal instead sparse timeconsuming obtain. evaluate collection treasure hunting tasks. tasks require agent discover rule determines location buried treasure large collection environments kind shown figure recover treasure agent must navigate goal location perform action. point episode ends; treasure located agent’s current position receives reward otherwise not. every task treasure consistently buried ﬁxed position relative landmark offset identity target landmark unknown agent location landmark varies across maps. indeed nothing agent’s observations action space suggest landmarks offsets even relevant axis variation across tasks structure made clear natural language annotations. high-level structure tasks similar used hermer-vazquez study concept learning humans. figure example treasure hunting task agent placed random environment must collect reward hidden consistent offset respect landmark. language-learning time natural language instructions expert policies additionally provided. agent must learn primitive navigation skills like avoiding water well highlevel structure reward functions domain. interesting facts stand out. ordinary evaluation condition language-learning natural language data actually better languagelearning regular expressions. might because extra diversity helps model ﬁgure relevant axes variation avoid overﬁtting individual strings. allowing model inference also better providing ground-truth natural language descriptions suggesting actually better generalizing relevant concepts human annotators unsurprisingly ground truth better models inference. coupling inference procedure oracle evaluator essentially recover synthesis-based approach devlin ﬁndings consistent theirs complete accurate execution engine available reason almost execution model learned scratch. examples model behavior shown figure found appendix generated conditioned pre-provided concept-learning observations. here agents free interact environment much need receive observations interaction. thus goal build agents adapt quickly environments rather requiring immediately perform well helddata. expect help setting? reinforcement learning typically encourage models explore injecting randomness either agent’s action space underlying parameterization. random random policies exhibit nonsensical behaviors; result quite inefﬁcient sample space network weights perform policy optimization random starting point. hope parameters instead chosen within structured family stochastic search structured space ever consider behaviors corresponding reasonable ﬁnal policy discover good behavior much faster ordinary interpretation model describes policy chooses actions conditioned current environment state linguistic parameterization. agent initially observations simply design proposal model generate unconditional samples prior descriptions. taking agent’s current observation environment state deﬁne state representation network parameterization assumes discrete action space assigns action probability proportional bilinear function encoded description world state. effectively instruction following model kind well-studied natural language processing literature proposal model allows generate instructions without external direction. figure learning curves treasure hunting. show average reward obtained learning algorithm across multiple evaluation environments language learning already taken place. multitask learns separate embedding task scratch trains every task individually. rapidly discovers high-scoring policies environments. dashed line indicates concept-learning phase; subsequent performance comes ﬁne-tuning. possible reward task points. error bands shows conﬁdence intervals mean performance. learn sample ﬁxed number descriptions description sample multiple rollouts policy induces obtain estimate average reward obtains. finally take highest-scoring description perform additional ﬁne-tuning induced policy. language-learning time assume access natural language descriptions target locations provided human annotators well expert policies navigating location treasure. multitask model compare replaces descriptions trainable task embeddings. learner trained task-speciﬁc expert policies using dagger during language-learning phase adapts individual environments using vanilla policy gradient concept learning phase. environment implementation linguistic annotations case adapted natural case particular contribution orthogonal meta-learning—one could imagine using technique like generate candidate descriptions efﬁciently maml rather zero-shot reward training criterion interpretation model. language navigation dataset originally introduced janner version problem agent begins episode random position randomly-chosen must attempt obtain treasure. relational concepts describing target locations reused language learning concept-learning phases environments distinct. language learning agent access tasks evaluated additional averaged learning curves held-out tasks shown figure expected reward model remains initial exploration period description chosen score improves rapidly. immediately achieves better reward multitask baseline though perfect; suggests interpretation model somewhat overﬁt pretraining environments. however additional ﬁne-tuning even better results rapidly obtained. example rollouts visualized appendix results show model used structure provided language learn better representation space policies— allows sample distribution interesting meaningful behaviors rather sequences random actions. ﬁrst approach aware frame general learning problem optimization space natural language strings. however many closely-related ideas explored literature. string-valued latent variables widely used language processing tasks ranging morphological analysis sentence compression natural language annotations used conjunction training examples guide discovery logical descriptions concepts used auxiliary loss training analogously meta+joint baseline paper. structured language-like annotations used improve learning generalizable structured policies finally natural language instructions available concept-learning time (rather languagepresented approach optimizing models space parameterized natural language. using standard neural encoder–decoder components build models representation search space demonstrated approach outperforms strong baselines classiﬁcation structured prediction reinforcement learning tasks. believe results suggest following general conclusions language encourages compositional generalization standard deep learning architectures good recognizing instances previouslyencountered concepts always generalizing ones. forcing decisions pass linguistic bottleneck underlying compositional structure concepts explicitly expressed stronger generalization becomes possible. relatedly linguistic scaffolding provide dramatic advantages problems like reinforcement learning require exploration models latent linguistic parameterizations sample space thus limit exploration class behaviors likely priori goal-directed interpretable. multitask settings even improve learning tasks language data available training test time. advantages also provided techniques like program synthesis built formal languages natural language expressive easier obtain formal supervision. believe work hints broader opportunities using naturallyoccurring language data improve machine learning tasks kinds.", "year": 2017}