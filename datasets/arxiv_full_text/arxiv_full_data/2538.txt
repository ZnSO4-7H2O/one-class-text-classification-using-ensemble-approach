{"title": "Engineering Safety in Machine Learning", "tag": ["stat.ML", "cs.AI", "cs.CY", "cs.LG"], "abstract": "Machine learning algorithms are increasingly influencing our decisions and interacting with us in all parts of our daily lives. Therefore, just like for power plants, highways, and myriad other engineered sociotechnical systems, we must consider the safety of systems involving machine learning. In this paper, we first discuss the definition of safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. Then we examine dimensions, such as the choice of cost function and the appropriateness of minimizing the empirical average training cost, along which certain real-world applications may not be completely amenable to the foundational principle of modern statistical machine learning: empirical risk minimization. In particular, we note an emerging dichotomy of applications: ones in which safety is important and risk minimization is not the complete story (we name these Type A applications), and ones in which safety is not so critical and risk minimization is sufficient (we name these Type B applications). Finally, we discuss how four different strategies for achieving safety in engineering (inherently safe design, safety reserves, safe fail, and procedural safeguards) can be mapped to the machine learning context through interpretability and causality of predictive models, objectives beyond expected prediction accuracy, human involvement for labeling difficult or rare examples, and user experience design of software.", "text": "abstract—machine learning algorithms increasingly inﬂuencing decisions interacting parts daily lives. therefore like power plants highways myriad engineered sociotechnical systems must consider safety systems involving machine learning. paper ﬁrst discuss deﬁnition safety terms risk epistemic uncertainty harm incurred unwanted outcomes. examine dimensions choice cost function appropriateness minimizing empirical average training cost along certain real-world applications completely amenable foundational principle modern statistical machine learning empirical risk minimization. particular note emerging dichotomy applications ones safety important risk minimization complete story ones safety critical risk minimization sufﬁcient finally discuss four different strategies achieving safety engineering mapped machine learning context interpretability causality predictive models objectives beyond expected prediction accuracy human involvement labeling difﬁcult rare examples user experience design software. recent years machine learning algorithms started inﬂuencing every part lives including health wellness order commerce entertainment ﬁnance human capital management communication transportation philanthropy. algorithms data trained models produce getting powerful ingrained society questions safety must examined. argued machine learning systems simply tools soon general intelligence surpasses human abilities something inbetween perspectives technological components larger sociotechnical systems engineered safety mind safety commonly used term across engineering disciplines connoting absence failures conditions render system dangerous safe food water safe vehicles highways safe medical treatments safe toys safe neighborhoods safe industrial plants. domains speciﬁc design principles regulations applicable works literature attempt precise deﬁnition applicable broad domains systems particular general deﬁnition safety minimization risk epistemic uncertainty associated unwanted outcomes severe enough seen harmful epistemic uncertainty part deﬁnition harmful outcomes often occur regimes operating conditions rare unexpected underdetermined. cost magnitude unwanted outcomes also safety concerned reducing undesired outcomes inconsequential nature. deﬁnition safety possible consider domains existing safety principles regulations machine learning. ﬁrst contribution work critically examine foundational statistical machine learning principles empirical risk minimization structural risk minimization perspective safety. discuss they names imply deal epistemic uncertainty. furthermore principles rely average losses laws large numbers-type arguments necessarily fully applicable considering safety. moreover loss functions involved formulations abstract distortions true predicted values rather application-speciﬁc quantities measuring loss life loss quality life etc. judged harmful best knowledge existing work analyzing machine learning using precise decision-theoretic deﬁnitions safety. second contribution paper emerges examining safety formulating machine learning problems. applications machine learning systems cluster types applications model predictions used support consequential decisions profound effect people’s lives applications model predictions used settings consequence large scale. type applications ones safety paramount. previously noted dichotomy type type applications machine learning data science pose consequences safety deﬁnitions. related literature cited again stem safety. ﬁnal contribution paper discussion strategies increase safety sociotechnical systems machine learning components. four categories approaches identiﬁed promoting safety general inherently safe design safety reserves safe fail procedural probability density function function mapping loss function risk expectation y)fxy dydx. loss function typically measures discrepancy value predicted using itself example regression problems. would like function minimizes risk. however machine learning context access probability rather training samples drawn i.i.d. joint distribution empirical risk remp yi). empirical risk minimization principle formulates learning minimization appealing results glivenko cantelli remp empirical process theory shown empirical risk remp converges risk uniformly goes inﬁnity. small minimizing yield small strucremp tural risk minimization principle alleviates problem restricting complexity introducing regularization minimization problem based inductive bias. risk minimization approach machine learning many strengths evidenced innumerable applied successes brought captures risk component safety. however capture issues related uncertainty loss functions relevant safety. first although training samples drawn true underlying probability distribution always case. furthermore distribution samples actually come cannot known precluding covariate shift domain adaptation techniques. form epistemic uncertainty quite relevant safety training data different distribution cause much harm. also training samples come true unknown underlying distribution absent large parts space small probability density there. learned completely dependent inductive bias rather uncertain true distribution could introduce safety hazard. learning theory analysis utilizes laws large numbers study effect ﬁnite training data convergence empirical risk true risk considering safety also cognizant deployment machine learning system encounters ﬁnite number test samples actual operational risk empirical quantity test set. thus operational risk much larger true risk small cardinality test sets even risk-optimal. uncertainty caused instantiation test large safety implications individual test samples. safeguards. discuss examples approaches speciﬁcally machine learning algorithms especially mitigate epistemic uncertainty. contribution recommend strategies engineer safer machine learning methods agenda machine learning safety research. remainder paper organized following manner. section discuss harm risk uncertainty deﬁnition safety. section examine statistical machine learning safety perspective. section sets forth types machine learning applications distinguished relationship safety. section describes ways achieving safety general specializations machine learning. section concludes. term safety many different technical nontechnical meanings purposes would like work precise domain-agnostic deﬁnition. welldescribed numerous references therein deﬁnition safety begins outcomes events. system yields outcome based state inputs receives; outcome event desired undesired. single events sets events associated costs measured quantiﬁed society numeric level morbidity example cost outcome. undesired outcome harm cost exceeds threshold. unwanted events small severity counted safety issues. next step deﬁning safety bring decision theory concepts risk epistemic uncertainty. risk expected value cost harm know outcome distribution known calculate expectation cost. uncertainty still know outcome contrast risk probability distribution also unknown epistemic uncertainty contrast aleatoric uncertainty results lack knowledge could obtained principle practically intractable gather. decision theorists argue uncertainty captured probabilistically maintain distinction risk uncertainty herein following tomes written costs risk uncertainty. mathematical precision also given. purposes points deﬁnition safety that costs sufﬁciently high human sense events harmful safety involves reducing probability expected harms possibility unexpected harms. risk minimization output abstract quantity representing prediction error. however real-world applications value loss function endowed human cost human cost imply loss function also includes domain. moreover cost severe enough harmful thus safety issue parts domain others. described general considerations machine learning terms safety section examine safety considerations speciﬁc applications machine learning systems section. begin severity unwanted outcomes. predictions made machine learning systems applications medical diagnosis loan approval prison sentencing profound effect people; undesired outcomes truly harmful human sense. contrast applications machine learning less consequential nature; examples include streaming services deciding compression level video packets transmit subscribers every seconds portals deciding news story show speech transcription systems classifying phonemes quality service implications unwanted outcomes applications safety hazards. taking nuanced look costs undesirable predictions note loss functions always monotonic correctness predictions depend whose perspective objective. consider loan approval application applicant would like approval decision regardless features indicating ability repay lender would like approval cases applicant features indicate likely repayment society would like fairness equitability system protected groups deﬁned race gender discriminated against. lender perspective consistent typical choice loss function others not. type machine learning applications potentially harmful consequences type harmless consequences analyzed respect epistemic uncertainty. priori reason applications follow type structure examining uncertainty discuss following types recapitulated. ease reference medical diagnosis loan approval prison sentencing-type applications constitute type class applications type nomenclature addition lack severity costs another characteristic type applications performed scales large training sets large testing sets ability explore feature space. example portal news story application billions data points training perform large-scale testing evaluate average performance millions billions clicks. reasons epistemic uncertainties discussed section less prevalent type applications type applications. contrast type applications often case uncertainty training samples representative testing samples predictions made. uncertainty various types discussed common type applications. thus errors type applications less costly human terms amount uncertainty system less. therefore reasons safety much less relevant type applications type applications. focus type applications squarely risk minimization whereas type applications require consideration strategies achieving safety discuss next. discussed introduction safety usually investigated application-by-application basis strategies achieving same. example setting minimum thickness vessels removing ﬂammable materials chemical plant ways achieving safety. analyzing strategies across domains identiﬁed four main categories approaches achieve safety. section discuss categories turn along speciﬁc approaches extend machine learning formulations beyond risk minimization safety. machine learning context would like robustness uncertainty training sampled test distribution. training various quirks biases unknown user present test phase. highly complex modeling techniques used today including extreme gradient boosting deep neural networks pick data vagaries learned models produce achieve high accuracy might fail unknown shift data domain. understand react shifts whether produce harmful outcomes result. related ways introduce inherently safe design insisting models interpreted people excluding features causally-related outcome examining interpretable models features functions capturing quirks data noted excluded thereby avoiding related harm. similarly excluding non-causal variables desire neither interpretability causality models captured standard risk minimization formulation machine learning. extra regularization constraints beyond implied structural risk minimization needed learn models. performance loss accuracy measuring accuracy common training testing data probability distribution reduction epistemic uncertainty increases safety. interpretability causality incorporated single learned model e.g. second strategy achieving safety multiplicative additive reserves known safety factors safety margins respectively. mechanical systems safety factor ratio maximal load lead failure load system designed. similarly safety margin difference two. purposes machine learning uncertainty whether uncertainty training data matching test distribution instantiation test parameterize unknown symbol risk risk-optimal model known along lines safety factors safety margins robust formulations constraining minimizing maxθ r∗). formulations maxθ capture uncertainty class priors uncertainty resulting label noise classiﬁcation problems. also capture uncertainty part space actual small test samples comes from care much average test error medical diagnosis problems model used handful patients maximum test error. different sort safety factor comes considering fairness equitability. certain prediction problems risk harm members protected groups much worse risk harm others features indicating protected group race gender dimensions space; partition space sets corresponding protected unprotected groups respectively. safety factor known disparate impact constrains following minimum value third general category safety measures ‘safe fail’ implies system remains safe fails intended operation. examples electrical fuses so-called dead man’s switches trains safety valves boilers. technique used machine learning predictions cannot given conﬁdently reject option model reports cannot reliably give prediction attempt thereby failing safely. model elects reject option typically human operator intervenes examines test sample provides manual prediction. classiﬁcation problems models reported least conﬁdent near decision boundary. however implicit assumption distance decision boundary inversely related conﬁdence. reasonable parts high probability density large numbers training samples decision boundary located large overlap likelihood functions. however discussed section parts density contain training samples decision boundary completely based inductive bias thereby containing much epistemic uncertainty. parts space distance decision boundary fairly meaningless typical trigger reject option avoided rare combination features test sample safe fail mechanism always manual examination. finally fourth strategy achieving safety given name procedural safeguards. strategy includes measures beyond ones designed core functionality system audits training posted warnings directions machine learning used increasing safety within category user experience design openness. type applications especially non-specialists often operators machine learning systems. deﬁning training data setting evaluation procedures among things certain subtleties cause harm operation done incorrectly. user experience design used guide warn novice experienced practitioners machine learning systems properly thereby increase safety. best breed machine learning algorithms days open source allows possibility public audit. safety hazards potential harms discovered examination source code. however open source software enough behavior machine learning systems driven data much software implementations algorithms. open data refers data freely used reused redistributed anyone. common type applications sponsored governments type applications data oftentimes value proposition. opening data procedural safeguard increasing safety increasingly adopted type applications. increase across areas life. prevailing trend machine learning researchers engineers ethicists started discussing topic safety. paper contribute discussion starting basic deﬁnition safety terms harm risk uncertainty building upon machine learning context. identify minimization epistemic uncertainty missing standard modes machine learning developed around risk minimization needs included considering safety. delineated types applications machine learning type safety important concern type discussed several strategies increasing safety especially pertinent type applications. within safety engineering subdivision concepts substantive safety nominal safety. design elements nominally safe system meet regulations design criteria. substantive safety longterm performance system actually exhibits. made distinction paper worth future work. also safety discussion paper related predictions outcomes based predictions. however parts machine learning system besides core prediction component also consider safety. example privacy disclosure risk microdata release safety issue part main prediction model part larger machine learning sociotechnical system work study parts machine learning similar fashion work starting ﬁrst principles safety terms cost risk uncertainty. strategies increasing safety mentioned section comprehensive list fully developed. paper seen laying foundations research agenda motivated type applications safety within strategies developed existing strategies ﬂeshed out. respects research community taken risk minimization close limits achievable. safety especially epistemic uncertainty minimization represents direction offers exciting problems pursue. said sanskrit literature ahim. paramo dharmah. conn wars battle human minds keep artiﬁcial intelligence safe http//futureoﬂife.org////the-ai-warsthe-battle-of-the-human-minds-to-keep-artiﬁcial-intelligence-safe dec. lessmann h.-v. seow baesens thomas benchmarking state-of-the-art classiﬁcation algorithms credit scoring tenyear update eur. oper. res. vol. nov. hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath kingsbury deep neural networks acoustic modeling speech recognition ieee signal process. mag. vol. nov. feldman friedler moeller scheidegger venkatasubramanian certifying removing disparate impact proc. sigkdd conf. knowl. discov. data min. sydney australia aug. varshney prenger marlatt chen hanley practical ensemble classiﬁcation error bounds different operating points ieee trans. knowl. data eng. vol. nov.", "year": 2016}