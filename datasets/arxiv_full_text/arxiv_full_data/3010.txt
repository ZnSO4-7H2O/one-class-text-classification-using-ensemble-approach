{"title": "Deep Variation-structured Reinforcement Learning for Visual Relationship  and Attribute Detection", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Despite progress in visual perception tasks such as image classification and detection, computers still struggle to understand the interdependency of objects in the scene as a whole, e.g., relations between objects or their attributes. Existing methods often ignore global context cues capturing the interactions among different object instances, and can only recognize a handful of types by exhaustively training individual detectors for all possible relationships. To capture such global interdependency, we propose a deep Variation-structured Reinforcement Learning (VRL) framework to sequentially discover object relationships and attributes in the whole image. First, a directed semantic action graph is built using language priors to provide a rich and compact representation of semantic correlations between object categories, predicates, and attributes. Next, we use a variation-structured traversal over the action graph to construct a small, adaptive action set for each step based on the current state and historical actions. In particular, an ambiguity-aware object mining scheme is used to resolve semantic ambiguity among object categories that the object detector fails to distinguish. We then make sequential predictions using a deep RL framework, incorporating global context cues and semantic embeddings of previously extracted phrases in the state vector. Our experiments on the Visual Relationship Detection (VRD) dataset and the large-scale Visual Genome dataset validate the superiority of VRL, which can achieve significantly better detection results on datasets involving thousands of relationship and attribute types. We also demonstrate that VRL is able to predict unseen types embedded in our action graph by learning correlations on shared graph nodes.", "text": "understanding—that model capable recognizing interactions relationships objects describing attributes. objects core building blocks image often relationships attributes determine holistic interpretation scene. example fig. left image understood standing yellow green skateboard right image woman wearing blue suit kneeling surfboard. able extract exploit visual information would beneﬁt many realworld applications image search question answering ﬁne-grained recognition visual relationships pair localized objects connected predicate; example predicates actions comparative spatial verbs prepositions attributes describe localized object e.g. color state detecting relationships attributes challenging traditional object detection following reasons massive number possible relationship attribute types resulting greater skew rare infrequent types. object associated many relationships attributes making inefﬁcient exhaustively search possible relationships despite progress visual perception tasks image classiﬁcation detection computers still struggle understand interdependency objects scene whole e.g. relations objects attributes. existing methods often ignore global context cues capturing interactions among different object instances recognize handful types exhaustively training individual detectors possible relationships. capture global interdependency propose deep variation-structured reinforcement learning framework sequentially discover object relationships attributes whole image. first directed semantic action graph built using language priors provide rich compact representation semantic correlations between object categories predicates attributes. next variation-structured traversal action graph construct small adaptive action step based current state historical actions. particular ambiguity-aware object mining scheme used resolve semantic ambiguity among object categories object detector fails distinguish. make sequential predictions using deep framework incorporating global context cues semantic embeddings previously extracted phrases state vector. experiments visual relationship detection dataset large-scale visual genome dataset validate superiority achieve signiﬁcantly better detection results datasets involving thousands relationship attribute types. also demonstrate able predict unseen types embedded action graph learning correlations shared graph nodes. figure overview framework sequentially detects relationships attributes first build directed semantic action graph conﬁgure whole action space. step input state consists current subject object instances history phrase embedding captures search paths already traversed agent. variation-structured traversal scheme dynamically constructs three small action sets agent predicts three actions attribute subject; predicate subject object; next object category interest state consists subject/object instances updated history phrase embedding. pair objects. global holistic perspective image essential resolve semantic ambiguities existing approaches predict limited relationship types ignore semantic interdependencies relationships attributes evaluating region within scene separately impractical exhaustively search possibilities region also deviates human perception. therefore preferable principled decision-making framework discover relevant relationships attributes within small number search steps. address aforementioned issues propose deep variation-structured reinforcement learning framework sequentially detects relationship attribute instances exploiting global context cues. first language priors build directed semantic action graph nodes nouns attributes predicates connected directed edges represent semantic correlations graph provides highly-informative compact representation enables model learn rare relationships attributes frequent ones using shared graph nodes. example semantic meaning riding learned person-ridingbicycle help predict rare phrase child-ridingelephant. generalizing ability allows handle considerable number possible relationship types. second existing deep reinforcement learning models often require several costly episodes trial error converge even small action space large action space would exacerbate problem. efﬁciently discover relationships attributes small number steps introduce novel variation-structured traversal scheme action graph constructs small adaptive action sets step based current state historical actions contains candidate attributes describe object; contains candidate predicates relating pair objects; contains object instances mine next step. since object instance belong multiple object categories object detector cannot distinguish introduce ambiguity-aware object mining scheme assign object appropriate category given global scene context. variation-structured traversal scheme offers promising technique extending applications deep complex real-world tasks. third incorporate global context cues better reasoning explicitly encode semantic embeddings previously extracted phrases state vector. makes better tradeoff increasing input dimension utilizing historical context compared appending history frames binary action vectors previous methods. extensive experiments visual relationship detection dataset visual genome dataset demonstrate proposed outperforms state-ofthe-art methods relationship attribute detection also good generalization capabilities predicting unseen types. relationship detection however existing approaches detect handful pre-deﬁned frequent types training individual detectors relationship. recently leveraged word embeddings handle large-scale relationships. however model still ignores structured correlations between objects relationships. furthermore methods organized predictions scene graph provide structured representation describing objects attributes relationships image. particular johnson introduced conditional random ﬁeld model reasoning possible groundings scene graphs schuster proposed rule-based classiﬁer-based scene graph parser. contrast proposed makes ﬁrst attempt sequentially discover objects relationships attributes fully exploiting global interdependency. deep reinforcement learning. integrating deep learning methods reinforcement learning recently shown promising results decision-making problems. example mnih proposed using deep q-networks play atari games. silver proposed search algorithm based integration monte-carlo tree search deep beat world champion game efforts applied deep various real-world tasks e.g. robotic manipulation indoor navigation object proposal generation work deals real-world scenes much complex atari games images taken constrained scenarios investigates make decisions larger action space handle large action space propose variation-structured traversal scheme whole action graph decrease number possible actions step substantially reduces number trials thus speeds convergence. propose novel framework formulates problem detecting visual relationships attributes sequential decision-making process. overview provided fig. components including directed semantic action graph variation-structured traversal scheme state space reward function detailed following sections. directed semantic action graph build directed semantic graph organize possible object nouns attributes relationships compact semantically meaningful representation nodes consist candidate object categories attributes predicates object categories nouns people places parts objects. attributes describe color shape pose. relationships directional i.e. relate subject noun object noun predicate. predicates spatial compositional action directed edges consist attribute phrases predicate phrases attribute phrase represents attribute belonging noun example attribute phrase young girl represented predicate phrase represents subject noun object noun related predicate example predicate phrase swinging represented recently released visual genome dataset provides large-scale annotation images containing unique object categories unique attributes unique relationships. select types appear least times visual genome dataset resulting object- attribute- relationshiptypes. attribute relationship types build directed semantic action graph extracting unique object category words attribute words predicate words graph nodes. directed action graph thus contains object nodes attribute nodes predicate nodes. average object word connected attribute words predicate words. semantic action graph serves action space next section. instead learning entire action space traditional deep propose novel variationstructured traversal scheme semantic action graph dynamically constructs small action sets step. first uses object detector candidate object instances sequentially assigns relationships attributes instance experiments used state-of-the-art faster r-cnn object detector network parameters initialized using pre-trained vgg- imagenet model since subject instances image often multiple relationships attributes breadth-ﬁrst search predict relationships attributes respect current subject instance interest move onto next instance. start subject instance conﬁdent classiﬁcation score. prevent agent trapped single search path agent selects starting subject instance traversed neighboring objects breadth-ﬁrst search. figure network architecture deep vrl. state vector concatenation -dim feature whole image taken layer pre-trained vgg- imagenet model -dim features subject object instances taken conv layer trained faster r-cnn object detector; -dim history phrase embedding created concatenating four -dim semantic embeddings skip-thought language model last relationship phrases last attribute phrases predicted vrl. variation-structured traversal scheme directed semantic action graph produces smaller action space whole action space originally consists attributes predicates object categories plus terminal trigger. variation-structured action space model selects actions highest predicted q-values state different semantically ambiguous noun categories cannot distinguished object detector. address semantic ambiguity introduce ambiguity-aware object mining scheme leverages scene contexts captured extracted relationships attributes help determine appropriate object category. variation-structured action space. directed semantic graph serves action space vrl. object instance image denote object category bounding center coordinate width height. given current subject instance object instance select three actions according network follows aware object mining scheme follows objects neighboring neighbor deﬁned object |˜sx |˜sy object object categories whose conﬁdence scores less conﬁdent cates∈n {terminal} previously extracted object instances terminal terminal trigger indicating object mining scheme subject instance. empty terminal trigger activated select subject instance following breadth-ﬁrst scheme. terminal trigger allows number object mining steps subject instance dynamically speciﬁed limited small number. state space. detailed overview state feature extraction process shown fig. given current subject object instances time step state vector concatenation feature vectors feature vector whole image; history phrase embedding vector created concatenating semantic embeddings last relationship phrases last attribute phrases mined variation-structured traversal scheme. speciﬁcally phrase embedded -dim vector using pre-trained skip-thought language model thus resulting -dim history phrase embedding. generalizes well unseen inputs. detailed architecture q-network illustrated fig. speciﬁcally estimate three q-value sets parametrized network weights correspond action sets apc. training episode \u0001greedy strategy select actions variationstructured action space agent selects random actions probability selects actions highest estimated q-values probability during testing directly select best actions highest estimated q-values agent sequentially determines best actions discover objects relationships attributes given image either maximum search step reached remaining uncovered object instances. also utilize replay memory store experience past episodes. step draw random minibatch replay memory perform q-learning update. replay memory helps stabilize training smoothing training distribution past experiences reducing correlation training samples given transition sample gcrarprc) network weights updated follows dataset. conduct experiments visual relationship detection dataset visual genome dataset contains images object categories predicates. total dataset contains relationship instances relationship types relationships occur test training set. visual genome dataset experiment images containing relationship instances relationship types attribute instances figure illustration ambiguity-aware object mining. image left shows subject instance neighboring object instances action contains candidate object categories neighboring object object detector cannot distinguish terminal trigger indicating object mining scheme subject instance. context cues help recognizing relationships attributes also allow agent aware uncovered objects. history phrase embedding captures search paths scene contexts already traversed agent. rewards suppose groundtruth labels consist object instances image attribute phrases predicate phrases describing objects given predicted object instance groundtruth object overlaps object category bounding boxes least intersection-overunion overlap. deﬁne following reward functions reﬂect detection accuracy taking action state current subject object instances respectively returns exists groundtruth object overlaps predicted attribute relationship groundtruth ˆea. otherwise returns returns exists ˆep. overlap respectively otherwise returns returns next object instance corresponding category overlaps groundtruth object otherwise returns thus encourages faster exploration objects image. optimize three policies select three actions state maximizing discounted rewards formulated decision-making process deep framework. high-dimensional continuous image data model-free environment resort deep q-network framework proposed implementation details. train deep q-network epochs shared rmsprop optimizer epoch ends performing episode training images. mini-batch size images. maximum search step image empirically \u0001-greedy training annealed linearly ﬁrst epochs ﬁxed remaining epochs. discount factor network parameters copied every steps. learning rate initialized decreased factor every epochs. candidate object instances ranked objectness conﬁdence scores trained object detector selected mining relationships attributes image order balance efﬁciency effectiveness. takes hours train object detector object categories days converge. visual genome dataset takes days train object detector object categories week converge. average takes feed-forward image vrl. details dataset provided sec. implementations based publicly available torch platform single nvidia geforce evaluation. following recall recall evaluation metrics. recallx computes fraction times correct relationship attribute instance covered conﬁdent predictions ranked product objectness conﬁdence scores relevant object instances q-values selected predicates attributes. discussed mean average precision pessimistic evaluation metric dataset cannot exhaustively annotate following evaluate three tasks relationship phrase detection goal predict subject-predicate-object phrase localization entire relationship least overlap groundtruth bounding box. relationship detection goal predict subject-predicate-object phrase localizations subject object instances least overlap corresponding groundtruth boxes. attribute detection goal predict subject-attribute phrase subject’s localization least overlap groundtruth box. baseline models. first compare model state-of-the-art approaches visual phrases joint cnn+r-cnn note latter methods r-cnn extract object proposals. results reported also experiment methods visual genome dataset. trains individual detectors object predicate categories separately combines conﬁdences generate relationship prediction. furthermore train compare following models faster r-cnn directly detects unique relationship attribute type following visual phrases faster r-cnn model similar difference faster rcnn used object detection. joint cnn+rpn extracts proposals using pre-trained model performs classiﬁcation. joint cnn+trained trains separate model dataset generate proposals. shared detectors individual detectors. compared models categorized classes models train individual detectors predicate attribute type i.e. visual phrases joint cnn+rcnn joint cnn+rpn faster r-cnn joint cnn+trained models train shared detectors predicate attribute types combine results object detectors generate ﬁnal prediction i.e. faster r-cnn vrl. since space possible relationships attributes often large insufﬁcient training examples infrequent relationships leading poor average performance models individual detectors. r-cnn. cases obtain performance improvements using network r-cnn proposal generation. additionally training proposal network datasets also increase recalls pre-trained networks datasets. language priors. unlike baselines simply train classiﬁers visual cues leverage language priors facilitate prediction. uses semantic word embeddings ﬁnetune likelihood predicted relationship follows variationalstructured traversal scheme directed semantic action graph built language priors. achieve signiﬁcantly better performance baselines demonstrates necessity language priors relationship attribute detection. moreover still shows substantial improvements comparison therefore vrl’s directed semantic action graph provides compact rich representation semantic correlations word embeddings used signiﬁcant performance improvement also sequential reasoning results fig. generates rich understanding image including localization recognition objects detection object relationships attributes. instance correctly detect interactions spatial layouts parts objects attribute descriptions reinforcement learning random walk. variant standard deep model selects three actions entire action space instead variationstructured action space. compare simple random walk traversal scheme step agent randomly selects object instance image predicts relationships attributions mostrecently selected instances.random walk achieves slightly better results joint+trained performs much worse remaining variants demonstrating beneﬁt sequential mining variation-structured traversal scheme. achieves remarkably higher recall compared thus conclude using variation-structured traversal scheme dynamically conﬁgure small action state accelerate stabilize learning procedure dramatically decreasing number possible actions. example number predicate actions dropped average. history phrase embedding. validate effectiveness history phrase embeddings evaluate variants history phrase incorporate history phrase embedding state features. variant causes recall drop compared original vrl. thus leveraging history phrase embeddings help inform current state happened figure examples relationship attribute detection results generated visual genome dataset. show predictions image localized objects semantic graph describing relationships attributes past stabilize search trajectories might stuck repetitive cycles. historical actions directly stores historical action vector state historical action vector concatenation four -dim action vectors corresponding last four actions taken action vector zero elements except indices corresponding three actions taken variant still causes recall drop demonstrating semantic phrase embeddings learned language models capture richer history cues ambiguity-aware object mining. ambiguity considers top- predicted category object action obtains lower recall suggesting incorporating semantically ambiguous categories help identify appropriate category object different scene contexts. fig. illustrates examples successfully resolves vague predictions ambiguity concrete ones spatial actions. similar experiment using spatial actions deep setting sequentially extract object instances. variant directional actions replaces -dim object category action vector -dim action vector indexed directions plus terminal trigger. step agent selects neighboring object instance highest conﬁdence whose center lies eight directions w.r.t. subject instance. diverse spatial layouts object instances across different images make difﬁcult learn spatial action policy causes variant perform poorly. long short-term memory lstm variant fully-connected layers fig. replaced lstm layers shown promising results capturing long-term dependencies. however lstm noticeable performance improvements requiring much training time. shows history phrase embeddings sufﬁciently model historical context sequential prediction. zero-shot learning also compare zeroshot learning setting promising model capable predicting unseen relationships since training data cover possible relationship types. uses word embeddings project similar relationships onto unseen ones uses large semantic action graph learn similar relationships shared graph nodes. achieves performance improvements datasets. proposed novel deep variation-structured reinforcement learning framework detecting visual relationships attributes. sequentially discovers relationship attribute instances following variation-structured traversal scheme directed semantic action graph. incorporates global interdependency facilitate predictions local regions. experiments visual genome dataset demonstrate power efﬁciency model baselines. future work larger directed action graph built using natural language sentences. additionally generalized unsupervised learning framework learn massive number unlabeled images.", "year": 2017}