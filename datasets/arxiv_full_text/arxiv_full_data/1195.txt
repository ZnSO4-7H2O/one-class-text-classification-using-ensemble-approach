{"title": "When Face Recognition Meets with Deep Learning: an Evaluation of  Convolutional Neural Networks for Face Recognition", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Deep learning, in particular Convolutional Neural Network (CNN), has achieved promising results in face recognition recently. However, it remains an open question: why CNNs work well and how to design a 'good' architecture. The existing works tend to focus on reporting CNN architectures that work well for face recognition rather than investigate the reason. In this work, we conduct an extensive evaluation of CNN-based face recognition systems (CNN-FRS) on a common ground to make our work easily reproducible. Specifically, we use public database LFW (Labeled Faces in the Wild) to train CNNs, unlike most existing CNNs trained on private databases. We propose three CNN architectures which are the first reported architectures trained using LFW data. This paper quantitatively compares the architectures of CNNs and evaluate the effect of different implementation choices. We identify several useful properties of CNN-FRS. For instance, the dimensionality of the learned features can be significantly reduced without adverse effect on face recognition accuracy. In addition, traditional metric learning method exploiting CNN-learned features is evaluated. Experiments show two crucial factors to good CNN-FRS performance are the fusion of multiple CNNs and metric learning. To make our work reproducible, source code and models will be made publicly available.", "text": "deep learning particular convolutional neural network achieved promising results face recognition recently. however remains open question cnns work well design ‘good’ architecture. existing works tend focus reporting architectures work well face recognition rather investigate reason. work conduct extensive evaluation cnn-based face recognition systems common ground make work easily reproducible. speciﬁcally public database train cnns unlike existing cnns trained private databases. propose three architectures ﬁrst reported architectures trained using data. paper quantitatively compares architectures cnns evaluates effect different implementation choices. identify several useful properties cnn-frs. instance dimensionality learned features signiﬁcantly reduced without adverse effect face recognition accuracy. addition traditional metric learning method exploiting cnn-learned features evaluated. experiments show crucial factors good cnn-frs performance fusion multiple cnns metric learning. make work reproducible source code models made publicly available. conventional face recognition pipeline consists four stages face detection face alignment feature extraction classiﬁcation. perhaps single important stage feature extraction. constrained environments hand-crafted features local binary patterns local phase quantisation achieved respectable face recognition performance. however performance using features degrades dramatically unconstrained environments face images cover complex large intra-personal variations pose illumination expression occlusion. remains open problem ideal facial feature robust face recognition unconstrained environments last three years convolutional neural network rebranded ‘deep learning’ achieved impressive results frue. unlike traditional hand-crafted features learningbased features robust complex intra-personal variations. notably three face recognition rates reported frue benchmark database achieved methods success latest cnns frue general object recognition task stems following facts much larger labeled training sets available; implementations greatly reduce time training large cnn; cnns greatly improve model generation capacity introducing effective regularisation strategies dropout despite promising performance achieved cnns remains unclear design ‘good’ architecture adapt speciﬁc classiﬁcation task lack theoretical guidance. however insights design gained experimental comparisons different architectures. work made comparisons comprehensive analysis task object recognition. however face recognition different object recognition. speciﬁcally faces aligned similarity transformation pose correction ﬁxed reference position images feature extraction object recognition usually conduct alignment therefore objects appear arbitrary positions. result architectures used face recognition rather different object recognition task face recognition important make systematic evaluation effect different design implementation choices. addition published cnns trained different face databases publicly available. difference training sets might result unfair comparisons architectures. avoid unfairness comparison different cnns conducted common ground. clarify contributions different components cnn-based face recognition systems paper systematic evaluation conducted. make work reproducible networks evaluated trained publicly available database. speciﬁcally contributions follows finally source code architectures trained networks made publicly available provides extremely competitive baseline face recognition community. knowledge ﬁrst publish fully reproducible cnns face recognition. methods drawn considerable attention ﬁeld face recognition recent years. particular cnns achieved impressive results frue. section brieﬂy review cnns. researchers facebook group trained -layer named deepface ﬁrst three layers conventional convolution-pooling-convolution layers. subsequent three layers locally connected followed fully connected layers. pooling layers make learned features robust local transformations result missing local texture details. pooling layers important object recognition since objects images well aligned. however face images well aligned training cnn. claimed pooling layer good balance local transformation robustness preserving texture details. deepface trained largest face database to-date contains four million facial images subjects. another contribution face alignment. traditionally face images aligned using similarity transformation cnns. however alignment cannot handle out-ofplane rotations. overcome limitation proposes alignment method using afﬁne camera model. cnn-based face representation referred deep hidden identity feature proposed. unlike deepface whose features learned single deepid learned training collection small cnns input single crops/patches facial images features learned cnns concatenated form powerful feature. grey crops extracted around facial points used train deepid. length deepid small network consists convolutional layers pooling layers fully connected layers shown table deepid uses identiﬁcation information supervise training. comparison deepid extension deepid uses identiﬁcation veriﬁcation information train aiming maximise inter-class difference minimise intra-class variations. improve performance deepid deepid deepid+ proposed. deepid+ adds supervision information convolutional layers rather topmost layers like deepid deepid. addition deepid+ improves number ﬁlters layer uses much bigger training deepid deepid also discovered deepid+ three interesting properties being sparse selective robust. face recognition pipeline refereed webface also learns face representation using cnn. webface collects database contains around subjects images makes database publicly available. motivated deep architectures webface trains much deeper used face recognition shown table speciﬁcally webface trains -layer includes convolutional layers pooling layers fully connected layers detailed table note small convolutional ﬁlters avoids much texture information decrease along deep architecture crucial learn powerful feature. addition webface stacks convolutional layers effective convolutional layer fewer parameters. table compares three typical cnns deepid webface clear architectures implementation choices rather different motivates work. study make systematic evaluations clarify contributions different components common ground. input image represented width×height×channels. mean grey images respectively. capital letters represent convolutional pooling locally connected average pooling fully connected layers respectively. capital letters followed indices layers. number ﬁlters ﬁlter size denoted ‘num size size’ facto benchmark database frue. exisiting cnns train networks private databases test trained models lfw. comparison train cnns using data make work easily reproducible. cannot directly reported architectures since training data much less extensive. introduce three architectures adapting training subsection improve discrimination cnnlearned features metric learning method usually used. metric learning method joint bayesian model detailed subsection design ‘good’ architecture remains open problem. generally architecture depends size training data. less data drive smaller network avoid overﬁtting. study size training data much smaller used state methods therefore smaller architectures designed. propose three architectures adapting size training data lfw. architectures three different sizes small medium large cnn-s cnn-m convolutional layers fully connected layers cnn-m ﬁlters cnn-s. compared cnn-s cnn-m cnn-l convolutional layers. activation function used rectiﬁcation linear unit experiments dropout improve preformance cnns therefore applied networks. following softmax function used last layer predicting single class mutually exclusive classes. training learning rate three networks batch size ﬁxed table details three architectures. softmax convolutional layer detailed sub-rows indicates number ﬁlters ﬁlter size ‘num size size’; speciﬁes convolutional stride padding speciﬁes max-pooling downsampling factor. fully connected layers specify dimensionality feature length number class/subjects. note every splits different number subjects around metric learning aims metric make classes separable often used face veriﬁcation. independent feature extraction process feature method. joint bayesian model well-known method widely used method applied features learned cnns models face veriﬁcation task bayesian decision problem. represent intra-personal extra-personal hypotheses respectively. based rule decision made follow gaussian distributions respectively. unknown covariance matrices regarded face prior. case faces joint distribution also assumed gaussian zero mean. based covariance faces contains subjects images training test sets deﬁned evaluation divided predeﬁned splits -fold cross validation. time nine used model training testing. deﬁnes three standard protocols evaluate face recognition performance. ‘unrestricted’ protocol applied information subject identities matched/unmatched labels used system. face recognition rate evaluated mean classiﬁcation accuracy standard error mean. images used aligned deep funneling image cropped based coordiates centers. sample crops visualised fig. commonly believed data augmentation boost generalisation capacity neural network; therefore image horizontally ﬂipped. mean images subtracted network training. open source implementation matconvnet used train cnns. section different components cnn-based face recognition system evaluated analysed. architectures choosing ‘good’ architecture crucial training. overlarge extremely small networks relative training data lead overﬁtting underﬁtting case network converge training. comparison colour images cnns feature distance measured cosine distance. performances three architectures compared table cnn-m achieves best face recognition performance indicating cnn-m generalises best among three architectures using data. point evaluations conducted using cnn-m. face recognition rate cnn-m considered baseline remaining investigations compared best distance measure face recognition. table compares impact distance measures face recognition accuracy. cosine correlation achieve best recognition rates however standard deviation cosine smaller correlation. therefore cosine distance best among distances. grey colour cnns trained using grey-level colour images respectively. comparison grey colour images used quantitatively compare impact images types face recognition. comparative evaluation yields face recognition accuracies using grey colour images respectively. performances using grey colour images close other. although colour images contain information deliver signiﬁcant improvement. data augmentation flip mirroring images horizontally producing samples each commonly used data augmentation technique face recognition. original mirrored images used training evaluations. however little discussion existing work made analyse impact image ﬂipping testing. naturally test images also mirrored. pair test images produce mirrored ones. images generate pairs instead original pair. combine images/pairs fusion strategies implemented work. feature fusion learned features test image mirrored concatenated feature used score computing. score fusion scores generated pairs averaged score. table compares three scenarios test feature score fusions. shown table mirroring images improve face recognition performance. addition feature fusion works slightly better score fusion however improvements statistically signiﬁcant. learned feature analysis interesting investigate properties cnn-learned face representations. first discuss feature normalisation standardises range features generally performed data preprocessing step. example implement eigenface features usually normalised training space. original normalised feature vectors respectively. mean standard deviation motivated this features normalised computing cosine distance. accuracies without normalisation respectively. thus normalisation effective improve recognition rate. second perform dimensionality reduction learned features using pca. shown figure dimensions feature space achieve comparable face recognition rates original space. interesting property cnn-learned features dimensionality signiﬁcantly reduce storage space computation crucial large scale applications mobile devices smartphone. network fusion work deepid variants apply fusion multiple networks. specifically images different facial regions scales separately networks architecture. features learned different networks concatenated powerful face representation implicitly captures spatial information facial parts. size images different shown table networks trained separately fusion. however clear greatly fusion improves face recognition performance. clarify issue implement network fusion. extract crops four corners center upsample original image size crops different scales loor loor operator integer part. therefore obtain local patches size original image. figure shows crops. evaluate performance network fusion separately train different networks using crops. face image represented concatenating features learned different networks. table compares performance single network network fusion. note choose best networks ones fusion. clear network fusion works much better single network. speciﬁcally fusion best networks improves face recognition accuracy single network clearly face representation network fusion actually fusion features different facial componets scales. similar ideas widely used improve facial representation capacity hand-crafted features multi-scale local binary pattern multi-scale local phase quantisation high-dimensional local features metric learning metric learning features fusion best networks used. feature dimensionality reduced figure compares face recognition accuracies without split database. consistently signiﬁcantly improves face recognition rates showing importance metric learning. table compares method non-commercial state-of-the-art methods. performance method slightly better worse however feature dimensionality much higher ours. large number pairs generated addition provided train model generate pairs. recently convolutional neural networks attracted attention ﬁeld face recognition. work present rigorous empirical evaluation cnnbased face recognition systems. speciﬁcally quantitatively evaluate impact different architectures implementation choices cnns face recognition performances common ground. shown network fusion signiﬁcantly improve face recognition performance different networks capture information different regions scales form powerful face representation. addition metric learning joint bayesian method improve face recognition greatly. since network fusion metric learning important factors affecting performance subject future investigation. acknowledgements work supported european union’s horizon research innovation program grant agreement epsrc/dstl project ‘signal processing networked battlespace’ under contract ep/k/ epsrc programme grant future spatial audio immersive listener experiences home’ contract ep/l european union project beat. also gratefully acknowledge support nvidia corporation donation gpus used research.", "year": 2015}