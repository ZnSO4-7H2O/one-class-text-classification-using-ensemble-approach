{"title": "Spontaneous Analogy by Piggybacking on a Perceptual System", "tag": ["cs.AI", "cs.LG"], "abstract": "Most computational models of analogy assume they are given a delineated source domain and often a specified target domain. These systems do not address how analogs can be isolated from large domains and spontaneously retrieved from long-term memory, a process we call spontaneous analogy. We present a system that represents relational structures as feature bags. Using this representation, our system leverages perceptual algorithms to automatically create an ontology of relational structures and to efficiently retrieve analogs for new relational structures from long-term memory. We provide a demonstration of our approach that takes a set of unsegmented stories, constructs an ontology of analogical schemas (corresponding to plot devices), and uses this ontology to efficiently find analogs within new stories, yielding significant time-savings over linear analog retrieval at a small accuracy cost.", "text": "figure analog analogical mapping spontaneous analogy. analogical mapping given explicit source target free interfering context. spontaneous analogy analogs spontaneously retrieved long-term memory. process spontaneous analogy shares properties low-level perception exempliﬁed figure within seconds presented visual image pterodactyl ﬂying canyon typically describe image using word pterodactyl even special explicit recent priming concept indeed even consciously thought pterodactyls several years. produce word pterodactyl must segment pterodactyl canyon retrieve pterodactyl concept thousands concepts stored memory. must learned pterodactyl concept begin unsegmented images. perceptual process robust noise pterodactyl image could partially occluded ill-lit oddly colored even drawn cartoon still able correctly identify shape likewise many details plot devices story example could altered obfuscated analogy would degrade gracefully. primary technical contribution paper algorithm called spontol solves problem spontaneous analogy efﬁcient parsing storage retrieval analogs long-term memory. given corpus many large unsegmented relational structures spontol discovers analogical schemas useful characterizing corpus efﬁciently retrieves analogs given structure. e.g. given narratives predicate form spontol discovers plot computational models analogy assume given delineated source domain often speciﬁed target domain. systems address analogs isolated large domains spontaneously retrieved long-term memory process call spontaneous analogy. present system represents relational structures feature bags. using representation system leverages perceptual algorithms automatically create ontology relational structures efﬁciently retrieve analogs relational structures long-term memory. provide demonstration approach takes unsegmented stories constructs ontology analogical schemas uses ontology efﬁciently analogs within stories yielding signiﬁcant time-savings linear analog retrieval small accuracy cost. day-to-day experience often generate analogies spontaneously explicit prodding conjure analogs aspects current situation. example reading story recognize plot device analogous used another story read long ago. shared plot device small part story usually explicitly delineated presented isolation rest story recognize analogy plot device even general plots stories analogous. somehow segment plot device retrieve analog another story longdormant memory. spontaneous analogy process efﬁciently retrieving analog long-term memory given unsegmented source domain part source shares structural similarity analog though might share surface similarity. process differs standard models analogy given delineated source concept often target concept. given pair analogs analogical mapping relatively straightforward. difﬁcult problem ﬁnding analogs begin with. chalmers french hofstadter argue when program’s discovery correspondences situations direct result explicitly given appropriate structures work with victory ﬁnding analogy becomes somewhat hollow. terminology analog substructure domain structurally similar substructure another domain analogical schema generalization analog. example input domain might entire story romeo juliet analog would part story romeo kills tybalt killed romeo’s friend mercutio analogical schema would generalized plot device revenge killing. remainder paper describe related work give background perceptual systems describe spontol algorithm transforms problem spontaneous analogy perceptual problem demonstrate spontol’s performance story database discuss implications shortcomings spontol conclude earlier work problem analogy absence explicitly segmented domains. coward system addresses problem searching mappings within large graph essentially searching isomorphic subgraphs. subdue compresses large graphs breaking repeated subgraphs limited output must strict hierarchy would unable discover lattice structure concepts figure nauty uses number heuristics efﬁciently determine whether graph subgraph another must given source target graphs begin with. also apply chunker feature graphlet kernels related spontol’s transform represent partial graphs earlier work applies cases kind entity kind relation binary relations spontol works multiple kinds entities relations including relations large arity. phase mac/fac bears relation spontaneous analog retrieval. uses vectors content number nodes edges graph heuristic analog retrieval. however cases subgraph question part much larger graph heuristics uses drowned larger graph. likewise arcs also assumes analogs delineated seql generalizes relational concepts doesn’t build hierarchical ontology analogical schemas. work representing structures feature vectors. example holographic reduced representations used implement vector symbolic architectures correlation vector overlap structural similarity work limited requires vectors length represent small graphs represents binary relations single type approach directly extendable relational structures stories demonstration. also limitation system proposed rachkovskij kussul baidyk systems also limited unable exploit partial analogical schemas. partial overlap systems’ vectors correspond common subgraph corresponding structures. systems stand contrast spontol able represent larger structures efﬁciently common substructures. spontol transforms relational structures feature bags surface similarity corresponds structural similarity relational structures. spontol made transformation problem spontaneous analogy reduced problem feature overlap several existing perceptual systems used exploit patterns feature vectors. implementation spontol uses model inspired human sensory cortices called ontol ontol pair algorithms given sensor inputs ﬁrst algorithm constructs ontology concisely encodes inputs. example given vectors representing visual windows natural images ontol produces feature hierarchy loosely modeled seen visual cortex. second algorithm takes input ontology vector parses vector. produces output vector encoded higher-level features ontology. addition bottomup parsing second algorithm also makes top-down predictions unspeciﬁed values vector. ontol ignorant modality input. ontol given information sensory organ producing inputs. ignorance able leverage ontol patterns abstract sensory inputs actually encodings relational structures. ontology learning ontol’s ontology formation algorithm called chunker seeks concepts allow concise characterization vectors. since chunks vectors chunker applied recursively create ontology. essence algorithm similar recursive block pursuit algorithm described search large frequently occurring sets features. chunker differs allows multiple inheritance recursive block pursuit creates strict tree structures. section show importance property ﬁnding multiple analogical schemas within single relational structure. simplicity describe discrete binary version chunker algorithm takes input feature bags produces ontology provided pickett modiﬁed continuous vectors. version vector treated value feature signifying inclusion value signifying exclusion. candidate evaluated much would compress ontology best candidate selected added feature bags process repeated candidates found reduce description length ontology. figure shows ontology constructed algorithm applied animal dataset sensory percepts features animal. although parsing problem np-complete single bottom-up pass performed logarithmic time importantly ontol examines small subset concepts instances parsing. means that judging concept similarity ontol need compare nodes. property important spontaneous analog retrieval describe method transforming relational structures sparse feature vectors problem analog retrieval reduced problem percept parsing. example process shown sour grapes fable figure process rely transform takes small relational structure converts feature size relational structure limited runtime quadratic size structure. view limitation acceptable people generally cannot keep details entire lengthy novel working memory. generally people focus aspect novel abstracted summary novel therefore break large relational structure multiple overlapping windows. window small connected statements statements connected share least argument. spontol exploits principle akin used hmax model visual cortex number windows relational structure increases probability decreases another structure windows without isomorphic ﬁrst. process building ontology analogical schemas large relational structures called spontol-build described figure algorithm extracts numwindows windows large relational structure transforms feature bags chunks feature bags create ontology windows called windowontology. spontol-build re-encodes windows parsing using ontology re-encodes larger structures feature parsed windows. finally spontol-build runs another pass chunking re-encoded structures generate schema ontology. process spontaneous analog retrieval called spontol-retrieve given figure given relational structure encode extracting windows parsing using windowontology parsing feature representation using schemaontology. yields schemas contained transforming small relational structures here describe operation transforms relational structure feature bag. demonstration assume relational structure described predicate logic approach limited representation. consider relational structure figure ontology instances. instances individual animals shown left base features right. black nodes middle correspond higher-level features. concept corresponds marked. inhibitory links shown dark circles. given ontology instance ontol’s parse doesn’t breathe feathers domestic ontol parse animal instance concept exception domestic. ontol given information animal also perform top-down inference unfold concept predict instance eggs hair tail etc.. latter step called top-down prediction. ontol searches parse minimizes description length instance. goldﬁsh example description goldﬁsh consists elements compressed description elements. creates ontology schemas given structures numwindows number windows grab structure. windowsize number statements window. deﬁne spontol-build randomly grab windows structure transform feature form. foreach numwindows wanted grapes could them. caused decide grapes sour though grapes weren’t. likewise often blame failures circumstances real reason incapable. blamefor=blamefor.fail circumstances=blamefor fail=blamefor.fail fail=blamefor incapable=blamefor.fail incapable=blamefor incapable=fail men=blamefor.fail men=blamefor men=fail men=incapable finds analogical schemas relational structure schemaontology schema ontology. windowontology window ontology. numwindows number windows grab structure. windowsize number statements window. deﬁne spontol-retrieve relational statements statement either relation arguments special relation sameas uses syntax sameas <name> sameas relation allows statements statements. e.g. statements figure encode decides grapes sour. given small relational structure transforms feature using variant conjunctive coding. breaks statement roles ﬁllers. example statement want offox ofgrapes roles ﬁllers namely arguments want relation. breaks statement want=offox want=ofgrapes want means argument want roles creates large ﬁllers. multiple instances relation gives arbitrary lettering makes special case sameas relation. case uses operator replace intermediate variable. example statements sameas sameas would yield decide.sour=ofgrapes. operator allows encode nested statements though input spontol already encoded predicate form shown shows story statements. show window story feature transform finally story represented many transformed windows ments). given roles ﬁllers chains ﬁllers ﬁller equalities. example decide=offox want=offox chaining gives decide=want. chaining essential recognizing structural similarity relational structures allows side-step criticism conjunctive coding tensor products code wantb=offox overlap code want=offox chaining introduces code wantb=want makes similarity apparent searching analogs chaining roles ﬁllers treats role-ﬁller bindings atomic feature. note that treat roles ﬁllers atomic features ontol doesn’t recognize overlap among feature bags unless share exactly feature. example atomic feature wantb=offox resemblance want=offox ontol feature. also note ordering roles feature arbitrary consistent men=incapable feature incapable=men feature. left side figure shows window taken sour grapes story figure right side feature transform statements consisting atoms. applied spontol database stories provided thagard include fables plays encoded predicate format story unsorted statements. example story predicate form shown figure note although predicates arguments english names algorithm treats gensyms except special sameas relation. encoding smallest story statements largest statements average statements. spontol-build stories using numwindows windowsize produced ontology stories part shown figure ﬁgure double suicide analogical schema found romeo juliet julius caesar. former romeo thinks juliet dead causes kill himself. juliet actually alive ﬁnds romeo died causes kill herself. likewise julius caesar cassius kills himself hearing titinius’s death. titinius actually alive sees cassius’s corpse kills himself. largest schema found shared romeo juliet west side story stories lovers rival groups. latter doesn’t inherit double suicide schema maria doesn’t story tony meets death murder suicide. schemas found quite general. example oval lower right incoming edges outgoing edges corresponds schema single event signiﬁcant effects. oval double suicide oval corresponds schema killing avenge another killing. spontol-retrieve uses schema ontology efﬁciently retrieve schemas story used make inferences story manner analogous goldﬁsh example section evaluate efﬁciency spontol-retrieve randomly split story dataset training stories testing stories. used ontology learned training measured number comparisons needed retrieve schemas testing set. compare approach mac/fac which phase visits figure part ontology spontol learned story dataset. ontology figure black ovals represent higher level concepts. features omitted space limitations. instead show outgoing edges black oval. ontology higher level concepts correspond shared surface features ﬁgure high level concepts correspond shared structural features analogical schemas. example highlighted oval right represents double suicide schema happens romeo juliet julius caesar. training stories. whereas mac/fac returns entire stories spontol-retrieve returns analogical schemas comparison modify spontol-retrieve return instances inherit relevantschemas rather schemas. sured percentage stories correctly retrieved story determined correct retrieved mac/fac. spontol effectively improves linear case-by-case comparison indexed logarithmic-time look-up slight cost accuracy. therefore spontol requires orders magnitude fewer comparisons mac/fac linear look-up algorithm larger datasets hypothesize differences even pronounced. although comparison spontol-retrieve fast vector operation large datasets even linear number vector operations becomes impractical. future work test systems broader range relational datasets help elucidate conditions spontol yields high accuracy very-low retrieval cost. chief contribution paper demonstration system spontol able solve problem spontaneous analogy. demonstrated spontol efﬁciently store retrieve analogs without need human delineation schemas. representation also offers solution binding problem long-term memory allows efﬁcient analog retrieval absence explicitly segmented domains. binding problem asks meaningfully represent bindings roles ﬁllers. solutions binding problem connectionism terms temporal synchronicity temporal synchronicity works knowledge working memory models typically address storage long-term memory relying form conjunctive coding tensor products. though systems fail address relational structures efﬁciently retrieved long-term memory hypothesize workingmemory system lisa necessary chaining process system relies. spontol offer evidence support uniform substrate intelligence particular we’ve shown system designed process perceptual data leveraged process symbolic data provide insight species capable higher-order cognition might evolved species capable low-level perception. although spontol addresses outstanding problems computational analogy still ample room future work. implementation characterizing relational structure windows might scale well large structures without modiﬁcations. open problem windows might managed sensible way. spontol currently uses bags windows medium-sized structures. propose extending spontol allowing hierarchies progressively higher-order bags represent larger structures", "year": 2013}