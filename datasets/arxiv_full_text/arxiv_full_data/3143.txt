{"title": "Generalizing k-means for an arbitrary distance matrix", "tag": ["cs.LG", "cs.CV", "stat.ML"], "abstract": "The original k-means clustering method works only if the exact vectors representing the data points are known. Therefore calculating the distances from the centroids needs vector operations, since the average of abstract data points is undefined. Existing algorithms can be extended for those cases when the sole input is the distance matrix, and the exact representing vectors are unknown. This extension may be named relational k-means after a notation for a similar algorithm invented for fuzzy clustering. A method is then proposed for generalizing k-means for scenarios when the data points have absolutely no connection with a Euclidean space.", "text": "original k-means clustering method works exact vectors representing data points known. therefore calculating distances centroids needs vector operations since average abstract data points undeﬁned. existing algorithms extended cases sole input distance matrix exact representing vectors unknown. extension named relational k-means notation similar algorithm invented fuzzy clustering. method proposed generalizing k-means scenarios data points absolutely connection euclidean space. main diﬃculty method requires data points elements euclidean space since need average data points somehow. practice often data points distance function derived euclidean representation. even worse distance function metric all. clustering schemes like k-means applicable cases k-means requires vectors input. method reported successfully generalized generalized method known non-euclidean relational fuzzy c-means similar extension k-means viewed vast simpliﬁcation nerf c-means described next sections. suppose ﬁrst euclidean distance matrix data points exact location vectors representing unknown rn×n squared distance matrix namely ||pi pj||. objective calculate squared norms ||pi zi||. distance vectors special case linear combinations points coeﬃcients zero. λipi calculated transformation made fact calculating centroid distance thus possible computing quadratic form. means that even thing know squared distance matrix practically k-means heuristic without substantial modiﬁcations. course time complexity impaired computing quadratic form expensive operation. denote standard basis vector index ...n} λ⊤aλ pi∈s still makes sense even derived euclidean distances. therefore formula yields generalization centroid distances. generalization shows k-means algorithm adapted abstract distances. questionable though whether generalized clustering method yields interesting useful clusters. completely arbitrary matrix produce strange λ⊤aλ takes negative value vector distance deﬁned negative. course possible case euclidean squared distance matrix. negative distances eliminated ensuring negative deﬁnite restriction quadratic form linear hyperplane perpendicular require modiﬁcation original squared distance matrix modiﬁcation small possible sense. method proposed called β-spread transformation applicable well. pairwise distances gradually increased amount matrix desired kind. approach reported work well fuzzy c-means real-world data. real-world suitability analogous matrix correction method generalized k-means evaluated.", "year": 2013}