{"title": "Estimating Causal Direction and Confounding of Two Discrete Variables", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "We propose a method to classify the causal relationship between two discrete variables given only the joint distribution of the variables, acknowledging that the method is subject to an inherent baseline error. We assume that the causal system is acyclicity, but we do allow for hidden common causes. Our algorithm presupposes that the probability distributions $P(C)$ of a cause $C$ is independent from the probability distribution $P(E\\mid C)$ of the cause-effect mechanism. While our classifier is trained with a Bayesian assumption of flat hyperpriors, we do not make this assumption about our test data. This work connects to recent developments on the identifiability of causal models over continuous variables under the assumption of \"independent mechanisms\". Carefully-commented Python notebooks that reproduce all our experiments are available online at http://vision.caltech.edu/~kchalupk/code.html.", "text": "propose method classify causal relationship discrete variables given joint distribution variables acknowledging method subject inherent baseline error. assume causal system acyclicity allow hidden common causes. algorithm presupposes probability distributions cause independent probability distribution cause-effect mechanism. classiﬁer trained bayesian assumption hyperpriors make assumption test data. work connects recent developments identiﬁability causal models continuous variables assumption independent mechanisms. carefully-commented python notebooks reproduce experiments available online vision.caltech.edu/ ˜kchalupk/code.html. take discrete variables probabilistically dependent. assume feedback variables case causes causes further assume probabilistic dependence variables always arises causal connection variables fundamental causal question answer questions cause cause common cause since assumed feedback system options mutually exclusive. them however occur together confounder. fig. enumerates possible hypotheses. within causal graphical models framework differentiating causally interesting possibilities general possible ability intervene system. example differentiate pure-confounding direct-causal case intervene observe whether effect distribution given observations ability intervene system however problem general identiﬁable. roughly speaking reason simply without assumptions form distribution joint factorized hidden confounder easily endowed distribution give marginal related work common remedies fundamental unidentiﬁability two-variable causal system resort interventions introduce additional assumptions system derive solution works assumptions. recent body work attacks problem establishing whether speciﬁc assumptions respect functional form causal relationship hold. shimizu showed continuous variables effect linear function cause non-gaussian noise causal direction identiﬁed limit inﬁnite sample size. bility results case effect nonlinear function cause noise additive even gaussian. zhang hyv¨arinen showed postnonlinear model invertible function noise term identiﬁable. additive noise models framework applied discrete variables peters work focused distinguishing causal orientation absence confounding extended linear non-gaussian methods general hypothesis space janzing showed additive noise assumption used detect pure confounding success i.e. distinguish hypothesis hypotheses assumption additive noise supplies remarkable identiﬁability results natural application many cases variation data thought derive measurement process otherwise deterministic functional relation. respect general space possible probabilistic causal relations constitutes substantive assumption. particular discrete case application longer natural. bayesian perspective question causal model identiﬁcation softened question model selection based posterior probability causal structure give data. classic work bayesian network learning heckerman chickering developed bayesian scoring criterion allowed deﬁne posterior probability possible bayesian network given dataset. motivated results geiger pearl meek showed linear gaussian parameterizations multinomial parameterizations causal models identical independence structure cannot principle distinguished given observational joint distribution observed variables score property assigned score graphs independence structure. results geiger pearl meek make existential claim joint distribution parameterization appropriate form exists causal structure markov equivalence class. need conclude existential claim like heckerman chickering aren’t reasons data could suggest causal structure markov equivalence class probable another. figure possible causal structures linking assume discrete unobserved. principle impossible identify correct causal structure given samples. report tackle problem using minimalistic assumptions. ﬁnal result classiﬁer differentiates between cases confusion matrices shown fig. equivalence class true causal model. this however renders task impossible hypotheses enumerated fig. markov-equivalent. contribution assumptions formally identical assess likelihood causal structures observed variables bearing mind even limit inﬁnitely many samples true model cannot determined structures deemed less likely. approach similar spirit work puts explicit bayesian prior likely causal system causes conditionals less complex reverse conditionals complexity measured hilbert space norm conditional density functions. formulation plausible easily applicable discrete systems consider dimensional parameterization joint. assume sampled according sampling procedure compute density function using multivariate change varirecent review mooij compares range methods decide causal direction variables including methods discussed above. knowledge none methods attempt distinguish pure-causal confounded causal+confounded case take approach inspired bayesian methods discussed sec. consider bayesian model sampled uninformative hyperprior property distribution cause independent distribution effect conditioned cause since distributions considerations multinomial uninformative hyperprior dirichlet distribution parameters equal remembering actually vector whose dimensionality clear context). variable cause effect whether confounding depends causal systems fig. sampled. example also confounding assumptions consider ﬁrst problem identifying causal direction. assume either confounding. assumptions sec. allow compute given joint likelihood likelihood likelihood ratio allows decide causal direction likely represents. ﬁrst derive visualize likelihood case binary variables. next generalize result general finally analyze experimentally sensitive causal direction classiﬁer breaking assumption uninformative dirichlet hyperpriors jacobian linear transformation jacobian transformation transformation determinant jacobian readily computable paper using computer algebra systems. implementation used theano perform computation note cardinality cardinality jacobians entries. computing determinants complexity assume grows rather quickly growing cardinality. priors call causal direction classiﬁer follows classiﬁer. classiﬁer outputs uninformative-hyperprior likelihood ratio larger outputs otherwise. note optimal classiﬁer perfect baseline error optimal classiﬁer assumptions built error assuming sampled uninformative dirichlet prior given either given probability limit inﬁnite classiﬁcation trials error rate classiﬁer elr. whereas integral analytically computable estimate using monte carlo methods following sections. fig. leftmost entry curve corresponds various cardinalities example already figure likelihood-ratio function nine different values corresponds values larger likely opposite causal direction regions. blue signiﬁes opposite. decision boundary shown black. union orthogonal planes simplex four connected components along skewed axis. classiﬁer assigns class class otherwise optimal classiﬁer assumptions. fig. shows across three-dimensional simplex. ﬁgure shows nine slices simplex different values coordinate. figure samples dirichlet mixtures. plot shows three random samples ten-component mixture dirichlet distributions simplex. mixture component different random parameter plot ﬁxed different |log| parameter limits smallest largest value coordinates deﬁne mixture component. tions? draw mixtures ﬁxed log|. k-th component mixture parameter cardinality however considerations suggest assumption noninformative hyperpriors rather strong fact possible show decision surface precisely ﬂipped appropriate adjustment making classiﬁer’s error precisely experiments however suggest using classiﬁer reasonable choice wide range circumstances especially cardinality grows. experiments checked error changes allow αmax parameter hyperpriors grow. experimental procedure follows dimensionality αmax. sample hyperpriors dimensionality αmax. sample parameters within given αmax bounds consists dirichlet mixtures described above. sample priors hyperprior. sample times hyperpriors chose transposep figure results direction-classiﬁcation experiment. varied cardinality well αmax mixture dirichlets setting sampled distributions according causal model recorded classiﬁcation error simple classiﬁer. results show that cardinality grows classiﬁer’s accuracy increases. figure results direction-classiﬁcation experiment number dirichlet mixture model hyperprior components varies. ﬁxed vary results show max-likelihood classiﬁer assumes noninformative priors sensitive number dirichlet mixture components test data sampled from. experiment available vision.caltech.edu/ ˜kchalupk/code.html). checked well classiﬁer performs vary cardinality variables allow true hyperprior mixture dirichlets analogously experiment sec. fig. shows results. note classiﬁcation errors much lower deciding causal direction case. problems principle unidentiﬁable appears latter inherently easier. neural classiﬁer seems little bothered growing αmax. largest source error cardinality larger seems neural network training rather anything grows classiﬁer’s decision boundary approximates decision boundary dirichlet mixtures. another trend αmax grows variance error grows small growing trend error itself. addition fig. shows error increase allow mixture components components holding αmax large value thus classiﬁer performs well even extremely complex hyperpriors least average. unfortunately deriving optimal classiﬁer case difﬁcult without additional assumptions latent instead propose black-box classiﬁer. created dataset distributions direct-causal confounded case using uninformative dirichlet prior either confounded case. confounded distribution chose cardinality hidden confounder uniformly random next trained neural network classify causal structure figure shows results applying classiﬁer distributions sampled hyperpriors cardinalities expected number errors much lower higher cardinality. cardinality confusion matrix shows neural networks however insigniﬁcant issues total error testpoints. error remark problem identiﬁable true causal class point training test dataset. distribution could arise possible causal figure confusion matrices all-causal-classes classiﬁcation task. test consists distributions sampled uniform hyperpriors sampled statistics training data results total number errors=. results total errors=. average results classiﬁer test sampled non-uniform hyperpriors αmax errors average. case test contains distributions classes sampled equal chance. systems independent. fact error nears high-cardinality case indicates likelihoods assumptions grow peaked cardinality grows. thus optimal decision quite safely called true decision. addition fig. shows average confusion table hundred trials classiﬁer applied distributions cardinality corresponding possible causal structures sampled non-uniform hyperpriors αmax performance drop drastic compared fig. discussion developed neural network determines causal structure links discrete variables. allow confounding variables assumed acyclicity. classiﬁer takes input joint probability table variables outputs likely causal graph corresponds joint. possible causal graphs span range shown fig. independence confounding co-occurring direct causation. emphasize limitations classiﬁer since classiﬁer makes forced choice acyclic alternatives necessarily produce error generated cyclic systems. goal achieve accuracy. example error fig. however necessarily result. considerations sec. show even assumptions hold optimal classiﬁer non-zero error. latter consequence non-identiﬁability problem possible general identify causal structure variables looking joint distribution without intervention. goal introduce minimal assumptions that acknowledging nonidentiﬁability enable make useful inferences. noted cardinality variables raises task becomes identiﬁable sense that given possible causal graphs strongly dominates others respect likelihood. situation likely causal structure becomes essentially possible barring small error problem becomes practically identiﬁable. applies assuming generative model corresponds reality. assumptions discussed sec. boil ideas world creates causes independently causal mechanisms causes random variables whose distributions sampled dirichlet hyperpriors. causal mechanisms conditional distributions effects given causes also sampled dirichlet hyperpriors. whether assumptions realistic undecidable question. nevertheless series simple experiments showed assumption hyperpriors essential classiﬁers’ average performance decrease signiﬁcantly allow hyperpriors vary although variance performance grows. future work carefully analyze conditions ﬂat-hyperprior classiﬁer performs well even hyperpriors ﬂat. current working hypothesis long hyperprior hyperprior classiﬁcation performance doesn’t change signiﬁcantly average seen experiments increased variance. shohei shimizu explained task under circumstances determine causal structure based data obtained controlled experiments passive observation only? answer high-cardinality discrete variables seems enough assume independence train neural network learns black-box mapping observations causal generative mechanism.", "year": 2016}