{"title": "Time Series Segmentation through Automatic Feature Learning", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Internet of things (IoT) applications have become increasingly popular in recent years, with applications ranging from building energy monitoring to personal health tracking and activity recognition. In order to leverage these data, automatic knowledge extraction - whereby we map from observations to interpretable states and transitions - must be done at scale. As such, we have seen many recent IoT data sets include annotations with a human expert specifying states, recorded as a set of boundaries and associated labels in a data sequence. These data can be used to build automatic labeling algorithms that produce labels as an expert would. Here, we refer to human-specified boundaries as breakpoints. Traditional changepoint detection methods only look for statistically-detectable boundaries that are defined as abrupt variations in the generative parameters of a data sequence. However, we observe that breakpoints occur on more subtle boundaries that are non-trivial to detect with these statistical methods. In this work, we propose a new unsupervised approach, based on deep learning, that outperforms existing techniques and learns the more subtle, breakpoint boundaries with a high accuracy. Through extensive experiments on various real-world data sets - including human-activity sensing data, speech signals, and electroencephalogram (EEG) activity traces - we demonstrate the effectiveness of our algorithm for practical applications. Furthermore, we show that our approach achieves significantly better performance than previous methods.", "text": "changepoint detection important fundamental technique used analysis time series data. generally applied analyzing stock data sensor data internet things deployments physiological data analysis many others changepoint detection fundamental discovering distinct sequences values might associated states process directly observable. examining changepoints analysts build models sequences look pašerns sequences across multiple data sets. changepoint detection fundamental primitive building state-space process models. amount available data grows observe large fraction annotated human labels provided domain expert. œese labels useful modeling latent states state-transition sequences. examining temporal boundaries states speciﬁed annotated data analysts look similar transition pašerns feed complex models capture relationship states. example many mobile phone applications infer user’s activity using onboard sensors. order train models user must provide information activity. recorded internet things applications become increasingly popular recent years applications ranging building energy monitoring personal health tracking activity recognition. order leverage data automatic knowledge extraction whereby observations interpretable states transitions must done scale. such seen many recent data sets include annotations human expert specifying states recorded boundaries associated labels data sequence. œese data used build automatic labeling algorithms produce labels expert would. here refer human-speciﬁed boundaries breakpoints. traditional changepoint detection methods look statistically-detectable boundaries deﬁned abrupt variations generative parameters data sequence. however observe breakpoints occur subtle boundaries non-trivial detect statistical methods. work propose unsupervised approach based deep learning outperforms existing techniques learns subtle breakpoint boundaries high accuracy. œrough extensive experiments various real-world data sets including human-activity sensing data speech signals electroencephalogram activity traces demonstrate effectiveness algorithm practical applications. furthermore show approach achieves signiﬁcantly bešer performance previous methods. permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights thirdparty components work must honored. uses contact owner/author. figure performance breakpoint detection diﬀerent methods using smartphone sensor data activity recognition green line represents original signal circle line ground truth breakpoints. yellow star lines represent detected breakpoints using existing bayesian method prior distribution gamma gaussian respectively blue triangle lines represent detected breakpoints using method. method signiﬁcantly outperforms previous approaches ﬁnding breakpoints real-world applications. annotation data start time time. similarly experts spend great deal time annotating electrocardiogram data labels separate traces various cardiac states patient. changepoints abrupt changes trends data sequence. bayesian techniques discover looking changes parameters distribution generates sequence. considering generality problem many techniques exist literature. œese techniques ašempt capture generative process pre-determined model look changes parameters generative process. learning expert-speciﬁed boundaries models o‰en fail since changes easily captured pre-speciﬁed model generative process changepoints typically fall along parameter-shi‰ boundaries. changepoints speciﬁed experts o‰en arise state transition function latent temporal properties underlying process diﬃcult capture pre-speciﬁed model. œese rules encoded latent features traces practically impossible detect existing generative-model based changepoint detection algorithms observe existing methods poor identifying human-speciﬁed changepoints. summary existing changepoint detection methods main weaknesses rely prior parametric model time series data o‰en utilize simple features extracted input data mean variance spectrum etc. œerefore previous methods discover statistically-detectable boundaries. diﬀerentiate statistically-detectable changepoints herea‰er refer human-speciﬁed changepoints breakpoints. furthermore propose novel algorithm uses deep learning techniques detect breakpoints without prior assumptions generative process. method automatically learns features useful represent input data thus discover hidden structure real-world time series data. note approach broad applicability general changepoint detection even outside application breakpoint detection considered paper. using smartphone sensor data activity detection note even a‰er careful tuning parameters method still could accurately detect breakpoint boundaries. furthermore technique sensitive parameter changes easily estimate number breakpoints. moreover clear adapt parameters capture statistical properties true segment. comparison approach learns automatically. explain choose hyperparameters model simple heuristics learn direct observation analysis real-world traces. propose novel method utilizes deep learning automatically learn useful features represent data sequences generated expert-speciﬁed sequential segments. technique rely assumption changepoints caused abrupt changes parameters generative process previous methods making applicable broad coverage real-world applications. extensive experimental analysis using multiple realworld data sets. furthermore show choose hyperparameters model simple heuristic derived association statistical properties data performance model. œese experimental analysis demonstrate approach serve enabler real-world applications. furthermore compare method several existing approaches introduce metric measures eﬀectiveness changepoint detection scheme respect accuracy number predicted changepoints overlap true changepoint coordinates. experimental results show signiﬁcant advantage approach existing methods. changepoint detection ašracted researchers statistics data mining communities decades changepoint detection techniques applied various applications stock data analysis sensor data analysis systems physiological data analysis climate change detection genetic time-series analysis intrusion detection computer networks important thread changepoint detection compares probability distributions time-series samples past present intervals. intervals move forward typical strategy issue alarm changepoint distributions become ‘signiﬁcantly’ different. various changepoint detection methods apply strategy cumulative method generalized likelihood-ratio method change ﬁnder method similar strategy also employed novelty detection outlier detection another common thread subspace method using pre-designed time-series model subspace discovered principal component analysis trajectories past present intervals dissimilarity measured distance subspaces. however challenge methods accurately estimate density. solve problem previous work tries estimate density-ratio instead density itself. rationale knowing densities implies knowing density ratio vice versa since decomposition unique. direct densityratio estimation substantially easier density estimation following idea methods direct densityratio estimation developed kernel mean matching method logistic-regression method kullback-leibler importance estimation procedure existing changepoint detection methods fundamentally limited type changepoints detect because rely pre-designed parametric models underlying probability distributions autoregressive models state-space models practice observe pre-speciﬁed parametric models diﬃcult parameterize predicted changepoints align annotation boundaries data; utilize simple statistical properties mean variance spectrum serve features changepoint detection. however features generalize well performance varies substantially across diﬀerent data sets. œerefore existing changepoint detection methods detect statistically-detectable boundaries overcome problems propose novel breakpoint detection scheme detect human-speciﬁed boundaries learning representative features speciﬁc input time-series data exploiting features segmentation. technique utilizes autoencoder model automatically learn features useful represent input time-series data generally applied broad coverage realworld applications. figure pipeline breakpoint detection system. ﬁrst segment input data series windows apply autoencoder models deep learning extract representative features input data. ‡ese extracted features utilized calculate distance consecutive windows timestamps corresponding local-maximal distance detected breakpoints. section describe breakpoint detection approach utilizes deep autoencoder model extract representative features time-series data. idea autoencoder models deep learning techniques automatically eﬀectively extract unique features speciﬁc input data without making prior assumption generative process produced data. obtain deeper understanding temporal dynamics input data achieve bešer performance detecting user-speciﬁed breakpoints. end-to-end pipeline method shown figure detailed steps described below. given time series consisting channels across timestamps input data matrix real matrix measurement recorded i-th channel j-th timestamp. fully explore temporal characteristics data follow common practice partition series segments according user-speciﬁed time window size t-th window stack recordings within form column vector denoted input data matrix thus reformulated note segmented data overlapping recordings shown figure powerful feature extraction hand-cra‰ed shallow models. moreover deep learning models progressively capture compact features higher layers corresponding hierarchical human vision systems. among building blocks models autoencoders automatically learn non-parametric feature mapping function minimizing reconstruction error input reconstructed output. œerefore ﬁrst explore autoencoder techniques extract features useful representing input data. autoencoders name suggests consist stages encoding decoding. single-layer autoencoder kind neural network consisting hidden layer aims common feature basis input data. ﬁrst used reduce dimensionality sešing number extracted features less input. dimension encoding output higher encoding result enriched expressive. autoencoder model usually trained back-propagation techniques unsupervised manner aiming minimizing error reconstructed results original inputs. stacking multiple autoencoders deep autoencoders generate compact higher-level semantic features beneﬁcial feature representation. second term regularization term tends decrease magnitude weights helps prevent overﬁšing model learning stacking objective feature representation minimize respect explore stochastic gradient descent technique solve optimization problem shown perform fairly well practice. train autoencoder network ﬁrst initialize parameter small random value near zero apply stochastic gradient descent technique iterative optimization. note compute exact gradient objective function respect variable /****************** *****************/ segmented time window extract features according compute distances dist consecutive feature vectors according dist local-maximal distance although stochastic gradient descent method eﬀective solving learnt result heavily relies seeds used initialize optimization process. œerefore multiple hidden layers stack model order achieve stable performance. words similar previous autoencoder variants mechanism also used build deep network model stacking. ﬁrst layer deep learning model optimal layer minimizing objective function using stochastic gradient descent technique. representations learned ﬁrst layer used input second layer forth. figure experiments approach synthetic data produced using generative models real-world crowdsignal.io data upper ﬁgures show input signals ground truth changepoints shown lines. bottom ﬁgures show distance features consecutive time windows detected changepoints shown dash lines. method eﬀective detecting statistically-detectable changepoints human-speciﬁed breakpoints a‰er extract representative features input data deep learning technique described above calculate distance features corresponding consecutive time windows. t-th timestamp distance consecutive features computed numerator euclidean distance features corresponding consecutive time windows denominator serves normalization term. based computed distance {dist summarize overall process automatic breakpoint detection algorithm worth noting approach broadly applied general changepoint detection even outside application breakpoint detection considered paper. compared stateof-the-art methods approach assumption generative models input data features automatically extracted input data making representative analysis. œrough extensive experimental analysis section show method signiﬁcantly outperforms previous approaches. section validate eﬀectiveness deep learning based breakpoint detection method. apply method real-world data sets including crowdsignal.io sensor data state data human activity recognition data dcase sound data systematically analyze robustness approach diﬀerent parameter sešings respect window size codebook size number layers autoencoder models order provide practical hyperparameter selection guidelines. furthermore show signiﬁcant advantage method state-of-the-art techniques. demonstrate fundamental intuition method detecting statistically-detectable changepoints human-speciﬁed breakpoints shown figure synthetic data generate number changepoints uniform distribution segment generated sampling exponential distribution whose parameter sampled uniform distribution. crowdsignal.io sensor data contains mobile sensor recordings associated users’ activity information taking elevator riding escalator walking. figure upper ﬁgures describe input signals lines represent ground truth changepoints. bošom ﬁgures show distance features consecutive windows dashed lines represent detected changepoints. figure show higher distance measurements method correspond ground-truth changepoints data thus resulting accurate changepoint detection lays foundations approach real-world applications. state data constructed continuous measurement emotiv neuroheadset. duration measurement seconds. state classiﬁed using camera measurement phase manually added a‰er analyzing video. indicates eye-closed eye-open state. values chronological order ﬁrst measured value data. human activity recognition data contains activity mode recordings carried group volunteers within bracket years. person performed activities wearing smartphone waist. using embedded accelerometer gyroscope captures -axial linear acceleration -axial angular velocity constant rate experiments video-recorded generate labels manually. dcase sound data contains sounds carry large amount information everyday environment physical events take place humans identify diﬀerent sounds scenes recognize individual sound sources data contains classes sound events. class represented recordings. choose time-series data randomly selecting sound events. ƒantification metrics. fair comparsion state-of-the-art techniques receiver operating characteristic curve measure performance approach. true positive rate false positive rate curve deﬁned follows deﬁne toleration distance detected breakpoint corresponding closest true breakpoint detected breakpoint seen correctly detected breakpoint following conditions satisﬁed condition closest detected breakpoint condition time distance smaller toleration distance i.e. obtain curve method varying toleration distance sensitivity analysis. examine sensitivity method diﬀerent parameter sešings order provide practical guidelines hyperparameter selection. eﬀects window size first show sensitivity approach respect window size setting depth model ratio codebook size input data size dim/dim figure shows curve data using diﬀerent window sizes curve generated calculating false-positive corresponding true-positive rate vary guard band around true breakpoint described section figure observe best window size data data dcase data set. investigate select best window size data show relationship true segment distribution input data corresponding best window size. figure describe cumulative distribution function true segment sizes input data line average size true segments. comparing figure figure observe best window size data roughly true segment size corresponding œerefore experiments suggest best window size size corresponds true segment distribution. eﬀects model depth since stacked autoencoders achieve stable detection results show depth inﬂuences method’s performance. ratio codebook size input data size dim/dim window size data data dcase data respectively experimental results shown figure best detection performance achieved hidden layers autoencoder models three data sets. similar observations made related work hidden layers commonly used existing deep learning research. eﬀects codebook size examine eﬀect codebook size method. model depth window size data data dcase data figure shows curve diﬀerent codebook sizes three data sets. size codebook negligible inﬂuence detection performance method. hyperparameter selection heuristic figures provide guide choosing hyperparameters method window size size corresponding true segment size distribution; model depth randomly select codebook size. performance method improved feeding detection results back network ﬁne-tune hyperparameters automatically. technique explored future work. compare method existing changepoint detection techniques. bayesian changepoint detection well studied literature several important variants developed compare method approaches three realworld data sets shown figure represent online bayesian method proposed adams prior distribution gamma gaussian respectively. represent pruned exact linear time method proposed killick prior distribution exponential mean-shi‰ mean-variance shi‰ figure curve data data dcase data diﬀerent model depth. experimental results observe best detection performance achieved hidden layers. similar observations found deep learning community hidden layers commonly used figure curve data data dcase data diﬀerent methods. represent online bayesian method proposed adams prior distribution gamma gaussian respectively. represent pruned exact linear time method proposed killick prior distribution exponential mean-shi… mean-variance shi… poisson respectively. represents density-ratio estimation method proposed experimental results observe approach signiﬁcantly outperforms previous techniques. parameter se‚ings. based analysis section model depth ratio codebook size input data size dim/dim window size data data dcase data set. fair comparison state-of-the-art approaches parameter sešings used papers speciﬁcally gamma prior inverse variance rate exponential prior segment size univariate gaussian model prior parameters rate exponential prior experimental results. figure observe method consistently achieves higher tpr’s approaches level fpr. instance equals achieve signiﬁcantly higher methods improvement corresponding data data dcase data respectively. œerefore method signiﬁcantly outperforms state-of-the-art approaches. table compares diﬀerent evaluation criteria. rather varying guard band calculate true false positive rate closest predicted breakpoint true breakpoint calculate mean-squared error measure rate over/under prediction breakpoints also calculate prediction ratio number detected breakpoints number true breakpoints higher prediction ratio means algorithm tends over-predict lower means under-predicts. ratio means algorithm predicted exact number actual breakpoints. algorithms high prediction ratios tend lower mse’s since higher probability predicted breakpoint close actual one. conversely algorithms prediction ratios tend higher mse’s. capture tradeoﬀ introduce measure prediction loss deﬁned follows. algorithm predicts breakpoint timestamp. result perfect prediction loss prevent prediction loss denoted undeﬁned number predicted breakpoints zero note high prediction ratio. table observe deep learning based method achieves lowest prediction loss among algorithms o‰en producing prediction ratio near small mse. œese experimental results demonstrate advantage approach existing methods. section observe method achieves signiﬁcant improvement state-of-the-art approaches reason previous methods suﬀer several following limitations however assumptions applicable real-world data sets following reasons input data points segments generated certain distributions data points three data sets); data points correlated ﬁxed parameter sešings optimal data sets. instance average size true segments three data sets respectively shown figure order achieve good detection performance optimal window size selected adapt data set. shown figure optimal window size automatically tuned algorithm three data sets respectively. summary deep learning based method overcome limitations previous work enabling system automatically learn hidden structures extract useful features time-series data. œerefore approach generally applied broad coverage real-world applications. table comparison existing approaches deep learning based method. represent online bayesian method proposed adams prior distribution gamma gaussian respectively. represent pruned exact linear time method proposed killick prior distribution exponential mean-shi… mean-variance shi… poisson respectively. represents densityratio estimation method proposed calculate prediction ratio mean-squared error prediction loss data data dcase data respectively. observe signiﬁcant advantage approach previous methods. represent input time-series data. worth noting approach independent interest general changepoint detection even outside context breakpoint detection considered paper. unlike previous methods approach rely specifying prior generative model input data. furthermore introduce simple hyperparameter tuning criteria careful sensitivity analysis window size codebook size depth network. œrough extensive experiments multiple types real-world data sets including human-activity sensing speech traces demonstrate eﬀectiveness proposed method show signiﬁcantly outperforms existing approaches. technique serve davide anguita alessandro ghio luca oneto xavier parra perez jorge luis reyes ortiz. public domain dataset human activity recognition using smartphones. proceedings international european symposium artiﬁcial neural networks computational intelligence machine learning. steﬀen bickel michael br¨uckner tobias scheﬀer. discriminative learning diﬀering training test distributions. proceedings international conference machine learning. brodsky boris darkhovsky. nonparametric methods change point problems. vol. springer science business media. chen arjun gupta. parametric statistical change point analysis applications genetics medicine ﬁnance. springer science business media. arthur grešon alex smola jiayuan huang marcel schmišfull karsten borgwardt bernhard sch¨olkopf. covariate shi‰ kernel mean matching. dataset shi‡ machine learning valery guralnik jaideep srivastava. event detection time series data. proceedings sigkdd international conference knowledge discovery data mining. abeer hasan ning arjun gupta. informationbased approach change-point problem noncentral skew distribution applications stock market data. sequential analysis shohei hido yuta tsuboi hisashi kashima masashi sugiyama takafumi kanamori. statistical outlier detection using direct density ratio estimation. knowledge information systems yoshinobu kawahara takehisa yairi kazuo machida. change-point detection time-series data based subspace identiﬁcation. seventh ieee international conference data mining ieee implicit smartphone user authentication sensors contextual machine learning. dependable systems networks annual ieee/ifip international conference ieee song makoto yamada nigel collier masashi sugiyama. change-point detection time-series data relative density-ratio estimation. neural networks university illinois urbana-champaign. center supercomputing research development cybenko. continuous valued neural networks hidden layers suﬃcient. rychelly glenneson ramos paulo ribeiro jos´e vin´ıcius cardoso. anomalies detection wireless sensor networks using bayesian changepoints. mobile sensor systems ieee international conference ieee jaxk reeves jien chen xiaolan wang robert lund review comparison changepoint detection techniques climate data. journal applied meteorology climatology oliver roesler. david rosenﬁeld enlu zhou frank wilhelm ansgar conrad walton roth alicia meuret. change point analysis longitudinal physiological data detection cardio-respiratory changes preceding panic ašacks. biological psychology vasilios siris fotini papagalou. application anomaly detection algorithms detecting ﬂooding ašacks. global telecommunications conference globecom’. ieee vol. ieee masashi sugiyama shinichi nakajima hisashi kashima paul buenau motoaki kawanabe. direct importance estimation model selection application covariate shi‰ adaptation. advances neural information processing systems. masashi sugiyama taiji suzuki takafumi kanamori. density ratio estimation machine learning. cambridge university press. pascal vincent hugo larochelle yoshua bengio pierre-antoine manzagol. extracting composing robust features denoising autoencoders. proceedings international conference machine learning. kenji yamanishi jun-ichi takeuchi. unifying framework detecting outliers change points non-stationary time series data. proceedings eighth sigkdd international conference knowledge discovery data mining. kenji yamanishi jun-ichi takeuchi graham williams peter milne. on-line unsupervised outlier detection using ﬁnite mixtures discounting learning algorithms. data mining knowledge discovery", "year": 2018}