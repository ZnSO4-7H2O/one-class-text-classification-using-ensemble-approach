{"title": "Label Stability in Multiple Instance Learning", "tag": ["cs.CV", "stat.ML"], "abstract": "We address the problem of \\emph{instance label stability} in multiple instance learning (MIL) classifiers. These classifiers are trained only on globally annotated images (bags), but often can provide fine-grained annotations for image pixels or patches (instances). This is interesting for computer aided diagnosis (CAD) and other medical image analysis tasks for which only a coarse labeling is provided. Unfortunately, the instance labels may be unstable. This means that a slight change in training data could potentially lead to abnormalities being detected in different parts of the image, which is undesirable from a CAD point of view. Despite MIL gaining popularity in the CAD literature, this issue has not yet been addressed. We investigate the stability of instance labels provided by several MIL classifiers on 5 different datasets, of which 3 are medical image datasets (breast histopathology, diabetic retinopathy and computed tomography lung images). We propose an unsupervised measure to evaluate instance stability, and demonstrate that a performance-stability trade-off can be made when comparing MIL classifiers.", "text": "abstract. address problem instance label stability multiple instance learning classiﬁers. classiﬁers trained globally annotated images often provide ﬁne-grained annotations image pixels patches interesting computer aided diagnosis medical image analysis tasks coarse labeling provided. unfortunately instance labels unstable. means slight change training data could potentially lead abnormalities detected diﬀerent parts image undesirable point view. despite gaining popularity literature issue addressed. investigate stability instance labels provided several classiﬁers diﬀerent datasets medical image datasets propose unsupervised measure evaluate instance stability demonstrate performance-stability trade-oﬀ made comparing classiﬁers. obtaining ground-truth annotations patches used train supervised classiﬁers localization abnormalities medical images costly time-consuming. hinders supervised classiﬁers task. fortunately global labels whole images overall condition patient available readily. multiple instance learning extension supervised learning train classiﬁers using weakly labeled data. example classiﬁer trained images labeled healthy abnormal consists unlabeled image patches would able label patches novel image healthy abnormal. becoming popular many applications desirable obtain instance labels inspect instances deemed positive. example weakly labeled x-ray images healthy subjects patients aﬀected tuberculosis used train classiﬁer provide local abnormality scores visualized across lungs. furthermore classiﬁer outperforms pitfall using classiﬁers obtain instance labels labels might unstable example diﬀerent subset data used training. clearly undesirable diagnostic setting abnormalities would highlighted diﬀerent parts image. example classiﬁer used identify regions tibial trabecular bone related cartilage loss. most positive region labeled positive classiﬁers trained diﬀerent subsets data. able identify research phenomenon investigated emphasizes importance present work. rare cases instance-level annotations available instance labels evaluated using auc. results show best classiﬁer correspond best instance classiﬁer emphasizing bag-level results reliable instance labels needed. another approach evaluate instances qualitatively. however typically done single classiﬁer raises question whether abnormalities would found training would change slightly. propose evaluate stability instance-labeling classiﬁers additional measure classiﬁer comparison. evaluate stability measures three datasets computed tomography lung images chronic obstructive pulmonary disease histopathology images breast cancer diabetic retinopathy images. demonstrate stability varies popular classiﬁers show choosing classiﬁer best bag-level performance lead reliable instance labels. multiple instance learning sample instances instance thus d-dimensional feature vector. given labeled training bags ...ntr} standard assumption exist hidden instance labels relate labels follows positive contains least positive instance. originally goal train classiﬁer label previously unseen bags. several classiﬁers inferring instance classiﬁer combining outputs bag’s instances example noisy-or simplemil propagates label instances simply trains supervised classiﬁer possibly noisy instance labels. classiﬁers explicitly assumption misvm milboost adaptations popular learning algorithms. example misvm extends searching optimal hyperplane deﬁnes also instance labels another group bag-level classiﬁers typically represent single feature vector supervised classiﬁers training directly classiﬁers often robust usually provide instance labels. notable exception miles represents similarities prototype instances data annotated instance level. otherwise papers examine instances qualitatively displaying abnormal instances although instance labels would interesting diagnostic point view proposed evaluation unsupervised easily adopted studies. interested evaluating similarity labeling vector outputs classiﬁers trained slightly diﬀerent subsets training data test compares outputs clustering procedures unsupervised. appropriate goal fact related measures proposed follows. situation many true negative instances value would inﬂated negative instances classiﬁers agree result classiﬁer still unstable respect positive instances. nature tasks might consider important classiﬁers agree positive instances. therefore also consider agreement positive labels only jaccard distance emphasize novelty measures themselves wellknown are. novelty resides measure context derive measures appropriate ones stability want quantify. classiﬁer selection. instance classiﬁcation stability crucial issue study measure combination bag-level select classiﬁer good trade-oﬀ instance stability. classiﬁer possible solution parametrized values. intermediate solutions classiﬁers theory obtained designing randomized classiﬁer trains classiﬁer probability auc-stability probability classiﬁer plane pareto frontier classiﬁers pareto eﬃcient i.e. improvement made without decreasing instance stability vice versa. optimal classiﬁers therefore selected pareto frontier. classiﬁer highest necessarily desirable solution instance labels importance. mark problems molecule activity prediction. breast instance patch tissue microarray analysis image patient malignant benign tumor. messidor instance illustrative example. fig. shows pairwise stability measures copd validation data miles classiﬁers trained random training data. considerable disagreement measures surprising large overlap training sets. measures quite correlated higher values inﬂated agreement negative instances. fig. shows instance classiﬁcations change true positive i.e. image copd patient. always classiﬁed positive instance labels unstable. perfectly stable classiﬁer would bimodal distribution classifying instances positive either times. also show number rois stable unstable labels. several rois containing emphysema unstable classiﬁcations emphysemous patch even consistently classiﬁed negative. shows always classiﬁed correctly instance labels reliable. fig. positiveness instances positive bag. left often classiﬁed positive many rois holds. right examples rois axial slice lung voxels hounsﬁeld units shown. rois contain emphysema often classiﬁed positive. rois largely unaﬀected consistently classiﬁed negative. linear kernel regularization parameter misvm miles. train/test split following times randomly sample training bags train classiﬁer evaluate test dataset. splits done randomly musk breast messidor based predeﬁned sets copd. average aucs average pairwise instance stabilities corresponding pareto frontiers shown fig. note point achieved classiﬁer labels instances positive. main observation accurate classiﬁer often stable one. trade-oﬀ especially well-illustrated copd datasets. similar behavior sets shows validation results classiﬁer selection would obtain classiﬁer similar performance stability test set. regard classiﬁers misvm variants seem relatively good choices. miles popular classiﬁer good performance indeed quite accurate time unstable. diﬀerence miclassiﬁers miles probably fact miles trains classiﬁer ﬁrst infers miclassiﬁers train directly. milboost inaccurate unstable especially copd high disagreement instances label positive. note goal experiments demonstrate trade-oﬀ between stability maximize auc. nevertheless best performances achieved classiﬁers tested breast messidor copd datasets. previous works highest performances datasets shows result state despite using less data optimization. addressed issue stability instance labels provided classiﬁers. examined unsupervised measures agreement based labels based positive labels might interesting point view. experiments demonstrate trade-oﬀ performance instance label stability misvm classiﬁer provides good trade-oﬀ. general propose instance label stability additional evaluation measure applying classiﬁers cad. acknowledgements. research partially ﬁnanced netherlands organization scientiﬁc research thank melih kandemir kindly providing breast messidor datasets.", "year": 2017}