{"title": "Generating Visual Explanations", "tag": ["cs.CV", "cs.AI", "cs.CL"], "abstract": "Clearly explaining a rationale for a classification decision to an end-user can be as important as the decision itself. Existing approaches for deep visual recognition are generally opaque and do not output any justification text; contemporary vision-language models can describe image content but fail to take into account class-discriminative image aspects which justify visual predictions. We propose a new model that focuses on the discriminating properties of the visible object, jointly predicts a class label, and explains why the predicted label is appropriate for the image. We propose a novel loss function based on sampling and reinforcement learning that learns to generate sentences that realize a global sentence property, such as class specificity. Our results on a fine-grained bird species classification dataset show that our model is able to generate explanations which are not only consistent with an image but also more discriminative than descriptions produced by existing captioning methods.", "text": "abstract. clearly explaining rationale classiﬁcation decision end-user important decision itself. existing approaches deep visual recognition generally opaque output justiﬁcation text; contemporary vision-language models describe image content fail take account class-discriminative image aspects justify visual predictions. propose model focuses discriminating properties visible object jointly predicts class label explains predicted label appropriate image. propose novel loss function based sampling reinforcement learning learns generate sentences realize global sentence property class speciﬁcity. results ﬁne-grained bird species classiﬁcation dataset show model able generate explanations consistent image also discriminative descriptions produced existing captioning methods. explaining output visual system compatible visual evidence component understanding interacting systems deep classiﬁcation methods tremendous success visual recognition predictions unsatisfactory model cannot provide consistent justiﬁcation made certain prediction. contrast systems justify prediction consistent visual elements user likely trusted consider explanations determining certain decision consistent visual evidence diﬀerentiate introspection explanation systems explain model determines ﬁnal output justiﬁcation explanation systems produce sentences detailing visual evidence compatible system output concentrate justiﬁcation explanation systems systems useful non-experts detailed knowledge modern computer vision systems fig. proposed model generates visual explanations. visual explanations image relevant class relevant. contrast image descriptions image relevant necessarily class relevant class deﬁnitions class relevant necessarily image relevant. visual explanations above class discriminative visual features also present image discussed. shown figure explanations distinct descriptions provide sentence based visual information deﬁnitions provide sentence based class information. unlike descriptions deﬁnitions visual explanations detail certain category appropriate given image mentioning image relevant features. example consider image classiﬁcation system predicts certain image belongs class western grebe standard captioning system might provide description this large bird white neck black back water. however description mention discriminative features could also applied laysan albatross contrast propose provide explanations this western grebe bird long white neck pointy yellow beak eye. explanation includes property e.g. crucial distinguishing western grebe laysan albatross. such system explains predicted category appropriate image. outline approach figure condition language generation image predicted class label allows generate classspeciﬁc sentences. unlike caption models condition visual features network pre-trained imagenet model also includes ﬁne-grained recognition pipeline produce strong image features like many contemporary description models model learns generate sequence words using lstm however design novel loss function encourages generated sentences include class discriminative information. challenge designing loss optimize class speciﬁcity class speciﬁcity global sentence property e.g. whereas sentence this black bird bright class speciﬁc bronzed cowbird words phrases sentence black less class discriminative own. proposed generation loss enforces generated sequences fulﬁll certain global property category speciﬁcity. ﬁnal output sampled sentence backpropagate discriminative loss fig. generation explanatory text joint classiﬁcation language model. model extracts visual features using ﬁne-grained classiﬁer language generation. additionally unlike description models also condition sentence generation predicted class label. sentence sampling mechanism technique reinforcement learning literature. typical sentence generation losses optimize alignment generated ground truth sentences discriminative loss speciﬁcally optimizes class-speciﬁcity. best knowledge ﬁrst method produce deep visual explanations using natural language justiﬁcations. describe novel joint vision language explanation model combines classiﬁcation sentence generation incorporates loss function operating sampled sentences. show formulation able focus generated text discriminative model produces better explanations description-only baseline. results also conﬁrm generated sentence quality improves respect traditional sentence generation metrics including discriminative class label loss training. result holds even class conditioning ablated test time. explanation. automatic reasoning explanation long rich history within artiﬁcial intelligence community explanation systems span variety applications including explaining medical diagnosis simulator actions robot movements many systems rule-based solely reliant ﬁlling predetermined template methods require expert-level explanations decision processes. contrast visual explanation method learned directly data optimizing explanations fulﬁll proposed visual explanation criteria. model provided expert explanations decision processes rather learns visual features text descriptions. contrast systems like explain underlying mechanism behind decision authors concentrate prediction justiﬁable user. systems advantageous rely user familiarity design intelligent system order provide useful information. variety computer vision methods focused discovering visual features help explain image classiﬁcation decision importantly models attempt link discovered discriminative features natural language expressions. believe methods discover discriminative visual features complementary proposed system features could used additional inputs model producing better explanations. visual description. early image description methods rely ﬁrst detecting visual concepts scene generating sentence either simple language model sentence template recent deep models outperformed systems capable producing ﬂuent accurate descriptions images. many systems learn images sentences directly guidance intermediate features likewise model attempts learn visual explanation given image predicted label intermediate guidance object attributes part locations. though description models condition sentence generation image features propose conditioning generation auxiliary information words used describe similar image train set. however explore conditioning generation category labels ﬁne-grained descriptions. common loss function used train lstm based sentence generation models cross-entropy loss probability distribution predicted ground truth words. frequently however cross-entropy loss directly optimize properties desired test time. proposes alternative training scheme generating unambiguous region descriptions maximizes probability speciﬁc region description minimizing probability region descriptions. work propose novel loss function sentence generation allows specify global constraint generated sentences. fine-grained classiﬁcation. object classiﬁcation ﬁne-grained classiﬁcation particular attractive demonstrate explanation systems describing image content suﬃcient explanation. explanation models must focus aspects class-speciﬁc depicted image. ﬁne-grained zero-shot few-shot image classiﬁcation systems attributes auxiliary information support visual information. attributes thought means discretize high dimensional feature space series simple readily interpretable decision statements explanation. however attributes several disadvantages. require ﬁne-grained object experts annotation costly. additional class list attributes needs revised ensure discriminativeness attributes generalizable. finally though list image attributes could help explain ﬁne-grained classiﬁcation attributes provide natural language explanation like user expects. therefore natural language descriptions collected achieved superior performance zero-shot learning compared attributes. fig. training explanation model. explanation model diﬀers caption models includes object category additional input incorporates reinforcement learning based discriminative loss reinforcement learning computer vision. vision models incorporate algorithms reinforcement learning speciﬁcally backpropagate sampling mechanism recently applied visual question answering activity detection additionally sampling mechanism attend speciﬁc image regions caption generation standard cross-entropy loss training. visual explanation model aims produce explanation describes visual content present speciﬁc image instance contains appropriate information explain image instance belongs speciﬁc category. ensure generated descriptions meet requirements explanation including relevance loss discriminative loss main technical contribution inclusion loss acts sampled word sequences training. proposed loss enables enforce global sentence constraints sentences applying loss sampled sentences ensure ﬁnal output system fulﬁlls criteria explanation. following sections consider sentence word sequence comprising either complete sentence sentence fragment. image relevance accomplished training visual description model. model based lrcn consists convolutional neural network extracts powerful high level visual features stacked recurrent networks learn generate description conditioned visual features. inference ﬁrst lstm receives previously generated word input produces output second lstm receives output ﬁrst lstm well image feature produces probability distribution next word. time step word generated sampling distribution generation continues end-of-sentence token generated. propose modiﬁcations lrcn framework increase image relevance generated sequences first explanation model uses category predictions additional input second lstm sentence generation model. intuitively category information help inform caption generation model words attributes likely occur description. example caption generation model conditioned images mistakes eyebrow category level information could indicate likely given class. experimented methods represent class labels found vector representation ﬁrst train language model e.g. lstm generate word sequences conditioned images compute average hidden state lstm across sequences classes train worked best. second rich category speciﬁc features generate relevant explanations. training instance consists image category label ground truth sentence. training model receives ground truth word time step deﬁne relevance loss ground truth word image category batch size. training model predict word ground truth sentence model trained produce sentences correspond image content. however loss explicitly encourage generated sentences discuss discerning visual properties. order generate sentences image relevant category speciﬁc include discriminative loss focus sentence generation discriminative visual properties image. discriminative loss based reinforcement learning paradigm learning layers require intermediate activations network sampled. formulation ﬁrst sample sentence input sampled sentence discriminative loss function. sampling sentence computing loss ensure sentences sampled model likely class discriminative. ﬁrst overview backpropagate sampling mechanism discuss calculate discriminative loss. overall function minimize explanation network weights descriptions given image category since expectation descriptions intractable estimate training time using monte carlo sampling descriptions categorical distribution given model’s softmax output timestep. discrete distribution sampling operation categorical distribution non-smooth distribution’s deﬁned log-likelihood sampled description log-likelihood ground truth description. case however sampled gradient term weighted reward pushing weights increase likelihood assigned highly rewarded descriptions. category given generated sentence placing discriminative loss sampled sentence sentence acts information bottleneck. model produce output large reward generated sentence must include enough information classify original image properly. sentence classiﬁer train single layer lstm-based classiﬁcation network classify ground truth sentences. sentence classiﬁer correctly predicts class unseen validation sentences time. number possibly descriptions dataset necessarily contain discriminative properties nonetheless classiﬁer provides enough information train explanation model. update sentence classiﬁer weights training explanation model. dataset. work employ caltech ucsd birds dataset contains classes north american bird species images total. recent extension dataset collected sentences images. sentences describe content image e.g. this bird also gives detailed description bird e.g. that cone-shaped beak feathers black face patch. unlike image-sentence datasets every image dataset belongs class therefore sentences well images associated single label. property makes dataset unique visual explanation task generate sentences discriminative classspeciﬁc. stress sentences collected collected task visual explanation. consequently explain image belongs certain class rather include discriptive details bird class. implementation. image features extract dimensional features penultimate layer compact bilinear ﬁne-grained classiﬁcation model pre-trained dataset achieves accuracy one-hot vectors represent input words time step learn -dimensional embedding inputting word -dimensional lstm. train models using caﬀe determine model hyperparameters using standard validation evaluating test set. reported results standard test set. baseline ablation models. order investigate explanation model propose baseline models description model deﬁnition model. description baseline trained generate sentences conditioned images equivalent lrcn except features ﬁne-grained classiﬁer. deﬁnition model trained generate sentences using image label input. consequently model outputs sentence diﬀerent image instances class. comparing baselines explanation model demonstrate explanation model image class relevant thus generates superior explanations. explanation model diﬀers description model ways. first addition image generated sentences conditioned class predictions. second explanations trained discriminative loss enforces generated sentences contain class speciﬁc information. understand importance contributions compare explanation model explanation-label model trained discriminative loss explanation-discriminative model conditioned predicted class. comparing explanation model explanation-label model explanation-discriminative model demonstrate class information discriminative loss important generating descriptions. metrics. evaluate explanation model automatic metrics human evaluation. automatic metrics rely common sentence evaluation metrics meteor cider meteor computed matching words generated reference sentences unlike common metrics bleu uses wordnet also match synonyms. cider measures similarity generated sentence reference sentence counting common n-grams tf-idf weighted. consequently metric rewards sentences correctly including n-grams uncommon dataset. measuring class relevance considerably diﬃcult. could lstm sentence classiﬁer used train discriminative loss unfair metric models trained directly increase accuracy measured lstm classiﬁer. instead measure class relevance considering similar generated sentences class ground truth sentences class. sentences describe certain bird class e.g. cardinal contain similar words phrases ground truth cardinal sentences ground truth black bird sentences. compute cider scores images bird class instead using ground truth image descriptions reference sentences reference sentences correspond particular class. call metric class similarity metric. class relevant sentences result higher cider scores possible model produces better overall sentences higher cider score without generating class relevant descriptions. demonstrate sentences class relevant also compute class rank metric. compute metric compute cider score generated sentence ground truth reference sentences classes dataset references. consequently image associated cider score measures similarity generated sentences classes dataset. cider scores computed generated sentences cardinals higher compared cardinal reference sentences compared reference sentences classes. choose emphasize cider score measuring class relevance includes tf-idf weighting n-grams. consequently bird includes unique feature eyes generated sentences mention attribute rewarded sentences mention attributes common across bird classes. ultimate goal explanation system provide useful information human. therefore also consulted experienced bird watchers rate explanations baseline ablation models. provided random sample images test sentences generated models asked bird watchers rank sentence explained classiﬁcation best. consulting experienced bird watchers important sentences list correct non-discriminative attributes. example sentence this geococcyx bird brown feathers brown crown. correct description mention unique attributes bird class poor explanation. though diﬃcult expect average person infer know information experienced bird watchers aware features important bird classiﬁcation. table comparison explanation model deﬁnition description baseline well explanation-label explanation-discriminative ablation models. demonstrate generated explanations image relevant computing meteor cider scores demonstrate class relevance using class similarity metric class rank metric finally experienced bird watchers rank explanations. metrics explanation model performs best. demonstrate model produces visual explanations showing generated explanations fulﬁll aspects proposed deﬁnition visual explanation image relevant class relevant. furthermore demonstrate training model generate class speciﬁc descriptions generate higher quality sentences based common sentence generation metrics. image relevance. table columns record meteor cider scores generated sentences. importantly explanation model higher meteor cider scores baselines. explanation model also outperforms explanation-label explanation-discriminative model suggesting label conditioning discriminative loss producing better sentences. furthermore meteor cider substantially higher including discriminative loss training demonstrating including additional loss leads better generated sentences. surprisingly deﬁnition model produces image relevant sentences description model. information label vector image appear complimentary explanation-label model conditions generation image label vector produces better sentences. class relevance. table columns record class similarity class rank metrics explanation model produces higher class similarity score models substantial margin. class rank explanation model also lower model suggesting sentences generated explanation model closely resemble correct class classes dataset. emphasize goal produce reasonable explanations classiﬁcations rank categories based explanations. expect rank sentences produced explanation model lower necessarily rank one. ranking metric quite diﬃcult; sentences must include enough information diﬀerentiate similar bird classes without looking image results clearly show explanation model performs best diﬃcult task. accuracy scores produced lstm sentence classiﬁer follow general trend explanation model producing highest accuracy description model producing lowest accuracy explanation. table column details evaluation experienced bird watchers. bird experts evaluated randomly selected images answered sentence provided best explanation bird class. explanation model best mean rank followed description model. trend resembles trend seen evaluating class relevance. additionally models conditioned label lower rank suggesting label information important explanations. figure shows sample explanations produced ﬁrst outputing declaration predicted class label justiﬁcation conjunction followed explantory text sentence fragment produced model described section qualitatively explanation model performs quite well. note model accurately describes detail black cheek patch kentucky warbler long neck pied billed grebe. remainder qualitative results omit class declaration easier comparison. comparison explanations baselines ablations. figure compares sentences generated deﬁnition description baselines explanationlabel explanation-discriminative ablations explanation model. model produces reasonable sentences however expect explanation model produce sentences discuss class relevant attributes. many images explanation model mentions attributes models mention. example figure explanation model speciﬁes bronzed cowbird eyes rarer bird attribute attributes mentioned correctly deﬁnition description models similarly explaining white necked raven explanation model identiﬁes white nape unique attribute bird. based image relevance metrics also expect explanations image relevant. obvious example figure explanation model includes attributes present image hooded merganser whereas models mention least incorrect attribute. fig. example sentences generated baseline models ablation models proposed explanation model. correct attributes highlighted green mostly correct attributes highlighted yellow incorrect attributes highlighted red. explanation model consistently discusses image relevant class relevant features. comparing deﬁnitions explanations. figure directly compares explanations deﬁnitions three bird categories. explanations left column include attribute image instance bird class present image instance bird class right column. deﬁnition remains constant image instances bird class deﬁnition produce sentences image relevant. example second deﬁnition model indicates bird spot head. though true image left many downy woodpecker images true image right. contrast explanation model produces image relevant sentences images. training discriminative loss. illustrate discriminative loss impacts sentence generation directly compare description model explanation-discriminative model figure neither models fig. compare generated explanations descriptions. explanations left include attribute present image right. contrast deﬁnitions explanation model adjust output based visual evidence. receives class information test time though explanation-discriminative model explicitly trained produced class speciﬁc sentences. models generate visually correct sentences. however generated sentences trained discriminative loss contain properties speciﬁc class often ones generated using image description model even though neither access class label test time. instance class black-capped vireo models discuss properties visually correct explanationdiscriminative model mentions black head prominent distinguishing properties vireo type. similarly white pelican image explanation-discriminative model mentions properties long neck orange beak ﬁne-grained discriminative. class conditioning. qualitatively observe relative importance image features label features explanation model condition explanations baltimore oriole cliﬀ swallow painted bunting correct class incorrect classes conditioning painted bunting explanations cliﬀ swallow baltimore oriole include colors present suggesting painted bunting label encourages generated captions include certain color words. however baltimore oriole image colors mentioned conditioning painted bunting similar true color oriole suggesting visual evidence informs sentence generation. explanation important capability deployment intelligent systems. visual explanation rich research direction especially ﬁeld computer vision continues employ improve deep models easily interpretable. work important step towards explaining deep visual fig. comparison sentences generated using description explanationdiscriminative models. though capable accurately describing visual attributes explanation-discriminative model captures class-speciﬁc attributes. fig. observe explanations change conditioning diﬀerent classes. bird categories like painted bunting carry strong class information heavily inﬂuence explanation. build explanation model proposed novel reinforcement learning based loss allows inﬂuence kinds sentences generated sentence level loss function. though focus discriminative loss work believe general principle including loss operates sampled sentence optimizes global sentence property potentially beneﬁcial applications. example propose introducing vocabulary words captioning system. though models optimize global sentence property neither optimizes property directly. summary presented novel framework provides explanations visual classiﬁer. quantitative qualitative evaluations demonstrate potential proposed model eﬀectiveness novel loss function. explanation model goes beyond capabilities current captioning systems eﬀectively incorporates classiﬁcation information produce convincing explanations potentially advance adoption many sophisticated systems. acknowledgements. work supported darpa afrl muri award awards iis- iis- berkeley vision learning center. marcus rohrbach supported fellowship within fitweltweit-program german academic exchange service lisa anne hendricks supported ndseg fellowship. thank experienced bird watchers celeste riepe samantha masaki helping evaluate model.", "year": 2016}