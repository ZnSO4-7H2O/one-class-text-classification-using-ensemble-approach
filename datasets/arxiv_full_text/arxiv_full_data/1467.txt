{"title": "Ask Your Neurons: A Neural-based Approach to Answering Questions about  Images", "tag": ["cs.CV", "cs.AI", "cs.CL"], "abstract": "We address a question answering task on real-world images that is set up as a Visual Turing Test. By combining latest advances in image representation and natural language processing, we propose Neural-Image-QA, an end-to-end formulation to this problem for which all parts are trained jointly. In contrast to previous efforts, we are facing a multi-modal problem where the language output (answer) is conditioned on visual and natural language input (image and question). Our approach Neural-Image-QA doubles the performance of the previous best approach on this problem. We provide additional insights into the problem by analyzing how much information is contained only in the language part for which we provide a new human baseline. To study human consensus, which is related to the ambiguities inherent in this challenging task, we propose two novel metrics and collect additional answers which extends the original DAQUAR dataset to DAQUAR-Consensus.", "text": "figure approach neural-image-qa question answering recurrent neural network using long short term memory answer question image feed both image question lstm. question encoded generate answers answer generation phase previously predicted answers lstm symbol predicted. generate image video descriptions conditioning visual features stem deep learning architectures employ recurrent neural network approaches produce descriptions. push boundaries explore limits deep learning architectures propose architecture answering questions images. contrast prior work task needs conditioning language well visual input. modalities interpreted jointly represented answer depends inferred meaning question image content. rich body work natural language understanding addressed textual question answering tasks based semantic parsing symbolic representation deduction systems also seen applications question answering images initial evidence deep architectures indeed achieve similar goal motivates work seek end-to-end architectures learn answer questions single holistic monolithic model. address question answering task real-world images visual turing test. combining latest advances image representation natural language processing propose neural-image-qa endto-end formulation problem parts trained jointly. contrast previous efforts facing multi-modal problem language output conditioned visual natural language input approach neural-image-qa doubles performance previous best approach problem. provide additional insights problem analyzing much information contained language part provide human baseline. study human consensus related ambiguities inherent challenging task propose novel metrics collect additional answers extends original daquar dataset daquar-consensus. advances natural language processing image understanding complex demanding tasks become within reach. take advantage recent developments push state-of-theart answering natural language questions real-world images. task unites inference question intends visual scene understanding word sequence prediction task. recently architectures based idea layered end-to-end trainable artiﬁcial neural networks improved state across wide range diverse tasks. prominently convolutional neural networks raised image classiﬁcation tasks long short term memory networks dominating performance range sequence prediction tasks machine translation answering recurrent neural network. overview given figure image analyzed convolutional neural network question together visual representation long short term memory network. system trained produce correct answer question image. lstm trained jointly end-to-end starting words pixels. contributions proposes novel approach based recurrent neural networks challenging task answering questions images. combines lstm end-to-end architecture predict answers conditioning question image. approach signiﬁcantly outperforms prior work task doubling performance. collect additional data study human consensus task propose metrics sensitive effects provide baseline asking humans answer questions without observing image. demonstrate variant system also answers question without accessing visual information beats human baseline. convolutional neural networks visual recognition. building recent success convolutional neural networks visual recognition directly learnt image data pre-trained large image corpora. rapid progress area within last years rich models disposal. recurrent neural networks sequence modeling. recurrent neural networks allow neural networks handle sequences ﬂexible length. particular variant called long short term memory shown recent success natural language tasks machine translation combining rnns cnns description visual content. task describing visual content like still images well videos successfully addressed combination previous ideas achieved using rnn-type model ﬁrst gets observe visual content trained afterwards predict sequence words description visual content. work extends idea question answering formulate model trained generate answer based visual well natural language input. ciation words meaning. often referred grounding problem particular meaning associated sensory input. problems historically addressed symbolic semantic parsing techniques recent trend machine learningbased approaches associations. approach follows idea enforce evaluate particular representation meaning language image modality. treat latent leave joint training approach establish appropriate internal representation question answering task. textual question answering. answering purely textual questions studied community state techniques typically employ semantic parsing arrive logical form capturing intended meaning infer relevant answers. recently success previously mentioned neural sequence models rnns carried task speciﬁcally uses dependency-tree recursive instead lstm reduce questionanswering problem classiﬁcation task. moreover according method cannot easily applied vision. propose different kind network memory networks unclear apply take advantage visual content. however neither show end-to-end monolithic approaches produce multiple words answers question images. visual turing test. recently several approaches proposed approach visual turing test i.e. answering question visual content. instance proposed binary version visual turing test synthetic data. present question answering system based semantic parser varied human question-answer pairs. contrast work method based neural architecture trained end-to-end therefore liberates approach ontological commitment would otherwise introduced semantic parser. scenario questions multiple word answers consequently decompose problem prewords ﬁnite vocabulary number answer words given question image. approach named neural-image-qa propose tackle problem follows. predict multiple words formulate problem predicting sequence words vocabulary extra token indicates answer sequence points question fully answered. thus formulate prediction procedure recursively ˆat− ˆat−} previous words beginning approach given answer far. approach terminated evaluate method solely based preˆ dicted answer words ignoring extra token ensure uniqueness predicted answer words want predict answer words prediction procedure trivially changed maximizing ˆat−. however practice algorithm learns predict previously predicted words. shown figure figure feed neural-imageqa question sequence words i.e. question. since problem formulated variablelength input/output sequence model parametric distribution neural-image-qa recurrent neural network softmax prediction layer. precisely neural-image-qa deep network built long-short term memory lstm recently shown effective learning variablelength sequence-to-sequence mapping one-hot vector encoding embedded lower dimensional space using jointly learnt latent linear embedding. training phase augment question words sequence corresponding ground truth answer words sequence i.e. test time prediction phase time step augment previously predicted answer words ˆa..t i.e. means question previous answers encoded implicitly hidden states lstm latent hidden representation learnt. encode image using provide every time step input lstm. input concatenation visualized detail figure lstm unit takes input vector time step predicts output word equal latent hidden state discussed linear embedding corresponding answer word contrast simple unit lstm unit additionally maintains memory cell allows learn long-term dynamics easily signiﬁcantly reduces vanishing exploding gradients problem precisely lstm unit described caffe implementation sigmoid nonlinearity hyperbolic tangent nonlinearity ev+e−v lstm updates time ev−e−v step given inputs memory cell follows embrace aforementioned ambiguities suggest using thresholded taxonomy-based wu-palmer similarity smaller threshold forgiving metric. report wups extremes start evaluation neural-image-qa full daquar dataset order study different variants training conditions. afterwards evaluate reduced daquar additional points comparison prior work. results full daquar table shows results neural-image-qa method full images question-answer pairs available test time. addition evaluate variant trained predict single word well variant visual features comparison prior work observe strong improvements points accuracy wups scores note that achieve improvement despite fact published number available comparison full uses ground truth object annotations puts method disadvantage. improvements observed train single word answer doubles accuracy obtained figure equation corresponds input gate equation input modulation gate equation forget gate determines much keep previous memory state. figures suggest output predictions occur question mark excluded loss computation model penalized solely based predicted answer words. implementation default hyper-parameters lstm models ﬁrst pretrained imagenet dataset next randomly initialize train last layer together lstm network task. step crucial obtaining good results. explored layered lstm model consistently obtained worse performance. pilot study found googlenet architecture consistently outperforms alexnet architecture model task model. section benchmark method task answering questions images. compare different variants proposed model prior work section addition section analyze well questions answered without using image order gain understanding biases form prior knowledge common sense. provide human baseline task. section discuss ambiguities question answering tasks analyze introducing metrics sensitive phenomena. particular wups score extended consensus metric considers multiple human answers. additional results available supplementary material project webpage experimental protocol evaluate approach daquar dataset provides human question answer pairs images indoor scenes follow evaluation protocol providing results accuracy wups score experiments full dataset well proposed reduced restricts output space object categories uses test images. addition also evaluate methods different subsets daquar word answers present. wups scores base experiments well consensus metrics wups scores metric generalization accuracy measure accounts word-level ambiguities answer words. instance ‘carton’ ‘box’ associated similar concept order study much information already contained questions train version model ignores visual input. results shown table table language best language only models compare well terms accuracy best models include vision. latter achieve full reduced respectively. order analyze ﬁnding collected human baseline human answer image asked participants answer daquar questions without looking images. turns humans guess correct answer cases exploiting prior knowledge common sense. interestingly best language only model outperforms human baseline substantial number answers plausible resemble form common sense knowledge employed humans infer answers without seen image. observe many cases inter human agreement answers given image question also reﬂected human baseline performance question answering task study analyze effect further extending dataset multiple human reference answers section proposing measure inspired work psychology handles disagreement section well conducting additional experiments section figure language neural-image-qa multi word models evaluated different subsets daquar. consider word subsets. blue horizontal lines represent single word variants evaluated answers exactly word. analyze effect figure show performance approach dependence number words answer performance single word variants one-word subset shown horizontal lines. although accuracy drops rapidly longer answers model capable producing signiﬁcant number correct words answers. single word variants edge single answers beneﬁt dataset bias towards type answers. quantitative results single word model one-word answers subset daquar shown table made substantial progress compared prior work still points margin human accuracy wups score results reduced daquar order provide performance numbers comparable proposed multiworld approach also method reduced object classes images question-answer pairs test time. subset agreement language multiple words single word neural-image-qa multiple words single word subset agreement language multiple words single word neural-image-qa multiple words single word subset full agreement language multiple words single word neural-image-qa multiple words single word figure study inter human agreement. x-axis consensus least half consensus full consensus results left consensus whole data right consensus test data. daquar-consensus order study effects consensus question answering task asked multiple participants answer question daquar dataset given respective image. follow scheme original data collection effort answer words numbers. impose restrictions answers. extends original data average test answers image question. refer dataset daquar-consensus. agreement propose consensus metric replacing averaging equation operator. call metric consensus suggest using metrics benchmarks. make implementation metrics publicly available. i-th question answer generated architecture k-th possible human answer corresponding k-th interpretation question. answers sets words membership measure instance call metric average consensus metric since limits approaches total number humans truly measure inter human agreement every question. consensus results using multiple reference answers daquarconsensus show detailed analysis inter human agreement. figure shows fraction data answers agree available questions least available questions agree observe majority data partial agreement even full disagreement possible. split dataset average consensus metric language multiple words single word neural-image-qa multiple words single word consensus metric language multiple words single word neural-image-qa multiple words single word three parts according criteria agreement agreement full agreement evaluate models splits subsets stronger agreement achieve substantial gains points accuracy full subset agreement respectively. splits seen curated versions daquar allows studies factored ambiguities. aforementioned average consensus metric generalizes notion agreement encourages predictions agreeable answers. hand consensus metric desired effect providing optimistic evaluation. table shows application measures data models. moreover table shows applied human answers test time captures ambiguities interpreting questions improving score human baseline also cooperates well wups takes word ambiguities account gaining higher score. show predicted answers different variants architecture table chosen examples highlight differences neural-image-qa language only. multiple words approach table otherwise single word model shown. despite failure cases language only makes reasonable guesses like predicting largest object could table object could found method answers correctly large part challenge spatial relations account substantial part daquar remain challenging. errors involve questions small objects negations shapes training data points aforementioned cases contribute mistakes. presented neural architecture answering natural language questions images contrasts prior efforts based semantic parsing outperforms prior work doubling performance challenging task. variant model image answer question performs slightly worse even outperforms human baseline collected condition. conclude model learnt biases patterns seen forms common sense prior knowledge humans accomplish task. observe indoor scene statistics spatial reasoning small objects well captured global representation true limitations representation explored larger datasets. extended existing daquar dataset daquarconsensus provides multiple reference answers allows study inter-human agreement consensus question answer task. propose metrics average consensus takes account human disagreement consensus captures disagreement human question answering. merrienboer gulcehre bougares schwenk bahdanau bengio. learning phrase representations using encoder-decoder statistical machine translation. emnlp donahue hendricks guadarrama rohrbach venugopalan saenko darrell. long-term recurrent convolutional networks visual recognition description. cvpr", "year": 2015}