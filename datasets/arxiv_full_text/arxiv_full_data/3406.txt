{"title": "Multivariate Regression with Grossly Corrupted Observations: A Robust  Approach and its Applications", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "This paper studies the problem of multivariate linear regression where a portion of the observations is grossly corrupted or is missing, and the magnitudes and locations of such occurrences are unknown in priori. To deal with this problem, we propose a new approach by explicitly consider the error source as well as its sparseness nature. An interesting property of our approach lies in its ability of allowing individual regression output elements or tasks to possess their unique noise levels. Moreover, despite working with a non-smooth optimization problem, our approach still guarantees to converge to its optimal solution. Experiments on synthetic data demonstrate the competitiveness of our approach compared with existing multivariate regression models. In addition, empirically our approach has been validated with very promising results on two exemplar real-world applications: The first concerns the prediction of \\textit{Big-Five} personality based on user behaviors at social network sites (SNSs), while the second is 3D human hand pose estimation from depth images. The implementation of our approach and comparison methods as well as the involved datasets are made publicly available in support of the open-source and reproducible research initiatives.", "text": "abstract paper studies problem multivariate linear regression portion observations grossly corrupted missing magnitudes locations occurrences unknown priori. deal problem propose approach explicitly consider error source well sparseness nature. interesting property approach lies ability allowing individual regression output elements tasks possess unique noise levels. moreover despite working non-smooth optimization problem approach still guarantees converge optimal solution. experiments synthetic data demonstrate competitiveness approach compared existing multivariate regression models. addition empirically approach validated promising results exemplar real-world applications ﬁrst concerns prediction big-five personality based user behaviors social network sites second human hand pose estimation depth images. implementation approach comparison methods well involved datasets made publicly available support open-source reproducible research initiatives. matrix containing observation noises. central problems statistics precisely estimate coeﬃcient regression matrix design matrix noisy observations typical assume noise bounded energy well-absorbed noise matrix usually modelled follow certain gaussian-type distributions. thus gives rise following regularized loss minimization framework statistics estimated denotes loss function refers tuning parameter corresponds regularization term. moreover least square loss usually popular choice shown achieve optimal rates convergence certain conditions also applied many applications including e.g. multi-task learning nonetheless exist real-life situations certain entries observation corrupted considerably larger errors normal ones incorporated noise model considered above. consider example following scenario data entries could severely contaminated careless even malicious user annotations errors unfortunately diﬃcult identiﬁed practice. type sparse large-magnitude noises might seriously damage performance above-mentioned estimator explicitly considering sparse matrix rn×p locations thus enables restore examples gross errors instead merely throwing away outliers. note model also capable dealing missing data problem i.e. situations subset observations missing. concretely missing observations imputed zeros model applied modiﬁed data. result loss function trade-oﬀ parameter regularization term. further rather usual least square loss norm deﬁned -norm columns considered loss function ability dealing diﬀerent noise levels regression tasks. additionally employ group sparsity inducing norm enforce group-structured sparsity -norm impose element-wise sparsity constraint detecting possible gross corruptions. paper contains following major contributions approach proposed context multivariate linear regression explicitly model recover missing grossly corrupted observations adoption -norm loss function also facilitates ability modeling noise levels individual outcome variables; induced non-smooth optimization problem addressed proposed multi-block proximal alternating direction method multipliers solver shown paper eﬃcient globally convergent; demonstrate general applicability approach interesting distinct real-world applications examined ﬁrst application involves investigation big-five personality user online behaviors interacting social network sites emerging problem computational psychology. second application concerns challenging computer-vision problem depthimage based human hand pose estimation. problems exemplify broad spectrum applications approach could applicable. empirical evaluation carried synthetic real datastets applications approach shown compare favorably existing multivariate regression models well application-speciﬁc state-of-the-art methods. last least support open-source reproducible practice implementations related datasets also made publicly available note passing part paper presented meanwhile paper presents substantial amount contents comparing algorithmic aspect approach carefully presented details self-complete manner convergence analysis proof well time complexity analysis; empirical application point view approach systematically examined series simulated data. practically approach also additionally validated interesting challenging application depth-image based human hand pose estimation competitive performance obtained synthetic real datasets. besides code also made publicly available support open-source research practice; presentation implementations approach well comparison methods related datasets detailed information found dedicated project webpage http//web.bii. a-star.edu.sg/~zhangxw/cmrg. side paper signiﬁcant re-written re-organized accommodate materials including e.g. review hand pose estimation related literature; overall work presented paper self-complete better connected real-world problems. line work machine learning statistics various methods proposed linear regression gross errors among examine univariate multivariate outputs respectively optimization problem standard least square loss. nevertheless pointed least square loss drawbacks first regression tasks corresponds element multivariate regression output regarded task) share regularization trade-oﬀ result varying noise levels contained diﬀerent regression tasks unfortunately ignored; second improve ﬁnite-sample performance often important choose optimal depends estimation unknown variance aiming address issues calibrated multivariate regression method proposed -norm employed novel loss function. enjoys number desirable properties including tuning insensitive capable calibrating tasks according individual noise levels. theoretical empirical evidence demonstrated ability deliver improved ﬁnite sample performance. inspires adopt approach -norm loss function. worth pointing induced optimization problem subsequently proposed solver bear clearly diﬀerences related work personality prediction relatively research eﬀorts attempting toward personality prediction snss behaviors prominent theory study personality big-five theory describes personality trait disparate dimensions areconscientiousness agreeableness extraversion openness neuroticism. traditionally common predict individual’s personality applying self-report inventory relies subjects questionnaires behaviors summarized quantitative ﬁve-dimensional personality descriptor. however method disadvantages. first practically infeasible conduct self-report inventory large-scale. second maliciously wrong answers might supplied sometimes idealized answers wishes provided instead real ones nevertheless reduce annotation credibility widely accepted psychology individual’s personality manifested behaviors. recent years social networks including facebook twitter renren weibo drastically changed people live communicate. evidences suggesting social network behaviors signiﬁcantly correlated real-world behaviors. hand fast growing number snss users provides large amount data social research hand still lacks proper model fully exploit data perform personality prediction. research eﬀort along direction probably gosling proposes mapping personality snss behaviors. speciﬁcally design features including friends count weekly usage based self-reported facebook usage observable proﬁle information investigate correlation personality features. meanwhile features entirely rely statistical descriptions rather ones explicitly revealing user behaviors. moreover data collection requires considerable manual eﬀorts since procedure based self-reported facebook utilization online proﬁle information making non-realistic practical purpose. related work hand pose estimation single depth images hand pose estimation refers problem estimating ﬁnger-level human hand joint locations vision-based hand interpretation played important roles diverse applications including humanoid animation robotic control human-computer interaction among others. core lies interesting challenging problem hand pose estimation owing mostly complex dexterous nature hand articulations facilitated emerging commodity-level depth cameras recent eﬀorts noticeable progress ﬁeld. binary latent tree model used guide searching process locations hand joints adopts evolutionary optimization method capture hand object interactions. dedicated random forest variant hand pose estimation problem proposed state-of-the-art empirical performance well nice theoretically consistency guarantees. emerging research topic hand pose dataset becoming facto benchmark methods assess performance hand pose estimation also considered empirical evaluation section paper. deﬁne max{α otherwise. given |xi|p) p-norm maxd |xi|p ∞-norm. group subset {··· cardinality denotes groups ∪g∈gg {··· denotes subset entries indices similar given matrix rn×d refer used size self-explained context. rows columns indexed respectively. identity matrix denotes symmetric positive deﬁnite matrices size p-by-p. follows deﬁne three norms frobenius spectral ∞-norms max≤i≤r maxij |aij|. rest paper organized follows. section propose robust multivariate regression model compare ﬁnite-sample performance multivariate regression models. section describe derivation algorithm cmrg solves induced optimization problem model proximal admm provide convergence analysis complexity analysis. section evaluate eﬀectiveness proposed method synthetic real data apply method predict personality user behaviours snss well estimate hand pose depth images. finally conclusions drawn section empirical loss function potential drawbacks tasks regularized parameter introduces unnecessary estimation bias tasks less noise order compensate tasks larger noise. highly non-trivial decide proper tuning parameter satisfactory result. remedy advocate calibrated multivariate regression model uses -norm loss function regularization dedicated regression task words calibrated toward individual noise level mathematically considers following optimization problem considered error k-th task. theoretically proven model achieves better ﬁnite-sample performance ordinary multivariate linear regression model sense estimator achieves optimal rates convergence choose independent therefore tuning parameter model depends noise level σk’s tuning parameter model insensitive noise level σk’s. unfortunately neither model model addresses gross error issue. natural idea toward addressing problem explicitly model gross errors stated corrected observations obtained simply removing gross errors used estimate coeﬃcient regression matrix speciﬁcally illustrate applicability model hand pose estimation depth images example. context instance depth image human hand associated observation vector containing coordinates hand joints. total length observation vector depends number joints. clear entries observation vector distinct intrinsically connected sense describe coordinates diﬀerent joints joints ﬁnger connected. moreover noise levels entries necessarily same. example ﬁnger tips prone large error joints ﬁnger smaller error. naturally suggests usage multi-task regression model loss aiming regularize diﬀerent tasks different parameters. hand ground-truth observations obtained based annual annotations hard precise occlusions truly diﬃcult rule potential existence gross errors either careless malicious user annotations. diﬀerent ordinary multivariate linear regression problems optimization problem challenging loss function regularization terms non-smooth. develop dedicated proximal admm algorithm also inline ﬁrst adopt variable splitting procedure reformulate equivalent linearly constrained problem follows. clear moreover linear system explicitly characterizes relations rd×d deﬁned otherwise. note coresponds sparse matrix. denotes diagonal matrix diagonal entries equals number repetitions corresponding special case corresponding composed non-overlapping natural algorithmic candidate tackle above-mentioned general block convex optimization problem concrete realization context multi-block admm direct extension admm addressing -block convex optimization problem unfortunately observed that although usual -block admm converges direct extension multi-block admm might however diverge. non-convergence behavior multi-block admm attracted number research eﬀorts convergent variants. study empirically examines regime existing multi-block admm convergent variants ﬁnds collectively substantially under-performs direct multi-block admm extension convergence guarantee. fortunately recently proximal admm developed enjoys theoretical convergence guarantee well supreme empirical performance direct admm extension. inspires propose similar algorithm described below. lagrangian multipliers barrier parameter. similar applying proximal admm solve optimization problem obtain following steps updating variables parameters iteration ready present algorithm calibrated multivariate regression grossly corrupted observations incorporates above-mentioned components. note examining side-by-side direct -block admm extension proximal admm proposed possesses additional step evaluate additional cost evaluating trivial inverse usually easy compute denotes subdiﬀerential convex functions. performing extra step fact crucial ensures global convergence sequence generated algorithm optimal solution satisfying formally stated theorem algorithmic complexitythe complexity algorithm consists main parts corresponding computation inverse updating variables iteration. since coeﬃcient matrix compute before iteration costs moreover cost d−x)−xd− computing inverse xd−x rn×n costs thus cost computing min. large might inapplicable compute cholesky factorization xd−x. circumstance solve linear systems using iterative solver preconditioned conjugate gradient method iteration cost computing dominated comput costs odp) respectively. central piece approach model cmrg short also referred approach without confusion. also three related models model ordinary multivariate regression model calibrated multivariate regression well omrg model ordinary multivariate regression gross error facilitate better understanding inner-working well systematic evaluation proposed approach ﬁrst consider series experiments simulated data full access ground-truths gross errors contaminated observations. followed experiments exemplar real-world applications big-ﬁve personality prediction ﬁrst generate simulation datasets systematically evaluate ﬁnitesample performance model controlled settings. synthetic data obtained following similar scheme follows. dataset examples training examples validation well examples testing. concretely training examples obtained follows implies regression tasks contain stochastic noises magnitude implies regression tasks contain stochastic noises diﬀerent magnitude. construct gross error number nonzero entries controlled ratio positions non-zero entries randomly selected magnitudes σmax generate validation samples testing samples except gross errors validation testing samples. empirical evaluations carried datasets generated diﬀerent values σmax evaluate performance cmrg. regularization parameters obtained measures prediction error testing data adjusted prediction error testing data estimation error estimation error respectively. throughout experiment shown results average results repetitions. ﬁrst study eﬀect stochastic noise level diﬀerent tasks letting show results four comparison models table table respectively. table since metric adj.pre.err. reduces metric pre.err. include results related adj.pre.err.. table table four observations gross error four models performance. models adopting -norm loss function outperform ones using least square loss terms prediction error testing data estimation error presence gross errors regression models omrg cmrg consider gross error perform consistently better without consideration. observed cmrg usually delivers lower prediction error well lower estimation error comparing omrg. summary newly proposed model cmrg achieves best overall performance outperforms models large margin gross errors. next study eﬀect σmax letting show results σmax table again observe regression models calibration perform better counterparts without calibration cmrg outperforms models large margin. models equal fig. observe four models prediction error estimation errors increase observations grossly corrupted. models calibration perform better models without calibration values advantage profound large. moreover newly proposed model cmrg outperforms similar performance reason cmrg fails identify gross errors observations half observations corrupted shown fig. suggests existence certain threshold approach could recover gross error successfully lower threshold. topic left future research. fig. cmrg insensitive magnitude hand omrg large deviations large also reﬂects diﬃculty selecting proper regularization parameters omrg. used snss dataset built microblogging site sina weibo recruiting subjects login weibo dedicated website users’ historical behavior data weibo collected. weibo dataset behavior features constructed arranged groups namely social networking proﬁle self-presentation security setting total subjects recruited dataset. publish zero blog past three months. leads ﬁnal dataset subjects partitioned instances training instances testing. subject also asked complete questionnaire well-known big-five inventory consisting forty-four inquiries. inventory results epitomize ﬁve-dimensional personality descriptor following standard procedure. gives rise vector element taking value four comparison methods employed here include three closely related methods well ridge regression method fact model considering least square similar simulated experiments considered previously subsection choose parameter p)∗{− −.··· pick-up parameter selected based begin with consider evaluations presence gross error. left half table illustrates averaged results repetitions personalities agreeableness conscientiousness extraversion neuroticism openness left-most column denote average prediction error evaluated corresponding personality. further pre.err. stands relative prediction error averaged output personalities. displayed table empirically omrg cmrg performs current dataset context practice situations entries multivariate output space missing. investigate type cases consider processing personality dataset entries observations randomly replaced zero experiments carried based corrupted dataset right half table presents average prediction errors repeats clearly observe cmrg signiﬁcantly outperforms rest competitors. investigate ability newly proposed model identifying gross errors observations introduce additional metric rec.rate.g quantiﬁes fraction perfectly restored positive negative entry signs words rec.rate.g equals number entries sign divided number entries table presents comparison cmrg omrg term restoring missing values. empirically cmrg shown capable accurately identifying missing observations performs much better omrg. addition since averaged absolute distance widely used evaluation metric area personality prediction also applied measure deviation gold-standard prediction corrupted data use. table displayed averaged results repeats cmrg consistently outperforms regression models. vision-based hand pose estimation plenty applications various areas including humanoid animation human-computer interaction robotic control. core problem problem hand pose estimation owing mostly complex dexterous nature hand articulations. facilitated emerging commoditylevel depth cameras kinect softkinect recent eﬀorts hand pose estimation depth images noticeable progress ﬁeld. section apply cmrg method problem hand pose estimation depth images. evaluate performance method home-grown synthesized depth image dataset well benchmark hand pose dataset described separately follows compare state-of-the-art methods ﬁeld. fig. average joint error millimeter synthetic dataset results using original training data; results using corrupted training data entries missing; results using corrupted training data entries missing. conduct quantitatively analysis generate in-house dataset synthesized hand depth images used training validation rest reserved testing. position orientation hand gesture randomly generated. distance form synthetic hand virtual camera varies within range vertical ﬁeld-of-view camera degree. depth image output label hand pose expressed term coordinates ﬁnger joints illustrated fig. concatenate coordinate joints obtain -dimensional vector. apply proposed approach convolutional neural network features extracted depth image input context corresponding -dimensional coordinate vector corresponds label features obtained follows imagenet-pretrained alexnet adopted learn model based aforementioned training set. note fulﬁll input requirement alexnet depth values image scaled image resized properly; depth image replicated three times form three-channel image. matconvnet deep learning library adopted paper. ﬁnal model attained training epochs. given image applying learned model features obtained simply retrieving output second-to-last fully connected layer -dimensional vector. fig. average joint error millimeter hand pose dataset results using original training data; results using corrupted training data entries missing; results using corrupted training data entries missing. displayed fig. ﬁnger joints annotated dataset output label becomes -dimensional coordinate vector. meanwhile input contains extracted features following protocol used synthetic dataset. competing regression models omrg cmrg original training images randomly partitioned subsets images training images validation determine internal parameters following convention hand pose estimation literature performance evaluation metric based joint error deﬁned euclidean distance ground-truth predicted ground truth joint locations. formally denote predicted joint locations j-th joint i-th testing sample. mean joint error j-th joint deﬁned number testing examples denotes euclidean norm four multivariate regression models omrg cmrg compared experiments. addition dedicated hand pose estimation methods considered recent work dhand recent dramatic progress deep learning becomes sensible include method based imagenet-pretrained alexnet described earlier paper right -dimensional fully connected layer standard least-square loss layer loss term used multivariate regression joint locations. similar previous experiments simulated data four regression problems optimal parameters chosen investigate methods behave exist missing annotations training data synthetic datasets additional sets training data obtained entries randomly deleted ground-truth rest remains same. note deleted annotation entries original values replaced quantitative results competing methods synthetic datasets presented fig. y-axis plot shows average joint error millimeter mean joint error entire hand participating methods also provided table fig. table clearly approach consistently outperforms rest methods presence gross errors including domain-speciﬁc methods dhand well deep learning baseline method. speciﬁcally training original non-contaminated data fig. four multivariate regression methods deliver similar performance cmrg slightly better. interestingly four methods perform better dhand alexnet attribute additional sparsity-induced regularizer adopted four models enforce feature selection comparison alexnet least-square empirical loss term use. compared dhand four regression models features secure performance boosting. particular illustrated fig. approach stands term robust increased missing entries meanwhile rest methods produce noticeably larger errors. similar trends also observed dataset presented fig. table worth mentioning advantage cmrg comparison methods data less signiﬁcant without gross error increasing amount missing entries cmrg behaves much better rest competitors retaining robust performance shown fig. table inspired surprisingly good performance approach combining model consider approach dedicating multivariate regression problem output labels either corrupted missing. gross error explicitly addressed model allows adaptation distinct regression elements tasks according noise levels. propose analyze convergence runtime properties proposed proximal admm algorithm globally convergent eﬃcient. model combined speciﬁcally designed solver enable approach tackle diverse range applications. practically demonstrated distinct applications predict personalities based behaviors snss well estimation hand pose single depth images. empirical experiments synthetic real datasets showcased applicability approach presence label noises. future work plan integrate advanced deep learning techniques better address practical problems including hand pose estimation beyond.", "year": 2017}