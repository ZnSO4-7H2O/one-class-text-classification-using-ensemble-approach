{"title": "Funneled Bayesian Optimization for Design, Tuning and Control of  Autonomous Systems", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "Bayesian optimization has become a fundamental global optimization algorithm in many problems where sample efficiency is of paramount importance. Recently, there has been proposed a large number of new applications in fields such as robotics, machine learning, experimental design, simulation, etc. In this paper, we focus on several problems that appear in robotics and autonomous systems: algorithm tuning, automatic control and intelligent design. All those problems can be mapped to global optimization problems. However, they become hard optimization problems. Bayesian optimization internally uses a probabilistic surrogate model (e.g.: Gaussian process) to learn from the process and reduce the number of samples required. In order to generalize to unknown functions in a black-box fashion, the common assumption is that the underlying function can be modeled with a stationary process. Nonstationary Gaussian process regression cannot generalize easily and it typically requires prior knowledge of the function. Some works have designed techniques to generalize Bayesian optimization to nonstationary functions in an indirect way, but using techniques originally designed for regression, where the objective is to improve the quality of the surrogate model everywhere. Instead optimization should focus on improving the surrogate model near the optimum. In this paper, we present a novel kernel function specially designed for Bayesian optimization, that allows nonstationary behavior of the surrogate model in an adaptive local region. In our experiments, we found that this new kernel results in an improved local search (exploitation), without penalizing the global search (exploration). We provide results in well-known benchmarks and real applications. The new method outperforms the state of the art in Bayesian optimization both in stationary and nonstationary problems.", "text": "bayesian optimization become fundamental global optimization algorithm many problems sample eﬃciency paramount importance. recently proposed large number applications ﬁelds robotics machine learning experimental design simulation etc. paper focus several problems appear robotics autonomous systems algorithm tuning automatic control intelligent design. problems mapped global optimization problems. however become hard optimization problems. bayesian optimization internally uses probabilistic surrogate model learn process reduce number samples required. facto standard surrogate model gaussian process ﬂexibility represent distribution functions. order generalize unknown functions black-box fashion common assumption underlying function modeled stationary process. nonstationary gaussian process regression cannot generalize easily typically requires prior knowledge function. works designed techniques generalize bayesian optimization nonstationary functions indirect using techniques originally designed regression objective improve quality surrogate model everywhere. instead optimization focus improving surrogate model near optimum. paper present novel kernel function specially designed bayesian optimization allows nonstationary behavior surrogate model adaptive local region. experiments found kernel results improved local search without penalizing global search provide extensive results well-known benchmarks real applications show method able outperform state bayesian optimization stationary nonstationary problems. many problems engineering computer science economics etc. require extremum unknown real valued function usign evaluations possible. many cases functions represent actual industrial processes expensive trials time consuming computations simulations. optimization process must consider actual budget limitations gathering evaluations. then sample eﬃciency becomes element. furthermore functions might highly multimodal requiring global solution. bayesian optimization also found literature names bayesian sampling eﬃcient global optimization sequential kriging optimization sequential model-based optimization bayesian guided pattern search classic optimization method become quite popular recently sample eﬃcient method global optimization applied great success autonomous algorithm tuning specially machine learning applications robot planning control task optimization reinforcement learning structural design sensor networks simulation design circuit design ecology biochemistry dynamical modeling biological systems etc. recent works found connections bayesian optimization biological systems adapt search nature human active search animal adaptation injuries bayesian optimization uses bayesian surrogate model distribution target functions incorporate available information optimization procedure. distribution capture prior information available information observation. therefore surrogate model provides memory improves sample eﬃciency method considering whole history trials evaluations optimization procedure. besides model sample eﬃcient using principles. summary bayesian optimization combination main components surrogate model captures prior observed information decision process performs optimal action i.e. sample next based previous model. methodology steps modeling decision connected many ﬁelds. points selected optimization problem considered active learning problem estimation optimum authors drawn connections bayesian optimization reinforcement learning setups multi-armed bandits pomdps even active reinforcement learning components also hide extra computational cost. hand need update surrogate model hand optimize criterion function however additional cost compensated reduced number target function evaluations thanks sample eﬃciency method. therefore bayesian optimization specially suitable expensive black-box functions trial-anderror methodologies. conditions quality surrogate model paramount importance also aﬀects optimality decision process. earliest versions bayesian optimization used wiener processes wiener ﬁelds surrogate models. similar methods used radial basis functions branch bound polynomials introduced gaussian processes also called kriging bayesian surrogate function. jones also wrote excellent review kind surrogate models recently bayesian models become popular like student’s processes treed gaussian processes random forests tree-structured parzen estimators deep neural networks case discrete inputs beta-bernouilli bandit setting provides equivalent framework however gaussian process still popular model accuracy robustness ﬂexibility bayesian optimization mainly used black grey-box scenarios. range applicability gaussian process deﬁned kernel function sets family functions able represent reproducing kernel hilbert space fact regret bounds bayesian optimization using gaussian processes always deﬁned terms speciﬁc kernel functions practical point view standard procedure select generic kernel function gaussian mat´ern kernels estimate kernel hyperparameters data. property kernels stationary. although might reasonable assumption black setup show section reduces eﬃciency bayesian optimization situations. also limits potential range applications. furthermore nonstationay methods usually require extra knowledge function global properties gathering knowledge data requires global sampling contrary bayesian optimization methodology. main contribution paper adaptive kernels gaussian processes speciﬁcally designed model functions nonstationary processes focused region near optimum. thus model maintains global exploration/local exploitation trade idea results improved eﬃciency applicability bayesian optimization based gaussian processes. call method spartan bayesian optimization algorithm extensively evaluated many scenarios applications. besides standard optimization benchmarks method evaluated automatic algorithm tuning machine learning applications optimal policy learning reinforcement learning scenarios autonomous wing design airplane using realistic simulations. results found reaches best performance problems clearly nonstationary local global shape function diﬀerent. however tests also shown improve results bayesian optimization scenarios. optimization point view kernels result improved local search maintaining global exploration capabilities similar locally-biased global optimization algorithms algorithm called spartan follows intuition analogous strategy greek forces battle thermopylae. likely theory claims that last battle small group forces spartan king leonidas stood narrow pass thermopylae block persian cavalry rest forces retreated cover terrain avoid surrounded persian moving mountain path dual strategy allocate global resources sparsely maintaining local dense vanguard strategic location emphasized within spartan bayesian optimization. start describing ingredients bayesian optimization algorithm using gaussian processes surrogate model. consider problem ﬁnding minimum unknown real valued function maximum budget evaluations target function purpose algorithm select best query points iteration optimization regret minimum available budget. model gaussian process inputs scalar outputs associate kernel covariance function hyperparameters hyperparameters estimated using monte carlo markov chain resulting samples {θi}m concretely slice sampling algorithm already used bayesian optimization although bootstraping could equally used advantage using gaussian processes distributions functions observations target function easily used update distribution functions. furthermore posterior distribution also therefore posterior used prior next iteration recursive algorithm. fact non-parametric method algorithm adding sample highly optimized provided update hyperparameters every iteration noise nugget term represent stochastic functions surrogate missmodeling note that sampling distribution predictive distribution point mixture gaussians. problem regret functions presented equation rely knowledge optimum thus cannot directly. instead bayesian optimization literature developed proxies functions called acquisition functions. select next point iteration expected improvement criterion proxy optimality criterion. expected improvement deﬁned expectation improvement function max). improvement deﬁned incumbent target many applications considered best outcome iteration ybest. incumbent values could considered specially presence noise. taking expectation mixture gaussians predictive distribution compute expected improvement corresponding gaussian probability density function cumulative prediction computed assuming incumbent target best observation iteration iteration finally order avoid bias guarantee global optimality rely initial design points based latin hypercube sampling following recommendation literature algorithm summarizes basic steps bayesian optimization. many applications gaussian process regression including bayesian optimization based assumption process stationary. reasonable assumption black-box optimization assume extra information evolution function space. example squared exponential kernel quite frequent. another popular kernel regression mat´ern kernel family kernels represents length-scale hyperparameter captures smoothness variability function. mat´ern kernel modiﬁed bessel function. mat´ern kernel usually computed values half-integers non-negative integer function becomes simpler. analysis kernel length-scale important optimization. small values suitable capture signals high frequency components; large values result model frequency signals functions. property also holds kernels automatic relevance determination becomes vector length-scale parameter dimension. bayesian optimization mat´ern kernel frequently used performance many benchmarks. length-scale estimation results interesting behavior bayesian optimization. distance points kernel smaller length-scale result higher predictive variance therefore exploration aggressive. idea previously explored wang forcing smaller scale parameters improve exploration. formally order achieve no-regret convergence minimum target function must element reproducing kernel proposition given kernels large small length scale hyperparameters respectively function rkhs characterized kernel also element rkhs characterized according previous deﬁnition applications bayesian optimization nonstationary local stationary. take example reinforcement learning problems section scenario agent trying optimal policy produce behavior maximize reward function example consider biped robot trying walking pattern maximizes walking speed setup policies reach undesirable states result failure condition like robot falling losing upright posture. then system returns null reward arbitrary penalty. cases ﬁnding stable policy diﬃcult reward function almost except small region successful policies reward actually informative order maximize speed. furthermore bayesian optimization inherently local stationary process depending acquisition function. dual behavior global exploration local exploitation. ideally samples uncertainty estimation distributed unevenly many samples small uncertainty near local optima sparse samples large uncertainty everywhere else. several attempts model nonstationary functions gaussian processes. example speciﬁc nonstationary kernels bayesian treed models projecting input space stationary latent space idea treed used bayesian optimization combined auxiliary local optimizer version warping idea applied bayesian optimization later assael built treed warping model used leaves. methods model nonstationary property global way. however pointed before sampling bayesian optimization uneven thus global model might inaccurate. like many global optimization bandit setups bayesian optimization requires control bounds function drive exploration eﬃciently. pointed bubeck tight bounds required near optimum setups. then milder conditions deﬁned elsewhere. example weak lipschitz condition milder version lipschitz condition. probabilistic terms upper lower bounds deﬁned gaussian process bayesian optimization play role lipschitz constant classical optimization high uncertainty represents loose bounds viceversa. proposal exploits idea providing adaptive kernel allows tight bounds near optimum looser bounds everywhere else. information optimum location available tight bounds moved towards location. approach nonstationarity based model presented krause guestrin input space partitioned diﬀerent regions resulting linear combination local λjξj. local speciﬁc hyperparameters making ﬁnal order achieve smooth interpolation nonstationary even local stationary. regions authors suggest weighting function region maximum region decreasing value distance region then practice mixed obtained combined kernel function λjλj)kj|θ). related approach additive used bayesian optimization propose combination local global kernels multivariate normal distributions weighting functions. called kernel spartan kernel seen centers inﬂuence region kernel represents area inﬂuence. note local kernels share mean value diﬀerent variance thus generates funnel-like structure. spartan kernel single local kernel shown figure figure representation spartan kernel sbo. case kernel combination single local global kernel. typically local global kernels small large length-scale respectively. inﬂuence kernel represented normalized weight bottom plot. note kernel small length-scale produce larger uncertainties advantage fast exploitation perform poorly global exploration tends sample equally everywhere. hand kernel large length-scale provides better global estimate smoother higher uncertainty improves global exploration. global kernel parameters unless prior knowledge function parameters global kernel mostly irrelevant. applications uniform distribution easily approximated large local kernel parameters local kernels estimate center funnel structure based data gathered. propose consider part hyperparameters spartan kernel also includes parameters local global kernels area inﬂuence local kernel could also adapted including terms part kernel hyperparameters however case problem becomes ill-posed resulting overﬁtting. instead adding regularization terms found simpler value deﬁne terms numbers samples inside. second method advantage that exploitation number local samples increase funnel gets narrower allowing better local reﬁnement. commented section data available parameters updated using mcmc. therefore position local kernel moved iteration represent posterior. sampling behavior bayesian optimization found intrinsically moves likely towards densely sampled areas many problems corresponds location function minima. furthermore mcmc samples diﬀerent positions local kernel seen algorithms spartan bayesian optimization simple implement implementation algorithm important note that although implemented relying gaussian processes expected improvement funnel kernel also works popular models student-t processes treed gaussian processes criteria upper conﬁdence bound relative entropy etc. summary requires modify kernel function hyperparameter estimation. however section results show large gain terms convergence speed sample eﬃciency many problems. intuition behind many acquisition functions bayesian optimization surrogate model approximate target function precisely every point provide information location minimum. many optimization problems diﬃcult fact region near minimum heteroscedastic i.e. higher variability rest space like function figure case greatly improves performance state bayesian optimization. selected variety benchmarks diﬀerent applications robotics test method. purpose twofold. first highly potential applicability bayesian optimization many ways robotics design control software tuning etc. second show setups method outperforms state bayesian optimization. algorithm tuning perception problems selected machine learning tuning benchmarks. include image classiﬁcation large clustering problems diﬀerent algorithms. finally address intelligent design embodiment problem optimal design wing proﬁle uav. highly complex scenario chaotic nature ﬂuid dynamics. thus problem ubiquitous global optimization evolutionary computation literature. evaluation purposes highlight robustness simpliﬁed funnel structure single local global kernel figure also took simpler approach variance found single value robust enough experiments input space normalized unit hypercube. although method allows combination local global kernels purpose evaluation used mat´ern kernel equation automatic relevance determination –local global– kernels. furthermore kernel hyperparameters initialized prior kernels. therefore data determine kernel smaller length-scale. found typical result behavior figure however problems method learn model local kernel larger length-scale global kernel also improve convergence plateau-like functions. besides target function stationary system might learning similar length-scale kernels thus equivalent single kernel. generalizes modeling capabilities standard standard special case local global kernels same. given single mat´ern kernel number kernel hyperparameters dimensionality problem number hyperparameters spartan kernel setup experiments drawback compared standard requires running mcmc larger dimensional space results higher computational cost. however eﬃcient extra computational cost easily compensated reduced number samples. implemented spartan bayesian optimization using bayesopt library codebase. allowed evaluate setup many surrogates criteria. comparison also evaluated nonstatioary bayesian optimization models ties applicability results. knowledge bayesian optimization algorithm deal nonstationarity using gaussian processes fully correlated way. however presented section warp much expensive terms computational cost time) performance excellent. however continuous functions sample performance good gp-based reported previously literature appendix discuss combine techniques exploit best properties method. number samples leaf reduced global correlation found require larger nugget noise term avoid numerical instability. deterministic functions large signal noise ratio like presented results increasing nugget reduces accuracy results. furthermore presented assael single nonstationary like input warping method spartan kernel used tree leaves. thus considered enhancement treed competitor. clarity plots included results warp algorithm current state standard reference baseline. include random forests treed performance worse standard warp algorithms. figure left exponential function proposed method results outstanding convergence speed compared state art. ﬁnds minimum function evaluations tests. right michalewicz function convergence slow nonstationay methods clearly perform better fastest. experiments reported used gaussian process unit mean function like warp also used mat´ern kernel ard. kernel hyperparameters including warping functions estimated using mcmc computational burden mcmc used small number samples trying decorrelate every resample large burn-in periods snoek experiments repeated times using common random numbers. commented section number function evaluations plot includes initial design points using latin hypercube sampling. figure show results functions smooth wide minima. bayesian optimization suitable function naive strategies preform well general. therefore barely room improvement. however show that even situation equal better stationary penalty extra complexity model. however warp method slower convergence extra complexity. first evaluated branin-hoo function figure left minimum value branin-hoo function. barely identical. center hartmann function. evolution minimum value method. right zoom minimum value ﬁnal iterations. warp produce accurate results smaller uncertainty meaning results repeatable. deﬁned appendix case diﬀerences small imply function likely stationary simple exploit. however variance plots nonstationary methods robust ﬁnal exploitation. ﬁrst problem consists tuning parameters logistic regression classiﬁer recognize handwritten numbers mnist dataset seen results easy problem bayesian optimization. even standard method able reach minimum less function evaluations. case warped method fastest almost evaluations. proposed method similar performance terms convergence order magnitude lower execution time second problem called online lda. problem based setup deﬁned snoek learning topics wikipedia articles using latent dirichlet allocation online fashion. requires tune parameters. standard warp method stuck method able escape local minimum outperform methods large margin. again required much lower computational cost warp. finally evaluated hp-nnet problem based deep neural network written bergstra classify modiﬁed mnist dataset. case handwritten numbers arbitrarily rotated random background images distractors database called mrbi mnist rotated background images. case high dimensionality heterogeneity input space tested approaches. figure surrogate benchmarks based real hyperparameter optimization machine learning algorithms. left right logistic regression online deep neural network deep neural network using hierarchical model appendix cases performs better logistic regression problem warp method outperforms sbo. figure classiﬁcations problems images handwritten numbers. objective classiﬁer identify correct number. left mnist dataset handwritten numbers used logistic regression problem. right modiﬁed mnist dataset rotated numbers background images increase diﬃculty classiﬁcation. used hp-nnet problem. first applied single fully-correlated model variables. categorical variables mapped integer values computed rounding query values. case similarly hartmann function method precise robust. second applied hierarchical model splits continuous categorical variables layer optimization process. case nonstationary algorithms applied continuous variables inner loop used hamming kernel categorical variables note plots respect target function evaluations. however results hierarchical model based iterations outer loop iteration requires function evaluations inner loop. early stages trying good location local kernel performance slightly worse. however data gathered local kernel jumped good spot convergence faster. benchmarks complexity machine learning algorithms size datasets single evaluation take hours days wall-time. order simplify comparison tests used surrogate benchmarks presented eggensperger uses surrogate functions build real data evaluations predict performance tuned algorithms. evaluating surrogate function done seconds compared actual training machine learning algorithm. authors provide diﬀerent surrogates selected gradient boosting provides lowest prediction error respect actual data problem. explicitly rejected gaussian process surrogate benchmark avoid potential advantage perfectly modeling. results shown figure detailed description experiments found original paper evaluated several reinforcement learning problems. reinforcement learning deals problem artiﬁcial agents perform optimal behaviors. agent deﬁned variables capture current state conﬁguration agent world. agent perform action modiﬁes agent state time step agent collects reward signal associated current state action actions selected according policy function represents agent behavior states actions transitions modeled using probabilities deal uncertainty. thus objective reinforcement learning optimal policy maximizes expected reward deﬁned time horizon reinforcement learning algorithms usually rely variants bellman equation optimize policy step step considering instantaneous reward separately. algorithms also rely partial total knowledge transition model advance. methods tackle optimization problem directly considering equation stochastic optimization problem. methods called direct policy search bayesian optimization reinforcement learning previously called active policy search connection active learning samples carefully selected based current information. main advantage using bayesian optimization compute optimal policy done little information. fact soon able simulate scenarios return need access dynamics instantaneous reward current figure left mountain scenario. underactuated cannot climb goal directly. instead requires move backwards inertia. line left inelastic wall. right figure total reward three limb walker mountain hovering helicopter problem. ﬁrst problem able achieve higher reward methods stuck local maxima. mountain able achieve maximum performance trials policy trials helicopter problem warp slow convergence many policies results early crash. providing almost information. however able exploit good policies quickly improve performance. state system. furthermore need space action discretization building complex features tile coding found many problems simple dimensional quase-linear controller able achieve state-of-the-art performance properly optimized. frequent issue applying general purpose optimization algorithms policy search that many problems occurrence failure states scenarios results large discontinuities regions large penalties. opposed behavior reward near optimal policy small variations suboptimal policy considerably change performance achieved. therefore resulting reward function presents nonstationary behavior respect policy. compared method three well-known benchmarks diﬀerent level complexity. ﬁrst problem learning controller three limb robot walker presented westervelt controller modulates walking pattern simple biped robot. desired behavior fast upright walking pattern reward based walking speed penalty maintaining upright position. dynamic controller continuous parameters. walker problem already used bayesian optimization benchmark third problem hovering helicopter rl-competition. challenging scenarios competition presented editions. problem based simulator xcell tempest aerobatic helicopter. simulator model learned based actual data helicopter using apprenticeship learning model used learn policy later used real robot. simulator included several diﬃcult wind conditions. state space action reward quadratic function penalizes state error action episode seconds simulator enters terminal state large negative reward given corresponding getting negative reward achievable remaining time. also used weak baseline controller included helicopter model. weak controller simple linear policy parameters theory controller enough avoid crashing robust. show policy easily improved iterations. case initial exploration parameter space specially important number policies crashing control steps small. policies reward negative reward achievable. thus case used sobol sequences initial samples bayesian optimization. samples deterministic therefore guarantee number non-crashing policies sampled every trial every algorithm. also increased number initial points figure shows performance three limb walker presented mountain helicopter problem. cases results obtained eﬃcient terms number trials accuracy respect standard warp. furthermore found results comparable obtained popular reinforcement learning solvers like sarsa much less information prior knowledge problem. helicopter problem solutions found literature require larger number scenarios/trials achieve similar performance computational ﬂuid dynamics software powerful tool design mechanical structural elements subject interaction ﬂuids aerodynamics hydrodynamics heating systems. compared physical design testing wind tunnels artiﬁcial channels cost simulation almost negligible. simulated redesign simple methods used autonomous design mechanical elements following principles experimental design. simulation-based autonomous design special case design analysis computer experiments recent developments terms algorithms available software reduced computational cost improved accuracy results allows dace methodologies used optimal designs based trial error. nevertheless computational cost average simulation still take days months time. therefore sample eﬃcient methodology mandatory. bayesian optimization enormous potential ﬁeld autonomous design. experiment designed highlight potential bayesian optimization ﬁeld autonomous design optimal wing airplane simulated wind tunnel using xflowtmcdf software. objective experiment shape wing minimizes drag maintaining enough lift. first common practice kind problems assumed simulation ﬂuid along proﬁle wing. reasonable assumption wings large aspect ration considerably reduces wall time simulation days hours. parametrization proﬁle many alternatives based geometric manufacturing principles. case used bezier curves simplicity generate corresponding shape. however note bayesian optimization agnostic geometric parametrization parametrization could also used. bezier curve wing based control points resulted parameters. however adding physical manufacturing restrictions resulted free parameters. figure vorticity plots diﬀerent wing shapes. left wing barely aﬀect trajectory wind resulting enough lift. meanwhile right wing able provide enough lift minimum drag. problem minimizing drag directly best solutions tends generate wings provide enough lift plane. figure shows comparison wing lift optimal design. although recent work bayesian optimization constraints decided simpler approach adding penalty purposes. firts input space remains unconstrained improving performance optimization acquisition function. second kernel smoothing penalty points generates safety area function partly penalized. besides drops edges penalties ﬂuid dynamics also chaotic properties small changes initial conditions produce large variability result. example near trailing edge transition laminar turbulent regime small change wing shape. thus resulting forces completely diﬀerent increasing drag reducing lift. conditions figure shows warp fail optimum wing shape. however ﬁnds better wing shape. furthermore iterations. table shows average time diﬀerent experiments total number function evaluations. hpnn-h uses hierarchical model function evaluations iterations optimization loop thus faster. extensive evaluation rely diﬀerent machines running experiments although algorithms single experiment compared machine. thus time diﬀerent experiments might directly comparable. warp. rest algorithm equivalent. used code optimization techniques. reason decided measure time direct metric computational cost. besides time robust wall-time. proﬁling found time diﬀerences algorithms mainly driven dimensionality hyperparameter space mcmc main bottleneck. furthermore shape posterior distribution kernel hyperparameters played important role. likelihood parameters beta narrow slice sampling algorithm spent many iterations accepting samples. narrow likelihoods largeﬂip sampling well known issues mcmc. methods could applied alleviate issues hybrid monte carlo sequential monte carlo samplers remains open problem. note that algorithms experiments used slice sampling recommended authors warp finally evaluation beta much involved computationally expensive evaluation mat´ern kernel gaussian weights. extra cost became important factor kernel function called billions times bayesian optimization run. important note that although bayesian optimization intended expensive functions cost iteration negligible applications diﬀerence methods could mean hours cpu-time single iteration changing range potential applications inexpensive function evaluations. paper presented algorithm called spartan bayesian optimization combines local global kernel single adaptive kernel deal exploration/exploitation trade-oﬀ inherent nonstationarity search process bayesian optimization. shown kernel increases convergence speed reduces number samples many kind problems. nonstationary problems method provides excellent results compared standard bayesian optimization state method deal nonstationarity. furthermore also performs well stationary problems improving local reﬁnement retaining global exploration capabilities. evaluated algorithm extensively standard optimization benchmarks automatic wing design machine learning applications hyperparameter tuning problems classic reinforcement learning scenarios. results shown outperforms state bayesian optimization experiments tests. requires less samples achieves smaller optimization gap. addition that shown much eﬃcient terms usage nonstationary methods bayesian optimization. results reinforcement learning also highlight potential active policy search paradigm reinforcement learning. method specially suitable paradigm. fact opens opportunity bayesian optimization eﬃcient competitive reinforcement learning solver without relying dynamics system instantaneous rewards discretization diﬀerent spaces. although bayesian optimization started method solve classic nonlinear optimization problems box-bounded restrictions sample eﬃciency ﬂexibility surrogate models attracted interest communities expanded potential applications method. many current bayesian optimization applications like hyperparameter optimization necessary simultaneously optimize diﬀerent kinds input variables example continuous discrete categorical etc. gaussian processes suitable modeling spaces choosing suitable kernel bayesian optimization become quite involved acquisition function must optimized mixed input space. available implementations bayesian optimization like spearmint grid sampling rounding tricks combine diﬀerent input spaces. however reduces quality ﬁnal result compared proper nonlinear optimization methods authors proposed heuristics specially designed criterion maximization bayesian optimization applicability mixed input spaces still remains open question. propose hierarchical bayesian optimization model input space partitioned homogeneous variables example continuous variables discrete variables therefore evaluation element higher hierarchy implies full optimization elements lower hierarchy. principle would require many function evaluations input space partitioned dimensionality separate problem much lower. practice number function evaluations computational cost optimization algorithm considerably reduced. also include conditional variables outer loop select computations perform inner loop. advantage approach combine diﬀerent surrogate models diﬀerent levels hierarchy. example using random forests tree-structured parzen estimators could suitable surrogate model certain discrete/categorical variables gaussian processes. could also speciﬁc kernels like hamming kernel used previous section. contrast loose correlation among variables inner loop counterproductive certain situations. similar alternative case target function actually combination lower spaces could additive models additive figure shows method requires function evaluations achieve similar results fully correlated approach. however seen table computations cost number iterations increases might open applications. similar approach recently proposed deal high dimensional problems evaluations expensive", "year": 2016}