{"title": "Extracting Actionability from Machine Learning Models by Sub-optimal  Deterministic Planning", "tag": ["cs.AI", "cs.LG"], "abstract": "A main focus of machine learning research has been improving the generalization accuracy and efficiency of prediction models. Many models such as SVM, random forest, and deep neural nets have been proposed and achieved great success. However, what emerges as missing in many applications is actionability, i.e., the ability to turn prediction results into actions. For example, in applications such as customer relationship management, clinical prediction, and advertisement, the users need not only accurate prediction, but also actionable instructions which can transfer an input to a desirable goal (e.g., higher profit repays, lower morbidity rates, higher ads hit rates). Existing effort in deriving such actionable knowledge is few and limited to simple action models which restricted to only change one attribute for each action. The dilemma is that in many real applications those action models are often more complex and harder to extract an optimal solution.  In this paper, we propose a novel approach that achieves actionability by combining learning with planning, two core areas of AI. In particular, we propose a framework to extract actionable knowledge from random forest, one of the most widely used and best off-the-shelf classifiers. We formulate the actionability problem to a sub-optimal action planning (SOAP) problem, which is to find a plan to alter certain features of a given input so that the random forest would yield a desirable output, while minimizing the total costs of actions. Technically, the SOAP problem is formulated in the SAS+ planning formalism, and solved using a Max-SAT based approach. Our experimental results demonstrate the effectiveness and efficiency of the proposed approach on a personal credit dataset and other benchmarks. Our work represents a new application of automated planning on an emerging and challenging machine learning paradigm.", "text": "main focus machine learning research improving generalization accuracy efﬁciency prediction models. many models random forest deep neural nets proposed achieved great success. however emerges missing many applications actionability i.e. ability turn prediction results actions. example applications customer relationship management clinical prediction advertisement users need accurate prediction also actionable instructions transfer input desirable goal existing effort deriving actionable knowledge limited simple action models restricted change attribute action. dilemma many real applications action models often complex harder extract optimal solution. paper propose novel approach achieves actionability combining learning planning core areas particular propose framework extract actionable knowledge random forest widely used best off-the-shelf classiﬁers. formulate actionability problem sub-optimal action planning problem plan alter certain features given input random forest would yield desirable output minimizing total costs actions. technically soap problem formulated sas+ planning formalism solved using max-sat based approach. experimental results demonstrate effectiveness efﬁciency proposed approach personal credit dataset benchmarks. work represents application automated planning emerging challenging machine learning paradigm. keywords actionable knowledge extraction machine learning planning random forest weighted partial max-sat research machine learning achieved great success enhancing models’ accuracy efﬁciency. successful models support vector machines random forests deep neural nets applied vast industrial applications mitchell however many applications users need prediction model also suggestions courses actions achieve desirable goals. practitioners complex model random forest often useful even accuracy high lack actionability. given learning model extraction actionable knowledge entails ﬁnding actions change input features given instance achieves desired output learning model. elaborate problem using example. example credit card company task decide promotion strategies maximize long-term proﬁt. customer relationship management department collects data data scientists need build models predict proﬁt brought customers. real case company builds random forest involving customer features. model predicts proﬁt customer. addition important task extract actionable knowledge revert negative proﬁt customers retain positive proﬁt customers. general much cheaper maintain existing positive proﬁtcustomers revert negative proﬁt ones. especially valuable retain high proﬁt large enterprise-level customers. certain actions company take making phone contacts sending promotional coupons. action change value multiple attributes customer. obviously actions incur costs company. instance different kinds promotions promotion associates features number accumulation effect sending kind promotion. performing action sending promotion change features promotion number accumulation effect sending sales promotion respectively. customer negative proﬁt goal extract sequence actions change customer proﬁle model gives positive proﬁt prediction minimizing total action costs. customer positive proﬁt goal actions customer positive proﬁt prediction higher prediction probability. research extracting actionability machine learning models still limited. existing works. statisticians adopted stochastic models speciﬁc rules response behavior customer desarbo ramaswamy levin zahavi also efforts development ranking mechanisms business interests hilderman hamilton pruning summarizing learnt rules considering similarity however approaches suitable problems studied paper major drawbacks. first provide customized actionable knowledge individual since rules rankings derived entire population training data. second consider action costs building rules rankings. example income housewife sensitive sales promotion driven consumption target social housewife interested promotions related social networks. thus rule-based ranking algorithms cannot tackle problems well since personalized customer. another related work extracting actionable knowledge decision tree additive tree models bounded tree search integer linear programming yang yang’s work focuses ﬁnding optimal strategies using greedy strategy search multiple decision trees yang integer linear programming method actions changing sample membership ensemble trees limitation works actions assumed change attribute time. discussed above actions like sending promotion change multiple features promotion moreover yang’s greedy method fast cannot give optimal solution yang cui’s optimization method optimal slow order address challenges propose novel approach extract actionable knowledge random forests popular learning models. approach leverages planning core extensively researched areas ﬁrst rigorously formulate knowledge extracting problem sub-optimal actionable planning problem deﬁned ﬁnding sequence actions transferring given input desirable goal minimizing total action costs. then approach consists phases. ofﬂine preprocessing phase anytime state-space search action graph preferred goal instance training dataset store results database. online phase given input translate soap problem sas+ planning problem. sas+ planning problem solved efﬁcient maxsat-based approach capable optimizing plan metrics. perform empirical studies evaluate approach. real-world credit card company dataset obtained industrial research collaboration. also evaluate standard benchmark datasets. compare quality efﬁciency method several stateof-the-art methods. experimental results show method achieves near-optimal quality real-time online search compared existing methods. random forest popular model classiﬁcation main tasks learning. reasons choose random forest addition superior classiﬁcation/regression performance random forest enjoys many appealing properties many models lack friedman including support multi-class classiﬁcation natural handling missing values data mixed types. often referred best off-the-shelf classiﬁer friedman random forest widely deployed many industrial products kinect shotton face detection camera viola jones popular method competitions search ranking mohan consider dataset training samples classiﬁcation labels. vector consists attributes attribute either categorical numerical ﬁnite inﬁnite domain dom. note represent confusion. labels ﬁnite categorical domain dom. classical planning popular formalisms strips pddl long recent years another indirect formalism sas+ attracted increasing uses many favorable features compact encoding multi-valued variables natural support invariants associated domain transition graphs causal graphs capture vital structural information b¨ackstr¨om nebel jonsson b¨ackstr¨om helmert sas+ formalism planning problem deﬁned multi-valued state variables variable ﬁnite domain dom. state full assignment variables. variable assigned state denote represent states. deﬁnition given multi-valued state variable domain transition deﬁned tuple written transition applicable state represent applying transition state applying transition state. also simplify notation variable denote transitions affect i.e. →g}∪ ∗→g} dom. also denote transitions i.e. sx∈x deﬁnition different transitions ′→g′ least mechanical transition compatible; otherwise mutually exclusive note made slight generalization original sas+ planning includes goal condition. state applicable action denote resulting state applying transitions note solution plan multiple non-mutex actions applied time step. means applying actions order state work want solution plan minimizes quality metric total action cost ppt∈p pa∈pt ﬁrst give intuitive description soap problem. given random forest input soap problem sequence actions that applied changes instance desirable output label random forest. since action incurs cost also needs minimize total action costs. general actions costs determined domain experts. example analysts credit card company decide actions perform much action costs. kinds features soft attributes changed reasonable costs hard attributes cannot changed reasonable cost gender yang consider actions change soft attributes. example random forest trees three features shown figure hard attribute soft attributes. given input output goal change instance output example actions changing plan instance soap problem proven np-hard problem even action change feature therefore cannot expect efﬁcient algorithm optimally solving propose planning-based approach solve soap problem. approach consists ofﬂine preprocessing phase needs given random forest online phase used solve soap problem instance. since typically prohibitively high number possible instances feature space expensive unnecessary explore entire space. reason training dataset building random forest gives representative distribution instances. therefore ofﬂine preprocessing form action graph identify preferred goal state training sample. given states deﬁne sas+ transitions actions according deﬁnitions example transformed state input corresponding state action changing represented thus resulting state applying soap problem deﬁnition equivalent ﬁnding shortest path state space graph given state goal state. node goal state given training data heuristic search preferred goal state path action graph state minimizing cost path. closed list implemented highly efﬁcient hashing-based duplicate detection. search terminates search found better plan long time large value experiments. note algorithm search states since stop search state satisﬁes termination condition online sas+ planning number closest states combination goals construct goal inspired idea similarity-based learning methods k-nearest-neighbor ﬁrst deﬁne similarity states. example preprocessed three initial states three preferred goal states found ofﬂine phase. online phase given input corresponding state suppose nearest neighbors goal sas+ problem online phase given solve sas+ instance deﬁned above. addition classical sas+ planning also want minimize total action costs. since existing classical planners perform well optimizing plan quality employ sat-based method. graphplan blum furst starts lower bound makespan encodes sas+ problem weighted partial max-sat instance either proves unsatisﬁable ﬁnds plan trying minimize total action costs time. clause types clauses soft clauses hard clauses. soft clause constructed {¬uat|∀a clause ¬uat weight deﬁned clause hard clause weight pc∈c must true. following hard clauses three main differences approach related work sase encoding huang first encoding transforms sas+ problem wpmax-sat problem aiming ﬁnding plan minimal total action costs sase transforms problem tries satisﬁable plan. second besides transition action variables encoding extra goal variables since goal deﬁnition sas+ problem combination several goal states sase partial assignment variables. third goal clauses encoding contain kinds clauses sase since goal deﬁnition complicated sase. solve encoding using maxsat solvers extensively studied. using soft clauses optimize plan wpmax-sat encoding similar balyo’s work balyo uses maxsat based approach plan optimization solve encoded wpmax-sat instances. comparison also implement three solvers iterative greedy algorithm denoted greedy chooses action iteration increases minimizes total action costs. keeps iterating variables change. sub-optimal state space method denoted integer linear programming method state-of-the-art algorithms solving soap problem. gives exact optimal solutions. test algorithms real-world credit card company dataset nine benchmark datasets repository libsvm website used ilp’s original experiments information datasets listed table number instances features classes respectively. random forest built training using random trees library opencv python run-time systems used. ofﬂine preprocess generate possible initial states algorithm preferred goal state initial state. dataset generate problems parameter settings experiments. speciﬁcally weighted euclidean distance action cost function. action changes state cost cost weight variable randomly generated since ofﬂine preprocess works totally independent parallelly solve large number workstation nodes. ofﬂine preprocess parallelly workstation computational nodes. node .ghz processor cores memory. instance time limit seconds. preprocess search ﬁnish seconds record best solution found terms proﬁt total search time ofﬂine preprocess percentage actual preprocessed states possible initial states transformed state space feature determing online search quality. preprocessing percentage randomly sample instances possible initial states algorithm preferred goals. then online search randomly sample instances test generate problems based preferred goals. report online search time seconds total action costs solutions averaged runs. figure total ofﬂine preprocessing time linearly increases percentage. average total action costs almost linearly decrease percentage. actually considering almost unlimited ofﬂine preprocessing time always increase preprocessing percentage eventually reach table shows comprehensive comparison terms average search time solution quality measured total action costs action number solutions memory usage preprocessing percentage report search time seconds total action costs solutions action number solutions memory usage averaged runs. table even though method spends quite time ofﬂine processing online search fast. since method ﬁnds near optimal plans training samples solution quality much better greedy spending almost search time. comparing method much faster online search maintains better solution qualities ionosphere scale equal solution qualities datasets. comparing method much faster online search cost losing optimality. typically trained random forest model used long time. since ofﬂine preprocessing needs once cost well amortized large number repeated uses online search. short planning approach gives good quality-efﬁciency tradeoff achieves near-optimal quality using search time close greedy search. note since need store preprocessed states preferred goal states online phase memory usage method much larger greedy approaches. studied problem extracting actionable knowledge random forest widely used best off-the-shelf classiﬁers. formulated sub-optimal actionable plan problem aims action sequence change input instance’s prediction label desired minimum total action costs. proposed sas+ planning approach solve soap problem. ofﬂine phase construct action graph identify preferred goal input instance training dataset. online planning phase given input formulate soap problem sas+ planning instance based nearest neighborhood search preferred goals encode sas+ problem wpmax-sat instance solve calling wpmax-sat solver. approach heuristic suboptimal leveraged sas+ planning carefully engineered system gives good performance. empirical results credit card company dateset nine benchmarks shown algorithm achieves near-optimal solution quality ultra-efﬁcient representing much better quality-efﬁciency tradeoff methods. great advancements data science ultimate goal extracting patterns data facilitate decision making. envision machine learning models part larger systems make rational decisions. support actionability models crucial. work represents novel deep integration machine learning planning core areas believe integration broad impacts future. note proposed action extraction algorithm easily expanded additive tree models adaboost freund schapire gradient boosting trees friedman. thus proposed action extraction algorithm wide applications. soap formulation consider actions deterministic effects. however many realistic applications tackle nondeterministic actions. instance push promotional coupon certain probability increase accumulation effect since people always accept coupon. consider nondeterministic actions model near future. work supported part national natural science foundation china natural science foundation jiangsu province natural science foundation jiangsu higher education institutions national science foundation united states microsoft research faculty fellowship.", "year": 2016}