{"title": "Learning Bayesian Nets that Perform Well", "tag": ["cs.AI", "cs.LG"], "abstract": "A Bayesian net (BN) is more than a succinct way to encode a probabilistic distribution; it also corresponds to a function used to answer queries. A BN can therefore be evaluated by the accuracy of the answers it returns. Many algorithms for learning BNs, however, attempt to optimize another criterion (usually likelihood, possibly augmented with a regularizing term), which is independent of the distribution of queries that are posed. This paper takes the \"performance criteria\" seriously, and considers the challenge of computing the BN whose performance - read \"accuracy over the distribution of queries\" - is optimal. We show that many aspects of this learning task are more difficult than the corresponding subtasks in the standard model.", "text": "bayesian encode probabilistic also corresponds queries. accuracy many algorithms attempt optimize ally likelihood regularizing distribution posed. paper takes \"performance criteria seriously challenge com­ puting whose performance read \"accuracy distribution optimal. learning corresponding model. many tasks require answering applies expert iden­ tify underlying fault given symp­ toms control actions readings. enough basis sensor certainty information probabil­ answering return value answer. many systems answer probabilistic queries \"bayesian tribution distribution appropriate cases learn model. measure mented \"regularizing\" sures like bayesian information terion sures independent understand care certain ability served likelihood produces care about. paper therefore learning queries events a.nd therefore seek best performance query distribution appears underlying event distribution. make point concrete queries assignments possible =true). cide best. imagine candidates performs optimally queries queries queries queries. here would penalize queries ally care b-over-b preference wrong. timated given examples mates conditional probabilities general examples eters within entire \"waste\" value irrelevant parameters. seems better focus learner's relevant queries variables; implicitly assumes possible complete tuples) contrast single occur equally query note particular query's consequent; considerably simplifies eral issues related tional/ given finding best given structure. climbing locally tasks computationally classes also presents class queries tion reflects knowledge efficiency show lead ways learning sample-efficient proach. first close section results related results closest friedman goldszmidt also con­ sider finding best distribution queries also maximal log-likelihood timal performance note evaluating training log-likelihood measure ables variables. such resemble stan­ dard class \"statistical kearns others learners. queries derlying accuracy queries expression trast learner posed \"environment\" based accuracy respect assigns probability event queries however value given values first summation rank could poorly contributions first. paper however building specific \"consequent\" possible written y=y) probability query \"what value asked. course allow prior value independe requesting also write refer conditioning. probability sets inferred variable context. correlated value conditional fact underlying means query determi­ nate answer given true condition general call tuple \"labeled tistical network real-value returns tion \"score\" simple example states sifications {ai}· variables claim /n+l assignment. state queries involve observed involve attributes different observed seek probability observed variables distribution variable need query \"legal\" note also capital letters represent variables lowercase letters values vari­ ables might assume boldface font dealing sets variables observation algorithm mations limit distribution becomes given small examples however tribution optimal. computational lying task. subsection task evaluating given network tion often essential tion analyses task filling cp-tables tion discusses tables optimal. structure variables people often know \"causal\" information actually expected given structure training filling connections i.e. learn \"strength\" motivate task cp-table entries. ''fitting\" given structure note general often sub-routine systems must also search en-learning space structures. computational best cp-table. subsection suggests practical stated precisely specific bayesian directed acyclic graph nodes edges course many structure corre­ sponding ways filling cp-tables. denote bns. address task finding whose score high probability minimal class; i.e. course as.\\ arbitrarily small worse) bound arbitrarily terms size bayesian net. note also friedman yakhini depends \"skewness\" define smallest event atomic events. final comments recall bounds scribe many examples required; much work required given information. unfor­ using examples compute score tunately requires solving p-hard problem; the­ orem sample complexity results hold estimating arbitrary distributions; probability subsection statistical unlabeled gether event unfortunately area appears computa­ teresting questions tionally difficult worst case. fact prove result finding stronger bayesian np-hard actually non-approximatable theorem assuming polynomial­ single since chosen fact cannot confidence estimated must sufficiently simultaneously many) t'?l/en within true values error. confident b*'s accuracy. section also consider complex task learning cp-table unlabeled underlying augmented tion however ward extension query\" case first draws slightly unlabeled sufficient mate labels queries ulating ciently many labeled caveats encounter statistical queries ditioning events probability nontrivial upper bound number ples needed learn good setting proof entries). xtension theorem sult straightforward omit details however problem complexity conditions; labeled gives minimal high probability full distribution conjecture true general. following restriction. conditioning events define point that sample complexity tive feasible learn near optimal settings model. difficult part actu­ ally computing training theorem fact section correct entry estimates. frequency t�en ';lse �his. derivati�e update gradi­ value htll-chmbmg furthermore gradient ascent move constrain remains difference b-pis correct) makes intuitive sense. unfortunately evaluating gradient quires computing conditional probabilities analogous known result tra­ model ditional thus follows gradient general however special casesi.e. inference possible. demonstration class \"markov­ blanket queries\" carrying gradient computation easy case updatin� gnore queries outside need consider markov blanket. therefore queries moreover consistent assign­ ment; queries intuition cess distribution learn better efficiently domain tuples alone. really true? note simplest standard approach learning cp-table entries simply filling estimates cp-table entry observed frequency obtained note ignores information query distribution. unfor­ tunately necessarily good idea model even arbitrary number theorem amples. follows immediately standard algorithm always success­ would trivial time gorithm computing near-optimal cp-table fixed bayesian structure -which cannot observation claim optimal faithful value tion meaning particular table entry filled true probability case structure corre­ spond true conditional underlying ignoring using straight results example suppose structure labeled queries proba­ querying bility interested given suppose completely structure situation event distribution would cp-table ries exia ex;t per­ ormance score consider whose ent�ies exia ecix exji make clearly -dependencies wrong score perfect i.e. thus filling estimates verges leads solution matter many training hand consider filling probabilities cp-table entries would eventually learn perfect classifier. might based course theo­ perhaps hill-climbing d-separated table entry evlu cannot affect answer query thus seems clear need bother estimating learning algorithm bound mance guarantees. distribution allow stop learning ples. thus using query advantage amount fill­ basic learning cp-table obtained distribution know safe stop earlier evant. queries answer queries constrained occur optimal bopt could \"set\" bopt extremely small; knowing perhaps large s�ead assumes former quantity small simply would helped restrictions example consider standard \"naive bayes\" model binary attributes conditionally independent given figure suppose single query interest must attempt learn directly wait (possibly rare} event easy construct require exponential examples. however en-structure compute required probability soon learned probabilities approach optimal tive techniques sample tasks (see theorems given various obvious also identif signific tasks computatio also contrasted approach standard found many subtle \"algorith small-sample", "year": 2013}