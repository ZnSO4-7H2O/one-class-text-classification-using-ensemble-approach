{"title": "OCRAPOSE II: An OCR-based indoor positioning system using mobile phone  images", "tag": ["cs.CV", "cs.AI"], "abstract": "In this paper, we propose an OCR (optical character recognition)-based localization system called OCRAPOSE II, which is applicable in a number of indoor scenarios including office buildings, parkings, airports, grocery stores, etc. In these scenarios, characters (i.e. texts or numbers) can be used as suitable distinctive landmarks for localization. The proposed system takes advantage of OCR to read these characters in the query still images and provides a rough location estimate using a floor plan. Then, it finds depth and angle-of-view of the query using the information provided by the OCR engine in order to refine the location estimate. We derive novel formulas for the query angle-of-view and depth estimation using image line segments and the OCR box information. We demonstrate the applicability and effectiveness of the proposed system through experiments in indoor scenarios. It is shown that our system demonstrates better performance compared to the state-of-the-art benchmarks in terms of location recognition rate and average localization error specially under sparse database condition.", "text": "abstract—in paper propose -based localization system called ocrapose applicable number indoor scenarios including ofﬁce buildings parkings airports grocery stores etc. scenarios characters used suitable distinctive landmarks localization. proposed system takes advantage read characters query still images provides rough location estimate using ﬂoor plan. then ﬁnds depth angle-of-view query using information provided engine order reﬁne location estimate. derive novel formulas query angle-of-view depth estimation using image line segments information. demonstrate applicability effectiveness proposed system experiments indoor scenarios. shown system demonstrates better performance compared state-of-the-art benchmarks terms location recognition rate average localization error specially sparse database condition. based fusion wi-fi ﬁngerprints inertial sensors data methods require fair number wi-fi access points visible location conditions demonstrate localization errors meters training points granularity meter scenarios enough wi-fi access points available; access wi-fi reader hardware blocked greater localization accuracy required image-based methods used effective solution. although image-based localization studied long time ﬁelds robotics augmented reality pursued past decade mobile phones indoor scenarios proposed methods categorized classes image retrieval-based landmark-based categories image-based localization methods i.e. landmark-based image retrieval-based require database images well coordinates/locations measured stored training phase. data gathering labor intensive always possible. furthermore methods proposed literature utilize feature extraction matching localization feature extraction corresponding database creation large environment highly time consuming. moreover simple feature matching robust large changes angle-of-view almost scene present images cannot acceptably matched difference large methods asift sadeghi valaee department electrical computer engineering university toronto canada e-mail hsadeghivalaeeece.utoronto.ca. shirani department electrical computer engineering mcmaster university canada email shiranimcmaster.ca. robust changes high complexity. instance complexity asift least times sift importantly observed number indoor environments ofﬁce buildings parkings airports grocery stores etc. distinctive landmarks text and/or numbers aforementioned methods fail provide good location recognition performance considerable percentage queries. scenarios large image databases stereo feature matching computationally expensive performed best matches detection image retrievalbased methods. instead features-based methods used best matching landmark/image. here stereo feature matching illustrate existence confusing similar features lack distinctive features main reasons failure best match detection fig. depicts university building scenario existing literature methods demonstrate poor localization performance. reason failure detecting correct existing characters using landmark-based methods characters textured commonly used landmarks commercial logos ﬁducial markers hence point feature-based recognition approaches fail extract enough distinctive features required distinguish different numbers other. instance fig. illustrates stereo feature matching cannot distinguish existing database numbers i.e. corresponds query number seen although digit common among different numbers features concentrated around confuses feature-based recognizer cannot correct i.e. last bottom one. problem exists want distinguish gate numbers airports instance gate numbers closest location query. seen fig. last bottom image correct database image containing numbers achieved minimum number common matching features huge difference angle-of-view. seen selected matching threshold door handle matched well digit hand although middle right image contains number gained maximum number common matches query angle-of-view similar query. image retrieval techniques features localization-speciﬁc ones might also fail retrieve correct matching characters. existence similar objects rather distinctive ones. doors windows door handles among objects scenario evaluate recognition performance liang’s method example experiments. noted image-retrieval based methods mentioned general point feature-based retrieval techniques retrieval methods designed location recognition. point feature-based techniques proposed originally character recognition result ocr-based localization method resides category method. mentioned issues i.e. labor extensiveness poor recognition performance conventional point featurebased methods motivate recognize existing location-distinctive characters. recognizing characters query image provide rough location estimate using building ﬂoor plan. assume ﬂoor plan tagged location-distinctive characters locations. example seen fig. location-distinctive characters shared different locations exit signs potentially confuse localizer. furthermore rely stable characters room/gate numbers rather texts/numbers bulletin boards could replaced removed while. besides location recognition provides clues localization demonstrated later. hence proposed image-based system performs location recognition location estimation based ocr. collect location-tagged image database localization. system requires ﬂoor plan tagged characters locations width boxes measured determined based typical values. furthermore require feature detection extraction matching. another characteristic proposed localization system integrated feature-based systems either landmark-based image retrieval-based. demonstrated improve landmark-based localization system terms location recognition localization accuracy. noted proposing character detection/recognition algorithm here. instead focus ocrbased location recognition well localization user using novel formulas depth angle-of-view estimation. contributions three-fold fig. sample scenarios landmark-based image retrieval-based methods fail correct match lack enough distinctive features; left-hand images query images right-hand ones different database images containing different numbers furthermore also high probability seeing similar scenery different locations mentioned scenarios. hence image retrieval-based methods might frequently fail best matching image i.e. novel formula query angle-of-view estimation novel formula query depth estimation taking advantage rough localization utilizing proposed formulas reﬁne estimate provide better localization results sample scenarios. ocrapose results better stateof-the-art terms location recognition rate mean localization error. furthermore shown proposed system localization performance maintained sparse database locations condition benchmarks degrades signiﬁcantly. paper organized follows. section brieﬂy introduces related literature work explains benchmarks details. section introduces proposed system explains details. section compares performance proposed system benchmarks extensive experiments scenarios. finally section concludes paper. related work although image-based robot localization augmented reality applications rich literature image-based user localization active ﬁeld research last decade. explained proposed image-based methods categorized classes. here provide examples category explain methods related works well selected benchmarks details. image retrieval-based methods applied general scenarios. methods perform well applications abundant distinctive landmarks shopping malls scenarios unrepeated scenery outdoors work basis visually different images taken different positions. captured image works ﬁngerprint location. implicit assumption methods give poor location estimates environments repeated scenery ofﬁce buildings parkings airports etc. moreover large database images required collected geo-tagged training phase. furthermore test phase query image compared entire database best match best pair hence considerable processing time required perform localization training query phases. landmark-based methods applicable scenarios highly textured distinctive landmarks present methods logo/landmark detection techniques detect existing landmarks/logos query image. afterwards previously measured coordinates detected landmark image used estimate camera matrix. query location obtained afterwards estimated camera matrix. instance shopping malls textured commercial logos ubiquitous methods provide great localization accuracy texture usually required extract feature points necessary unique logo detection. terms database size contrary image retrieval-based methods landmark-based methods require small image database existing landmarks well actual among works proposed literature utilize localization mentioned explicit rough localizer. fact proposes ocr-assisted multi sensor method navigation emergency indoor scenarios. proposed method provides rough location estimates localization method proposed. good indoor localization system benchmarks proposed uses cbir perform rough localization. requires location-tagged database. training phase sift features images extracted loaded single flann kd-tree. test phase sift features query image extracted looked flann tree. fact nearest neighbors feature found votes corresponding image database increased i.e. voting scheme. thereafter database images ranked based collected votes. ﬁnding best matches geometric consistency sift features angle difference checks performed prune matched features query image best matches. next best match selected among best matches. following stage perform pose estimation fact phone sensors including accelerometer magnetometer order rotation angles. since side information available problem best match selection benchmark coarse localizer refer work liang’s method experimental results. second benchmark method proposed proposes feature-based method localization. proposed method composed stages. ﬁrst stage ﬁnds best pair images database. best pair deﬁned pair images linear combination image descriptors estimates query descriptor least error. next linearly combines locations best matches interpolation factor order estimate query location. suggests interpolation factor afﬁne function visual similarity database query images. visual similarity computed using well-known feature representation database query images. offset slope parameters linear relation interpolation factor visual similarity learned independent database training phase. image similarity computation features representation used paper modiﬁed vlad’s representation demonstrated supreme performance. refer benchmark torii’s method. proposed ocr-aided localization system called ocrapose. system utilizes read existing characters query image provides rough location estimate using character location-tagged ﬂoor plan. afterwards performs ocr-aided stereo feature matching query database images containing characters. stereo matching results used estimate homography matrix. homography used world coordinates query features. next problem solved query feature points world coordinates obtain location estimate. main difference ocrapose ocrapose proposed system require world coordinates measurement image database collection point feature extraction/matching. hence practical terms alleviating requirement huge image database collection avoiding point feature processing complexity. furthermore novel projective geometrybased formulas proposed ocrapose depth angle-of-view estimation. mentioned benchmarks require training images. therefore collect number training images scenario. noted method require image databases. side information required locations characters centroid indoor scenarios well width boxes deﬁned later. information required perform query localization ﬂoor plan. proposed system fig. depicts structure proposed system. seen proposed system detects horizontal vanishing point order estimate user’s respect location centroid characters. furthermore detects recognizes characters query image along ﬂoor plan provides required information rough localization. next using estimated width image real world depth query estimated. finally estimate user’s location computed using estimated depth aov. sequel explain role system blocks details. characters detection seen fig. query image input characters detection block. role characters detection block detect regions interest contain characters. false positive regions tolerable long able identify remove list true positives. text detection natural scene images extremely difﬁcult problem might need parameters tuning scenario investigation. hand proposing text detection algorithm scope paper. hence state-of-theart techniques design text detection block. noted utilizing better text detection algorithm results higher location recognition performance proposed method. consequently results larger performance proposed method featurebased ones. indoor scenarios text usually printed uniformly board causes text regions appear uniform colors inside query images. regions good candidates detected maximally stable extremal regions also suggested hence extract mser regions potential characters. found inefﬁcient since computationally cheaper remove improbable regions ﬁrst avoid required excess processing later. therefore perform geometric ﬁltering ﬁrst follows reﬁne mser regions afterwards. deﬁne detected mser regions geometric ﬁltering composed steps. first remove large regions whose area times median area regions. next remove regions whose orientation degrees away vertical orientation. since character usually oriented vertically query camera image captured zero pitch angle. mser region detector known sensitive image blur blurring causes mser detector miss detect distorted regions makes difﬁcult. hence enhance mser regions using uses canny edge detector enhance outline detected extremal regions. fact prunes mser regions along detected gradient direction suggested canny edge detector. avoid reﬁnement using detection techniques proposed literature stroke width transform complexity. mentioned level reﬁnement turned sufﬁcient applications. perform simple preprocessing operations inputting image engine explained section block recognizes existing characters detected regions. perform preprocessing prior inputting enhanced mser regions block. preprocessing includes global binarization removing relatively small/large regions. next input remaining regions engine. order perform matlab function using google tesseract engine. engine based convolutional neural network approach character recognition. tesseract believed accurate engines detect line segments query image utilize order estimate horizontal vanishing point next derive novel formula estimation using detected vanishing point. dist represents distance image point line furthermore |li| stands length terms number pixels. fact minimize weighted horizontal distances detected lines. hence solution essentially estimate priors assigned proportional line lengths. moreover distance noise assumed gaussian. conditions minimizing proposed cost function maximizes a-posteriori probability. proposed minimization problem closed form solution follows. proposition assume almost horizontal line vanishing points present image contain information query camera rotation respect seen objects roll angle query camera zero respect horizon horizontal line segments intersect horizontal moreover perpendicular obtained cross product vps. therefore image line segments help vanishing points hence complete query rotation matrix. perform line segments processing detection. explain section horizontal needed method. hence detect solving novel robust optimization problem partly inspired line segments detected using edge-based method proposed also method extract line segments. afterwards estimate horizontal vanishing point location image using detected line segments. order this propose novel robust optimization problem inspired using ransac assume total number detected lines ransac selects line segments iteration. least order vanishing point proposed optimization problem ﬁnds point image plane minimum total weighted distances lines considered current iteration camera center. motivation place location detected characters center attention i.e. middle image. used test whether angle conditions met. since tilt roll assumed zero unknown angle pan. mentioned indoor images visible objects located single wall. conclusion lines seen horizontal/vertical query image actually horizontal/vertical real world. consider scenario depicted fig. seen angle equal aov. location horizontal function angle. hence knowing horizontal estimate aov. following section propose novel formula estimates scenario depicted fig. estimating horizontal vanishing point section propose novel formula estimating practical scenario depicted fig. using estimated horizontal corners derivation formula required detect corners actual query phase practice. ﬁctitious surrounding characters depicted fig. approximate formula derived estimation independent dimensions box. depth estimation formula requires actual width box. hence need measure width environment. since value high probability text/number plates single building need perform measurement once. character boxes different width size environment possible tabulate sizes engine identiﬁed characters. fig. shows result applying proposed method sample query image taken inside university building. stated order derive practical formulas depth estimation make assumptions query rotation angles respect characters centroid first assume roll angle zero. assumption easily relaxed image preprocessing. stated vertical vanishing point known roll angle estimated vertical vanishing point also estimated using method similar proposed horizontal roll angle estimated query image rotated accordingly order remove non-zero roll effect. human user localization need perform pre-processing compensate nonzero roll. assume tilt angle zero. assumption exactly practice practical values fairly close zero. difference comes height difference characters centroid camera center. section study range tilt angles practice demonstrate negligible effect accuracy depth formulas. order derive formula consider arbitrary dimensions. analyze projection query image. projected coordinates formula derived obtaining horizontal manipulating formula closed-form formula derived estimation terms horizontal location. proposition summarizes results. seen roll angle account pointing camera towards reference frame origin inwards direction. depicted fig. x··· represent coordinates corners. deﬁne xbox verify xbox represented terms equation gives expression xbox function horizontal width using coordinates. here goal horizontal terms done intersecting ‘almost’ horizontal lines connecting proof without loss generality assume located origin reference frame depicted fig. furthermore according scenario depicted fig. user i.e. query camera located depth query respect characters centroid. normalized camera matrix k−p) analysis make independent camera calibration matrix. using assumptions normalized camera matrix written fig. depicts true approximated values xhor. seen approximation close true value almost entire range depicts error estimation mentioned range. seen closer boundaries interval worse approximation. value error entire range investigate sensitivity measure robustness derived formulas. take derivative formula derived quantity interest respect parameters problem. fig. depicts sensitivity estimated range xhor values samsung galaxy cellphone. instance xhor recognized existing characters rough estimate user’s location obtained using ﬂoor plan. moreover user’s estimated missing information user’s location distance characters centroid. hence input output image depth estimation block. notice existence block required since provides rough location estimate side information required depth estimation. proof consider fig. estimation studied bottom horizontal line segments box. here calculate width show function depth similar angle-of-view formula derivation corners coordinates order derive depth formula. fact required detect corners actual query phase. consider matrix xbox contains image coordinates corners. projective distortion image quadrilateral general. considering fact vertical lines remain vertical neither in-plane rotation tilt angle calculated similar formula derivation know complete query camera matrix terms coordinates corners. hence using parameterized camera matrix corner location image using non-zero tilt angle effect depth estimation error derivation xhor formulas assumed tilt angle zero. order study effect non-zero tilt angle practice re-derive formulas non-zero tilt angle depth formula concord intuition smaller corresponds greater distance characters. fig. shows sensitivity depth estimate respect estimated i.e. seen distance characters center degrees worst cases localization accuracy degree error result error depth estimate. fig. depicts sensitivity depth estimate w.r.t. samsung galaxy used calibration matrix phone camera obtain sensitivity meters/pixel. seen pixels pixel error results error depth estimation. finally sensitivity depth formula linear respect measured considered derivation formula rectangular provided engine always frames entire area characters. hence width equal maximum horizontal distance among based sign stated formula. equation obviously hence cannot approximated way. furthermore noted yhor zero case non-zero tilt angle. still utilize xhor estimate using would error. fig. depicts value error range w.r.t. different values tilt angle seen tilt angles range error estimate decreasing absolute value tilt increases. shows error induced non-zero tilt angle canceling approximation error existing reason absolute value estimated i.e. inverse xhor always greater absolute value actual i.e. |θactual| |θestimated| |xhor| addition increasing absolute value decreases |xhor| hence increases |θestimated|. essence fig. depicts normalized error depth estimate different values normalized error deﬁned error depth estimate divided actual depth. seen value normalized error less conclusion formulas depth estimation still effective used without change. furthermore mentioned quite large interval practical scenarios. example university scenario experiments centroid characters region located height stated human users naturally point phones towards centroid characters plate. furthermore usually hold phones height approximately equal level. hence non-zero tilt comes height difference phone characters centroid stated before. conclusion user horizontally away characters centroid phone held height tilt varies mentioned interval. user gets further tilt range corresponds even greater range heights. hence mentioned range quite large contains almost possible people heights indoor scenarios. similar discussion airport scenario. worst case scenario assume gate centroid located height query camera case user horizontal distance centroid greater tilt angle less experimental results localization performance proposed system compared state-of-the-art works liang’s torii’s compare methods terms recognition error rate location estimation error. liang’s method recognition error percentage deﬁned percentage images wrong detected best match. location recognition problem wrong best match database image contain characters query. torii’s method recognition rate meaningless since image retrieval phase best image pair selected database images. method i.e. ocrapose wrong recognition corresponds recognizing characters wrong. conventional buildings wrong recognition single character lead false location right besides query meters away even ﬂoors depending location mis-recognized character. furthermore estimation error methods deﬁned localization error among truly recognized locations. camera calibration matrices phones cameras assumed known scenarios. feature extraction processing needed benchmarks performed using codes available torii’s method modiﬁed vlad decriptors image description obtain high recognition performance. modiﬁed vlad descriptor improved version descriptor suggested demonstrated supreme performance compared tf-idf methods used studied university building scenarios parking area representatives indoor scenarios. building scenarios contain large number different numbers located different locations makes appropriate candidates location recognition error evaluation. hand parking scenario contains word seen distances different angleof-views. hence suitable scenario localization error evaluation. addition commercial mobile phones i.e. google nexus samsung galaxy used experiments provide device diversity conditions. furthermore university building scenarios measurement done since characters width. scenario exist light characters printed dark plates. sample query images shown fig. furthermore ﬂoor plan depicted fig. trace locations seen dotted line. training query phases benchmarks images captured regular locations. room number fig. capture three images i.e. left middle right following pair information done locations total images taken scenario. consider odd-index images queries even ones database images. furthermore samsung galaxy cellphone used image capturing scenario. fig. shows number sample images. location recognition rate i.e. correct detections among queries. hence include results method scenario. recognition rate demonstrates weakly image retrieval-based method might perform mentioned indoor scenarios. distribution function) localization error ocrapose torii’s methods. seen ocrapose demonstrates better localization error compared torii’s. reason torii’s method interpolates image pair locations hence performs poorly query located outside database locations i.e. extrapolation case. however proposed method capable estimation depth estimation cases including extrapolation. finally downsample database locations evaluate robustness methods coarse databases fewer locations. fact keep query points downsample database locations set. noted results ocrapose method different downsampling factors since rely database images. fig. shows average location estimate error different methods. seen torii’s error generally increasing database downsampling factor. contrary ocrapose error ﬁxed always less torii’s method. stated before scenario designed compare location estimation error methods only. fact word east depicted used localization. actual width word fig. depicts sample images taken scenario. images taken three angle-of-views depths belong interval table shows summary location estimation error results. seen ocrapose outperforming benchmarks terms location accuracy large gap. existence larger scenario compared previous ones. leads lower relative error estimation width. fig. comparing localization error results. seen ocrapose demonstrates smaller average localization errors. moreover fig. shows effect database locations downsampling average localization error. depicted ocrapose demonstrates much less error compared benchmarks. studied scenarios demonstrate applicability proposed ocr-based method. assumptions made regarding alignment characters relative position orientation user respect characters usually hold practice. furthermore size conventional characters large enough recognized high probability even furthest possible locations user. fact texts gate numbers bigger larger areas airports parkings etc. user might tens meters away. based experiments character seen least width pixels query image large enough engines recognize. locations. scenario sampled images regularly locations distance using google nexus cellphone. depths range aovs belong here show brief summary results table favor limited space available. seen location recognition proposed system comparable liang’s method. demonstrates smaller localization error average. reason liang’s method performs location recognition image-based location reﬁnement stage. however stated ocrapose reﬁnes location estimate cases hence outperforms benchmarks terms localization accuracy. utilizes perform rough localization. novel formulas also proposed angle-of-view depth estimation used reﬁne location estimate. experiments demonstrate proposed ocr-based system achieves better performance compared state-of-the-art localization methods terms location recognition rate average localization error. also shown benchmarks performance degrades database locations becomes sparser performance proposed system independent database sparsity remains constant. yang tracking mobile users wireless networks semi-supervised colocalization pattern analysis machine intelligence ieee transactions vol. march sadeghi-tehran behera angelov andreu autonomous visual self-localization completely unknown environment evolving adaptive intelligent systems ieee conference paucher turk location-based augmented reality mobile phones computer vision pattern recognition workshops ieee computer society conference ieee petriu fiducial marker indoor localization artiﬁcial neural network advanced intelligent mechatronics ieee/asme international conference july liang corso turner zakhor image based localization indoor environments computing geospatial research application fourth international conference sadeghi valaee shirani weighted epipolar geometry-based approach vision-based indoor localization using smartphone cameras sensor array multichannel signal processing workshop ieee ieee petriu fiducial marker indoor localization artiﬁcial neural network advanced intelligent mechatronics ieee/asme international conference july sadeghi valaee shirani semi-supervised logo-based indoor localization using smartphone cameras ieee pimrc alcantarilla mariottini bergasa dellaert learning visibility landmarks vision-based localization robotics automation ieee international conference paper discuss number indoor scenarios challenging existing localization methods propose using recognize characters suitable location distinctive landmarks. novel system proposed iwamura kobayashi kise recognition multiple characters scene image using arrangement local features document analysis recognition international conference sept sadeghi valaee shirani ocrapose indoor positioning system using smartphone/tablet cameras ocr-aided stereo feature matching acoustics speech signal processing ieee international conference april w.-t. t.-c. logo recognition localization real-world images using visual patterns acoustics speech signal processing ieee international conference march orlosky toyama sonntag sarkany lorincz on-body multi-input indoor localization dynamic emergency scenarios fusion magnetic tracking optical character recognition mixed-reality display pervasive computing communications workshops ieee international conference chen tsai schroth chen grzeszczuk girod robust text detection natural images edgeenhanced maximally stable extremal regions image processing ieee international conference ieee hallquist zakhor single view pose estimation mobile devices urban environments applications computer vision ieee workshop ieee gioi jakubowicz j.-m. morel randall fast line segment detector false detection control ieee transactions pattern analysis machine intelligence vol. j´egou douze schmid p´erez aggregating local descriptors compact image representation computer vision pattern recognition ieee conference ieee", "year": 2017}