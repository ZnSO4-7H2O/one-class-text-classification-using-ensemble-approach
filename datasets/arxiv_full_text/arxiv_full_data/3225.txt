{"title": "Video Ladder Networks", "tag": ["cs.LG", "cs.CV", "stat.ML"], "abstract": "We present the Video Ladder Network (VLN) for efficiently generating future video frames. VLN is a neural encoder-decoder model augmented at all layers by both recurrent and feedforward lateral connections. At each layer, these connections form a lateral recurrent residual block, where the feedforward connection represents a skip connection and the recurrent connection represents the residual. Thanks to the recurrent connections, the decoder can exploit temporal summaries generated from all layers of the encoder. This way, the top layer is relieved from the pressure of modeling lower-level spatial and temporal details. Furthermore, we extend the basic version of VLN to incorporate ResNet-style residual blocks in the encoder and decoder, which help improving the prediction results. VLN is trained in self-supervised regime on the Moving MNIST dataset, achieving competitive results while having very simple structure and providing fast inference.", "text": "present video ladder network efﬁciently generating future video frames. neural encoder-decoder model augmented layers recurrent feedforward lateral connections. layer connections form lateral recurrent residual block feedforward connection represents skip connection recurrent connection represents residual. thanks recurrent connections decoder exploit temporal summaries generated layers encoder. layer relieved pressure modeling lower-level spatial temporal details. furthermore extend basic version incorporate resnet-style residual blocks encoder decoder help improving prediction results. trained selfsupervised regime moving mnist dataset achieving competitive results simple structure providing fast inference. recent years several research groups deep learning computer vision communities targeted video prediction brabandere kalchbrenner task consists providing model sequence past frames asking generate next frames sequence challenging task model needs embed rich internal representation world physical rules highly-structured. machine learning -based models video prediction typically trained self-supervised regime ground-truth future frames provided targets. sometimes referred also unsupervised training manually-labelled data needed. training model predict future video frames beneﬁcial number applications. first learned internal representations used extracting rich semantic features space time utilized different supervised discriminative tasks action activity recognition semantic segmentation etc. also ability predict future important skill humans used anticipating consequence actions real-world thus allowing make decisions action perform. hence internal video representations support robots action decision process. propose video ladder network neural network architecture generating future video frames efﬁciently. proposed network evaluated benchmark dataset moving mnist dataset compared relevant prior works. show model achieves competitive results simple structure providing fast inference. rest paper organized follows. section describes proposed model. section provides experimental results. finally section draws concluding remarks. encoder decoder common fully-convolutional feedforward neural networks. particular encoder consists dilated convolutional layers whereas decoder uses normal convolutions. encoder decoder batch-normalization leaky-relu activation function also experimented simple extension basic model incorporating resnet-style residual blocks encoder decoder. extended model named vln-resnet shown figure vln-resnet layers similar number parameters. seen ﬁgure forward backward signals using multiple paths encoder-decoder sides lateral connections. valpola showed supplying decoder information encoder layers improves learned image features makes invariant small changes input. transfers concept unsupervised learning temporal domain using recurrent lateral connections feedforward lateral connections. layer recurrent connection feedforward connection form recurrent residual block recurrent connection represents residual feedforward connection represents skip connection. separate recurrent residual block different layers hierarchy relieves higher layers pressure modeling lower-level spatial temporal details. feedforward lateral connections supply decoder information latest input sample expect especially useful modeling static parts. recurrent connection consists convolutional long short-term memory extension fully-connected lstm particular conv-lstms replace matrix multiplications convolution operations thus allow previous hidden state bias terms tanh sigmoid hyperbolic tangent non-linearities respectively convolution operator. then hidden state output recurrent lateral connection layer computed follows evaluate video ladder networks moving mnist dataset generate using code provided authors. dataset derived popular mnist dataset contains training samples testing samples. validation samples selected picking training samples preserving percentage samples class. produce moving mnist samples corresponding mnist partitions generating train samples validation samples epoch. furthermore evaluation performed provided test-set samples. video sequence generated moving digits within video frames. digit randomly chosen initially positioned randomly inside patch. moved along random direction constant speed bouncing hitting frame’s boundaries. digits frame move independently allowed overlap. video sequence consists frames ﬁrst represent past frames used input frames model whereas following frames represent future ground-truth frames predicted. frame size encoder consists dilated convolutional layers stride dilations number ﬁlters decoder convolutional layers preceded up-sampling. empirically observed using dilation decoder bring beneﬁt. layers kernel size convolutional lstms number channels input. vln-resnet encoder decoder consist residual blocks block contains convolutional layers stride kernel size number ﬁlters encoder uses dilated convolutions dilation rates followed element-wise skip connection strided convolution halving resolution. decoder side residual block starts up-sampling. compare models relevant prior baselines vln-bl vln-bl-ff. speciﬁcally vln-bl convolutional-lstm layer feedforward lateral connections. vln-bl-ff includes also feedforward connections layers. order improve computational efﬁciency model decided extend effective receptive ﬁeld model reducing resolution striding going model hierarchy. computational efﬁciency issue possible larger dilations and/or depth preserve resolution layers kalchbrenner left future work. train evaluate using binary cross-entropy loss interpreting grayscale targets probabilities kalchbrenner ideally loss used training averaged predictions limited computational resources average predictions. disadvantage respect prior works. however losses used model evaluation averaged frames order fairly compare prior art. train models epochs using rmsprop initial learning rate windowing approach training prediction. input window length latest prediction ˆxt+ back input window shifted used ground-truth xnt+ shifting window training phase conv-lstm hidden state preserved whereas evaluation phase state reset. figure plot test-set loss time-step. seen losses last predictions variance apart other compared ﬁrst predictions. causes average test loss high variance too. results table show vln-resnet outperform models except baseline video pixel networks much parameters depth. baselines vln-bl vln-bl-ff perform well attribute competitive results convolutional-lstm batch-normalization windowing training prediction approach. comparing vln-bl vln-bl-ff worth noticing feedforward connections bring marginal improvement moving mnist dataset providing evidence main beneﬁt comes recurrent lateral connections. figure shows four randomly drawn test-set samples predictions generated vln-resnet. left comparison works comparable vln. speciﬁcally model described kalchbrenner frame predicted pixel pixel slow uses layers needs iterations model described patraucean encodes motion explicitly. model simple structure faster inference encode motion explicitly. furthermore vln’s recurrent residual blocks easily included encoder-decoder models baseline. figure four randomly selected test-set samples. first sample ﬁrst frames input past frames remaining frames ground-truth future frames. second sample future frames predicted vln-resnet. proposed video ladder network novel neural architecture generating future video frames conditioned past frames. characterized lateral recurrent residual blocks. lateral connections connecting encoder decoder summarize spatial temporal information layers. layer relieved pressure modeling spatial temporal details decoder generate future frames using information different semantic levels. furthermore proposed extension uses resnet-style encoder decoder. proposed models evaluated moving mnist dataset comparing prior works including current state-of-the-art model showed vln-resnet achieve competitive results simple structure providing fast inference.", "year": 2016}