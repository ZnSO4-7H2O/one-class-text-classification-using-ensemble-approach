{"title": "On the High-dimensional Power of Linear-time Kernel Two-Sample Testing  under Mean-difference Alternatives", "tag": ["math.ST", "cs.AI", "cs.IT", "cs.LG", "math.IT", "stat.ML", "stat.TH"], "abstract": "Nonparametric two sample testing deals with the question of consistently deciding if two distributions are different, given samples from both, without making any parametric assumptions about the form of the distributions. The current literature is split into two kinds of tests - those which are consistent without any assumptions about how the distributions may differ (\\textit{general} alternatives), and those which are designed to specifically test easier alternatives, like a difference in means (\\textit{mean-shift} alternatives).  The main contribution of this paper is to explicitly characterize the power of a popular nonparametric two sample test, designed for general alternatives, under a mean-shift alternative in the high-dimensional setting. Specifically, we explicitly derive the power of the linear-time Maximum Mean Discrepancy statistic using the Gaussian kernel, where the dimension and sample size can both tend to infinity at any rate, and the two distributions differ in their means. As a corollary, we find that if the signal-to-noise ratio is held constant, then the test's power goes to one if the number of samples increases faster than the dimension increases. This is the first explicit power derivation for a general nonparametric test in the high-dimensional setting, and also the first analysis of how tests designed for general alternatives perform when faced with easier ones.", "text": "nonparametric sample testing deals question consistently deciding distributions diﬀerent given samples both without making parametric assumptions form distributions. current literature split kinds tests consistent without assumptions distributions diﬀer designed speciﬁcally test easier alternatives like diﬀerence means main contribution paper explicitly characterize power popular nonparametric sample test designed general alternatives mean-shift alternative high-dimensional setting. speciﬁcally explicitly derive power linear-time maximum mean discrepancy statistic using gaussian kernel dimension sample size tend inﬁnity rate distributions diﬀer means. corollary signal-to-noise ratio held constant test’s power goes number samples increases faster dimension increases. ﬁrst explicit power derivation general nonparametric test high-dimensional setting also ﬁrst analysis tests designed general alternatives perform faced easier ones. central topic paper nonparametric two-sample testing detect diﬀerence d-dimensional distributions based samples both i.e. deciding whether samples drawn distribution. concerned following settings ﬁrst deals general alternatives i.e. called nonparametric two-sample testing parametric assumptions made form term general alternatives mean diﬀerence need simple form. contrast second setting concerned deals mean-shift alternatives i.e. ex∼p still nonparametric two-sample testing since make assumptions deals easier alternatives meaning specify exact form diﬀer i.e. diﬀer means. parametric two-sample testing also important scope discussion; lopes recent example. assume equal number samples many tests literature including ones consider calculate test statistic reject null hypothesis threshold depends distribution pre-deﬁned lehmann romano detailed introduction. test would called consistent ﬁxed power whenever false. vital importance theoretically practically understand power tests settings characterize rate must grow function test still consistent. classical tests proposed low-dimensional settings past decades several tests proposed speciﬁcally studied setting; subsection however best knowledge formal precise characterization power tests designed high dimensions. second motivation comes observation literature tests designed perform msa. words expected tests designed consistent general unclear exactly tests designed general alternatives fare faced mean-shift alternative. usual empirical estimators joint covariance matrix seminal paper saranadasa showed high-dimensional setting t-test performs quite poorly small intuitively diﬃculty estimating parameters samples. indeed even deﬁned poorly conditioned similar order avoid problem proposed test statistic many nonparametric test statistics two-sample testing. popular tests kernel maximum mean discrepancy henceforth called proposed gretton technical details kernel literature unnecessary purposes paper suﬃces population statistic recent related manuscript reddi conducts detailed experiments demonstrate ﬁxed increasing setting power distance correlation decay polynomially high dimensions fair alternatives. authors provide initial insights phenomenon speciﬁc examples still theoretical analysis power alternatives high dimensional setting. another statistic called energy distance sz´ekely rizzo closely tied indeed form euclidean distance instead kernel; lyons showed also metrics instead euclidean distance sejdinovic showed close metrics kernels problems. initial attempt characterize properties distance correlation high dimensions sz´ekely rizzo analysis power available easily derivable. also exist many tests like cross-match test rosenbaum none analyzed ﬁrst review basic argument gretton showing power ﬁxed dimensional setting. become clear main diﬃculties establishing results high-dimensional setting. increasing setting limiting distribution longer trivially normal needs establish conditions indeed normal important question rate convergence normality depends k-th central moments coordinate exist note coordinates need independent ex∼p ey∼q denote denote second third fourth central moments i.i.d. coordinate remember denote second third fourth central moments represent euclidean norm. main alternatives surprising interesting case gaussian kernel msa. discussed later theorem applies bandwidth chosen so-called median heuristic; sch¨olkopf smola implies median heuristic provides arguably safe choice light information also works reasonably well practice/simulations. assumptions general enough predictions made theorem accurate representative observed behavior. verify predictions theorem corollaries simulations. coordinates need independent ﬁrst assumption restrict covariances note sz´ekely rizzo makes restrictive assumption independent coordinates assumption saranadasa chen assume model don’t require spherical covariance. however assumption truly mathematical convenience; instead diagonal rescaling calculations still carried would tedious since coordinates still independent identically distributed would need track existence third fourth moments needed calculating population variance terms well berry-esseen lemma control deviation normality convergence existence sixth moment needed bound taylor expansion residual term calculations. note needs existence eighth moments assume existence fourth moments chen assumption saranadasa restriction remember power independent bandwidth long allow control residual term taylor expansion gaussian kernel. however restrictive since smaller typically leads worse power. speciﬁcally note experiments reddi mean-shift alternatives show convincingly chosen constant power poor highest power occurs values hence choice covers reasonable choices bandwidth. furthermore popular methods bandwidth selection called median heuristic sch¨olkopf smola chooses bandwidth median distances pairs points. simple calculation shows believe mistake derivation chen applies small regime dictated describe detail appendix section summarize corrected resulting observation below. comparing expressions corollary clear advantage mmdl low-snr setting. example constant power times faster mmdl power increase methods scales fashion. advantage might wiped considering ascertaining case important direction future work. split proof four subsections challenges need calculate ﬁrst moments introduced main tool taylor expansions following results follow sequence tedious calculations detailed book-keeping. need bound third fourth moments main tool used berry-esseen theorem helps track deviation normality ﬁnite samples tackled chebyshev’s inequality handle variance details deferred appendix outline main steps derivations here. proof. defer details appendix section using taylor’s expansion gaussian kernel terms aforementioned expression approximated bounding higher order residual terms. prove ﬁrst term central moment absolute value sign. given mean second central moment might imagine using similar techniques calculate however absolute value poses problem must take alternate route. speciﬁcally tedious calculations appendix section prove bounded section conﬁrm theoretical predictions made lemmas theorems. important claims address berry-esseen bound independent null alternate distributions indeed normal even extreme case ﬁxed increasing ratio mmd/ independent bandwidth ﬁnally ﬁnal power expression independent bandwidth exact predicted scaling given expressions. since calculations rather tedious also verify prediction made subsection constant independent dimension verify this draw samples calculate empirical ratio ranging steps make sets choices standard normals distribution distribution reason ﬁnite fourth moment cases ratio constant showing prediction extremely accurate. also proof proceeded bounding seems hold true even higher moments don’t exist since holds distribution. spikes calculate single empirical ratio calculating test statistic experimentally approximate null alternate distributions repeating process times; histogram obtained compared normal plotting standard normal quantile-quantile plot. overlapping straight lines indicate null alternate distributions almost exactly standard normal even small value like agrees derivation berry-esseen constant small normality achieved soon. ﬁrst lemmas together imply ratio mmd/ independent long test this actually calculate ratio remember lastly minimax lower bounds required understand tradeoﬀs involved", "year": 2014}