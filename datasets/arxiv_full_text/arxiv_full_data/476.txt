{"title": "Neural Models for Key Phrase Detection and Question Generation", "tag": ["cs.CL", "cs.AI", "cs.NE"], "abstract": "We propose a two-stage neural model to tackle question generation from documents. Our model first estimates the probability that word sequences in a document compose \"interesting\" answers using a neural model trained on a question-answering corpus. We thus take a data-driven approach to interestingness. Predicted key phrases then act as target answers that condition a sequence-to-sequence question generation model with a copy mechanism. Empirically, our neural key phrase detection model significantly outperforms an entity-tagging baseline system and existing rule-based approaches. We demonstrate that the question generator formulates good quality natural language questions from extracted key phrases, and a human study indicates that our system's generated question-answer pairs are competitive with those of an earlier approach. We foresee our system being used in an educational setting to assess reading comprehension and also as a data augmentation technique for semi-supervised learning.", "text": "propose two-stage neural model tackle question generation documents. model ﬁrst estimates probability word sequences document compose interesting answers using neural model trained questionanswering corpus. thus take data-driven approach interestingness. predicted phrases target answers condition sequence-tosequence question generation model copy mechanism. empirically neural phrase detection model signiﬁcantly outperforms entity-tagging baseline system existing rule-based approaches. demonstrate question generator formulates good quality natural language questions extracted phrases human study indicates system’s generated questionanswer pairs competitive earlier approach. foresee system used educational setting assess reading comprehension also data augmentation technique semi-supervised learning. many educational applications beneﬁt automatic question generation including vocabulary assessment brown frishkoff eskenazi writing support calvo assessment reading comprehension mitkov kunichika formulating questions test certain skills certain levels requires signiﬁcant human effort difﬁcult scale e.g. massive open online courses despite applications majority existing models automatic question generation rely rule-based methods likewise scale well across different domains and/or writing styles. address limitation propose compare several neural models automatic question generation. focus speciﬁcally assessment reading comprehension. domain question generation typically involves inter-related components ﬁrst system identify interesting entities events within passage document becker basu vanderwende second question generator constructs questions natural language speciﬁcally given phrases. phrases thus correct answers generated questions. procedure ensures assess student’s performance ground-truth target. formulate phrase detection modeling probability potential answers conditioned given document i.e. inspired successful work question answering propose sequence-to-sequence model generates key-phrase boundaries. model ﬂexibly select arbitrary number phrases document. teach assign high probability interesting answers train human-selected answers large-scale crowd-sourced question-answering datasets. thus take purely data-driven approach concept interestingness working premise crowdworkers tend select entities events interest formulate comprehension questions. premise correct growing collection crowd-sourced question-answering datasets rajpurkar trischler harnessed learn models phrases interest human readers. given extracted phrases approach question generation modeling conditional probability question given document-answer pair i.e. sequenceto-sequence model attention bahdanau bengio pointer-softmax mechanism gulcehre component also trained dataset maximizing likelihood questions dataset. empirically proposed model phrase detection outperforms baseline systems signiﬁcant margin. support quantitative ﬁndings qualitative examples generated question-answer pairs given documents. automatic question generation systems often used alleviate burden human generation questions assess reading comprehension mitkov kunichika various techniques adopted systems improve generation quality including parsing heilman smith mitkov semantic role labeling lindberg lexicographic resources like wordnet miller mitkov however majority proposed methods resort simple rule-based techniques slot-ﬁlling templates lindberg chali golestanirad labutov basu vanderwende syntactic transformation heuristics agarwal mannem chali hasan techniques inadequate capture diversity natural language questions. address limitation end-to-end-trainable neural models recently proposed question generation vision mostafazadeh language. latter shao cardie used sequence-to-sequence model attention mechanism derived encoder states. yuan proposed similar architecture addition improved model performance policy gradient techniques. wang yuan trischler proposed generative model learns jointly generate questions answers based documents. meanwhile highly relevant aspect question generation identify parts given document important interesting asking questions. existing studies formulate phrase extraction two-step process. ﬁrst step lexical features used extract phrase candidate list certain types wang zhao huang nguyen shimazu yang second step ranking models often used select phrase. medelyan frank witten; lopez romary used bagged decision trees lopez romary used multi-layer perceptron support vector machine label candidates binary fashion. mihalcea tarau; xiao; nguyen shimazu scored phrases using pagerank. heilman smith asked crowdworkers rate acceptability computer-generated natural language questions quiz questions becker basu vanderwende solicited quality ratings text chunks potential gaps clozestyle questions. studies closely related proposed work common goal modeling distribution phrases given document. major difference previous studies begin prescribed list candidates might signiﬁcantly bias distribution estimate. contrast adopt dataset originally designed question answering crowdworkers presumably tend pick entities events interest most. postulate resulting distribution learned directly data likely reﬂect true importance appropriateness answers. recently meng proposed generative model phrase prediction encoderdecoder framework able generate words vocabulary point words document. model achieved state-of-the-art results multiple scientiﬁc publication keyword extraction datasets. model shares similar ideas phrase extractor i.e. using single neural model learn probabilities words phrases. yang used rule-based method extract potential answers unlabeled text generated questions given documents extracted answers using pre-trained question generation model combined model-generated questions human-generated questions training question answering models. experiments showed question answering models beneﬁt augmented data provided approach. baseline model predicts entities tagged spacy phrases. motivated fact answers squad entities include dates numeric entities people locations entities baseline model na¨ıvely selects entities candidate answers. pitfall exhibits high recall expense precision ﬁrst attempt address neural entity selection model selects subset entities list candidates. neural entity selection model takes document list entities sequence locations within document model trained binary classiﬁcation task parameterize using neural model document distributed vector using word embedding lookup ﬁrst embeds word table. encode document using bidirectional long short-term memory net). compute using three-layer multiwork annotation vectors here layer perceptron takes input concatenation three vectors average ﬁnal state annotation vectors respectively average annotation vectors corresponding i-th entity trained point sequentially start locations phrase answers. entity selection model ﬁrst encode document sequence annotation vectors decoder lstm trained point start locations answers document left right conditioned annotation vectors attention mechanism. special termination token document decoder trained attend generated phrases. provides ﬂexibility learn number phrases model extract particular document. contrast work meng ﬁxed number phrases generated document. pointer network extension sequence-to-sequence models sutskever vinyals target sequence consists positions source sequence. encode source sequence document sequence annotation vectors using embedding lookup table followed bidirectional lstm. decoder also consists embedding lookup shared encoder followed unidirectional lstm attention mechanism. denote decoder’s annotation vectors number answer phrases correspond start annotation vectors ﬁrst answer phrase parameterize using product attention mechanism luong pham manning decoder encoder annotation vectors afﬁne transformation matrix. inputs step decoder words document correspond start locations pointed decoder. inference employ decoding strategy greedily picks best location softmax vector every step post process results remove duplicate phrases. since output sequence relatively small observed similar performances using greedy decoding beam search. question generation model adopts sequence-to-sequence framework sutskever vinyals attention mechanism bahdanau bengio pointersoftmax decoder gulcehre takes document answer captured ﬁnal states bilstm character sequences concatenated embeddings subsequently encoded another bilstm annotation vectors take better advantage extractive nature answers documents encode answer extracting document encodings answer word positions. speciﬁcally encode hidden states document correspond answer phrase another condition aggregation bilstm. ﬁnal state encoding answer. decoder employs pointer-softmax module gulcehre step question generation process decoder decides adaptively whether generate decoder vocabulary point word source sequence pointer-softmax decoder thus components pointer attention mechanism generative decoder. pointing decoder recurrence implemented cascading lstm cells ﬁrst layers tanh activation ﬁnal layer uses sigmoid. highway connections present ﬁrst second layer. finally resulting switch used interpolate pointing generative probabilities predicting next word conduct experiments squad rajpurkar newsqa trischler corpora. machine comprehension datasets consisting crowdsourced question-answer pairs. squad contains paragraphs wikipedia newsqa created news articles. simple preprocessing performed including lower-casing word tokenization using nltk. test split squad hidden public therefore take question-answer pairs training validation ofﬁcial development data report test results. newsqa evaluate phrase detection models transfer setting. also attach entropy softmax distributions input ﬁnal layer postulating guides switching mechanism indicating conﬁdence pointing generating. observed improvement question quality technique. figure comparison phrase extraction methods. phrases extracted pointer network violet green baseline brown correspond squad gold answers cyan indicates overlap pointer model squad gold questions. last paragraph exception lyndon johnson april extracted well baseline model. phrase detection models used pretrained word embeddings dimensions generated using wordvec extension ling trained english gigaword corpus. used bidirectional lstms dimensions encode document lstm dimensions decoder pointer network model. dropout used outputs every layer network. question generation decoder vocabulary uses words sorted frequency gold questions training data. word embedding matrix initialized dimensional glove vectors pennington socher manning dimensionality character representations number hidden units encoder/decoder cells. dropout applied rate embedding layers well hidden states encoder/decoder rnns across time steps. since phrase multi-word unit believe nai¨ve word-level considers entire phrase single unit well suited evaluate models. thus propose extension squad evaluation metric multiple spans within document called multi-span score. metric calculated follows. given predicted phrase gold phrase ﬁrst construct pairwise token-level score matrix elements phrases max-pooling along gold-label axis essentially assesses precision prediction partial matches accounted pair-wise cells maxj. analogously recall label deﬁned maxpooling along prediction axis maxi. multi-span score deﬁned existing evaluations seen computation performed matrix exact match scores predicted gold phrases. using token-level scores phrase pairs allow fuzzy matches. phrase extraction fairly well deﬁned quantitative evaluation metric evaluating generated text question generation harder problem. instead using automatic evaluation metrics bleu rouge meteor cider performed human evaluation generated questions conjunction answer phrases. used different evaluation approaches ambitious compares generated question-answer pairs human generated ones squad another compares model heilman smith comparison human generated questions presented annotators documents squad ofﬁcial development sets question-answer pairs model squad annotators tasked identifying question-answer pairs machine generated. order questionanswer pairs appear example randomized. annotators free criterion choice make distinction poor grammar answer phrase correctly answering generated question uninteresting answer phrases etc. implict comparison compare system existing methods human generated squad question-answer pairs setup implict comparison. human annotators presented document question-answer pairs comes squad ofﬁcial development another either system annotators made aware fact different models generating pairs. annotators tasked identifying pair human generated. evaluate accuracy annotators distinguish human machine using models. comparison direct evaluation strategy present annotators documents squad ofﬁcial development instead human generated question-answer pair generated model ours. annotators prefer. evaluation phrase extraction systems presented table compare answer phrases extracted baseline entity tagger neural entity selection module pointer network. expected entity tagging baseline achieved best recall likely overgenerating candidate answers. model hand exhibits much larger advantage precision consequently outperforms entity tagging baseline notable margins trend persists comparison model pointer-network model. model exhibits high recall lacks precision similar baseline entity tagger. surprising since model hasn’t exposed squad answer phrase distribution. qualitatively observe entity-based models strong bias towards numeric types often fail capture interesting information article. addition also notice entity-based systems tend select central topical entity answer contradict distribution interesting answers selected humans. example given wikipedia article kenya fact agriculture second largest contributor kenya gross domestic product entity-based systems propose kenya phrase country nigeria second largest contributor given information pointer model picked agriculture answer asked second largest contributor kenya gross domestic product qualitative results question generation phrase extraction modules presented table contrast system human generated pairs squad. phrases selected model appear different ptrnet human generated ones; example start prepositions large noun-phrases student motivation attitudes towards school closely linked student-teacher relationships. addition phrases seen figure seem interesting appear contain somewhat arbitrary phrases this theory some studies person etc. question generation module appears produce ungrammatical sentences ﬁrst time yuan dynasty non-native chinese people ruled china system since phrase extraction module trained squad selected phrases closely resemble gold squad answers. however answers don’t answer questions generated them eicosanoids cytokines bacteria produced model sometimes able effectively parse coreferent entities. generate mongol empire yuan dynasty considered continuation model resolve pronoun yuan dynasty generally considered continuation mongol empire comparison human generated questions presented annotators total documents containing question-answer pairs. observed annotators able identify machine generated question-answer pairs time standard deviation implict comparison presented annotators documents come model examples paired squad gold questions answers. ﬁrst annotator labeled correctly gold labeled correctly gold; second annotator labeled correctly gold labeled correctly gold. neither annotators substantial prior knowledge squad dataset. experiment shows annotator harder time distinguishing generated question-answer pairs gold gold. comparison presented annotators examples contains document question-answer pairs generated model h&s’s model. ﬁrst annotator chose question-answer pairs generated model preferred choice second annotator chose model. experiment shows that without given ground truth question-answer pairs humans consider models’ outputs equally good. proposed two-stage framework tackle problem question generation documents. first question answering corpus train neural model estimate distribution phrases interesting question-asking humans. proposed neural models ranks entities proposed entity tagging system another points key-phrase start boundaries pointer network. compared entity tagging baseline proposed models exhibit signiﬁcantly better results. adopt sequence-to-sequence model generate questions conditioned phrases selected framework’s ﬁrst stage. question generator inspired attention-based translation model uses pointer-softmax mechanism dynamically switch copying word document generating word vocabulary. qualitative examples show generated questions exhibit syntactic ﬂuency semantic relevance conditioning documents answers appear useful assessing reading comprehension educational settings. references agarwal mannem automatic gap-ﬁll question generation text books. proceedings workshop innovative building educational applications association computational linguistics. becker basu vanderwende mind learning choose gaps question generation. proceedings conference north american chapter association computational linguistics human language technologies association computational linguistics. brown frishkoff eskenazi automatic question generation vocabulary assessment. proceedings conference human language technology empirical methods natural language processing association computational linguistics. heilman smith good question statistical ranking question generation. human language technologies annual conference north american chapter association computational linguistics association computational linguistics. heilman smith rating computer-generated questions mechanical turk. proceedings naacl workshop creating speech language data amazon’s mechanical turk association computational linguistics. meng zhao brusilovsky deep keyphrase generation. annual meeting association computational linguistics. association computational linguistics. mitkov computer-aided generation multiple-choice tests. proceedings hlt-naacl workshop building educational applications using natural language processing-volume association computational linguistics. yang salakhutdinov cohen semi-supervised generative domain-adaptive nets. annual meeting association computational linguistics. association computational linguistics. yuan wang gulcehre sordoni bachman subramanian zhang trischler machine comprehension text-to-text neural question generation. workshop representation learning nlp. inﬂammation ﬁrst responses immune system infection symptoms inﬂammation redness swelling heat pain caused increased blood tissue inﬂammation produced eicosanoids cytokines released injured infected cells eicosanoids include prostaglandins produce fever dilation blood vessels associated inﬂammation leukotrienes attract certain white blood cells research shows student motivation attitudes towards school closely linked student-teacher relationships enthusiastic teachers particularly good creating beneﬁcial relations students ability create effective learning environments foster student achievement depends kind relationship build students useful teacher-to-student interactions crucial linking academic success personal achievement personal success student internal goal improving whereas academic success includes goals receives superior teacher must guide student aligning personal goals academic goals students receive positive inﬂuence show stronger self-conﬁdenche greater personal academic success without teacher interactions research shows student motivation attitudes towards school closely linked studentteacher relationships student-teacher relationships research show student motivation attitudes towards school closely linked useful teacher-to-student interactions crucial linking academic success personal achievement student motivation attitudes towards school closely linked student-teacher relationships research show student-teacher relationships student motivation attitudes towards school closely linked teacher-to-student interactions crucial linking academic success personal achievement beneﬁcial type relationships enthusiastic teachers cause student motivation attitudes towards school strongly linked good student-teacher relationships yuan dynasty ﬁrst time non-native chinese people ruled china historiography mongolia generally considered continuation mongol empire mongols widely known worship eternal heaven july walt disney company announced agreement merge capital cities/abc billion premiered aaron sorkin-created sitcom sports night centering travails staff sportscenter-style sports news program despite earning critical praise multiple emmy awards series cancelled seasons", "year": 2017}