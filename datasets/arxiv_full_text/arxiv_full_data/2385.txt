{"title": "Efficient Learning in Large-Scale Combinatorial Semi-Bandits", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "A stochastic combinatorial semi-bandit is an online learning problem where at each step a learning agent chooses a subset of ground items subject to combinatorial constraints, and then observes stochastic weights of these items and receives their sum as a payoff. In this paper, we consider efficient learning in large-scale combinatorial semi-bandits with linear generalization, and as a solution, propose two learning algorithms called Combinatorial Linear Thompson Sampling (CombLinTS) and Combinatorial Linear UCB (CombLinUCB). Both algorithms are computationally efficient as long as the offline version of the combinatorial problem can be solved efficiently. We establish that CombLinTS and CombLinUCB are also provably statistically efficient under reasonable assumptions, by developing regret bounds that are independent of the problem scale (number of items) and sublinear in time. We also evaluate CombLinTS on a variety of problems with thousands of items. Our experiment results demonstrate that CombLinTS is scalable, robust to the choice of algorithm parameters, and significantly outperforms the best of our baselines.", "text": "subject combinatorial constraints. many important problems minimum spanning tree shortest path maximum-weight bipartite matching viewed instances problem. practice optimized modular function often unknown needs learned repeatedly solving problem. class learning problems recently formulated combinatorial bandit/semi-bandit depending feedback model since then many combinatorial bandit/semi-bandit algorithms proposed stochastic setting adversarial setting subclasses combinatorial problems matroid polymatroid bandits submodular maximization cascading bandits many regret bounds established combinatorial semi√ bandit algorithms. achieve dependence time regret bounds number items. dependence intrinsic because algorithms estimate weight item separately matching lower bounds established however many real-world problems number items intractably large. instance online advertising mainstream commercial website viewed bipartite matching problem millions users products; routing internet formulated shortest path problem billions edges. thus learning algol) regret impractical problems. rithms combinatorial linear algorithms computationally efﬁcient long ofﬂine version combinatorial problem solved efﬁciently. establish comblints comblinucb also provably statistically efﬁcient reasonable assumptions developing regret bounds independent problem scale sublinear time. also evaluate comblints variety problems thousands items. experiment results demonstrate comblints scalable robust choice algorithm parameters signiﬁcantly outperforms best baselines. combinatorial optimization mature ﬁeld countless practical applications. studied problems combinatorial optimization maximization modular function ture learn make good decisions efﬁciently. speciﬁcally assume linear generalization across items conditioned features item expected weight item estimated using linear model. goal develop efﬁcient learning algorithms combinatorial semi-bandits linear generalization. relatively easy extend many linear bandit algorithms thompson sampling linear dani abbasicombinatorial semi-bandits yadkori linear generalization. paper propose learning algorithms combinatorial linear thompson sampling combinatorial linear based thompson sampling linucb. comblints comblinucb computationally efﬁcient long ofﬂine version combinatorial problem solved efﬁciently. ﬁrst major contribution paper establish bayes regret bound comblints regret bound comblinucb reasonable assumptions. bounds l-independent sublinear time. second major contribution paper evaluate comblints variety problems thousands items problems based real-world datasets. evaluate comblints since recent literature suggests thompson sampling algorithms usually outperform ucb-like algorithms practice. experimental results demonstrate comblints scalable robust choice algorithm parameters signiﬁcantly outperforms best baselines. worth mentioning derived l-independent regret bounds also hold cases moreover discuss section proposed algorithms analyses easily extended contextual combinatorial semibandits. finally brieﬂy review relevant papers. gabillon guestrin focus submodular maximization linear generalization. paper differs papers following aspects paper allows general combinatorial constraints not; paper focuses maximization modular functions focus submodular maximization. focus class combinatorial optimization problems maximum-weight given family sets. speciﬁcally combinatorial optimization problem represented triple items called ground family many classical combinatorial optimization problems ﬁnding bipartite matching shortest path problem traveling salesman problem form though problems solved efﬁciently others known np-hard. however many nphard problems exist computationally efﬁcient approximation algorithms and/or randomized algorithms achieve near-optimal solutions high probability. similarly chen paper allow agent approximation randomized algorithm oracle solve denote solution oracle. distinguish learning algorithm refer combinatorial optimization algorithm oracle paper. many real-world problems combinatorial nature. recommender systems instance user typically recommended items value item expected rating movie never known perfectly reﬁned repeatedly recommending pool users. recommender problems known highly structured. particular well known user-item matrix typically low-rank value item written linear combination position latent space. work propose learning algorithm combinatorial optimization leverages structure. particular assume weight item linear function features learn parameters model jointly items. formalize learning problem combinatorial semi-bandit. combinatorial semi-bandit triple deﬁned section probability distribution weights items ground assume weights drawn i.i.d. mean weight denoted paper assume linear generalization model across items. speciﬁcally assume agent knows generalization matrix rl×d s.t. either lies close subspace span denote transpose e-th refer feature vector item without loss generality assume rank similar distinguish between coherent learning cases span agnostic learning cases span like existing literature linear bandits analysis paper focuses coherent learning cases. however would like emphasize proposed algorithms comblints comblinucb also applicable agnostic learning cases. demonstrated section comblints performs well agnostic learning cases. finally deﬁne since rank uniquely deﬁned. moreover coherent learning cases φθ∗. performance metrics oracle. paper measure performance loss learning algorithm respect recall learning algorithm chooses episode deﬁne realized regret episode expected weight ﬁxed unknown deﬁne expected cumulative regret learning algorithm episodes expectation random weights possible randomization learning algorithm. necessary denote emphasize dependence hand randomly generated agent prior belief russo bayes cumulative regret learning algorithm episodes deﬁned item associated assume multiple arms pulled. subset arms pulled return pulling arms weights items arms pulled observe individual return feedback model known semi-bandit combinatorial structure assume known distribution unknown. would like stress make structural assumptions optimal solution problem maximumweight expectation aopt learning problem episodic. episode learning agent adaptively chooses based observations weights episode gains observes weights chosen items episode at}. learning agent interacts combinatorial semi-bandit times goal maximize expected cumulative return n-episodes expectation random weights wt’s possible randomization learning algorithm randomly generated. notice choice impacts return observations episode need trade exploration exploitation similarly bandit problems. discussed section many provably efﬁcient algorithms developed various combinatorial semi-bandits form however since parameters learn algorithms consider generalization across items derived upper bounds expected cumulative regret and/or bayes cumulative regret algorithms furthermore audibert least lower bound adversarial combinatorial semi-bandits kveton derived asymptotic ω/∆) gap-dependent lower bound stochastic combinatorial semi-bandits gap. respectively motivated thompson sampling linucb. algorithms maintain mean vector covariance matrix kalman ﬁltering update differ choose episode comblints chooses based randomly sampled coefﬁcient vector comblinucb chooses based optimism face uncertainty principle. psuedocode comblints given algorithm combinatorial structure generalization matrix oracle combinatorial optimization algorithm algorithm parameters controlling learning rate. speciﬁcally inverseregularization parameter smaller makes covariance matrix closer thus small lead insufﬁcient exploration signiﬁcantly reduce performance comblints. hand controls decrease rate covariance matrix particular large lead slow learning small make algorithm quickly converge sub-optimal coefﬁcient vector. episode algorithm consists three steps. first randomly samples coefﬁcient vector gaussian distribution. second computes based pre-speciﬁed oracle. finally updates mean vector ¯θt+ covariance matrix based kalman ﬁltering worth pointing prior noise independently sampled episode comblints algorithm samples posterior distribution henceforth refer case satisfying condition coherent gaussian case. obviously comblints algorithm applied general cases even cases prior and/or agnostic learning cases. pseudocode comblinucb given algorithm oracle deﬁned algorithm three algorithm parameters. similarly inverse-regularization parameter controls decrease rate covariance matrix controls degree optimism speciﬁcally small algorithm might converge suboptimal coefﬁcient vector insufﬁcient exploration; hand large lead excessive exploration slow learning. episode algorithm also consists three steps. first computes upper conﬁdence bound ˆwt. second computes based pre-speciﬁed oracle. finally updates ¯θt+ based kalman ﬁltering section present bayes regret bound comblints regret bound comblinucb. also brieﬂy discuss bounds derived well tightness. detailed proofs left appendices. without loss generality throughout section assume notice condition ensure coherent gaussian case condition almost always holds. notation hides logarithm factors. also note equation minimum bounds. ﬁrst bound outline proof theorem motivated russo dani denote history start episode note bayesian perspective conditioning i.i.d. drawn conditioning posterior belief based algorithm independently sampled since oracle ﬁxed combinatorial optimization algorithm ﬁxed conditioning also i.i.d. furthermore conditionally independent conditionally independent simplify exposition deﬁne bound rbayes thompson sampling applied audibert provides lower bound. since results indicate general best upper bound kdn). hence bound hope factor linear generalization discussed appendix extra factor section evaluate comblints three problems. ﬁrst problem synthetic last problems constructed based real-world datasets. discussed section evaluate comblints since practice thompson sampling algorithms usually outperform ucb-like algorithms. experiment results synthetic problem demonstrate comblints scalable robust choice algorithm parameters. also suggest bayes regret bound derived theorem likely tight. hand experiment results last problems show value linear generalization real-world settings domainspeciﬁc imperfect linear generalization comblints signiﬁcantly outperform stateof-the-art learning algorithms exploit linear generalization serve baselines problems. three problems oracle oracle exactly solves ofﬂine combinatorial optimization problem. moreover real-world problems demonstrate experiment results using performance metric expected per-step return episodes deﬁned obviously expected cumulative return episodes divided demonstrate experiment results using expected cumulative return rather since illustrative. ﬁrst evaluate comblints synthetic problem. speciﬁcally experiment stochastic longest path problem square grid. items ground edges grid total. feasible paths grid upper left corner bottom right corner follow directions edges. length paths problem focus coherent gaussian cases randomly sample linear generalization matrix rl×d weaken dependence particular choice sextuple deﬁned λtrue σtrue respectively true standard deviations observation noises. round simulation ﬁrst construct problem instance follows generate sampling component i.i.d. sample indeassumptions support subset stochastic item weights {w}e∈e statistically independent oracle oracle exactly solves ofﬂine optimization problem following upper bound comblinucb applied coherent learning cases theorem satisfying generally speaking proof theorem proceeds follows. ﬁrst construct conﬁdence based self normalized bound developed abbasi-yadkori decompose regret high-probability good event low-probability event complement finally bound term associated event based worst-case σtφe used analysis comblints bound term associated event based naive bound. please refer appendix detailed proof theorem notice choose lower bound speciﬁed inequality regret bound derived theorem also compared lower bound derived audibert bound larger. similarly extra factors also linear generalization. finally would like clarify assumption support bounded essential. slightly modifying analysis achieve similar highprobability bound realized cumulative regret long sub-gaussian. also want point lindependent bounds derived theorem still hold even second study bayes cumulative regret comblints scales dimension feature vectors varying demonstrate result figure experiment results indicate rbayes also roughly increases linearly hence comblints also scalable feature dimension result also suggests bound theorem tight. finally study robustness comblints respect algorithm parameters figure vary figure vary would like emphasize vary algorithm parameters σtrue λtrue experiment results show comblints robust choice algorithm parameters performs well wide range however small large small signiﬁcantly reduce performance comblints discussed section second experiment evaluate comblints advertising problem. objective identify people likely accept advertisement offer subject targeting constraint exactly half females. speciﬁcally ground includes representative people adult dataset collected census. feasible solution subset satisfying targeting constraint mentioned above. assume person accepts advertisement offer probability people accept offers independently other. features generalization matrix binned groups; gender; whether person works hours week; length education years. features constructed based adult dataset. comblints compared three baselines. ﬁrst baseline optimal solution aopt. second baseline easily extended cases maxe∈e scaling bayes regret bound however problem bounded since sampled gaussian distribution. believe theorem extended case exploiting properties gaussian distribution. roughly speaking problem high probability φθ∗; pendently observation noise i.i.d. true). apply comblints sampled constructed instance episodes. notice general average experiment results simulations estimate bayes cumulative regret rbayes. start default case λtrue σtrue notice case choose since default case bayes per-episode regret comblints vanishes period default case rbayes experiments vary parameter keeping parameters ﬁxed default values speciﬁed demonstrate scalability robustness comblints. first study bayes cumulative regret comblints scales size problem varying show result figure experiment results show rbayes roughly increases linearly indicates comblints scalable respect problem size also experiment case rbayes times rbayes default case. worth mentioning result also suggests bayes regret bound derived theorem tight problem. notice recall theorem requires maxe∈e combucb algorithm estimates probability person accepts offer independently probabilities. third baseline comblints without linear generalization simply refer combts. combucb algorithm estimates probability person accepts offer independently probabilities. posterior modeled beta distribution. experiment results reported figure observe major trends. first comblints learns extremely quickly. particular per-step return episode optimum per-step return episode optimum. results remarkable since linear generalization imperfect problem. second combucb combts perform poorly insufﬁcient observations respect model complexity. speciﬁcally episodes people observed times implies person observed times average. enough discriminate people likely accept advertisement offer not. last experiment evaluate comblints problem recommending music artists likely chosen average user music recommendation website. speciﬁcally ground include artists last.fm music recommendation dataset dataset contains tagging music artist listening information users last.fm online music system. tagging part includes assignments artists provided users. user artists listened number listening events also available dataset. choose artists listened least users least assignment among popular tags artist construct feature vector setting component fraction users assigned artist. assume artist chosen average user probability |ue| users listened artist probability user likes artist esti¯ mate based na¨ıve bayes classiﬁer respect number person/artist listening events. like section also compare comblints three baselines optimal solution aopt combucb algorithm combts algorithm. experiment results reported figure similarly figure expected per-step return comblints approaches aopt much faster combucb combts. moreover combucb combts perform poorly insufﬁcient observations respect model complexity episodes artist observed less times average enough discriminate popular artists less popular artists. proposed learning algorithms comblints comblinucb stochastic combinatorial semibandits linear generalization. main contribution work two-fold first established lindependent regret bounds algorithms reasonable assumptions number items. second also evaluated comblints variety problems. experiment results ﬁrst problem show comblints scalable robust experiment results problems demonstrate value exploiting linear generalization real-world settings. tended contextual combinatorial semi-bandits linear generalization. contextual combinatorial semibandit probability distribution also depends context either follows exogenous stochastic process adaptively chosen adversary. assume state-item pair associated feature vector similar agrawal goyal comblints comblinucb well analyses generalized contextual combinatorial semi-bandits. leave open several questions interest. interesting open question derive regret bounds comblints comblinucb agnostic learning cases. another interesting open question extend results combinatorial semi-bandits nonlinear generalization. believe results extended combinatorial semi-bandits generalized linear generalization leave future work. references abbasi-yadkori yasin p´al d´avid szepesv´ari csaba. improved algorithms linear stochastic bandits. advances neural information processing systems agrawal shipra goyal navin. analysis thompson sampling multi-armed bandit problem. colt annual conference learning theory june edinburgh scotland agrawal shipra goyal navin. thompson sampling contextual bandits linear payoffs. proceedings international conference machine learning icml atlanta june chen wang yajun yuan yang. combinatorial multi-armed bandit general framework applications. proceedings international conference machine learning gabillon victor kveton branislav zheng eriksson brian muthukrishnan adaptive submodular maximization bandit setting. advances neural information processing systems gabillon victor kveton branislav zheng eriksson brian muthukrishnan large-scale optimistic adaptive submodularity. proceedings aaai conference artiﬁcial intelligence krishnamachari bhaskar jain rahul. combinatorial network optimization unknown variables multi-armed bandits linear rewards individual observations. ieee/acm transactions networking kveton branislav zheng ashkan azin eydgahi hoda eriksson brian. matroid bandits fast combinatorial optimization learning. proceedings conference uncertainty artiﬁcial intelligence gergely bart´ok g´abor. efﬁcient algorithm jain sanlearning semi-bandit feedback. munos r´emi stephan frank zeugmann thomas algorithmic learning theory volume lecture notes computer science springer berlin heidelberg isbn ---. zheng kveton branislav eriksson brian bhamidipati sandilya. sequential bayesian search. proceedings international conference machine learning outline proof theorem based denote history start episode note bayesian perspective conditioning i.i.d. drawn conditioning posterior belief based algorithm independently sampled since oracle ﬁxed combinatorial optimization algorithm ﬁxed conditioning also i.i.d. furthermore conditionally independent conditionally independent simplify exposition deﬁne interested readers might refer appendix derivation equation proof proceeds follows. ﬁrst construct conﬁdence based self normalized bound developed derive regret bound based lemma derived above. observation ηtk’s form martingale difference sequence since statistically independent moreover since bounded interval ηtk’s sub-gaussian constant deﬁne suitably redeﬁning realized regret prove variant theorem oracle approximation algorithm. speciﬁcally algorithm oracle solution oracle optimization problem sub-optimality oracle assumptions support subset item weight statistically independent oracle oracle sub-optimality following variant theorem comblinucb applied coherent learning cases theorem satisfying", "year": 2014}