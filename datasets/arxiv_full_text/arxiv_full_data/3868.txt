{"title": "JamBot: Music Theory Aware Chord Based Generation of Polyphonic Music  with LSTMs", "tag": ["cs.SD", "cs.AI", "cs.IT", "cs.LG", "eess.AS", "math.IT", "stat.ML", "I.2.1; I.2.4; I.2.6; H.5.5"], "abstract": "We propose a novel approach for the generation of polyphonic music based on LSTMs. We generate music in two steps. First, a chord LSTM predicts a chord progression based on a chord embedding. A second LSTM then generates polyphonic music from the predicted chord progression. The generated music sounds pleasing and harmonic, with only few dissonant notes. It has clear long-term structure that is similar to what a musician would play during a jam session. We show that our approach is sensible from a music theory perspective by evaluating the learned chord embeddings. Surprisingly, our simple model managed to extract the circle of fifths, an important tool in music theory, from the dataset.", "text": "abstract— propose novel approach generation polyphonic music based lstms. generate music steps. first chord lstm predicts chord progression based chord embedding. second lstm generates polyphonic music predicted chord progression. generated music sounds pleasing harmonic dissonant notes. clear long-term structure similar musician would play session. show approach sensible music theory perspective evaluating learned chord embeddings. surprisingly simple model managed extract circle ﬁfths important tool music theory dataset. robocop ghost shell titanfall popular culture seems believe robots mechanically stronger quicker humans humans always outsmart robots; human mind robot body basically invincible. last years neural networks question doctrine. creative computing seemed reach long getting traction rise machine learning tools. recently neural networks writing novels style shakespeare turning photos paintings music believed closely connected feelings closer forms art. area music psychology seeks understand relationship music emotions. such music composition considered pinnacle understand machine creativity. work introduce jambot music theory aware system generation polyphonic music. early approaches mechanically compose music using recurrent neural networks decades also long short-term memory networks considered quite early early approaches however limited. recently models generate polyphonic harmonic sounding music proposed also models integrate concept chords monophonic melody predicted ﬁrst chord generated played melody. generally models chords melody separate entities even though chords melody usually strictly separated music. instead chords melody sides coin single notes chord played like melody notes melody form chord. contrast work jambot separate chords melody. predict chord progression ﬁrst structural guide music. since chord every time steps polyphonic model chord structures last longer time frame; possible lstm. chord structure polyphonic lstm generates actual music. contrast work polyphonic lstm free predict note chord notes. chords provided information lstm rule. model manages produce harmonic sounding music long time structure. trained midi music major/natural minor scales twelve keys model learns chord embedding corresponds strikingly well circle ﬁfths. thus lstm capable extracting important concept music theory data. neural networks used generate music decades. mozer used recurrent neural network produced pitch duration chord time step. approach however encoded principles music theory data representation. schmidhuber ﬁrst lstm. trained lstm repeat blues chord progression play melodies boulanger-lewandowski proposed model predicts polyphonic music distinction chords melodies since predicted music polyphonic form chords. resulting music sounds pleasing contains long term structure. since music samples short possible tell structure spans multiple bars. approaches create polyphonic music hadjeres create nice sounding bach chorales always exactly voices johnson generates pleasing sounding music also long term structure. recently approaches take chord progressions account. choi propose text based lstm learns relationships within text documents represent chord progressions. present hierarchical recurrent neural network ﬁrst monophonic melody generated based melody chords drums added. worth noting incorporates circle ﬁfths rule generating chord progressions whereas model able extract circle ﬁfths data. huang also experiment learning embeddings notes. visualized embeddings show model learned distinguish high pitches. oord created wavenet text-to-speech model based cnns trained audio data. show model also used generate music. mehri train hierarchical rnns audio data. since approaches audio data whereas midi ﬁles results directly comparable. generally systems midi ﬁles produce better sounding less noisy music. moreover training audio data requires computing power often infeasible current approaches. musical notation measure segment time corresponding speciﬁc number beats. beat corresponds note value. boundaries bars indicated vertical lines. most music beats long. temperament system tuning frequency interval every pair adjacent notes ratio. notes c♯/d♭ d♯/e♭ f♯/g♭ g♯/a♭ octave higher. cycle called octave. notes different octaves denoted number example sixth octave. natural minor scale different pitch intervals major scale natural minor scale root note contains exactly notes major scale root note call relative minor. chord notes played together. chords deﬁned like keys pitch intervals starting note. common types chords major chords minor chords. denote major chords capital starting note e.g. major chord. minor chords e.g. minor chord. circle ﬁfths shown figure relationship among notes associated major minor keys. geometrical representation notes helps musicians switch different keys develop chord progressions. choosing adjacent chords form chord progression often produces harmonic sounding music. train models used subset lakh midi dataset dataset contains approximately hundred thousand songs midi data format. midi ﬁles contain sounds rather series messages like note note change tempo. midi messages interpreted hardsoftware midi instrument produces sound. midi messages chord extraction order train chord lstm need extract chords songs. feasible determine chords manually automated process. compute histogram notes bar. three played notes make chord. length chosen usually popular music chords roughly change every bar. course approximation chord deﬁned music theory. consider chords three notes even though chords four notes. method might also detect note patterns chords music theoretical sense appear often real world music. example note note current chord played often chord notes detected chord might vary actual chord. table common chords extracted chord datasets seen. datasets common chords might expect large datasets music coincides therefore conclude chord extraction method plausible. sent different channels different sounding instruments assigned them. example channel represent piano channel corresponds guitar. midi ﬁles contain score song actual sound song usually takes much less storage space audio ﬁles also beneﬁcial training neural networks. since dataset smaller incorporate songs training. moreover simple change instrument music played. furthermore midi format already provides basic representation music whereas audio difﬁcult interpret humans well machine learning algorithms. scales keys analyze scales keys songs considered scale types major natural minor harmonic minor melodic minor blues scale. major scale relative natural minor scale contain notes root note different treat major/relative minor scale preprocessing. every scale start different root notes different possible keys. root notes scale types songs computed histogram twelve notes whole song. determine keys occurring notes histograms matched conﬁgurations. analyzing songs dataset shows songs major/relative minor scale harmonic minor blues scale melodic minor. remaining another scale change song scale could detected correctly method. changes song histogram method possibly detects neither key. also scale note played often song also detected correctly. simplify music generation task used songs major/minor scales training data since make data. additionally songs shifted root note corresponds constant shift notes song. call dataset shifted dataset models learn create music instead twelve keys. step taken avoid overﬁtting lack data key. generation transpose song simply adding constant shift notes. song sounds good also sound good keys. figure shows histogram notes shifted dataset. notice notes belong scale them. therefore simply ignoring notes belong scale solely predicting in-scale notes would make generated music simplistic. real music scale notes played e.g. create tension. range midi capacity different pitches figure shows high deep notes played often. lstm input sequences output sequences. memory cell network computes output four gates update gate input gate forget gate output gate. outputs gates hidden state computed function cell state output gate ﬁnally output computed output activation function output matrix wout multiplied hidden state architecture jambot. chords piano roll representations fig. extracted midi ﬁles training data extracted chords piano rolls used train chord polyphonic lstms music generation chord lstm generates chord progression used input polyphonic lstm generates music midi format. listening music freely vary tempo instrumentation. listen song dependencies song important. likewise read paper understand word based understanding context previous words. classical neural networks so-called multi layer perceptrons cannot well. recurrent neural networks proposed address issue however normal rnns usually capture short-term dependencies. order long-term dependencies generated music believed feature pleasing music lstm networks architecture designed improve upon introduction simple memory cells gating architecture. gates decide whether polyphonic lstm represent music data polyphonic lstm piano roll representation. every divided eight time steps. notes played time step represented vector. length vectors number notes. note played time step corresponding vector entry note played corresponding entry piano rolls songs created pretty midi library python. chord lstm represent chords song borrow technique natural language processing. machine learning applications deal language words often replaced integer word/id pairs stored dictionary. vocabulary size usually limited. occurring words corpus receive unique remaining words occur often enough algorithms learn anything meaningful them. rarely occurring words receive unknown tag. chord lstm technique. chords replaced chord/id pairs stored dictionary. chord lstm sees chords knowledge notes make chords. embedding layer embedded chords lstm hidden cells. output activation function softmax used. output lstm corresponds vector contains probabilities chords played next. training train chord lstm used crossentropy loss function adam optimizer. best initial learning rate found training data consists extracted chords songs shifted dataset. trained model data epochs. also trained second chord lstm extracted chords songs original unshifted dataset visualize embeddings learned. prediction predict chord progression ﬁrst feed seed variable length lstm. next chord predicted sampling output probability vector temperature. predicted chord lstm next chord sampled temperature temperature parameter controls divers generated chord progression temperature zero would mean given seed predicted chord progression would stay run. input input vector polyphonic lstm seen figure consists vectors piano rolls songs described section iv-a. additional features appended vectors. ﬁrst feature embedded chord next time step. embedding completely trained chord lstm described section iv-b. chord notes predicted given lstm learn notes usually played chords. predicted notes follow chord progression generated songs receive long term structure. music melodies often lead next chord. reason also append embedded vector chord follows chord next time step. lstm target melodies predicting music. cause generated songs structured. last feature appended simple binary counter counts every bar. helps lstm know time step many steps remain next chord change. make chord-transitions smoother. architecture input vectors lstm cells hidden layer. activation function output sigmoid. output lstm time poly seen figure vector number entries notes. every output vector entry probability corresponding note played next time step conditioned inputs time steps before. figure shows number occurrences unique chords shifted dataset. left frequent chord right least frequent one. even though different possible note combinations notes different combinations present shifted dataset. makes sense since random note combinations sound pleasing thus occur real music. seen chords played often number occurrences chords drops fast. based data vocabulary size chosen remaining chords received unknown tag. feed chord chord lstm encode vectors. one-hot encoding. input vectors size size chord vocabulary. vector entries except entry index chord equals architecture ﬁrst layer chord lstm used another technique natural language processing; word embeddings. technique pioneered bengio since continuously developed improved. google’s wordvec recent successful result trend. natural language processing word embedding maps words vocabulary vectors real numbers. embeddings often ﬁxed learned training data. idea vector space capture relationships words e.g. words semantically similar also close together vector space. example days week words like king queen might close together embedding space. chords used exact technique. one-hot vectors xchord described section iv-a. multiplied embedding matrix wembed resulting -dimensional embedded chord vector piano roll representation distinction time steps note note held played repeatedly time steps. interpret piano roll replaying predicted song. found generally sounds better notes played continuously. achieve this merge consecutive notes pitch saving ﬁnal midi ﬁle. however beginning notes repeated again. adds structure music emphasizes chord changes. instrumentation tempo predicted songs played back chosen arbitrarily. thus produced music made diverse choosing different instruments e.g. piano guitar organ etc. varying tempo produced midi ﬁle. interesting result chord lstm embeddings learned training data. visualize embeddings used reduce dimensional embeddings chords dimensions. figure plot visualized embeddings chord lstm trained original unshifted dataset. plot contains major chords circle ﬁfths figure interestingly visualized embeddings form exactly circle circle ﬁfths. chord lstm learned representation similar diagram musicians visualize relationships chords. thus model capable extracting concepts music theory songs. contrast previous methods background knowledge input manually help system post-processing method automatically mines knowledge dataset exploits mined theory produce good songs. actually learning methods also similar ways human-being learns. human musician either learns theory teacher learns listening number songs summarizing high level description frequent patterns good music. ﬁrst glance ﬁrst appears efﬁcient cases encoding knowledge machine-readable manually difﬁcult expensive impossible. besides second learning help extend current theory ﬁnding patterns data. hand someone wants generate good music based preference expert music machine learning could input preferred theory system? data mining based method becomes powerful since tell system music likes also related another active research ﬁeld; learning salient representations data. meaningful representation similar instances closely representation space. training polyphonic lstm trained reduce cross entropy loss output vectors poly ground truth. adam optimizer initial learning rate since every time step chord lstm time steps polyphonic lstm training data polyphonic lstm consists songs shifted dataset order reduce training time. trained lstm epochs. generation predict song ﬁrst feed seed consisting piano roll corresponding chords lstm. notes played next time step sampled output vector poly. notes sampled independently note chosen played probabilities notes change. also implement soft upper limit number notes played time step. training data mainly consists songs different instruments playing time different volumes. predicted song however played back instrument every note played volume. songs training data might away many notes playing time playback method quickly sounds cluttered. reason implemented soft upper limit number notes played time step. prediction take probabilities output vector greater upper limit divide probabilities multiply fig. chord embeddings chord lstm trained original unshifted dataset. learned embedding strongly resembles circle fifths. dimensional embeddings reduced dimensions pca. fig. chord embeddings chord lstm trained shifted dataset. instead chord names notes chord shown. dimensional embeddings reduced dimensions pca. figure used technique visualize chord embeddings trained shifted dataset. embeddings occurring chords plotted. instead chord names three notes make chord shown. chords contain common notes close together. makes sense chords share notes also close together vector space. circle ﬁfths present chord lstm trained shifted dataset. even chords present chord dictionary since size limited makes sense many chords occur often major/a harmonic minor. chord progressions predicted chord lstm contain structures often present western music. often repeats four chords especially temperature low. temperature higher chord progressions become divers fewer repeating structures. sampling temperature predicted chords mostly also ones occur training data i.e. table sampling temperature high less occurring chords predicted often. songs generated polyphonic lstm sound pleasing. clearly long term structure songs hear distinct chord changes. lstms succeeded learning relationship chords notes played them. therefore able generate polyphonic music long term structure given predicted chords. lower sampling temperature chord lstm songs sound harmonic also boring. accordingly sampling temperature high music sounds less harmonic also diverse. might chord lstm predicts less occurring chords higher temperature less training data learn relationship less occurring chords notes. introduced jambot system predict chord progressions structural guide song generate polyphonic music chord progressions. generated music long term structure similar human musician might play improvisation session. visualizing embedded chords show jambot learns circle ﬁfths original dataset. trained shifted dataset also learns meaningful embeddings related chords closer together embedding space. especially surprising considering chord lstm provided chord ids. receive information notes chords. thus without explicitly implement principles music theory model gained understanding observing dataset. jambot capable learning meaningful representations. plan incorporate representation learning methods autoencoders order learn complex music theory related representations data. notes played next time step sampled independently probability output vector poly however matters notes played together since intervals played notes characterize chords harmonies. common problem models generate polyphonic music. able mitigate problem providing polyphonic lstm current chord. instead sampling every note probability independently could come calculate joint probabilities notes. could help reduce number dissonant notes would closer humans compose music. limitation piano roll data representation cannot distinguish note held several repeatedly played every time step. existing data representations address problem work monophonic music. data representation allows polyphony notes different lengths would favorable. two-level approach ﬁrst step generate chord progressions. second step generated chords used generate music. thus chord lstm guides polyphonic lstm helps produce music long-term structure. would interesting levels hierarchy example adding another network guides chord lstm. might enable system produce music repeating structures choruses verses. parts lakh midi dataset aligned million song dataset contains meta information like artist genre lyrics songs. make generated music diverse could input genre feature lstms. generating song could provide lstms desired genre feature thus conditioning output said genre. bharucha todd modeling perception tonal structure neural nets computer music journal vol. available http//www.jstor.org/stable/ mozer neural network music composition prediction exploring beneﬁts psychoacoustic constraints multi-scale processing connect. sci. vol. available https//doi.org/./ boulanger-lewandowski bengio vincent modeling temporal dependencies high-dimensional sequences application polyphonic music generation transcription available http//icml.cc//papers/.pdf oord dieleman simonyan vinyals graves kalchbrenner senior kavukcuoglu wavenet generative model available audio corr vol. abs/. http//arxiv.org/abs/. mehri kumar gulrajani kumar jain sotelo courville bengio samplernn unconditional end-to-end neural audio generation model corr vol. abs/. available http//arxiv.org/abs/. burgoyne wild fujinaga expert ground analysis truth proceedings music ismir miami florida information retrieval conference october available http//ismir.ismir.net/papers/os-.pdf carlton blog post analyzed chords popular songs patterns. found. http//www.hooktheory.com/blog/ianalyzed-the-chords-of--popular-songs-for-patterns-this-is-whati-found accessed raffel ellis intuitive analysis creation manipulation midi data pretty midi international society music information retrieval conference late breaking demo papers", "year": 2017}