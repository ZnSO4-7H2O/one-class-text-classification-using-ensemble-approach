{"title": "Brain-Inspired Deep Networks for Image Aesthetics Assessment", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Image aesthetics assessment has been challenging due to its subjective nature. Inspired by the scientific advances in the human visual perception and neuroaesthetics, we design Brain-Inspired Deep Networks (BDN) for this task. BDN first learns attributes through the parallel supervised pathways, on a variety of selected feature dimensions. A high-level synthesis network is trained to associate and transform those attributes into the overall aesthetics rating. We then extend BDN to predicting the distribution of human ratings, since aesthetics ratings are often subjective. Another highlight is our first-of-its-kind study of label-preserving transformations in the context of aesthetics assessment, which leads to an effective data augmentation approach. Experimental results on the AVA dataset show that our biological inspired and task-specific BDN model gains significantly performance improvement, compared to other state-of-the-art models with the same or higher parameter capacity.", "text": "abstract. image aesthetics assessment challenging subjective nature. inspired scientiﬁc advances human visual perception neuroaesthetics design brain-inspired deep networks task. ﬁrst learns attributes parallel supervised pathways variety selected feature dimensions. high-level synthesis network trained associate transform attributes overall aesthetics rating. extend predicting distribution human ratings since aesthetics ratings often subjective. another highlight ﬁrst-of-its-kind study labelpreserving transformations context aesthetics assessment leads eﬀective data augmentation approach. experimental results dataset show biological inspired task-speciﬁc model gains signiﬁcantly performance improvement compared state-of-the-art models higher parameter capacity. automated assessment rating pictorial aesthetics many applications image retrieval system picture editing software compared many typical machine vision problems aesthetics assessment even challenging highly subjective nature aesthetics seemingly inherent semantic low-level computable features high-level human-oriented semantics. though aesthetics inﬂuences many human judgments understanding makes image aesthetically pleasing still limited. contrary semantics aesthetics response usually subjective diﬃcult gauge even among human beings. existing research predominantly focused constructing hand-crafted features empirically related aesthetics. features designed guidance photography psychological rules rule-ofthirds composition depth ﬁeld colorfulness images represented hand-crafted features aesthetic classiﬁcation regression models trained datasets consisting images associated human aesthetic ratings. however eﬀectiveness hand-crafted features empirical vagueness certain photographic psychologic rules. recently et.al. proposed rating pictorial aesthetics using deep learning model impressive accuracies aesthetic visual fig. brain-inspired deep networks architecture. input image ﬁrst processed parallel pathways learns attribute along selected feature dimension independently. except ﬁrst three simplest features parallel pathways take form fully-convolutional networks supervised individual labels; hidden layer activations utilized learned attributes. associate pre-trained pathways high-level synthesis network jointly tune entire network predict overall aesthetics ratings. addition binary rating prediction also extend predicting rating distribution introducing kullback-leibler -divergence based loss high-level synthesis network. furthermore study cognitive neural underpinnings aesthetic appreciation means neuroimaging techniques yields promise understanding human aesthetics although results studies somewhat divergent hierarchical core mechanisms involved aesthetic preference identiﬁed whereas deep learning well known analogous brain mechanisms hardly work providing synergy neuroaesthetics advances learning-based aesthetics assessment models. work develop novel deep-learning based image aesthetics assessment model called brain-inspired deep networks clearly distinguishes prior models unique architecture inspired chatterjee’s visual neuroscience model introduce speciﬁc architecture parallel supervised pathways learn multiple attributes variety selected feature dimensions. attributes associated transformed overall aesthetic rating high-level synthesis network. extend predicting distribution human ratings since aesthetics ratings often vary somewhat observer observer. technical contribution also includes study label-preserving transformations context aesthetics assessment facilitates data augmentation. examine model large-scale dataset binary rating rating distribution prediction tasks conﬁrms superiority competitive methods larger amounts parameters. neuroscience principles also considered traditional aesthetics assessment tasks makes innovative meaningful progresses develop much sophisticated brain-type model ways. first deep model itself processes input information multiphase hierarchy emulates underlying complex neural mechanisms human perception. eﬀective biologically plausible compared standard aesthetics models hand-crafted features linear classiﬁers. second among existing deep aesthetics assessment models ﬁrst introduce design independent feature dimensions parallel pathways followed fusing prediction score. exploits neuroaesthetic wisdom part previously utilized oversimpliﬁed integrates prior wisdom power deep models. datta et.al. ﬁrst casted image aesthetics assessment problem classiﬁcation regression problem. given image mapped aesthetic rating usually collected multiple subject raters. rating normally quantized discrete values. earliest work extracted various handcrafted features including low-level image statistics distributions edges color histograms high-level photographic rules rule thirds. part subsequent eﬀorts focus improving quality features. generic image features sift fisher vector also applied predict aesthetics. however empirical features cannot accurately exhaustively represent aesthetic properties. human brain transforms synthesizes torrent complex ambiguous sensory information coherent thought decisions. aesthetic assessment methods adopt simple linear classiﬁers categorize input features obviously oversimpliﬁed. deep networks attempt emulate underlying complex neural mechanisms human perception display ability describe image content primitive level abstract level composed multiple non-linear transformations yield abstract descriptive embedding representations. rapid model among ﬁrst apply deep convolutional neural networks aesthetics rating prediction features automatically learned. improved model exploring style annotations associated images. fact even hidden activations generic proved work reasonably well aesthetics features taken label photo. example rapid simply divided samples aesthetic unaesthetic trained binary classiﬁcation model. however common diﬀerent users rate visual subjects inconsistently even oppositely subjective problem nature since human aesthetic assessment depends multiple dimensions composition colorfulness even emotion diﬃcult individuals reliably convert experiences single rating resulting noisy estimates real aesthetic responses. et.al. ﬁrst proposed represent photo’s rating distribution vector basic ratings constituting structural regression problem. et.al. formulated aesthetic assessment multi-label task multiple aesthetic attributes predicted jointly bayesian networks. large reliable datasets consisting images corresponding human ratings essential foundation development machine assessment models. several photo resources taken advantage crowdsourcing contributions flickr dpchallenge.com dataset large-scale collection images meta-data derived dpchallenge.com. contains images aesthetic ratings subset binary style labels making automatic feature learning using deep learning approaches possible. paper focus research subject. recent advances neuroaesthetics imply human perception aesthetics complicated systematic process. multiple parallel processing strategies involving dozen retinal ganglion cell types found retina. ganglion cell type tiles retina focus speciﬁc kind feature provide complete representation across entire visual ﬁeld retinal ganglion cells project parallel retina lateral geniculate nucleus thalamus primary visual cortex. primary visual cortex receives parallel inputs thalamus uses modularity deﬁned spatially cell-type speciﬁc connectivity recombine inputs parallel outputs. beyond primary visual cortex separate interacting dorsal ventral streams perform distinct computations similar visual information support distinct behavioural goals integration visual information achieved progressively. independent groups cells different functions brought temporary association so-called binding mechanism ﬁnal decision-making. divergence comes later stage low-level visual features processed parallel pathways utilized. pathway characterized hierarchical architecture neurons higher areas code progressively complex representations pooling information lower areas. example evidence neurons code relatively simple features local contours colors whereas neurons response abstractive features encode scene’s gist and/or saliency information holistic signature input. notations consistency terms feature dimension denote prominent visual property relevant aesthetics judgement. deﬁne attribute learned abstracted holistic feature representation speciﬁc feature dimension. deﬁne pathway processing mechanism visual input attribute. computational model deep learning known tied class theories brain development example design cnns follows discovery general human vision mechanisms indicating usefulness ideas borrowed neurobiological processes. hand current deep models remain extremely simple compared vastness complexity biological information processing. demonstrated single neuron probably complex entire mention lack knowledge cells’ electrochemical properties inter-neuron interactions. argue neither impractical necessary model exactly reproduce full perception process human brain take typical example able without complexity ﬂuidity ﬂapping wings. main insights gained classical important chatterjee’s visual neuroscience model models cognitive aﬀective processes involved visual aesthetic preference providing means organize results obtained neuroimaging studies within series information-processing phases. chatterjee’s model concludes following simpliﬁed important insights inspire model step derived many recent advances showing aesthetics judgments evidently involve multiple pathways could connect related perception tasks previously many feature dimensions color shape composition already discovered crucial aesthetics. bold rational assumption thus made attribute learning aesthetics tasks could decomposed onto pre-known feature dimensions processed parallel. architecture brain-inspired deep networks depicted fig. whole training process divided stages based insights. brief ﬁrst learn attributes parallel pathways selected feature dimensions. combine pre-trained pathways high-level synthesis network jointly tune entire network predict overall aesthetics ratings. testing process completely feed-forward end-to-end. selecting feature dimensions ﬁrst select feature dimensions discovered highly related aesthetics assessment. despite lack rules certain visual features believed please humans others take advantage photographically psychologically inspired features priors force focus them. previous work e.g. identiﬁed aesthetically discriminative features. suggested light exposure saturation play indispensable roles. assume data image converted color space size original image. furthermore many photographic style features inﬂuence human’s aesthetic judgements. proposed sets photographic styles including rule thirds composition textures shapes shallow depth-of-ﬁeld experiments downsample original size improve training eﬃciency. turns model performance hardly aﬀected understandable since human perceptions features insensitive scale changes. parallel supervised pathways among feature dimensions simplest three immediately obtained input. however remaining style feature dimensions qualitatively well-deﬁned; attributes straightforward extracted. style category feature dimension create binary individual labels labelling images style annotation otherwise follows many previous work design special architecture called parallel supervised pathways. pathway modeled fully convolutional neural network fig. takes image input outputs image’s individual label along feature dimension. pathways learned parallel without intervening other. choice fcnn motivated spatial locality-preserving property human brain’s low-level visual perception feature dimension number labeled samples limited shown table therefore pre-train ﬁrst layers fig. using images dataset unsupervised way. construct layer stacked convolutional auto encoder ﬁrst layers follows topology conv conv layers last layers mirror-symmetrical deconvolutional layers scae trained ﬁrst layers applied initialize conv conv layers fcnn pathways. strategy based common belief lower layers cnns learn general-purpose features edges contours could adapted extensive high-level tasks initialization ﬁrst layers pathway concatenate conv conv layers conduct supervised training using individual labels. conv layer always channel number corresponding style classes followed global average pooling step correlated binary labels. eventually conv layer well classiﬁer discarded conv-conv layers pathways passed next stage. treat conv layer activations pathway learned attributes finally simulates brain’s high-level association synthesis using larger fcnn. architecture resembles fig. except ﬁrst three convolutional layers channels instead high-level synthesis network takes attributes parallel pathways inputs outputs overall aesthetics rating. entire tuned end. existing studies apply scalar value represent predicted aesthetics quality appears insuﬃcient capture true subjective nature. example images equal mean score could diﬀerent deviations among raters. typically image large rating variance likely edgy subject interpretation. assigned images binary aesthetics labels i.e. high quality quality thresholding mean ratings provided less informative supervision large intra-class variation. suggested represent ratings distribution pre-deﬁned ordinal basic ratings. however structural label could noisy coarse grid basic ratings limited sample size image lack shifting robustness l-based loss. images standard deviation image’s ratings function mean rating. especially images moderate ratings tend lower variance images extreme ratings. inspires estimations mean ratings standard deviations jointly performed potentially mutually reinforce other. image distribution ratings diﬀerent raters largely gaussian. according gaussian functions perform adequately good approximations rating distributions images. besides non-gaussian distributions tend highly-skewed occurring high extremes rating scale mean ratings could predicted higher conﬁdences. propose explicitly model rating distribution image gaussian jointly predict mean standard deviation. assuming underlying distribution predicted distribution diﬀerence calculated kullback-leibler divergence training predict rating distributions replace default softmax loss loss function corresponds kl-loss branch fig. outputs global average pooling highbinary prediction task output denotes bernoulli distribution labels elements output denote predicted mean variance respectively. could thus arbitrary real values falling within rating scale. training deep networks common approach reduce overﬁtting artiﬁcially enlarge dataset using label-preserving transformations image translations horizontal reﬂections generated intensities channels altered apparently change object class labels. alternatives random noise rotations warping scaling also widely adopted latest deep-learning based object recognition methods. however little work identifying label-preserving transformations image aesthetics assessment e.g. signiﬁcantly alter human aesthetics judgements considering rating-based labels subjective. motivated need create ﬁxed-size inputs authors created randomly-cropped local regions training images empirically treated data augmentation. make ﬁrst exploration identify whether certain transformation preserve binary aesthetics rating i.e. high quality versus quality conducting subjective evaluation survey among participants. select high-quality images dataset image processed diﬀerent kinds transformations table time participant shown image pairs originated image processed diﬀerent transformations pair participant needs decide better terms aesthetics quality. image pairs drawn randomly image winning pairwise comparison compared next round best selected. bradley-terry model estimate subjective scores method ranked. groundtruth score transformation receive score deﬁne score label-preserving factor transformation; larger factor denotes smaller impact image aesthetics. according table reﬂection random scaling receive high factors; small noise seems marginally aﬀect aesthetics feelings remaining signiﬁcantly degrade human aesthetics perceptions. therefore adopt reﬂection random scaling small noise default data augmentation approaches unless otherwise speciﬁed. implement models based cuda-convnet package relu nonlinearity well dropout applied. batch size ﬁxed since fully convolutional need normalize input size. experiments workstation intel xeon .ghz cpus gpu. training pathway takes roughly hours. ﬁne-tuning entire model typically takes day. low-quality mean ratings larger referred high-quality. distribution prediction quantize ratings. adjustment learning rates hierarchical model calls special attentions. ﬁrst train parallel pathways identical learning rates unsupervised pre-training supervised tuning annealed throughout training. train high-level synthesis network ﬁne-tune entire bdn. pathway part learning rate starts high-level part learning rate starts training curve reaches plateau ﬁrst dividing dividing training/validation error still decrease. static regularization versus joint tuning rapid model also extracted attributes along diﬀerent columns combine them. pre-trained style classiﬁer frozen acted static network regularization. curiosity also tried parallel pathways training high-level synthesis network e.g. resulting performance veriﬁed inferior joint tuning entire bdn. compare state-of-the-art rapid model binary aesthetics rating prediction. beneﬁting fully-convolutional architecture model much lower parameter capacity rapid relies fullyconnected layers. addition compare proposed model three baseline networks exactly parameter capacity attribute learning part trained unsupervised concatenated high-level synthesis network jointly supervised-tuned. bfcn utilize style annotations. train models binary rating predictions overall accuracies compared table appears bfcn performs signiﬁcantly worse others absence style attribute information. rapid bdn-wp utilize style annotations supervision outperforms cases remarkable margins. comparing bdn-wp observe biologicallyinspired parallel pathway architecture facilitates learning. speciﬁc architecture avoids overly large all-in-one models instead eﬀective dedicated sub-models. style annotations serve powerful priors enforce focus extracting features highly correlated aesthetics judgements. jointly tuned diﬀerent rapid whose style column acts static regularization. also notice gain nearly bdn-wa veriﬁes eﬀectiveness proposed augmentation approaches. linear classiﬁer trained ﬁsher vector signatures computed color sift descriptors. aesthetic quality categorization setting baselines reported falling behind rapid. qualitatively analyze results display eight images correctly classiﬁed high-quality fig. eight correctly classiﬁed low-quality images fig. images ranked high terms aesthetics typically present salient foreground objects depth ﬁeld proper composition color harmony. contrast low-quality images least defected aspect. example left image focused foreground object bottom right suﬀers messy layout. right girl portrait investigated original comments dpchallenge.com found people rated noticeable detail loss caused noise reduction post-processing well unnatural plastic-like lights hair. even interestingly fig. lists failure examples bdn. left image fig. depicts waving glowstick captured time-lapse photography. image appealing composition colors thus idenfig. contexts emotions could alter aesthetics judgment. incorrectly classiﬁed examples semantic contents; high-variance examples nonconventional styles subjects. tiﬁed low-quality. however dpchallenge raters/commenters amazed angel shape rated favorably creative idea. right image contrast high-quality portrait conﬁdently agrees. however associated rectangular challenge topic dpchallenge rated targeted theme overshadowed woman. failure examples manifest huge subjectivity sensitivity human aesthetics judgement. best knowledge among state-of-the-art models working latest largescale datasets accounting rating distribution prediction. binary prediction initialization re-train high-level synthesis network loss deﬁned eqn. compare predicted distributions groundtruth testing set. also include variants baselines task softmax loss rating distribution vectors makes architecture change modifying global average pooling high-level network -channel. output compared rating distribution conventional softmax loss compared table kl-based loss function tends perform better softmax function speciﬁc task. important notice reduces divergence compared bdn-kl-d. ratings noisy coarse rating grid limited rating number able obtain robust estimation underlying rating distribution strong gaussian prior study notably observe testing images diﬀerences groundtruth mean values estimates less binarize estimated groundtruth mean values re-evaluate results context binary rating prediction. overall accuracies improved veriﬁes beneﬁts jointly predict means standard deviations built upon observation correlated. fig. visualizes images correctly predicted large variances. intuitive images high variance seem likely edgy subject interpretation. taking right image example comments received indicate many voters found photo striking others found rude eﬀorts continued explore distinct aspects neural underpinnings aesthetic appreciation recognition familiarity bottom-up versus top-down pathways inﬂuence expertise could also corresponded computational process bdn. example bottom-up/top-down pathways reminds feedforward/back-propogration processes training deep networks. certainly much room strengthen synergy neuroaesthestics computaitonal models. ﬁndings indicated aesthetic judgements partially overlap evaluative judgements social moral cues also implied examples fig. immediate next work take account. paper inspired knowledge abstracted human visual perception neuroaesthetics formulate brain-inspired deep networks biological inspired task-speciﬁc architecture leads superior performances compared state-of-the-art models higher parameter capacity. since observed fig. emotions contexts could alter aesthetics judgment plan take factors account comprehensive framework.", "year": 2016}