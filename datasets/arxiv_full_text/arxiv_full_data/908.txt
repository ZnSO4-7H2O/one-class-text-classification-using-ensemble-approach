{"title": "Pruning Techniques for Mixed Ensembles of Genetic Programming Models", "tag": ["cs.NE", "cs.LG", "stat.ML"], "abstract": "The objective of this paper is to define an effective strategy for building an ensemble of Genetic Programming (GP) models. Ensemble methods are widely used in machine learning due to their features: they average out biases, they reduce the variance and they usually generalize better than single models. Despite these advantages, building ensemble of GP models is not a well-developed topic in the evolutionary computation community. To fill this gap, we propose a strategy that blends individuals produced by standard syntax-based GP and individuals produced by geometric semantic genetic programming, one of the newest semantics-based method developed in GP. In fact, recent literature showed that combining syntax and semantics could improve the generalization ability of a GP model. Additionally, to improve the diversity of the GP models used to build up the ensemble, we propose different pruning criteria that are based on correlation and entropy, a commonly used measure in information theory. Experimental results,obtained over different complex problems, suggest that the pruning criteria based on correlation and entropy could be effective in improving the generalization ability of the ensemble model and in reducing the computational burden required to build it.", "text": "abstract. objective paper deﬁne eﬀective strategy building ensemble genetic programming models. ensemble methods widely used machine learning features average biases reduce variance usually generalize better single models. despite advantages building ensemble models well-developed topic evolutionary computation community. propose strategy blends individuals produced standard syntax-based individuals produced geometric semantic genetic programming newest semantics-based method developed fact recent literature showed combining syntax semantics could improve generalization ability model. additionally improve diversity models used build ensemble propose diﬀerent pruning criteria based correlation entropy commonly used measure information theory. experimental results obtained diﬀerent complex problems suggest pruning criteria based correlation entropy could eﬀective improving generalization ability ensemble model reducing computational burden required build last years eﬀort dedicated deﬁnition analysis methods exploit semantic awareness term semantics generally refers behavior program executed training cases. semantics-based methods provide conceptual view successfully used solve complex problems diﬀerent domains however standard syntax-based also capable obtaining competitive results diﬀerent ﬁelds cases application algorithm generally performed objective obtaining ﬁnal model able training data best possible. little research eﬀort dedicated construction ensemble models based somesurprisingly considering vast amount literature advantages ensemble methods reported formally deﬁne ensemble model refer standard symbolic regression problem since kind application addressed study. symbolic regression goal search symbolic expression best particular training ensemble regression models symbolic expressions whose individual predictions combined predict target interestingly ensembles often much accurate individual predictors make main reasons summarized follows learning algorithm performs search space hypotheses identify best hypothesis space. number training data small compared size hypothesis space learning algorithm return diﬀerent hypotheses present error training instances. situation ensemble reduce bias toward particular hypothesis simply considering diﬀerent hypothesis returning prediction based predictions hypothesis made ensemble. large part problems addressed using machine learning techniques target function cannot represented hypotheses case ensemble expand space representable hypothesis considering weighted sums hypotheses drawn main reasons poor attention dedicated ensembles literature related fact that since inception considered time-consuming process computational complexity required evaluation ﬁtness function. issue critical semantics-based despite availability eﬀective hardware nowadays allows perform fast parallel computations construction ensemble models based received attention deserves. answer call study presents method eﬀectively build ensembles models. method designed overcome main limitations typical approach used building ensemble model diﬀerent parallel populations evolved ﬁnal ensemble composed best models returned populations. fact approach predominant across literature important consider several issues negative impact ensemble model developed approach. important issues related generalization. generalization refers ability model perform well unseen examples. critical aspect model interest studying generalization recently increasing importance related fact that typically ﬁnal user model wants obtain satisfactory performance instances problem hand performance training cases generally irrelevant. reason study takes account diﬀerent approaches expect beneﬁcial increasing generalization ability ensemble model. ﬁrst idea comes recent literature authors demonstrated blend individuals created standard syntax-based geometric semantic genetic programming results model better generalization ability respect kind solutions. mind build ensemble models parallel diﬀerent populations evolved using stgp others evolved using gsgp hypotheses study blend stgp gsgp beneﬁcial also building ensemble models. second idea related fact running populations given number generations result unwanted behavior evolved individuals semantically similar situation would little advantage using ensemble respect usage single model. fact reported ensemble composed models accurate diverse. context models said diverse make diﬀerent errors data. would possible achieve better generalization ability respect achievable considering single model. take account relevant aspect strategy presented work evolve diﬀerent parallel populations removed using diﬀerent similarity-based pruning criteria. criteria considered study based level entropy correlation best models available populations. pruning criteria guarantee sort diversity among models used build ensemble. paper structured follows section brieﬂy presents previous studies related deﬁnition ensemble models. section presents strategy developed study build ensemble models similarity-based criteria deﬁned. section contains experimental study including presentation used test problems experimental settings discussion obtained results. finally section concludes paper suggests possible avenues future work. ensemble models presents contributions literature. ﬁrst studies dates back study decomposition regression error bias variance terms provide insight generalization capability modelling methods proposed introduction bias/variance decomposition mean squared error authors showed ensemble methods bagging boosting reduce generalization error bagging boosting considered context ensemble models work authors presented extension means resampling techniques. considering bagging boosting manipulated training data order improve learning algorithm. work extended dividing whole population sub-populations evolved using bagging boosting methods. best individuals sub-population participate voting give prediction unseen data. performance approach discussed authors also showed beneﬁcial eﬀect proposed technique reducing bloat respect standard algorithm. study related suitability techniques building ensemble models classiﬁcation tasks presented authors presented so-called evolutionary ensemble learning approach. objective study twofold side deﬁned ﬁtness function inspired co-evolution enforce classiﬁer diversity. additionally selection criterion based classiﬁcation margin proposed. selection criterion used extract classiﬁer ensemble ﬁnal population incrementally along evolution. experimental phase showed suitability approach compared single-hypothesis evolutionary learning process. besides aforementioned theoretical studies ensemble models used solve complex real-world problems mainly related classiﬁcation tasks. authors demonstrated suitability base classiﬁer algorithm building ensembles large-scale data classiﬁcation. particular showed ensemble individuals able signiﬁcantly outperform counterparts built upon base classiﬁers trained decision tree logistic regression. authors also claimed superiority ensemble partly attributed higher diversity terms functional form well respect variables deﬁning models among base classiﬁers upon built context large-scale data classiﬁcation extension cellular genetic programming data classiﬁcation induce ensemble predictors presented work authors developed algorithms based bagging boosting compared performance cgpc. results showed proposed approaches able deal large datasets main memory also producing better classiﬁcation accuracy respect standard cgpc. authors proposed ensemble distributed intrusion detection systems algorithm runs distributed hybrid multi-island model-based environment monitor security-related activity within network. experiments showed validity approach compared standard techniques task hand. applications ensemble methods includes querying-by-committee methods divide-andconquer strategy solution need work well subset entire training respect ensembles regression models quite recent contribution proposed idea explored authors generate several regression models concurrently executing multiple independent instances subsequently analyze several strategies fusing predictions multiple regression models. study considered small datasets memory constraints authors able draw interesting conclusions suitability approach producing accurate predictions. study diﬀer described several ways constraint size datasets consider models produced diﬀerent algorithms deﬁne diﬀerent similarity-based criteria that taking account information related populations evolved improving generalization ability ﬁnal ensemble well reducing computational eﬀort. hence experiments described contribution explained section populations evolved independent other. reported section idea exploited study build ensemble consists blend individuals produced stgp gsgp. gsgp newest methods directly include semantic awareness search process interested reader referred description concept semantics uses present semantic operators used paper. despite plethora studies investigating role semantics still topic ﬁeld particularly interesting respect study work proposed work authors deﬁned simple eﬀective algorithm initialization population inspired biological phenomenon demes despeciation synthesis initial population created using best individuals separate subpopulations demes stgp others gsgp generations. experimental results showed initialization technique outperforms traditional ramped half-and-half algorithm complex symbolic regression applications. even interesting using proposed initialization technique process produces individuals better generalization ability ones obtained initializing population traditional ramped half-and-half algorithm. hence construct gpbased ensemble build upon idea expect obtain ﬁnal ensemble better generalization ability respect counterparts stgp gsgp considered. section describes proposed system building gp-based ensemble models. main idea provide pruning method reduce number populations ensemble exploring similar regions search space sense possibly wasting computational eﬀort perform work times. therefore need measure similarity among solutions allows pruning procedure take place. generation best solutions populations part ensemble pairwise compared deemed similar worst performing removed remaining weighted calculating semantics ensemble formally populations best individuals semantics population associated weight semantics entire ensemble given wis. generation subn routine calculates similarity called best individuals populations. since many similarity measures returns real value measuring similar individuals obtain boolean answer comparing similarity measure threshold. that true returned ﬁtness compared population corresponding worst ﬁtness removed. example worst ﬁtness removed ensemble increase weight main aspect governs process subroutine going describe four diﬀerent implementations based diﬀerent notions semantic similarity entropy correlation. idea correlation-based similarity consider semantics similar correlation among certain threshold. semantics i.e. semantic vectors pearson correlation coeﬃcient among them. value varies correlation higher consider individual similar enough. threshold selected preliminary tuning phase diﬀerent values tested across benchmarks considered. variation method introduces probability considered similar enough correlation coeﬃcient goes threshold. probability considered equal greater threshold value true returned probability ρij). reduce expected number populations removed ensemble still assuring similar ones almost surely removed. entropy-based similarity based idea that semantics similar possible infer outputs based other possible even relation complex captured using linear correlation coeﬃcient. given semantics denote mutual entropy mutual discrete data case semantics individuals equally-sized bins regression problems. therefore discretize using length semantic vectors counting number elements present bin. metric normalize distance close semantics dissimilar close otherwise. threshold value chosen. thus semantics distance lower considered similar enough. also case threshold selected preliminary tuning phase diﬀerent values tested. five datasets considered testing performance gp-based ensemble. datasets already considered previous studies. hence summarize main properties table reporting number independent variables name problem reference readers detailed descriptions datasets. experimental phase benchmarks real-world data chosen establish suitability proposed methods real-world setting. here notion better interpreted ways either performance improvement respect ﬁtness comparable ﬁtness values obtained using smaller number populations. proposed pruning criteria either improve results reduce computational burden. ensembles composed beginning populations half evolve using stgp half using gsgp. generate training global training consisting problem instances selected. remaining used test set. training population ensemble provided local training consisting number observations obtained randomly sampling replacement global training set. performed runs. general parameters system summarized table values parameters selected taking account values already used existing literature datasets considered study already used benchmarks. sake brevity report results obtained test avoid reporting global training results. test statistical signiﬁcance results used single tailed mann-whitney u-test alternative hypothesis ﬁrst series ﬁtness values lower second series. threshold p-value selected tables show results statistical tests entry column p-value mann-whitney u-test technique i-th compared j-th column. value less indicates accepted alternative hypothesis thus i-th method produces lower ﬁtness values j-th test data. figures show test problems considered ﬁtness test diﬀerent methods. average size ensemble across generations runs shown figure results airfoil dataset show standard ensemble method best performer. four proposed methods however perform better simply halving randomly removing populations root mean squared error ramped half-and-half maximum depth protected input variables constants tournament size best individual always survives none concrete dataset standard method four proposed methods perform similar way. using half populations randomly removing produces worse results. case correlation-based methods also half populations employed standard method. dataset correlation-based methods return lowest ﬁtness diﬀerence statistically signiﬁcant compared standard entropy-based methods. methods worst performers. best results obtained using quite high number populations proposed methods. might indicate problem well-suited solved ensemble techniques additional populations help producing better results. slump dataset standard entropybased methods best performers. worst performers correlationbased methods which case also employ number populations. yacht dataset interesting since provides example proposed methods namely correlation-based ones perform worse entropy-based remains on-par standard method price removing populations. conclude section important discuss competitive advantage considering blend stgp gsgp. evaluate aspect compared performance ensemble model built considering blend stgp gsgp without pruning ones obtained considering stgp gsgp. results achieved benchmarks show statistically signiﬁcant diﬀerence exists respect performance considered ensemble models unseen instances. result seems contradict recent studies deeper analysis needed. particular would interesting study number models ﬁnal ensemble aﬀects generalization ability three systems analyze impact pruning techniques generalization error. despite fact statistically signiﬁcant diﬀerences noticed using blend stgp gsgp might still important detrimental results show diversity model generally greater observable considering pool individuals obtained gsgp additionally pruning criteria determine populations models evolve. hence might advisable systems evolve weak models pruning criteria select needed create competitive ensemble model. advantage term runtime number ﬁtness evaluations important notice pruning method that example reduces average number distinct populations used third also reduces number ﬁtness evaluations third since computation similarity usually computationally intensive part algorithm similar improvement reﬂected reduction runtime. machine learning literature deeply investigated ensemble models reporting advantages respect weak learner. particular ensemble models characterized diﬀerent features could improve performance learning technique able reduce variance average biases cover larger area hypothesis space respect single model generally present better generalization single model. nonetheless ensemble models deeply investigated ﬁeld paper answered call proposing strategy build ensemble models using genetic programming. diﬀerent versions taken account standard syntax-based system able directly include semantic awareness search process using geometric semantic operators. main objective study understand whether ensemble model made blend individuals evolved stgp gsgp eﬀectively pruned using diﬀerent criteria based correlation entropy. criteria used avoid construction ensemble weak learners semantically similar. fact existing literature suggested ensemble model made accurate diverse models. strategies developed tested diﬀerent benchmark problems already considered literature. results interesting allow draw airfoil standard random half correlation prob-correlation entropy prob-entropy concrete standard random half standard random half correlation prob-correlation entropy prob-entropy standard random half standard random half correlation prob-correlation entropy prob-entropy slump standard random half standard random half correlation prob-correlation entropy prob-entropy yacht standard random half standard random half correlation prob-correlation entropy prob-entropy general conclusion superiority criterion respect ones show considering similarity criterion constructing ensemble help maintaining generalization ability resulting model reducing computational eﬀort. ﬁrst study aimed determining optimal number weak learners optimizing performance ensemble unseen data represent priority. would allow practitioners system without need determine number weak learners parameter impact performance ensemble. furthermore design pruning criteria parameter independent important future work save user time required tuning them. additionally would interesting pursue study interaction syntax semantics important topic ﬁeld still well understood.", "year": 2018}