{"title": "Estimating the Maximum Expected Value: An Analysis of (Nested) Cross  Validation and the Maximum Sample Average", "tag": ["stat.ML", "cs.AI", "cs.LG", "stat.ME"], "abstract": "We investigate the accuracy of the two most common estimators for the maximum expected value of a general set of random variables: a generalization of the maximum sample average, and cross validation. No unbiased estimator exists and we show that it is non-trivial to select a good estimator without knowledge about the distributions of the random variables. We investigate and bound the bias and variance of the aforementioned estimators and prove consistency. The variance of cross validation can be significantly reduced, but not without risking a large bias. The bias and variance of different variants of cross validation are shown to be very problem-dependent, and a wrong choice can lead to very inaccurate estimates.", "text": "investigate accuracy common estimators maximum expected value general random variables generalization maximum sample average cross validation. unbiased estimator exists show non-trivial select good estimator without knowledge distributions random variables. investigate bound bias variance aforementioned estimators prove consistency. variance cross validation signiﬁcantly reduced without risking large bias. bias variance diﬀerent variants cross validation shown problem-dependent wrong choice lead inaccurate estimates. often need estimate maximum expected value random variables noisy estimates variables given. instance problem arises optimization stochastic decision processes algorithmic evaluation. easy construct consistent estimators also interested quality small sample sizes. mean squared error common metric quality estimator sometimes bias important. unfortunately discuss section unbiased estimators exist. common estimator maximum estimator constructs estimates uses maxi ˆµi. contains direct samples average simply maximum sample average. average overestimates bias rediscovered several times instance economics steen decision making smith winkler lead overestimation performance algorithms varma simon cawley talbot poor policies reinforcement learning algorithms hasselt related over-ﬁtting model selection selection bias sample selection heckman feature selection ambroise mclachlan winner’s curse auctions capen common alternative avoid bias cross validation larson mosteller tukey used construct thereafter estimate called nested double cross stone unfortunately lead large variance. perhaps surprisingly show absolute bias larger bias trying prevent. however bias provably negative advantage. paper give general distribution-independent bounds bias variance present variant show dependent estimator accurate terms mse. therefore non-trivial construct accurate estimators without knowledge distributions discuss standard -folds often choice model selection show settings estimators much accurate. learning algorithms many learning algorithms explicitly maximize noisy values update internal parameters. instance reinforcement learning sutton barto goal strategies maximize reward signal decision task. inaccurate biased estimators adverse eﬀects speed learning strategies learned hasselt evaluation algorithms machine-learning algorithms tunable parameters. internal parameters lagrangian multipliers support vector machine vapnik optimized algorithm. hyper-parameters choice kernel function often tuned manually chosen domain knowledge. relevant choices typically evaluate conﬁgurations denotes speciﬁc algorithm speciﬁc hypermeta-parameters. often evaluation noisy randomness algorithms inherent randomness problem. performance random variable want construct estimate best performance instance varma simon note results overlyoptimistic prediction errors propose nested evaluate various hyper-parameters artiﬁcial problem actual error estimate nested results varma simon argue latter exceeds nested removes sample training set. however fact diﬀerence demonstration completely diﬀerent general bias discuss section bias received little attention although—as show—it general smaller bias caused using overview rest section discuss related work preliminaries. section discuss properties including bounds bias variance. section discuss concrete settings empirical illustrations. section contains discussion section concludes paper. bootstrap efron tibshirani resampling method used estimate bias estimator order reduce bias. based this tibshirani tibshirani tibshirani tibshirani propose estimator model selection classiﬁcation. inevitably—see section —the resulting estimate still biased typically variable original estimate. also speciﬁcally considering model selection classiﬁers bernau bernau propose smoothed version nested resulting estimator performs similar normal turn shown typically accurate approach tibshirani tibshirani. paper focus widely used. problem estimating related multi-armed bandit framework robbins berry fristedt goal identity action maximum expected value rather value. focus literature multi-armed bandits often best collect samples. contrast paper assume samples given. discussion best collect samples minimize bias outside sometimes interested conﬁguration optimizes performance resulting performance often performance least important. part depends whether focus research algorithms problem. write estimator based sample similarly estimator write clear context. unbiased samples might sample average. case unbiased general biased discussed next section general unbiased estimator exists even unbiased. estimator called optimal maximal whenever index optimal maximal respectively. note optimal estimators necessarily maximal maximal estimators necessarily optimal. given concrete setting single unknown therefore exist world’. rather might model prior belief sets likely given setting might specify would like estimator perform well. consists variance bias. reason generality estimators good practice discuss non-existence unbiased estimators direction bias. unfortunately interest estimator exists. instance blumenthal cohen show exists normal distributions dhariyal proved arbitrary general distributions including exponential family. essentially argument reasonable estimator depends smoothly values samples whereas real value piece-wise linear function discontinuous derivative. know location discontinuities without knowing actual maximum. cases direction bias direction bias important. suppose test algorithm various hyper-parameters observe best performance better baseline. simply highest test result concluded algorithm really structurally outperform baseline speciﬁc hyper-parameters. although sound trivial common practice manually tune hypermeta-parameters problem best result using maxi non-negative bias. hard avoid optimizing meta-parameters include problem test algorithm practical implication positive bias algorithm disappoint future evaluations similar problems. contrast estimator non-positive bias estimate higher baseline much conﬁdence algorithm reach performance consistently properly tuned hyper-parameter. similar considerations overﬁtting model selection often used. prove indeed non-positive bias therefore avoid overestimations another example performance machine-learning algorithms improves data available. data collection expensive useful predict algorithm performs data available actually collecting data. overestimation future performance lead misallocation resources since collected data less useful predicted. underestimation means pessimistic often decide collect data. whether false positives important false negatives depends crucially speciﬁcs setting. section discuss estimators detail. bound biases variances estimators discuss similarities contrasts prove consistency. introduce low-variance variant give necessary suﬃcient conditions non-zero biases occur estimators perhaps surprisingly show settings negative bias variants larger size positive bias proofs given appendix paper. estimator conceptually simple easy implement estimator often used practice. theorem proves bias non-negative gives necessary suﬃcient conditions strictly positive bias. theorem stronger general similar earlier theorems. instance smith winkler consider possibility multiple optimal variables discuss necessity conditions strictly positive bias. reduces ˆµme however suppose independent. idea leads cross-validation estimators. course new. however seems less well-known properties problem aﬀect accuracy quite biased. know previous work discusses variant. however lower variance sometimes result much lower mses obtained lbcv. lbcv lvcv sample average samples unbiased e{ˆak large enough treated parameter trades bias variance. lbcv larger implies less bias variance lvcv implies bias less variance. lbcv lvcv equivalent. lvcv biased less variable lbcv since based fewer samples based samples. |xi| lbcv based single sample resulting large variance. variant commonly known leave-one-out |xi| lvcv based single sample potentially resulting large bias large probabilities selecting sub-optimal indices. bias received comparatively little attention. sometimes bias mentioned without explanation sometimes even claimed unbiased often observed bias attributed fact biased based rather samples factor bias induced using often least important demonstrated below. confusion seems arise fact often unbiased unfortunately imply ˆµcv unbiased average underestimate non-zero probability prominent case hold variables mean since interestingly implies unbiased worst case theorem implies bias bound zero. conjecture bias bound follows. averages estimators estimators unaﬀected fact ˆµcv aﬀect bias regulating many samples used mentioned earlier lvcv larger implies higher bias since variable lbcv larger implies lower bias since less variable. framework multi-armed bandits used optimize shown website consider unknown ﬁxed expected returns visitor bandit algorithm used balance exploration exploitation optimize online return visitor converges however quick accurate estimates important instance base future investments additionally placing induce cost want know quickly whether diﬀerent settings averaged figure ˆµme experiments. left-most always ˆµme bars left right leave-one-out lvcv -folds lvcv -folds lvcv -folds -folds lbcv -folds lbcv leave-one-out lbcv. note -folds lvcv equivalent -folds lbcv therefore shown separately. mean variance ﬁrst experiment visitors shown equally often means equal theorem implies estimators unbiased; depends solely variance. second—more realistic—setting mean click rates distributed evenly visitors ads. implies depicted contributions bias variance rmse general exactly equal bias standard deviation depiction allow directly many percentage points error caused bias variance. ﬁrst setting indeed unbiased. leave-one-out lvcv lowest variance methods—it barely visible—which implies smallest mse. huge bias causes overestimate actual maximal click rate second setting clear trade-oﬀ lvcv large large bias small variance whereas lbcv large small bias large variance. bias estimators clearly important even though unbiased. even leave-one-out lbcv bias non-negligible bias larger bias interestingly increases error leave-one-out lvcv stays virtually unchanged approximately since error estimators increases increasing implies leave-one-out lvcv goes least accurate almost accurate contrast goes accurate least accurate reason increasing variables relatively similar variables best case lvcv worst case three cases -folds lvcv good choice. consider regression problem. goal polynomials noisy samples function sin). denote noisy data inputs zero-mean gaussian noise variance denote polynomial degree coeﬃcients ﬁtted least-squares equidistant inputs. want maximize negative mse. lowest expected ﬁtting samples testing independent test samples obtained implies construct independent noisy sets conduct following experiment. given deﬁned inner loop follows. test error obtain error average errors obtain biased since ﬁtted samples. ˆµme maxi means samples used lbcv means since much smaller lvcv signiﬁcantly biased. consider lbcv also known nested leave-one-out figure shows results. lvcv shown lvcv meaningless since cannot polynomial single point. huge. sharp contrast previous settings lvcv fares poorly—even terms variance—and leave-one-out lbcv best estimator. however interestingly accurate estimators even size bias much smaller n-fold lbcv results show hard choose estimator good general. unfortunately best choice setting worst choice another. poorly chosen estimator less accurate imply suggest using often biased. potential advantage estimators settings guaranteed non-positive bias. desirable even estimator less accurate. however results recommendation always -folds lbcv seems unfounded. unbiased especially large lvcv often performs much better. hand estimator bias decreases number samples bias lvcv become prohibitively large illustrated regression setting. explains -folds lbcv often choice model selection long fairly small fairly biased. however note -folds lbcv accurate estimator none experiments. general recommendation good estimators. estimates close together indicates likely accurate. although true maximum expected value often estimate simply average estimates shown instance biased settings hardly biased others. furthermore potentially excessive variance variants lbcv implies cases estimate overestimation recommend include lvcv analysis. alternative estimators course possible alternatives estimators discussed. first consider using maximum lower conﬁdence bounds individual value estimates. although counter overestimation guaranteed lead underestimation place. furthermore non-trivial select good conﬁdence interval resulting estimate typically much variable second model-selection exist criteria penalty term based number parameters model. obviously penalties useful comparing homomorphic models diﬀerent numbers parameters therefore apply general setting consider paper. furthermore main purpose criteria give accurate estimate expected value best model increase probability selecting goals related unfortunately equivalent. finally estimate belief distributions location instance bayesian inference. distributions estimate approach less general since requires prior knowledge seem reasonable. probability maximum mean smaller equal probability means smaller estimate show perhaps counter-intuitive result approach discuss small example. consider bernoulli variables. consider means equally likely uniform prior beta distribution parameters suppose draw samples variable. expected estimate unbiased since means equal. depending many samples equal one. note positive bias even higher bias uniform prior prior individual variables uniform implies prior maximum expected value negatively skewed expected value increased. eﬀect already apparent variables increases analyzed bias variance common estimators maximum expected value random variables. maximum estimate results non-negative bias. common alternative cross validation non-positive bias preferable. unfortunately accuracies diﬀerent variants dependent setting; uninformed choice result extremely inaccurate estimates. general rule—e.g. always -fold cv—is always optimal.", "year": 2013}