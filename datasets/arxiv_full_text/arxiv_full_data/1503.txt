{"title": "Multimodal Storytelling via Generative Adversarial Imitation Learning", "tag": ["cs.AI", "cs.CL", "cs.CV"], "abstract": "Deriving event storylines is an effective summarization method to succinctly organize extensive information, which can significantly alleviate the pain of information overload. The critical challenge is the lack of widely recognized definition of storyline metric. Prior studies have developed various approaches based on different assumptions about users' interests. These works can extract interesting patterns, but their assumptions do not guarantee that the derived patterns will match users' preference. On the other hand, their exclusiveness of single modality source misses cross-modality information. This paper proposes a method, multimodal imitation learning via generative adversarial networks(MIL-GAN), to directly model users' interests as reflected by various data. In particular, the proposed model addresses the critical challenge by imitating users' demonstrated storylines. Our proposed model is designed to learn the reward patterns given user-provided storylines and then applies the learned policy to unseen data. The proposed approach is demonstrated to be capable of acquiring the user's implicit intent and outperforming competing methods by a substantial margin with a user study.", "text": "capture meaningful stories. instance argues maximizing weakest link makes good storylines reduced density-based clustering. however model users’ preferred stories requires understand evolution patterns merely keep strong coherence. speciﬁcally existing research area suffers several shortcomings strong assumptions lead poor storylines. related works manually design coherence metrics directly assumed associated good storylines. however high consistency guarantee story quality since good story might properties interest novelty user-preferred style. therefore coherence based metric sufﬁcient modeling storylines. lack multimodal learning. existing works focus unimodal data text storytelling visual storytelling overlooking cross-modality information. multimodal learning entity linkages absence benchmark dataset unimodal miss. prior works reported provide publicly available dataset imitation storytelling. paper focuses directly imitating user-provided storylines rather designing indirect measures. basic idea learn connectivity features structure storylines agent reveal similar stories domains. approach illustrated figure september attack event contains storyline shows entities related cause perpetrators victims aftermath. similarly event charlie hebdo attack also deriving event storylines effective summarization method succinctly organize extensive information signiﬁcantly alleviate pain information overload. critical challenge lack widely recognized deﬁnition storyline metric. prior studies developed various approaches based different assumptions users’ interests. works extract interesting patterns assumptions guarantee derived patterns match users’ preference. hand exclusiveness single modality source misses cross-modality information. paper proposes method multimodal imitation learning generative adversarial networks directly model users’ interests reﬂected various data. particular proposed model addresses critical challenge imitating users’ demonstrated storylines. proposed model designed learn reward patterns given user-provided storylines applies learned policy unseen data. proposed approach demonstrated capable acquiring user’s implicit intent outperforming competing methods substantial margin user study. introduction internet becomes pervasive information overload becomes increasingly severe. even help search engines google yahoo people cannot easily understand series coherent news events. example person desires learn presidential election needs iteratively search several keywords many times review numerous news documents generate cohesive picture e.g. knowledge graph. storytelling efﬁcient solve issue information overload. inferring entity nodes connections original documents represented knowledge graph consists storylines. current works mainly focus task employ strict assumptions story similar type. argue similar storylines share structure certain embedding space. therefore reveal similar stories another event domain. inherent beneﬁt utilizing multimodal data humans often make inferences images texts resolve ambiguities. deep reinforcement learning learn multi-step decisions. however critical difﬁculty reinforcement learning designing reward function optimizing agent. unlike game application exists responsive environment dramatically difﬁcult design reward function storytelling unavailability responses. instead proposing reward function introduce typical inverse reinforcement learning imitation learning learn latent policy. imitating demonstrations strategy agent learns hidden policy dynamic environment observing demonstrations delivered expert agent. often issues instability implicit policy. solve problems generative adversarial networks mechanism employed solve instability issue. yields internal generator model output policy explicitly training addresses second issue. therefore promising integrate learn policy users’ demonstrations. different previous work study treats storytelling imitation learning. speciﬁcally policy acquired event domain transfer policy learn storyline another event. furthermore work takes full advantage multimodal data improve imitation performance. paper deﬁne multimodal imitation storytelling task propose multimodal generative adversarial method derives latent policy behind users’ demonstrations without explicitly designing reward function. main contributions follows proposing imitation learning method storytelling avoid difﬁculty designing reward function storytelling enforce generative adversarial model imitation learning. using learning strategy model robustly model latent connectivity patterns. designing multimodal model integrated based imitation learning inspired human’s ability link multiple entities visual similarity propose multimodal method across textual visual modality imitation learning. model learns reward functions modalities correlation. creating benchmark dataset multimodal imitation storytelling multimodal storytelling dataset collected multiple attacks civil unrest events. several selected topics storylines manually extracted validated. texts images included dataset. related works storytelling storyline generation problem ﬁrst generic studied kumar redescription mining technique series redescription given disjoint dissimilar object sets corresponding subsets discovered. storytelling efﬁcient solve issue information overload. extracting critical connected entities original document structurally summarized. current works contain categories textual storytelling visual storytelling. works reported extract storylines based text image. current methods often suggest assumptions good storyline explicit metrics average similarity weakest similarity neighbor nodes. however assumptions limit generating meaningful stories since user unique notions good storylines. researchers employ latent dirichlet allocation extract stories unsupervised fashion. however difﬁcult accurately model sequential data. reinforcement learning starting alphago atari numerous game applications enjoy property deep reinforcement learning imitating sequential patterns. however often difﬁcult design rewards function especially real world problem. possible solutions include behavior cloning inverse reinforcement learning derive underlying cost function expert data uniquely optimal. unfortunately behavior cloning learns policy supervised learning problem state-action pairs expert trajectories required large amounts data compounding error caused covariate shift. stability issue explicitly tell act. several works employ generative adversarial networks solve issue. hence leverage effectively imitate user-provided storylines. multimodal learning derive patterns associated cross-modality information. example readers often estimate relationship among news articles using images inside images contain entity probably involved event. however current works focus joint representation learning paying little attention sequence problem. different previous study work treats storytelling combination problem imitation learning multimodal learning. employing based imitation learning proposed model learn show hidden ﬁxed length evaluated discriminator. however incomplete sequence provide partial information rating. estimate incomplete portion sequence action-value function value assigned expected rewards obtained lstm sampling controlled πgθ. therefore using values generator update objective function w.r.t. parameters. generator ﬁnishes update sampling sequences mixed real data discriminator. following typical rules improvement original operation discriminator removed discriminator improve function ∼πgθ minφ ∼pdata illustrated figure iteratively updates multimodal generators using formula improves multimodal discriminators formula following policy gradient theorem gradient objective function w.r.t. parameters expressed theorem gradient objective function w.r.t. parameter policy gradient proof theorem denote state value function. keep notation simple leave implicit cases controlled generator gθi. single modality intermediate rewards zero state transferring probability one-hot deterministic have multimodal imitation storytelling section formally deﬁnes task imitation storytelling describes proposed mil-gan model. particular multimodal based imitation learning elaborated multimodal method applied introduced problem setup based event document-storyline pairs goal reveal user generated policy πguser. documents collection consist several entity nodes {txt types modalities appearing denote textual data image multimodal relationship respectively. proposed method generator controlled multimodal parameters {θtxt θimg θmm} used approximate users’ policy generator πguser. following reinforce algorithm collected rewards along sequence starting initial state {etxt eimg emm} maximized optimize generator. utilizing model discriminator yields rewards state score proposed generator. since value function inﬂuenced generator discriminator denote function. learning process iteratively updates objective function gradient w.r.t. parameters convergence. intermediate rewards zero storytelling task it’s difﬁcult evaluate generated storyline it’s complete. following objective policy generate sequence starting maximize expected reward action-value function estimates expected accumulative reward initial state value rating sequence generated πgθ. discriminator consider generated sequences real value increase. basic idea estimating value treat probability sequence real considered discriminator i.e. model limitation sequence algorithm presents full details proposed method. first pre-train input then generator discriminator trained alternatively periodically. training discriminator positive examples given dataset negative examples sampled generator. algorithm multimodal imitation storytelling input initialize generator policy discriminator random weights; multimodal storyline dataset data it}; event documents knowledge base derive embeddings entity compute representations based using multimodal learning generate sequence including train using lstm generate negative samples using training feed negative samples real data; train minimizing cross entropy; training repeat using weighted likelihood expectation inside formula decomposed using unbiased estimation. keep notation simple leave implicit cases function given function thus gradient estimated multimodal learning task contains three types modalities text image coherence. entity words encoded using word embeddings algorithm wordvec. whereas model expresses images semantic sentential space instead word space since images contain massive information. svd-based semantic embedding model employed derive vectors images conditioning contextual words. denote image vector multimodal vector space associated sentential description indicates words. represent vectors condition embedding vector description model conditional distribution following word given context contextual words vector vocabulary embedding matrix associated image vectors represented using tensor ⊗sen mv×k×k mean tensor product word description associated related images. given model predicts word representation following words function contextual words using tensor decomposition dimensionality tunable. denote function retain arguments diagonal multiplication. idea share resemblance middle matrix diagonal matrix. context represented intermediate variable subject expectation weights distribution among word pairs ev×v combining another intermediate factor encode context image using hadamard product using softmax conditional probability calculated. true following words used true label backpropagation method neural networks iteratively update w.r.t. parameters. training parameters include weights distribution evv. model encodes image vector space finally third modality sequential difference word embeddings image vectors. benchmark experiment setting proposed method evaluated newly-proposed storytelling dataset. guide model discover desirable stories manually labeled storylines compiled training. generator obtained event dataset tested another event corpus. experiment shows generator capable deriving transferable storyline. please note different event datasets share entities. benchmark description metrics training contain events major categories homicide protest. homicide contains storylines protest chooses storylines. short examples shown figure famous historical events attack orlando nightclub attack occupy wall street protest martin luther king. event contains several hundred documents. articles taken google news wikipedia. generators trained categories separately. test includes event iguala mass kidnapping malaysia airlines flight since test events involve homicide protest sub-events. data augmentation purpose slicing window employed divide data minimal sequence. metrics first proposed method several baselines tested convergence performance. secondly evaluation conducts user studies amazon mechanical turk cloud sourcing service since ultimate goal validate imitation behaviors. training setting words expressed using wordvec independent event corpus images initially represented transferred sentential space using multimodal learning. normalize shape word vectors along storyline reduced vector ﬁrst word storyline. likewise image vectors reduced ﬁrst image storyline. operation also conducted multimodal sequence. model generator implemented using lstm model accept continuous values. textcnn used discriminator since effective text image. baselines include random scheduled sampling policy gradient lstm. evaluate result several established alternatives random scheduled sampling policy gradient similarity. unfortunately baselines share metric objective function. instead compared regarding accumulative normalized similarity training performance well modalities performance increases. makes sense image contain much information likely lead confusion. instance image original world trade center attached could either victim object attacker textual label victim image would conﬁned smaller accurate semantic space. however result training show potential ability achieve success ultimate evaluation. next section conducted user study amazon mechanical turk service directly assess users’ satisfaction. evaluation user study evaluating storytelling difﬁcult task fact established golden standard even ground truth hard elicit. ultimate goal imitation storytelling help users discover customized storylines given users’ examples. therefore third-party user study conducted since allows obtain accurate statistical information large sample size users. aims test whether generated storyline matches users’ interests. evaluate result baselines mentioned last subsection. study workers asked storyline given storyline best. dynamic reward assignment every minimal unit cost treated evaluation rating collected. test event several starting entities randomly chosen. storylines generated starting entities using proposed method baselines. unit task workers asked choose best among generated candidates gave event background knowledge wikipedia news articles ﬁnal result shown table demonstrates proposed mil-gan signiﬁcantly preferred users. slightly improve preference beyond schedule sampling. policy gradient fails capture users’ behavior. zaharie→wife→wife→cockpit zaharie→flight→fariq→training zaharie→flight→aisa→search mil-gan zaharie→mh→india→debris found generated sequences baselines often contains vague words student gang. baselines tend overﬁt often yield repeat nodes case suggests models without likely overﬁt. proposed models seems succeeded avoid overﬁt issue. compared mil-gan tend generate speciﬁc word rather ambiguous ones. example case mil-gan generated speciﬁc words aisa debris. compared mil-gan generates even speciﬁc entity name ayotzinapa flipe india. implies multimodal constraints improve unimodal performance. conclusion paper proposed multimodal imitation learning approach generating storyline unseen events. avoid reward function designing based imitation learning introduced learn latent policy given users’ demonstrations. bridge information text image model effectively integrates generative adversarial nets multimodal learning deterministic policy gradient. different modalities learn potentially resolve confusion single modality. experiments utilized user-provided demonstration explicitly illustrate advantage proposed method beyond baselines. associating multimodal perspective model succeeds capture latent patterns across different modalities therefore reveal satisfying storylines towards users’ interests. shahriar hossain patrick butler arnold boedihardjo naren ramakrishnan. storytelling entity networks support intelligence analysts. sigkdd pages volodymyr mnih koray kavukcuoglu david silver human-level control deep reinforcement learning. nature karthik narasimhan adam yala improving information extraction acquiring external evidence reinforcement learning. emnlp andrew stuart russell algorithms inverse reinforcement learning. icml pages dingding wang mitsunori ogihara. generating pictorial storylines minimumweight connected dominating approximation multiview graphs. aaai. citeseer", "year": 2017}