{"title": "Analogs of Linguistic Structure in Deep Representations", "tag": ["cs.CL", "cs.NE"], "abstract": "We investigate the compositional structure of message vectors computed by a deep network trained on a communication game. By comparing truth-conditional representations of encoder-produced message vectors to human-produced referring expressions, we are able to identify aligned (vector, utterance) pairs with the same meaning. We then search for structured relationships among these aligned pairs to discover simple vector space transformations corresponding to negation, conjunction, and disjunction. Our results suggest that neural representations are capable of spontaneously developing a \"syntax\" with functional analogues to qualitative properties of natural language.", "text": "figure overview task. given dataset referring expression games example human expressions associated logical forms compute explicit denotations original task possible tasks—giving rise truth-conditional representation natural language. train recurrent encoder–decoder model solve tasks directly decoder generate comparable truth-conditional representations neural encodings. distinguishing features natural language compositionality existence operations like negation coordination applied utterances predictable effects meaning. models trained natural language processing tasks found learn representations encode compositional structure—for example sentence representations machine translation encode explicit features certain syntactic phenomena represent semantic relationships translationally thus natural whether language-like structures also arise spontaneously models trained directly environment signal. rather using language form supervision propose probe—exploiting post-hoc statistical correspondences natural language descriptions neural encodings discover regular structure representation space. investigate compositional structure message vectors computed deep network trained communication game. comparing truth-conditional representations encoder-produced message vectors human-produced referring expressions able identify aligned pairs meaning. search structured relationships among aligned pairs discover simple vector space transformations corresponding negation conjunction disjunction. results suggest neural representations capable spontaneously developing syntax functional analogues qualitative properties natural language. past year seen renewal interest endto-end learning communication strategies between pairs agents represented deep networks approaches kind make possible learn decentralized policies scratch multiple agents coordinating learned communication protocol. generally encoder–decoder model viewed implementing analogous communication protocol input encoding playing role message artiﬁcial language shared encoder decoder earlier work found suitable conditions protocols acquire simple interpretable lexical sequential structure even without natural language training data. communication network hidden states. similar problem translating representations recently investigated andreas build approach order perform detailed analysis compositional structure learned languages. investigate communication game previously studied fitzgerald make discoveries model trained without access language data strategies employed human speakers given communicative context surprisingly good predictors behavior context humans rnns send messages whose interpretations agree nearly object-level decisions even outside contexts produced. interpretable language-like structure naturally arises space representations. identify geometric regularities corresponding negation conjunction disjunction show possible linearly transform representations ways approximately correspond logical operations. focus evaluation communication game fitzgerald top). world objects labeled attributes designated target subset objects world. listener observes speaker’s goal communicate representation enables listener accurately reconstruct genx dataset collected purpose contains human-generated natural-language referring expressions corresponding logical forms instances game. human-generated expressions pre-annotated treat language logic interchangeably refer symbol write expression generated human particular world interested using language data kind analyze behavior deep model trained play game. focus analysis standard encoder–decoder encoder playing role speaker decoder playing role listener. encoder single-layer cells consumes input world target labeling outputs -dimensional hidden representation. write output encoder model world make predictions representation passed decoder implemented multilayer perceptron. decoder makes independent labeling decision every object instead goal explore kinds messages model computes order achieve accuracy—and speciﬁcally whether messages contain high-level semantics low-level structure similar referring expressions produced humans. judge semantic equivalence natural language vector representations? here andreas adopt approach inspired formal semantics represent meaning messages truth conditions every problem instance dataset access human messages well encoding truth-conditional account meaning suggests judge equivalent designate objects world enough compare predictions solely context results suggest model learned communication strategy least superﬁcially language-like admits representations kinds communicative abstractions humans makes abstractions frequency. purely statement high-level behavior model structure space representations. primary goal determine whether behavior achieved using lowlevel structural regularities vector space associated aspects natural language communication. turn focused investigation three speciﬁc logical constructions used natural language unary operation binary operations used training data variety scopes figure evaluating theories model behavior. first encoder initial world producing representation whose meaning would like understand observe behavior decoder holding representation ﬁxed replacing underlying world representation alternatives like compare true decoder output number theories behavior. random theory outputs random decision every object. literal theory predicts decoder output positive label objects exactly match object initial observation. human theory assigns labels according logical semantics utterance produced human presented initial observation. table agreement predicted model behavior high-level semantic correspondence task computed objects worlds full tables. referring expressions generated humans single communicative context highly predictive learned representations interpreted decoder across multiple contexts. logically equivalent messages tabular representations guaranteed identical sampling procedure viewed approximate test equivalence. additionally allows compute softer notions equivalence measuring agreement individual worlds objects. begin simplest question answer tool often messages generated encoder model meaning messages generated humans context? again goal evaluate performance model instead ability understand behavior. send messages human-like semantics? explicit? behave indistinguishable random classiﬁer? scene genx test compute model-generated message tabular representation measure extent agrees representations produced three theories model behavior random theory accepts rejects objects uniform probability literal theory predicts membership objects exactly match object original target human theory predicts according frequent logical form associated natural language descriptions target evaluate agreement level individual objects worlds full tabular meaning representations. results shown table model behavior well explained human decisions context object-level decisions predicted close accuracy based human judgments alone third message pairs agree exactly every sampled scene providing strong evidence carry semantics. rep) rep). words pairs pairs representations natural language messages serve denotational certiﬁcate behaves negation learned model kind primitive notion negation expect possible kind predictable relationship pairs conversely ﬁrst-class notion negation able select arbitrary representation vector associated referring expression apply transformation able predict priori decoder model interpret representation f—i.e. correspondence make strong assumption negation operation predictable linear. previous work found linear operators powerful enough capture many hierarchical relational structures using examples collected training described above compute least-squares estimate minn evaluate collect example representations test equivalent known logical forms measure frequently model behaviors agree logical predictions figure principal components structured message transformations discovered experiments. negation black white dots show message vectors denotationally equivalent provided logical cluster label dots show result transforming black dots estimated negation operation corresponding experiment disjunction using transformation rep—in words often linear operator actually corresponds logical negation. results shown portion table correspondence logical form quite high resulting agreement level individual objects agreement full representations. conclude estimated linear operator analogous negation natural language. indeed behavior operator readily visible figure predicted negated forms close vector space true values negation corresponds roughly mirroring across central point. ﬁnal experiment explore whether kinds linear maps learned binary operations conjunction disjunction. previous section collect examples training data representations whose denotations known correspond groups logical forms desired relationship—in case tuples rep) rep) rep) rep) either table agreement predicted model behavior negation conjunction disjunction tasks evaluation performed transformed message vectors described section discover robust linear transformation message vectors corresponding negation well evidence structured representations binary operations. nicholas fitzgerald yoav artzi luke zettlemoyer. learning distributions logical proforms referring expression generation. ceedings conference empirical methods natural language processing. jakob foerster yannis assael nando freitas shimon whiteson. learning communicate deep multi-agent reinforcement learning. advances neural information processing systems. pages alberto paccanaro jefferey hinton. learning hierarchical structures linear relational advances neural information embedding. processing systems. vancouver canada volume page xing inkit padhi kevin knight. string-based neural learn source syntax? proceedings conference empirical methods natural language processing. results shown bottom portions table correspondence behavior predicted contextual logical form model’s actual behavior less tight negation. time estimated operators clearly capturing structure case disjunction example model interpretations correctly modeled logical form time object level time denotation level. suggests operations conjunction disjunction functional counterparts language functions everywhere well approximated linear. building earlier tools identifying neural codes natural language strings presented technique exploring compositional structure space vector-valued representations. analysis encoder–decoder model trained reference game identiﬁed number language-like properties model’s representation space including transformations corresponding negation disjunction conjunction. major question left open analysis happens multiple transformations applied hierarchically future work might focus extending techniques paper explore recursive structure. believe experiments highlight usefulness denotational perspective formal semantics interpreting behavior deep models. kyunghyun bart merri¨enboer dzmitry bahdanau yoshua bengio. properties neural machine translation encoder-decoder approaches. arxiv preprint arxiv.", "year": 2017}