{"title": "Vision-Based Navigation III: Pose and Motion from Omnidirectional  Optical Flow and a Digital Terrain Map", "tag": ["cs.CV", "cs.AI", "68T45", "E.5; E.4; E.2; H.1.1; F.1.1; F.1.3"], "abstract": "An algorithm for pose and motion estimation using corresponding features in omnidirectional images and a digital terrain map is proposed. In previous paper, such algorithm for regular camera was considered. Using a Digital Terrain (or Digital Elevation) Map (DTM/DEM) as a global reference enables recovering the absolute position and orientation of the camera. In order to do this, the DTM is used to formulate a constraint between corresponding features in two consecutive frames. In this paper, these constraints are extended to handle non-central projection, as is the case with many omnidirectional systems. The utilization of omnidirectional data is shown to improve the robustness and accuracy of the navigation algorithm. The feasibility of this algorithm is established through lab experimentation with two kinds of omnidirectional acquisition systems. The first one is polydioptric cameras while the second is catadioptric camera.", "text": "abstract— algorithm pose motion estimation using corresponding features omnidirectional images digital terrain proposed. previous paper algorithm regular camera considered. using digital terrain global reference enables recovering absolute position orientation camera. order this used formulate constraint corresponding features consecutive frames. paper constraints extended handle non-central projection case many omnidirectional systems. utilization omnidirectional data shown improve robustness accuracy navigation algorithm. feasibility algorithm established experimentation kinds omnidirectional acquisition systems. ﬁrst polydioptric cameras second catadioptric camera. vision-based navigation algorithms major research issue past decades. common approaches navigation problem landmarks ego-motion integration. landmarks approach several features located image-plane matched known location. using data camera’s pose derived. examples algorithms landmarks found pose derivation simple achieve quite accurate estimates. main difﬁculty detection features correct matching landmarks set. ego-motion integration approach motion camera respect estimated. ego-motion derived optical-ﬂow ﬁeld instruments accelerometers gyroscopes. ego-motion obtained integrate motion derive camera’s path. factors make approach attractive speciﬁc features need detected unlike previous approach. several ego-motion estimation algorithms found weakness ego-motion integration comes fact small errors accumulated integration process. hence estimated camera’s path drifted pose estimation accuracy decrease along time. approach used would desirable reduce drift activating while additional algorithm estimates pose directly. navigation-system suggested. work like work drift corrected using digital terrain discrete representation observed ground’s topography. contains altitude level terrain geographical location. segment ground reconstructed using ‘structurefrom-motion’ algorithm matched order derive camera’s pose. using algorithm make information obtained bases estimate ﬂow-ﬁeld alone positions technique critique applies algorithms algorithm presented previous work require intermediate explicit reconstruction world. combining information directly images information claimed algorithm well-conditioned generates accurate estimates reasonable scenarios reasonable error sources. recently increasing interest omnidirectional vision applications robotics could noted. technically omnidirectional vision sometimes also called panoramic vision achieved various ways. examples include camera extreme wide angle lenses cameras hyperbolic parabolic mirrors mounted front standard lens sets cameras mounted ringlike sphere-like conﬁguration ordinary camera rotates around axis takes sequence images covers ﬁeld view degrees omnidirectional vision provides large ﬁeld view useful properties. instance enables tracking objects placed different directions surrounding scene. well established variety features facilitates obtainment robust accurate estimate camera pose. hand vision algorithms account speciﬁc properties particular omnidirectional imaging sensor setup use. comprise theoretical methodological challenges case catadioptric vision. here extreme geometrical distortions images caused parabolic hyperbolic fig. using omnidirectional vision system wide area terrain visible even camera approaches mountainside. using regular camera similar scenario small patch almost planar observed projection induced omnidirectional camera transformation space image plane. least restrictive assumption made camera model inverse image point line space. many omnidirectional cameras lines necessarily intersect single point. envelope called dia-caustic represents locus viewpoints. lines intersect single point system single effective viewpoint central projection. theorem presented stating catadioptric camera single effective viewpoint mirrors cross-section conic section. case including multiple cameras conﬁgurations rotating camera systems shapes mirrors single center projection. data acquired omnidirectional systems cannot processed vision algorithms developed single effective viewpoint assumption. paper navigation algorithm presented extended handle omnidirectional data. general case non-central projection analyzed. single center projection case previously analyzed becomes particular case general formulation optical centers located single point. shown important factors inﬂuence robustness accuracy navigation algorithm complexity observed terrain. extreme case planar segment terrain visible results ill-conditioned system lead failure algorithm. whenever navigating platform comes close mountainside terrain ill-conditioned scenario might arise regular camera used. however using omnidirectional vision system rest terrain still visible even platform approaches mountainsides therefore robust accurate results achieved using omnidirectional vision. paper continues follows section formally deﬁne navigation problem. section derive constraint corresponding features coming consecutive images along trajectory. experimental results presented section conclusions drawn section problem brieﬂy described follows given time instance coordinates system ﬁxed omnidirectional camera. time instance camera located geographical location vector given orientation orthonormal rotation matrix respect global coordinates system deﬁne transformation camera’s frame world’s frame vectors respectively considering sequential time instances transformation given translation vector rotation matrix rough estimates camera’s pose ego-motion time instances assumed known estimates obtained dead-reckoning navigation system. also supplied optical-ﬂow ﬁeld. special assumption made omnidirectional acquisition system. assumed however system fully calibrated. result visible feature possible compute line sight respect camera system deﬁned source point unit-vector oriented source point observed feature. using notations objective proposed algorithm estimate true camera’s pose ego-motion using corresponding features optical-ﬂow ﬁeld {csi cqi} initial-guess δre. following section describes navigation algorithm estimate mentioned parameters. pose ego-motion camera derived using optical-ﬂow ﬁeld consecutive frames. unlike landmarks approach speciﬁc features detected matched. correspondence consecutive images found order derive opticalﬂow ﬁeld. mentioned previous section rough estimate required parameters supplied input. nevertheless since algorithm input initial guess re-calculate pose ego-motion directly integration previous errors take place accuracy preserved. approach founded following observation. since supplies information structure observed terrain depth observed features dictated camera’s pose. hence given pose ego-motion camera optical-ﬂow ﬁeld uniquely determined. objective algorithm ﬁnding pose ego-motion lead optical-ﬂow ﬁeld close possible given ﬁeld. single vector optical-ﬂow ﬁeld used deﬁne constraint camera’s pose ego-motion. location ground feature point world. different time instances feature point detected omnidirectional images lines sight computed. using initial-guess pose camera line passing direction intersected dtm. ray-tracing style algorithm used purpose. location intersection denoted subscript letter highlights fact ground-point estimated location feature point general different true ground-feature location difference true estimated locations main sources error initial guess pose errors determination caused discretization intrinsic errors. reasonable initial-guess dtm-related errors points close enough allow linearization around denoting normal plane tangent point write order simplify notations replaced likewise replaced respectively. superscript describing coordinate frame vector given also omitted except cases special attention needs drawn frames. normally camera’s frame rest vectors given world’s frame. using simpliﬁed notations assigned reorganization expression clear geometric interpretation vector projected onto tangent plane. projection along direction next step transferring global coordinates frame ﬁrst camera’s frame second camera’s frame since describe transformation inverse transformation constraint involves position orientation egomotion deﬁning frames camera. although involves vectors clear rank exceed usage projects two-dimensional subspace. constraint established vector optical-ﬂow ﬁeld non-singular system obtained. since twelve parameters need estimated least optical-ﬂow vectors required system solution. usually vectors used order deﬁne over-determined system lead robust solution. reader attention drawn fact non-linear constraint obtained. thus iterative scheme used order solve system. example newton-iterations start rough estimate pose motion parameters iteratively converge least square solution performed. suggested m-estimator integrated scheme increase robustness presence outliers. experimentation performed using real model terrain images omnidirectional acquisition system. dimensions model elevation variations high laserbased d-scanner used capture terrain build spatial grid tested trajectories. trajectory contains constant fig. translational motion trajectory signiﬁcant changes orientation. true paths marked black solid line pathes reconstructed algorithm marked line. black dotted lines represent trajectories would obtained case algorithm activated. three cameras wide ﬁeld view ﬁrmly attached robotic arm. camera posed different orientation internal parameters relative pose parameters accurately estimated part system calibration phase. experiment cameras conﬁguration moved along different trajectory. robotic allowed moving cameras controlled manner also providing true measurements pose cameras time instances. fig. shows examples trajectories evaluated. ﬁrst trajectory contains constant translational motion orientation held constant. second trajectory position orientation cameras changed signiﬁcantly. although highly accurate ground-truth data trajectory cameras obtained robotic manipulator trajectory corrupted using simulated error model true priori trajectories drifted away time. error model drifted trajectory position orientation mm/sec .◦/sec respectively. order compensate drift proposed algorithm called rate. whenever activated algorithm supplied latest images previous image triplet captured compares translational accuracies obtained using three cameras reconstructing trajectory clear advantage observed utilization omnidirectional conﬁguration. sensitivities proposed algorithm studied. found obtained accuracy highly related complexity observed terrain. extreme case planar segment terrain visible results ill-conditioned system leads failure algorithm. whenever navigating platform comes close mountainsides terrain ill-conditioned scenario might happen regular camera used. however using omnidirectional vision system rest terrain still visible even approaching mountainsides. therefore robust accurate results expected using omnidirectional vision conﬁrmed fig. note blue ﬁgure. time instance algorithm performance relatively poor single camera scenario since small segment terrain visible camera fig. second experiment three regular cameras replaced single catadioptric system constructed parabolic mirror mounted front orthographic camera images pixels captured camera feature correspondences consecutive images computed algorithm using lucas-kanade method noted tracking method optimal catadioptric images nature distortion kind images. however since catadioptric system ﬁrst calibrated distortions computed cancelled. feature warped images rendered original images local area feature appears would regular perspective camera. next lucaskanade tracking method activated warped images special difﬁculty. fig. results trajectories using three cameras conﬁguration. position errors orientation errors drifted path marked black dashed line errors corrected path marked solid line. away. priori information derived available drifted pose frames. since baseline desired algorithm activated ﬁrst time seconds movement. later periodically activated second gaps. experiments gray-level images pixels obtained three cameras. correspondence features camera derived using lucas-kanade tracking method features selected using image-dependent algorithm rather using regular grid spanned image-plane. shown figure algorithm converged reasonable estimates navigation parameters along trajectories described above. ﬁgure shows ground-truth together trajectories computed using error model ﬁrst contains updates second updated periodically using proposed algorithm rate. ﬁgure clearly show corrected-path remains close true-path along whole trajectory. figure shows position orientation errors drifted corrected paths trajectories. seen errors corrected path kept small errors uncompensated path increase gradually. saw-tooth shaped graph corrected path characteristic orientation errors accumulate updates strongly reduced time algorithm applied. order demonstrate importance omnidirectional vision usage trajectories also reconstructed using features coming cameras data cameras ignored. fig. prevent trajectory drifts. moreover utilization omnidirectional data shown improve robustness accuracy navigation algorithm compared counterpart algorithm regular cameras. improvement attributed wide segment visible terrain. segment tends include much higher complexity smaller segments might observed using regular camera. fig. catadioptric system used omnidirectional vision second experiment. example optical-ﬂow ﬁeld extracted algorithm. small blue arrow shows corresponding couple. fig. results trajectories using catadioptric system. position errors orientation errors drifted path marked black dashed line errors corrected path marked solid line. algorithm pose motion estimation using corresponding features omnidirectional images presented. served global reference data used recovering absolute position orientation camera. derived constraint eliminates requirement commonly used assumption single effective viewpoint. result presented algorithm applicable omnidirectional acquisition systems. performance presented algorithm demonstrated using polydioptric cameras catadioptric camera. position orientation estimates found sufﬁciently accurate order bound accumulated errors", "year": 2011}