{"title": "Latent Hierarchical Model for Activity Recognition", "tag": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "abstract": "We present a novel hierarchical model for human activity recognition. In contrast to approaches that successively recognize actions and activities, our approach jointly models actions and activities in a unified framework, and their labels are simultaneously predicted. The model is embedded with a latent layer that is able to capture a richer class of contextual information in both state-state and observation-state pairs. Although loops are present in the model, the model has an overall linear-chain structure, where the exact inference is tractable. Therefore, the model is very efficient in both inference and learning. The parameters of the graphical model are learned with a Structured Support Vector Machine (Structured-SVM). A data-driven approach is used to initialize the latent variables; therefore, no manual labeling for the latent states is required. The experimental results from using two benchmark datasets show that our model outperforms the state-of-the-art approach, and our model is computationally more efficient.", "text": "fig. example shows robot helping people elderly home. care-o-bot offers water elderly detecting elderly resident drunk water long time. work rgb-d sensor used recognize human activities. work built upon existing methods object recognition object localization human skeleton tracking. object human skeleton information combined input model infer human activities. distinguish activities actions follows. actions atomic movements person relate object environment e.g. reaching placing opening closing. actions completed relatively short period time. contrast activities refer complete sequence composed different actions. example microwaving food activity decomposed number actions opening microwave reaching food moving food placing food closing microwave. relation actions activities illustrated fig. abstract—we present novel hierarchical model human activity recognition. contrast approaches successively recognize actions activities approach jointly models actions activities uniﬁed framework labels simultaneously predicted. model embedded latent layer able capture richer class contextual information state-state observation-state pairs. although loops present model model overall linear-chain structure exact inference tractable. therefore model efﬁcient inference learning. parameters graphical model learned structured support vector machine data-driven approach used initialize latent variables; therefore manual labeling latent states required. experimental results using benchmark datasets show model outperforms state-of-the-art approach model computationally efﬁcient. daily life currently widely studied. numerous studies focused providing people physical cognitive social support. achieve this fundamental necessary task recognize human activities. example decide offer physical support robot needs recognize person walking. decide whether remind people continue drinking robot needs recognize past drinking activities. determine whether person lonely robot needs detect interactions people. paper propose hierarchical approach model human activities. different types sensors applied task activity recognition kasteren adopt simple sensors i.e. pressure contact motion sensors recognize daily activities people smart home. ceiling-mounted color camera recognize human postures postures recognized based still images. recently rgb-d sensors microsoft kinect asus xtion become popular activity recognition capture data using structured light thereby allowing researchers extract rich class depth features activity recognition. work equip robot rgb-d sensor collect sequences activity data extract object locations human skeleton points shown fig. based observations fig. graphical representation approach. proposed model paper based previous work wherein recognize sequence actions using conditional random fields model augmented layer latent nodes enrich model’s expressiveness. simplicity latent variables refer variables hidden layer unknown training testing. labels contrast known training latent testing. latent variables able capture difference able model rich variations actions. imagine latent variables represent sub-types actions e.g. action opening able model difference opening bottle opening door using latent variables. temporal segment preserve full connectivity among observations latent variables action nodes thus avoiding making inappropriate conditional independence assumptions. describe efﬁcient method applying exact inference graph whereby collapsing latent states target states allows graphical model considered linear-chain structure. applying exact inference structure efﬁcient. max-margin approach learning parameters model. beneﬁting discriminative framework method needs model correlation input data thus providing natural data fusion. model evaluated using rgb-d data different benchmark datasets results compared number state-of-the-art approaches results show model performs better state-of-the-art approaches model efﬁcient terms inference. summary contribution paper novel hidden model jointly predicting activities sublevel actions outperforms state terms predictive performance computational cost. software open source freely accessible http//ninghanghu.eu/activity recognition.html. remainder paper organized follows. describe related work section formalize model present objective function section iii. inference learning algorithms introduced section section show implementation details comparison results state-of-the-art approach section fig. illustration activity hierarchy. input video represented spatial-temporal volume. bottom layer shows video discretized multiple temporal segments modeling spatial-temporal features extracted temporal segment. middle layer actions recognized input features atomic activity segment. second layer activities described terms sub-level activity sequence. un-directed links graph represent inter-dependency layers. note video segments length; thus segmentation method needs applied. fig. graphical representation model. nodes represent observations observed training testing rendered black. refers action nodes corresponding activity label sequence. gray observed training testing. white nodes refer latent variables unknown either training testing. used represent hidden sub-level semantics among consecutive actions. note fully connected model temporal transitions actionlatent pairs. therefore model enables richer representation activity hierarchy. represents global features. rgb-d video ﬁrst divided smaller video segments segment contains approximately action. accomplished either manual annotation automated temporal segmentation based motion features. spatiotemporal features extracted segment. realworld tasks desirable recognize activities higher level whereby activities usually performed longer duration. combination actions activities forms sequential model hierarchy previous work addresses activity action recognition separate tasks i.e. action labels need inferred activity labels predicted. contrast paper jointly model actions activities uniﬁed framework activity action labels learned simultaneously. experimental evaluation demonstrates framework beneﬁcial compared separate recognition. intuitively understood considering case learning actions activity label provides additional constraints action labels result better estimation actions vice versa. hierarchical layout model i.e. whether model contains single layer multiple layers. second methodology based nature learning method i.e. whether method discriminative generative. human activity recognition component particularly re-ablement elderly depending complexity duration activities activity recognition approaches separated categories single-layer approaches hierarchical approaches. singlelayer approaches refer methods able directly recognize human activities data without deﬁning activity hierarchy. usually activities simple short; therefore higher level layers required. typical activities category include walking waiting falling jumping waving. nevertheless real world activities always simple basic actions. example activity preparing breakfast consist multiple actions opening fridge getting salad making coffee. typical hierarchical approaches ﬁrst estimate sub-level actions then high-level activity labels inferred based action sequences. sung proposed hierarchical maximum entropy markov model detects activities rgb-d videos. consider actions hidden nodes learned implicitly. recently koppula presented interesting approach models activities object affordance random variables. object affordance label deﬁned possible manners people interact object e.g. reachable movable eatable. nodes inter-connected model object-object object-human interactions. nodes connected across segments enable temporal interactions. given test video model jointly estimates human activities object affordance labels using graph-cut algorithm. actions recognized activities estimated using multi-class svm. paper build hierarchical approach jointly estimates actions activities rgb-d videos. inference algorithm efﬁcient compared graph-cut methods. hidden markov models dynamic bayesian networks linear-chain crfs loopy crfs semimarkov models hidden crfs applied recognition human activities. graphical models divided categories generative models discriminative models generative models require making assumptions concerning correlation data data distributed given activity state. risky assumptions reﬂect true attributes data. discriminative models contrast focus modeling posterior probability regardless data distributed. robotic smart environment scenarios usually equipped combination multiple sensors. sensors highly correlated temporal spatial domain e.g. pressure sensor mattress motion sensor bed. scenarios discriminative models provide natural data fusion human activity recognition. linear-chain conditional random field popular discriminative models used many applications. linear-chain crfs efﬁcient models exact inference tractable. however models limited cannot capture intermediate structures within target states adding extra layer latent variables model allows ﬂexibility therefore used modeling complex data. names models including hiddenunit hidden-state hidden inter-changeable literature. koppula present model temporal interactions humans objects loopy spatial crfs. speciﬁcally develop model types nodes representing action labels human object affordance labels objects. human nodes object nodes within temporal segment fully connected. time nodes transited nodes type. results show modeling human-object interaction model outperforms earlier work inference loopy graph solved quadratic optimization problem using graph-cut method inference method however less efﬁcient compared exact inference linear-chain structure graph-cut method requires multiple iterations convergence; iterations usually preferred ensure good solution obtained. another study augments additional layer latent variables linear-chain crfs. explicitly model latent layer represent durations activities. contrast tang solve inference problem reforming graph cliques exact inference efﬁciently solved using dynamic programming. model latent variables observation assumed conditionally independent given target states. work different previous approaches terms utilized graphical model efﬁciency inference. first similar model also uses extra latent layer. however instead explicitly modeling latent variables directly learn latent variables data. second make conditional independence assumptions latent variables observations. instead extra edge make local graph fully connected. third although graph also presents many loops able transform cyclic graph linear-chain structure wherein exact inference tractable. exact inference graph requires passes messages across linear chain structure substantially efﬁcient method finally model interaction human objects feature level instead modeling object affordance many cases. consider aforementioned example. knowing action opening whether latent state refers opening microwave opening bottle depends opening action performed observed video i.e. latent state observation inter-dependent given action label. third potential characterizes transition score joint state comparing normal leverages latent variable modeling richer contextual information consecutive temporal segments. model contain transition action states also captures sub-level context using latent variables. target states. therefore parameters learned directly optimized activity recognition rather making joint estimation object affordance human activity. apply data-driven approach initializing latent variables hand labeling object affordance necessary model. results show model outperforms state-of-the-art approaches dataset graphical model proposed system illustrated fig. xk|xk sequence observations total number temporal segments video. goal predict likely underlying action sequence yk|yk corresponding activity label based observations. deﬁne global features extracted observation feature vector extracted segment form quite ﬂexible. collections data different sources e.g. simple sensor readings human locations human poses object locations. observations highly correlated other e.g. wearable accelerate meters motion sensors would highly correlated. discriminative nature model need model correlation among observations. deﬁne zk|zk latent variables model. latent variables implicitly learned data considered modeling sub-level semantics actions. clarity could imagine refers action opening. then joint describe opening microwave describe opening bottle. note sub-types opening actions differ greatly observed videos. however latent variables allow capture large variations action. ﬁrst potential measures score making observation joint-state assignment deﬁne function maps input data feature space. matrix contains model parameters. potential models full connectivity among avoids making conditional independence assumptions. accurate structure conditionally independent given potential function evaluates matching score joint states input score equals un-normalized joint probability space. objective function rewritten general linear form therefore model class log-linear models. note necessary explicitly model latent variables; rather latent variables automatically learned training data. theoretically latent variables represent form data e.g. time duration action primitives long data used facilitate task. optimization latent model however max-margin approach learning parameters graphical model. given training examples would like learn model parameters produce activity label action labels given test input note activities action labels observed training. latent variables unobserved automatically inferred training process. object function viewed generalized form previous work recognize sequence actions. performed simply setting leaving graphical structure unchanged. learning framework tracks incorrectly predicted actions regardless activities. directly optimizing possible loss function involves computing argmax following substitute loss function margin rescaling surrogate serves upper-bound loss function. converge local minimum. initialization random variables therefore great importance. compare three initialization strategies paper. details latent variable initialization discussed section vi-b. notice graphical model many loops general makes exact inference intractable. because graph complies semi-markov property show beneﬁt structure obtain efﬁcient inference learning. generally solving np-hard problem requires evaluation objective function exponential number state sequences. exact inference preferable guaranteed global optimum. however exact inference usually applied efﬁciently graph acyclic. contrast approximate inference suitable loopy graphs take longer converge likely obtain local optimum. although graph contains loops transform graph linear-chain structure exact inference becomes tractable. collapse latent variable single factor edges among become internal factor node transition edges collapse single transition edge. results typical linear-chain cardinality nodes ny×nz×na. linear-chain exact inference efﬁciently performed using dynamic programming function evaluated iteratively across entire sequence. iteration record joint state contributes max. last segment computed optimal assignment segment computed methods evaluated benchmark datasets i.e. cad- cad- datasets contain sequences color depth images collected rgb-d sensor. skeleton joints person obtained using openni. datasets quite different other; therefore generalizability methods. cad- dataset consists human action labels activity labels. actions include rinsing mouth brushing teeth wearing contact lens talking phone drinking water opening pill container cooking cooking talking couch relaxing couch writing white board working computer. actions performed different subjects different environments i.e. kitchen bedroom bathroom living room ofﬁce. total dataset includes approximately videos video contains action label. contrast cad- dataset contains rgbvideos video contains activity sequence actions. total activities deﬁned dataset including making cereal taking medicine stacking objects unstacking objects microwaving food picking objects cleaning objects taking food arranging objects meal. fig. shows various sample images activities. addition dataset also consists sub-level actions i.e. reaching moving pouring eating drinking opening placing closing scrubbing null. objects cad- automatically detected locations objects also provided dataset. datasets challenging following aspects. activities dataset performed four different actors. actors behave quite differently e.g. terms left right handed viewed front view side view sitting standing. large variation even action e.g. action opening refer opening bottle opening microwave. although actions label appear signiﬁcantly different video. partial full occlusion also challenging aspect dataset. e.g. certain videos actors’ legs completely occluded table objects frequently occluded objects. makes difﬁcult obtain accurate object generated data noisy. number recent approaches evaluated datasets; results directly compared. ensure fair comparison input features extracted following speciﬁcally object features object-object interaction features object-subject relation features temporal object subject features cad- extract complete features object locations provided dataset. cad- dataset skeletal features extracted object information. inference problem using similarly third term solved adding evidence graph applying inference using exact inference tractable graphical model terms computed efﬁciently. note summation convex concave function. solved concave-convex procedure substituting concave function tangent hyperplane function serves upper bound concave function concave term transformed linear function. thus becomes convex again. note exponential number constraints solved using cutting-plane method another intuitive method understanding cccp algorithm consider algorithm solves learning problem incomplete data using expectationmaximization training data latent variables unknown. start initializing latent variables. latent variables data become complete. then standard structured-svm learn model parameters subsequently update latent states using parameters learned iteration continues convergence. cccp algorithm decreases objective function iteration. however algorithm cannot guarantee global optimum. avoid trapped local minimum present three different initialization strategies details presented section vi-b. note inference algorithm extensively used learning. able compute exact inference transforming loopy graph linear-chain graph learning algorithm much faster accurate compared approaches approximate inference. implemented proposed model denoted full model along three variations. speciﬁcally ﬁrst model recognizes low-level actions second model recognizes high-level activities third model recognizes activities based actions. models evaluated different datasets. results different models compared gain insight research questions full model also shown outperform state-of-the-art methods. section describe three baseline models detail followed introduction full model. note models ﬁrst evaluated cad- dataset. test generalizability model experiments repeated using cad- dataset. note cad- dataset contains activity labels additional labels indicate environments. experiments treat additional labels activities; thus model structure left unchanged compared experiments cad-. difference jointly model actions environments instead activities. recognize low-level actions ﬁrst model adopted previous work predicts action labels based video sequence. model singlelayer approach contains low-level layer nodes. setting weight zero model focuses predicting correct action labels regardless activity label; therefore model considered special case full model. parameters model learned structured-svm framework margin rescaling surrogate loss. optimization -slack algorithm described initialize latent states cad- adopt three different initialization strategies. random initialization. latent states randomly selected. data-driven approach. apply clustering input data number clusters number latent states. k-means times. then choose best clustering results based minimal within-cluster distances. labels clusters assigned initial latent states. initialized object affordance. object affordance labels provided cad- dataset used training apply k-means clustering upon affordance labels. affordance labels categorical -of-n encoding transform affordance labels binary values clustering. cad- dataset contain affordance labels therefore latent variables initialized data-driven approach. recognize high-level activities second model contains single layer recognizing activities i.e. disregard layer actions; instead learn direct mapping video features activity labels. similar ﬁrst model parameters learned structuredsvm model contains transition. recognize activities based action sequences approach built upon ﬁrst baseline. based inferred action labels learn model classify activities. extract unigram bigram features based action sequence well occlusion features. model parameters estimated variation multi-class latent layer augmented model. approach actions activities recognized succession. joint estimation activity actions using hierarchical approach approach refers proposed model paper. instead successively recognizing actions activities model uses hierarchical framework make joint predictions activity action labels. compare different segmentation methods videos cad- dataset. ﬁrst method ground truth segmentation manually annotated. second segmentation apply motion-based approach i.e. extract spatial-temporal features frames similar frames grouped together using graph-based approach form segments. cad- apply uniform segmentation enable fair comparison methods. methods evaluated cad- cad- datasets. datasets quite different other used test results generalized data. performance methods datasets reported section vi-d. model evaluated -fold cross-validation. folds split based subjects. choose hyperparameters i.e. number latent states segmentation methods used subjects training subject validation subject testing. optimal hyperparameters chosen performance model testing measured another cross-validation process i.e. training using videos persons testing person. cross-validation performed times. observe generalization model across different data sets results averaged across folds. paper accuracy precision recall f-score reported enable comparison results. cad- dataset half instances reaching moving. therefore consider precision recall relatively better evaluation criteria accuracy remain meaningful despite class imbalance. experimental results compare performance different models. table shows performance models testing dataset. performances action activity recognition reported. comparison results ground-truth segmentation motion-based segmentation reported. table shows performance testing cad- dataset. importance hierarchical model. table single layer refers second baseline approach wherein learn direct mapping video-level features activity labels. intermediate layer labels. single layer approach achieves average performance segmentation methods large standard error approximately contrast hierarchical approaches outperform single layer approach least percentage points using ground-truth segmentation percentage points using motion-based segmentation. incorporating layer action labels signiﬁcant improvements terms recognizing activities. therefore temporal information transitions actions important aspect activity recognition. table shows results using cad- dataset similar experiment settings; however goal predict actions together environment. f-score environment prediction increased percentage points using hierarchical approach signiﬁcantly better single-layer approach. hierarchical approaches also exhibit signiﬁcant improvements terms precision recall. increase mean percentage points reduced standard error rate. proposed model model without augmenting latent variables table shows full model outperforms latent terms recognition actions activities. notably adding latent variable precision recall activity increased percentage points respectively using groundtruth segmentation. using motion-based segmentation performance full model activity increased percentage points terms precision percentage points terms recall. improvement signiﬁcant using latent variables. note latent model special case full model i.e. latent equivalent full model latent state. here list models separately illustrate effect using multiple latent states. contrast table shows performance full model model starts overﬁtting data latent states applied model i.e. latent achieves best performance. this model quite ﬂexible used data varying levels complexity simply adjusting number latent states model. importance jointly modeling activity action. table refers combination ﬁrst third baseline approaches used two-step approach successively recognize actions activities. method shows signiﬁcant improvement single layer approach. however approach signiﬁcantly outperformed proposed hierarchical method using segmentation methods. notably activity recognition fscore increased percentage points using proposed model increase percentage points terms precision percentage points terms recall. action recognition performance gain terms f-score approximately percentage points includes signiﬁcant improvements precision recall. full model allows interaction low-level high-level layers learning inference labels hierarchy jointly estimated making predictions. similar results found using cad- dataset table note performance largely increased using full model. f-score increased percentage points predicting action environment labels. comparable approaches following conduct similar experiments cad- dataset group actions based environment labels separate model learned tested groups. results experiments reported table iii. note model outperforms environments. compared state model outperforms environments. average precision model recall model outperforms percentage points achieving precision table compares performance different approaches cad- datasets. similar koppula two-step approach infer high-level activity labels actions estimated. beneﬁting joint estimation action activity full model outperforms state-of-the-art models terms action activity recognition tasks. notably using ground-truth segmentation f-score improved approximately percentage points recognizing actions. based motion segmentation activity recognition performance improved percentage points terms f-score. fig. shows confusion matrix action activity classiﬁcation results. difﬁcult action class scrubbing. task sometimes confused reaching placing. overall performance activity recognition good activities correctly classiﬁed. difﬁcult case distinguish stacking objects arranging objects. overall high values found diagonal using segmentation methods demonstrates good performance paper present hierarchical approach simultaneously recognizes actions activities based rgb-d data. interactions actions activities captured hidden-state framework. framework latent variables exploit underlying structures actions. prediction based joint interaction activities actions contrast traditional approach focuses them. results show signiﬁcant improvement using hierarchical model compared using single-layered approach. results also demonstrate effectiveness adding latent layer model importance jointly estimating actions activities. finally show proposed hierarchical approach outperforms state-of-theart methods benchmark datasets. performance cad- dataset. note experiments actions grouped based locations separate model trained tested based environment label; therefore results different table ryoo human activity prediction early recognition ongoing activities streaming videos proceedings ieee international conference computer vision ieee kasteren englebienne kr¨ose activity recognition using semi-markov models real world smart home datasets journal ambient intelligence smart environments vol. two-layered approach recognize high-level human activities proceedings ieee international symposium robot human interactive communication ieee koppula saxena learning spatio-temporal structure rgb-d videos human activity detection anticipation proceedings international conference machine learning amirabdollahian bedaf bormann draper evers p´erez gelderblom ruiz hewson others assistive technology design development acceptable robotics companions ageing years paladyn journal behavioral robotics laptev marszalek schmid rozenfeld learning realistic human actions movies proceedings ieee conference computer vision pattern recognition shah learning human actions information maximization proceedings ieee conference computer vision pattern recognition ryoo aggarwal spatio-temporal relationship match video structure comparison recognition complex human activities proceedings ieee conference computer vision pattern recognition bormann zw¨olfer kr¨ose multi-user identiﬁcation efﬁcient user approaching fusing robot ambient sensors proceedings ieee international conference robotics automation kelley nicolescu tavakkoli king bebis understanding human intentions hidden markov models autonomous mobile robots proceedings international conference human-robot interaction sheng human daily activity recognition robotassisted living using multi-sensor fusion proceedings ieee international conference robotics automation ieee chen chen shinh huang wang chen active-learning assisted self-reconﬁgurable activity recognition dynamic environment proceedings ieee international conference robotics automation ieee wang mori max-margin hidden conditional random ﬁelds human action recognition proceedings ieee conference computer vision pattern recognition ieee rother kolmogorov lempitsky szummer optimizing binary mrfs extended roof duality proceedings ieee conference computer vision pattern recognition ieee tang fei-fei koller learning latent temporal structure complex event detection proceedings ieee conference computer vision pattern recognition ieee ninghang currently ph.d. candidate informatics institute university amsterdam netherlands. research interests machine learning robot vision focus human activity recognition data fusion. received m.sc. artiﬁcial intelligence university b.sc. software engineering xidian university china trainee gwenn englebienne received ph.d. degree computer science university manchester since focused automated analysis human behavior university amsterdam developed computer vision techniques tracking humans across large camera networks machine learning techniques model human behavior networks simple sensors. main research interests models human behavior especially interaction humans environment intelligent systems. zhongyu received b.sc. m.sc. degrees xidian university xi’an china respectively. currently pursuing ph.d. degree intelligent systems amsterdam university amsterdam netherlands. main research interests include computer vision image processing machine learning. kr¨ose professor ambient robotics university amsterdam professor digital life amsterdam university applied science. research focuses robotics interactive smart devices expected widely applied smart services ensure health safety well-being security comfort users. ﬁelds artiﬁcial intelligence autonomous systems published papers scientiﬁc journals edited books special issues submitted conference papers. owns patent multi-camera surveillance. member ieee dutch pattern recognition association dutch association.", "year": 2015}