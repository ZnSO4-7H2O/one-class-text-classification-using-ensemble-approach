{"title": "Variational hybridization and transformation for large inaccurate  noisy-or networks", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Variational inference provides approximations to the computationally intractable posterior distribution in Bayesian networks. A prominent medical application of noisy-or Bayesian network is to infer potential diseases given observed symptoms. Previous studies focus on approximating a handful of complicated pathological cases using variational transformation. Our goal is to use variational transformation as part of a novel hybridized inference for serving reliable and real time diagnosis at web scale. We propose a hybridized inference that allows variational parameters to be estimated without disease posteriors or priors, making the inference faster and much of its computation recyclable. In addition, we propose a transformation ranking algorithm that is very stable to large variances in network prior probabilities, a common issue that arises in medical applications of Bayesian networks. In experiments, we perform comparative study on a large real life medical network and scalability study on a much larger (36,000x) synthesized network.", "text": "variational inference provides approximations computationally intractable posterior distribution bayesian networks. prominent medical application noisy-or bayesian network infer potential diseases given observed symptoms. previous studies focus approximating handful complicated pathological cases using variational transformation. goal variational transformation part novel hybridized inference serving reliable real time diagnosis scale. propose hybridized inference allows variational parameters estimated without disease posteriors priors making inference faster much computation recyclable. addition propose transformation ranking algorithm stable large variances network prior probabilities common issue arises medical applications bayesian networks. experiments perform comparative study large real life medical network scalability study much larger synthesized network. noisy-or bayesian network popular class statistical models modeling observable events unobserved potential causes. best known medical applications nobn quick medical reference qmr-dt describes expert-assessed relationships observable binary symptom variables binary latent disease variables illustrated figure improve variational inference large qmr-dt style nobn areas scalability stability accuracy previously unattainable untested levels. part medical messaging inference goal perform reliable real time diagnosis scale. figure shows messaging bot’s interface. ongoing project aims serve substantial portion internet users experience health issues reliable disease diagnosis accurate accessible text-based searches searches emphasize retrieval similarity lack clinical technicality developing completed organic non-scripted dialogues qualiﬁed human testers. assessed licensed doctors network plans cover conceivable human diseases health conditions approximately according revision international statistical classiﬁcation diseases related health problems best knowledge aforementioned scales make largest medical application noisy-or bayesian networks. figure graphical model structure qmr-dt. shaded round nodes observed nodes variables binary. screenshot diagnosis bot. running time comparison exact quickscore variational inference provided variational authors’ implementation. recent advances modern machine learning artiﬁcial intelligence quickly proliferate beyond traditional bayesian framework. mission critical applications medical diagnosis prefers bayesian network-based approach reasoning instead entirely data driven approach. reasons traceable outcome easy debuggability provenance. data source unreliability scarcity also prevent medical applications taking full advantage large body data driven algorithms quickly accelerated larger datasets speech recognition example caroli disease fewer recorded cases worldwide making almost impossible gather/label data points. hand disease rare deserve attention ethical perspective even -in- chance translates suffering individuals worldwide. academic perspective understanding rare diseases brings irreplaceable medical knowledge. expert-assessed probability observing symptom given disease denoted denote diseases could cause non-zero probability. like qmr-dt assume prior probability disease without observing symptoms. deﬁne notations respectively. typical diagnosis session user ﬁrst inputs positive negative ﬁndings model performs inference calculate crux deriving conditional intractable intractability motivates investigations approximation inference algorithms. variational method mean ﬁeld local approximation hybrid approximation algorithms. describe variational approximation show inverse prior odds disease. order partial derivatives derived mechanically. figure illustrates complexity exact variational inference real application. discussion existing inference algorithms related works section inaccurate hidden variable prior recognized often avoided issue nobn. inaccuracy disease prior among likely errors constructing nobn medical applications. real life disease priors span several orders magnitude. example acne affects teenagers western world syndromes like caroli disease historical infection rates less likely even medical experts statistical estimators misjudge prior probability order magnitude relative rare common diseases. beneﬁcial obtain fast accurate variational algorithms resistant large variances disease priors. following sections propose inference algorithms greatly immunize current variational inference inaccuracy disease priors. partition employed realization classic hybrid paradigm balancing accuracy runtime entire applying different posterior estimators controlling cardinalities. main drawbacks prevent fulﬁlling scalability stability requirements building diagnostic bot. first equation estimates ξmin using exactly treated disease posterior words uses substantial portion evidence priming unaudited priors ﬁrst reﬁnes posterior probabilities using smaller leftover portion evidence. propose variational-ﬁrst hybridization issues. described algorithm later performs inference calculating ξmin relies disease priors instead posteriors. therefore calculation invariant ﬁndings make allows caching ξmin values leads faster inference summarized table equation explicitly expresses joint variational evidence given ﬁndings using concepdue lack prior knowledge. however approach competitive certain range disease priors prior/posterior-free estimator ξmin independent disease prior posterior allows ξmin server grows. hand proposed perform variational step constant time w.r.t. proposed estimator ξmin hybridization schemes execute variational transformation constant time w.r.t. table summarizes practical efﬁciency proposed variational hybridization used either estimator ξmin. term optimization cost using second order algorithms like newton’s method. note table compares cost variational step. evaluate overall inference cost different inferencers experiments section. table detailed temporal complexities proposed variational parameter estimation terms entries big-o complexity. note although equivalent variational parameter estimation higher overall inference complexity difference equation addition inference formula ξmin solver third component variational inference critical posterior accuracy transformation ranking algorithm partitions simple greedy heuristic ordering algorithm rank order transformation based greedy local optimum minimizing overall variational upper bound minimizing overall variational upper bound naturally commendable goal. given inaccuracy widely-ranged disease priors ordering algorithm fender uncertainty effectively gdo? simplify discussion assume uniform pair random variable |d|} drawn independently choice rather inconsequential discussion. reasonable uniform mean distribution introduces gaussian-like variance without breaking positive deﬁnite constraint pi’s. desire establish ordering algorithm minimizes variance posterior predictions ﬁrst step show existence. formally stated proved proposition proposition +|}. exists every proposition states existence construction involves calculating ξmin construction ordering algorithm slower actual variational transformation show simplify construction algorithm ξmin since strategy minimizes every must stable globally well. therefore arrive extremely simple variational transformation algorithm sort refer strategy ﬁnding-degree order combination presence absence subsets junction tree algorithms efﬁcient practice maximal clique size moralized network. quickscore reduces temporal complexity exponential function quantity substantially smaller make inference practical common various approximate inference methods proposed place quickscore processing expensive inference cases nobn variational inference nobn developed reduces cost computing applying variational transformation subset variational evidence incorporated posterior probability general approximation methods applied nobn include loopy belief propagation mean ﬁeld approximation importance sampling based sampling methods also considered processing ﬁnding sequentially arguably similar style realistic patient-to-doctor diagnosis. evaluate proposed inference algorithms real-world symptom-disease nobn called qmr-like medical nobn constructed multiple reliable medical knowledge sources amended medical experts. unlike qmr-dt focuses symptoms diseases related maternal infant care. anonymous submission authors refrain discussing details listing vital statistics table unavailability proprietary qmr-dt network anonymized version available however aqmr anonymizes symptom disease node names randomizes qmr-dt’s probabilities. medical connotation removed difﬁcult conﬁdently generate user queries label disease likely disease given symptoms according medical experts). previous works working aqmr face issue since require use-cases. example focus recovering network structure parameters; focuses inference time relative divergence approximate inference outcome exact inference outcome. also evaluate algorithm’s scalability artiﬁcially generated much larger scale qmr-dt. hidden disease nodes approximately total number diseases icd- classiﬁcation. figure compares various inference algorithms baseline proposed variational-ﬁrst hybridization consistently faster methods. despite variational cost joint hybridization slowest repeated negative evidence computation equation jj+ppf signiﬁcantly faster jj+cvx simpliﬁed ξmin estimation. figure compares inference accuracies simulate wide-ranged inaccuracy disease priors scramble samples drawn uniform mean distribution different values. total test four sets queries different kinds false positive ﬁndings. query contains random caused labeled disease. false symptoms caused common chronic diseases chronic symptoms often mentioned inadvertently patients doctor’s visit making diagnosis harder. type false chronic ratio false symptoms caused diseases similar labeled disease diseases share several symptoms often severity symptoms decisive telling apart. four sets queries query consists average eight four f−’s. shown figure vfh+cvx+fdo performs better jj+cvx+gdo baseline across wide range even outperforms exact quickscore certain values. vfh+ppf+fdo suffers suboptimal ξmin estimations. vfh+ppf+fdo comparable jj+cvx+jj lower range values. lastly jh+cvx+fdo closest performance portfolio quickscore quite competitive. figure accuracy comparisons x-axis mean value transforms ﬁndings variationally. random. chronic. chronic. confuse. measure top- accuracies. measure corresponding top- accuracies. variational transformation. proposed algorithms greatly immunize current variational inference algorithms inaccuracies widely-ranged hidden prior probabilities common issue arises modern medical applications bayesian networks. future plan investigate applicability proposed algorithms general bayesian networks. references amodei anubhai battenberg case casper catanzaro chen chrzanowski coates diamos elsen engel fougner hannun legresley narang ozair prenger raiman satheesh seetapun sengupta wang wang wang xiao yogatama zhan zhu. deep speech end-to-end speech recognition english mandarin. corr abs/. http//arxiv.org/abs/.. cheng greiner kelly bell liu. learning bayesian networks data informationtheory based approach. artiﬁcial intelligence issn http //dx.doi.org/./s--. http//www.sciencedirect.com/science/ article/pii/s. cooper. computational complexity probabilistic inference using bayesian belief networks artif. intell. mar. issn ./--d. http//dx.doi.org/./--d. jernite halpern sontag. discovering hidden variables noisy-or networks using quartet tests. advances neural information processing systems pages liao learning bayesian network parameters incomplete data domain knowledge. pattern recognition issn http//dx.doi.org/./j.patcog.... http//www.sciencedirect.com/science/article/pii/s. middleton shwe heckerman henrion horvitz lehmann cooper. probabilistic diagnosis using reformulation internist-/qmr knowledge base. methods information medicine riggelsen. learning parameters bayesian networks incomplete data importance sampling. international journal approximate reasoning issn http//dx. doi.org/./j.ijar.... http//www.sciencedirect.com/science/article/ pii/sx.", "year": 2016}