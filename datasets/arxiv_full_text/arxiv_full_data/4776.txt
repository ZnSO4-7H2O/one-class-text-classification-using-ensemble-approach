{"title": "ASlib: A Benchmark Library for Algorithm Selection", "tag": ["cs.AI", "cs.LG"], "abstract": "The task of algorithm selection involves choosing an algorithm from a set of algorithms on a per-instance basis in order to exploit the varying performance of algorithms over a set of instances. The algorithm selection problem is attracting increasing attention from researchers and practitioners in AI. Years of fruitful applications in a number of domains have resulted in a large amount of data, but the community lacks a standard format or repository for this data. This situation makes it difficult to share and compare different approaches effectively, as is done in other, more established fields. It also unnecessarily hinders new researchers who want to work in this area. To address this problem, we introduce a standardized format for representing algorithm selection scenarios and a repository that contains a growing number of data sets from the literature. Our format has been designed to be able to express a wide variety of different scenarios. Demonstrating the breadth and power of our platform, we describe a set of example experiments that build and evaluate algorithm selection models through a common interface. The results display the potential of algorithm selection to achieve significant performance improvements across a broad range of problems and algorithms.", "text": "task algorithm selection involves choosing algorithm algorithms per-instance basis order exploit varying performance algorithms instances. algorithm selection problem attracting increasing attention researchers practitioners years fruitful applications number domains resulted large amount data community lacks standard format repository data. situation makes diﬃcult share compare diﬀerent approaches eﬀectively done other established ﬁelds. also unnecessarily hinders researchers want work area. address problem introduce standardized format representing algorithm selection scenarios repository contains growing number data sets literature. format designed able express wide variety diﬀerent scenarios. demonstrate breadth power platform describe study builds evaluates algorithm selection models common interface. results display potential algorithm selection achieve signiﬁcant performance improvements across broad range problems algorithms. kerschkeuni-muenster.de larskocs.ubc.ca lindauercs.uni-freiburg.de yuri.malitskygmail.com afrechetcs.ubc.ca hooscs.ubc.ca fhcs.uni-freiburg.de kevinlbcs.ubc.ca tierneydsor.de j.vanschorentue.nl although np-complete problems widely believed intractable worst case often possible solve even large instances problems arise practice. fortunate problems ubiquitous artiﬁcial intelligence applications. thus emerged large subﬁeld devoted advancement analysis heuristic algorithms attacking hard computational problems. indeed quite surprisingly subﬁeld made consistent substantial progress past decades newest algorithms quickly solving benchmark problems beyond reach recently. results international competitions provide paradigmatic example phenomenon. indeed importance competition series gone beyond documenting progress achieved community solving diﬃcult application-relevant instances— instrumental driving research itself helping community coalesce around shared benchmark instances providing impartial basis determining ideas yield biggest performance gains. central premise events like competitions research community ought build identify reward single solvers achieve strong across-the-board performance. however quest appears quixotic hard computational problems admit multiple solution approaches none dominates alternatives across multiple problem instances. particular fact observed hold across wide variety applications including propositional satisﬁability constraint satisfaction planning supervised machine learning alternative accept single algorithm oﬀer best performance instances instead identify portfolio complementary algorithms strategy choosing appeal idea consider results sequential application track competition. best submitted solvers lingeling solved instances. however could somehow choose best among solvers per-instance basis would able solve instances. research algorithm selection problem demonstrated practical feasibility using machine learning task. fact although practical algorithm selectors occasionally choose suboptimal algorithms performance close oracle always makes best choice. area began attract considerable attention methods based algorithm selection began outperform standalone solvers competitions algorithm selectors since come dominate state many problems including planning max-sat demonstrated algorithm competitions originally intended non-portfoliobased solvers. given rise variety challenges ﬁeld. first benchmarks selected competitions tend emphasize problem instances currently hard existing standalone algorithms rather wide range easy hard instances would encountered practice relatedly benchmark sets change year year making diﬃcult assess progress algorithm selectors time. second although competitions often require entrants publish source code none require entries based algorithm selectors publish code used construct algorithm selector adhere consistent input format. third overwhelming competition victories algorithm selectors make diﬃcult standalone solver designs attention deserve thus create resentment among solver authors. concerns backlash participation portfolio-based solvers competitions; example starting solvers explicitly combine component algorithms excluded competitions. similar reasons speciﬁc prize non-portfolio solvers learning track international planning competition natural solution challenges evaluate algorithm selectors terms rather trying shoehorn competitions intended standalone solvers. article written large authors active research algorithm selectors aims advance goal introducing speciﬁcations tools designed standardize facilitate evaluations. speciﬁcally propose benchmark library called aslib tailored cross-domain evaluation algorithm selection techniques. section provide summary data format speciﬁcation used aslib covers wide variety foreseeable evaluations. date instantiated speciﬁcation benchmarks diﬀerent problem domains describe section however intend aslib grow evolve time. thus article accompanied online repository accepts submissions researcher. indeed already included scenarios submitted contributors outside core group aslib maintainers. system automatically checks newly submitted datasets verify adhere speciﬁcations provides overview data including results straightforward algorithm selection approaches based regression clustering classiﬁcation. provide examples automatically-generated overviews benchmark results sections code used parse format ﬁles explore algorithm selection scenarios benchmark machine learning models publicly available package dubbed aslib. section discuss recent examples competition settings using aslib along advantages disadvantages. overall main objective creating aslib algorithm competition allow researchers compare algorithms systematically fairly without replicate someone else’s system personally collect data. hope help community obtain unbiased understanding strengths weaknesses diﬀerent methodologies thus improve current state per-instance algorithm selection. rice ﬁrst formalize idea selecting among diﬀerent algorithms per-instance basis. referred problem simply algorithm selection prefer precise term per-instance algorithm selection avoid confusion task selecting several given algorithms optimize performance given distribution instances. per-instance algorithm selection problem mapping optimizes ei∼dm) i.e. expected performance measure instances distributed according achieved running selected algorithm mapped algorithm using machine learning techniques. however computation instance features incurs additional costs considered performance measure many ways tackling per-instance algorithm selection related problems. almost contemporary approaches machine learning build predictors behaviour given algorithms function instance features. general strategy involve single learned model complex combination several which given problem instance solve used decide algorithm combination algorithms choose. perhaps natural select single algorithm solving given problem instance. approach e.g. used satzilla argosmart salsa eureka systems. main disadvantage mitigating poor selection—the system cannot recover algorithm chose problem instance exhibits poor performance. alternatively seek schedule determines ordering time budget according subset algorithms portfolio; usually schedule chosen reﬂects expected performance given algorithms approaches computation schedule treated optimization problem aims maximize e.g. number problem instances solved within timeout. stochastic algorithms question whether restart algorithm arises opening possibility schedules contain single algorithm restarted several times instead performing algorithm selection starting solve problem selection also carried repeatedly instance solved taking account information revealed algorithm run. methods monitor execution chosen algorithm take remedial action performance deviates expected perform selection repeatedly subproblems given instance kinds decisions selection process asked produce drive choice machine learning models perform selection. single algorithm train classiﬁcation model makes exactly prediction. renders algorithm selection conceptually quite simple—only single machine learning model needs trained determine algorithm choose alternatives using classiﬁcation model select single algorithm given instance using regression models predict performance algorithm portfolio. regression approach adopted several systems approaches include clustering techniques partition problem instances feature space make decisions partition separately hierarchical models make series decisions cost-sensitive support vector machines cost-sensitive decision forests order make decisions algorithm selection systems need information problem instance solve performance algorithms given portfolio. extraction information—the features used machine learning techniques used selection—incurs overhead required single algorithm used instances regardless instance characteristics. therefore desirable extract information cheaply approaches past performance algorithms portfolio basis selecting given problem instance approach beneﬁt required data collected minimal overhead algorithms executed. work well performance algorithms similar broad ranges problem instances. however assumption satisﬁed informative features needed. turning richer instance-speciﬁc features commonly used features include number variables problem instance properties variable domains deeper analysis involve properties graph representations derived input instance properties encodings diﬀerent problems addition features extracted short runs solvers given problem instance. examples probing features include number search nodes explored within certain time fraction partial solutions disallowed certain constraint clause average depth reached backtracking required characteristics local minima found quickly using local search. probing features usually expensive compute features obtained shallow analysis instance speciﬁcation also powerful thus used many authors continuous blackbox optimization algorithm selection performed based exploratory landscape analysis approach deﬁnes numerical features describe landscapes optimization problems. examples range simple features describe distribution sampled objective values expensive probing features based local search. finally area meta-learning features known meta-features. include statistical information-theoretical measures landmarkers sampling landmarkers model-based meta-features meta-features past performance measurements many machine learning algorithms available online machine learning platform openml contrast aslib however openml designed allow cross-domain evaluation algorithm selection techniques. problem closely related algorithm selection algorithm conﬁguration problem given parameterized algorithm problem instances performance measure parameter setting optimizes formal deﬁnition). algorithm selection operates ﬁnite sets algorithms algorithm conﬁguration operates combinatorial space algorithm’s parameter settings. general algorithm conﬁguration methods paramils i/f-race smac yielded substantial performance improvements state-of-the-art algorithms several benchmarks including sat-based formal veriﬁcation mixed integer programming planning combined selection hyperparameter optimization machine learning algorithms joint architecture hyperparameter search deep learning algorithm conﬁguration selection complementary since conﬁguration identify algorithms peak performance homogeneous benchmarks selection choose among specialized algorithms. consequently several possibilities exist combining algorithm conﬁguration selection algorithm conﬁguration counterpart aslib aclib contrast aslib infeasible aclib store performance data possible parameter conﬁgurations often number therefore experiment aclib includes runs target algorithms diﬀerent conﬁgurations hence experiments aclib costly experiments aslib algorithm runs necessary. furthermore contrast aclib aslib include actual instances binaries algorithms. therefore aslib provide generate performance data required aclib consequence need assess performance target algorithm conﬁgurations arising within conﬁguration process. however aslib aclib combined generating actual performance data based resources aclib creating aslib scenario selects diﬀerent solver conﬁgurations per-instance basis. propose data format speciﬁcation algorithm selection scenarios i.e. instances per-instance algorithm selection problem. format resulting data repository allow fair convenient scientiﬁc evaluation comparison algorithm selectors. algorithm conﬁguration need expensive runs indeed causes problem research. mitigating oﬀered fast-to-evaluate surrogate algorithm conﬁguration benchmarks putation occur several stages produces group features. furthermore later stages depend results earlier ones. feature group incurs cost e.g. runtime. features required cost purpose library provide information necessary performing algorithm selection experiments using given scenario data. user need actually algorithms instances performance data already precomputed. drastically reduces time required executing studies i.e. runtime studies dominated time required learning applying algorithms instances also means results perfectly reproducible; example algorithm selection scenarios release version library shown table assembled represent diverse selection problem settings covers wide range problem domains types algorithms sat-hand sat-indu sat-rand sat-all sat-hand sat-indu sat-rand sat-indu qbf- qbf- maxsat-pms maxsat-pms-indu csp- csp-mzn- proteus- asp-potassco premar-astar- features problem instances. scenarios include problems broadly studied context algorithm selection techniques well recent ones scenarios taken publications report performance improvements algorithm selection consist algorithms virtual best solver signiﬁcantly better single best solver. therefore problems makes sense seek performance improvements algorithm selection. scenarios available online platform propositional satisﬁability problem classic np-complete problem consists determining existence assignment values variables boolean formula formula true. widely studied many applications including formal veriﬁcation scheduling scenarios characterized high level maturity diversity terms solvers features instances. scenario involves highly diverse solvers many developed several years. addition features probably best-studied feature among scenarios; includes static probing features organized many diﬀerent feature groups. instance sets used various scenarios range randomly-generated ones real-world instances submitted industry. quantiﬁed boolean formula formula propositional logic universal existential quantiﬁers variable formula. solver ﬁnds variable assignments makes formula true proves exist. pspace-complete problem solvers exhibit wide range performance characteristics. qbf- data comes solver evaluation consists instances main small hard random tracks. qbf- data comes application track gallery instance features computed using aqme system described detail pulina solvers qbf- come aqme system well whereas solvers qbf- ones submitted application track gallery. maxsat optimization version previously introduced problem aims variable assignment maximizes number satisﬁed clauses. maxsat problem representation used eﬀectively encode number real-world problems fpga routing software package installation among others permits reasoning optimality feasibility. particular scenarios focus partial maxsat problem maxsat-pms scenario composed collection random crafted industrial instances maxsat evaluation techniques used solve various instances scenario complementary other leading substantial performance single best virtual best solver. furthermore solvers diﬀerent performance characteristics algorithm selection approaches must accurate choices mistake heavily penalized. recent maxsat-pms-indu built performance data industrial track partial maxsat problems maxsat evaluation. algorithms provides larger solvers maxsat-pms. however diﬀerent parameterizations solvers e.g. four diﬀerent variants ahms subsets strongly correlated solvers. performance single best virtual best solver larger maxsat-pms maxsat-pmsindu. concerned ﬁnding solutions constraint satisfaction problems—a task np-complete. learning context constraint solving technique previously unknown constraints implied problem speciﬁcation uncovered search subsequently used speed solving process. scenario csp- contains solvers employs lazy learning data heavily biased towards non-learning solver baseline good already. improving challenging task harder many scenarios. furthermore solvers share common core results scenario directly evaluates eﬃcacy speciﬁc technique diﬀerent contexts. recent scenario csp-mzn- provides larger instances algorithms instance features. instances algorithms come minizinc challenge international constraint solver competitions speciﬁcally instances come minizinc benchmark suite algorithms scenario participated minizinc challenge algorithms instances instance features described detail ﬁnal scenario proteus comes includes extremely diverse well-known solvers alongside competition-winning solvers solve xcsp instances. solvers accept diﬀerent conversions problem format provided separate algorithms. scenario solvers tested varying views problem. features scenario also unique include features given instance. potentially provides additional information selection approach would normally available solving csps. algorithm selection system high degree ﬂexibility choose perform part possible conversions thereby reducing solvers features also reducing overhead performing conversions feature computations. also synergies feature computation algorithm runs exploited e.g. conversion used feature computation chosen algorithm cost performing conversion incurred once. cases features computed representation another solved conversion costs incurred feature computation running algorithm. answer programming form declarative programming roots knowledge representation non-monotonic reasoning constraint solving. contrast many constraint solving domains provides rich simple declarative modeling language problems expressed. proven eﬃciently applicable many real-world applications e.g. product conﬁguration decision support nasa shuttle controllers synthesis multiprocessor systems industrial team building contrast scenarios algorithms scenario asppotassco automatically constructed adapted version hydra i.e. algorithms consists complementary conﬁgurations solver clasp instance features generated light-weight version clasp including static probing features organized feature groups; previously used algorithm selector claspfolio container pre-marshalling problem np-hard container stacking problem container terminals literature constructed algorithm selection scenario recent ida* approaches solving cpmp presented using instances literature. scenario described detail pre-marshalling scenario diﬀers scenarios algorithms highly homogeneous. algorithms parameterizations single symmetry breaking heuristic either using ida* search techniques stands sharp contrast diversity solvers present scenarios. scenario represents real-world time-sensitive problem operations research literature algorithm selection techniques large impact. online platform benchmark repository oﬀers scenario data ﬁles themselves. also provides many tables ﬁgures summarize them. pages automatically generated currently consist following parts platform’s summary page algorithms starts table listing summary statistics regarding performance status also indicate whether algorithm dominated another i.e. algorithm dominates another algorithm performance least equal instances outperforms least instance. useful reason include dominated algorithm portfolio. various visualizations plots scatter plot matrices correlation plots density plots enable inspection performance distribution correlation algorithms allowing reader better understand strengths weaknesses algorithm. plots conﬁgured scales often improves visual understanding heavy-tailed distributions figure shows boxplots cumulative distribution functions algorithms qbf- scenario example. boxplots summarize runtimes algorithm drawing %%-quantile sample i.e. smallest values greater equal runtimes. addition contains line showing median runtime well so-called whiskers i.e. lines connect runtimes within interquartile range %%-quantile respectively. observations even extreme runtimes considered outliers depicted single point outlier. cumulative distribution function plots hand show runtimes instances algorithm. point within plot consists plots show location mean distribution spread density multimodality properties distribution. addition reveal long took algorithm solve given instances. example qbf- scenario figure algorithm quantor ﬁnds solution quickly instances i.e. solves approximately instances less second. however succeed quickly often succeed all—it solved less instances. contrast ssolve usually needs longer solution time does best algorithms. behavior indicate algorithm requires ‘warm-up’ stage considered deploying left panel figure shows pairwise scatterplots qbf- scenario allowing easy comparison algorithm pairs instances given scenario. point represents problem instance within scenario location point cloud whether algorithm dominant majority instances whether relative performance strongly varies across instances. ﬁrst case identiﬁed cloud located either upper-left lower-right corner single scatterplot. case dominated algorithm could discarded portfolio. however type dominance relationship present potential realize performance improvements means per-instance algorithm selection. detecting correlation algorithm performance also interest analyzing strengths weaknesses given portfolio-based solver also present correlation matrix figure algorithms positive correlation likely redundant portfolio whereas pairs negative correlation likely complement other. calculate spearman’s correlation coeﬃcient ranks. blue boxes represent positive correlation boxes represent negative correlation shading indicates strength correlation. algorithms also clustered according values sorted similar algorithms appear together blocks. type clustering allows identiﬁcation algorithms highly correlated performance. figure shows correlation algorithms sat-all scenario. plot reveals four groups algorithms high correlations within group. desirable include single representative group reducing size entire portfolio four algorithms. algorithm runs characterise features giving summary statistics feature values status cost feature groups. table shows summary feature groups sat-rand scenario. scenario features feature group requirement. preprocessing group succeeded cases group feature group failed cases exceeding time memory limits even instances succeeded quite expensive information useful understand behavior features risky compute feature group much time must invest order obtain corresponding features? tables ﬁgures many generated online platform also accessible package aslib. functions highly conﬁgurable customisable. plan extend data analysis additional techniques measures algorithm performance table feature group summary sat-rand scenario. second column shows many features depend another feature group computed ﬁrst. percentages runstatus events followed summary statistics group costs. algorithm selectors scenarios. perform subset selection study identify important algorithms instance features scenarios. make claim presented experimental settings exhaustive achieve state-of-the-art algorithm selection performance; rather provide results used baseline comparison approaches. results framework general allow study algorithm selection approaches work well scenarios. llama toolkit version combination aslib package algorithm selection study. llama package facilitates many common algorithm selection approaches. particular enables access classiﬁcation regression clustering models algorithm selection—the three main approaches study. package interface machine learning models provided packages. parallelize benchmark experiments batchexperiments package. paper present aggregated benchmark results interested reader access full benchmark results http//aslib.net. study fully reproducible complete code generate results part aslib package. subset feature groups recommended authors respective scenario called default feature set. feature subset selection study used feature groups. detailed continuously updated information provided aslib website. linear model employ best-studied regression method. basic version models data using linear function parameters obtained minimizing squared loss. trees constructed cart algorithm handle classiﬁcation regression problem grown top-down manner divide training data rectangular regions axis-parallel splits interior node. splits selected considering label impurity reduction measured impurity function based e.g. gini index classiﬁcation squared loss regression. leaf nodes associate best constant label feature region prediction. random forests form ensemble ntree simpler trees bootstrapping multiple data sets original ﬁtting tree each. predictions made majority voting classiﬁcation averaging regression. furthermore ensemble members decorrelated randomly selecting candidate features split point tree maximally growing trees without early stopping pruning. support vector machines perform linear classiﬁcation transformed feature space maximizing margin positive negative examples. parameter controls trade-oﬀ size margin classiﬁcation loss. feature mapping implicitly built algorithm substituting regular inner product euclidean space so-called kernel. parameter property radial basis function kernel used here. xmeans clustering algorithm unsupervised learning algorithm study. extension well known k-means method adaptively select number clusters. k-means starts random cluster centroids assigns point nearest centroid iteratively recomputes cluster centroids cluster assignments convergence. details methods reader referred standard literature xmeans tuned hyperparameters ksvm randomforest within listed parameter ranges using random search iterations nested cross validation ensure unbiased performance results. parameters left default values. clustering algorithm number clusters preliminary experiments; exact number clusters determined internally xmeans. preprocessed data follows. removed constant-valued features imputed missing feature values mean non-missing values feature. clustering methods normalized range feature interval scenarios consider article contain continuous features. machine learning methods require normalized data perform internally missing performance values imputed using timeout value scenario. problem instance calculated total feature computation cost costs feature groups order speciﬁed deﬁnition scenario. problem instance solved feature computation considered cost feature groups solved furthermore runtime algorithms zero instances solved feature computation. instance solved feature computation added feature costs computed runtimes individual algorithms respective instances given runtimes checked whether speciﬁed timeout exceeded status corresponding algorithm accordingly. preprocessing runtimes include feature computation time allows focus algorithm selection system’s overall performance avoids overstating fraction instances would solved within time budget cases features expensive compute. note misclassiﬁcation penalty zero deﬁnition. single best solver actual solver overall best performance data speciﬁcally consider solver best figure presents summary results study. cases algorithm selection approaches performed better single best solver. expected this data sets come publications advocate algorithm selection systems. nevertheless signiﬁcant diﬀerences scenarios. almost algorithm selection approaches outperformed single best algorithm scenarios seem much harder algorithm selection. particular sat-indu scenario three approaches able achieve performance improvement. random regression forests stood quite clearly best overall approach achieving best performance datasets. line recent results showing strong performance model algorithm runtime prediction results also consistent original papers introducing datasets. figure summary results study. show much single best virtual best solver terms score closed model. value corresponds single best solver value virtual best. negative values indicate performance worse single best solver. within data best model annotated asterisk. shading emphasizes comparison green cells correspond values close whereas shows models performance. white shading indicates values close i.e. model performance single best algorithm. arithmetic mean model type across scenarios given parentheses model name. xmeans performed worst average. scenarios performed well particular sat-rand maxsat-pms proteus-. however sat-all sat-indu sat-indu xmeans performed worse single best solver. default subset instance features appears unfavorable xmeans industrial instances. provide insight algorithm selection scenarios applied forward selection algorithms features determine whether smaller subsets still achieve comparable performance. performed forward search independently algorithms features scenario. forward selection iterative selection algorithm whose ﬁrst iteration starts empty algorithms features; subsequent iteration greedily adds algorithm feature improves cross-validated score predictor. selection process terminates score improve least roughly corresponds improvement second instance. aspects experimental setup described before. used random regression forests best overall approach far. note selection results standard cross validation rather nested version result overconﬁdent performance estimates selected subsets accept caveat since goal study ranking features size selected sets complex nested approach would resulted multiple selected sets. sat-hand sat-indu sat-rand sat-all sat-hand sat-indu sat-rand sat-indu qbf- qbf- maxsat-pms maxsat-pms-indu csp- csp-mzn- proteus- asp-potassco premar-astar- tables present results forward selection algorithms features scenarios. usually number selected features small compared complete feature set. consistent observations roberts howe hutter found experiments instance features necessary reliably predict runtime algorithms. example sat-rand three features selected sat-hand sat-indu sat-rand sat-all sat-hand sat-indu sat-rand sat-indu qbf- qbf- maxsat-pms maxsat-pms-indu csp- csp-mzn- proteus- asp-potassco premar-astar- number algorithms forward selection also substantially reduced scenarios. scenarios expected scenarios consider huge solvers pre-selected way. showed many solvers strongly correlated make small contributions ﬁnding corroborated results example sat-rand scenario solvers selected sparrow eagleup. expect algorithms reduced asp-potassco scenario portfolio automatically constructed using algorithm conﬁguration obtain complementary parameter settings particularly amenable portfolios; nevertheless conﬁgurations chosen forward selection. results indicate real-world settings selecting predictive features solvers make highest contributions important. detailed continuously updated results found aslib website. described illustrated section designed aslib enable easy fair comparison diﬀerent algorithm selection approaches. next step unbiased performance comparisons algorithm selectors organize competitions based aslib. section brieﬂy describe exemplary competition settings based aslib. on-going evaluation aslib. on-going evaluation aslib every participant simply submit his/her performance scenario source code algorithm selector. latter used verify results case doubt. results average performance scenario) added overview table system linked. setting every system read aslib format easily participate deadlines submission required. therefore newest systems results always added on-the-ﬂy on-going evaluation always reﬂects recent known state-of-the-art systems performances. disadvantages setting diﬀerent participants diﬀerent amounts computational resources compute results example well-performing systems on-going evaluation satzilla autofolio also well-known systems computation resources systems; icon challenge algorithm selection. icon challenge algorithm selection provided comparative evaluation state-of-the-art algorithm selection systems. winner challenge zilla system competition algorithm selectors needed submitted ﬁxed deadline system executed organizers’ hardware limitations although used scenarios also already published organizers reveal training-test splits avoid overly strong overﬁtting scenarios. furthermore icon challenge assessed performance algorithm selectors based diﬀerent performance metrics revealed strengths weaknesses algorithm selectors e.g. systems used algorithm schedule better performance solved instances wasted time respect mcp. introduced aslib benchmark library algorithm selection rapidly growing ﬁeld research substantial impact various subcommunities artiﬁcial intelligence. aslib facilitates research algorithm selection methods providing common benchmarks tools working these. similar solver competitions enables principled comparative empirical performance assessment. also considerably lowers otherwise rather high barrier researchers work algorithm selection since anyone using benchmark scenarios provide perform actual runs solvers contained them. since library provides performance data solvers problem instances included selection scenario using aslib also substantially reduces computational burden performance assessments. otherwise data would produced considerable computational cost anyone working scenario. carefully selected scenarios included release version aslib challenge algorithm selection methods various ways thus provide solid basis developing assessing methods. release version library contains algorithm selection scenarios diﬀerent areas focus constraint satisfaction problems. discussed format algorithm selection scenarios showed examples automated exploratory data analysis scenario submitted online platform http//aslib.net/. finally exploratory studies various algorithm selection approaches demonstrated performance algorithm selection systems achieve scenarios. thank creators algorithms instance distributions used various algorithm selection scenarios. performance algorithm selection systems depends critically upon ingenuity tireless eﬀorts domain experts continue invent novel solver strategies. supported emmy noether grant supported nserc e.w.r. steacie fellowship; addition these along supported nserc discovery grant program. part research supported azure research grant.", "year": 2015}