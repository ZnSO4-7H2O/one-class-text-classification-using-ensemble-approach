{"title": "Dance Dance Convolution", "tag": ["cs.LG", "cs.MM", "cs.NE", "cs.SD", "stat.ML"], "abstract": "Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players perform steps on a dance platform in synchronization with music as directed by on-screen step charts. While many step charts are available in standardized packs, players may grow tired of existing charts, or wish to dance to a song for which no chart exists. We introduce the task of learning to choreograph. Given a raw audio track, the goal is to produce a new step chart. This task decomposes naturally into two subtasks: deciding when to place steps and deciding which steps to select. For the step placement task, we combine recurrent and convolutional neural networks to ingest spectrograms of low-level audio features to predict steps, conditioned on chart difficulty. For step selection, we present a conditional LSTM generative model that substantially outperforms n-gram and fixed-window approaches.", "text": "dance dance revolution popular rhythm-based video game. players perform steps dance platform synchronization music directed on-screen step charts. many step charts available standardized packs players grow tired existing charts wish dance song chart exists. introduce task learning choreograph. given audio track goal produce step chart. task decomposes naturally subtasks deciding place steps deciding steps select. step placement task combine recurrent convolutional neural networks ingest spectrograms low-level audio features predict steps conditioned chart difﬁculty. step selection present conditional lstm generative model substantially outperforms n-gram ﬁxed-window approaches. figure proposed learning choreograph pipeline four seconds song knife party feat. mistajam sleaze. pipeline ingests audio features produces playable choreography corresponding audio. dance dance revolution rhythm-based video game millions players worldwide players perform steps atop dance platform following prompts on-screen step chart step platform’s buttons speciﬁc musically salient points time. player’s score depends upon hitting correct buttons hitting correct time. step charts vary difﬁculty harder charts containing steps complex sequences. dance contains down left right arrows four states hold release. four arrows activated released independently possible step combinations instant. step charts exhibit rich structure complex semantics ensure step sequences challenging enjoyable. charts tend mirror musical structure particular sequences steps correspond different motifs entire passages reappear sections song repeated. moreover chart authors strive avoid patterns would compel player face away screen. community uses simulators opensource stepmania allow fans create play charts. number proliﬁc authors produce disseminate packs charts bundling metadata relevant recordings. typically song packs contain chart difﬁculty levels. despite game’s popularity players reasonable complaints packs limited songs favorable licenses meaning players unable dance favorite songs. even charts available players tire repeatedly performing charts. although players produce charts process painstaking requires signiﬁcant expertise. under-recognized source annotated data research. stepmania online popular repository data distributes packs annotations songs. addition introducing novel task methodology contribute large public datasets consider notably high quality consistency. dataset collection recordings step charts. contains charts single author multiple authors. prediction stages learning choreograph demonstrate superior performance neural networks strong alternatives. best model step placement jointly learns convolutional neural network representation recurrent neural network integrates information across consecutive time slices. method outperforms cnns alone multilayer perceptrons linear models. best-performing system step selection consists conditional lstm generative model. auxiliary information model takes beat phase number representing fraction beat step occurs. additionally best models receive time difference since last next step. model selects steps consistent expert authors best n-gram ﬁxed-window models measured perplexity per-token accuracy. introduce large curated datasets benchmarking choreography algorithms. represent under-recognized source music annotations. introduce effective pipeline learning basic statistics datasets shown table ﬁrst dataset contains songs choreographed single proliﬁc author works name fraxtil. dataset contains charts song corresponding increasing difﬁculty levels. charts overlap signiﬁcantly lower difﬁculty charts strict subsets higher difﬁculty charts figure four-beat measure typical chart rhythm depicted musical notation. quarter notes blue eighth notes yellow sixteenth notes jump step freeze step paper seek automate process step chart generation players dance wider variety charts song choosing. introduce task learning choreograph learn generate step charts audio. although task previously approached ad-hoc methods ﬁrst cast learning task seek mimic semantics human-generated charts. break problem subtasks first step placement consists identifying timestamps song place steps. process conditioned playerspeciﬁed difﬁculty level. second step selection consists choosing steps place timestamp. running steps sequence yields playable step chart. process depicted figure progress learning choreograph also lead advances music information retrieval step placement task example closely resembles onset detection well-studied problem. goal onset detection identify times musically salient events melody notes drum strikes. every onset data corresponds step every step corresponds onset. addition marking steps packs specify metronome click track song. songs changing tempos exact location change tempo annotated. click data could help spur algorithmic innovation beat tracking tempo detection. unfortunately research stymied difﬁculty accessing large well-annotated datasets. songs often subject copyright issues thus must gathered researcher independently. collating audio separately-distributed metadata nontrivial errorprone owing multiple available versions many songs. researchers often must manually align version song metadata. contrast dataset publicly available standardized contains meticulouslyannotated labels well relevant recordings. second dataset larger multi-author collection called groove dataset contains songs chart difﬁculty except songs lack charts highest difﬁculty. datasets contain electronic music constant tempo strong beat characteristic music favored community. note total number songs relatively small considering charts across songs datasets contain around hours annotations steps. datasets similar vocabulary sizes around steps datasets consist single instantaneous arrow. step charts contain several invariances example interchanging instances left right results equally plausible sequence steps. augment amount data available training generate four instances chart mirroring left/right up/down considerably improves performance practice. addition encoded audio packs consist metadata including song’s title artist list time-stamped tempo changes time offset align recording tempos. also contain information chart difﬁculties name choreographer. finally metadata contains full list steps marking measure beat each. make data easier work with convert canonical form consisting tuples. charts datasets echo high-level rhythmic structure music. increase difﬁculty corresponds increasing propensity steps appear ﬁner rhythmic subdivisions. beginner charts tend contain quarter notes eighth notes. higher-difﬁculty charts reﬂect complex rhythmic details music featuring higher densities eighth sixteenth note steps well triplet patterns step occur different locations within measure. however measures contain roughly steps average. level sparsity makes difﬁcult uncover patterns across long sequences frames single end-to-end sequential model. make automatic choreography tractable decompose subtasks step placement step selection. step placement goal decide precise times place steps. step placement algorithm ingests audio features outputs timestamps corresponding steps. addition audio signal provide step placement algorithms one-hot representation intended difﬁculty rating chart. step selection involves taking discretized list step times computed step placement mapping step. approach problem involves modeling probability distribution step sequence. steps require player arrows once jump; hold arrow duration freeze feed representation step placement algorithm estimates probabilities ground truth step lies within frame; peak-picking process sequence probabilities identify precise timestamps place steps; ﬁnally given sequence timestamps step selection algorithm choose steps place time. music ﬁles arrive lossy encodings .khz decode audio ﬁles stereo audio average channels produce monophonic representation. compute multiple-timescale short-time fourier transform using window lengths stride shorter window sizes preserve low-level features pitch timbre larger window sizes provide context high-level features melody rhythm using essentia library reduce dimensionality stft magnitude spectra frequency bands applying mel-scale ﬁlterbank. scale ﬁlter outputs logarithmically better represent human perception loudness. finally prepend append seven frames past future context respectively frame. ﬁxed-width methods ﬁnal audio representation tensor. correspond temporal width representing audio context frequency bands different window lengths. better condition data learning normalize frequency band zero mean unit variance. approach acoustic feature representation closely follows work schl¨uter b¨ock develop similar representations perform onset detection cnns. consider several models address step placement task. model’s output consists single sigmoid unit estimates probability step placed. models augment audio features one-hot representation difﬁculty. following state-of-the-art work onset detection adopt convolutional neural network architecture. model consists convolutional layers followed fully connected layers. ﬁrst convolutional layer ﬁlter kernels -wide time -wide frequency. second layer ﬁlter kernels -wide time -wide frequency. apply max-pooling convolutional layer frequency dimension width stride convolutional layers improve upon propose c-lstm model combining convolutional encoding integrates information across longer windows time. encode audio time step ﬁrst apply convolutional layers across full unrolling length. output second convolutional layer tensor ﬂatten along channel frequency axes ﬂattened features time step become inputs two-layer rnn. c-lstm contains long short-term memory units forget gates lstm consists layers nodes each. following lstm layers apply fully connected relu layers dimension architecture depicted figure train model using unrollings backpropagation time. chart’s intended difﬁculty inﬂuences decisions many steps place place them. low-difﬁculty charts average number steps second less one. contrast highest-difﬁculty charts exceed seven steps second. trained models without conditioning difﬁculty found inclusion feature informative. figure second peak picking. green ground truth region true positive false positive false negative peaks smoothed hamming window misaligned peak accepted true positive tolerance concatenate difﬁculty features ﬂattened output feeding vector fully connected layers initialize weight matrices following scheme glorot bengio training methodology minimize binary crossentropy mini-batch stochastic gradient descent. models train batches size scaling gradients norm exceeds apply dropout following lstm fully connected layer. lstm layers apply dropout input output temporal directions following best practices although problem exhibits pronounced class imbalance achieved better results training imbalanced data re-balancing schemes. exclude examples ﬁrst step chart last step charts typically span entire duration song. recurrent neural networks target frame ground truth value corresponding frame. calculate updates using backpropagation time steps unrolling equal second audio beats typical track train networks early-stopping determined area precision-recall curve validation data. models satisfy criteria within hours training single machine nvidia tesla gpu. chosen placements peak-picking process. first step placement algorithm entire song assign probabilities step occurring within frame. convolve sequence predicted probabilities hamming window smoothing predictions suppressing double-peaks occurring within short distance. finally apply constant threshold choose peaks high enough number peaks varies according chart difﬁculty choose different threshold difﬁculty level. consider predicted placements true positives within window ground truth. treat step selection task sequence generation problem. approach follows related work language modeling rnns well-known produce coherent text captures long-range relationships lstm model passes ground truth step placements predicts next token given previous sequence tokens. output softmax distribution possible steps. input compact bag-of-arrows representation containing features depict previous step. arrow corresponding features represent states hold release. found bag-of-arrows give equivalent scores depend accuracy player’s step timing. highest scores require step performed within appointed time; suggests reasonable algorithm place steps even ﬁner level granularity. performance one-hot representation requiring fewer parameters. additional feature functions start token denote ﬁrst step chart. task lstm layers cells each. finally provide additional musical context step selection models conditioning rhythmic features inform models non-uniform spacing step placements consider following three features ∆-time adds features representing time since previous step time next step; ∆-beat adds features representing number beats since previous next step; beat phase adds four features representing note subdivision beat current step closely aligns training methodology neural network models learn parameters minimizing cross-entropy. train mini-batches size scale gradients using scheme step placement. dropout training models fashion step placement. steps unrolling representing average seconds easiest charts seconds hardest. apply earlystopping determined average per-step cross entropy validation data. models satisfy criteria within hours training single machine nvidia tesla gpu. fraxtil datasets apply splits training validation test data respectively. correlation charts song varying difﬁculty ensure charts particular song grouped together split. model ∆-time ∆-beat beat phase lstm lstm ∆-time lstm ∆-beat beat phase lstm lstm ∆-time lstm ∆-beat beat phase ∆-time ∆-beat beat phase lstm lstm ∆-time lstm ∆-beat beat phase lstm lstm ∆-time lstm ∆-beat beat phase baselines establish reasonable baselines step placement ﬁrst report results logistic regressor trained ﬂattened audio features. also report performance mlp. architecture contains fully-connected layers size rectiﬁer nonlinearity applied layer. apply dropout probability fully-connected layer training. model baseline method schl¨uter b¨ock state-of-the-art algorithm onset detection. metrics report model’s perplexity averaged across frame chart test data. using sparse step placements calculate average perchart area precision-recall curve average best per-chart f-scores report value f-scorec. calculate micro f-score across charts report value f-scorem. table list results experiments step placement. models conditioned difﬁculty also one-hot representation chart author. datasets c-lstm model performs best evaluation metrics. models achieve signiﬁcantly higher f-scores harder difﬁculty step charts. fraxtil dataset c-lstm achieves f-scorec hardest difﬁculty charts lowest difﬁculty. difﬁcult charts contribute fscorem calculations ground truth positives. discuss results section baselines step selection compare performance conditional lstm n-gram model. note perplexity unbounded test token assigned probability generative model. protect n-gram models unbounded loss previously unseen n-grams modiﬁed kneser-ney smoothing following best practices language modeling speciﬁcally train smoothed -gram model backoff implemented stolcke following work bengio also compare ﬁxed-window -gram takes bag-of-arrows-encoded steps input predicts next step. contains fully-connected layers nodes dropout layer during training. lstm train without access side features. addition lstm steps unrolling train lstm steps unrolling. baselines show lstm learns complex long-range dependencies. also demonstrate discriminative information conferred ∆-time ∆-beat beat phase features. metrics report average per-step perplexity averaging scores calculated separately chart. also report per-token accuracy. calculate accuracy comparing ground-truth step argmax model’s predictive distribution given previous sequence ground-truth tokens. given chart token accuracy averaged across time steps. produce ﬁnal numbers averaging scores across charts. table present results step selection task. fraxtil dataset best performing model lstm conditioned ∆-beat beat phase lstm conditioned ∆-time. conditioning rhythm features generally beneﬁcial beneﬁts various features strictly additive. representing ∆-beat ∆-time real numbers outperformed bucketed representations. additionally explored possibility incorporating comprehensive representations audio step selection model. considered variety representations conditioning features learned step placement task. also experimented jointly learning audio encoder. cases approaches rapid overﬁtting never approached performance conditional lstm generative model; perhaps much larger dataset could support approaches. finally tried conditioning step selection models difﬁculty chart author found models overﬁt quickly well. figure real step chart fraxtil dataset song anamanaguchi mess. middle one-step lookahead predictions lstm model given fraxtil’s choreography input. model predicts next step high accuracy bottom choreography generated conditional lstm model. experiments establish feasibility using machine learning automatically generate high-quality charts audio. performance evaluations subtasks demonstrate advantage deep neural networks classical approaches. step placement best performing model lstm encoder approach used speech recognition knowledge never music-related tasks. noticed metrics models perform better higher-difﬁculty charts. likely owes comparative class imbalance lower difﬁculty charts. superior performance lstms ﬁxed-window approaches step selection suggests charts exhibit long range dependencies recurrent neural networks exploit complex structure. addition reporting quantitative results visualize step selection model’s next-step predictions. here give entire ground truth sequence input show predicted next step time. also visualize generated choreography sampled output lstm subsequent input note high accuracy model’s predictions qualitative similarity generated sequence fraxtil’s choreography. step selection notice modeling fraxtil dataset choreography appears easy compared multi-author dataset. believe owes distinctiveness author styles. many step charts fraxtil network able closely mimic patterns. dataset contains multiple charts author none proliﬁc fraxtil. released public demo using promising models measured quantitative evaluation. players upload audio select difﬁculty rating receive step chart stepmania simulator. demo produces step chart minute song seconds using nvidia tesla gpu. time writing players produced step charts demo. also solicited feedback scale player satisfaction demo results. respondents reported average satisfaction promising direction future work make selection algorithm audio-aware. know qualitatively elements ground truth choreography tend coincide speciﬁc musical events jumps used emphasize accents rhythm; freezes used transition regions high rhythmic intensity ambient sections. choreography might also beneﬁt end-to-end approach model simultaneously places steps selects them. primary obstacle data sparsity sufﬁciently high feature rate. labels null. time-steps unrolling might encounter ground truth steps. demonstrate step selection methods improved incorporating ∆-beat beat phase features however current pipeline produce information. lieu manual tempo input restricted using ∆-time features executing pipeline unseen recordings. trained model detect beat phase would able features step selection. several academic papers address ddr. include anthropological studies papers describe approaches automated choreography. ﬁrst called dancing monkeys uses rule-based methods step placement step selection second employs genetic algorithms step selection optimizing ad-hoc ﬁtness function neither establishes reproducible evaluation methodology learns semantics steps data. step placement task closely resembles classic problem musical onset detection several onset detection papers investigate modern deep learning methodology. eyben employ bidirectional lstms onset detection; marchi improve upon work developing rich multi-resolution feature representation; schl¨uter b¨ock demonstrate cnn-based approach performs competitively prior blstm work. neural networks widely used range tasks including musical chord detection boundary detection another transient audio phenomenon. step selection problem resembles classic natural language processing task statistical language modeling. classical methods consider include n-gram distributions bengio demonstrate approach language modeling using neural networks ﬁxed-length context. recently rnns demonstrated superior performance ﬁxed-window approaches lstms also capable modeling language character level thorough explanation modern rnns exceeds scope paper point comprehensive reviews literature several papers investigate neural networks single-note melody generation polyphonic melody generation learning choreograph requires predicting timing type events relation piece music. respect task similar audio sequence transduction tasks musical transcription speech recognition. rnns currently yield state-of-the-art performance musical transcription rnns widely used speech recognition state-of-the-art method combines convolutional recurrent networks. work methodologically similar differs consider entirely different application. combining insights musical onset detection statistical language modeling designed evaluated number deep learning methods learning choreograph. introduced standardized datasets reproducible evaluation methodology hope encouraging wider investigation related problems. emphasize sheer volume available step charts presents rare opportunity access large amounts high-quality annotated data. data could help spur innovation several tasks including onset detection beat tracking tempo detection. authors would like thank jeff donahue shlomo dubnov jennifer mohsen malmir miller puckette adith swaminathan sharad vikram helpful feedback work. work used extreme science engineering discovery environment supported national science foundation grant number aci-. gpus used research graciously donated nvidia corporation. references amodei dario anubhai rishita battenberg eric case carl casper jared catanzaro bryan chen jingdong chrzanowski mike coates adam diamos greg deep speech end-to-end speech recognition english mandarin. icml bello juan pablo daudet laurent abdallah samer duxbury chris davies mike sandler mark tutorial onset detection music signals. ieee transactions speech audio processing bogdanov dmitry wack nicolas g´omez emilia gulati sankalp herrera perfecto mayor oscar roma gerard salamon justin zapata jos´e serra xavier. essentia audio analysis library music information retrieval. ismir boulanger-lewandowski nicolas bengio yoshua vincent pascal. modeling temporal dependencies high-dimensional sequences application polyphonic music generation transcription. icml eyben florian b¨ock sebastian schuller bj¨orn graves alex. universal onset detection bidirectional long short-term memory neural networks. ismir graves alex fern´andez santiago gomez faustino schmidhuber j¨urgen. connectionist temporal classiﬁcation labelling unsegmented sequence data recurrent neural networks. icml greff klaus srivastava rupesh koutn´ık steunebrink schmidhuber j¨urgen. lstm search ieee transactions neural networks space odyssey. learning systems sigtia siddharth benetos emmanouil dixon simon. end-to-end neural network polyphonic piano muieee/acm transactions audio transcription. speech language processing towns john cockerill timothy dahan maytal foster gaither kelly grimshaw andrew hazlewood victor lathrop scott lifka dave peterson gregory xsede accelerating scientiﬁc discovery. computing science engineering yoon jernite yacine sontag david rush alexander character-aware neural language models. proceedings thirtieth aaai conference artiﬁcial intelligence marchi erik ferroni giacomo eyben florian gabrielli leonardo squartini stefano schuller bjorn. multi-resolution linear prediction based features audio onset detection bidirectional lstm neural networks. ieee", "year": 2017}