{"title": "Distributed Constrained Optimization with Semicoordinate Transformations", "tag": ["cs.NE", "cs.AI"], "abstract": "Recent work has shown how information theory extends conventional full-rationality game theory to allow bounded rational agents. The associated mathematical framework can be used to solve constrained optimization problems. This is done by translating the problem into an iterated game, where each agent controls a different variable of the problem, so that the joint probability distribution across the agents' moves gives an expected value of the objective function. The dynamics of the agents is designed to minimize a Lagrangian function of that joint distribution. Here we illustrate how the updating of the Lagrange parameters in the Lagrangian is a form of automated annealing, which focuses the joint distribution more and more tightly about the joint moves that optimize the objective function. We then investigate the use of ``semicoordinate'' variable transformations. These separate the joint state of the agents from the variables of the optimization problem, with the two connected by an onto mapping. We present experiments illustrating the ability of such transformations to facilitate optimization. We focus on the special kind of transformation in which the statistically independent states of the agents induces a mixture distribution over the optimization variables. Computer experiment illustrate this for $k$-sat constraint satisfaction problems and for unconstrained minimization of $NK$ functions.", "text": "recent work shown information theory extends conventional full-rationality game theory allow bounded rational agents. associated mathematical framework used solve constrained optimization problems. done translating problem iterated game agent controls diﬀerent variable problem joint probability distribution across agents’ moves gives expected value objective function. dynamics agents designed minimize lagrangian function joint distribution. illustrate updating lagrange parameters lagrangian form automated annealing focuses joint distribution tightly joint moves optimize objective function. investigate semicoordinate variable transformations. separate joint state agents variables optimization problem connected onto mapping. present experiments illustrating ability transformations facilitate optimization. focus special kind transformation statistically independent states agents induces mixture distribution optimization variables. computer experiment illustrate k-sat constraint satisfaction problems unconstrained minimization functions. ﬁrst described turns translate many concepts statistical physics game theory distributed optimization distributed control another. translation based fact concepts involve distributed systems random variables single instant statistically independent. using translation transfer theory techniques ﬁelds creating large common mathematics connects them. common mathematics known probability collectives unifying concern probability distributions govern particular distributed system manipulate distributions optimize objective functions. earlier less formal work topic. paper consider solve constrained optimization and/or control problems. reﬂecting focus distributed systems problems particularly appropriate variables collective spread across many physically separated agents limited inter-agent communication general advantage problems since work probabilities rather underlying variables implemented arbitrary types underlying variables. characteristic also means provides multiple solutions robust along sensitivity information concerning solutions. advantage particulary relevant optimization distributed algorithm often implemented parallel computer. advantage particularly relevant control problems algorithms desired used without modelling assumptions system controlled. advantages discussed detail below. broadly speaking approach optimization/control follows. first maps provided problem multi-agent collective. simplest version process assigns separate agent collective determine value variables problem control. example i’th variable take ﬁnite number values |xi| possible values constitute possible moves i’th agent. value joint variables describing system unlike many optimization methods variables manipulated directly. rather probability distribution manipulated. avoid combinatorial explosions number dimensions grows must restrict attention low-dimensional subset space probability distributions. indicate writing distributions manipulation proceeds iterative process. ultimate goal process induce distribution highly peaked optimizing objective function sometimes called world cost world utility function. precise algorithms investigated here start iteration single lagrangian function speciﬁed based associated constraints optimization problem. rather minimize objective function space algorithm minimization lagrangian modiﬁes lagrangian slightly. done optimizing lagrangian tightly concentrated solve optimization problem current uses current starting point another process agents minimize lagrangian time work lagrangian. sequence iterations ends ﬁnal used determine ﬁnal answer e.g. sampling evaluating mode evaluating mean etc. properly chosen sequence lagrangians algorithm minimizing lagrangians last step should high probability provide desired optimal point class lagrangians used paper sequence minimizations lagrangians closely related simulated annealing. diﬀerence simulated annealing ineﬃcient metropolis sampling process used implicitly descend iteration’s lagrangian. explicitly manipulating allows eﬃcient descent. associated formulation sometimes called product distribution theory. corresponds noncooperative game theory agent mixed strategy particular focus product distributions ultimate space optimization variables formulation modiﬁcation presented intermediate mapping provided actually function intermediate mappings called semicoordinate systems going another semicoordinate transformation. elaborated below transformations allow arbitrary coupling among variables preserving many computational advantages using product distributions advantages probability collectives many advantages working distribution rather points usually support i.e. minimizing lagrangian lies interior unit simplices giving conversely element viewed probability distribution edge simplices. working special case working sticks vertices this optimizing rather analogous interior point methods. breadth support minimizing also viewed allow information value objective function exploited simultaneously. another advantage alluded above working distributions rather space general approach used essentially continuous discrete time-extended mixtures these etc. expository simplicity though work ﬁnite therefore probability distributions rather density functions sums rather integrals etc. particular analysis explicitly case inﬁnite another advantage arises fact ﬁnite vector euclidean space. accordingly lagrangian minimizing real-valued function euclidean vector. means allows leverage power descent schemes continuous spaces like gradient descent newton’s method even categorical ﬁnite space. schemes like gradient descent categorical variables perfectly well-deﬁned. lagrangians based prior knowledge modelling assumptions concerning problem need optimization lagrangian require control variables allows broadly applicable. general advantage relates seemingly disparate disciplines another. particular motivated using information theory relate bounded rational game theory statistical physics allows techniques ﬁeld imported ﬁeld. example illustrated below grand canonical ensemble physics imported noncooperative game theory analyze games stochastic numbers players various types. review noncooperative game consists sequence stages. beginning stage every agent sets probability distribution moves joint move stage formed agents simultaneously sampling mixed strategies stage. moves agents make particular stage game statistically independent distribution joint-moves stage product distribution like theory. mean moves agents across time statistically independent however. stage game agent mixed strategy based information gleaned preceding stages information general reﬂect earlier moves agents. agents coupled indirectly across time updating {qi}n stage. analogously consider iterative algorithm outlined above particular process optimizing lagrangian within particular single iteration. typically process proceeds successively modifying across sequence timesteps. timesteps ﬁrst sampled updated based previous samples. like noncooperative game direct coupling values underlying variables {xi}at particular timestep rather like noncooperative game variables indirectly coupled across time coupling distributions diﬀerent timesteps. addition information theory used show bounded rational equilibrium noncooperative game optimizing associated maxent lagrangian lagrangian turns exactly arises version considered paper. bounded rational game theory instance statistical physics often wishes distribution allowed distributions minimal distance ﬁxed target distribution space possible distributions perhaps popular choice distance measure typically physics given statistical ensembles. important example minimization arises boltzmann distribution canonical ensemble exp/t hamiltonian system. distance boltzmann distribution proportional gibbs free energy statistical physics. free energy identical maxent lagrangian considered paper. stated diﬀerently solves distribution one’s minimizes distance boltzmann distribution gets distribution one’s maximal entropy subject constraint speciﬁed expected value distributions one’s considering product distributions minimizing distance called mean-ﬁeld approximation mean-ﬁeld theory instance illustrates bounded rational games mean-ﬁeld approximation boltzmann distributions essentially identical. relate equates common payoﬀ function equivalence completed identifying agent diﬀerent physical variables argument hamiltonian. connection ﬁelds allows exploit techniques statistical physics bounded rational game theory. example mentioned above rather canonical ensemble apply grand canonical ensemble bounded rational games. allows consider games number players type stochastic contribution paper product distribution space optimization consistent game theory further choice results highly parallel algorithm well-suited problems inherently distributed. nonetheless concerns dictate diﬀerent particular many optimization tasks seek multiple solutions apart another. example constraint satisfaction problems goal identify feasible solutions satisfy constraints show none exist. small problem instances exhaustive enumeration techniques like branch-and-bound typically used identify feasible solutions. however larger problems desirable develop local-search-based approaches determine multiple distinct solutions single run. cases like these desire multiple distinct solutions product distribution poor choice. problem distribution peaked every value occurs least multiple solutions general spurious alternatively peaked solutions provide many solutions. address might descend lagrangian many times beginning diﬀerent starting points however guarantee multiple runs generate diﬀerent solutions. oﬀers simple solution problem allows still product distributions extend event space underlying product distribution single game provides multiple distinct solutions optimization problem. intuitively speaking transformation recasts problem terms meta-game cloning original game several simultaneous games independent agents game. supervisory agent chooses game played. form lagrangian meta-game biased towards agents control variable diﬀerent games diﬀerent mixed strategies another. joint strategies separate games meta-game give multiple solutions original game. supervisory agent sets relative importance solution used. since general resultant distribution across variables formally process represented semicoordinate transformation. recall space arguments objective function product distribution deﬁned semicoordinate system maps introduction semicoordinate system product distributions give product distributions however introduce semicoordinate system product distributions need product distributions appropriate choice semicoordinate transformation distributions made correspond coupled distributions across general bayes topology achieved appropriate semicoordinate transformation diﬀerent product distributions correspond diﬀerent bayes nets independence relations. intuitively distribution moves supervisor agent labelling game agent chooses. mixture product distributions allows determination solutions once. time entropy term lagrangian pushes separate products mixture apart. biases algorithm locating well separated solutions desired. sec. review arrives lagrangian considered paper maxent lagrangian. sec. review elementary techniques introduced updating product distribution minimize associated lagrangian. depending form objective terms involved updating evaluated closed form require estimation monte carlo methods. experiments reported terms calculated closed form. however demonstrate wider applicability update rules review appendix monte-carlo techniques providing variance estimates required quantities. ﬁrst derivation estimators presented work. background review complete semicoordinate transformations introduced sec. illustration semicoordinate transformations particular attention placed mixture models mixture models seen product distributions diﬀerent space. sec. analyze minimization maxent lagrangian associated mixtureinducing semicoordinate transformations. section also relate maxent lagrangian mixture distributions jensen-shannon distance experimental validation techniques presented k-satisﬁability problem family discrete optimization problems sections consider situation semicoordinate transformation ﬁxed priori suggestions made determine good semicoordinate transformation dynamically algorithm progresses. conclude synopsis techniques updating product distribution minimize associated lagrangian. synopsis serves basis discussion relationship techniques. like techniques presented paper readily applied problems constrained optimization. example provides natural improvement metropolis sampling algorithm techniques paper able improve further. addition simplicity focus optimization countable domains extended many ways continuous space optimization. associated technical diﬃculties addressed. examples experiments. emphasized usually good choice best optimize problems lying narrowly deﬁned class. know class optimization problems scrutiny algorithms hand-tailored class almost called for. also situations often call upon formal convergence bounds. contrast spirit genetic algorithms cross entropy method simulated annealing etc. broadly applicable optimization algorithm performs well many domains even little prior knowledge domain. general discussion issue.) finally statistical inference parameterizes possible solutions one’s problem reduce dimensionality solution space. without parameterization curse dimensionality prevents good performance general choosing one’s parameterization though assumes parameterization ﬂexible enough capture salient aspects stochastic process generating one’s data. essence assumes parameterization projects noise keeping signal. analogue problem parameterization precise semicoordinate transformation use. universally correct choice parameterize statistics problem universally correct choice semicoordinate transformation use. situations must rely prior knowledge make one’s choice potentially combined conservative online adaptation choice. lagrangian product distributions begin considering case identity semicoordinate system discussed above consider distance -parameterized boltzmann distribution exp/t normalization constant. boltzmann distribution concentrated values product distribution minimal distance would expected behavior. accordingly would expect taking distance distribution one’s lagrangian modifying lagrangian iteration next lowering concentrated values. detailed formal justiﬁcation using lagrangian based solving constrained optimization problems lagrange parameters.) accordingly view maxent lagrangian equivalent lagrangians ﬁrst term minimized perfectly rational players i.e. players concentrate probability moves best them given distributions agents. second term minimized perfectly irrational players i.e. perfectly uniform joint mixed strategy speciﬁes balance rational irrational behavior players. particular minimizing lagrangian recover nash equilibria game. alternatively statistical physics perspective temperature system maxent lagrangian simply gibbs free energy hamiltonian original objective function equality constraint functions required equal zero. constraint satisfaction problems take original objective function constant function lagrange multipliers used enforce constraints. collectively refer lagrange multipliers vector λλλ. constraints equality constraints saddle point lagrangian space possible solution problem. note however exact saddle point; general sampling close saddle point give seek. certainly ways constraints addressed within framework. alternative approach might allow constraints weakly violated. would iteratively anneal weaknesses i.e. strengthen constraints violated. approach could replace maxent lagrangian formulation encapsulated eq.’s iteration algorithm treated lagrange parameters solves values enforce equality constraints constraints also minimizing usual since constraints equalities ﬁnding saddle points next iteration would start modifying lagrangian shrinking values {γa} slightly proceeding process ﬁnding saddle point. another theoretically justiﬁed incorporate constraints requires support constrained entirely within feasible region. violates constraint assigned probability i.e. violate constraints. pedagogical simplicity consider alternative approaches concentrate lagrangian addition constraints associated optimization problem vectors {qi} must probability distributions. implicit minimizing maxent lagrangian ﬁxed task saddle point ﬁrst order methods saddle point found iterating two-step process. ﬁrst step lagrange parameters ﬁxed solves minimizes associated second step freezes updates lagrange parameters. sophisticated ways ﬁnding saddle points generally modiﬁed versions lagrangian simplicity consider sophisticated approaches. section review approaches ﬁnding {qi} ﬁxed lagrange multipliers λλλ. also describe approach second step ﬁrst order method i.e. describe gradient ascent update lagrange multipliers ﬁxed discussion approaches well many others use. equation proportional unit vector magnitude ensure step direction ˜∇∇∇ql remains unit simplex. furthermore component gradient every agent every possible move agent optimal assuming agents don’t change distributions. however agents change distributions thereby least partially confound agent address problem agent current value rather weights shrinking weighted average values past goes. introduces inertia eﬀect helps stabilize updating. alone move part parallel brouwer update recommends. whether moves part-way agent interested distribution optimal next distributions agents. accordingly makes sense agent predict using standard time-series tools future distributions amounts predicting next vector values based seeing vector evolved recent past. related ideas. another circumventing thrashing agents update distributions serially rather parallel. description various kinds serial schemes well discussion partial serial partial parallel algorithms. nearest-newton updating agents evaluate gradient needs evaluate estimate terms consequently gradient descent typically straight-forward. though also usually simple evaluate hessian lagrangian conventional newton’s descent intractable large systems inverting hessian computationally expensive. course schemes conjugate gradient quasi-newton exploit second order information even hessian cannot inverted. however special structure lagrangian also allows second order information used simple variant newton descent. associated update rule called nearest-newton updating review here. derive nearest-newton begin considering lagrangian unrestricted probability distribution lagrangian convex function diagonal hessian. given current distribution make unrestricted newton step lagrangian distribution πt+. distribution typically even starting distribution however solve nearest example ﬁnding minimizes distance point. normalized normalized step size. typically belong product distribution nearest minimizing distance i.e. marginal given respect result integrating x−i. order satisfy imposed optimization constraints {ca} must also update lagrange multipliers. minimize communication agents done simplest possible gradient descent. taking partial derivatives respect gives update rule emphasized encompasses many approaches optimization lagrangian diﬀer used here. example discussion alternative types descent algorithms related block relaxation well ﬁctitious play algorithm game theory multi-agent reinforcement learning algorithms like collective intelligence another example discussions using distance rather distance. interestingly discussed below alternative distance must used even descent distance wishes order descent schemes. discusses using non-boltzmann target distributions many options functional descend. described possible algorithms summarize steps involved each. basic framework form basis semicoordinate extensions described section pseudocode basic optimization appears algorithm lines initialize algorithmic parameters. best starting temperatures multiplier values vary problem problem. typically initialize maximum entropy distribution uniform search space outer loop decreases temperature according schedule determined function updatet. later comment automatic schedules generated settings lagrange multipliers. inside loop another loop increments lagrange multipliers according every time iterated local minimum lagrangian. minimization ﬁxed temperature setting multipliers accomplished innermost loop. minimization λaca|xi) using either update rules eqs. evaluation λaca accomplished either analytically monte carlo estimates. many problems analytical evaluation prohibitively costly monte carlo methods option. appendix consider unbiased variance monte carlo methods estimating required conditional expectations appendix derive minimal variance estimator within class useful estimators. consider multi-stage game like chess stages delineated game theoretic terms strategy player mapping board-conﬁguration response speciﬁes rule adopts play starts generally multi-stage game like chess strategy player t-indexed maps taking player observed stages move stage formally maps called player normal form strategy. joint strategy players chess sets joint move-sequence though general reverse need true. addition always joint strategy result particular joint move-sequence. typically stage overlap players observed preceding stages. means even players’ strategies statistically independent move sequences statistically coupled. situation parameterizing space joint-move-sequences joint-strategies shift focus coupled distribution decoupled product distribution advantage casting multi-stage games terms normal form strategies. generally given spaces associated onto mapping necessarily invertible called semicoordinate system. identity mapping trivial example semicoordinate system. another semicoordinate system mapping joint-strategies multi-stage game joint move-sequences. words changing intuitively semicoordinate transformation reparameterization game mapping joint moves associated payoﬀs represented. perform semicoordinate transformation even single-stage game. restrict attention distributions product distributions. changing identity function means players’ moves longer independent. transformation move choices components statistically coupled even though considering product distribution. distributions across respectively. rule means geometrically recall space distributions space product distributions image changing change image; diﬀerent choices result diﬀerent manifolds example players possible moves each. consists possible joint moves labelled take choose given distribution joint-moves pzpz; moves players statistically coupled even though strategies independent. matter coupling among components expressed product distribution associated worst case simply choose single component bijection component vector trivially distribution product distribution. another simple example aggregates agents single agent i.e. replaces product distribution joint moves agents arbitrary distribution joint moves. related concept coalitions cooperative game theory well aumann’s correlated equilibrium less trivially given model class distributions {pz} associated {pz} identical formally expressed result concerning bayes nets. simplicity restrict attention ﬁnite order components index parent function subset components index greater returning value components second argument subset components non-empty. example could another possibility empty independent distributions equals exactly proposition deﬁne components using multiple indices possible associated values vector separate component xi;pa. component take values can. deﬁne recursively starting working lower following rule intuitively component proposition conditional distribution particular instance vector illustration consider example assumes value components component also either product distribution proposition means principle never need consider coupled distributions. suﬃces restrict attention product distributions long appropriate semicoordinate system. semicoordinate systems also enable representation mixture models also represented using products. however discussing mixture models show transformation semicoordinate systems principle used escape local minima illustrate another application semicoordinate transformations conﬁne case bijection |xi| size search space. coordinate variable partitions search space |xi| disjoint regions. partitions intersection variable coordinates yields single particular standard semicoordinate system relies partition coordinate illustrative example consider binary variables figure shows points search space represented standard coordinate system. figure shows shuﬄing conﬁgurations permutation resulting partitions conﬁgurations given table means gradient maxent lagrangian typically diﬀer application particular local minimum zero gradient semicoordinate transformation local minimum transformation resultant shuﬄing simple example shown lagrangian surface binary variables shown. utility values temperature units objective global minimum temperature suboptimal local minimum located number criteria might used determine semicoordinate transformation escape local minimum simple choices select transformation minimizes value maxent lagrangian select transformation results largest gradient maxent lagrangian ∇ql). simple problem results choices shown figures respectively. transformation cases determined optimizing semicoordinate transformations keeping probabilities ﬁxed either minimize lagrangian value maximize norm gradient principle semicoordinate search embedded within optimization dynamically escape local minima encountered. importantly search criteria listed require look ahead order identify best semicoordinate permutation. however practice since search arbitrarily large permutation spaces must select variables permute amongst possible joint moves. composing permutations easily account escape multiple local minima. heuristics selection permuting variables results procedure await future work. figure original lagrangian function. suboptimal local minimum located indicated lower left corner. lagrangian coordinate transformation minimizes lagrangian coordinate transformation maximizes norm gradient direction negative gradient indicated black arrow. section turn diﬀerent semicoordinate transformations. previously described lagrangian measuring distance product distribution boltzmann distribution minimized distributed fashion. extend results mixtures product distributions order represent multiple product distribution solutions once. always means semicoordinate transformation underlying variables. section demonstrate explicitly. indicate variables space dimension original n-dimensional space deﬁned. identify product distribution appropriately chosen mapping induce mixture distribution consider component mixture distribution variables write express product distribution space dimension intuitively ﬁrst dimension labels mixture remaining correspond original dimensions dimensions maximize entropy mixture weights provides incentive distributions diﬀer other. argued desirable diﬀerent mixtures capture diﬀerent solutions modify lagrangian function slightly. conventional jensen-shannon distance deﬁned compare distributions other gives distributions equal weight. contrast generalized distance concerns multiple distributions weights nonuniformly according maximized diﬀerent other. thus inclusion lagrangian pushes mixing components away another. this view novel derivation jensen-shannon distance. unfortunately distance also couples variables prevents highly distributed solution. desired results require minimal communication agents. supervisory agent call -agent assigned manage determination -agents manage -agents ﬁxed communicate determine determination agent forwarded -agent forms broadcasts back -agents. quantities local estimates eqm−i test mixture semicoordinate probability collective method diﬀerent problems k-sat constraint satisfaction problem multiple feasible solutions optimization unconstrained optimization function. k-sat problem perhaps best studied goal assign binary variables true/valse values disjunctive clauses satisﬁed. clause involves variables labelled binary clause violated zvaj lagrangian product distributions written λλλc c-vector expected constraint violations vector lagrange multipliers. a’th compoz qvaj note monte carlo estimates required evaluate quantity. further communication required evaluate conditional expectations agents appearing clause. typically communication network sparse; variable problem consider agent interacts agents average. ﬁrst present results single product distribution. ﬁxed setting lagrange multipliers lagrangian minimized iterating minimization done brouwer method random subset variables appear clause updated simultaneously. eliminates thrashing ensures lagrangian decreases iteration. minimization terminated local minimum detected norm gradient falls threshold. constraints satisﬁed return solution maxz otherwise lagrange multipliers updated according present context updating rule oﬀers number beneﬁts. firstly constraints figure evolution lagrangian value expected constraint violation constraint violations likely conﬁguration minimizing lagrangian ﬁrst multiplier settings. termination violated strongly penalty increased most consequently agents involved constraints likely alter state. secondly lagrange multipliers contain history constraint violations agents coordinate next move unlikely return previously violated state. mimics approach used taboo search revisiting conﬁgurations explicitly prevented aids eﬃcient exploration search space. lastly rescaling lagrangian update gives ˆλλλc ˆλλλ λλλ/λλλ /λλλ. ﬁrst term reweights clauses according expected violation temperature cools automated annealing schedule lagrange multipliers increase. cooling rapid expected constraint violation large slows optimum approached. parameters thus govern overall rate cooling. used ﬁxed value figure presents results variable problem using single mixture. problem satisﬁable formula uf-.cnf satlib generated ratio clauses variables near phase transition consequently solutions. fig. shows variation lagrangian expected number constraint violations number constraints violated probable state maxz function number iterations. starting state maximum entropy conﬁguration uniform starting temperature iterations lagrange multipliers updated indicated vertical dashed lines clearly visible discontinuities lagrangian values. show stochastic underpinnings algorithm plot fig. probability downward movement expected value algorithm progresses. figure shows evolution renormalized langrange multipliers ˆλλλ. ﬁrst iteration multiplier clauses equal. algorithm progresses weight shifted amongst diﬃcult satisfy clauses. results larger problem multiple mixtures shown fig. variable/ clause problem uf-.cnf satlib ﬁrst clauses removed problem multiple solutions. optimization performed selecting random subset variables appear clause iteration updating according eqs. convergence local minimum lagrange multipliers updated according expected constraint violation. initial temperature plot number constraints violated probable state mixture function number updates. well expected number violated constraints. steps three distinct solutions found along fourth conﬁguration violates single constraint. next consider unconstrained discrete optimization problem. model deﬁnes family tunably diﬃcult optimization problems objective binary variables {zi}n deﬁned average randomly generated contributions depending randomly chosen variables local conﬁgurations assigned value drawn uniformly ranges controls number local minima; hamming neighborhoods optimization landscapes single global optimum landscapes average local minima. properties landscapes found fig. plots energy mixture model multi-modal figure solid curves show number unsatisﬁed clauses probable conﬁguration mixtures iterations. topmost solid black line plots expected number violations dashed black line shows approximation distance. solid curves show evolution value best conﬁgurations mixtures versus number iterations. dashed black line shows corresponding approximation distance. function. spins upon depends selected random. termination algorithm distinct conﬁgurations obtained nearest pair solutions hamming distance note unlike k-sat problem multiple conﬁgurations global minimal energy distance fig. drops zero temperature decreases. exactly zero temperature term forcing diﬀerent solutions lagrangian minimized mixtures converge delta functions lowest objective value conﬁguration. eﬀect mixtures enables algorithm simultaneously explore multiple local extema converging lowest objective solution. much work many ﬁelds related maxent lagrangian used statistical physics century rubric free energy. derivation terms information theoretic statistical inference jaynes maxent lagrangian also appeared occasionally game theory heuristic without statistical inference justiﬁcation none earlier work appreciation relationship related work ﬁelds. context distributed control/optimization distinguishing feature view variable fundamental object rather distribution across samples distribution direct object interest fact used necessary estimate functionals fundamental objective function stated terms explicated next subsection associated optimization algorithms related finally note maxent lagrangian viewed barrier-function method objective entropic barrier function used enforce constraints constraint implicit. direct application equations minimize lagrangian form basis brouwer update rules. alternatively steepest descent maxent lagrangian forms basis nearest newton algorithm. update rules analogues conventional optimization. example nearest-newton based newton’s method brouwer updating similar block-relaxation. advantages embedding original optimization problem involving problem involving distributions across allows solve problems non-euclidean spaces using powerful methods already well-understood optimization euclidean spaces. euclidean analogues iterative focusing update rules described iterative focusing updates intrinsically tied fact we’re minimizing expectation value. rules list probability distribution never increases addition const scalar ensures distribution properly normalized stepsize. finally iterative focusing technique repeats following process takes distribution input. produces output distribution focused tightly good focused distribution becomes next iteration. gradient descent distance list highlights ability beyond conventional euclidean optimization update rules advantage embedding original optimization problem problem space probability distributions. another advantage fact distribution provides much useful information another advantage natural monte carlo techniques arise embedding allow optimization used adaptive control. work optimization precedes directly considered distribution object interest. much work viewed special cases particular deterministic annealing bare-bones parallel brouwer updating. involves data-aging diﬀerence utilities etc.. tantalizingly technique probability matching uses monte carlo sampling optimize functional work context single agent exploit techniques like data-ageing. unfortunately work pursued. work viewed fundamental object interest used techniques like data-aging diﬀerence utilities. particular case collective intelligence work however work based information-theoretic considerations explicit objective function introduction considerations resulted another interesting body early work cross entryop method work iterative focusing using distance. method consider formal diﬃculty iterative focusing identiﬁed potential solutions problem discussed there. diﬃculty means even sampling error general guarantees algorithm converges optimal early work grew genetic algorithms community. work initiated mimic since developed estimation distribution algorithms approach number important issues raised early work e.g. importance information theoretic concepts. part however especially early stages work viewed samples fundamental object interest rather view distribution sampled way. little concern arises objective function distribution sampled samples used achieve optimization. means little concern issues like convexity implicit objective function. prevents eda’s fully exploiting power continuous space optimization e.g. absence local minima convex problems similarly means eda’s concern cases distribution objective function optimized closed form without need sampling all. widespread appreciation sample re-used help guide optimization contrasts whose distinguishing feature treat variable fundamental object optimized rather distribution across example samples distribution used necessary estimate quantities cannot evaluated ways; fundamental objective function stated terms indeed cases considered paper well earlier work like reported samples arise. shortly introduction variant monte carlo version parallel brouwer updating introduced called method variant annealing lagrangian doesn’t involve changing temperature instead changing value constraint specifying accordingly rather jump directly solution given above solve coupled nonlinear equations relating method justiﬁed argument reviewed rather ratchet-based maximum entropy arguments. redrawn attention role argument-ordering distance relates brouwer updating method. another body work related propagation algorithms bethe approximations like techniques seen alternative semicoordinate transformations beyond product distributions. unlike approaches guaranteed reach local minimum free energy. addition utilities like exploit variance reduction techniques absent techniques. similarly techniques make data-aging. distributed constrained optimization framework based probability collectives presented. motivation framework drawn extension full-rationality game theory bounded rational agents. algorithm capable obtaining solutions simultaneously developed demonstrated problems. results show promising highly distributed oﬀ-the-shelf approach constrained optimization. many avenues future exploration. alternatives lagrange multiplier method used developed constraint satisfaction problems. viewing constraints separate objectives pareto-like optimization procedure developed whereby gradient direction chosen constrained constraints worsened. idea motivated highly successful walksat algorithm k-sat spins ﬂipped previously satisﬁed clause becomes unsatisﬁed result change. probability collectives also oﬀer promise devising methods escaping local minima. unlike traditional optimization methods monotonic transformations objective leave local minima unchanged transformations alter local minima structure lagrangian. observation alternative lagrangians related approach using diﬀerent minimization criterion) oﬀer approaches improved optimization. adopt notation indicates distribution variable marginalized i.e. product analogously properly speaking global minimizer content ﬁnding local minima. n.b. project onto rather vector back distribution relax requirement product particular form; jacobian factor irrelevant permutation. alternatively parameterize smaller space candidate permutations select best amongst note /|zi| uniform across ln|zi|. maximizing thus maximizing respect increases distance determining density samples drawn gaussians centered value width gaussians determined cross validation likelihood. fact non-zero probability obtaining non-integral numbers constraint violations artifact ﬁnite width gaussians. however attempt ﬁrst-principles derivation found practical matter nearest newton gradient-based updating modiﬁed particular step step size large enough would otherwise take unit simplex. changes update ratio step.", "year": 2008}