{"title": "Learning Human Identity from Motion Patterns", "tag": ["cs.LG", "cs.CV", "cs.NE"], "abstract": "We present a large-scale study exploring the capability of temporal deep neural networks to interpret natural human kinematics and introduce the first method for active biometric authentication with mobile inertial sensors. At Google, we have created a first-of-its-kind dataset of human movements, passively collected by 1500 volunteers using their smartphones daily over several months. We (1) compare several neural architectures for efficient learning of temporal multi-modal data representations, (2) propose an optimized shift-invariant dense convolutional mechanism (DCWRNN), and (3) incorporate the discriminatively-trained dynamic features in a probabilistic generative framework taking into account temporal characteristics. Our results demonstrate that human kinematics convey important information about user identity and can serve as a valuable component of multi-modal authentication systems.", "text": "inertial data incorporating biometrics setting characterized limited resources. limitations include computational power model adaptation user real-time inference well absence negative samples. response challenges propose noncooperative non-intrusive method on-device authentication based components temporal feature extraction deep neural networks classiﬁcation probabilistic generative model. assess several popular deep architectures including one-dimensional convolutional nets recurrent neural networks feature extraction. however apart application itself main contribution work developing shift-invariant temporal model ﬁxes deﬁciency recently proposed clockwork recurrent neural networks retains ability explicitly model multiple temporal scales. exploiting wearable mobile inertial sensors authentication action recognition estimating parameters particular activity explored different contexts. gait analysis attracted signiﬁcant attention biometrics community non-contact non-obtrusive authentication method resistant spooﬁng attacks. detailed overview benchmarking existing state-of-the-art provided derawi example used smartphone attached human body extract information walking cycles achieving equal error rate. abstract—we present large-scale study exploring capability temporal deep neural networks interpret natural human kinematics introduce ﬁrst method active biometric authentication mobile inertial sensors. google created ﬁrst-of-its-kind dataset human movements passively collected volunteers using smartphones daily several months. compare several neural architectures efﬁcient learning temporal multi-modal data representations propose optimized shift-invariant dense convolutional mechanism incorporate discriminatively-trained dynamic features probabilistic generative framework taking account temporal characteristics. results demonstrate human kinematics convey important information user identity serve valuable component multi-modal authentication systems. finally demonstrate proposed model successfully applied also visual context. billions smartphone users worldwide remembering dozens passwords services need spending precious seconds entering pins drawing sophisticated swipe patterns touchscreens becomes source frustration. recent years researchers different ﬁelds working creating fast secure authentication alternatives would make possible remove burden user historically biometrics research hindered difﬁculty collecting data practical legal perspective. previous studies limited tightly constrained lab-scale data collection poorly representing real world scenarios limited amount variety data also essential self consciousness participants performing tasks. response created unprecedented dataset natural prehensile movements collected volunteers several months daily apart data collection main challenges developing continuous authentication system smartphones efﬁciently learning task-relevant representations noisy partially obfuscate inter-device variations ensure decorrelation user identity device signature learned data representation introduce low-level additive multiplicative noise training example. following noise vector obtained drawing dimensional obfuscation vector uniform distribution data preprocessing addition extract angles α{xyz} describing orientation vectors phone’s coordinate system compute magnitudes normalize components. finally normalized coordinates angles magnitudes combined -dimensional vector indexing frames. relying cloud computing authenticate mobile user unfeasible privacy latency. although technology well established many mobile services application essentially different others voice search involves constant background collection particularly sensitive user data. streaming information cloud would create impermissible threat privacy perspective users legal perspective service providers. therefore authentication must performed device constrained available storage memory processing power. furthermore adapting user quick resulting limited amount training data positive class. data completely representative typical usage. reasons purely discriminative setting involving learning separate model user even ﬁne-tuning model user would hardly feasible. therefore adapt generative model namely gaussian mixture model estimate general data distribution dynamic motion feature space create universal background model learned ofﬂine i.e. prior deployment phones using large amount pre-collected training data. user small amount enrollment samples perform online adaptation create client model. models used real time inference trust scores allowing continuous authentication. vector features extracted sequence prehensile movements deep neural networks described section probability densities deﬁned feature vectors weighted multi-dimensional gaussian distributions parameterized θ={µi mean vector covariance matrix mixture coefﬁcient overviews preprocessing techniques manual feature extraction accelerometer data activity recognition given. perhaps relevant study ﬁrst report effectiveness rbm-based feature learning accelerometer data proposed data-adaptive sparse coding framework. convolutional networks explored context gesture activity recognition lefebvre applied bidirectional lstm network problem -class gesture classiﬁcation berlemont proposed fully-connected siamese network task. believe multi-modal frameworks likely provide meaningful security guarantees. combination face recognition speech gait voice proposed context. deep learning techniques achieved early success modeling sequential data motion capture video shown promise multi-modal feature learning goal separate user impostor based time series inertial measurements method based components feature extraction pipeline associates user’s motion sequence collection discriminative features biometric model accepts features inputs performs veriﬁcation. feature extraction component interesting novel aspect technique delay discussion section begin discussing data format biometric model. celeration angular velocity denote projections corresponding axes aligned phone. important steps take prior feature extraction. obfuscation-based regularization important differentiate notion device user. dataset collected device assigned single user thus data considered authentic. however real-world scenarios theft authentic imposter data originate device. recent study shown conditions particular device could identiﬁed response motion sensors given signal. happens imperfection calibration sensor resulting constant offsets scaling coefﬁcients output estimated calculating integral statistics data. formally measured output accelerometer gyroscope expressed follows learning effective efﬁcient data representations entire framework since ability perform realworld deﬁned criteria latency representational power extracted features inference speed feature extractor. ﬁrst conditions known contradict performance standalone feature typically grows integration time paradigms strike balance representational power speed dominated feature learning landscape recent years. multi-scale temporal aggregation -dimensional convolutional networks fig. explicit modeling temporal dependencies recurrent neural networks fig. former model popular speech recognition involves convolutional learning integrated temporal statistics short long sequences data short-term architectures produce outputs relatively high rate fail model context. long-term networks learn meaningful representations different scales suffer high degree temporal inertia generalize sequences arbitrary length. recurrent models explicitly model temporal evolutions generate low-latency feature vectors built context previously observed user behavior. dynamic nature representations allow modeling richer temporal structure better discrimination among users acting different conditions. sufﬁciently large number neural architectures proposed modeling temporal dependencies different contexts baseline methods compared work summarized fig. rest section provides brief description models. then section introduces shift-invariant model based modiﬁed clockwork rnns feature extractors ﬁrst pretrained discriminatively multi-device classiﬁcation task then following removal output layer activations penultimate hidden layer provided input generative model described section iii. ﬁnal outputs background client models integrated window. accordingly user either authenticated rejected. input denotes network’s hidden state time feed-forward recurrent weight matrices respectively nonlinear activation function typically tanh. output produced combining hidden this decision made avoid introducing notation index hidden layers well simplify generalize presentation previous section taken generic temporal features. fig. learning data representations static convnet directly operating sequences aggregating temporal statistics temporal pooling; explicitly modeling temporal transitions recurrent connections. client model adapted ubm. models share weights covariance matrices avoid overﬁtting limited amount enrollment data. along lines maximum posteriori adaptation mean vectors given user performed. immediate advantage creating independent user ensuring proper alignment welltrained background model client model updating subset parameters speciﬁc given user. particular given enrollment samples {yq} device create client-speciﬁc update mean mixture component follows ﬁnal step zt-score normalization performed compensate inter-session inter-person variations reduce overlap distribution scores authentic users impostors. only. fig. active rows also shown zero addition multi-scale dynamics creating sparse connections reduces number free parameters inference complexity. long short-term memory networks anvariant rnns recent convolutional extensions proven best performing models learning long-term temporal dependencies. handle information past additional gates regulate memory cell affected input signal. particular input gate allows memory cell’s state forget gate resets memory output gate regulates gates next step affected current cell’s state. basic unit composed input output forget input modulation gates memory cell element parameterized corresponding feed-forward recurrent weights bias vectors. despite effectiveness high complexity architecture appear computationally wasteful mobile setting. furthermore signiﬁcance learning long-term dependencies context continuous mobile authentication compromised necessity early detection switching users. absence annotated ground truth data events efﬁcient training forgetting mechanisms would problematic. given correlation individual frames user identity found strongly beneﬁcial make input layer convolutional regardless model type thereby forcing earlier fusion temporal information. simplify presentation made convolution explicit description methods above however absorbed inputto-hidden matrix fig. temporal models basic recurrent unit; lstm unit clockwork bands base increasing indicates lower operating frequency. grey color indicates inactivity unit. main drawbacks model operates predeﬁned temporal scale. context free motion involves large variability speed changing intervals typical gestures serious limitation. recently proposed clockwork operates several temporal scales incorporated single network trained jointly. decomposes recurrent layer several bands high frequency frequency units band updated pace. size step band band typically increases exponentially deﬁned base number band. cwrnn fast units connected bands beneﬁtting context provided slow bands frequency units ignore noisy high frequency oscillations. equation classical rnns modiﬁed leading update rule k-th band output iteration follows denote rows matrices matrix upper triangular structure corresponds connectivity frequency bands. equation intuitively explained part fig. inspired line corresponds band. time step instance ﬁrst bands updated. triangular structure matrix results band getting updated bands lower frequency components inactive time dark gray. mentioned section iv-a original cwrnn time instant instance unit updated i.e. ﬁrst lines fig. dense network hidden units updated moment time. addition vector previous hidden states replaced lower triangular history matrix size obtained concatenating several columns history activations here number bands. time instances sampled consecutively strided exponential range i.e. finally diagonal elements product triangular matrices form recurrent contribution vector feedforward contribution calculated standard rnn. practical implementation lower-triangular matrix containing history previous hidden activations dcwrnn requires usage additional memory buffer |hk| whereas stated general case |hk|≥ hidden units belonging band training updating bands constant rate important preventing simultaneous overﬁtting highfrequency underﬁtting low-frequency bands. practice leads speedup training process improved performance. finally constant update rate bands dense network learned representations invariant local shifts input signal crucial unconstrained settings input unsegmented. demonstrated section vii. dataset introduced work part general multi-modal data collection effort performed google atap known project abacus. facilitate research worked third party vendor’s panel recruit obtain consent volunteers provide nexus research phones specialized read memory data collection. volunteers complete control data throughout collection well ability review delete sharing research. further volunteers could fact request data deleted. third party vendor acted privacy buffer google atap volunteers. data corpus consisted smartphone sensor signals including images front-facing camera touchscreen bluetooth cell antennae etc. motion data acquired three sensors accelerometer gyroscope magnetometer. study included approximately volunteers using research phones primary devices daily basis. data collection completely passive require action volunteers order ensure data collected representative regular usage. among existing temporal models considered clockwork mechanisms appear attractive computational burden associated combination high modeling capacity. however practice inactivity slow units long periods time cannot respond high frequency changes input produce outputs which sense stale. additionally setting goal learn dynamic data representations serving input probabilistic framework architecture weakness stems fact different bands active given time step. network respond differently input stimuli applied different moments time. shift-variance convolutes feature space introducing shift-associated dimension. work propose solution issues namely twined dense clockwork mechanisms inference scale exist parallel threads shifted respect other time unit belonging threads ﬁres updating state providing input higher frequency units. weights threads belonging band shared keeping overall number parameters network original clockwork architecture. without loss generality keep notation uncluttered unnecessary indices following describe network single hidden unit band generalization multiple units band straightforward experiments course performed general case. matrix concatenating history hidden units deﬁne operator matrices returning diagonal elements column vector. intuition equation given fig. compare update rules original cwrnn proposed dcwrnn using example network hidden units associated base bands. consistent employ matrix form original cwrnn paper show accelerometer gyroscope sensors magnetometer however prevent drain battery accelerometer gyro data recorded device rest. done deﬁning separate thresholds signal magnitude channel. finally accelerometer gyroscope streams synchronized hardware timestamps. even though sampling rate accelerometer gyroscope study noticed intervals readings coming different devices varied slightly. eliminate differences decrease power consumption research resampled data following experiments data devices used discriminative feature extraction training universal background models devices formed validation tuning hyperparameters another devices represented clients testing. section existing relatively small inertial dataset demonstrate ability proposed dcwrnn learn shift-invariant representations. describe study involving large-scale dataset collected wild. explore nature inertial sensor signals performed preliminary analysis hmog dataset containing similar data collected constrained settings part study. data collection performed help volunteers performing sessions predeﬁned tasks reading typing navigation sitting walking. unfortunately direct application whole pipeline corpus relevant absence task-totask transitions single session insufﬁcient data form separate subsets feature learning background model client-speciﬁc subsets enrollment still reserve separate subset impostors testing haven’t seen training. however detailed visual analysis accelerometer gyroscope streams proven inertial data seen combination periodic quasi-periodic signals well non-periodic movements. observation additionally motivates clockwork-like architectures allowing explicit modelling periodic components. subsection describe hmog data explore shift-invariance temporal models explicit reset gates experiment randomly selected sequences normalized accelerometer magnitudes applied three different networks hidden units single output neuron. weights networks initialized randomly normal distribution ﬁxed seed. clockwork architectures used base exponential setting rule bands. finally network performed runs shifted input beginning sequence padded zeros. resulting hidden activations shifted back initial position superimposed. fig. visualizes hidden unit traces sample sequences hmog dataset corresponding different activities reading walking writing sitting. ﬁgure shows dense version clockwork network considered shiftinvariant output cwrnn highly shiftdependent. reason spite atractiveness context multi-scale periodic non-periodic signals usage cwrnn purpose feature learning unsegmented data suboptimal high shiftassociated distortion learned distributions case dcwrnns. evaluate proposed authentication framework real-world dataset described section table appendix provides architectural hyper-parameters chosen convnets well recurrent models. make fair comparison number parameters approximately rnns. convnet trained sequences samples convnets take input samples architectures trained sequences blocks samples inter-block overlap ensure smooth transitions blocks dense sparse clockwork architectures number bands base layers architectures tanh activations. training networks produce softmax output block sequence rather last one. mean per-block negative likelihood loss taken blocks minimized. dimensionality feature space produced networks pca-reduced gmms mixture components trained iterations initialization k-means adaptation device performed iterations relevance factor zt-score normalization exploit data training create t-models z-sequences non-overlapping subsets. t-model trained based adaptation. hyperparameters optimized validation set. networks trained using stochastic gradient descent dropout fully connected layers negative likelihood loss. temporal architectures mean pooling layer applying softmax. element input normalized zero mean unit variance. deep nets implemented theano trained nvidia tesla gpus. ubm-gmms trained toolbox employ gpus. feature extraction ﬁrst performed quantitative evaluation effectiveness feature extractors alone multi-class classiﬁcation problem class corresponds devices training set. class meant correspond user equal device training data justify assumption manually annotated periods non-authentic usage based input smartphone camera excluded sessions test training sets. experiments showed percentage sessions insigniﬁcant presence training data almost effect classiﬁcation performance. note test generative model considered feature extractor simply evaluated terms classiﬁcation accuracy. deﬁne accuracy must consider human kinematics sensed mobile device considered weak biometric used perform soft clustering users behavioral groups. evaluate quality feature extractor classiﬁcation scenario session obtained aggregated probabilities target classes selected classes highest probability that user behavior considered interpreted correctly ground truth label among them. accuracy obtained type deep network corresponding number parameters reported table results show feed forward convolutional architectures generally perform poorly among temporal models proposed dense clockwork mechanism conv-dcwrnn appeared effective original clockwork network slightly outperformed lstm. authentication evaluation moving binary authentication problem optimal balance false rejection false acceptance rates captured classiﬁcation accuracy becomes particularly important. validation subset optimize generative model minimal equal error rate obtained threshold value θeer used evaluate performance test using half total error rate criterion hter frr] false acceptance false rejection rates respectively. validation also provide average per-device means time correct user using device s/he authenticated s/he moves holds phone necessarily interacting also means time system identiﬁes user correct one. results align well estimated quality feature extraction case show context-aware features efﬁciently incorporated generative setting. compare performance traditional approach retraining ﬁnetuning separate deep model device randomly drew devices validation replaced output layer pretrained lstm feature extractor binary logistic regression. average performance small subset inferior respect overﬁtting enrollment data poor generalization unobserved activities. efﬁciently handled mean-only adaptation general distribution probabilistic setting. another natural question whether proposed model learns something speciﬁc user style performing tasks rather typical sequence tasks itself. explore this performed additional tests extracting parts session users interacted application observed results almost identical ones previously obtained whole dataset indicating correlation particular activity. viii. model adaptation visual context finally would like stress proposed dcwrnn framework also applied sequence modeling tasks including visual context. described model speciﬁc data type particular reason cannot applied general human kinematic problem support claim conducted additional tests proposed method within task visual gesture recognition. namely provide results motion capture modality chalearn looking people gesture dataset dataset contains instances italian conversational gestures detect recognize localize gestures continuous noisy recordings. generally corpus comprises multimodal data captured kinect therefore includes video depth stream mocap data. however last channel used round experiments. model evaluation performed using jaccard index penalizing errors classiﬁcation well imprecise localization. direct application gesture recognition suboptimal therefore task perform end-to-end discriminative training model evaluate effectiveness feature extraction dense cwrnn model. spirit skeleton descriptor input. however described authentication framework input convolutional temporal architecture instead directly concatenating frames spatio-temporal volume. ﬁnal aggregation localization step correspond table reports jaccard index per-sequence classiﬁcation accuracy shows application proposed dcwrnn also outperforms alternative solutions. modeling perspective work demonstrated temporal architectures particularly efﬁcient learning dynamic features large corpus noisy temporal signals learned representations incorporated generative setting. respect particular application conﬁrmed natural human kinematics convey necessary information person identity therefore useful user authentication mobile devices. obtained results look particularly promising given fact system completely non-intrusive non-cooperative i.e. require effort user’s side. non-standard weak biometrics particularly interesting providing context example face recognition speaker veriﬁcation scenarios. augmentation data extracted keystroke touch patterns user location connectivity application statistics creating ﬁrst secure non-obtrusive mobile authentication framework. finally additional round experiments demonstrated proposed dense clockwork successfully applied tasks based analysis sequential data gesture recognition visual input. table provides complete hyper-parameters chosen based held-out validation set. convolutional nets distinguish convolutional layers fully-connected layers recurrent models report total number units provide details zt-normalization given section recall estimate authenticity given motion features scoring features universal background model client model. speciﬁcally threshold log-likelihood ratio ofﬂine z-step compensates intermodel variation normalizing scores produced client model zero mean unit variance order single global threshold test session impostor sessions. parameters deﬁned given user model enrollment completed. then -norm compensates inter-session differences scoring session background -models. t-models typically obtained map-adaptation universal background model client models using different subsets training corpus. z-sequences taken part training data used t-models. hannun case casper catanzaro diamos elsen prenger satheesh sengupta coates deepspeech scaling end-to-end speech recognition. arxiv preprint arxiv. kahou bouthillier froumenty gülçehre memisevic vincent courville bengio. combining modality speciﬁc deep neural networks emotion recognition video. icmi neverova wolf taylor nebout. moddrop adaptive multi-modal gesture recognition. ieee transactions pattern analysis machine intelligence appear. deepak chandra heads authentication machine intelligence research group google. project aims completely redeﬁning authentication digital physical world. prior program lead google’s advanced technology projects organization heads product engineering design mobile authentication projects. deepak deﬁned company wide authentication strategy motorola prior leading efforts google. developed multiple wearable authentication products including brandon barbello product manager google research machine intelligence works privacy-sensitive on-device machine learning. previously google advanced technology projects project abacus team managed efforts develop multimodal continuous authentication system smartphones. prior google brandon co-founded four companies across electronics ﬁntech private equity. graham taylor assistant professor university guelph. interested statistical machine learning biologically-inspired computer vision emphasis unsupervised learning time series analysis. completed university toronto thesis co-advisors geoffrey hinton roweis. postdoc chris bregler fergus yann lecun. natalia neverova candidate insa lyon liris working area gesture action recognition emphasis multi-modal aspects deep learning methods. advised christian wolf graham taylor research part interabot project partnership awabot sas. visiting researcher university guelph google christian wolf assistant professor insa lyon liris cnrs since interested computer vision machine learning especially visual analysis complex scenes motion structured models graphical models deep learning. received computer science vienna university technology national institute applied science obtained habilitation diploma. grifﬁn lacey masters applied science student university guelph. primary research interests developing tools techniques support deep learning fpgas. recently acted visiting researcher google. grifﬁn holds beng engineering systems computing university guelph. fridman postdoctoral associate massachusetts institute technology received drexel university. research interests include machine learning decision fusion computer vision applied especially detection analysis human behavior semiautonomous vehicles.", "year": 2015}