{"title": "Towards Adversarial Retinal Image Synthesis", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Synthesizing images of the eye fundus is a challenging task that has been previously approached by formulating complex models of the anatomy of the eye. New images can then be generated by sampling a suitable parameter space. In this work, we propose a method that learns to synthesize eye fundus images directly from data. For that, we pair true eye fundus images with their respective vessel trees, by means of a vessel segmentation technique. These pairs are then used to learn a mapping from a binary vessel tree to a new retinal image. For this purpose, we use a recent image-to-image translation technique, based on the idea of adversarial learning. Experimental results show that the original and the generated images are visually different in terms of their global appearance, in spite of sharing the same vessel tree. Additionally, a quantitative quality analysis of the synthetic retinal images confirms that the produced images retain a high proportion of the true image set quality.", "text": "synthesizing images fundus challenging task previously approached formulating complex models anatomy eye. images generated sampling suitable parameter space. work propose method learns synthesize fundus images directly data. that pair true fundus images respective vessel trees means vessel segmentation technique. pairs used learn mapping binary vessel tree retinal image. purpose recent image-to-image translation technique based idea adversarial learning. experimental results show original generated images visually different terms global appearance spite sharing vessel tree. additionally quantitative quality analysis synthetic retinal images conﬁrms produced images retain high proportion true image quality. modern machine learning methods require large amounts data trained. data rarely available ﬁeld medical image analysis since obtaining clinical annotations often costly process. therefore possibility synthetically generating medical visual data greatly appealing explored years. however realistic generation high-quality medical imagery still remains complex unsolved challenge current computer vision methods. early methods medical image generation consisted digital phantoms following simpliﬁed mathematical models human anatomy models slowly evolved complex techniques able reliably model relevant aspects different acquisition devices. combined anatomical physiological information arising expert medical knowledge realistic images produced useful validate image analysis techniques medical training therapy planning wide range applications. however traditional top-down approach observing available data formulating mathematical models explain implies modeling complex natural laws unavoidably simplifying assumptions. recently paradigm arisen ﬁeld medical image generation exploiting bottom-up approach directly learning data relevant information. achieved machine learning systems able automatically learn inner variability large training dataset trained system sampled output plausible image general computer vision ﬁeld synthesis natural images recently experimented dramatic progress based general idea adversarial learning context generator component synthesizes images random noise auxiliary discriminator system trained real data assigned task discerning whether generated data real not. training process generator expected learn produce images pose increasingly difﬁcult classiﬁcation problem discriminator. although adversarial techniques achieved great success generation natural images application medical imaging still incipient. partially lack large amounts training data partially difﬁculty ﬁnely controlling output adversarial generator. work propose apply adversarial learning framework retinal images. notably instead generating images scratch propose generate plausible images binary retinal vessel trees. therefore task generator remains achievable needs learn generate part retinal content optical disk texture background remaining work organized follows ﬁrst describe recent generative adversarial framework employed pairs vessel trees retinal images learn former latter. then brieﬂy review u-net deep convolutional neural network architecture designed image segmentation allows generate pairs retinal images corresponding binary vessel trees. model provides dataset vessel trees corresponding retinal images train adversarial model producing goodquality retinal images vessel tree. finally quality generated images evaluated qualitatively quantitatively description potential future research directions presented. image-to-image translation relatively recent computer vision task goal learn mapping called generator image another representation model trained able predict likely representation previously unseen image xnew. however many problems single input image correspond many different correct representations. consider mapping retinal vessel tree corresponding retinal fundus image variations color illumination produce many acceptable retinal images correspond vessel tree i.e. rn}. directly related choice objective function minimized learning turns critical. training model naively minimize distance collection training pairs given known produce low-quality results lack detail model selecting average many equally valid representations. instead explicitly deﬁning particular loss function task possible employ generative adversarial networks implicitly build appropriate loss case learning process attempts maximize misclassiﬁcation error neural network trained jointly goal discriminating real generated images. also loss progressively learned examples adapt other tries generate increasingly plausible representations deceive becomes better task thereby improving ability generate high-quality samples. speciﬁcally adversarial loss deﬁned evr∼pdata represents expectation log-likelihood pair sampled underlying probability distribution real pairs pdata pdata corresponds distribution real vessel trees. overview process shown figure generate realistic retinal images binary vessel trees follow recent ideas propose combine adversarial loss global loss produce sharper results. thus loss function optimize becomes balances contribution losses. goal learning process thus equilibrium expression. discriminator attempts maximize classifying patch retinal image deciding comes real synthetic image generator aims minimizing loss controls low-frequency information images generated order produce globally consistent results adversarial loss promotes sharp results. trained able produce realistic retinal image binary vessel tree. model described requires training data form pairs binary retinal vessel trees corresponding retinal images. since large scale manually annotated database available apply state-of-the-art retinal vessel segmentation algorithm obtain enough data model learn mapping vessel trees retinal images. exist large number methods capable providing reliable retinal vessel segmentations. employ supervised method based convolutional neural networks namely u-net architecture ﬁrst proposed segmentation biomedical images. technique extension idea fully-convolutional networks introduced adapted trained number images produce precise segmentations. architecture u-net consists downsampling upsampling block. ﬁrst half network follows typical architecture stacked convolutional layers stride rectiﬁed linear unit activations. second part architecture upsamples input input feature symmetrically downsampling path. feature last layer downsampling path upsampled dimension second last layer. result concatenated feature corresponding layer downsampling path feature undergoes convolution activation. repeated upsampling path layers reach dimensions ﬁrst layer network. ﬁnal layer convolution followed sigmoid activation order feature vector vessel/non-vessel classes. concatenation operation allows precise spatial localization preserving coarse-level features learned downsampling path. representation architecture used present work depicted figure purpose retinal vessel segmentation drive database used train method described previous section. images ground truth annotations divided overlapping patches pixels randomly u-net patches used validation. network trained using adam optimizer binary crossentropy loss function. retinal vessel segmentation using u-net evaluated drive’s test achieving aligned state-of-the-art results optimal binarization threshold maximizing youden index selected. messidor images cropped order display ﬁeld view downscaled then segmentation method applied images. messidor contains images annotated corresponding diabetic retinopathy grade displays color texture variability drive’s training images. u-net trained tested different datasets produced segmentations entirely correct. related drive containing examples images signs mild diabetic retinopathy reason decided retain pairs images vessel trees corresponding image grade ﬁnal dataset collected training adversarial model consisted messidor image pairs. dataset randomly divided training validation test sets. regarding image resolution original model used pairs images u-net-like generator modiﬁed architecture handle pairs closer resolution drive images. that added layer downsampling part another upsampling part discriminator classiﬁes overlapping patches size implementation developed python using keras learning process starts training real generated pairs then trained real pairs. process repeated iteratively losses stabilize. figure results model. first true retinal images test used training. second vessel trees obtained segmenting images ﬁrst row. third corresponding retinal images generated model. images resolution. subjective visual evaluation images generated model show figure results. ﬁrst depicts random sample real images extracted held-out test used training. second shows vessel trees segmented images method outlined section bottom shows synthetic retinal images produced proposed technique. original generated images share global geometric characteristics. natural since approximately share vascular structure. however synthetic images markedly different high-level visual features color tone image illumination. information extracted model training effectively applied input vessel trees order produce realistic retinal images. ﬁrst seven columns figure show results model behaved expected vessel trees retrieved images ﬁrst approximately correct provided sufﬁcient information generator create consistent information synthetic image shown last row. last column figure shows failure case proposed technique. therein segmentation technique described section failed produce meaningful vessel network original image. probably high degree defocus input image had. situation binary vessel tree supplied generator contained information leading appearance spurious artifacts chromatic noise synthetic image. fortunately amount cases happens relatively test images found suffer artifacts. objective image quality veriﬁcation known hard challenge reference available addition generative models recently observed specialized evaluation performed problem case achieve meaningful objective quantitative evaluation quality generated images apply different retinal image quality metrics namely score proposed image structure clustering metric metrics employed previously assess quality retinal images. score focuses assessment contrast around vessel pixels metric performs global evaluation. thus together provide appropriate mechanism quantitatively evaluate correctness synthetically generated retinal image. worth noting cases artifacts distortions generated undercomplete vessel network problem explained above metric tended artiﬁcially rise quality synthetic image compared real one. this synthetic images containing class degradations manually identiﬁed removed metric analysis below together real counterparts. detailed discussion employed retinal image quality metrics behavior distorted images supplied provided appendix together supplementary results generated proposed technique. score computed reduced test images score computed images. statistical analysis performed quality score distributions showed normal according kolmogorov-smirnov test. resulting data therefore expressed mean standard deviation compared paired student’s t-test. p-values two-tailed considered signiﬁcant. statistical analyses performed using graphpad prism software. results obtained methodology shown table case metric synthetic images produced slightly higher quality score difference statistically signiﬁcant score real images considered better quality regard synthetic counterparts difference statistically signiﬁcant however considered score consists anisotropy measure weighted values simple vessel detector case expected image regions around vessels synthetic image won’t probably better quality original ones. hand results metric global nature point similar quality real synthetic images agrees subjective visual quality found produced images appendix visual quantitative results demonstrate feasibility learning synthesize retinal images dataset pairs retinal vessel trees corresponding retinal images applying current generative adversarial models. addition dimension produced images greater commonly generated images general computer vision problems. believe achieving resolution possible constrained class images method applied contrarily generic natural images retinal images show repetitive geometry high-level structures ﬁeld view optical disc macula usually present image guide model learn produce texture background intensities. main limitation presented method dependence pre-existing vessel tree order generate image. furthermore vessel tree comes application segmentation technique original image potential weaknesses segmentation algorithm inherited synthesized image. currently working overcoming challenges. work ﬁnanced erdf european regional development fund operational programme competitiveness internationalisation compete programme national funds fundação para ciência tecnologia within project cmup-eri/tic// north portugal regional operational programme portugal partnership agreement within project \"nanostima macro-to-nano human sensing towards integrated multimodal health monitoring analytics/norte---feder-\". recipient robert watzke professor ophthalmology visual sciences. interest algorithms discussed study. discuss technical details retinal image quality metrics employed work. regarding score no-reference quality metric proceeds computing local degree vesselness around pixel. achieved building multiscale version input image represented local hessian matrix around pixel extracted green channel. frangi’s vesselness measure computed used estimate visible vessel pixels. following anisotropy measure based local singular value decomposition computed ﬁnal quality score obtained weighted average vesselness local anisotropy values. vessel pixels considered metric since expected good candidates reliable contrast focus estimate. hand image structure clustering proposed follows substantially different approach. even also no-reference quality metric trained dataset retinal images. dataset contained images previously labeled medical experts depending whether showed enough visibility perform diagnosis. metric assesses correct distribution pixel intensities corresponding relevant anatomical structures present retina. achieved extracting features consisting intensities gaussian derivatives channels employing k-means group different clusters. observed sufﬁcient model relevant regions retinal image histograms counts computed features passed trained predict presence proportion pixels associated structures consistent according training correspondent quantities. metrics seem thus quite complementary since technique considers regions image addressed score. experiments however noticed artifacts produced generative model provided undercomplete vessel tree tended rise score. drawback observed score computed. believe reason following starting real synthetic image method employs vessel tree extracted synthesize image; thus amount vessel pixels present real image always greater corresponding synthetic image favoring score. metric rely vessels anatomical structures. addition considers three color channels score employs them. supplied image artifacts figure score ﬁnds proportion colors edges adequate still relatively acceptable situation detected images entire images present test set. accordingly fair comparison images removed statistical experiments involved score. since score seemed unaffected problem include every test image analysis. believe current retinal image quality metrics reasonably suitable assess visual quality synthetic images. however study anatomical plausibility images beneﬁt speciﬁcally designed quality metrics involve different aspects existing quality assessment approaches.", "year": 2017}