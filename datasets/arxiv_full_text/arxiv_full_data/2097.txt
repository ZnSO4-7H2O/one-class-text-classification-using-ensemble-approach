{"title": "Objective Improvement in Information-Geometric Optimization", "tag": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "abstract": "Information-Geometric Optimization (IGO) is a unified framework of stochastic algorithms for optimization problems. Given a family of probability distributions, IGO turns the original optimization problem into a new maximization problem on the parameter space of the probability distributions. IGO updates the parameter of the probability distribution along the natural gradient, taken with respect to the Fisher metric on the parameter manifold, aiming at maximizing an adaptive transform of the objective function. IGO recovers several known algorithms as particular instances: for the family of Bernoulli distributions IGO recovers PBIL, for the family of Gaussian distributions the pure rank-mu CMA-ES update is recovered, and for exponential families in expectation parametrization the cross-entropy/ML method is recovered. This article provides a theoretical justification for the IGO framework, by proving that any step size not greater than 1 guarantees monotone improvement over the course of optimization, in terms of q-quantile values of the objective function f. The range of admissible step sizes is independent of f and its domain. We extend the result to cover the case of different step sizes for blocks of the parameters in the IGO algorithm. Moreover, we prove that expected fitness improves over time when fitness-proportional selection is applied, in which case the RPP algorithm is recovered.", "text": "information-geometric optimization uniﬁed framework model based stochastic search algorithms optimization problem. typiﬁed estimation distribution algorithms model based randomized search algorithms build statistical model search space generate search points. parameters statistical model updated time probability distribution hopefully concentrates around minimum objective function. model based algorithms edas colony optimization algorithms parameter calibration based maximum likelihood principle intuitive ways. unlike them performs natural gradient ascent parameter space ﬁrst adaptively transformed objective function function construction oﬀers maximal robustness guarantees respect changes representation problem importantly framework recovers several known algorithms instantiated using family bernoulli distributions obtains population based incremental learning algorithm using family gaussian distributions instantiates variant covariance matrix adaptation evolution strategies so-called pure rank-µ cma-es update moreover using exponential family expectation parameters instance equivalent cross-entropy method optimization course framework provides information-theoretic derivations existing algorithms automatically oﬀers algorithms possibly complicated optimization problems. instance update rule parameters restricted boltzmann machines derived theoretical justiﬁcation framework therefore important provide theoretical basis recovered algorithms make design principle future algorithms reliable. focus providing measure progress course optimization terms quantile values objective function. parameter updates gradient ascent somewhat justiﬁed general least inﬁnitesimally small steps because gradient points direction steepest ascent function. however argument apply algorithm objective function adaptively transformed time-dependent function abstract information-geometric optimization uniﬁed framework stochastic algorithms optimization problems. given family probability distributions turns original optimization problem maximization problem parameter space probability distributions. updates parameter probability distribution along natural gradient taken respect fisher metric parameter manifold aiming maximizing adaptive transform objective function. recovers several known algorithms particular instances family bernoulli distributions recovers pbil family gaussian distributions pure rank-µ cmaes update recovered exponential families expectation parametrization cross-entropy/ml method recovered. article provides theoretical justiﬁcation framework proving step size greater guarantees monotone improvement course optimization terms q-quantile values objective function range admissible step sizes independent domain. extend result cover case diﬀerent step sizes blocks parameters algorithm. moreover prove expected ﬁtness improves time ﬁtness-proportional selection applied case algorithm recovered. permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. foga’ january adelaide australia. copyright ----// ..... ural gradient algorithm ﬁtness-proportional selection scheme monotone improvement expected ﬁtness proven. short discussion section closes article. {pθ} family probability distributions parametrized probability density function induced w.r.t. arbitrary reference measure namely pθdx. given family probability distributions evolves probability distribution time higher probabilities assigned better regions. transforms objective function deﬁnes function maximized performs steepest gradient ascent hopefully time distribution concentrates around minima objective function. designed exhibit many invariance properties possible ﬁrst property invariance strictly increasing transformations strictly increasing minimizes easily property realized quantile based mapping time. second property invariance change coordinates provided coordinate change globally preserves family probability distributions {pθ}. example algorithm gaussian distributions invariant aﬃne transformation coordinates whereas algorithm isotropic gaussian distribution invariant translation rotation. invariance xcoordinate transformation properties success cma-es. last property invariance reparametrization least inﬁnitesimal steps gradient ascent follows trajectory parameter space whatever parametrization property obtained considering intrinsic metric parameter space deﬁning steepest ascent w.r.t. metric i.e. using natural gradient. study intrinsic metric parameter space probability distribution called statistical manifold main topic information geometry widely used divergence points space probability distributions kullback–leibler divergence gradient computed changes time increase necessarily mean global improvement. still framework comes guarantee inﬁnitesimally small step along natural gradient leads monotone improvement speciﬁed quantity objective function result q-quantile value objective function monotonically improves along natural gradient. result limited exact i.e. inﬁnite number sample points considered step size gradient ascent inﬁnitesimal. still ensures randomized algorithm large sample size stays close deterministic trajectory inﬁnite samples high probability provided step size suﬃciently small. question arises whether actual non-inﬁnitesimal step sizes still ensure monotone q-quantile improvement. article prove step size greater guarantees monotone q-quantile value improvement algorithm exponential family ﬁnite step size thus extending previous result inﬁnitesimal steps continuous time realistic algorithmic situations. instance ensures monotone q-quantile improvement pbil cross-entropy method exponential families expectation parameters. interestingly results show admissible step sizes independent objective function least large population sizes extend result deﬁning blockwise updates diﬀerent blocks parameters adjusted another diﬀerent step sizes. motivation practice pure rank-µ update cma-es updates mean vector covariance matrix diﬀerent learning rates. show blockwise update rule recovers pure rank-µ cma-es update using diﬀerent learning rates mean vector covariance matrix prove distinct step sizes less guarantee monotone q-quantile improvement justiﬁes parameter setting used cma-es practice examples ﬁtting framework relative payoﬀ procedure situations ﬁtness-proportional selection applied using exponential families considered alternative gradient based methods allows relatively large learning rates. turns described natural gradient based algorithm step size result extension proof monotone improvement generic natural gradient algorithms. article organized follows. section explain framework implementation practice. igo-maximum likelihood variant maximum likelihood presented followed relation algorithm igo-ml cross-entropy method optimization exponential families distributions. section prove monotone q-quantile improvement igo-ml. result extended deﬁning blockwise igo-ml q-quantile improvement blockwise igo-ml proved. also provide result ﬁnite large population sizes. section devoted natfinally uses natural gradient ascent parameter space. natural gradient statistical manifold equipped fisher metric given product inverse fisher information matrix vanilla gradient. natural gradient written ˜∇θj ∇θj. according rewrite natural gradient mathematically neater deﬁnition rank based weights accounting possible ties. practice design weight values instead selection scheme rest article assume simplicity selection weights non-negative case instance selection scheme q-truncation above. expansion follows well-known fact fisher information matrix hessian divergence. using divergence following property steepest ascent direction theorem proposition since divergence depend parametrization natural gradient invariant reparametrization hence natural gradient step—steepest ascent step w.r.t. fisher metric—is invariant least inﬁnitesimal step size first transforms objective function adaptive weighted preference quantile based approach. results rank based algorithm invariant increasing transformations objective function. deﬁne lower upper pθ-f -quantiles lower quantile value probability sampling strictly better points current distribution upper quantile value probability sampling points better equivalent given weight function non-increasing weighted preference deﬁned quality point measured function pθ-quantile lies. typical choice selection scheme call q-truncation selection scheme. using q-truncation amounts ﬁnal algorithm giving positive weight fraction best samples population weight rest often case practice. finally obtain explicit form parameter update equation need know explicit form natural gradient log-likelihood depends family probability distributions parametrization. explicit forms known speciﬁc families probability distributions speciﬁc parametrizations algorithm sometimes coincides several known algorithms. note ﬁniteinﬁnite-population igo-ml updates make sense unique maximizer respectively. assumption always satisﬁed instance exponential families probability distributions considered ≤i≤n so-called natural parameter; linearly independent; normalization factor. linear independence ensures manifold exponential family nonsingular. many probability models including multivariate gaussian ≤i≤n so-called expectation parameter. example expectation parameter multivariate gaussian distribution encodes ﬁrst moment second moment examples found function restriction placed belong statistical manifold necessary instance gaussian distributions number points greater dimension ambient space degenerate distribution result.) following statement shows natural gradient function expectation parametrization given vanilla gradient function w.r.t. normal parameter vice versa. tion statistical manifold exponential family above. components natural gradient w.r.t. expectation parameters given vanilla gradient w.r.t. natural parameters vice versa optimization using exponential family {pθ} three algorithms coincide igo-ml; expressed expectation parameters; ce/ml expressed expectation parameters. exponential family expectation parametrization remark malag`o study information-geometric aspects exponential families optimization. diﬀerence framework optimization problem deﬁned minimization expectation objective function namely call stochastic relaxation original optimization problem. study exponential family discrete search space natural parametrization propose natural gradient descent algorithm. note requires computation empirical fisher information matrix perform natural gradient descent. however algorithm modiﬁed expectation parameters instead compute natural gradient descent directly possible provide theoretical backing optimization algorithm show monotonic improvement step algorithm example consider sphere function kxk. then easy show gradient steps xt+δt generate monotonically decreasing sequence provided smooth function inﬁnitesimal gradient steps guaranteed improve objective function values; general feature framework invariance changing objective function increasing transformation thus measure progress compatible transformations good candidate always improve course optimization. measure improvement arnold notion q-quantile q-quantile under probability distribution number instance median value smooth distributions continuous number general closed interval instance jumps. sake deﬁniteness largest value second condition equality typically happens discrete search spaces spaces q-quantile evolves time discrete jumps even moves smoothly cannot expect strict quantile improvement step. hand continuous distributions continuous search spaces second equality condition occur objective function plateau remember idea follows letting points objective function smallest choice equal elsewhere represents times pθ-probability falling thus mean pθ-probability falling larger improves q-quantile decreased. going prove igo-ml update satisﬁes pθt+δt precisely prove practice explicit algorithms continuous time inﬁnitesimal time steps time step quite large calibration important issue. interesting important long steps take along natural gradient i.e. large choose guaranteeing q-quantile improvement. expectation parameter always obvious one. comes multivariate gaussian distributions expectation parameter mean vector second moment meanwhile cmaes ce/ml method continuous optimization parametrize mean vector covariance matrix hence diﬀer igo-ml algorithm. moreover sometimes diﬀerent step sizes employed parameter makes direction parameter update diﬀerent natural gradient. here justify settings guaranteeing q-quantile improvement extended framework. note blockwise igo-ml depends decomposition parameters blocks update order independent parametrization inside block. blockwise igo-ml necessarily equivalent igo-ml even equal proposition pure rank-µ cma-es update instance blockwise igo-ml gaussian distributions parameter decomposition covariance matrix mean vector. example bernoulli distributions constitute exponential family suﬃcient statistics parameter used pbil indeed expectation parameter. thus pbil instance igo-ml viewed ce/ml method time. hence theorem inﬁnite-population pbil step leads q-quantile improvement employ q-truncation selection exponential weights introduced remark proof theorem quantitative kullback–leibler divergence indicates much progress made. precisely probability fall best percent points deﬁnition probability pθt+δt fall best percent points least considering exponential family gaussian distributions whose mean vector ﬁxed viewed ordinary igo-ml step restricted model. then since expectation parameter restricted model update given namely assume deﬁning partial inﬁnite-population igo-ml update uniquely determined. inﬁnitepopulation blockwise igo-ml step leads q-quantile improvement consequently inﬁnite-population step pure rank-µ cma-es update guarantees q-quantile improvement. indeed proposition variant cma-es instance blockwise igo-ml. moreover level zero lebesgue measure often holds continuous optimization strict q-quantile improvement. θtj− θtj−. right-hand side inequality non-negative therefore moreover since pθt+ least θtj− thus implying completes proof. finite population sizes results valid ideal updates inﬁnite sample size. ﬁnite sample size update deﬁnes stochastic sequence cannot expect monotone q-quantile improvement step. still expect q-quantile improvement high probability population size suﬃciently large. provide analogue theorem ﬁnite large population size. similar statement holds blockwise igo-ml. proof follows standard probabilistic approximation argument. proposition q-truncation selection scheme {pθ} exponential family probability distributions parametrized expectation parameter. assume deﬁning inﬁnite-population igo-ml step uniquely deﬁned. note assumption ideal dynamics reached equilibrium θt+δt ﬁnitepopulation dynamics randomly wander around equilibrium value noise resulting either improvement deterioration step. also note population size needed depend current location parameter space well objective function instance highly oscillating functions likely require higher population sizes consistent estimation igo-ml update. sometimes employed avoid issue. theorem however ensures natural gradient step improves expected ﬁtness exponential family used expectation parameters. reinforcement learning algorithm also known expectationmaximization algorithm reinforcement learning expresses policy action space bernoulli distribution parametrized expectation parameter. objective maximized expectation non-negative reward taking action updates parameters proof. exponential families igo-ml updates coincide. conditions theorem ﬁnite-population update consistent estimator inﬁnite-population update implying θt+δt converges probability θt+δt regularity assumptions implies pointθt wise convergence pθt+δt bounded leads right-hand side greater shown proof theounless θt+δt thus high probability suﬃciently large thus lemma entails q-quantile improvement high probability. fitness-proportional selection results carry composite function objective function selection weight instead framework. covers instance ﬁtness-proportional selection prove that considering natural gradient ascent exponential family using expectation parameter guarantee monotone ]-value improvement updates step size inversely proportional precisely gradient based methods ﬁtness-proportional selection often employed especially reinforcement learning e.g. policy gradient parameter based exploration disadvantage gradient based methods step size calibrated user depending problem hand. alternative methods expectation-maximization including below known monotonically improve expected reward thanks expectation-maximization interpretation. theorem thought extension result also shows monotone improvement smoothed step size introduced. remark mentioned remark malag`o propose natural gradient algorithm discrete optimization using exponential distributions. however parametrize exponential distributions natural parameters theorem guarantee expected results contribute bringing theory closer practice waiving need inﬁnitesimal step sizes gradient ascent. still cover ideal situation inﬁnite population size well ﬁnite large population sizes finite population sizes lead stochastic behavior monotone objective improvement step occurs high probability. practice population sizes used quite small medium small step sizes shown population size tend inﬁnity expectation natural gradient estimate natural gradient diﬀerent selection scheme using truncation weight small population size small step sizes result machinery stochastic approximation simulating inﬁnite-population step another selection scheme situation outside scope article. results contrary suggest using larger populations larger step sizes instead. finally stress objective improvement itself suﬃcient guarantee optimization performs well situations premature convergence objective still improves step. premature convergence occur large values learning rate instantiations igo-ml results nothing phenomenon. continuous time trajectories isotropic evolution strategies monotonic c-composite functions. parallel problem solving nature ppsn international conference number lecture notes computer science pages taormina italy september springer. bidirectional relation evolution strategies natural evolution strategies. schaefer cotta kolodziej rudolph editors parallel problem solving nature ppsn international conference volume lecture notes computer science pages krak´ow poland september springer. distribution algorithms tool evolutionary computation. estimation distribution algorithms tool evolutionary computation. kluwer academic publishers geometry estimation distribution algorithms based exponential family. h.-g. beyer langdon editors foga proceedings workshop proceedings foundations genetic algorithms pages", "year": 2012}