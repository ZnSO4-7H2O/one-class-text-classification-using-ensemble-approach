{"title": "SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image  Segmentation", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network. The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN and also with the well known DeepLab-LargeFOV, DeconvNet architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance.  SegNet was primarily motivated by scene understanding applications. Hence, it is designed to be efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than other competing architectures. We also performed a controlled benchmark of SegNet and other architectures on both road scenes and SUN RGB-D indoor scene segmentation tasks. We show that SegNet provides good performance with competitive inference time and more efficient inference memory-wise as compared to other architectures. We also provide a Caffe implementation of SegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.", "text": "abstract—we present novel practical deep fully convolutional neural network architecture semantic pixel-wise segmentation termed segnet. core trainable segmentation engine consists encoder network corresponding decoder network followed pixel-wise classiﬁcation layer. architecture encoder network topologically identical convolutional layers network role decoder network resolution encoder feature maps full input resolution feature maps pixel-wise classiﬁcation. novelty segnet lies manner decoder upsamples lower resolution input feature map. speciﬁcally decoder uses pooling indices computed max-pooling step corresponding encoder perform non-linear upsampling. eliminates need learning upsample. upsampled maps sparse convolved trainable ﬁlters produce dense feature maps. compare proposed architecture widely adopted also well known deeplab-largefov deconvnet architectures. comparison reveals memory versus accuracy trade-off involved achieving good segmentation performance. segnet primarily motivated scene understanding applications. hence designed efﬁcient terms memory computational time inference. also signiﬁcantly smaller number trainable parameters competing architectures trained end-to-end using stochastic gradient descent. also performed controlled benchmark segnet architectures road scenes rgb-d indoor scene segmentation tasks. quantitative assessments show segnet provides good performance competitive inference time efﬁcient inference memory-wise compared architectures. also provide caffe implementation segnet demo http//mi.eng.cam.ac.uk/projects/segnet/. index terms—deep convolutional neural networks semantic pixel-wise segmentation indoor scenes road scenes encoder decoder pooling upsampling. semantic segmentation wide array applications ranging scene understanding inferring support-relationships among objects autonomous driving. early methods relied lowlevel vision cues fast superseded popular machine learning algorithms. particular deep learning seen huge success lately handwritten digit recognition speech categorising whole images detecting objects images active interest semantic pixel-wise labelling however recent approaches tried directly adopt deep architectures designed category prediction pixel-wise labelling results although encouraging appear coarse primarily pooling sub-sampling reduce feature resolution. motivation design segnet arises need resolution features input resolution pixel-wise classiﬁcation. mapping must produce features useful accurate boundary localization. architecture segnet designed efﬁcient architecture pixel-wise semantic segmentation. primarily motivated road scene understanding applications require ability model appearance shape understand spatial-relationship between different classes road side-walk. typical road scenes majority pixels belong large classes road building hence network must produce smooth segmentations. engine must also ability delineate objects based shape despite small size. hence important retain boundary information extracted image representation. computational perspective necessary network efﬁcient terms memory computation time inference. ability train end-to-end order jointly optimise weights network using efﬁcient weight update technique stochastic gradient descent additional beneﬁt since easily repeatable. design segnet arose need match criteria. encoder network segnet topologically identical convolutional layers remove fully connected layers makes segnet encoder network signiﬁcantly smaller easier train many recent architectures component segnet decoder network consists hierarchy decoders corresponding encoder. these appropriate decoders max-pooling indices received corresponding encoder perform non-linear upsampling input feature maps. idea inspired architecture designed unsupervised feature learning reusing max-pooling indices decoding process several practical advantages; improves boundary delineation reduces number parameters enabling end-to-end training form upsampling incorporated encoder-decoder architecture little modiﬁcation. main contributions paper analysis segnet decoding technique widely used fully convolutional network order convey practical trade-offs involved designing segmentation architectures. recent deep architectures segmentation identical encoder networks differ form decoder network training inference. another common feature trainable parameters order hundreds millions thus encounter difﬁculties performing end-toend training difﬁculty training networks multi-stage training appending networks pre-trained architecture supporting aids region proposals inference disjoint training classiﬁcation segmentation networks additional training data pre-training full training addition performance boosting post-processing techniques also popular. although factors improve performance challenging benchmarks unfortunately difﬁcult quantitative results disentangle design factors necessary achieve good performance. therefore analysed decoding process used approaches reveal pros cons. evaluate performance segnet scene segmentation tasks camvid road scene segmentation rgb-d indoor scene segmentation pascal benchmark challenge segmentation years. however majority task foreground classes surrounded highly varied background. implicitly favours techniques used detection shown recent work decoupled classiﬁcation-segmentation network classiﬁcation network trained large weakly labelled data independent segmentation network performance improved. method also feature maps classiﬁcation network independent postprocessing technique perform segmentation. performance also boosted additional inference aids region proposals therefore different scene understanding idea exploit co-occurrences objects spatial-context perform robust segmentation. demonstrate efﬁcacy segnet present real-time online demo road scene segmentation classes interest autonomous driving example test results produced randomly sampled road scene images google indoor test scenes rgb-d dataset shown fig. remainder paper organized follows. sec. review related recent literature. describe segnet architecture analysis sec. sec. evaluate performance segnet outdoor indoor scene datasets. followed general discussion regarding approach pointers future work sec. conclude sec. literature review semantic pixel-wise segmentation active topic research fuelled challenging datasets arrival deep networks best performing methods mostly relied hand engineered features classifying pixels independently. typically patch classiﬁer e.g. random forest boosting predict class probabilities center pixel. features based appearance appearance explored camvid road scene understanding test per-pixel noisy predictions classiﬁers smoothed using pair-wise higher order improve accuracy. recent approaches aimed produce high quality unaries trying predict labels pixels patch opposed center pixel. improves results random forest based unaries thin structured classes classiﬁed poorly. dense depth maps computed camvid video also used input classiﬁcation using random forests another approach argues combination popular hand designed features spatio-temporal super-pixelization obtain higher accuracy best performing technique camvid test addresses imbalance among label frequencies combining object detection outputs classiﬁer predictions framework. result techniques indicate need improved features classiﬁcation. indoor rgbd pixel-wise semantic segmentation also gained popularity since release dataset dataset showed usefulness depth channel improve segmentation. approach used features rgb-sift depth-sift pixel neural network classiﬁer predict pixel unaries. noisy unaries smoothed using crf. improvements made using richer feature including region segmentation obtain higher accuracy followed crf. recent work class segmentation support relationships inferred together using combination depth based cues. another approach focuses real-time joint reconstruction semantic segmentation random forests used classiﬁer gupta boundary detection hierarchical grouping performing category segmentation. common attribute approaches hand engineered features classiﬁcation either rgbd images. success deep convolutional neural networks object classiﬁcation recently researchers exploit feature learning capabilities structured prediction problems segmentation. also attempts apply networks designed object categorization segmentation particularly replicating deepest layer features blocks match image dimensions however resulting classiﬁcation blocky another approach using recurrent neural networks merges several resolution predictions create input image resolution predictions. techniques already improvement hand engineered features ability delineate boundaries poor. newer deep architectures particularly designed segmentation advanced state-of-the-art learning decode resolution image representations pixel-wise predictions. encoder network produces resolution representations architectures classiﬁcation network convolutional layers fully connected layers. encoder network weights typically pre-trained large imagenet object classiﬁcation dataset decoder network varies architectures part responsible producing multi-dimensional features pixel classiﬁcation. architecture learns upsample input feature combines corresponding encoder feature produce input next decoder. architecture large number trainable parameters encoder network small decoder network overall large size network makes hard train end-to-end relevant task. therefore authors stage-wise training process. decoder decoder network progressively added existing trained network. network grown increase performance observed. growth stopped three decoders thus ignoring high resolution feature maps certainly lead loss edge information apart training related issues need reuse encoder feature maps decoder makes memory intensive test time. study network detail core recent architectures predictive performance improved appending recurrent neural network ﬁne-tuning large datasets layers mimic sharp boundary delineation capabilities crfs exploiting feature representation power fcn’s. show signiﬁcant improvement fcn- also show difference reduced training data used train fcn-. main advantage crf-rnn revealed jointly trained architecture fcn. fact joint training helps also shown recent results interestingly deconvolutional network performs signiﬁcantly better although cost complex training inference. however raises question whether perceived advantage crf-rnn would reduced core feed-forward segmentation engine made better. case crf-rnn network appended deep segmentation architecture including segnet. multi-scale deep architectures also pursued come ﬂavours input images scales corresponding deep feature extraction networks combine feature maps different layers single deep architecture common idea features extracted multiple scales provide local global context using feature maps early encoding layers retain high frequency detail leading sharper class boundaries. architectures difﬁcult train parameter size thus multi-stage training process employed along data augmentation. inference also expensive multiple convolutional pathways feature extraction. others append multi-scale network jointly train them. however feed-forward test time require optimization determine labels. several recently proposed deep architectures segmentation feed-forward inference time require either inference aids region proposals inference. believe perceived performance increase obtained using lack good decoding techniques core feed-forward segmentation engine. segnet hand uses decoders obtain features accurate pixel-wise classiﬁcation. recently proposed deconvolutional network semi-supervised variant decoupled network locations encoder feature maps perform non-linear upsampling decoder network. authors architectures independently segnet performs convolution trainable ﬁlter bank densify feature map. ﬁnal decoder output feature maps soft-max classiﬁer pixel-wise classiﬁcation. cvpr proposed idea decoding decoder network. however encoder network consists fully connected layers vgg- network consists parameters entire network. makes training network difﬁcult thus require additional aids region proposals enable training. moreover inference proposals used increases inference time signiﬁcantly. benchmarking point view also makes difﬁcult evaluate performance architecture without aids. work discard fully connected layers encoder network enables train network using relevant training using optimization. another recent method shows beneﬁt reducing number parameters signiﬁcantly without sacriﬁcing performance reducing memory consumption improving inference time. work inspired unsupervised feature learning architecture proposed ranzato learning module encoder-decoder network. encoder consists convolution ﬁlter bank element-wise tanh non-linearity max-pooling sub-sampling obtain feature maps. sample indices locations computed pooling stored passed decoder. decoder upsamples feature maps using stored pooled indices. convolves upsampled using trainable decoder ﬁlter bank reconstruct input image. architecture used unsupervised pre-training classiﬁcation. somewhat similar decoding technique used visualizing trained convolutional networks classiﬁcation. architecture ranzato mainly focused layer-wise feature learning using small input patches. extended kavukcuoglu accept full image sizes input learn hierarchical encoders. approaches however attempt deep encoder-decoder networks unsupervised feature training discarded decoders encoder training. here segnet differs architectures deep encoder-decoder network trained jointly supervised learning task hence decoders integral part network test time. applications pixel wise predictions made using deep networks image super-resolution depth prediction single image authors discuss need learning upsample resolution feature maps central topic paper. segnet encoder network corresponding decoder network followed ﬁnal pixelwise classiﬁcation layer. architecture illustrated fig. encoder network consists convolutional layers correspond ﬁrst convolutional layers network designed object classiﬁcation. therefore initialize training process weights trained classiﬁcation large datasets also discard fully connected layers favour retaining higher resolution feature maps deepest encoder output. also reduces number parameters segnet encoder network signiﬁcantly compared recent architectures encoder layer corresponding decoder layer hence decoder network layers. ﬁnal decoder output multi-class soft-max classiﬁer produce class probabilities pixel independently. encoder encoder network performs convolution ﬁlter bank produce feature maps. batch normalized element-wise rectiﬁedlinear non-linearity applied. following that max-pooling window stride performed resulting output sub-sampled factor max-pooling used achieve translation invariance small spatial shifts input image. sub-sampling results large input image context pixel feature map. several layers max-pooling sub-sampling achieve translation invariance robust classiﬁcation correspondingly loss spatial resolution feature maps. increasingly lossy image representation beneﬁcial segmentation boundary delineation vital. therefore necessary capture store boundary information encoder feature maps sub-sampling performed. memory inference constrained encoder feature maps stored. usually case practical applications hence propose efﬁcient store information. involves storing max-pooling indices locations maximum feature value pooling window memorized encoder feature map. principle done using bits pooling window thus much efﬁcient store compared memorizing feature ﬂoat precision. show later work appropriate decoder decoder network upsamples input feature using memorized max-pooling indices corresponding encoder feature map. step produces sparse feature map. segnet decoding technique illustrated fig. feature maps convolved trainable decoder ﬁlter bank produce dense feature maps. batch normalization step applied maps. note decoder corresponding ﬁrst encoder produces multi-channel feature although encoder input channels unlike decoders network produce feature maps number size channels encoder inputs. high dimensional feature representation output ﬁnal decoder trainable soft-max classiﬁer. soft-max classiﬁes pixel independently. output soft-max classiﬁer channel image probabilities number classes. predicted segmentation corresponds class maximum probability pixel. architectures deconvnet u-net share similar architecture segnet differences. deconvnet much larger parameterization needs computational resources harder train end-to-end primarily fully connected layers report several comparisons deconvnet later paper sec. compared segnet u-net reuse pooling indices instead transfers entire feature corresponding decoders concatenates upsampled decoder feature maps. conv max-pool block u-net architecture. segnet hand uses pre-trained convolutional layer weights pre-trained weights. decoder variants many segmentation architectures share encoder network vary form decoder network. choose compare segnet decoding technique widely used fully convolutional network decoding technique order analyse segnet compare performance smaller version segnet termed segnet-basic encoders decoders. encoders segnet-basic perform max-pooling subsampling corresponding decoders upsample input using received max-pooling indices. batch normalization used convolutional layer encoder decoder network. biases used convolutions relu nonlinearity present decoder network. further constant kernel size encoder decoder layers chosen provide wide context smooth labelling i.e. pixel deepest layer feature traced back context window input image pixels. small size segnet-basic allows explore many different variants train reasonable time. similarly create fcn-basic comparable version analysis left fig. decoding technique used segnet learning involved upsampling step. however upsampled maps convolved trainable multi-channel decoder ﬁlters densify sparse inputs. decoder ﬁlter number channels number upsampled feature maps. smaller variant decoder ﬁlters single channel convolve corresponding upsampled feature map. variant reduces number trainable parameters inference time signiﬁcantly. right fig. decoding technique. important design element model dimensionality reduction step encoder feature maps. compresses encoder feature maps used corresponding decoders. dimensionality reduction encoder feature maps channels performed convolving trainable ﬁlters number classes. compressed channel ﬁnal encoder layer feature maps input decoder network. decoder network upsampling performed inverse convolution using ﬁxed trainable multi-channel upsampling kernel. kernel size manner upsampling also termed deconvolution. note that comparison segnet multi-channel convolution using trainable decoder ﬁlters performed upsampling densifying feature maps. upsampled feature channels. added element-wise corresponding resolution encoder feature produce output decoder feature map. upsampling kernels initialized using bilinear interpolation weights decoder model requires storing encoder feature maps inference. memory intensive embedded applications; e.g. storing feature maps ﬁrst layer fcn-basic resolution ﬂoating point precision takes made smaller using dimensionality reduction feature maps requires storage. segnet hand requires almost negligible storage cost pooling indices also create variant fcn-basic model discards encoder feature addition step learns upsampling kernels addition variants study upsampling using ﬁxed bilinear interpolation weights therefore requires learning upsampling extreme encoder feature maps layer corresponding output feature maps segnet decoder create memory intensive variant segnet pooling indices upsampling used followed convolution step densify sparse input. added element-wise corresponding encoder feature maps produce decoders output. another memory intensive fcn-basic variant dimensionality reduction performed encoder feature maps. implies unlike fcn-basic ﬁnal encoder feature compressed channels passing decoder network. therefore number channels decoder corresponding encoder fig. illustration segnet decoders. correspond values feature map. segnet uses pooling indices upsample feature convolves trainable decoder ﬁlter bank. upsamples learning deconvolve input feature adds corresponding encoder feature produce decoder output. feature output max-pooling layer corresponding encoder. note trainable decoder ﬁlters fcn. comparison decoder variants. quantify performance using global class average mean intersection union semantic contour measure testing training accuracies shown percentages natural frequency median frequency therefore memory efﬁcient inference. note theoretical memory requirement reported based size ﬁrst layer encoder feature map. fcn-basic segnet-basic segnet-basic-encoderaddition high scores indicating need information encoder feature maps better class contour delineation. networks larger decoders using encoder feature maps full perform sparse) array indices upsampling. performed quite poorly comparison variants. variant without max-pooling sub-sampling encoder network consumes memory takes longer converge performs poorly. finally please note encourage reproduction results release caffe implementation variants training camvid road scenes dataset benchmark performance decoder variants. dataset small consisting training testing images resolution. challenge segment classes road building cars pedestrians signs poles side-walk etc. perform local contrast normalization input. encoder decoder weights initialized using technique described train variants stochastic gradient descent ﬁxed learning rate momentum using caffe implementation segnet-basic train variants training loss cross-entropy loss objective function training network. loss summed pixels mini-batch. large variation number pixels class training need weight loss differently based true class. termed class balancing. median frequency balancing weight assigned class loss function ratio median class frequencies computed entire training divided class frequency. implies larger classes training weight smaller weights smallest classes highest. also experimented training different variants without class balancing equivalently using natural frequency balancing. analysis compare quantitative performance different decoder variants three commonly used performance measures global accuracy measures percentage pixels correctly classiﬁed dataset class average accuracy mean predictive accuracy classes mean intersection union classes used pascal challenge miou metric stringent metric class average accuracy since penalizes false positive predictions. however miou metric optimized directly class balanced cross-entropy loss. miou metric otherwise known jacard index commonly used benchmarking. however csurka note metric always correspond human qualitative judgements good quality segmentation. show examples miou favours region smoothness evaluate boundary accuracy point also alluded recently authors hence propose complement miou metric boundary measure based berkeley contour matching score commonly used evaluate unsupervised image segmentation quality csurka simply extend semantic segmentation show measure semantic contour accuracy used conjunction miou metric agrees human ranking segmentation outputs. idea computing semantic contour score evaluate f-measure involves computing precision recall values predicted ground truth class boundary given pixel tolerance distance. used value image diagonal tolerance distance. fmeasure class present ground truth test image averaged produce image f-measure. compute whole test average denoted boundary f-measure average image measures. test architectural variant iterations optimization camvid validation training loss converges. training mini-batch size corresponds testing approximately every epochs training set. select iteration wherein global accuracy highest amongst evaluations validation set. report three measures performance point held-out camvid test set. although class balancing training variants still important achieve high global accuracy result overall smooth segmentation. another reason contribution segmentation towards autonomous driving mainly delineating classes roads buildings side-walk sky. classes dominate majority pixels image high global accuracy corresponds good segmentation important classes. also observed reporting numerical performance class average highest often correspond global accuracy indicating perceptually noisy segmentation output. table report numerical results analysis. also show size trainable parameters highest resolution feature pooling indices storage memory ﬁrst layer feature maps max-pooling sub-sampling. show average time forward pass caffe implementation averaged measurements using input nvidia titan cudnn acceleration. note upsampling layers segnet variants optimised using cudnn acceleration. show results testing training variants selected iteration. results also tabulated without class balancing training testing accuracies. analyse results class balancing. upsampling without learning performs worst based measures accuracy. methods either learning upsampling learning decoder ﬁlters upsampling perform signiﬁcantly better. emphasizes need learn decoders segmentation. also supported experimental evidence gathered authors comparing segnet-type decoding techniques compare segnet-basic fcn-basic perform equally well test measures accuracy. difference segnet uses less memory inference since stores max-pooling indices. hand fcn-basic stores encoder feature maps full consumes much memory segnet-basic decoder feature maps decoder layer. comparison fcn-basic uses dimensionality reduction fewer feature maps decoder layer. reduces number convolutions decoder network hence fcn-basic faster inference another perspective decoder network segnet-basic makes overall larger network fcn-basic. endows ﬂexibility hence achieves higher training accuracy fcn-basic number iterations. overall segnet-basic advantage fcn-basic inference time memory constrained inference time compromised extent. segnet-basic similar fcn-basic-noaddition terms decoders although decoder segnet larger. learn produce dense feature maps either directly learning perform deconvolution fcn-basic-noaddition ﬁrst upsampling convolving trained decoder ﬁlters. performance segnet-basic superior part larger decoder size. accuracy fcn-basic-noaddition also lower compared fcn-basic. shows vital capture information present encoder feature maps better performance. particular note large drop measure variants. also explain part reason segnet-basic outperforms fcn-basicnoaddition. fcn-basic-noaddition-nodimreduction model slightly larger segnet-basic since ﬁnal encoder feature maps compressed match number classes makes fair comparison terms size model. performance variant poorer segnet-basic test also training accuracy lower number training epochs. shows using larger decoder enough also important capture encoder feature information learn better particular grained contour information also interesting segnet-basic competitive training accuracy compared larger models fcnbasic-nodimreduction. interesting fcn-basicnoaddition segnet-basic-singlechanneldecoder shows using max-pooling indices upsampling overall larger decoder leads better performance. also lends evidence segnet good architecture segmentation particularly need compromise storage cost accuracy versus inference time. best case memory inference time constrained larger models fcn-basic-nodimreduction segnet-encoderaddition accurate variants. particularly discarding dimensionality reduction fcn-basic model leads best performance amongst fcn-basic variants high score. emphasizes trade-off involved memory accuracy segmentation architectures. columns table show result class balancing used here observe without weighting results poorer variants particularly class average accuracy miou metric. global accuracy highest without weighting since majority scene dominated road building pixels. apart inference comparative analysis variants holds true natural frequency balancing including trends measure. segnetbasic performs well fcn-basic better larger fcn-basic-noaddition-nodimreduction. bigger less efﬁcient models fcn-basic-nodimreduction segnetencoderaddition perform better variants. benchmarking quantify performance segnet scene segmentation benchmarks using caffe implementation ﬁrst task road scene segmentation current practical interest various autonomous driving related problems. second task indoor scene segmentation immediate interest several augmented reality applications. input images tasks benchmarked segnet several well adopted deep architectures segmentation deeplablargfov deconvnet objective understand performance architectures trained end-to-end datasets. enable end-to-end training added batch normalization layers convolutional layer. deeplab-largefov changed pooling stride achieve ﬁnal predictive resolution restricted feature size fully connnected layers deconvnet enable training batch size models. note authors deeplab-largefov also reported little loss performance reducing size fully connected layers. order perform controlled benchmark used solver ﬁxed learning rate momentum optimization performed epochs dataset performance increase observed. dropout added deeper road scene segmentation number road scene datasets available semantic parsing choose benchmark segnet using camvid dataset contains video sequences. enables compare proposed architecture motion structure video segments also combine form ensemble images train segnet additional benchmark. demo road scene segmentation include camvid test larger dataset. here would like note another recent independent segmentation benchmark road scenes performed segnet competing architectures used paper however benchmark controlled meaning architecture trained separate recipe varying input resolutions sometimes validation included. therefore believe controlled benchmark used complement efforts. qualitative comparisons segnet predictions deep architectures seen fig. qualitative results show ability proposed architecture segment smaller classes road scenes producing smooth segmentation overall scene. indeed controlled benchmark setting segnet shows superior performance compared larger models. deeplab-largefov efﬁcient model post-processing produce competitive results although smaller classes lost. learnt deconvolution clearly better ﬁxed bilinear upsampling. deconvnet largest model inefﬁcient train. predictions retain small classes. also benchmark ﬁrst compare segnet several deep-learning methods including random forests boosting combination based methods done give user perspective improvements accuracy achieved using deep networks compared classical feature engineering based techniques. results table show segnet-basic segnet obtain competitive results compared methods crfs. shows ability deep architecture extract meaningful features input image accurate smooth class segment labels. interesting result large performance improvement class average miou metrics obtained large training dataset obtained combining used train segnet. correspondingly qualitative results segnet clearly superior rest methods. able segment small large classes well. remark used median frequency class balancing training segnet-basic segnet. addition overall smooth quality segmentation much like typically obtained post-processing. although fact results improve larger training sets surprising percentage improvement obtained using pre-trained encoder network training indicates architecture potentially deployed fig. results camvid dusk test samples. segnet shows superior performance particularly ability delineate boundaries compared larger models trained controlled setting. deeplab-largefov efﬁcient model post-processing produce competitive results although smaller classes lost. learnt deconvolution clearly better. deconvnet largest model longest training time predictions loose small classes. note results correspond model corresponding highest miou accuracy table practical applications. random testing urban highway images internet demonstrates segnet absorb large training generalize well unseen images. also indicates contribution prior lessened sufﬁcient amount training data made available. table compare segnet’s performance widely adopted fully convolutional architectures segmentation. compared experiment table class blancing training deep architectures including segnet. found difﬁcult train larger models deconvnet median frequency balancing. benchmark performance iterations given mini-batch size training size approximately corresponds epochs. last test point also report maximum number iterations beyond observed accuracy improvements over-ﬁtting report metrics three stages training phase reveal metrics varied training time particularly larger networks. important understand additional training time justiﬁed accuracy increases. note also evaluation performed complete dataset obtain batch norm statistics evaluated test model statistic evaluations expensive perform large training sets hence report metrics three time points training phase. table immediately segnet deconvnet achieve highest scores metrics compared models. deconvnet higher boundary delineation accuracy segnet much efﬁcient compared deconvnet. seen compute statistics table quantitative comparisons segnet traditional methods camvid road class segmentation problem segnet outperforms methods including using depth video and/or crf’s majority classes. comparison based methods segnet predictions accurate classes. also shows good improvement class average accuracy trained large dataset images. particularly noteworthy signiﬁcant improvements accuracy smaller/thinner classes. note deconvnet fully connected layers train much slowly comparable higher forward-backward pass time reference segnet. note also over-ﬁtting issue training larger models since comparable iterations segnet metrics showed increasing trend. model learning deconvolutional layers opposed ﬁxing bi-linear interpolation weights improves performance particularly score. also achieves higher metrics lesser time. fact agrees earlier analysis sec. surprisingly deeplab-largefov trained predict labels resolution produces competitive performance given smallest model terms parameterization also fastest training time table however boundary accuracy poorer shared architectures. deconvnet’s score higher networks trained long time. given analysis sec. fact shares segnet type architecture. impact dense post-processing seen last time point deeplab-largefov-densecrf. global miou improve class average diminshes. however large improvement obtained score. note dense hyperparameters obtained expensive grid-search process subset training since validation available. rgb-d indoor scenes rgb-d challenging large dataset indoor scenes training testing images. images captured different sensors hence come various resolutions. task segment indoor scene classes including wall ﬂoor ceiling table chair sofa etc. task made hard fact object classes come various shapes sizes different poses. frequent partial occlusions since typically many different classes present test images. factors make hardest segmentation challenges. modality training testing. using depth modality would necessitate architectural modiﬁcations/redesign also quality depth images current cameras require careful post-processing ﬁll-in missing measurements. also require using fusion many frames robustly extract features segmentation. therefore believe using depth segmentation merits separate body work scope paper. also note earlier benchmark dataset nyuv included part dataset. road scene images limited variation terms classes interest spatial arrangements. captured moving vehicle camera position nearly always parallel road surface limiting variability view points. makes easier deep networks learn segment robustly. comparison images indoor scenes complex since view points vary less regularity number classes present scene spatial arrangement. another difﬁculty caused widely varying sizes object classes scene. test samples recent rgb-d dataset shown fig. observe scenes large classes others dense clutter appearance also widely vary indoor scenes. therefore believe hardest challenge segmentation architectures methods computer vision. challenges pascal salient object segmentation occupied researchers believe indoor scene segmentation challenging current practical applications robotics. encourage research direction compared well known deep architectures large rgb-d dataset. qualitative results segnet samples indoor scenes laboratory different meeting room bathroom shown fig. segnet obtains reasonable predictions size classes large different view points. particularly interesting since input modality rgb. images also useful segment thinner structures legs chairs tables lamps difﬁcult achieve using depth images currently available sensors. seen results segnet deconvnet fig. also useful segment decorative objects paintings wall tasks. however compared outdoor scenes segmentation quality quantitative comparison deep networks semantic segmentation camvid test trained corpus road scenes without class balancing. end-to-end training performed ﬁxed learning rate smaller networks like segnet learn modality used experiments. complex task classes architectures perform poorly particularly smaller sized classes skew class distribution. deeplab-large smallest efﬁcient model slightly higher miou quantitative results table show deep architectures share miou boundary metrics. global class averages also small. segnet outperforms methods terms metrics slightly lower miou deeplab-largefov. stand alone experiment trained segnet median frequency class balancing metrics higher agrees analysis sec. interestingly using grid search based optimal hyperparameters dense-crf worsened except score metric deeplab-largefovdensecrf. optimal settings could perhaps found grid search process expensive given large inference time dense-crfs. reason overall poor performance large number classes segmentation task many occupy small part image appear infrequently. accuracies reported table clearly show larger classes reasonable accuracy smaller classes lower accuracies. improved larger sized datasets class distribution aware training techniques. another reason poor performance could inability deep architectures large variability indoor scenes conjecture part based fact smallest model deeplab-largefov produces best accuracy terms miou comparison larger parameterizations deconvnet improve perfomance even much longer training suggests could common reason poor performance across architectures. controlled datasets needed verify hypothesis. deep learning models often achieved increasing success availability massive datasets expanding model depth parameterisation. however practice factors like memory computational time training testing important factors consider choosing model large bank models. training time becomes important consideration particularly performance gain commensurate increased training time shown experiments. test time memory computational load important deploy models specialised embedded devices example applications. overall efﬁciency viewpoint feel less attention paid smaller memory time efﬁcient models real-time applications road scene understanding primary motivation behind proposal segnet signiﬁcantly smaller faster competing architectures shown efﬁcient tasks road scene understanding. segmentation challenges pascal ms-coco object segmentation challenges wherein classes present test image. scene segmentation challenging high variability indoor scenes need segment larger number classes simultaneously. task outdoor indoor scene segmentation also practically oriented current applications autonomous driving robotics metrics chose benchmark various deep segmentation architectures like boundary f-measure done complement existing metrics biased towards region accuracies. clear experiments independent benchmarks outdoor scene images captured moving easier segment deep architectures perform robustly. hope experiments encourage researchers engage attention towards challenging indoor scene fig. qualitative assessment segnet predictions indoor test scenes recently released rgb-d dataset hard challenge segnet predictions delineate inter class boundaries well object classes variety scenes view-points. overall segmentation quality better object classes reasonably sized noisy scene cluttered. note often parts image scene ground truth labels shown black colour. parts masked corresponding deep model predictions shown. note results correspond model corresponding highest miou accuracy table important choice make benchmarking different deep architectures varying parameterization manner train them. many architectures used host supporting techniques multi-stage training recipes arrive high accuracies datasets makes difﬁcult gather evidence true performance time memory constraints. instead chose perform controlled benchmarking used batch normalization enable end-to-end training solver however note approach cannot entirely disentangle effects model versus solver achieving particular result. mainly fact training networks involves gradient back-propagation imperfect optimization non-convex problem extremely large dimensions. acknowledging shortcomings hope controlled analysis complements benchmarks future would like exploit understanding segmentation architectures gathered analysis design efﬁcient architectures real-time applications. also interested estimating model uncertainty predictions deep segmentation architectures conclusion presented segnet deep convolutional network architecture semantic segmentation. main motivation behind segnet need design efﬁcient architecture road indoor scene understanding efﬁcient terms memory computational time. analysed segnet compared important variants reveal practical trade-offs involved designing architectures segmentation particularly training time memory versus accuracy. architectures comparison computational time hardware resources required various deep architectures. caffe time command used compute time requirement averaged iterations mini batch size image resolution used nvidia-smi unix store encoder network feature maps full perform best consume memory inference time. segnet hand efﬁcient since stores max-pooling indices feature maps uses decoder network achieve good performance. large well known datasets segnet performs competitively achieving high scores road scene understanding. end-to-end learning deep segmentation architectures harder challenge hope attention paid important problem. schulz behnke fast semantic segmentation rgb-d scenes gpu-accelerated deep neural networks advances artiﬁcial intelligence vol. lecture notes computer science springer international publishing zheng jayasumana romera-paredes vineet huang torr conditional random ﬁelds recurrent neural networks proceedings ieee international conference computer vision mottaghi chen n.-g. s.-w. fidler urtasun role context object detection semantic segmentation wild computer vision pattern recognition ieee conference ieee everingham eslami gool williams winn zisserman pascal visual object classes challenge retrospective international journal computer vision vol. russakovsky deng krause satheesh huang karpathy khosla bernstein berg fei-fei imagenet large scale visual recognition challenge international journal computer vision april t.-y. maire belongie hays perona ramanan doll´ar zitnick microsoft coco common objects context computer vision–eccv springer schwing urtasun fully connected deep structured mostajabi yadollahpour shakhnarovich feedforward semantic segmentation zoom-out features proceedings ieee conference computer vision pattern recognition eigen puhrsch fergus depth prediction single image using multi-scale deep network nips ioffe szegedy batch normalization accelerating deep shift corr shelhamer donahue karayev long girshick guadarrama darrell caffe convolutional architecture fast feature embedding proceedings international conference multimedia long shelhamer darrell fully convolutional networks semantic segmentation https//arxiv.org/pdf/.v.pdf martin fowlkes malik learning detect natural image boundaries using local brightness color texture cues ieee transactions pattern analysis machine intelligence vol. cordts omran ramos rehfeld enzweiler benenson franke roth schiele cityscapes dataset semantic urban scene understanding arxiv preprint arxiv. kendall badrinarayanan cipolla bayesian segnet model uncertainty deep convolutional encoder-decoder architectures scene understanding arxiv preprint arxiv. vijay badrinarayanan obtained ph.d inria rennes france senior post-doctoral research associate machine intelligence laboratory department engineering university cambridge u.k. currently works principal engineer deep learning magic leap inc. mountain view research interests probabilistic graphical models deep learning applied image video based perception problems. alex kendall graduated bachelor engineering first class honours university auckland zealand. awarded woolf fisher scholarship study towards ph.d university cambridge u.k. member machine intelligence laboratory interested applications deep learning mobile robotics. roberto cipolla obtained b.a. degree university cambridge m.s.e. university pennsylvania d.phil. university oxford toshiba fellow engineer toshiba corporation research development centre kawasaki japan. joined department engineering university cambridge lecturer fellow jesus college. became reader information engineering professor became fellow royal academy engineering research interests computer vision robotics. authored books edited volumes co-authored papers.", "year": 2015}