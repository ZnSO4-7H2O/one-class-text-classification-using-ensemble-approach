{"title": "The LAMBADA dataset: Word prediction requiring a broad discourse context", "tag": ["cs.CL", "cs.AI", "cs.LG"], "abstract": "We introduce LAMBADA, a dataset to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word. To succeed on LAMBADA, computational models cannot simply rely on local context, but must be able to keep track of information in the broader discourse. We show that LAMBADA exemplifies a wide range of linguistic phenomena, and that none of several state-of-the-art language models reaches accuracy above 1% on this novel benchmark. We thus propose LAMBADA as a challenging test set, meant to encourage the development of new models capable of genuine understanding of broad context in natural language text.", "text": "introduce lambada dataset evaluate capabilities computational models text understanding means word prediction task. lambada collection narrative passages sharing characteristic human subjects able guess last word exposed whole passage last sentence preceding target word. succeed lambada computational models cannot simply rely local context must able keep track information broader discourse. show lambada exempliﬁes wide range linguistic phenomena none several state-ofthe-art language models reaches accuracy novel benchmark. thus propose lambada challenging test meant encourage development models capable genuine understanding broad context natural language text. recent spurt powerful end-to-end-trained neural networks natural language processing sparked interest tasks measure progress bringing genuine language understanding. special care must taken evaluating systems since effectiveness picking statistical generalizations large corpora lead illusion reaching deeper degree understanding really are. example denis germ´an share ﬁrst authorship. marco separately system responses appropriate respective questions. however taken together incoherent. system behaviour somewhat parrot-like. locally produce perfectly sensible language fragments fails take meaning broader discourse context account. much research effort consequently focused designing systems able keep information broader context memory possibly even perform simple forms reasoning paper introduce lambada lambada proposes word prediction task target item difﬁcult guess sentence appears available becomes easy broader context presented. consider example figure sentence honestly think would want multitude possible continuations broad context clearly indicates missing word miscarriage. lambada casts language understanding classic word prediction framework language modeling. thus test several existing language modeling architectures including systems capacity hold longer-term contextual memories. preliminary experiments none models came even remotely close human performance conﬁrming lambada challenging benchmark research automated models natural language understanding. cnn/daily mail benchmark recently introduced hermann closely related lambada. cnndm includes large online articles published together short summaries main points. task guess named entity removed summary. although data normed subjects unlikely missing named entity guessed short summary alone thus like lambada models need look broader context differences datasets include text genres fact missing items cnndm limited named entities. importantly datasets require models perform different kinds inferences broader passages. cnndm models must able summarize articles order make sense sentence containing missing word whereas lambada last sentence summary broader passage continuation story. thus order succeed models must instead understand plausible development narrative fragment dialogue. another related benchmark introduced hill like lambada collection book excerpts word randomly removed last sentence sequence sentences. design differences crucial distinction between lambada passages ﬁltered human-guessable broader context only. indeed according post-hoc analysis sample passages reported hill colleagues large proportion cases annotators could guess missing word broader context could also guess last sentence alone. time ﬁfth cases annotators could guess word even broader context given. thus small portion passages really probing model’s idea book excerpt completion task originally introduced msrcc dataset however latter limited context single sentences attempting measure broader passage understanding. text understanding tested tasks including entailment detection answering questions text measuring inter-clause coherence different tasks provide complementary insights models’ abilities word prediction particularly attractive naturalness simplicity. models need trained predict likely word given previous context following classic language modeling paradigm much simpler setup required determine whether sentences entail other. moreover models access virtually unlimited amounts training data required train language model text. general methodological level word prediction potential probe almost aspect text understanding including limited traditional narrower tasks entailment co-reference resolution word sense disambiguation. data collection lambada consists passages composed context target sentence. context size minimum number complete sentences target sentence cumulatively contain least tokens task guess last word target sentence constraint target word last word sentence necessary research goal makes task natural human subjects. context preston last person wear chains knew feel slipped onto skin-the reaper’s unending hatred felt enough emotion already amphitheater. didn’t want feel anymore. don’t whispered. please. context tuned discussed moment struck lively jig. everyone joined turning courtyard even chaotic scene people dancing circles swinging spinning circles everyone making dance steps. felt feet tapping body wanting move. context shook head took step back held hands tried smile without losing cigarette. julia said reassuring voice. already focused friend. click shutter here. context palm clear stone inside small ivory statuette. guardian angel. figured you’re going night getting cars might well backup. look feeling stunned. like sort sign. context sun-speckled shade cool grass beneath welcome respite stiﬂing kitchen glad relax tree’s rough brittle bark begin breakfast buttery toasted bread fresh fruit. even water tasty clean cold. context wife refused allow come hong kong plague height your wife johanne? married last johanne grinned. well gets starts need home comforts. context again left you. however adamant desire remain private ceremony. asked make sure instance information given newspaper regarding death even obituary. context battery logan’s radio must out. told himself. explanation beyond cygan staff white house overrun. lizzie opened eyes ﬂutter. road hour without incident. usefulness general world knowledge external resources task contrast kinds texts like news data wikipedia text famous novels. corpus duplicate removal ﬁltering potentially offensive material stop word list contains novels million words. randomly divided novels equally-sized training development+testing partitions. built lambada dataset latter idea models tackling lambada trained text training partition composed novels encompassing words. novels pre-assigned partitions only lambada passages self-contained cannot solved exploiting knowledge remainder novels example background information characters involved properties ﬁctional world given novel. novel-based division method used split lambada data development testing. reduce time cost dataset collection ﬁltered passages relatively easy standard language models since cases likely guessable based local context alone. used combination four language models chosen availability and/or ease training pre-trained recurrent neural network three models trained book corpus passage whose target word probability according language models excluded. subjects step allowed guesses sentence maximize chances catching cases target words guessable sentence alone. step added based pilot study revealed that step enough ensure data could guessed local context only step alone ensure data easy given discourse context made sure possible subject judge item passage sentence conditions crowdsourcing pipeline items discarded step additional step another step input examples passed selection steps. subjects paid page steps page step overall item resulting dataset costed average. alternative designs step step step found expensive. cost considerations also precluded using subjects stage could principle improve quality ﬁltering step. note criteria passage inclusion strict required consecutive subjects exactly match missing word made sure subject able provide based local context only even given guesses. alternative perfect-match approach would include passages broad-context subjects provided plausible synonymous continuations. however challenging practically methodologically determine answers original passage well especially goal distinguish items solvable broad-discourse context local context enough. theoretically substitutability context could tested manual annotation multiple additional raters would ﬁnancially practically feasible dataset scale average passage consists sentences context plus target sentence total length tokens tokens examples passages dataset given figure training data language models tested lambada include full text novels comprising million words. note training data consists text domain dev+test passages large amounts ﬁltered way. partially motivated economic considerations importantly justiﬁed intended lambada tool evaluate general-purpose models terms fare broad-context understanding resource develop ad-hoc models meant predict ﬁnal word sort passages encountered lambada. development data used ﬁne-tune models speciﬁcs lambada passages. dataset analysis analysis lambada data suggests that order target word predictable broad context only must strongly cued broader discourse. indeed typical lambada items target word occurs context. figure compares lambada items random -item sample input data passages presented human subjects ﬁltering phase ﬁgure shows subjects guessed word broad context often word itself occurred context lambada passages include target word context input data case less passages. guess right word however subjects must still linguistic general cognitive skills good shown examples featuring target word context reported figure figure shows target words lambada proper nouns followed common nouns distance verbs fact proper nouns hugely overrepresented lambada categories under-represented compared distribution input. variety factors converges making proper nouns easy subjects lambada task. particular context clearly demands referential expression constraint blank ﬁlled single word excludes possibilities noun phrases articles reasons suspect co-reference easier discourse phenomena task however although co-reference seems play role target words pronouns. common nouns still pretty frequent lambada constituting third data. qualitative analysis reveals mixture phenomena. co-reference quite common figure sometimes partial co-reference facilitated bridging mechanisms presence near synonym however also often phenomena inference prototypical participants event. instance passage describes someone breakfast together typical food beverages subjects guess target word coffee without explicitly mentioned. contrast verbs adjectives adverbs rare lambada. many items guessed local sentence context only shown figure also reports distribution items guessed subjects based target-sentence context note higher proportion verbs adjectives adverbs latter figure end-of-sentence context skews input distribution favour nouns subject ﬁltering show clear differential effect nouns poss. manual inspection reveals broad context necessary guess items like figure target word context; target word distribution lambada data presented human subjects items guessed sentence context target word distribution lambada passages lemma target word context frequent verbs adjectives closed-class adverbs well time-related adverbs cases sentence context sufﬁces lambada target word adjective). contrasts types open-class adverbs generally hard guess local broad context. proportion kinds adverbs verbs among guessed items general suggests tracking event-related phenomena harder subjects coreferential phenomena least framed lambada task. research needed probe hypothesis. furthermore observe that explicit mention preceding discourse context critical proper nouns categories often guessed without explicitly introduced. shown figure depicts distribution lambada items lemma target word context qualitative analysis items verbs adjectives targets suggests target word although present passage still strongly implied conthe apparent out-of-context proper nouns shown figure lemmatization mistakes manual check conﬁrmed proper noun target words lambada indeed also present context. cases correct prediction requires complex discourse inference including guessing prototypical participants scene actions events strongly suggested discourse mention road helps predicting target driving) qualitative properties participants situations course kind discourse reasoning takes place target word already present context presence word context make reasoning unnecessary facilitates inference. ﬁnal observation intriguingly lambada items contain direct speech signiﬁcantly often input items overall e.g. examples analysis needed investigate dialogic discourse might facilitate prediction ﬁnal target word. lambada contains myriad phenomena that besides making challenging text understanding perspective great interest broad computational linguistics community. return example solving requires combination linguistic skills ranging phonology morphosyntax pragmatics addition general reasoning skills. surprising thus lambada challenging current models show next. computational methods tested several existing language models baselines lambada. implemented simple long short-term memory network traditional statistical n-gram language model without cache memory network remark least lstm memory network certain extent cache n-gram model have among supposed beneﬁts ability take broader contexts account. note moreover variants rnns lstms state tested standard language modeling benchmarks memory network implementation similar hill reached best results data could re-implement models performed best cnndm lstm architecturally similar deep lstm reader hermann achieved respectable performance data set. importantly show models reach impressive performance tested standard language modeling data sourced corpus used build lambada. control constructed randomly sampling passages shape size ones used build lambada test novels without ﬁltering way. based control results discussed below reasonably claim models testing lambada good standard language modeling performance latter cannot attributed poor quality. constructed sup-cbow baseline model weakly tailored task hand consisting simple neural network takes input bag-ofword representation passage attempts predict ﬁnal word. input representation comes adding pre-trained cbow vectors words passage. also considered unsupervised variant target word predicted cosine similarity passage vector target word vector. finally evaluated several variations random guessing baseline differing terms word pool sample from. guessed word could picked from full vocabulary words appear current passage random uppercased word passage. latter baseline aims exploiting potential bias proper names account consistent portion lambada data note lambada designed challenge language models harder-than-average examples broad context understanding crucial. however average case disregarded either since want language models able handle cases. reason trained models entirely unsupervised data expect future work follow similar principles. concretely trained models standard practice predicting upcoming word given previous context using lambada training data input corpus. exception procedure sup-cbow extracted training novels similar-shaped passages lambada trained model again goal model test potential biases data provide full account phenomena testing. restricted vocabulary models frequent words training model hyperparameters tuned accuracy development set. trained models tested lambada control sets. tuning details. lambada average success model predicting target word i.e. accuracy however observe bottoming effect accuracy also report perplexity median rank correct word better compare models. anticipated above line expected models good performance called perform standard language modeling task control set. indeed models guess right word cases. situation drastically changes look lambada results models performing badly. indeed model even able compete simple heuristics picking random word passage especially random capitalized word time performance latter heuristic absolute terms shows that despite bias favour names passage simply relying sufﬁce obtain good performance lambada models rather pursue deeper forms analysis broader context conﬁrms difﬁculty lambada relies mainly accounting information available broader context task predicting exact word missing. comparative terms observe stronger performance traditional n-gram models neuralnetwork-based ones possibly pointing difﬁculty tuning latter properly. particular best relative performance lambada achieved n-gram w/cache takes passage statistics account. even model effectively unable guess right word achieves respectable perplexity recognize course evaluation performed preliminary must taken proof-of-concept study difﬁculty lambada. better results might obtained simply performing extensive tuning adding sophisticated mechanisms attention forth. still would surprised minor modiﬁcations models tested human-level performance task. also note that constructed lambada standard language models bound fail design ﬁrst ﬁlters choose passages number simple language models failing predict upcoming word. however future research ways around inherent difﬁculty. humans still able solve task model claims good language understanding ability able succeed well. paper introduced lambada dataset aimed testing language models ability take broad discourse context account predicting word. number linguistic phenomena make target words lambada easy guess human subjects look whole passages come from nearly impossible last sentence considered. preliminary experiments suggest even cutting-edge neural network approaches principle able track long-distance effects passing lambada challenge. hope computational community stimulated develop novel language models genuinely capturing non-local phenomena lambada reﬂects. promote research direction plan announce public competition based lambada data. hunch that despite initially disappointing results vanilla memory network tested ability store information longer-term memory crucial component successful models coupled ability perform kind reasoning what’s general note believe leveraging human performance word prediction promising strategy construct benchmarks computational models supposed capture various aspects human text understanding. inﬂuence broad context explored lambada example idea. grateful aurelie herbelot linzen nghia pham especially roberto zamparelli ideas feedback. project received funding european union’s horizon research innovation programme under marie sklodowska-curie grant agreement starting independent research grant vidi grant gratefully acknowledge support nvidia corporation donation gpus used research. samuel bowman gabor angeli christopher potts christopher manning. large annotated corpus learning natural language inference. proceedings emnlp pages lisbon portugal. karl moritz hermann tom´aˇs koˇcisk´y edward grefenstette lasse espeholt mustafa suleyman phil blunsom. teaching proceedmachines read comprehend. ings nips montreal canada. published online https//papers.nips.cc/book/ advances-in-neural-informationprocessing-systems--. felix hill antoine bordes sumit chopra jason weston. goldilocks principle reading children’s books explicit memory repreproceedings iclr conference sentations. track juan puerto rico. published online http//www.iclr.cc/doku.php?id= iclrmain. yukun ryan kiros richard zemel ruslan salakhutdinov raquel urtasun antonio torralba sanja fidler. aligning books movies towards story-like visual explanations watching iccv pages movies reading books. tomas mikolov stefan kombrink anoop deoras lukar burget honza cernocky. rnnlm recurrent neural network language. proceedings asru. ieee automatic speech recognition understanding workshop. tomas mikolov armand joulin sumit chopra michael mathieu marc’aurelio ranzato. learning longer memory recurrent neural netproceedings iclr workshop track works. diego published online http//www. iclr.cc/doku.php?id=iclrmain. matthew richardson christopher burges erin renshaw. mctest challenge dataset open-domain machine comprehension text. proceedings emnlp pages seattle rockt¨aschel edward grefenstette karl moritz hermann tom´aˇs koˇcisk´y phil blunsom. reasoning entailment neural attention. proceedings iclr conference track juan puerto rico. published online http//www. iclr.cc/doku.php?id=iclrmain. alessandro sordoni michel galley michael auli chris brockett yangfeng margaret mitchell jian-yun jianfeng bill dolan. neural network approach context-sensitive generation conversational responses. proceedings naacl pages denver oriol vinyals quoc neural conversational model. proceedings icml deep learning workshop lille france. published online https//sites.google.com/site/ deeplearning/accepted-papers.", "year": 2016}