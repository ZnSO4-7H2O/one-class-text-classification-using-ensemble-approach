{"title": "Photographic Image Synthesis with Cascaded Refinement Networks", "tag": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "abstract": "We present an approach to synthesizing photographic images conditioned on semantic layouts. Given a semantic label map, our approach produces an image with photographic appearance that conforms to the input layout. The approach thus functions as a rendering engine that takes a two-dimensional semantic specification of the scene and produces a corresponding photographic image. Unlike recent and contemporaneous work, our approach does not rely on adversarial training. We show that photographic images can be synthesized from semantic layouts by a single feedforward network with appropriate structure, trained end-to-end with a direct regression objective. The presented approach scales seamlessly to high resolutions; we demonstrate this by synthesizing photographic images at 2-megapixel resolution, the full resolution of our training data. Extensive perceptual experiments on datasets of outdoor and indoor scenes demonstrate that images synthesized by the presented approach are considerably more realistic than alternative approaches. The results are shown in the supplementary video at https://youtu.be/0fhUJT21-bs", "text": "figure given pixelwise semantic layout presented model synthesizes image conforms layout. semantic layouts cityscapes dataset urban scenes; semantic classes coded color. images synthesized model layouts. layouts shown throughout paper validation depict scenes cities never seen training. best viewed screen. present approach synthesizing photographic images conditioned semantic layouts. given semantic label approach produces image photographic appearance conforms input layout. approach thus functions rendering engine takes two-dimensional semantic speciﬁcation scene produces corresponding photographic image. unlike recent contemporaneous work approach rely adversarial training. show photographic images synthesized semantic layouts single feedforward network appropriate structure trained end-to-end direct regression objective. presented approach scales seamlessly high resolutions; demonstrate synthesizing photographic images -megapixel resolution full resolution training data. extensive perceptual experiments datasets outdoor indoor scenes demonstrate images synthesized presented approach considerably realistic alternative approaches. consider semantic layouts figure skilled painter could draw images depict urban scenes conform layouts. highly trained craftsmen even create paintings approach photorealism train computational models ability? given semantic layout novel scene artiﬁcial system synthesize image depicts scene looks like photograph? question connected central problems computer graphics artiﬁcial intelligence. first consider problem photorealism computer graphics. system synthesizes photorealistic images semantic layouts would effect function kind rendering engine bypasses laborious speciﬁcation detailed threedimensional geometry surface reﬂectance distributions avoids computationally intensive light transport simulation direct synthesis approach could immediately replace modern rendering engines would indicate alternative route photorealism viable could complement existing computer graphics techniques. second source motivation role mental imagery simulation human cognition mental imagery believed play important role planning decision making. level detail completeness mental imagery matter debate role human intelligence suggests ability synthesize photorealistic images support development artiﬁcial intelligent systems work develop model photographic image synthesis pixelwise semantic layouts. model convolutional network trained supervised fashion pairs photographs corresponding semantic layouts. pairs provided semantic segmentation datasets infer semantic layouts photographs synthesize photographs semantic layouts. sense problem inverse semantic segmentation. images synthesized model shown figure show photographic images synthesized directly single feedforward convolutional network trained minimize regression loss. departs much recent contemporaneous work uses adversarial training generator-discriminator dyads show direct supervised training single convolutional network yield photographic images. bypasses adversarial training known massively unstable furthermore presented approach scales seamlessly high image resolutions. synthesize images resolution megapixels full resolution training data. doubling output resolution generating appropriate details resolution amounts adding single module end-to-end model. conduct careful perceptual experiments using amazon mechanical turk platform comparing presented approach range baselines. experiments clearly indicate images synthesized model signiﬁcantly realistic images synthesized alternative approaches. prominent contemporary approach image synthesis based generative adversarial networks original work goodfellow gans used synthesize mnist digits images aimed reproduce appearance different classes cifar- dataset. denton proposed training multiple separate gans level laplacian pyramid. model trained independently synthesize details scale. assembling separatelytrained models fashion enabled authors synthesize smoother images push resolution work important precursor multiscale reﬁnement central characteristic approach. differences train single model end-to-end directly synthesize output image adversarial training used. radford remark historical attempts scale gans using cnns model images unsuccessful describe number modiﬁcations enable scaling adversarial training images. salimans also tackle instability training describe number heuristics encourage convergence. authors synthesize images possess plausible low-level statistics. nevertheless observed recent work widely known folklore gans remain remarkably difﬁcult train approaches attacking problem still rely heuristics extremely sensitive modiﬁcations work demonstrates difﬁculties avoided setting consider. dosovitskiy train convnet generate images models given model viewpoint. network thus acts directly rendering engine model. also important precursor work uses direct feedforward synthesis network trained regression loss. model loss problem setting different enabling synthesis sharper higherresolution images scenes without models. dosovitskiy brox introduced family composite loss functions image synthesis combine regression activations ﬁxed perceiver network loss. networks trained using composite loss functions applied synthesize preimages induce desired excitation patterns image classiﬁcation models images excite speciﬁc elements models recent work networks trained using losses applied generate diverse sets images synthesize images given captions inpaint missing regions works rely aforementioned composite losses require balancing adversarial loss regression loss. work differs gans used simpliﬁes trainisola consider family problems include image synthesis problem focus paper isola appeared arxiv course research. provides opportunity compare approach credible alternative independently tested data. like number aforementioned formulations isola composite loss combines regression term. authors cityscapes dataset synthesize images given semantic layouts. comparison simpler direct formulation yields much realistic images scales seamlessly high resolutions. qualitative comparison shown figure reed synthesize images scenes described given sentences. mansimov describe different model generates images sentences. generate images faces birds given attributes. reed synthesize images birds people conditioned text descriptions spatial constraints bounding boxes keypoints. wang gupta synthesize images indoor scenes factorizing image generation process synthesis normal subsequent synthesis corresponding color image. works gans exception variational autoencoders mansimov recurrent attention-based model problem statement different input pixelwise semantic layout technical approach differs substantially single feedforward convolutional network trained end-to-end synthesize high-resolution image. line work considers synthesis future frames video. srivastava train recurrent network purpose. mathieu build work denton composite loss combines adversarial term regression penalties colors gradients. predict future frames atari games conditioned player’s action. finn explicitly model pixel motion also condition action. vondrick learn model scene dynamics synthesize video sequences single images. develop probabilistic model enables synthesizing multiple plausible video sequences. works color image available starting point synthesis. video synthesis accomplished advecting content initial image. setting photographic scene appearance must synthesized without initialization. researchers also studied image inpainting superresolution novel view synthesis interactive image manipulation problems photographic content given input whereas concerned synthesizing photographic images semantic layouts alone. consider semantic layout }m×n×c pixel resolution number semantic classes. pixel represented one-hot vector indicates semantic label possible labels ‘void’ indicates semantic class pixel speciﬁed. goal train parametric mapping given semantic layout produces color image rm×n× conforms course project experimented large number network architectures. result experiments identiﬁed three characteristics important synthesizing photorealistic images. review characteristics describing solution. global coordination. globally consistent structure essential photorealism. many objects exhibit nonlocal structural relationships symmetry. example network synthesizes light left side corresponding light right also red. distinguishes photorealistic image synthesis texture synthesis leverage statistical stationarity model based multi-resolution reﬁnement. synthesis begins extremely resolution feature maps progressively reﬁned. thus global structure coordinated lower octaves even distant object parts represented nearby feature columns. decisions reﬁned higher octaves. high resolution. produce truly photorealistic results model must able synthesize high-resolution images. resolution akin myopic vision visual features discernable. drive high image video resolutions multiple industries testament resolution’s importance. model synthesizes images progressive reﬁnement going octave resolution amounts adding single reﬁnement module. entire cascade reﬁnement modules trained end-to-end. memory. conjecture high model capacity essential synthesizing high-resolution photorealistic images. human hyperrealistic painters photographic references external memory detailed object appearance best existing image compression techniques require millions bits information represent content single high-resolution image exists known reconstruct given photograph high ﬁdelity lowercapacity representation order model able synthesize diverse scenes given domain given semantic layouts input capacity model must sufﬁciently high able reproduce detailed photographic appearance many objects. expect successful model reproduce images training extremely well also apply learned representations novel layouts requires high model capacity. design modular capacity model expanded allowed hardware. network used experiments parameters maximizes available memory. consistently found increasing model capacity increases image quality. architecture cascaded reﬁnement network cascade reﬁnement modules. module operates given resolution. implementation resolution ﬁrst module resolution doubled consecutive modules resolution module ﬁrst module receives semantic layout input produces feature layer resolution output. modules structurally identical receives concatenation layout feature layer input produces feature layer output. denote number feature maps module consists three feature layers input layer intermediate layer output layer. illustrated figure input layer dimensionality wi×hi× concatenation downsampled semantic layout bilinearly upsampled feature layer note upconvolutions upconvolutions tend introduce characteristic artifacts intermediate layer output layer dimensionality wi×hi×di. hyperparameters {λl} automatically. initialized inverse number elements layer. epochs {λl} rescaled normalize expected contribution term loss. synthesizing diverse collection architecture training procedure described synthesize single image given input experiments already yields good results. however since given semantic layout correspond many images also makes sense generate diverse images output. conditional synthesis diverse images approached stochastic process take different tack modify network emit collection images shot modiﬁed loss encourages diversity within collection. speciﬁcally change number output channels desired number images. consecutive -tuple channels forms image. consider loss. loss applied independently output image synthesized images identical. ﬁrst modiﬁcation consider outputs together deﬁne loss whole collection terms best synthesized image. image synthesized collection. ﬁrst version modiﬁed loss based hindsight loss developed multiple choice learning considering best synthesized image loss encourages network spread bets cover space images conform input semantic layout. loss structurally akin k-means clustering objective considers closest centroid datapoint thus encourages centroids spread cover dataset. build idea formulate loss considers virtual collection images. speciﬁcally semantic class denote corresponding channel input label map. deﬁne powerful diversity loss mask downsampled match resolution hadamard product. loss effect constructs virtual image adaptively taking best synthesized content semantic class whole collection scoring collection based assembled image. output layer ﬁnal module folinstead linear lowed normalization nonlinearity. projection applied output color image total number reﬁnement modules cascade depends output resolution. main experiments high-resolution cityscapes dataset number modules accounting resolution increase number feature maps trained supervised fashion semantic segmentation dataset semantic layout used input corresponding color image output. thought inverse semantic segmentation. underconstrained one-to-many inverse problem. generally refer reference image rather ground truth since many valid photographic images could yielded semantic layout. given underconstrained nature problem using appropriate loss function critical observed prior work image synthesis. simply comparing pixel colors synthesized image reference image could severely penalize perfectly realistic outputs. example synthesizing white instead black would induce high loss. instead adopt content representation gatys also referred perceptual loss feature matching basic idea match activations visual perception network applied synthesized image separately reference image. trained visual perception network layers network represent image increasing levels abstraction edges colors objects categories. matching lower-layer higher-layer activations perception network guides synthesis network learn ﬁne-grained details global part arrangement. {φl} collection layers network denotes input image. layer threedimensional tensor. training pair loss image synthesis network trained parameters network. hyperparameters {λl} balance contribution layer loss. layers ‘conv ‘conv ‘conv ‘conv ‘conv vgg- image-to-image translation. last baseline contemporaneous approach isola implementation results publicly available approach uses conditional representative dominant stream research image synthesis. generator encoder-decoder setup derived work radford methodology. reliable known methodology evaluating realism synthesized images perceptual experiments human observers. experiments yield quantitative results used related work also attempts design automatic measures evaluate realism without humans loop. example salimans pretrained image classiﬁcation network synthesized images analyzed predictions experimented automatic measures found fooled augmenting baseline also optimize evaluated measure; resulting images realistic score highly well-designed perceptual experiments human observers reliable. therefore carefully designed perceptual experiments quantitative evaluation. release complete implementation experimental setup experiments replicated others. experiments pairwise tests deployed amazon mechanical turk platform. similar protocols used evaluate realism reconstructions mturk involves batch roughly pairwise comparisons along sentinel pairs test whether worker attentive diligent. pair contains images synthesized label different approaches workers asked select realistic image pair. images shown resolution comparisons randomized across conditions left-right order order within randomized. approach presented section ﬁrst tried. section describe number alternative approaches used baselines section semantic segmentation. ﬁrst baseline consistent current trends research community. combines semantic segmentation objective. generator trained synthesize image fools discriminator additional term loss speciﬁes synthesized image given input pretrained semantic segmentation network produce label close input layout possible. setup follows work radford input generator semantic layout semantic segmentation network publicly available networks pretrained cityscapes dataset dataset training objective combines loss semantic segmentation loss. full-resolution network. second baseline feedforward convolutional network operates full resolution. baseline uses loss described section difference network architecture. particular experimented variants multi-scale context aggregation network appealing property network retains high resolution intermediate layers hypothesized helpful photorealistic image synthesis. original architecture described yield good results well-suited problem input semantic layouts piecewise constant network begins small receptive ﬁeld. obtained much better results inverse architecture start large dilation decrease factor layer. viewed full-resolution counterpart based dilating ﬁlters instead scaling feature maps. drawbacks approach intermediate feature layers full image resolution high memory footprint. thus ratio capacity memory footprint much lower crn. high memory footprint intermediate layers also constrains resolution approach scale layers feature maps layer maximal resolution could trained available memory encoder-decoder. third baseline encoder-decoder network u-net network also trained loss crn. thus additional baseline evaluates effect using versus different architecture everything else held ﬁxed. image-space loss. next baseline controls feature table results pairwise comparisons images synthesized models trained cityscapes datasets. column compares approach baselines. cell lists fraction pairwise comparisons images synthesized approach rated realistic images synthesized corresponding baseline. chance ment demonstrated supplementary videos. datasets. datasets pixelwise semantic labels depicting outdoor scenes depicting indoor scenes. primary dataset cityscapes become dominant semantic segmentation dataset quality data train training evaluate validation second dataset older dataset indoor scenes dataset smaller images resolution. note depth data dataset semantic layouts color images. ﬁrst labeled images training remaining testing. primary experiments. table reports results randomized pairwise comparisons images synthesized models trained cityscapes dataset. images synthesized presented approach rated realistic images synthesized four alternative approaches. note ‘image-space loss’ baseline uses architecture controls loss ‘full-resolution network’ ‘encoder-decoder’ loss control architecture. results statistically signiﬁcant compared approach isola images synthesized rated realistic comparisons. qualitative results shown figure figure reports results time-limited pairwise comparisons real cityscapes images images synthesized images synthesized approach isola ages clearly rated less realistic real cityscapes images images hand images real images time seen real>crn rate nearly identical real>pixpix crn>pixpix rates. second) real>pixpix rate rises real>crn rate crn>pixpix rate still nearly identical real>pixpix. milliseconds real>pixpix crn>pixpix rates ﬁnally diverge although extremely high real>crn rate rises time crn>pixpix rate rises real>pixpix rate remains consistently higher real>crn rate. dataset. conduct supporting experiments dataset. dataset smaller lower-resolution quality images synthesized approaches lower. nevertheless differences still clear. table reports results randomized pairwise comparisons images synthesized dataset. images synthesized presented approach rated consistently realistic baselines. results statistically signiﬁcant qualitative results shown figure diversity loss. preceding experiments used feature matching loss speciﬁed equation models produced single image output image evaluated baselines. qualitatively demonstrate effect diversity loss described section trained models produce image collections output figure shows pairs images sampled synthesized collections different input layouts validation set. ﬁgure illustrates diversity loss lead output channels spread produce different appearances. presented direct approach photographic image synthesis conditioned pixelwise semantic layouts. images synthesized convolutional network trained end-to-end regression loss. direct approach considerably simpler contemporaneous work produces much realistic results. hope simplicity presented approach support follow-up work advance realism explore applications photographic image synthesis. results signiﬁcantly realistic prior state clearly indistinguishable real images. exciting work remains done achieve perfect photorealism. level realism ever achieved believe possible alternative routes image synthesis computer graphics open", "year": 2017}