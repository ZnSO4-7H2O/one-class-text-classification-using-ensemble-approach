{"title": "Open Source Dataset and Deep Learning Models for Online Digit Gesture  Recognition on Touchscreens", "tag": ["cs.CV", "cs.AI"], "abstract": "This paper presents an evaluation of deep neural networks for recognition of digits entered by users on a smartphone touchscreen. A new large dataset of Arabic numerals was collected for training and evaluation of the network. The dataset consists of spatial and temporal touch data recorded for 80 digits entered by 260 users. Two neural network models were investigated. The first model was a 2D convolutional neural (ConvNet) network applied to bitmaps of the glpyhs created by interpolation of the sensed screen touches and its topology is similar to that of previously published models for offline handwriting recognition from scanned images. The second model used a 1D ConvNet architecture but was applied to the sequence of polar vectors connecting the touch points. The models were found to provide accuracies of 98.50% and 95.86%, respectively. The second model was much simpler, providing a reduction in the number of parameters from 1,663,370 to 287,690. The dataset has been made available to the community as an open source resource.", "text": "paper presents evaluation deep neural networks recognition digits entered users smartphone touchscreen. large dataset arabic numerals collected training evaluation network. dataset consists spatial temporal touch data recorded digits entered users. neural network models investigated. ﬁrst model convolutional neural network applied bitmaps glpyhs created interpolation sensed screen touches topology similar previously published models ofﬂine handwriting recognition scanned images. second model used convnet architecture applied sequence polar vectors connecting touch points. models found provide accuracies respectively. second model much simpler providing reduction number parameters dataset made available community open source resource. touchscreens pervasively used smartphones computing tablets. text input touchscreen commonly uses virtual keyboard. unfortunately virtual keyboard occupies signiﬁcant portion screen. loss screen noticeable smartphones especially problematic smaller devices smartwatches. text entry means handwriting using ﬁnger thumb advantage gestures performed screen image background. smaller screens easily accommodated entering characters individually another previous work handwriting recognition mainly focused processing images pen-on-paper writing i.e. ofﬂine character recognition. notably mnist dataset created using images handwritten census returns excellent recognition accuracy demonstrated mnist dataset using convolutional neural network contrast online character recognition systems take input form continuously sensed position ﬁnger thumb. online systems advantage recording temporal information well spatial information. date work online character recognition focused based systems lecun al.’s paper proposed convnet approach problem achieving accuracy. method involved considerable preprocessing without accuracy falls preprocessing step requires entire glyph known priori removing possibility early recognition completion glyph. date almost work using neural networks online recognition touchscreen handwriting using ﬁnger thumb. observation digits formed using ﬁnger thumb greater variability formed using examples poorly formed glyphs. likely users better grained control pen. furthermore enable operation cost small form factor devices desirable resource footprint recognizer terms computational complexity memory requirements. date unexplored dimension problem online entry allows early recognition conﬁrmation character entered enabling faster text entry. herein report investigation seeking address challenges. large dataset arabic numerals collected using smartphone. number deep learning models explored accuracy evaluated collected dataset. architectures reported herein. ﬁrst model uses approach similar ofﬂine character recognition systems i.e. convnet taking bitmap completed glyph input. second model uses convnet applied polar vector connecting touch positions. accuracy size networks reported herein together analysis errors. addition initial results early digit recognition provided. best knowledge ﬁrst work report footprint recognizer using polar vector inputs online ﬁnger thumb touch digit recognition. software application developed record dataset. prior participation subjects signed consent form. application ﬁrstly asked subjects enter nationality handedness. subject instructed gesture digits touchscreen using index ﬁnger. digits entered four times. sequence digit entry random. instructions user provided using voice synthesis avoid suggesting speciﬁc glyph rendering. process repeated input using thumb holding device hand. allow applications user hand free. cubic interpolation touches gesture input rendered screen provide visual feedback subject compute arclengths. screen initially blank gestures displayed black. subject could screen gesture small areas bottom reserved instructions/interactions/guidance. subject permitted erase repeat entry desired. dataset acquired inch iphone running force touch data available. touch panel characteristics publicly available speciﬁcally sampling frequency spatial accuracy unknown. values typically reported data stored relational database. subject details handedness recorded along associated glyphs. glyphs stored associated strokes corresponding period subject’s ﬁnger continuous contact device panel. coordinate touch position sampled touch panel device this along timestamp touch stored. dataset reviewed manually incorrectly entered glyphs marked invalid. ﬁnal dataset contained input subjects total digits gestured demographic details summarized table deep learning models developed. takes ofﬂine glyph bitmap input takes polar vectors connecting touch points input. models implemented using keras tensorflow backend trained nvidia titan gpu. ﬁrst architecture investigated listed table consisted convolutional layers fully connected layers. convolutional layers followed rectiﬁed linear unit activation layer pooling layer. convolutional layers kernels size used stride padding ensure height width output input. pooling layers non-overlapping windows size result output second pooling layer fully connected layers come aforementioned layers. dropout used training prevent ﬁtting momentum optimizer implementing variation stochastic gradient descent used minimise error. learning rate used optimiser exponential decay used decay rate running epochs network took approximately seconds train nvidia titan graphics card. coordinates touch samples converted series polar vectors. touch point vector next touch point calculated. angle vector calculated angle positive axis range vertically upwards. length vector expressed pixels. network architecture listed table input sequences padded zeros length longest sequence dataset points. dropout layers dropout rate used avoid co-adaption training data hence reduce overﬁtting. pooling layers pool size used progressively reduce number parameters network hence reduce computation required training process. convolutional layers kernel size used found capture local features within sequence. activation function used relu found provide highest accuracy commonly used activation functions. softmax used order perform ﬁnal classiﬁcation. three input cases considered angle-only vector length-only angle length. glyphs include multiple strokes. longest stroke input network. found give better accuracy inputting entire multi-stroke gesture. training considered ﬁnished validation accuracy change epochs. typically occurred epochs. networks evaluated dataset using training validation test split. accuracy networks listed table seen network bitmap input gives highest accuracy. accuracy close results reported nmist dataset suggesting network able cope variability ﬁnger thumb touch gestures. case polar vector input best results obtained using angle distance data. also polar vector model using longest stroke provided better results using full multi-stroke gesture. dataset deﬁciency artiﬁcial concatenation multi-strokes. size networks compared table network clearly larger number points screen whereas network takes sequence input. figure selection classiﬁcation errors. show glyphs mis-clasiﬁcation occurs omission subsequent strokes. ambiguous glyphs. show mis-classiﬁcation glyph formation. dataset created consisting arabic numerals recorded smartphone touchscreen using single ﬁnger thumb gestures. deep neural networks trained recognise digits. models achieved high accuracy. models used novel polar vector data format signiﬁcantly lower footprint. future work plan enhance accuracy early digit recognition accelerate digit entry process. hoped open source dataset described facilitate work topic. dataset available", "year": 2017}