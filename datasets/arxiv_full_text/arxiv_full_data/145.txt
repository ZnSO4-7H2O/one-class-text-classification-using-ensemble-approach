{"title": "Learning unbiased features", "tag": ["cs.LG", "cs.AI", "cs.NE", "stat.ML"], "abstract": "A key element in transfer learning is representation learning; if representations can be developed that expose the relevant factors underlying the data, then new tasks and domains can be learned readily based on mappings of these salient factors. We propose that an important aim for these representations are to be unbiased. Different forms of representation learning can be derived from alternative definitions of unwanted bias, e.g., bias to particular tasks, domains, or irrelevant underlying data dimensions. One very useful approach to estimating the amount of bias in a representation comes from maximum mean discrepancy (MMD) [5], a measure of distance between probability distributions. We are not the first to suggest that MMD can be a useful criterion in developing representations that apply across multiple domains or tasks [1]. However, in this paper we describe a number of novel applications of this criterion that we have devised, all based on the idea of developing unbiased representations. These formulations include: a standard domain adaptation framework; a method of learning invariant representations; an approach based on noise-insensitive autoencoders; and a novel form of generative model.", "text": "element transfer learning representation learning; representations developed expose relevant factors underlying data tasks domains learned readily based mappings salient factors. propose important representations unbiased. different forms representation learning derived alternative deﬁnitions unwanted bias e.g. bias particular tasks domains irrelevant underlying data dimensions. useful approach estimating amount bias representation comes maximum mean discrepancy measure distance probability distributions. ﬁrst suggest useful criterion developing representations apply across multiple domains tasks however paper describe number novel applications criterion devised based idea developing unbiased representations. formulations include standard domain adaptation framework; method learning invariant representations; approach based noise-insensitive autoencoders; novel form generative model. suggest formulations relevant transfer learning workshop reasons focus deep learning; formulations include supervised unsupervised learning scenarios; well-suited scenario emphasized call-for-papers learning task focused regime limited training data instead must manage large scale data limited labels quality. approaches learn unbiased features rely sample-based measure bias representation. sample test statistical test tries determine given datasets {xn} {ym} whether datasets generated underlying distribution i.e. maximum mean discrepancy useful distance measure distributions used perform sample tests. feature expansion function. apply kernel trick inner product equation implicit feature space. space deﬁned kernel universal reproducing kernel hilbert space asymptotically framework want learn unbiased features invariant nuances across different domains. classiﬁer trained features generalize well domains. deep neural networks classiﬁcation model. used penalty hidden layer neural drive distributions features source target domains close other. similar neural network learn features classiﬁer jointly. distributed representation neural network powerful linear transformation clustering method proposed tested neural network penalty model amazon product review sentiment classiﬁcation dataset dataset contains product reviews domains corresponding product categories review labeled either positive negative preprocessed tf-idf vectors. tested hidden layer neural model adaptation tasks pairs source target domains. task small portion labeled source domain data used validation data early stopping. hyper parameters chosen optimize average target performance random splits data setting similar cross-validation. best target accuracy standard deviation tasks shown table results experiment settings found appendix. compare method models adaptation neural architecture penalty another popular domain adaptation baseline transfer component analysis neural model penalty dominates tasks. even basic word count features method still works better baselines demonstrating ability model learn features useful across domains. application proposed framework learn features invariant transformations input data. speciﬁcally want learn features human faces good identity recognition invariant different lighting conditions. experiment used extended yale dataset contains faces people various lighting conditions corresponding light source different directions. created groups images corresponding light source upper right lower right lower left upper left front. group images chose image person form domain lighting condition. domains images total. images used testing. task recognize identity person image i.e. -way classiﬁcation task. task validation rather report best result test limits different models are. note lighting conditions modeled well lambertian model however strong model rather choose generic neural network learn invariant features proposed method readily applied applications. proposed model task similar used previous section except penalty applied distribution hidden representations different domains rather two. used following formulation individual distribution average distribution across domains indexes domains indexes examples number different domains number examples domain total number examples across domains domain label example hidden representation computed neural network. hidden layer neural relu units task. penalty gaussian kernel applied second hidden layer. dropout used methods compared regularize network overﬁtting problem. task baseline model trained without penalty achieves test accuracy using penalty gaussian kernel best test accuracy improved signiﬁcantly around using linear kernel leads test accuracy visualize hidden representations training images learned gaussian kernel penalty figure note examples person different lighting conditions grouped together even though penalty depends lighting condition take account identity. auto-encoders neural network models basic components encoder maps data latent space decoder maps latent space back original space. auto-encoders typically trained minimize reconstruction loss encoding decoding. many applications reconstruction loss merely proxy lead spurious representations. researchers spent great deal effort developing regularization schemes improve learned representation methods include denoising auto-encoders contractive auto-encoders denoising auto-encoders data perturbed noise reconstruction loss altered measure faithfully original data recovered pertrubed data. contractive auto-encoders explicitly penalize latent representation becomes invariant inﬁnitesimal perturbations original space. appendix show penalty interpreted form penalty linear kernel. experiment several single-layer auto-encoder variants including ordinary auto-encoder trained reconstruction loss contractive auto-encoder denoising auto-encoder. comparison augment ordinary auto-encoder denoising auto-encoder penalty hidden layer sampling perturbed hidden units weight update. trained model mnist digits tuned hyperparameters minimize denoising reconstruction loss held-out data. details found appendix. measure invariance perturbation created noisy copy test data trained classiﬁer latent representations distinguish clean noisy data. worse accuracy corresponds unbiased latent representation. autoencoder outperformed approaches measure. surprisingly denoising autoencoder performed worst demonstrating denoising necessarily produce features invariant noise. also interesting relatively contraction penalty chosen higher penalties seemed incur higher denoising reconstruction loss. likely difference applied bernoulli noise inﬁntesimal noise assumed cae. plots ﬁlters found appendix. last application consider criterion learning generative models. unlike previous sections used learn unbiased representations application match distribution generative model data distribution. idea small samples good generative model. train generative deep model proposed subset mnist digits. model contains stochastic hidden layer ﬁxed prior distribution mapping deterministically maps prior mapping together implicitly deﬁnes distribution authors proposed minimax formulation learn mapping extra classiﬁer looks data samples model good distinguishing them parameters updated make classiﬁer possible samples generated close data. formulation interleaves optimization problems opposite objectives careful scheduling required model converge good point. propose directly minimize data model samples. given ﬁxed sample backpropagate penalty whole network drive model samples close data. method utilizes single consistent objective completely avoids minimax problem. details architecture training found appendix. figure visualizes bottom layer weights network samples generated model. method model learns meaningful features able generate realistic samples.", "year": 2014}