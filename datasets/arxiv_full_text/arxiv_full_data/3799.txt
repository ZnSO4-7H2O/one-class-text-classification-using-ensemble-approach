{"title": "Emergent Communication in a Multi-Modal, Multi-Step Referential Game", "tag": ["cs.LG", "cs.CL", "cs.CV", "cs.IT", "cs.MA", "math.IT"], "abstract": "Inspired by previous work on emergent communication in referential games, we propose a novel multi-modal, multi-step referential game, where the sender and receiver have access to distinct modalities of an object, and their information exchange is bidirectional and of arbitrary duration. The multi-modal multi-step setting allows agents to develop an internal communication significantly closer to natural language, in that they share a single set of messages, and that the length of the conversation may vary according to the difficulty of the task. We examine these properties empirically using a dataset consisting of images and textual descriptions of mammals, where the agents are tasked with identifying the correct object. Our experiments indicate that a robust and efficient communication protocol emerges, where gradual information exchange informs better predictions and higher communication bandwidth improves generalization.", "text": "inspired previous work emergent communication referential games propose novel multi-modal multi-step referential game sender receiver access distinct modalities object information exchange bidirectional arbitrary duration. multi-modal multi-step setting allows agents develop internal communication signiﬁcantly closer natural language share single messages length conversation vary according difﬁculty task. examine properties empirically using dataset consisting images textual descriptions mammals agents tasked identifying correct object. experiments indicate robust efﬁcient communication protocol emerges gradual information exchange informs better predictions higher communication bandwidth improves generalization. recently surge work neural network-based multi-agent systems capable communicating order solve problem. distinct lines research discerned. ﬁrst communication used essential tool sharing information among multiple active agents reinforcement learning scenario active agents addition traditional capability interacting environment able communicate agents. population agents subsequently jointly tuned reach common goal. main goal line work communication means enhance learning difﬁcult sparse-reward environment. communication also mimic human conversation e.g. settings agents engage natural language dialogue based shared visual modality contrast goal work learn communication protocol aligns closely another line research focuses investigating analyzing emergence communication multi-agent referential games agent must communicate sees using discrete emergent communication protocol agent tasked ﬁguring ﬁrst agent saw. lines work partially motivated idea artiﬁcial communication emerge interacting world and/or agents could converge towards human language recently proposed basic version game single transmission message sender receiver test inducing analyzing communication protocol neural network-based agents. related approach using referential game agents proposed recently introduced game similar setting above multiple transmissions messages earlier works lack fundamental aspects human communication solving cooperative games. first human information exchange bidirectional symmetric communication abilities spans exchanges arbitrary length. words linguistic interaction one-way take long short needs. second information exchange emerges result disparity knowledge access information capability bridging different modalities. example human never seen tiger knows stripes would able identify picture without effort. humans identify previously unseen object textual description alone agents previous interaction games access modality shared communication protocol. based considerations extend basic referential game used multi-modal multi-step referential game. firstly agents sender receiver grounded different modalities access visual modality access textual information sender sees image communicates receiver whose determine object sender refers access textual descriptions. secondly communication bidirectional symmetrical sender receiver send arbitrary binary vector other. furthermore allow receiver autonomously decide terminate conversation leads adaptive-length conversation multi-modal nature proposal enforces symmetric high-bandwidth communication enough agents simply exchange carbon copies modalities order solve problem. multistep nature work allows train agents develop efﬁcient strategy communication implicitly encouraging shorter conversation simpler objects longer conversation complex objects. evaluate analyze proposed multi-modal multi-step referential game creating dataset consisting images mammals textual descriptions. task somewhat related recently proposed multi-modal dialogue games played agents using emergent communication. build neural network-based sender receiver implementing techniques visual attention textual attention agent generates multi-dimensional binary message time step receiver decides whether terminate conversation. train agents jointly using policy gradient possible messages used communication sender receiver. analogy natural languages would possible sentences. unlike shared agents makes proposed game realistic proxy natural language conversations parties share single vocabulary. paper deﬁne symbols d-dimensional binary vectors reminiscent widely-used bag-of-words representation natural language sentence. objects. sets separate views modes objects exposed sender receiver respectively. variability introduced choice mode cardinalities latter sets differ i.e. |os| |or| usual cardinalities greater equal i.e. |os| |or| |o|. paper instance selected mammals respectively images textual descriptions mammals |os| |or| |o|. ground-truth given function used determine whether elements belong object returns otherwise. conversation receiver selects element answer used scorer particular conversation based sender’s object receiver’s prediction ˆor. agents proposed game played agents sender receiver sender stochastic function takes input sender’s view object message received receiver outputs binary message unlike sender necessary receiver possess memory order reason series message exchanges sender make ﬁnal prediction. receiver also option determine whether terminate on-going conversation. thus deﬁne receiver indicates whether terminate conversation. receives sender’s message memory previous step stochastically outputs whether terminate conversation prediction message back sender play given game instance initiated uniformly selecting object object corresponding view sampled given sender whole provided receiver receiver’s memory initial message learned separate parameters. agents time step tmax} sender computes message message transmitted receiver. receiver updates memory terminate conversation makes prediction weight vector bias respectively. training sample sender’s message distribution test time take likely message i.e. maxb∈{} attention-based sender view object given vectors osn} rather single vector implement test attention mechanism vector ﬁrst compute attention weight received message mr)) take weighted-sum input αjosj weighted used instead input intuitively process attention corresponds selecting subset sender’s view object according receiver’s query. recurrent receiver real-valued vector d-dimensional binary message received sender. receiver recurrent neural network ﬁrst updates recurrent activation function. gated memory recurrent unit initial message receiver sender learned separate parameter. weight vector bias respectively. receiver terminates conversation either sampling taking likely value distribution. receiver computes message distribution similarly sender d-dimensional factorized bernoulli distribution rdim trainable function embeds q-dimensional real-valued vector space. second term inside tanh function ensures message generated receiver takes consideration receiver’s current belief object sender viewing. again embedding object based receiver’s view similarly proposed receiver’s prediction given maxor∈or entire prediction distribution used compute cross-entropy loss. attention-based receiver similarly sender incorporate attention mechanism receiver. done level embedding function modifying take input vectors orn} current memory vector attention weights view vectors computed memory vector weighted afﬁne transformation returned. reward given ground-truth mapping reinforcement learning loss corresponds reinforce baseline estimators sender receiver respectively trained predict ﬁnal reward suggested order facilitate exploration sender receiver training regularize negative entropies sender’s receiver’s message distributions. also minimize negative entropy receiver’s termination distribution encourage conversation length node collect word corresponding textual description order construct object receiver’s view word query flickr retrieve many images images form sender’s view sample mammals subtree build three sets collected data. first keep subset sixty mammals training aside data validation test constitutes in-domain test measures well model mammals familiar with. remaining mammals build out-of-domain test allows test generalization ability sender receiver unseen objects thereby determine whether receiver indeed relies availability different mode sender. addition mammals build third test consisting different types insects rather mammals. construct transfer test uniformly select images insect random imagenet dataset descriptions collected wordnet similarly mammals. test meant measure extreme case zero-shot generalization entirely different category objects image processing instead image features extracted resnet- attention-based sender -dimensional feature vectors ﬁnal convolutional layer. otherwise -dimensional feature vector average pooling vectors. ﬁne-tune network. query flickr obtaining images word remove duplicates heuristic discard undesirables images. duplicates detected using dhash heuristic take image classiﬁer trained imagenet classify candidate image discard image likely class animal. randomly select remaining images acquire desired amount. text processing description lowercased. stopwords ﬁltered using stopwords corpus included nltk treat description unique words removing duplicates. average description length words standard deviation dataset relatively small especially textual mode pretrained -dimensional glove word embeddings attention-based receiver consider glove vectors otherwise average vectors used representation description. feedforward sender attention used sender conﬁgured single hidden layer tanh units. input constructed concatenating image vector receiver’s message vector point-wise difference point-wise product embedding image message vectors space linear transformation. attention-based sender uses single-layer feedforward network tanh units compute attention weights. recurrent receiver receiver single hidden-layer recurrent neural network gated recurrent units. receiver conﬁgured attention words description feedforward network single hidden layer rectiﬁed linear units. baseline networks baseline networks feedforward networks single hidden layer rectiﬁed linear units each. receiver’s baseline network takes input recurrent hidden state training evaluation train sender receiver well associated baseline networks using rmsprop learning rate minibatches size each. coefﬁcients entropy regularization respectively based development performance preliminary experiments. training early-stopped based development accuracy maximum epochs. evaluate model test computing accuracyk number categories three test sets metric enable comparison different test sets avoid overpenalizing predicting similar classes e.g. kangaroo wallaby. maximum length conversation i.e. tmax train single single experiment takes roughly hours epochs. model approach paper differentiated previous work mainly variable conversation length multi-modal nature game particular nature communication protocol i.e. messages. section experimentally examine setup speciﬁcally test following hypotheses difﬁcult complex referential game dialogue turns would needed humans play similarly expect receiver need information questions problem difﬁcult. hence examine relationship conversation length accuracy/difﬁculty. agents take turns continuing conversation information becomes available implies receiver become sure prediction even problem difﬁcult begin with. thus separately examine conﬁdence predictions conversation progresses. agents play different roles game. hand would hypothesize receiver’s messages become speciﬁc. example receiver already established picture feline make sense e.g. whether animal tusks ﬁns. implies entropy messages decrease. hand questions become speciﬁc also likely become difﬁcult sender answer high conﬁdence. answering something aquatic mammal easier describing e.g. particular shape consequently entropy sender’s messages likely increase grows less conﬁdent answers. examine this analyze information theoretic content messages sent agents. follows discuss experiments along lines hypotheses. addition analyze impact changing message dimensionality effect applying visual linguistic attention mechanisms. figure difﬁculty versus conversation length across classes. negative correlation observed implying difﬁcult classes require turns. accuracyk versus conversation length in-domain out-ofdomain test sets. conversation length accuracy/difﬁculty train pair agents adaptive conversation length receiver terminate conversation early based stop probability. training done inspect relationship average conversation length difﬁculty across classes well accuracy conversation length partitioning test examples length-based bins. expect difﬁcult classes require higher average length exchange. test hypothesis accuracy separate classiﬁer proxy difﬁculty sample. speciﬁcally train classiﬁer based pre-trained resnet- freeze last layer obtain score class evaluated in-domain test set. pearson correlation score average conversation length across classes p-value implying statistically signiﬁcant negative relationship displayed fig. addition present accuracies conversation lengths fig. notice clear trend in-domain test examples conversations shorter better classiﬁed might indicate easier. important remember receiver’s stop probability artiﬁcially tied performance conﬁdence receiver’s prediction simply learned playing proposed game. similar trend observed out-of-domain test however lesser degree. similar trend longer conversation difﬁcult objects also found humans game questions figure prediction entropy conversation using in-domain out-of-domain test sets. prediction certainty time example conversations kangaroo wolf respectively. conversation length conﬁdence agents trained adaptive conversation length investigate prediction uncertainty receiver evolves time. plot evolution entropy prediction distribution fig. averaged conversation length bucket. ﬁrst notice conversation length determined receiver correlates well prediction conﬁdence receiver. also clear in-domain test entropy almost monotonically decreases conversation receiver terminates conversation predictive entropy converges. trend however apparent out-of-domain test attribute difﬁculty zero-shot generalization. goal conversation i.e. series message exchanges distinguish among many different objects. initial message sender could example give rough idea high-level category object belongs goal becomes distinguish different objects within high-level category. words objects single cluster visually similar sender’s access visual mode object predicted different time steps conversation. qualitatively examine hypothesis visualizing predictive probabilities receiver evolve conversation. fig. show example categories kangaroo wolf. conversation progress information gathered receiver similar incorrect categories receive smaller probabilities correct one. notice similar trend categories. information theoretic message content previous section examined prediction certainty evolved time. messages sent respective agents. fig. plot entropies message distributions sender receiver. notice that conversation progresses entropy decreases receiver increases sender. observation explained following conjecture. receiver accumulates information transmitted sender possible queries send back sender shrinks consequently entropy decreases. could said questions become speciﬁc information becomes available receiver zones correct answer. hand receiver’s message becomes speciﬁc difﬁcult answer certainty sender providing correct answer decreases thereby increasing entropy sender’s message distribution. notice similar trend out-of-domain test well. effect message dimensionality next vary dimensionality message investigate impact constraint communication channel keeping conversation length adaptive. generally expect better accuracy higher bandwidth. speciﬁcally expect generalization unseen categories would improve information bandwidth communication channel increases. bandwidth limited agents forced create communication protocol highly specialized categories seen training. hand agents learn decompose structures underlying visual textual modes object generalizable descriptions higher bandwidth channel. figure accuracyk indomain out-of-domain test sets adaptive models varying message size. notice increasing accuracy out-ofdomain test bandwidth channel increases. dimensionality changes. observe however strong correlation message dimensionality accuracy out-of-domain test set. -dimensional messages agents able achieve accuracy out-of-domain test consists mammals seen training. effect modifying message dimension less clear measured transfer set. effect attention mechanism experiments without attention mechanism. train additional three pairs agents -dimensional message vectors; attentionbased sender attention-based receiver attention-based sender attention-based receiver. in-domain test able observe improvement attention mechanism either agents. however notice attention mechanism signiﬁcantly improves accuracy transfer test conjecture fact attention allows agents focus aspects objects familiar with means less susceptible noise introduced exposed entirely category. leave analysis effect attention mechanism future work. communication necessary? important consideration whether trained agents utilize adaptability communication protocol. indeed possible sender learn shape communication simply relies random communication protocol decided random initialization parameters. case receiver need recover information sender sent random communication channel. order verify case train pair agents without updating parameters sender. receiver still updated sender’s information still ﬂows toward receiver learning happens. however observe overall performance signiﬁcantly lags behind case agents trained together shown fig. suggests agents must learn task-speciﬁc communication protocol emerges order solve problem successfully. paper proposed novel multi-modal multi-step referential game building analyzing communication-based neural agents. design game enables human-like communication agents allowing variable-length conversation symmetric communication. conducted experiments analyses reveal three interesting properties communication protocol artiﬁcial language emerges learning play proposed game. first sender receiver able adjust length conversation based difﬁculty predicting correct object. length conversation found correlate conﬁdence receiver making predictions. second receiver gradually asks speciﬁc questions conversation progresses. results increase entropy sender’s message distribution ways answer highly speciﬁc questions. observe increasing bandwidth communication measured terms message dimensionality allows improved zero-shot generalization. importantly present suite hypotheses associated experiments investigating emergent communication protocol believe useful future research emergent communication. future direction despite signiﬁcant extension made basic referential game proposed multi-modal multi-step game also exhibits number limitations. first emergent communication game entirely symmetric constraint prevents agents partitioning message space. could addressed agents interacting exchanging roles leave future work. second message consists ﬁxed-dimensional binary vectors. choice effectively prevents linguistic structures syntax. third proposed game well existing referential game require action speaking. contrast ﬁrst line research discussed earlier sec. communication happens among active agents. anticipate future research direction approaches combined. thank brenden lake alex cohen valuable discussion. also thank maximilian nickel y-lan boureau jason weston dhruv batra devi parikh helpful suggestions. thanks support adeptmind tencent ebay nvidia cifar. thanks nvidia corporation donation titan pascal. work done part course ds-ga independent study data science center data science york university. part fig. licensed emmymik/cc ./https//www.ﬂickr.com/photos/emmymik//. kyunghyun bart merrienboer caglar gulcehre fethi bougares holger schwenk yoshua bengio. learning phrase representations using encoder-decoder statistical machine translation. conference empirical methods natural language processing harm vries florian strub sarath chandar olivier pietquin hugo larochelle aaron courville. guesswhat? visual object discovery multi-modal dialogue. arxiv preprint arxiv. deng dong richard socher li-jia fei-fei. imagenet large-scale hierarchical image database. computer vision pattern recognition cvpr ieee conference ieee jakob foerster yannis assael nando freitas shimon whiteson. learning communicate solve riddles deep distributed recurrent q-networks. arxiv preprint arxiv. kaiming xiangyu zhang shaoqing jian sun. deep residual learning image recognition. proceedings ieee conference computer vision pattern recognition alex krizhevsky ilya sutskever geoffrey hinton. imagenet classiﬁcation deep convolutional neural networks. advances neural information processing systems jeffrey pennington richard socher christopher manning. glove global vectors word representation. empirical methods natural language processing florian strub harm vries jeremie mary bilal piot aaron courville olivier pietquin. end-to-end optimization goal-driven visually grounded dialogue systems. arxiv preprint arxiv. tijmen tieleman geoffrey hinton. lecture .-rmsprop divide gradient running average recent magnitude. coursera neural networks machine learning kelvin jimmy ryan kiros kyunghyun aaron courville ruslan salakhudinov rich zemel yoshua bengio. show attend tell neural image caption generation visual attention. international conference machine learning sender agent receiver agent possible messages used communication agents mammal classes mammal images available sender mammal descriptions available receiver ground-truth namely element element element corresponding correct object sender-receiver exchange receiver’s predicted distribution objects timestep receiver’s prediction binary message sent sender binary message sent receiver binary indicators terminating conversation value indicator terminating conversation yielded receiver value indicator terminating conversation yielded receiver time step maximal value number time steps conversation time step conversation sender receiver binary message generated sender time step binary message generated receiver time step hidden state vector sender hidden state vector receiver hidden state receiver time step function computing hidden state sender function computing hidden state attention-based sender receiver’s recurrent activation function computing baseline feedforward network sender baseline feedforward network receiver j-th coordinate sender’s message j-th column sender’s weight matrix j-th coordinate sender’s bias vector embedding object receiver’s view j-th coordinate receiver’s message receiver’s weight matrix hidden space receiver’s weight matrix embeddings receiver’s bias vector embeddings j-th column receiver’s weight matrix j-th coordinate receiver’s bias vector hidden state transpose vector per-instance loss per-instance reinforcement learning loss per-instance baseline loss reward ground-truth mapping entropy entropy regularization coefﬁcient binary messages distributions agents entropy regularization coefﬁcient receiver’s termination distribution standard setup times using different random seeds. experiment trained model convergence using early stopping validation data measured loss accuracy in-domain test set. accuracy mean variance accuracy mean variance loss mean variance .e−. results suggest model effective classifying images also robust random restart.", "year": 2017}