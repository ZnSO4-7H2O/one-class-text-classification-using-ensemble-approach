{"title": "Learning Concept Taxonomies from Multi-modal Data", "tag": ["cs.CL", "cs.CV", "cs.LG"], "abstract": "We study the problem of automatically building hypernym taxonomies from textual and visual data. Previous works in taxonomy induction generally ignore the increasingly prominent visual data, which encode important perceptual semantics. Instead, we propose a probabilistic model for taxonomy induction by jointly leveraging text and images. To avoid hand-crafted feature engineering, we design end-to-end features based on distributed representations of images and words. The model is discriminatively trained given a small set of existing ontologies and is capable of building full taxonomies from scratch for a collection of unseen conceptual label items with associated images. We evaluate our model and features on the WordNet hierarchies, where our system outperforms previous approaches by a large gap.", "text": "figure overview system. input collection label items represented text images; output build taxonomy scratch extracting features based distributed representations text images. computer vision. hand number methods developed build hierarchies based lexical patterns text works generally ignore rich visual data encode important perceptual semantics proven complementary linguistic information helpful many tasks hand researchers built visual hierarchies utilizing visual features resulting hierarchies limited interpretability usability knowledge transfer. hence propose combine visual textual knowledge automatically build taxonomies. induce is-a taxonomies supervised learning existing entity ontologies concept category associated images either existing dataset retrieved using search engines illustrated scenario realistic extended variety tasks; example knowledge base study problem automatically building hypernym taxonomies textual visual data. previous works taxonomy induction generally ignore increasingly prominent visual data encode important perceptual semantics. instead propose probabilistic model taxonomy induction jointly leveraging text images. avoid hand-crafted feature engineering design end-to-end features based distributed representations images words. model discriminatively trained given small existing ontologies capable building full taxonomies scratch collection unseen conceptual label items associated images. evaluate model features wordnet hierarchies system outperforms previous approaches large gap. human knowledge naturally organized semantic hierarchies. example wordnet speciﬁc concepts categorized assigned general ones leading semantic hierarchical structure variety tasks question answering document clustering text generation beneﬁt conceptual relationship present hierarchies. traditional methods manually constructing taxonomies experts interest communities either knowledge time intensive results limited coverage. therefore automatic induction taxonomies drawing increasing attention construction text image collections readily available label relations among categories uncovered. largescale object recognition automatically learning relations labels quite useful textual visual information provide important cues taxonomy induction. illustrates example. parent category seaﬁsh child categories shark closely related hypernym-hyponym relation words seaﬁsh shark/ray text descriptions like ...seaﬁsh shark ray... ...shark group seaﬁsh...; images close neighbors e.g. shark usually visually similar images shark/ray similar subchild e.g. images seaﬁsh. effectively capture patterns contrast previous works rely various hand-crafted features extract features leveraging distributed representations embed images words compact vectors based semantic closeness directly measured vector space. further develop probabilistic framework integrates rich multi-modal features induce is-a relations between categories encouraging local semantic consistency category visually textually close parent siblings. summary paper following contributions propose novel probabilistic bayesian model taxonomy induction jointly leveraging textual visual data. model discriminatively trained directly applied build taxonomy scratch collection semantic labels. design novel features based generalpurpose distributed representations text images capture textual visual relations labels. evaluate model features imagenet hierarchies different taxonomy induction tasks achieve superior performance tasks improve score taxonomy construction task compared previous approaches. extensive comparisons demonstrate effectiveness integrating visual features language features taxonomy induction. also provide many approaches recently developed build hierarchies purely identifying either lexical patterns statistical features text corpora approaches yang callan snow assume starting incomplete hierarchy extend inserting terms. kozareva hovy navigli ﬁrst leaf nodes lexical patterns intermediate terms attested hypernymy links them. syntactic contextual similarity exploited construct taxonomy tuan step consider trustiness collective synonym/contrastive evidence. different them model discriminatively trained multi-modal data. works bansal similar language-based features ours. speciﬁcally linguistic regularities pretrained word vectors modeled projection mappings. trained projection matrix used induce pairwise hypernym-hyponym relations words. features partially motivated jointly leverage textual visual information. kiela textual visual evidences exploited detect pairwise lexical entailments. work signiﬁcantly different model optimized whole taxonomy space rather considering word pairs separately. structural learning model developed induce globally optimal hierarchy. compared work exploit much richer features text images leverage distributed representations instead hand-crafted features. several approaches also proposed construct visual hierarchies image collections. nonparametric bayesian model developed group images based low-level features. construct taxonomy tree categories categories speciﬁc object types grouped assigned general concepts categories multiple disjoint taxonomy trees pseudo category hyper-root optimal taxonomy ensured single tree. index parent category i.e. hypernymic category thus problem inducing taxonomy structure equivalent inferring conditional distribution indices based images text. model formulate distribution model leverages rich multi-modal features. speciﬁcally child nodes category taxonomy encoded model deﬁned cn\\xn) deﬁned measures semantic consistency category parent well siblings indexed cn\\xn. function loglinear respect nncn\\xn feature vector deﬁned relevant categories cn\\xn) cn\\xn child categories excluding simple exponential formulation effectively encourage close relations among nearby categories induced taxonomy. function combination weights maximum depth taxonomy capture importance different features function return depth current taxonomy. layer taxonomy speciﬁc thereby allowing varying weights features different layers. parameters learned supervised manner. also introduce weight node order capture varying popularity different categories example categories like assume tree. existing taxonomies modeled trees since tree helps simplify construction ensures learned taxonomy interpretable. minor modiﬁcations model also works non-tree structures. visual taxonomy built accelerate image categorization. binary object-object relations extracted using co-detection matrices. work differs integrate textual visual information construct taxonomies. also note several works integrate text images evidence knowledge base autocompletion zeroshot recognition work different because task accurately construct multilevel hyponym-hypernym hierarchies categories. model motivated observation semantically meaningful taxonomy category tends closely related children well siblings. instance exists hypernym-hyponym relation name category shark parent seaﬁsh. besides images shark tend visually similar seaﬁshes. model thus designed encourage local semantic consistency; jointly considering categories inference globally optimal structure achieved. advantage model incorporate visual textual features induced distributed representations images text features capture rich underlying semantics facilitate taxonomy induction. distinguish relative importance visual textual features could vary different layers taxonomy. intuitively visual features would increasingly indicative deeper layers sub-categories category speciﬁc objects tend visually similar. contrast textual features would important inducing hierarchical relations categories general concepts visual characteristics necessarily similar. proof straightforward omit space limitations. also pseudo node ﬁxed root taxonomy. hence initializing tree-structured state rooted restricting updating step structure operation sampling procedure able explore whole valid tree space. output taxonomy selection. apply model discover underlying taxonomy given categories ﬁrst obtain marginals averaging samples generated output optimal taxonomy ﬁnding maximum spanning tree using chu-liu-edmonds algorithm training. need learn model parameters layer capture relative importance different features. model trained using algorithm. depth category denote gold structure training data. training algorithm updates maximum likelihood estimation wherein gradient difference gold feature vectors expected feature vectors model. expectation approximated collecting samples using sampler described averaging them. section describe feature vector used model defer details supplementary material. compared previous taxonomy induction works rely purely linguistic information exploit perceptual textual features capture rich spectrum semantics encoded images text. moreover leverage distributed representations images words construct compact effective features. speciﬁcally image represented embedding vector extracted deep convolutional neural networks. image representation successfully applied various vision tasks. hand category name represented word embedding low-dimensional dense vector induced skip-gram model encode prior knowledge category popularity; conjugacy allows marginalize analytically number children category next describe approach infer expectation based select particular taxonomy structure category nodes constrained tree include indicator factor takes corresponds tree otherwise. modify inference algorithm appropriately incorporate constraint. inference. exact inference computationally intractable normalization constant therefore gibbs sampling procedure approximate inference. present sampling formula directly defer details supplementary material. sampling procedure highly efﬁcient normalization term factors irrelevant cancelled out. formula number children category superscript denotes number excluding examining validity taxonomy structure sampling step computationally prohibitive. handle this restrict candidate value ensuring always tree. speciﬁcally given tree deﬁne structure operation procedure detaching node parent appending another node descendant proposition applying structure operation tree result structure still tree. tree structure node root node tree achieved applying structure operation ﬁnite number times. further inspired linguistic regularities word embedding i.e. hypernym-hyponym relationship words approximated linear projection operator word vectors design similar strategy images words parent predicted given image embedding child category projection matrix. speciﬁcally parent-child pair training data learn projection matrix minimizes distance φvin child) word features brieﬂy introduce text features employed. details text feature extraction could found supplementary material. word embedding features.d pc-v induce features using word vectors measure sibling-sibling parent-child closeness text domain exception that category word sibling similarity computed cosine distance word vectors produce another parts features parentchild word-word relation feature siblings word-word relation feature word surface features. addition embedding-based features leverage lexical features based surface forms child/parent category names. speciﬁcally employ capitalization ends with contains sufﬁx match length different features commonly used previous works taxonomy induction widely used diverse applications too. design cn\\xn) based image text representations. feature vector used measure local semantic consistency category parent category well siblings cn\\xn. sibling similarity. mentioned above close neighbors taxonomy tend visually similar indicating embedding images sibling categories close vector space category image gaussian distribution image vectors mean vector ra×a covariance matrix. sibling category deﬁne visual similarity vissim=+n average probability mean image vector category gaussian distribution other. takes account distance mean images also closeness images category. accordingly compute visual similarity between cn\\xn averaging vissim cn\\xn values vissim cn\\xn) represent one-hot vector constitutes component named siblings imageimage relation feature parent prediction. similar feature also create similarity feature image vectors parent child measure visual similarity. however parent node usually general concept child usually consists images necessarily similar child. intuitively narrowing images similar child improves feature. therefore different estimating gaussian distribution parent node images highest probabilities gaussian distribution child node. empirically show section choosing appropriate consistently boosts performance. name feature parent-child image-image relation feature reproducibility. compare model previous state-of-the-art methods taxonomy induction tasks. finally provide analysis weights taxonomies induced. dataset. conduct experiments imagenet dataset provides large collection category items associated images label hierarchy them. original imagenet taxonomy preprocessed resulting tree structure nodes. word embedding training. train word embedding synsets replacing word/phrase synset unique token using google’s wordvec tool combine three public available corpora together including latest wikipedia dump billion word language modeling benchmark umbc webbase corpus resulting corpus total billion tokens. dimension embedding image processing. employ ilsvrc pre-trained convolutional neural networks embed image vector space. then category images estimate multivariate gaussian parameterized constrain diagonal prevent overﬁtting. categories images estimate mean vector µxn. nodes images ignore visual feature. training conﬁguration. feature vector concatenation parts detailed section pairwise distances precomputed stored memory accelerate gibbs sampling. initial learning rate gradient descent step decreased fraction every iterations. evaluation experimental settings evaluate model three subtrees sampled imagenet taxonomy. collect subtrees start given root traverse full taxonomy using collect descendant nodes within depth vary series subtrees increasing heights various scales different domains. statistics evaluation sets provided table avoid ambiguity nodes used ilsvrc removed feature extractor trained them. design different tasks evaluate model. hierarchy completion task randomly remove nodes tree remaining hierarchy training. test phase infer parent removed node compare groundtruth. task designed ﬁgure whether model successfully induce hierarchical relations learning within-domain parent-child pairs. hierarchy different previous construction task designed test generalization ability model i.e. whether model learn statistical patterns hierarchy transfer knowledge build taxonomy another collection out-of-domain labels. speciﬁcally select trees training learn test phase model required build full taxonomy scratch third tree. results hierarchy completion. hierarchy completion task split tree nodes training test experiment different compare following three systems model language features enabled model language features visual features average performance three trees reported table observe performance gradually drops increases nodes inserted tree grows higher leading complex difﬁcult taxonomy accurately constructed. overall model outperforms terms score even withvisual features. difﬁcult case model still holds score demonstrating superiority model. hierarchy construction. hierarchy construction task much difﬁcult hierarchy completion task need build taxonomy scratch given hyper-root. task leave-one-out strategy i.e. train model every trees test third report average performance table compare following methods described above; bansal model bansal tried different parameter settings number clusters identiﬁcation threshold reported best performance achieved. comparisons simply i.e. available images parent category estimate pc-v feature. retrained using dataset; excluding visual features including language features bansal full model enhanced semantic features bansal excluding word embeddingbased language features shown hierarchy construction task model language features still outperforms large uses similar embeddingbased features. potential reasons two-fold. first take account parent-child relations also siblings. second method designed induce pairwise relations. build full taxonomy ﬁrst identify possible pairwise relations using simple thresholding strategy eliminate conﬂicted relations obtain legitimate tree hierarchy. contrast model optimized full space legitimate taxonomies taking structure operation account gibbs sampling. comparing bansal model word embedding-based features underperforms theirs. however introducing visual features performance comparable .furthermore discard visual features semantic features bansal achieve slight improvement bansal largely attributed incorporation word embedding-based features encode high-level linguistic regularity. finally enhance full model semantic features bansal model outperforms justiﬁes intuition perceptual semantics underneath visual contents quite helpful. section conduct qualitative studies investigate visual information helps taxonomy induction task. contributions visual features. evaluate contribution part visual features ﬁnal performance train model jointly textual features different combinations visual features report ancestorf scores. shown table incorporating feature performance substantially boosted large heights showing visual similarity sibling nodes strong evidence taxonomy induction. intuitively plausible highly likely speciﬁc categories share common parent category similar visual contents observed them. further adding pc-v feature gains better improvement adding pc-v minor s-v. compared siblings visual similarity parents children strongly holds time. example images terrestrial animal partially similar feline former contains later subset. feature captures type contain relation parents children considering top-k images parent category highest probabilities gaussian distribution child category. this vary keep settings plot scores observe trend gradually increase performance goes reaching maximal; slightly drops even images available conﬁrms feature design images considered parent-child visual similarity. overall three visual features complement other achieve highest performance combined. visual representations. investigate image representations affect ﬁnal performance compare ancestor-f score different pre-trained cnns used visual feature extraction. speciﬁcally employ cnn- model model simonyan zisserman observe slight improvement ancestor-f score later one. relevance textual visual features v.s. depth tree. compared bansal major difference model different layers taxonomy correspond different weights layers share weights. intuitively introducing layer-wise extends model capacity also differentiates importance feature different layers. example images speciﬁc categories shark likely visually similar. however taxonomy goes bottom visual similarity gradually undermined images terrestrial animal necessarily similar more. hence necessary privatize weights different layers capture variations i.e. visual features become evident shallow deep layers textual counterparts capture abstract concepts relatively grow indicative oppositely speciﬁc general. block then average observe values change layer depth example parent-child word-word relation feature ﬁrst fetch corresponding weights matrix feature dimension number layers. average absolute values column vector length normalization magnitude entry directly reﬂects relative importance feature evidence taxonomy induction. plots magnitudes change every feature component averaged three train/test splits. noticeable wordword relations corresponding weights slightly decrease increases. contrary image-image relation features grows relatively prominent. results verify conjecture category hierarchy goes deeper speciﬁc classes visual similarity becomes relatively indicative evidence taxonomy induction. visualizing results. finally visualize excerpts predicted taxonomies compared groundtruth paper study problem automatically inducing semantically meaningful concept taxonomies multi-modal data. propose probabilistic bayesian model leverages distributed representations images words. compare model features previous ones different tasks using imagenet hierarchies demonstrate superior performance model effectiveness exploiting visual contents taxonomy induction. conduct qualitative studies distinguish relative importance visual textual features constructing various parts taxonomy. would like thank anonymous reviewers valuable feedback. would also like thank mohit bansal helpful suggestions. thank nvidia donations. work supported data iis.", "year": 2016}