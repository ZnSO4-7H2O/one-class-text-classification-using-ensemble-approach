{"title": "Toward Controlled Generation of Text", "tag": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "abstract": "Generic generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain. This paper aims at generating plausible natural language sentences, whose attributes are dynamically controlled by learning disentangled latent representations with designated semantics. We propose a new neural generative model which combines variational auto-encoders and holistic attribute discriminators for effective imposition of semantic structures. With differentiable approximation to discrete text samples, explicit constraints on independent attribute controls, and efficient collaborative learning of generator and discriminators, our model learns highly interpretable representations from even only word annotations, and produces realistic sentences with desired attributes. Quantitative evaluation validates the accuracy of sentence and attribute generation.", "text": "generic generation manipulation text challenging limited success compared recent deep generative modeling visual domain. paper aims generating plausible text sentences whose attributes controlled learning disentangled latent representations designated semantics. propose neural generative model combines variational auto-encoders holistic attribute discriminators effective imposition semantic structures. model alternatively seen enhancing vaes wake-sleep algorithm leveraging fake samples extra training data. differentiable approximation discrete text samples explicit constraints independent attribute controls efﬁcient collaborative learning generator discriminators model learns interpretable representations even word annotations produces sentences desired attributes sentiment tenses. quantitative experiments using trained classiﬁers evaluators validate accuracy short sentence attribute generation. surge research interest deep generative models variational autoencoders generative adversarial nets autoregressive models despite impressive advances visual domain image generation learning interpretable image representations image editing applications natural language generation relatively less studied. even generating realistic sentences challenging generative models required capture complex semantic structures underlying sentences. previous work mostly limited task-speciﬁc applications supervised settings including machine translation image captioning however autoencoder frameworks recurrent neural network language models apply generic text generation arbitrary hidden representations unsmoothness effective hidden codes recent attempts using vaes gans made investigate generic text generation generated text largely randomized uncontrollable. paper tackle problem controlled generation text. focus generating realistic sentences whose attributes controlled learning disentangled latent representations. enable manipulation generated sentences challenges need addressed. ﬁrst challenge comes discrete nature text samples. resulting non-differentiability hinders global discriminators assess generated samples back-propagate gradients guide optimization generators holistic manner shown highly effective continuous image generation representation modeling number recent approaches attempt address non-differentiability policy learning tends suffer high variance during training continuous approximations preliminary qualitative results presented. alternative discriminator based learning semi-supervised vaes minimize element-wise reconstruction error observed examples applicable discrete visibles. this however loses holistic view full sentences inferior especially modeling global abstract attributes another challenge controllable generation relates learning disentangled latent representations. interpretability expects part latent representation govern focus aspect samples. prior methods structured representation learning lack explicit enforcement independence property full latent representation varying individual code result unexpected variation unspeciﬁed attributes besides desired one. paper propose text generative model addresses issues permitting highly disentangled representations designated semantic structure generating sentences dynamically speciﬁed attributes. base generator vaes combination holistic discriminators attributes effective imposition structures latent code. end-to-end optimization enabled differentiable softmax approximation anneals smoothly discrete case helps fast convergence. probabilistic encoder also functions additional discriminator capture variations implicitly modeled aspects guide generator avoid entanglement attribute code manipulation. model interpreted enhancing vaes extended wake-sleep procedure sleep phase enables incorporation generated samples learning generator discriminators alternating manner. generator discriminators effectively provide feedback signals other resulting efﬁcient mutual bootstrapping framework. show little supervision sufﬁcient learn structured representations. besides efﬁcient representation learning enabled semisupervised training another advantage using discriminators learning signals generator compared conventional conditional reconstruction based methods discriminators different attributes trained independently. attribute separate labeled data training respective discriminator trained discriminators combined arbitrarily control attributes interest. contrast reconstruction based approaches typically require every instance training data labeled exhaustively target attributes marginalize missing attributes computationally expensive. showing case apply model generate sentences controlled sentiment tenses. though best knowledge text corpus sentiment tense labels method enables separate datasets annotated sentiment tense labels. quantitative experiments demonstrate efﬁcacy method. model improves previous generative models accuracy generating speciﬁed attributes well performing classiﬁcation using generated samples. show method learns highly disentangled representations word-level labels produces plausible short sentences. remarkable progress made deep generative modeling. provide uniﬁed view diverse deep generative methods. variational autoencoders consist encoder generator networks encode data example latent representation generate samples latent space respectively. model trained maximizing variational lower bound data log-likelihood generative model. divergence loss minimized match posterior latent code prior enables every latent code prior decode plausible sentence. without regularization vaes degenerate autoencoders become inapplicable generic generation. vanilla vaes incompatible discrete latents hinder differentiable parameterization learning encoder. wake-sleep algorithm introduced learning deep directed graphical models shares similarity vaes also combining inference network generator. wake phase updates generator samples generated inference network training data sleep phase updates inference network based samples generator. method combines vaes extended wake-sleep sleep procedure updates generator inference network enabling collaborative semi-supervised learning. besides reconstruction data space discriminatorbased metric provides different generator learning i.e. discriminator assesses generated samples feedbacks learning signals. instance gans discriminator feedback probability sample recognized real example. larsen combine vaes gans enhanced image generation. dosovitskiy brox taigman discriminators measure highlevel perceptual similarity. applying discriminators text generation hard non-differentiability discrete samples bowman tang yang instead vaes without discriminators. text generation methods learn disentangled latent representations resulting randomized uncontrollable samples. contrast disentangled generation visual domain made impressive progress. e.g. infogan resembles extended sleep procedure joint vae/wakesleep algorithm disentangles latent representation unsupervised manner. semantic dimension observed training rather designated users controlled way. siddharth kingma base vaes obtain disentangled image representations semi-supervised learning. zhou neubig extend semi-supervised vaes text transduction. contrast model combines vaes discriminators provide better holistic metric compared element-wise reconstruction. moreover approaches focused disentanglement structured part latent representations ignoring potential dependence structured code attributes explicitly encoded. address introducing independency constraint show effectiveness improved interpretability. model aims generate plausible sentences conditioned representation vectors endowed designated semantic structures. instance control sentence sentiment model allocates dimension latent representation encode positive negative semantics generates samples desired sentiment simply specifying particular code. beneﬁting disentangled structure code able capture salient attribute independent features. deep text generative model possesses several merits compared prior work facilitates effective imposition latent code semantics enabling global discriminators guide discrete text generator learning; improves model interpretability explicitly enforcing constraints independent attribute controls; permits efﬁcient semi-supervised learning bootstrapping synthesizing variational auto-encoders tailored wake-sleep approach. ﬁrst present overview framework describe model detail build framework starting variational autoencoders used text generation sentence generated conditioned latent code vanilla employs unstructured vector dimensions entangled. model control attributes interest interpretable augment unstructured variables structured variables targets salient independent semantic feature sentences. want sentence generator condition combined vector generate samples fulﬁll attributes speciﬁed structured code conditional generation context vaes often learned reconstructing observed examples given feature code. however demonstrated visual domain compared computing element-wise distances data space computing distances feature space allows invariance distracting transformations provides better holistic metric. figure generative model unstructured latent code structured code targeting sentence attributes control. blue dashed arrows denote proposed independency constraint arrows denote gradient propagation enabled differentiable approximation. thus attribute code individual discriminator measure well generated samples match desired attributes drive generator produce improved results. difﬁculty applying discriminators context text samples discrete non-differentiable breaks gradient propagation discriminators generator. continuous approximation based softmax decreasing temperature anneals discrete case training proceeds. simple effective approach enjoys variance fast convergence. intuitively interpretable representation would imply structured code independently control target feature without entangling attributes especially explicitly modeled. encourage independency enforcing irrelevant attributes completely captured unstructured code thus separated manipulate. reuse encoder additional discriminator recognizing attributes modeled train generator unstructured attributes recovered generated samples. result varying different attribute codes keep unstructured attributes invariant long unchanged. figure shows overall model structure. complete model incorporates vaes attribute discriminators component trains generator reconstruct real sentences generating plausible text discriminators enforce generator produce attributes coherent conditioned code. attribute discriminators learned labeled examples entail designated semantics well trained explain samples generator. generator discriminators form pair collaborative learners provide feedback signals other. collaborative optimization resembles wake-sleep algorithm. show combined vae/wake-sleep learning enables highly efﬁcient semisupervised framework requires little supervision obtain interpretable representation generation. ˆx<t indicates tokens preceding ˆxt. generation thus involves sequence discrete decision making samples token multinomial distribution parametrized using softmax function time step unstructured part representation modeled continuous variables standard gaussian prior structured code contain continuous discrete variables encode different attributes appropriate prior given observation base includes conditional probabilistic encoder infer latents denote parameters generator encoder respectively. optimized minimize reconstruction error observed real sentences time regularize encoder close prior here notational simplicity assume structured variable thus discriminator though model speciﬁcation straightforwardly applied many attributes. distribution factors learning disentangled representations. note discriminator code learned loss instead optimized objectives described shortly. besides reconstruction loss drives generator produce realistic sentences discriminator provides extra learning signals enforce generator produce coherent attribute matches structured code however impossible propagate gradients discriminator discrete samples resort deterministic continuous approximation. approximation replaces sampled token step probability vector differentiable w.r.t generator’s parameters. probability vector used output current step input next step along sequence decision making. temperature training proceeds yielding increasingly peaked distributions ﬁnally emulate discrete case. simple deterministic approximation effectively leads reduced variance fast convergence training enables efﬁcient learning conditional generator. diversity generation results guaranteed since approximation attribute modeling base sentence generation learned vaes. objective structured attribute generated sentences controlled corresponding code independent variables latent representation. however still possible attributes explicitly modeled also entangle code thus varying dimension yield unexpected variation attributes interested address this introduce independency constraint separates attributes enforcing fully captured unstructured part therefore besides attributes explicitly encoded also train generator non-explicit attributes correctly recognized generated samples match unstructured code instead building discriminator reuse variational encoder serves precisely infer latents base vae. loss form except replacing discriminator conditional encoder conditional discriminator learning discriminator trained accurately infer sentence attribute evaluate error recovering desired feature speciﬁed latent code. instance categorical attribute discriminator formulated sentence classiﬁer; continuous target probabilistic regressor used. discriminator learned different compared encoder since target attributes discrete supported framework. moreover contrast unstructured code learned unsupervised manner structured variable uses labeled examples entail designated semantics. derive efﬁcient semisupervised learning method discriminator. besides conditional generator also capable synthesizing sentence-attribute pairs used augment training data semi-supervised learning. alleviate issue noisy data ensure robustness model optimization incorporate minimum entropy regularization term resulting objective thus −epgpp ˆx)) empirical shannon entropy distribution evaluated generated sentence balancing parameter. intuitively minimum entropy regularization encourages model high conﬁdence predicting labels. figure left wake procedure corresponding eq.. right sleep procedure corresponding eqs. black arrows denote inference generation; dashed arrows denote gradient propagation. steps sleep procedure i.e. optimizing discriminator generator respectively performed alternating manner. summarization discussion derived model learning procedure. generator ﬁrst initialized training base large corpus unlabeled sentences objective minimizing latent code time sampled prior distribution full model trained alternating optimization generator discriminator summarized algorithm model viewed combining framework extended wake-sleep method illustrated figure speciﬁcally samples produced generator used targets maximum likelihood training discriminator. resembles sleep phase wake-sleep. eqs.- leverage generated samples improve generator. together extended sleep procedure based dream samples obtained ancestral sampling generative network. hand samples discriminator distribution observation form target training generator corresponds wake phase. effective combination enables discrete latent code holistic discriminator metrics efﬁcient mutual bootstrapping. training discriminators need supervised data impose designated semantics. discriminators different attributes trained independently separate labeled sets. model require sentence annotated attributes instead needs independent labeled data individual attribute. moreover labeled data used learning attribute semantics instead direct sentence generation allowed extend data scope beyond labeled sentences e.g. labeled words phrases. shown experiments method able effectively lift word level knowledge sentence level generate convincing sentences. finally augmented unsupervised training sleep phrase show little supervision sufﬁcient learning structured representations. experiments apply model generate short sentences controlled sentiment tense. quantitative experiments using trained classiﬁers evaluators show model gives improved generation accuracy. disentangled representation learned labels word annotations. also validate effect proposed independency constraint interpretable generation. datasets sentence corpus. large imdb text corpus training generative models. collection movie reviews. select sentences containing words replace infrequent words token <unk>. resulting dataset contains around sentences vocabulary size sentiment. control sentiment generated sentences test following labeled sentiment data stanford sentiment treebank- consists movie review sentences binary sentiment annotations train/dev/test sets respectively. training examples sentence length evaluate classiﬁcation accuracy original test set. sstsmall. study size labeled data required semi-supervised learning accurate attribute control sample small subset sst-full containing labeled sentences training. lexicon. also investigate effectiveness model terms using word-level labels sentence-level control. lexicon contains words sentiment labels. lexicon training treating words sentences evaluate sst-full test set. imdb. collect dataset imdb corpus randomly selecting positive negative movie reviews. dataset k/k/k sentences train/dev/test. tense. second attribute tense main verb sentence. though corpus sentence tense annotations readily available method able learn labeled words generate desired sentences. compile timebank dataset obtain lexicon words phrases labeled {past present future}. lexicon mainly consists verbs different tenses well time expressions parameter setting generator encoder single-layer lstm rnns input/hidden dimension sample length discriminators convnets. detailed conﬁgurations supplements. avoid vanishingly small term module term weight linearly annealing training. balancing parameters selected sets. test time sentences generated eq.. quantitatively measure sentence attribute control evaluating accuracy generating designated sentiment effect using samples training classiﬁers. compare semi-supervised existing deep models capable conditional text generation. s-vae learns reconstruct observed sentences given attribute code discriminators used. discussions. state-of-the-art sentiment classiﬁer achieves accuracy test automatically evaluate sentiment generation accuracy. speciﬁcally generate sentences given sentiment code pre-trained sentiment classiﬁer assign sentiment labels generated sentences. accuracy calculated percentage predictions match sentiment code table shows results sentences models trained sstfull sst-small lexicon respectively. method consistently outperforms s-vae datasets. particular trained labeled examples sstsmall model achieves reasonable generation accuracy demonstrating ability learning disentangled repretable compares samples generated models without constraint term respectively. left column constraint applies pair sentences conditioned different sentiment codes highly relevant terms e.g. subject tone wording explicitly modeled structured code instead implicitly encoded unstructured code varying sentiment code precisely changes sentiment sentences keeping aspects unchanged. contrast results right column independency constraint unactivated show varying sentiment code changes polarity samples also change aspects unexpected control making generation results less interpretable predictable. demonstrate power learned disentangled representation varying attribute variable time. table shows generation results. attribute variable model successfully controls corresponding attribute disentangled attribute code. right column table shows meaningful variation sentence tense tense code varies. note semantic tense learned lexicon without complete sentence examples. model successfully captures ingredients combines knowledge well-formed sentences generate realistic samples speciﬁed tense attributes. table shows generated sentences varying code different settings structured attribute factors. obtain samples diverse content consistent sentiment tense. also occasionally observed failure cases table implausible sentences unexpected variations irrelevant attributes inaccurate attribute generations. improved modeling expected using dilated convolutions decoder decoding beam search etc. better systematic quantitative evaluations also desired. proposed deep generative model learns interpretable latent representations generates sentences speciﬁed attributes. obtained meaningful generation restricted sentence length improved accuracy sentiment tense attributes. future would like improve modeling training above extend generate longer sentences/paragraphs control attributes ﬁne-grained structures. approach combines vaes attribute discriminators imposes explicit independency constraints attribute controls enabling disentangled latent code. semi-supervised learning within joint vae/wake-sleep figure test-set accuracy classiﬁers trained four sentiment datasets augmented different methods ﬁrst three datasets sst-full test evaluation. sentations little supervision. importantly given word-level annotations lexicon model successfully transfers knowledge sentence level generates desired sentiments reasonably well. compared method drives learning directly assessing generated sentences s-vae attempts capture sentiment semantics reconstructing labeled words less efﬁcient gives inferior performance. next generated samples augment sentiment datasets train sentiment classiﬁers. aiming build best-performing classiﬁers datasets classiﬁcation accuracy serves auxiliary measure sentence generation quality. higherquality sentences accurate sentiment attribute predictably help yield stronger sentiment classiﬁers. figure shows accuracy classiﬁers trained four datasets different augmentations. convnet trained standard original datasets network structure sentiment discriminator model. h-reg additionally imposes minimum entropy regularization generated sentences. ours incorporates minimum entropy regularization sentiment attribute code generated sentences eq.. s-vae uses protocol method augment data generated s-vae model. comparison figure shows method consistently gives best performance four datasets. instance lexicon approach achieves accuracy compared std. improvement h-reg shows positive effect minimum entropy regularization generated sentences. incorporating conditioned sentiment code generated samples ours s-vae provides additional performance gains indicating advantages conditional generation automatic creation labeled data. consistent experiment model outperforms s-vae. table samples models without independency constraint attribute control pair sentences generated sentiment code negative positive respectively ﬁxing unstructured code sst-full dataset used learning sentiment representation. framework effective little incomplete supervision. develop uniﬁed view diverse deep generative paradigms including gans vaes wake-sleep algorithm. model alternatively motivated view enhancing vaes extended sleep phase leveraging generated samples. interpretability latent representations allows dynamic control generated attributes also provides interface connects end-to-end neural model conventional structured methods. instance encode structured constraints interpretable latent code incorporate prior knowledge human intentions plug disentangled generation model dialog systems generate natural language responses structured dialog states though focused generation capacity model proposed collaborative semi-supervised learning framework also helps improve discriminators generating labeled samples data augmentation generally discriminative task build conditional generative model synthesize additional labeled data. accurate attribute generation approach offer larger performance gains compared previous generative methods. acknowledgments research supported chen duan houthooft rein schulman john infogan intersutskever ilya abbeel pieter. pretable representation learning information maxadvances imizing generative adversarial nets. neural information processing systems diao qiming minghui chao-yuan smola alexander jiang jing wang chong. jointly modeling aspects ratings sentiments movie recommendation proceedings sigkdd international conference knowledge discovery data mining goodfellow pouget-abadie jean mirza mehdi bing warde-farley david ozair sherjil courville aaron bengio yoshua. generative adversarial nets. advances neural information processing systems kingma diederik mohamed shakir rezende danilo jimenez welling max. semi-supervised advances learning deep generative models. neural information processing systems radford alec metz luke chintala soumith. unsupervised representation learning deep convolutional generative adversarial networks. arxiv preprint arxiv. yang zichao zhiting salakhutdinov ruslan berg-kirkpatrick taylor. improved variational autoencoders text modeling using dilated convolutions. icml jun-yan kr¨ahenb¨uhl philipp shechtman efros alexei generative visual manipulation european conference natural image manifold. computer vision springer reed scott honglak anguelov dragomir szegedy christian erhan dumitru rabinovich andrew. training deep neural networks noisy labels bootstrapping. arxiv preprint arxiv. siddharth paige brooks desmaison alban meent jan-willem wood frank goodman noah kohli pushmeet torr philip h.s. learning disentangled representations deep generative models. socher richard perelygin alex jean chuang jason manning christopher andrew potts christopher recursive deep models semantic compositionality sentiment treebank. proceedings conference empirical methods natural language processing volume citeseer vinyals oriol toshev alexander bengio samy erhan dumitru. show tell neural image caption proceedings ieee conference generator. computer vision pattern recognition tsung-hsien gasic milica mrksic nikola peihao vandyke david young steve. semantically conditioned lstm-based natural language generation spoken dialogue systems. emnlp wilson theresa wiebe janyce hoffmann paul. recognizing contextual polarity phrase-level sentiment proceedings conference human analysis. language technology empirical methods natural language processing association computational linguistics", "year": 2017}