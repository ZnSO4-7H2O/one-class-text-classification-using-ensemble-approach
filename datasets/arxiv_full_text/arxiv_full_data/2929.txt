{"title": "Multi-Label Zero-Shot Human Action Recognition via Joint Latent  Embedding", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Human action recognition refers to automatic recognizing human actions from a video clip, which is one of the most challenging tasks in computer vision. In reality, a video stream is often weakly-annotated with a set of relevant human action labels at a global level rather than assigning each label to a specific video episode corresponding to a single action, which leads to a multi-label learning problem. Furthermore, there are a great number of meaningful human actions in reality but it would be extremely difficult, if not impossible, to collect/annotate video clips regarding all of various human actions, which leads to a zero-shot learning scenario. To the best of our knowledge, there is no work that has addressed all the above issues together in human action recognition. In this paper, we formulate a real-world human action recognition task as a multi-label zero-shot learning problem and propose a framework to tackle this problem. Our framework simultaneously tackles the issue of unknown temporal boundaries between different actions for multi-label learning and exploits the side information regarding the semantic relationship between different human actions for zero-shot learning. As a result, our framework leads to a joint latent embedding representation for multi-label zero-shot human action recognition. The joint latent embedding is learned with two component models by exploring temporal coherence underlying video data and the intrinsic relationship between visual and semantic domain. We evaluate our framework with different settings, including a novel data split scheme designed especially for evaluating multi-label zero-shot learning, on two weakly annotated multi-label human action datasets: Breakfast and Charades. The experimental results demonstrate the effectiveness of our framework in multi-label zero-shot human action recognition.", "text": "shot human action recognition. joint latent embedding learned component models exploring temporal coherence underlying video data intrinsic relationship visual semantic domain. evaluate framework different settings including novel data split scheme designed especially evaluating multi-label zero-shot learning weakly annotated multi-label human action datasets breakfast charades. experimental results demonstrate effectiveness framework multi-label zero-shot human action recognition. keywords human action recognition multi-label learning zero-shot learning joint latent embedding weakly supervised learning challenging tasks computer vision human action recognition refers automatic recognizing human actions conveyed video clip. last decades human action recognition extensively studied. many different human actions reality task generally formulated multi-class classiﬁcation problem. train multi-class classiﬁer human action recognition great number examples single action required current setting. collect training examples needs manually trim video steam ensure human action appearing trimmed video episode. annotation process laborious time-consuming hence largescale dataset ﬁne-grained annotation human action recognition. contrast imagenet object recognition consists total million cleanly labelled images spread categories much fewer annotated video clips involving small number human actions. instance hmdb abstract human action recognition refers automatic recognizing human actions video clip challenging tasks computer vision. fact annotating video data laborious timeconsuming existing works human action recognition limited number small scale benchmark datasets small number video clips associated human actions video clip often contains single action. reality however often exist multiple human actions video stream. video stream often weakly-annotated relevant human action labels global level rather assigning label speciﬁc video episode corresponding single action leads multi-label learning problem. furthermore great number meaningful human actions reality would extremely difﬁcult impossible collect/annotate video clips regarding various human actions leads zero-shot learning scenario. best knowledge work addressed issues together human action recognition. paper formulate real-world human action recognition task multi-label zero-shot learning problem propose framework tackle problem. framework simultaneously tackles issue unknown temporal boundaries different actions multilabel learning exploits side information regarding semantic relationship different human actions zero-shot learning. result framework leads joint latent embedding representation multi-label zeroucf among commonly used benchmark datasets human action recognition instances different human actions respectively. limitation human action datasets scale become obstacle developing large-scale human action recognition system. real scenario video clip often conveys multiple human actions corresponding different concepts. hence multiple action labels used characterize complete semantics underlying human actions conveyed video clip. example video clips youtube usually uploaded users along descriptive terms used infer human actions conveyed video clips descriptive terms viewed coherent labels collectively characterize semantics global level. recently large multi-label video dataset youtube-m collected google research. although dataset restricted human action video clips paves various video analyses including human action recognition. essential video analysis problems data formulated multi-label learning predicts labels associated given instance conﬁdence scores corresponding candidate labels related instance. multi-label learning training example often consists input instance labels associated instance global level multi-label data common many domains multi-label classiﬁcation studied different applications e.g. semantic image tagging text categorization gene functionality prediction works focusing multi-label human action recognition found literature lack human action datasets annotated multiple class labels. dataset dubbed charades collected especially multi-label human action recognition made publicly available recently. addition datasets also considered used multi-label human action recognition although originally collected different tasks. thus data sets provide proper test multi-label human action recognition studies. multi-label human action recognition works weakly labelled video data i.e. training data annotated video level without exhaustively trimming annotating multiple action episodes. easier collect video clips associated labels global level ﬁne-grained annotation would still challenging collect training examples existence many different human actions. zero-shot learning provides alternative solution alleviate problem. aims recognize instances belonging novel classes seen training. formally shown system trained dataset ﬁnite classes could used predict inﬁnite number classes unseen learning under framework merely need collect annotate training examples moderate training classes expect large number novel classes recognized exploiting semantic relationship different human actions. algorithm needs transfer knowledge regarding relations visual features class label semantics learned known training classes unseen test classes. knowledge transfer enabled modelling semantic representations different classes easily obtained side information e.g. descriptive texts much less effort. nevertheless existing methods proposed tackle single-label problems. although methods extended multi-label scenarios effectiveness different algorithms extensively investigated multi-label learning scenarios. best knowledge exists work multi-label zero-shot human action recognition. paper address multi-label issue context human action recognition. training video data weakly annotated exact temporal-spatial locations multiple human actions video clip unknown. addition training examples available training/known labels subset action label collection considered recognition stage. address multilabel problem human action recognition propose novel joint latent embedding framework. framework aims learn joint latent space visual semantic representations. learned joint space visual semantic representations human actions mapped visual semantic embedding respectively. then visual semantic domains related joint embedding space human actions considered action label collection recognized regardless known unseen classes learning. framework visual model learns mapping visual representations video clip latent visual embedding semantic model learns mapping semantic representations human action labels latent semantic embedding joint embedding space. visual model long short-term memory network employed explore saliency multiple human actions conveyed weakly annotated multi-label video data plays role implicitly ﬁnding speciﬁc episode containing multiple human actions conveyed video clip. semantic model three-layer fully-connected neural network employed learn latent semantic embedding semantic visual semantic space bridged semantic relations different labels considered action collection well explored modeled properly. learning visual semantic models trained proposed alternate learning algorithm. recognition trained visual semantic models used together recognize test video clip measuring distance visual embedding semantic embedding labels. considering real scenarios formulate generic human action recognition multi-label zero-shot learning problem. best knowledge work presented paper ﬁrst attempt study human action recognition multi-label zero-shot perspective. address multi-label zero-shot issue arising weakly annotated data human action recognition propose novel joint latent embedding framework consisting visual semantic embedding models. train embedding models effectively come learning algorithm alternately optimizes parameters embedding models learning. test performance proposed framework conduct thorough evaluation comparative study benchmark multi-label human action datasets breakfast charades various evaluation metrics different settings including novel data split protocol simulating real scenario zero-shot human action recognition. rest paper organized follows. section reviews related works. section presents framework multi-label zero-shot human action recognition. section describes experimental settings section reports experimental results. last section draws conclusions. section review existing works relating multi-label human action recognition especially applicable multi-label zero-shot learning scenarios. also address limitations existing works make connection work related works. result ﬁrst overview existing multi-label classiﬁcation methods focus existing works multi-label learning despite fact none multi-label methods applied human action recognition. world e.g. videos. human action video clip multiple actions could happen simultaneously e.g. sitting eating listening. scenario episode video clip characterized single action label labels hence collectively used describe video clip. even though video clip divided several episodes corresponding different human actions segmentation annotation process could difﬁcult tedious laborious time-consuming. particular semantic image segmentation human action detection video streams remain unsolved. result multi-label learning often formulated weakly supervised learning task predicts labels associated instance address issue assigning labels speciﬁc object within instance. tackle weakly supervised multi-label learning problem different representation methods used characterize input data instance-level object-level representation. instance-level representation holistic representation instance without considering objects containing instance object-level representation objectbased representation extracts potential objects instances form bag-of-object representations. depending representation input data multi-label learning methods divided categories. multi-label learning existing methods work instance-based representation single feature vector holistically representing multiple objects within instance. recently fasttag proposed multi-label image tagging learning mapping visual space label space. image containing multiple objects represented aggregated visual representation. alternatively tagprop uses adapted nearest neighbour model multi-label learning visual space image multiple objects also represented feature vector. wang convolutional neural network directly working images multiple objects learn image-level deep visual representations multi-label classiﬁcation. deep neural network ranking loss learning largescale multi-label text classiﬁcation input document represented feature vector. although representing instance single feature vector straightforward convenient might neglect intrinsic relationship between multiple objects within instance. thus holistic instance-level representation might result catastrophic information loss especially long-term dependent complex video data. multi-label learning methods. although difﬁcult segmentation multiple objects within instance turns beneﬁcial multi-label learning. framework named multi-instance multi-label learning demonstrates multi-label learning fulﬁlled effectively multiple objects within instance explicitly separated segmented even label explicitly assigned multiple objects within instance learning. real applications however automatic semantic segmentation objects instance also challenging manual segmentation process laborious time-consuming. recently efforts made explore object-based representations without using explicit semantic object segmentation techniques seeks synergy miml object-level representations. address weakly supervised issue multi-label human action detection two-stage solution. first potential objects spatial-temporal volumes generated selected video instance handcrafted rules. problem transformed miml problem solved traditional multi-label learning algorithms miml framework. similar idea also explored tang multi-label image classiﬁcation. however extraction true positive objects original example challenging non-trivial task critically determines multi-label learning performance. extract meaningful objects within instance candidate proposals considered might suffer high computational burden. instead using miml cabral attempt explore information regarding multiple objects instances matrix completion method. method works assumption instance represented linear combination object representations instance. experimental results reported cabral demonstrate effectiveness method objectlevel bag-of-words image representation. however remains unknown whether method also applicable kinds representations popular powerful deep representations. zero-shot learning attracted much attention recent years provides promising technique recognizing large number classes without need training data concerning classes. recently zhang formally shown feasible predict collection inﬁnite unseen labels classiﬁer learned training data concerning number labels collection subset collection multi-label special case so-called inﬁnite-label learning paradigm. according taxonomy existing approaches divided three categories namely direct mapping model parameter transfer joint space learning although existing works focus single-label efforts made extend multi-label learning scenarios direct mapping needs learn direct mapping visual semantic space zero-shot recognition poses challenge multi-label zsl. single-label training example provides visual-semantic representation pair used learn one-to-one direct mapping. multi-label however instance associated multiple labels number labels associated different instances various. label represented semantic feature vector e.g. vector attributes word vector semantic space longer straightforward learn direct mapping visual semantic space context multi-label zsl. model complex semantics underlying labels associated instance becomes central issue multi-label zsl. tackle issue existing works make composition properties semantic representations word vectors using average semantic representations multiple labels collective semantic representation labels associated instance. thus training example formed pair instancelevel visual representation corresponding collective semantic representation enables learning direct mapping multi-label zsl. apparently collective representation cannot avoid information loss even though contextualized semantic representation used. alleviate information loss problem generating collective semantic representation fasttag introduces alternative solution collective semantic representations. method visual instance mapped principal direction semantic space based assumption always direction multi-labelled instance semantic space e.g. word vector space labels relevant instance always higher ranking values irrelevant labels. words always hyperplane separate relevant labels irrelevant ones multi-labelled instance. assumption holds datasets demonstrated zeroshot image tagging work remains unclear datasets different domain e.g. human action recognition especially existence various semantic representations lead different semantic spaces. different perspective suggest using object-level visual presentation direct mapping framework multi-label zero-shot object recognition. multi-label learning takes place image thus semantically segmented meaningful subregions subregion characterized label. result solution actually special case miml hence rely sophisticated semantic segmentation techniques remain unavailable date. like works extending direct mapping multilabel model parameter transfer idea also taken account multi-label zsl. costa aims estimate model unseen label linear weighted combination known-label models e.g. support vector machines combination coefﬁcients determined label co-occurrences derived either annotations datasets hand external sources. costa models regarding known labels trained independently means one-vs-rest binary classiﬁer without considering relation coherence among labels assigned single object. furthermore costa uses label co-occurrences model relatedness pair labels neglects semantic individual label itself. among three kinds algorithms joint space learning methods often yield promising results single-label zsl. apart used joint space learning methodology also applied traditional multi-label learning tasks favorable results. main idea underlying joint space learning learning joint latent representation space visual semantic space bridge semantic gap. best knowledge however extension existing joint space learning methods multi-label problems great extent difﬁculty modelling complex semantics underlying labels describing instance elucidated regarding direct-mapping. paper hence propose novel approach multi-label zero-shot human action recognition joint space learning framework addressing critical issues. attributes labels semantic representation label characterized list attributes common labels label embedding refers class approaches embedding labels onto semantic space semantic relatedness labels reﬂected label embedding often carried learning external textural resources. example famous wordvec semantic embedding obtained training skip-gram neural network large-scale corpora e.g. google news dataset semantic representations widely used e.g. unlike label embedding obtained external resources co-occurrence labels approach capturing relatedness different labels information co-occurrence labels hierarchical relationship labels given dataset used e.g. alternatively co-occurrence information different class labels also extracted external resources particular cooccurrence labels allows capturing relatedness between labels jointly used describe instance. label co-occurrence information incorporated learning semantic embedding given dataset e.g. concept embedding semantic meaning label assumed polysemous depending different labels jointly used describe instance. hence semantic meaning label speciﬁc context frames concept. result concept embedding viewed contextualized label embedding label multiple semantic representations embedding space used different labels describing different instances. concept embedding leads speciﬁc approach multi-label however contextualized semantic representation learning suffers high computational burden difﬁcult deal large-scale label collection. proposed framework multi-label zero-shot human action action generic semantic representations apart concept embedding used directly proposed framework. regardless different scenarios modelling semantics underlying collection labels relatedness plays critical role knowledge transfer required zsl. miscellaneous methods semantics modelling represensection present novel framework multi-label zero-shot human action recognition. first overview proposed framework along motivation. make self-contained describe lstm unit important mechanism used framework implicit saliency detection video data. next present method joint fig. multi-label zero-shot human action recognition framework. framework shown left composed component models visual semantic model highlighted grey colors. joint latent embedding learning trained visual semantic models work together multi-label zero-shot recognition shown right box. action labels marked brown color training classes known labels learning action labels marked blue colour test classes unseen labels learning. latent embedding learning including loss functions used learning learning algorithm especially designed proposed architecture. finally specify procedure multi-label zero-shot human action recognition based trained joint latent embedding model. proposed framework aims multi-label zero-shot human action recognition. formulate problem learning mapping r|c| visual input e.g. segment-level visual feature vectors extracted video clip r|c| list label-relatedness scores respect action label collection {··· |c|} divided mutually exclusive label subsets corresponding known unseen actions; i.e. ctr∪cu ctr∩cu learning mapping training examples labels available. however learned mapping used predict actions including unseen actions deﬁned video clip. wang chen zhang zhang saligrama would tackle knowledge transfer issue joint latent space visual semantic representation embedding resides. embedding visual semantic representations latent space expect semantic narrowed considerably semantic relatedness known unseen labels effectively explored exploited zero-shot recognition. thus framework consists component models visual semantic models used learn visual semantic embedding well joint latent embedding knowledge transfer illustrated left figure visual embedding encounter major technical issues nature weakly annotated data visual input remains unknown episode conveying action remains unclear action labels describing video clip associated speciﬁc video episode. nevertheless video clip ordered sequence frames could explore temporal coherence underlying video clip tackle aforementioned technical issues. motivated recent works video classiﬁcation activity recognition employ long short-term memory recurrent neural network layer capture temporal coherence underlying action episode. thus lstm layer ﬁrst used process sequence visual representations extracted video segments. memorising forgetting mechanism lstm units expect lstm layer explores temporal structure human actions conveyed video sequence; lstm units would memorize input segments parsing episode regarding human action completed forget previous input segments episode conveying another action starts. thus implicit saliency detection carried action episode boundaries explicitly speciﬁed visual embedding employ fully-connected layers dense visual embedding layers figure capture salient features temporal coherence representation yielded lstm layer. speciﬁc visual model used experiments capacity increased adding hidden layers necessary. score averaging pool layers visual embedding layer used joint latent embedding learning presented section thus visual model deep network heterogeneous layers. semantic embedding employ three-layer fullyconnected neural network carry semantic model. expect learning model capable capturing intricate semantic relatedness different actions label collection moderate size e.g. datasets experiments. general capacity increased adding hidden layers necessary. result neural network speciﬁc semantic representation action labels e.g. word vectors subsequently semantic embedding layer hidden layer shown figure likewise score averaging pool layers semantic embedding layer used joint latent embedding learning. explore semantic relatedness different labels bridging semantic visual semantic space semantic embedding learning needs exploit information carried training data e.g. frequency label co-occurrence training dataset joint latent embedding learning visual semantic models coupled form joint latent embedding space. learning propose learning algorithm working alternately models parameter estimation promoting positive video-label pairs negative ones. thus visual model learns visual embedding video example corresponding relevant labels rank ahead irrelevant ones terms relatedness scores estimated semantic latent space alternately semantic model learns semantic embedding action labels relevant videos rank higher irrelevant ones terms relatedness scores calculated visual latent space learning completed trained joint latent embedding model applied test video clip human action recognition. result relatedness scores corresponding known unseen action labels label collection achieved using visual semantic models illustrated right figure described previously lstm layer plays crucial rule tackling technical issues arising weakly annotated data visual embedding proposed framework. here brieﬂy review mechanism lstm unit facilitate understanding framework. shown figure lstm unit consists memory cell reserving historic information previous time steps. output time step determined current input activation value memory cell. three gates inputoutput forgetting gates used control information lstm unit. information lstm unit formulated follows tanh sigmoid tangent hyperbolic functions refer input forget output gates respectively. cell state representing information stored cell output lstm unit input receiving output another lstm general description given training annotated video clips {xxxiyyyi}|d| xxxi visual input yyyi {}|ctr| binary target label vector i-th example element indicates presence/absence speciﬁc action belonging xxxi. video instance xxxi divide evenly segments segment-level visual representations extracted collectively denoted {xxxixxxi··· xxxit}. t-th time step segment representation xxxit hidden lstm layer processed lstm layer subsequent fully-connected layers linear activation functions latent visual embedding t-th segment eeev here visual embedding function implemented parametric visual model collective notation parameters model including weights biases involved deep network. likewise depicted figure c-th label label collection ﬁrst represented speciﬁc semantic representation sssc semantic embedding function implemented parametric semantic model parameters denoted collectively. thus semantic embedding eees score layer employed visual semantic models. visual model score layer takes outputs visual embedding layer time steps yield relatedness scores regarding labels xixixi product visual embedding segment xixixi semantic embedding labels label collection eeev eees rde×|ctr| collective notation semantic embedding labels. here <aaabbb>= aaatbbb vectorial notation product vector column matrix bbb. relatedness scores video instance different labels achieved averaging scores segments video instance description training test datasets cardinality norm vector label collection training unseen class label subsets visual semantic embedding space visual representation t-th segment i-th example collection segment-level visual representations i-th example semantic representation c-th label binary target label matrix training dataset binary target label i-th example i.e. i-th column matrix binary indicator vector c-th label appearing examples i.e. c-th matrix visual embedding matrix column vector video clip semantic embedding matrix column vector c-th label dimensions visual semantic space relatedness scores i-th example candidate labels visual model relatedness scores c-th label training examples semantic model visual embedding function parameters semantic embedding function parameters shot recognition ground-truth label test instance ˆxxx ranking list labels predicted ˆxxx terms relatedness scores test instances ground-truth label sets include c-th label ranking list test instances terms relatedness scores c-th label lstm units used hidden layer done framework dimension hidden vector determined number lstm units used hidden layer. hence hyper-parameter tuned given dataset. dimensions weight matrices thus determined dimensions output vector input gates cell state dimension relatedness scores c-th label training examples oooc calculated eqs. based quantities deﬁne ranking-based loss functions loss exerted instance positive labels rank ahead negative ones according relatedness scores. otherwise violation expected ranking incurs loss. normalizes perinstance ranknet loss speciﬁed ranking loss incurred speciﬁc labels yiqoiq. intuitively loss function deﬁned eqs. used ensure ranking relevant labels ahead irrelevant ones learning relatedness scores irrelevant labels decreased radically relatedness scores relevant labels increased considerably intuitively loss function deﬁned eqs. able ensure video instances conveying action c-th label ranked without action similarly video instances without action tend small relatedness scores video instances action tend large relatedness scores understand motivation behind loss functions formulated eqs. would make following remarks. loss functions nature crossentropy ranking-based losses. hand crossentropy loss tends enlarge marching scores relevant labels diminish irrelevant labels simultaneously training examples learning. estimated manner used visual model based visual embedding video instances semantic embedding c-th label. thus i-th element oooc relatedness score regarding i-th visual instance joint latent embedding learning need optimize parameters visual semantic models training data proper loss functions assume loss functions respect visual semantic model joint latent embedding learning boiled solving following optimization problems here binary indicator vector yyyc i×|d| vector target label matrix i|ctr|×|d| training dataset non-zero elements yyyc indicate c-th label appears target label sets corresponding training examples binary indicator vector yyyi i|ctr|× column vector non-zero elements yyyi refers labels target label associated i-th training example described section multi-label zero-shot learning needs establish mapping outputs label-relatedness score list video input scores relevant labels higher irrelevant ones. motivated previous works develop regularized ranking-based loss functions joint latent embedding learning. target label expressed binary indicators i-th training example non-zero elements indicate relevant labels zero elements expresses irrelevant labels xxxi. converting binary indicator representation easily non-zero elements yyyi −yyyi express relevant irrelevant labels respectively vector elements dimension yyyi. likewise binary indicator regarding whether c-th action appears training examples handled manner. thus relatedness scores xxxi positive negative labels oooi achieved eqs. labels considered independently treated equally less frequently used relevant labels might overlooked learning. hand rankingbased loss generally makes pairwise constraints exploring relationship labels associated instance explicitly. however relatedness scores ranking-based loss bounded could hence vary across different examples. thus difﬁcult pairs labels likely incur larger cost predominates overloss could make learning biased pairs labels only. furthermore relatedness scores vary large range different examples training even though proper ranking relationships among established. circumstance performance appears poor terms label-centric evaluation metric described section thus tackle issues loss functions seek synergy crossentropy ranking-based losses. loss functions losses incurred irrelevant labels predominate beginning learning much irrelevant labels relevant ones training example. however minimizing term allows lowering relatedness scores irrelevant labels considerably loss functions gradually guide learning generate proper relatedness scores relevant labels ranking-based loss. thus proposed loss functions actually work ranking-based constraints regularization properly conﬁning magnitude relatedness scores relevant irrelevant labels. thus loss functions signiﬁcantly distinguish ranking-based loss without regularization used fasttag hence expect regularized ranking-based losses would lead better generalization veriﬁed experiments. formulated eqs. learning going optimal parameters minimizing loss functions deﬁned eqs. however relatedness scores required regarding visual model involve output semantic model vice versa moreover requires relatedness scores candidate labels training examples needs relatedness scores training examples action labels ctr. thus optimization problems complex unsolvable simultaneously commonly used local search methods e.g. gradientdescent based methods. visual semantic models respectively; extract visual representations training example xxxi semantic representations training labels sssc ctr; input target label matrix training pre-set dimensionality joint latent embedding space visual semantic models alternately learning. alternate learning strategy learning algorithm begins randomly initializing parameters semantic model initialized parameter generate initial semantic embedding. using initial semantic embedding visual model trained local search method mini-batch stochastic gradient decent method. epoch current parameters visual model frozen used generate visual embedding examples. manner using current visual embedding semantic model trained manner. alternate learning process carries stopping condition satisﬁed. details alternate learning algorithm described algorithm worth stating loss functions deﬁned visual semantic model related optimisation model would naturally promote towards optimal solution. hence alternative learning algorithms converge running ﬁnite epochs properties held similar methods joint latent embedding learning completed visual seφφφ test video clip labels ˆeees divide segments extract segment-level representations collectively denoted ˆxxx {ˆxxx ˆxxx ˆxxxt}. feeding ˆxxx visual embedding function achieve visual embedding ˆeeev thus relatedness scores test video clip actions considered label collection including known unseen labels learning achieved section describe experimental design settings including datasets visual semantic representations model learning evaluation scenarios criteria used experiments. moreover design number comparative experiments exhibit gain resulting different components framework demonstrate effectiveness framework comparison several state-of-the-art multi-label methods could applied human action recognition. evaluate framework employ publicly available video datasets breakfast charades experiments. datasets least actions involved video clip duration video clip relatively long implies temporal coherence information explored exploited human action recognition. hence datasets suitable evaluate multi-label human action recognition. below summarize main aspects video datasets. breakfast dataset video clips totally video clip conveys several cooking actions. totally cooking actions ‘stirring pouring milk opening fridge. actions performed people different kitchens. although dataset collected especially multi-label human action recognition would proof-of-concept test bed. charades dataset collected hundreds people recording videos home especially video-based human activity analysis daily lives. hence challenging multi-label human action recognition. dataset video clips involving different human actions totally acting casual everyday activities. average duration video clips around seconds average number actions involved video clip actions performed people three continents person appear video clips. video data used experiments available charades project page. simulate zero-shot scenario need split dataset training test sets training contains examples associated known classes test test instances involving least unseen class. unlike single-label dataset automatically split training test sets unseen classes speciﬁed dataset split issue multi-label becomes much complicated. experiments make different split settings named instance-ﬁrst label-ﬁrst split respectively illustrated figure instance-first split commonly used data split setting nearly existing multi-label works e.g. setting instances dataset ﬁrst split training validation test subsets. training validation subsets used parameter estimation hyper-parameter tuning dimension latent embedding space number iterations algorithm model. test involve unseen labels reserved performance evaluation. then divide action label collection mutually exclusive known unseen label sets. learning unseen labels target label instance training validation subsets removed shown left plot figure words known labels target label sets instance datasets used learning. worth clarifying label-first split although instance-ﬁrst data split setting widely used multi-label suffers fundamental limitation. well known multiple labels together could frame speciﬁc concept removing label label cohort lead less accurate semantic meaning biases learning. furthermore instance-ﬁrst split allows accessing visual features instances involved unseen actions. overcome limitation propose novel data split setting multi-label named labelﬁrst split. setting labels label collection used dataset ﬁrst divided mutually exclusive subsets known unseen labels. then instances unseen labels reserved test rest instances known labels divided subsets training validation. sparsity training data validation label-ﬁrst split also adopts protocol used multi-label learning split breakfast dataset setting randomly choose labels unseen labels rest labels designated known labels accordingly. hence dataset naturally split sets training test. training data divided training validation. validation randomly choose instances training data. likewise charades dataset split using randomly chosen label unseen labels. thus remaining labels become known labels. instances known labels randomly choose instance used validation. reliability repeat experiments dataset split setting three trials. trial training data given pre-split dataset randomly divided training validation subsets instance-ﬁrst split setting known/unseen label split dataset chosen randomly label-ﬁrst split setting. clarity summarize data split information datasets table fig. different data split settings used experiments. instance-ﬁrst split data simply split three mutually exclusive subsets training validation test subsets. unseen labels associated instances training validation subsets removed target label sets used learning. label-ﬁrst split number labels ﬁrst speciﬁed unseen labels. instances associated unseen labels form test subset. remaining data known labels divided training validation subsets used learning. unlike single-label often infeasible simulate scenario manipulating validation insufﬁcient data datasets used experiments. hence validation hyper-parameter tuning experiments follow typical protocol used multilabel learning split breakfast dataset setting adopt pre-split data collectors video clips people reserved test. divide rest video clips training validation video clips people training remaining video clips seven people validation. result numbers video clips training validation test respectively. randomly split labels known unseen labels labels reserved unseen labels rest known labels. charades dataset also adopt pre-split provided data collectors video clips used training test respectively. divide training data subsets training validation experiments. randomly choose suggested tran features extracted segment frames eight frames overlapping adjacent segments. thus video clip always divided segments following treatment simply sequence zeros short video clips down-sample long video clips ensure video clip divided segments. then feature vectors collectively form features video clip. comparative study also convert feature vectors holistic visual representation averaging feature vectors. holistic visual representation would demonstrate performance gain beneﬁting exploring/exploiting temporal coherence information underlying segments video clip. based crossvalidation experiment choose breakfast charades. although features used experiments worth mentioning kinds visual representations e.g. features deep image features extracted frame basis also used straightforwardly framework. experiments adopt wordvec semantic representation. wordvec trained skip-gram neural network google news dataset billion words result action label represented -dimensional word vector. although -dimensional word vectors used experiments word vectors different dimensionality used moreover semantic representations e.g. attributes used framework without difﬁculty available. experiments model learning implemented keras high-level neural networks library running either tensorflow theano. neural networks carry visual semantic models need decide speciﬁc network architectures relevant hyper-parameters datasets model learning. optimal hyperparameters found grid-based search crossvalidation procedure. adam stochastic optimisation method used training model default conﬁguration. lstm units. improve generalization also apply dropout procedure lstm layer dropout rate needs specifying. output lstm units fully connected dense layer neurons output dense layer visual embedding layer neurons. learning hyper-parameters involved score average pooling layer visual model. described section semantic model carried fully-connected three-layer feed-forward neural network. word vectors dimensions ﬁrst input hidden layer relu units subsequently output hidden layer semantic embedding layer linear units. note joint latent embedding learning dimension semantic embedding space visual embedding space experiments. likewise hyper-parameters involved score average pooling layer semantic model learning. multi-label zero-shot recognition complex given fact test instance associated label including known unseen class labels. thus different evaluation scenarios previous works focuses speciﬁc aspect. following settings evaluate framework along learning models used comparative study described later section three different scenarios known-action only setting performance evaluated regarding known actions. scenario boils conventional supervised multi-label learning. circumstance longer take unseen action labels account test; test instance relatedness score ranking list contains regarding known action labels unseen action label ground-truth label removed modiﬁed ground-truth includes known action labels ctr. unseen-action only setting performance evaluated regarding unseen actions. scenario boils standard setting. situation longer consider known action labels; test instance relatedness score ranking list contains regarding unseen action labels known action label ground-truth label removed modiﬁed ground-truth includes unseen action labels generalized setting performance evaluated regarding actions labels appearing label collection without considering action label i-map measures accuracy terms test instances l-map evaluate performance different perspective light candidate labels. given speciﬁc label model predicts relatedness scores action speciﬁed c-th label test instances hence achieve instancej= terms relatedness scores c-th label ∀ˆxxxip ˆxxxiq score score denote collection test instances ground-truth label sets indeed include c-th label. thus l-map test dataset deﬁned ˆxxxi otherwise. widely used evaluation metrics information retrieval also used evaluating multi-label learning systems e.g. experiments adopt overall top-k precision recall score measured test dataset deﬁned follows experiments conduct comparative study different perspectives baseline state-of-the-art models. result number baseline systems designed demonstrate roles played main components framework several state-of-the-art multi-label algorithms adapted human action recognition. comparative study evaluate different models three evaluation scenarios evaluation metrics described sections exactly conditions including visual semantic representations. known unseen learning. scenario named generalized machine learning community. situation known unseen action labels treated equally; test instance relatedness score ranking list contains regarding action labels evaluation made ground-truth label could mixture known unseen labels. worth highlighting generalized setting required multi-label zero-shot human action recognition real application. variety evaluation metrics multi-label learning. depending output multi-label learning system evaluation metrics generally divided types ranking-based bipartition-based metrics ranking-based metrics work situation learning system yields ranking list continuous-valued relatedness scores candidate labels. contrast bipartition-based metrics used learning system produces binary indicator vector candidate labels element expresses presence/absence. since model yields ranking list continuous-valued relatedness scores employ commonly used ranking-based metrics performance evaluation instance-centric mean average precision label-centric mean average precision addition employ metrics precision recall score also used performance evaluation multi-label learning ground-truth retrieved entities ranked terms relevance indii= learning model yields label-based ranking list test instance ˆxxxi terms relatedness scores ∀cpcq score score denote ground-truth label ˆxxxi. i-map test dataset deﬁned investigate roles played different component mechanisms employed framework design four baseline models random guess scores non-recurrent connection without semantic embedding randomized label representation manipulating framework different purposes described follows random guess scores general baseline provides lowest performance bound used reference improvement made learning model. work randomly generate relatedness scores candidate labels test instance. performance baseline model evaluated based random guess scores. reliability repeat process times experiments statistics performance including mean standard error mean reported. non-recurrent connection framework lstm layer recurrent connections employed capture temporal coherence underlying sequential video data visual embedding learning. examine role played lstm layer replace recurrent connected layer fully connected layer without recurrent connections keep components framework unchanged. setting model converted baseline model named non-recurrent connection. learning obviously baseline model longer explicitly makes temporal dependency information underlying sequential segments video clip. algorithm used directly parameter estimation. without semantic embedding framework semantic model semantic embedding motivation joint latent embedding space narrows semantic visual semantic domains zero-shot recognition done joint latent embedding space. however existing works e.g. fasttag learn semantic embedding zero-shot recognition takes place directly semantic space. examine effectiveness semantic embedding come baseline model named without semantic embedding removing semantic model framework. thus original semantic representations used replace semantic embedding representations eees required score layer visual model framework amount mapping visual space directly onto original semantic space. baseline model visual model learning becomes simpler; i.e. solving optimal problem formulated based original semantic representations. thus adam used parameter estimation. worth clarifying baseline model similar fasttag apart lstm-based visual embedding model used framework feed-forward neural network without recurrent connections employed fasttag visual embedding. randomized label representation important issues exploring/exploiting side information conveyed semantic domain. framework works multi-label zero-shot recognition would investigate whether semantic relatedness information encoded semantic embedding inherited original semantic representations effectively used knowledge transfer. design another baseline model named randomized label representation replacing word vector label vector dimensionality generated randomly normalized norm ensure range word vector. apparently semantic relatedness information longer exists randomized label representations. parameter estimation algorithm used directly replacing semantic representations labels randomized label representations training data. although best knowledge exists work multi-label zero-shot human action recognition notice multi-label algorithms. comparative study adopt extend multi-label algorithms human action recognition thorough evaluation proposed framework. below brieﬂy describe multi-label algorithms used experiments. direct semantic prediction well-known baseline model used previous works multi-label e.g. derived direct attribute prediction originally proposed single-label idea behind learning mapping function visual semantic space directly zsl. using composition property word vectors given multi-labelled video clip mean word vector achieved averaging word vectors labels associated video clip semantic representation. thus multi-label problem boiled single-label zsl. experiments employ support vector regressor models learn mapping function given test instance ˆxˆxˆx learned used predict compositional semantic representation ˆsˆsˆs prediction scores regarding different labels estimated measuring distances predictions word vectors labels label collection score ˆsˆsˆssssc leads label-based ranking list terms semantic relatedness. convex combination semantic embedding conse algorithm proposed norouzi naturally applied multi-label zsl. formulated conse also learns mapping predict compositional semantic representation visual representation given video clip. instead learning direct mapping function does however conse learns conditional probabilities regarding known actions training data. recognition compositional collective semantic representation test instance ˆxˆxˆx estimated convex combination semantic representations top- known actions highest conditional probabilities. combination weights normalized conditional probabilities top- known actions ˆsˆsˆs ∑c∈ctr psssc. thus prediction scores regarding labels action label collection score ˆsˆsˆssssc leads label-based ranking list costa costa method proposed mensink especially multi-label zero-shot classiﬁcation. method multi-label classiﬁcation converted number binary classiﬁcation problems one-vsrest setting. |ctr| linear binary svms trained based examples regarding |ctr| known actions. parameters unseen label estimated weighted combination parameters |ctr| trained svms corresponding known actions wwwc |ctr| αkβckwwwk. here wwwk parameters garding k-th label combination coefﬁcient regarding importance achieved |ctr| learning. exp/∑ factor indicating relatedness unseen label known label semantic distance labels measured word vectors. thus parameters wwwc used predict unseen label given test instance. note experimental results reported paper limited space suggest learning time consuming also yields poorer performance |ctr| svms treated equally; i.e. |ctr|. later report best performance setting. fasttag fasttag latest state-of-the-art methods proposed multi-label image tagging multi-label main idea behind fasttag learning mapping function visual semantic space multi-label zero-shot tagging recognition. unlike ranking-based loss function ranknet used train deep network carry video clip relevant labels ranked ahead irrelevant ones. recognition mapping function yields predicted semantic representation test instance ˆxxx. then achieve relatedness scores labels action label collection label-based ranking list done conse. experiments strictly follow settings suggested zhang fasttag+ work presented paper suggests learned semantic embedding leads better performance original semantic representations directly. investigate idea make extension fasttag incorporating semantic model fasttag model name extension fasttag+. result fasttag+ architecture resembling visual model carried original fasttag architecture semantic model presented section original ranking-base loss functions fasttag used alternate learning algorithm described algorithm used parameter estimation. recognition procedure presented section used given test instance. here argue extension would provide evidence examining effectiveness semantic embedding learning. comparative study optimal hyper-parameters involved baseline state-of-the-art learning models sought learning cross-validation procedure described section moreover stateof-the-art methods described extensible multi-label recognition straightforwardly; i.e. actions known advance training examples available learning. thus also report multi-label recognition performance extends comparative study wider scope also provides benchmark much performance method degraded zero-shot circumstance. described section employ grid-based search procedure cross-validation optimal hyperparameters terms i-map performance experiments seek optimal value candidate hyper-parameters involved different learning models follows network architecture optimal architecture neural networks model used experiments investigated tuning different number neurons hidtable optimal hyper-parameter values different learning models found random search. notation instance-first split; label-first split; visual model; semantic model; learning rate; soft-margin percentage support vectors svm/svr. indicates neural network architecture number neurons ﬁrst hidden layer dropout rate used learning; number hidden neurons second hidden layer; number neurons latent embedding layer. layer. proposed model totally four structural hyper-parameters. number hidden units lstm layer selected candidate visual model number neurons hidden layer lstm layer investigated semantic model number neurons ﬁrst hidden layer semantic model chosen critical hyper-parameter algorithm dimension latent embedding space number neurons visual/semantic embedding layers investigated setting candidate values nonrecurrent baseline model number neurons ﬁrst hidden layer replacing lstm layer chosen fasttag fasttag+ number neurons ﬁrst second hidden layers selected respectively. table multi-label zero-shot recognition performance baseline models full model three evaluation scenarios different data split settings. notation gzsl generalized scenario; knowna known-action scenario; unseena unseen-action scenario. notations described table learning rate neural networks proposed model baseline state-of-the-art models candidate learning rates visual model semantic model respectively. number epoches learning stopped i-map performance validation longer improved within last epoches. optimal model chosen yields highest value i-map validation set. dropout rate dropout rate used ﬁrst layer neural model learning selected {.}. hyper-parameters comparative study conse costa employ linear classiﬁcation uses linear regression. experiments optimal soft-margin value sought percentage support vectors always suggested literature. table summarizes results yielded four baseline models described section full model described section experimental results reported based different data split settings described section instance-ﬁrst split label-ﬁrst split three different evaluation scenarios described section i.e. generalized known-action unseen-action scenarios. reliability report mean standard error mean results three randomly generated known/unseen label splits evaluation scenario. setting observed table baseline models perform signiﬁcantly better random guess model datasets regardless evaluation scenarios apart model unseen-action scenario. lack knowledge transfer random label representation zero-shot performance expected. overall full model outperforms baseline models datasets generalized scenario regardless evaluation metrics unseen-action scenario terms precision recall although performs better breakfast scenario terms l-map imap. known-action scenario yield best performance breakfast general. result implies necessity semantic embedding learning depends complexity semantics underlying actions involved speciﬁc dataset. although human actions involved breakfast video clips simply record cooking processes dishes thus multiple action labels regarding video clips breakfast already well characterized relevant word vectors semantic representation used experiments. hence semantic embedding learning lead gain simplicity semantics underlying cooking actions. contrast performance full model charades lends evidence support semantic embedding learning presence complex semantics underlying actions given fact semantic embedding learning leads gain data known-action scenario. also observe leads best performance charades known-action scenario performance full model slightly worse rlr. result suggests label representation critically important known actions multi-label learning. nevertheless performance unseen-action generalized scenarios clearly indicate importance action label semantic representation knowledge transfer required zsl. also evident table full model always outperforms recurrent connections. thus comparison baseline models clearly suggest performance gain brought lstm layer visual model semantic embedding learning fulﬁlled semantic model. setting results shown table suggest baseline models perform signiﬁcantly better random guess. overall full model outperforms baseline models charades generalized unseen-action scenarios. however full model slightly under-performs generalized known-action scenarios reason stated earlier results setting. also generally performs better charades known-action scenario breakfast unseenaction scenario respectively. results reveal recurrent layer used visual model semantic embedding learning sematic model sufﬁcient generalizing capturing temporal coherence underlying episode conveying unseen action exploring intrinsic semantic relatedness known unseen actions insufﬁcient training data setting described below. general results table reveal models question behave differently different data split settings. performance model setting generally worse setting. breakfast number unseen labels recognition performance much lower ifs. charades performance also inferior despite fact number unseen actions half ifs. observation suggests setting closer real application challenging setting widely used existing methods literature. closer look experimental protocol notice training examples critically training examples contain instances associated unseen labels though relevant unseen labels instance used learning. note known unseen labels linked semantic representations also label co-occurrences training examples. example know actions pour cereal stir cereal closely related semantic space high probability co-occurrences. suppose actions fall known unseen action categories. test instance conﬁdently high score pour cereal could lead high score stir cereal. thanks label cooccurrences stir cereal could easily recognized despite unseen action. contrast unlikely label-occurrence property exploited since video clip containing pour cereal action would excluded training data happens contain unseen action stir cereal. summary comparison elaborated baseline models facilitates understanding different components employed proposed multi-label zero-shot human action recognition framework. comparison four baseline models full model generally leads favorable results datasets measured different evaluation metrics three evaluation scenarios although experimental results also reveal limitation components used full model studied future research. table summarizes experimental results comparative study described section multi-label performance different methods reference random guess reported compared proposed framework. again experiments conducted different data split settings evaluated three evaluation scenarios described section reliability report mean results three randomly generated known/unseen label splits evaluation scenario. setting seen table models perform better random guess evaluation scenarios. however conse result poorer performance random guess unseen-action scenario breakfast terms speciﬁc metric e.g. i-map. overall conse under-perform methods considerably terms evaluation metrics table multi-label zero-shot recognition performance state-of-the-art methods reference random guess three evaluation scenarios different data split settings. notations used tables three evaluation scenarios. results demonstrate simply combining semantic representations cooccurred multiple labels collective representation leads catastrophic loss semantic information mainly responsible poor performance conse multi-label recognition. fasttag generally outperforms costa datasets terms evaluation metrics. costa learns classiﬁer label separately without considering relationship among co-occurred labels taking account relationship fasttag accounts better performance. incorporating semantic embedding learning fasttag fasttag+ extension fasttag constantly improves performance original version circumstances datasets general. again result lends evidence justify necessity semantic embedding learning used framework zero-shot multilabel zsl. contrast model generally outperforms models signiﬁcantly terms evaluation metrics different evaluation scenarios datasets highlighted bold-font table comparing model fasttag+ three main differences follows visual representations network architectures visual model loss functions. regarding visual representations model uses segment-based visual features instance fasttag+ employs instance-level holistic visual representation. network architectures employ lstm layer recurrent connections capture temporal coherence among segments video clip fasttag+ simply uses feed-forward network. described section propose alternative loss function fasttag. thus differences together leverage performance gain fasttag+ lends evidence support proposed framework. setting experimental results suggest models question similar behavior setting shown table again conse generally perform worse models even under-perform random guess charades unseen-action scenario. costa yields better performance conse overall generally under-performs fasttag fasttag+ three evaluation scenarios. nevertheless overall model perform better fasttag+ unseen-action scenario although outperforms fasttag generalized known-action scenarios. described section setting challenging setting salient visual features test instances corresponding unseen actions could completely miss training examples. case segment-level based visual representation lstm layer visual model able generalize well lack training examples. although result sufﬁciently favor segment-level based visual representation lstm layer visual model presence limited training data doubt introducing semantic model fasttag leverages performance gain. again experimental results along compared baseline models setting reveal training data sparsity issue addressed future multi-label zero-shot human action recognition study. furthermore table shows experimental results conventional multi-label human action recognition i.e. actions known learning. circumstance setting applicable. hence setting described section unlike done simulating zero-shot scenario reserve actions. also procedure done zero-shot learning search optimal hyper-parameters models repeat experiments data split setting three trials different parameter initialization. result report mean standard deviation three-trial results yielded different methods. evident table model performs best conventional multi-label recognition datasets. degraded performance zero-shot scenario compare performance generalized evaluation scenario setting shown table reported table comparison seen zero-shot performance model drops narrow margin given fact human actions reserved unseen labels breakfast charades respectively comparison experimental results suggests proposed framework yields promising performance multi-label zero-shot human action recognition close performance multilabel human action recognition. experimental results shown table also suggest state-of-the-art methods behave similarly general. however also observe unusual phenomenon performance; i.e. comparison generalized performance reported table always yields slightly better performance multi-label recognition generalized scenario regardless evaluation metrics breakfast fasttag fasttag+ terms l-map. closer look dataset results experiments well analysis least factors account unusual phenomenon co-occurred labels associated video clips breakfast redundant light semantics single collective semantic representation co-occurred multiple labels used insensitive missing co-occurred labels label information redundancy information loss resulting averaging operation forming single representation. thus reckon phenomenon rather speciﬁc nature dataset setting small number unseen labels. summary comparative study suggests proposed framework yields favorable results outperforms existing state-of-the-art methods general although always perform better fasttag+ extension fasttag made ourselves. also experimental results demonstrate challenges multi-label novel setting especially training data less correlated test instances associated unseen classes semantic visual domains. fig. test video clip setting top- labels predicted different methods. ground-truth labels take bowl crack eggplate take platestir pour eggpan stir salt pepper butter pan. tion recognition visualize number typical test video clips breakfast top- labels predicted different state-of-the-art methods described section terms semantic relatedness scores. visual inspection mainly focuses understanding behavior model issues arising work. result figures illustrate several frames human actions typical test video clips top- predicted labels different methods baseline models correctly predicted setting figures illustrate three typical results yielded different methods. figure exempliﬁes success model top- labels predicted model ground-truth actions including unseen action methods match performance model. exempliﬁed test instance suggests lstm layer visual model facilitates recognition distinctive actions video clip. figure refig. test video clip appearing settings top- labels predicted different methods data split settings. ground truth labels take bowl crack eggplate take plate stir pour eggpan stir salt pepper butter setting take bowl crack eggplate take plate stir pour eggpan stir salt pepper butter setting respectively. veals test instance methods outperform ours. comparing labels predicted model ground truth predicted labels semantically correlated ground truth e.g. fruit orange fruitbowl pour juice. test instance demonstrates limitation model capturing features visual domain associated accurate semantic description semantic domain exist many similar actions targeted application. figure shows test instance methods fail ground-truth labels top- predicted labels. visual inspection test instance reveals non-trivial objects pertaining different actions concentrated small region located top-right frames video clip. thus extremely difﬁcult capture useful information visual domain poses challenge existing human action recognition techniques. three test instances illustrated figures also provide insight methods work. instance conse likely yield labels regarding frequently used words human action domain. evident conse predicts top- labels pertaining different actions taken instance shown figure pour actions commonly taken kitchen instance shown figure limitation fact conse uses single collective semantic representation resulting averaging semantic representations multiple co-occurred labels favors frequently used word vectors diminishes opportunity ﬁnding infrequently used word vectors prediction. setting setting. hand setting results training data sparsity issue contrast setting. issue take ﬁrst split breakfast example. split shown table training examples setting respectively. however number training examples pertaining speciﬁc known actions signiﬁcantly different split settings different data split protocols described section example training examples target labelscrack eggplate take plate stir salt pepper respectively setting. contrast examples target labels respectively setting. hand major difference models ours; i.e. visual model employs hidden layer recurrent connection capture temporal coherence underlying intrinsic visual features state-of-the-art models used comparative study mechanism. well known learning model higher complexity larger capacity demands informative training data. training data sparsity issue severely affects performance model models; evident performance gain lstm layer visual model disappears lack sufﬁcient training data required training visual model capture temporal coherence. understand difference settings training data sparsity issue intuitively illustrate results yielded state-of-the-art methods common instance appearing test sets data split settings shown figure evident top- action labels predicted model ground truth models predict ground-truth actions correctly setting. contrast however none models correctly predicts ground-truth action exactly test instance setting. visual inspection test instance clearly demonstrates distinction data split settings visual features associated unseen actions available setting unavailable setting training data sparsity issue setting poses challenge also existing multi-label methods. paper formulated human action recognition multi-label zero-shot learning problem provide effective solution proposing novel framework joint latent embedding learning. carry framework employ neural network heterogeneous architecture visual embedding lstm layer used facilitate capturing temporal coherence information underlying different actions weakly annotated video data. also advocate semantic embedding learning facilitate bridging semantic effective knowledge transfer implemented feed-forward neural network. contributions thoroughly veriﬁed comparative study various well-motivated settings. experimental results benchmark multi-label human action datasets suggest proposed framework generally outperforms baseline systems also several state-of-the-art multi-label approaches different test scenarios. although demonstrated favorable results benchmark datasets comparison state-of-the-art approaches observations performance approaches used comparative study including suggest existing multi-label techniques ready real application; particular performance becomes even worse label-ﬁrst split setting corresponding real scenario human action recognition system deployed. nevertheless experiment results including visual inspection provide insightful information improving proposed framework. ongoing work would address issues arising experiments observations proper techniques. address training data sparsity issue revealed experiments would develop unsupervised learning algorithms discover salient intrinsic visual features unlabeled video clips incorporate proper temporal constraints loss functions better capture temporal coherence. moreover would introduce attention mechanisms model improving implicit salient feature extraction different actions involved video clip visual embedding learning. also would employ alternative semantic representations developed encode semantic relatedness action labels accurately semantic embedding learning facilitate knowledge transfer. framework proposed especially multilabel zero-shot human action recognition would highlight directly applicable multi-label human action recognition without modiﬁcation demonstrated experiments. also framework easy adapt tackling various multi-label problems different domains. example apply framework miscellaneous multi-label zero-shot classiﬁcation tasks temporal sequential data e.g. acoustic event classiﬁcation straightforward well multi-label zero-shot learning tasks static data e.g. object recognition replacing neural network heterogeneous architecture neural network feed-forward connections visual model. thus going explore extensions applications future work.", "year": 2017}