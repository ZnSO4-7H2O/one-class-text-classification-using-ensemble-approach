{"title": "Hybrid Gradient Boosting Trees and Neural Networks for Forecasting  Operating Room Data", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Time series data constitutes a distinct and growing problem in machine learning. As the corpus of time series data grows larger, deep models that simultaneously learn features and classify with these features can be intractable or suboptimal. In this paper, we present feature learning via long short term memory (LSTM) networks and prediction via gradient boosting trees (XGB). Focusing on the consequential setting of electronic health record data, we predict the occurrence of hypoxemia five minutes into the future based on past features. We make two observations: 1) long short term memory networks are effective at capturing long term dependencies based on a single feature and 2) gradient boosting trees are capable of tractably combining a large number of features including static features like height and weight. With these observations in mind, we generate features by performing \"supervised\" representation learning with LSTM networks. Augmenting the original XGB model with these features gives significantly better performance than either individual method.", "text": "time series data constitutes distinct growing problem machine learning. corpus time series data grows larger deep models simultaneously learn features classify features intractable suboptimal. paper present feature learning long short term memory networks prediction gradient boosting trees focusing consequential setting electronic health record data predict occurrence hypoxemia minutes future based past features. make observations long short term memory networks effective capturing long term dependencies based single feature gradient boosting trees capable tractably combining large number features including static features like height weight. observations mind generate features performing \"supervised\" representation learning lstm networks. augmenting original model features gives signiﬁcantly better performance either individual method. hospitals data constantly recorded often form physiological signals blood oxygen heart rate blood pressure more. paper address problem hypoxemia within operating rooms; common potentially serious concerns anesthesiologists deal safeguarding patients. particular recent study found hypoxemic events occur every surgery hours average hospitals’ operating rooms events cause serious patient harm general anesthesia surgery correlated cardiac arrest cardiac arryhythmias decreased cognitive function order assist anesthesiologists lundberg developed method hypoxemia prediction operating room data interpretability compared parzen windows linear linear lasso gradient boosting trees. found gradient boosting trees pre-processed features performant method hypoxemia predictions. evaluation machine learning technique found method made accurate hypoxemia predictions practicing anesthesiologists. lundberg showed gradient boosting trees powerful methods prediction preprocessed time series features used exponential moving averages/variances improved. representation learning would take advantage recurrence/memory neural networks encode pass latent representations gradient boosting tree improve doctor performance. general representation learning already achieved great success speech recognition signal processing object recognition natural language processing well suited time series biomedical data inherent/latent structure reasonable assumption physiological data. explore approach present framework forecasting biomedical time series data. long short term memory networks long short term memory networks sophisticated explicitly retain memory comparison autoregressive methods used previous exploration hypoxemia recurrent neural networks like lstm networks capable capturing complex dependencies. train networks python using keras open source neural network library tensorﬂow backend utilize cpus xeon .ghz) train networks tree models. terms design networks paper simply utilize layers adding many layers made convergence difﬁcult application. found important steps training lstm networks operating room data impute missing values training mean standardize data randomize sample ordering prior training. prevent overﬁtting utilized dropouts layers well recurrent dropouts lstm nodes using learning rate rmsprop optimizer sigmoid output layer gave best ﬁnal results. lstm models validation accuracy improve twenty rounds. best knowledge ﬁrst applications rnns within operating room setting unaware others. rnns applied health settings lipton applied lstm networks clinical setting applied grus imputation clinical synthetic data sets chauhan rajpurkar done work focused univariate applications neural networks health settings gradient boosting trees gradient boosting trees work well practice ease ﬂexibility. imputing standardizing randomizing unnecessary gradient boosting trees based splits training data. postulate gradient boosting trees better incorporating important static features predictions lstm networks good performance simple methods processing time series features found learning rate tree depth subsampling rate logistic objective gave good performance. models validation accuracy non-improving rounds. train models python using xgboost open source library gradient boosting trees methodology using processed times series data static data. identify important features. supervised learning univariate lstm networks features. second last lstm layer create features xgb. retrain model additional hidden features ﬁnal model. data surgeries containing real-time features sampled minute minute etco etc. well static summary information height weight codes etc. obtained appropriate institutional review board approval. splitting surgeries multiple time points samples positive examples. labels represent time series binary hypoxemia classiﬁcation problem less considered hypoxemia. evaluation metric area precision-recall curve evaluation metric. curves widely used binary classiﬁcation tasks summarize predictive accuracy model. rather curves curves better suited classiﬁcation problems imbalanced labels. true positives positive sample points classiﬁed positive whereas true negatives negative sample points classiﬁed negative. then false positives negative sample points classiﬁed positive whereas false negatives positive sample points classiﬁed negative. precision deﬁned tp+f curve plotted precision value recall order summarize curve conventional area curve measure prediction performance. performance demonstrate long short term memory networks outperform autoregressive methods. figure reveals things. first univariate signal lstm networks substantially outperform autoregressive methods even performant ones like gradient boosting trees. second lstm networks improve performance even autoregressive methods saturate terms accuracy. utilizing lookbacks rather markedly improves lstm network performance suggesting successfully identify complex long term patterns relevant prediction. moving forward lstm networks lookbacks minutes predict desaturation. although multivariate lstm networks predict hypoxemia appear promising take substantial amount time train. despite twice many nodes table model gives slight improvement table model based training gradient boosting model suspect static features contain information relevant prediction multivariate lstm networks capable utilizing additionally cost training lstm network already increasing drastically model size. order successfully capture relationships complete multivariate network network size would need increase intractably large size. preliminary results geforce approximately three times faster multivariate network would likely still intractable. then table shows utilizing processed immediately well. access processed features pr-auc increases drastically result suggests gradient boosting trees able leverage remaining features improve predictive accuracy lstm networks alone could not. ﬁgure dominates important features hypoxemia prediction static features like weight also importance. training models effectively utilize pr-auc test set. don’t report time train gradient boosting trees training times fairly short slowest model taking approximately hours train. processed denotes three exponential moving averages well exponential moving variance time series features. lstm output denotes using probability hypoxemia output ﬁnal sigmoid layer input xgb. lstm hidden denotes using outputs penultimate lstm layer inputs xgb. lstm output/hidden features generating using model table additional features appear tractable lstm networks thus motivating exploration hybrid approach. then model table utilizing lstm latent representations gives slightly better performance lstm network alone suggesting gradient boosting trees able capture non-linearity ﬁnal layer lstm network. next model shows augmenting supervised latent representation lstm network gives substantially better performance either individual model. since gradient boosting trees work well hidden features alone combine model processed features yields performant model hypoxemia prediction. included emas/emv models much predictive performance emas/emv much hidden lstm features still open question. models hidden features revealed much informative single predictive probability suggesting hidden features serve fairly powerful surrogates emas/emv also capture additional information emas/emv features not. suggests supervised representation learning capable ﬁnding sensible representations. representations learned many tasks data sets machine learning research scientists able work additively impactful questions health. representation learning motifs time series data conveyed research groups access different data sets anonymous meaningful ways protecting patient privacy. high level hybrid approach simplistic. simplicity offers nice properties ﬁrst generalizability hybrid approach machine learning easily applied problem would beneﬁt sophisticated time series processing. second property accessibility using open source packages available methodologies easily combined performative ways biomedical data. accessibility ideally encourages references jesse ehrenfeld funk schalkwyk merry sandberg gawande. incidence hypoxemia surgery evidence institutions. canadian journal anesthesia dunham hutchinson hileman chance huang. perioperative hypoxemia common horizontal positioning general anesthesia associated major adverse outcomes retrospective study consecutive patients. anesthesiol. scott lundberg bala nair monica vavilala mayumi horibe michael eisses trevor adams david liston daniel king-wai shu-fang newman jerry su-in lee. explainable machine learning predictions help anesthesiologists prevent hypoxemia surgery. biorxiv martín abadi ashish agarwal paul barham eugene brevdo zhifeng chen craig citro gregory corrado andy davis jeffrey dean matthieu devin sanjay ghemawat goodfellow andrew harp geoffrey irving michael isard yangqing rafal józefowicz lukasz kaiser manjunath kudlur josh levenberg mané rajat monga sherry moore derek gordon murray chris olah mike schuster jonathon shlens benoit steiner ilya sutskever kunal talwar paul tucker vincent vanhoucke vijay vasudevan fernanda viégas oriol vinyals pete warden martin wattenberg martin wicke yuan xiaoqiang zheng. tensorﬂow large-scale machine learning heterogeneous distributed systems. corr abs/. nitish srivastava geoffrey hinton alex krizhevsky ilya sutskever ruslan salakhutdinov. dropout simple prevent neural networks overﬁtting. mach. learn. res. january chauhan vig. anomaly detection timesignals deep long short-term memory networks. proc. ieee international conference data science advanced analytics pages october pranav rajpurkar awni hannun masoumeh haghpanahi codie bourn andrew cardiologist-level arrhythmia detection convolutional neural networks. corr abs/. tianqi chen carlos guestrin. xgboost scalable tree boosting system. proceedings sigkdd international conference knowledge discovery data mining pages york acm.", "year": 2018}