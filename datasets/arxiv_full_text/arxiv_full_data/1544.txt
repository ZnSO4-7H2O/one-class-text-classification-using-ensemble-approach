{"title": "Domain Adaptation for Neural Networks by Parameter Augmentation", "tag": ["cs.CL", "cs.AI", "cs.LG"], "abstract": "We propose a simple domain adaptation method for neural networks in a supervised setting. Supervised domain adaptation is a way of improving the generalization performance on the target domain by using the source domain dataset, assuming that both of the datasets are labeled. Recently, recurrent neural networks have been shown to be successful on a variety of NLP tasks such as caption generation; however, the existing domain adaptation techniques are limited to (1) tune the model parameters by the target dataset after the training by the source dataset, or (2) design the network to have dual output, one for the source domain and the other for the target domain. Reformulating the idea of the domain adaptation technique proposed by Daume (2007), we propose a simple domain adaptation method, which can be applied to neural networks trained with a cross-entropy loss. On captioning datasets, we show performance improvements over other domain adaptation methods.", "text": "propose simple domain adaptation method neural networks supervised setting. supervised domain adaptation improving generalization performance target domain using source domain dataset assuming datasets labeled. recently recurrent neural networks shown successful variety tasks caption generation; however existing domain adaptation techniques limited tune model parameters target dataset after training source dataset design network dual output source domain target domain. reformulating idea domain adaptation technique proposed daum´e propose simple domain adaptation method applied neural networks trained cross-entropy loss. captioning datasets show performance improvements domain adaptation methods. learning domain adaptation paradigm aims improving generalization performance domain using dataset original domain. suppose that source domain dataset captioning corpus consisting images daily lives image captions. suppose also would like generate captions exotic cuisine rare corpus. usually costly make corpus target domain i.e. taking captioning mainly settings domain adaptation fully supervised semi-supervised. focus supervised setting source target domain datasets labeled. would like label information source domain improve performance target domain. recently recurrent neural networks successfully applied various tasks ﬁeld natural language processing including language modeling caption generation parsing standard methods supervised domain adaptation ﬁrst method tuning ﬁrst train model source dataset tune target domain dataset since objective function neural network training nonconvex performance trained model depend initialization parameters. contrast convex methods support vector machines expect ﬁrst training gives good initialization parameters therefore latter training gives good generalization even target domain dataset small. downside approach lack optimization objective. method design neural network outputs. ﬁrst output trained source dataset output trained target dataset input part shared among domains. call method dual outputs. type network architecture successfully applied multitask learning part-of-speech taglarge body previous work domain adaptation. state-of-the-art methods supervised domain adaptation feature augmentation idea method augment original features/parameters order model source speciﬁc target speciﬁc general behaviors data. however straight-forward apply neural network models cost function form probabilities. paper propose domain adaptation method neural networks. reformulate method daum´e derive objective function using convexity loss function. high-level perspective method shares idea feature augmentation. redundant parameters source target general domains general parameters tuned model common characteristics datasets source/target parameters tuned domain speciﬁc aspects. latter part paper apply domain adaptation method neural captioning model show performance improvement standard methods several datasets metrics. datasets source target different word distributions thus adaptation output parameters important. augment output parameters facilitate adaptation. although captioning models experiments method applied neural networks trained cross-entropy loss. several recent studies applying domain adaptation methods deep neural networks. however studies focused improving tuning dual outputs methods supervised setting. proposed unsupervised domain adaptation method apply features deep neural networks. idea minimize domain shift aligning secondorder statistics source target distributions. setting necessarily true correspondence source target input distributions therefore cannot expect method work well. proposed procedure generate natural language multiple domains spoken dialogue systems. improve tuning method pre-trainig synthesized data. however synthesis protocol applicable spoken dialogue system. paper focus domain adaptation methods applied without dataset-speciﬁc tricks. yang conducted series experiments investigate transferability neural networks nlp. compare performance transfer methods called init mult correspond tuning dual outputs methods terms. conclude mult slightly better comparable init; consistent experiments shown section although obtain little improvement transferring output parameters achieve signiﬁcant improvement augmenting parameters output layers. start basic notations formalization domain adaptation. inputs outputs. source domain dataset sampled distribution also target domain dataset sampled another distribution since considering supervised settings element datasets form input output pair goal domain adaptation learn function models input-output relation implicitly assume connection source target distributions thus leverage information source domain dataset. case image caption generation input image caption language generation tasks sequence words generated input state-ofthe-art model language generation lstm initialized context vector computed input lstm particular form recurrent neural network three gates memory cell. time step vectors computed folconditional distributions given parameters model optimized minimize cost training dataset. also note extensions models attentions forms cost functions same. standard baseline methods trivial method domain adaptation simply ignoring source dataset train model using target dataset. method heredenoted tgtonly. baseline meaningful method must beat another method source target datasets combined used training. although method uses data training criteria enforce model perform well domains therefore performance target domain necessarily high. approach widely used neural network community finetune. ﬁrst train model source dataset used initial parameters training model target dataset. training process stopped reference development order avoid over-ﬁtting. could extend method posing regularization term order deviate pre-trained parameter. latter experiments however pursue direction found performance gain. note hard control scales regularization part neural many parameters havfigure schematic view lstm captioning model. ﬁrst input lstm image feature. sentence piece chocolate cake glass plate generated. generation process ends symbol. tunable parameter matrix feature extractor usually given convolutional neural network. output words selected order caption ends special symbol <eos>. process illustrated figure note cost function generated caption easily equal θg−θt respectively thus additional regularization enforces away. feature augmentation method shares domain information parameters another common approach neural domain adaptation dual. method output network dualized. words different parameters source target domains. source dataset model trained ﬁrst output second target dataset. rest parameters shared among domains. type network design often used multi-task learning. work source target versions method actually dual parameters completely redundant. difference objective proposed upper bound works regularization term results good generalization performance. although formulation unique objective three types cross entropy loss terms given denote respectively. source data general source loss terms optimized target dataset general target loss terms optimized. proposed algorithm summarized algorithm note parameters lstm except output part. epoch training data once. combine parameter update methods neural network training adam conducted domain adaptation experiments following three datasets. ﬁrst experiment focuses situation domain adaptation useful. second experiment show beneﬁt domain adaptation directions source target target source. third experiment shows improvement another metric. although method applicable adaptation food domain captioning experiment highlights typical scenario domain adaptation useful. suppose large dataset captioned images taken daily lives would like generate high quality captions specialized domain images minor sports exotic food. however captioned images domains quite limited annotation cost. domain adaptation methods improve captions target domain. simulate scenario split microsoft coco dataset food non-food domain datasets. coco dataset contains approximately images training images validation; image captions dataset contains images diverse categories including animals indoor scenes sports foods. selected food category data scoring captions according much related food category. score computed based wordnet similarities training validation datasets split score threshold. consequently food dataset images training validation. non-food dataset images training validation. selected pictures food domain typically close-up foods people eating foods. table shows captions food non-food domain datasets. table shows twenty frequent words datasets except stop words. observe frequent words largely different still words common datasets. model image captaining lstms described previous section. image features computed trained googlenet lstms single layer hidden units standard optimization method adam hyper parameters stop training based loss development set. training generate captions beam search size beam settings closeup bins food include broccoli bread. woman sitting front table plate food. large pizza covered cheese toppings. people shopping open market vegetables. purse sits foot large beds. large television screen large room. compare proposed method baseline methods. methods adam hyper parameters. finetune freeze parameters target training. dual samples source target datasets weighted equally. evaluated performance domain adaptation methods qualities generated captions. used bleu metor cider scores evaluation. results summarized table proposed method improves metrics. baseline methods srconly tgtonly worse methods limited data training. note cider scores correlate human evaluations better bleu metor scores generated captions sample images shown table ﬁrst example fails identify chocolate cake birds source dataset somehow look similar chocolate cake. argue proposed learns birds source parameters chocolate cakes target parameters thus succeeded generating appropriate captions. another captioning dataset consisting images image captions although formats datasets almost same model trained coco dataset work well flickr dataset vice versa. word distributions captions considerably different. ignore words less counts coco words flickerk words; words shared. also average lengths captions different. average length captions flickrk coco ﬁrst result domain adaptation coco flickrk summarized table again observe proposed method achieves best score among methods. difference finetune bigger previous setting datasets different captions even similar images. scores finetune dual almost level. second result domain adaptation flickrk coco shown table typical situation number samples target domain larger source domain. srconly model trained flickrk tested coco dataset. observe finetune gives little beneﬁt tgtonly implies bird sitting tree branch piece chocolate cake sitting white plate close bird tree branch close plate food plate close plate food close piece chocolate cake plate true caption piece chocolate cake glass plate. srconly tgtonly finetune dual proposed true caption woman sandwich plate drinking wine glass. srconly tgtonly finetune dual proposed woman holding cake table woman eating slice pizza person holding cake plate fork close plate food table group people sitting table eating food woman sitting table plate food difference initial parameters little effect case. also dual gives little beneﬁt tgtonly meaning parameter sharing except output layer important case. note cider score proposed slightly improved. answer sentence selection experiment captioning model afﬁnity measure images sentences. toeic part test consists fourchoice questions english learners. correct choice sentence best describes shown image. questions easy because confusing keywords wrong choices. example question shown table downloaded questions http//www.english-test.net/toeic/ listening/. approach select probable choice given image captioning models. train captioning models images correct answers training set. since toeic dataset small domain adaptation give large beneﬁt. compared domain adaptation methods percentage correct answers. source dataset samples coco target dataset toeic dataset. split toeic dataset samples training samples testing. percentages correct answers method summarized table since questions four choices methods perform better tgtonly close baseline model trained samples. previous experiments finetune dual better proposed better methods. proposed method supervised domain adaptation neural networks. captioning datasets shown method outperforms standard adaptation methods applicable neural networks. proposed method decomposes output word parameters parameters word embedding completely shared across domains. augmentation parameters part network would interesting direction future work. references dzmitry bahdanau kyunghyun yoshua bengio. neural machine translation jointly learning align translate. proceedings international conference learning representations tsung-yi michael maire serge belongie james hays pietro perona deva ramanan piotr doll´ar lawrence zitnick. microsoft coco common objects context. proceedings european conference computer vision pages tomas mikolov martin karaﬁ´at lukas burget cernock`y sanjeev khudanpur. recurrent neural network based language model. interspeech volume page christian szegedy yangqing pierre sermanet scott reed dragomir anguelov dumitru erhan vincent vanhoucke andrew rabinovich. going proceedings deeper convolutions. ieee conference computer vision pattern recognition pages vedantam lawrence zitnick devi parikh. cider consensus-based image description evaluproceedings ieee conference ation. computer vision pattern recognition pages venugopalan jeff donahue marcus rohrbach huijuan raymond mooney kate saenko. translating videos natural language using deep proceedings recurrent neural networks. conference north american chapter association computational linguistics oriol vinyals łukasz kaiser terry slav petrov ilya sutskever geoffrey hinton. grammar foreign language. advances neural information processing systems pages oriol vinyals alexander toshev samy bengio dumitru erhan. show tell neural image caption generator. proceedings ieee conference computer vision pattern recognition pages tsung-hsien milica gasic nikola mrksic lina rojas-barahona pei-hao david vandyke steve young. multi-domain neural network language generation arxiv preprint spoken dialogue systems. arxiv.. kelvin jimmy ryan kiros aaron courville ruslan salakhutdinov richard zemel yoshua bengio. show attend tell neural image caption generation visual atproceedings international tention. conference machine learning peter young alice micah hodosh julia hockenmaier. image descriptions visual denotations similarity metrics semantic inference event descriptions. transactions association computational linguistics", "year": 2016}