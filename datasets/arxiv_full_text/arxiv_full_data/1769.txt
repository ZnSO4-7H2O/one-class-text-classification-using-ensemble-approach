{"title": "Stochastic Structured Prediction under Bandit Feedback", "tag": ["cs.CL", "cs.LG", "stat.ML"], "abstract": "Stochastic structured prediction under bandit feedback follows a learning protocol where on each of a sequence of iterations, the learner receives an input, predicts an output structure, and receives partial feedback in form of a task loss evaluation of the predicted structure. We present applications of this learning scenario to convex and non-convex objectives for structured prediction and analyze them as stochastic first-order methods. We present an experimental evaluation on problems of natural language processing over exponential output spaces, and compare convergence speed across different objectives under the practical criterion of optimal task performance on development data and the optimization-theoretic criterion of minimal squared gradient norm. Best results under both criteria are obtained for a non-convex objective for pairwise preference learning under bandit feedback.", "text": "stochastic structured prediction bandit feedback follows learning protocol sequence iterations learner receives input predicts output structure receives partial feedback form task loss evaluation predicted structure. present applications learning scenario convex non-convex objectives structured prediction analyze stochastic ﬁrst-order methods. present experimental evaluation problems natural language processing exponential output spaces compare convergence speed across different objectives practical criterion optimal task performance development data optimization-theoretic criterion minimal squared gradient norm. best results criteria obtained non-convex objective pairwise preference learning bandit feedback. present algorithms stochastic structured prediction bandit feedback obey following learning protocol sequence iterations learner receives input predicts output structure receives partial feedback form task loss evaluation predicted structure. contrast full-information batch learning scenario gradient cannot averaged complete input set. furthermore contrast standard stochastic learning correct output structure revealed learner. present algorithms feedback banditize expected loss minimization approaches structured prediction algorithms follow structure performing simultaneous exploration/exploitation sampling output structures log-linear probability model receiving feedback sampled structure conducting update negative direction unbiased estimate gradient respective full information objective. algorithms apply situations learning proceeds online sequence inputs gold standard structures available feedback predicted structures elicited users. practical example interactive machine translation instead human generated reference translations translation quality judgments predicted translations used learning example machine translation showcases complexity problem input sentence receive feedback single predicted translation space exponential sentence length goal learn predict translation smallest loss complex evaluation metric. showed partial feedback indeed sufﬁcient optimization feature-rich linear structured prediction large output spaces various natural language processing tasks. experiments follow standard online-to-batch conversion practice applications model optimal task performance development data selected ﬁnal evaluation test set. contribution paper analyze algorithms stochastic ﬁrst-order methods framework investigate connection optimization task performance optimization-theoretic concepts convergence. analysis starts revisiting approach stochastic optimization non-convex expected loss criterion presented iteration complexity stochastic optimization non-convex objective analyzed framework terms number iterations needed reach accuracy criterion attempt improve convergence speed introducing cross-entropy objective seen convexiﬁcation expected loss objective. known best iteration complexity strongly convex stochastic optimization suboptimality criterion lastly analyze pairwise preference learning algorithm introduced algorithm also analyzed method non-convex optimization. knowledge ﬁrst approach stochastic learning form pairwise comparison feedback related approaches fall area gradient-free stochastic zeroth-order approaches convergence rate methods depends dimensionality function evaluated example non-convex algorithm iteration complexity algorithms depend crucial dimensionality feature space large common structured prediction. furthermore present comparison empirical theoretical convergence criteria tasks machine translation noun-phrase chunking. compare empirical convergence criterion optimal task performance development data theoretically motivated criterion minimal squared gradient norm. correspondence fastest convergence pairwise preference learning tasks. given standard analysis asymptotic complexity bounds result surprising. explanation given measuring variance lipschitz constant stochastic gradient smallest pairwise preference learning largest cross-entropy minimization several orders magnitude. offsets possible gains asymptotic convergence rates strongly convex stochastic optimization makes pairwise preference learning attractive method fast optimization practical interactive scenarios. reinforcement learning goal maximizing expected reward choosing action given state markov decision process model unknown rewards received state ﬁnal state. algorithms paper seen one-state mdps context choosing action corresponds predicting structured output. closely related recent applications policy gradient methods exponential output spaces problems similar expected loss minimization approaches approaches based nonconvex models however convergence rates rarely focus reinforcement learning literature. focus paper present analysis asymptotic convergence convergence rates non-convex stochastic ﬁrst-order methods. contextual one-state mdps also known contextual bandits operate scenario maximizing expected reward selecting multi-armed slot machine. similar case feedback partial models consist single state. bandit learning mostly formalized online regret minimization respect best ﬁxed hindsight characterize approach asymptotic convergence framework. furthermore highdimensional models predict structures exponential output spaces. since train models interaction real users focus ease elicitability feedback speed convergence. spectrum stochastic versus adversarial bandits approach semi-adversarial making stochastic assumptions inputs rewards pairwise preference learning studied full information supervised setting given preference pairs assumed. work stochastic pairwise learning formalized derivative-free stochastic zeroth-order optimization knowledge approach introduce expected loss criterion structured prediction minimization expectation given task loss function respect conditional distribution structured outputs. structured input space possible output structures input quantify loss suffered predicting instead gold standard structure full information setting given data distribution learning problem deﬁned gibbs distribution joint feature representation weight vector normalization constant despite highly non-convex optimization problem positive results obtained gradient-based optimization respect unlike full information scenario structured learning bandit feedback gold standard output structure respect objective function evaluated revealed learner. thus neither evaluate task loss calculate gradient full information case. solution problem pass evaluation loss function user access loss directly user feedback without assuming existence ﬁxed reference following drop subscript referring gold standard structure deﬁnition indicate feedback general independent gold standard outputs. particular allow equal several outputs. algorithm structure. algorithm shows structure methods analyzed paper. assumes sequence input structures generated ﬁxed unknown distribution randomly chosen input output sampled gibbs model perform simultaneous exploitation exploration output structures then feedback predicted structure obtained update performed taking step negative direction stochastic gradient rate post-optimization step solution chosen list vectors given algorithm formalize notion banditization objective functions presenting different instantiations vector showing unbiased estimates gradients corresponding full information objectives. instantiating algorithm stochastic gradient equation yields update compares sampled feature vector average feature vector performs step opposite direction difference higher loss sampled structure following refer algorithm expected loss minimization deﬁned update algorithm pairwise preference learning. decomposing complex problems series pairwise comparisons shown advantageous human decision making example machine translation means instead requiring numerical assessments translation quality human users relative preference judgement pair translations needs elicited. idea formalized expected loss objective respect conditional distribution pairs structured outputs. {hyi denote output pairs input denote task loss function speciﬁes dispreference compared experiments reported paper simulate types pairwise feedback. firstly continuous pairwise feedback computed factorization model product pwp−w allows efﬁcient sampling calculation expectations. instantiating objective case pairs output structures deﬁnes following objective non-convex cases paper learning partial feedback pairwise preferences ensure model ﬁnds ranking function assigns probabilities discordant pairs respect observed preference pairs. stronger assumptions learned ranking made asymmetry transitivity observed ordering pairs required. algorithm pairwise preference learning deﬁned instantiating algorithm sampling output pairs h˜yi ˜yjit receiving feedback performing stochastic gradient update using cross-entropy minimization. standard theory stochastic optimization predicts considerable improvements convergence speed depending functional form objective. motivated formalization convex upper bounds expected normalized loss normalized gain function objective seen cross-entropy model respect proper probability distribution application jensen’s inequality convex negative logarithm function shows objective convex upper bound objective however normalizing gain function prohibitive partial feedback setting since would require elicit user feedback structure output space. thus work unnormalized gain function preserves convexity. seen rewriting objective linear convex function note ability sample structures comes price normalize /pwt. minimization objective assign high probabilities structures high gain desired update affected probability changes time unreliable training started. increases variance already present stochastic optimization. deal problem clipping small sampling probabilities max{pwt constant algorithm cross-entropy minimizaˆ tion based stochastic gradient referred algorithm following. analyze convergence describe algorithms stochastic ﬁrst-order methods framework assume lower bounded differentiable objective functions lipschitz continuous gradient satisfying condition three algorithms taking expectations sources randomness i.e. random inputs output structures. assuming since ratio bounded variance condition bounded. note analysis justiﬁes constant learning rates convergence speed quantiﬁed terms number iterations needed reach accuracy gradient-based criterion stochastic optimization non-convex objectives iteration complexity respect criterion analyzed complexity result applies algorithms iteration complexity stochastic optimization convex objectives analyzed best suboptimality criterion decreasing learning rates strong convexity objective achieved easily adding regularizer constant algorithm modiﬁed following regularized update rule approaches. second standard asymptotic complexity bound non-convex stochastic optimization hides constants iteration complexity increases linearly. show constants substantial inﬂuence possibly offsetting advantages asymptotic convergence speed algorithm measuring numerical convergence task loss performance. following present experimental evaluation complex structured prediction tasks area namely statistical machine translation noun phrase chunking. tasks involve dynamic programming exponential output spaces large sparse feature spaces non-linear non-decomposable task loss metrics. training tasks done simulating bandit feedback evaluating gold standard structures never revealed learner. compare empirical convergence criterion optimal task performance development data numerical results theoretically motivated convergence criteria. purpose measuring convergence respect optimal task performance report evaluation convergence speed ﬁxed unseen data performed instantiates selection criterion line algorithm evaluation respective task loss function prediction maxy∈y development data. corresponds standard practice online-to-batch conversion model selected development data used ﬁnal evaluation unseen test set. bandit structured prediction algorithms ﬁnal results averaged three runs different random seeds. purpose obtaining numerical results convergence speed compute estimates expected squared gradient norm lipschitz constant variance asymptotic bounds iteration complexity grow linearly. estimate squared gradient norm squared norm stochastic gradient ﬁxed time horizon lipschitz constant equation estimated maxij kwi−wj pairs randomly drawn weights produced training. variance equation computed empirical variance stochastic gradient taken regular intervals epoch size yielding estimate estimates include multiplication stochastic gradient learning rate. comparability results across different algorithms constant learning rates algorithms. statistical machine translation. experiment interactive machine translation scenario simulated given machine translation system adapted user style domain based feedback predicted translations. domain adaptation europarl newscommentary domains using data provided shared task performed french-to-english translation. note squared gradient norm upper bounds suboptimality criterion s.t. k∇jk strongly convex functions. together constant learning rates means measure convergence point near optimum strongly convex objectives. table test evaluation stochastic learning bandit feedback chunking f-score machine translation bleu. higher better scores. results stochastic learners averaged three runs algorithm standard deviation shown subscripts. meta-parameter settings determined sets constant learning rate clipping constant regularization constant experiments based synchronous context-free grammar decoder cdec models standard dense lexicalized sparse features including out-of indomain language model. out-of-domain baseline model around active features. pre-processing data splits feature sets tuning strategies described detail difference task loss evaluation out-of-domain in-domain models gives range possible improvements bandit learning. learning bandit feedback starts learned weights out-of-domain median models. uses parallel in-domain data simulate bandit feedback evaluating sampled translation reference using loss function smoothed per-sentence bleu update hypergraph re-decoded hypotheses re-ranked. training distributed across shards using multitask-based feature selection algorithm noun-phrase chunking. experimental setting chunking following conditional random ﬁelds applied noun phrase chunking task conll dataset. implemented feature templates simpliﬁed version leads around active features. training full information log-likelihood objective yields difference machine translation training bandit feedback starts pre-trained model. task loss evaluation. table lists results task loss evaluation machine translation chunking performed together optimal meta-parameters number iterations needed optimal result development set. note pairwise feedback type treated meta-parameter algorithm simulation experiment. found preferable machine translation cont chunking order obtain highest task scores. machine translation bandit learning runs show signiﬁcant improvements bleu score out-of-domain baseline. early stopping task performance development selection algorithm number iterations factor smaller compared algorithms chunking experiment f-score results obtained bandit learning close fullinformation baseline. number iterations needed optimal result development smallest algorithm compared algorithms however best f-score obtained algorithm table estimates squared gradient norm lipschitz constant variance stochastic gradient ﬁxed time horizon constant learning rates chunking. clipping regularization parameters table machine translation except chunking results averaged three runs algorithm standard deviation shown subscripts. lipschitz constant estimated variance smallest algorithm since iteration complexity increases linearly respect terms smaller constants smaller value estimate number iterations indicates fastest convergence algorithm theoretically motivated result consistent practical convergence criterion early stopping development data algorithm yields smallest squared gradient norm time horizon also needs smallest number iterations achieve optimal performance development set. case machine translation algorithm even achieves nominally best bleu score test data. chunking experiment iterations estimated squared gradient norm either constants algorithm several orders magnitude smaller algorithm similar results algorithm corresponding iteration counts determined early stopping development data show improvement algorithm algorithms however smaller factor machine translation experiment. note comparability across algorithms constant learning rates used runs. however obtained similar relations algorithms using meta-parameter settings chosen development data shown table furthermore tendendencies hold settings meta-parameter cont algorithm presented learning objectives algorithms stochastic structured prediction bandit feedback. presented methods banditize well-known approaches probabilistic structured prediction expected loss minimization pairwise preference ranking cross-entropy minimization. presented comparison practical convergence criteria based early stopping theoretically motivated convergence criteria based squared gradient norm. experimental results showed fastest convergence speed criteria pairwise preference learning. numerical evaluation showed smallest variance pairwise preference learning possibly explains fastest convergence despite underlying non-convex objective. furthermore since algorithm requires easily obtainable relative preference feedback learning attractive choice practical interactive learning scenarios. duchi jordan wainwright wibisono optimal rates zero-order convex optimization power function evaluations. ieee translactions information theory dyer lopez ganitkevitch weese ture blunsom setiawan eidelman resnik cdec decoder alignment learning framework ﬁnite-state context-free translation models. demo.", "year": 2016}