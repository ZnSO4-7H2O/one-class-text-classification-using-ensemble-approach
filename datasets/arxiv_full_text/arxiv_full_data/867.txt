{"title": "Training recurrent networks online without backtracking", "tag": ["cs.NE", "cs.LG", "stat.ML"], "abstract": "We introduce the \"NoBackTrack\" algorithm to train the parameters of dynamical systems such as recurrent neural networks. This algorithm works in an online, memoryless setting, thus requiring no backpropagation through time, and is scalable, avoiding the large computational and memory cost of maintaining the full gradient of the current state with respect to the parameters.  The algorithm essentially maintains, at each time, a single search direction in parameter space. The evolution of this search direction is partly stochastic and is constructed in such a way to provide, at every time, an unbiased random estimate of the gradient of the loss function with respect to the parameters. Because the gradient estimate is unbiased, on average over time the parameter is updated as it should.  The resulting gradient estimate can then be fed to a lightweight Kalman-like filter to yield an improved algorithm. For recurrent neural networks, the resulting algorithms scale linearly with the number of parameters.  Small-scale experiments confirm the suitability of the approach, showing that the stochastic approximation of the gradient introduced in the algorithm is not detrimental to learning. In particular, the Kalman-like version of NoBackTrack is superior to backpropagation through time (BPTT) when the time span of dependencies in the data is longer than the truncation span for BPTT.", "text": "introduce nobacktrack algorithm train parameters dynamical systems recurrent neural networks. algorithm works online memoryless setting thus requiring backpropagation time scalable avoiding large computational memory cost maintaining full gradient current state respect parameters. algorithm essentially maintains time single search direction parameter space. evolution search direction partly stochastic constructed provide every time unbiased random estimate gradient loss function respect parameters. gradient estimate unbiased average time parameter updated should. resulting gradient estimate lightweight kalman-like filter yield improved algorithm. recurrent neural networks resulting algorithms scale linearly number parameters. small-scale experiments confirm suitability approach showing stochastic approximation gradient introduced algorithm detrimental learning. particular kalman-like version nobacktrack superior backpropagation time time span dependencies data longer truncation span bptt. however data arrive time streaming fashion backpropagation time would require making full backward computation time time data point becomes available. results complexity necessity store past states inputs outputs. possible strategy backtrack finite number time steps rather going back provides biased gradient estimates impair detection time dependencies longer range backtracking time range. contrast methods fully online typically scalable. strategy known real-time recurrent learning recurrent network community maintains full gradient current state respect parameters however full gradient object dimension prevents computing even storing moderately largedimensional dynamical systems recurrent neural networks. algorithms using kalman filter also rely derivative case recurrent networks). efficient estimating derivative turn kalman-type algorithm. algorithms suggested train hidden markov models online based expectation-maximization instead gradient descent) share algebraic structure suffer problem. nobacktrack algorithm rank-one trick expectation-preserving reduction propose build approximation sustainable algorithmic cost; random property stochastic gradient based introduce noise bias learning average change large number time steps reflect true gradient direction. different times sufficiently decorrelated. case dynamical system sufficiently ergodic.) unbiasedness hold instance gradient estimate simply projected onto nearest small-rank diagonal plus small-rank approximation. moreover minimize variance taking advantage additional degrees freedom decomposition namely first replace 𝜌𝑖𝑣𝑖 𝑤𝑖/𝜌𝑖 choice yields minimal variance norms become equal kalman filtering either alone pair first case explicitly needed. second case information influences current state contained covariance algorithm must maintain costly maintaining above. proof first statement immediate. statement minimizing variance proven appendix minimizing variance thanks quite important practice section rank-one trick also extends tensors arbitrary order; sparse vectors. 𝑖-th basis vector space understand structure rank-one unbiased approximation evolution equation approximation approximation rank-one more used perform gradient step reduced rank-one approximation next time step. note handling usually cheap many situations small subset parameter directly influences component given component state space non-zero components. instance recurrent neural network activities taken independently random among e±𝑖𝜋/}. involves complex numbers need complexify original dynamical system another complex-free possibility apply 𝑢𝑖⊗𝑣𝑖⊗𝑤𝑖⊗𝑥𝑖 apply independent rank-one trick also performed using random gaussian vectors namely version depend chosen decomposition depends choice variance much larger case instance actually rank-one rank-one trick random signs exact whereas gaussian version yields correct expectation. case particularly relevant going apply reduction time step thus working objects stay close rank-one. generalization tensors also cumbersome gaussian case. 𝑟𝑖𝑘𝑥𝑘 𝑊𝑗𝑖𝑎𝑗 derivative respect parameter involves parameters unit situations total cost computing storing 𝑤𝑖’s order cost computing itself. section details example. reduction step algorithm interpreted search direction parameter space estimate effect current state changing direction search direction evolves stochastically fully random time average fair estimate actual influence parameter construction step algorithm quantity ¯𝑤⊤+ 𝑒𝑖𝑤⊤ however since value changes along algorithm must careful meaning statement. intuitively derivative respect taken along actual trajectory parameters realized algorithm. particular learning rates tending parameter evolves slowly derivative close derivative respect current value parameter. thus regime tends since unbiased estimate situation gets closer closer ordinary stochastic gradient descent small. presumably observation step compute prediction current state observe incur loss update step compute derivative loss respect output parameters update output parameters happens whenever learning rate small enough change much within time range corresponding forgetting time dynamical system although work needed here. euclidean version nobacktrack algorithm presented algorithm enough obtain good performance fast. online estimation often yields best results using filters kalman family. refer discussion kalman filtering applied recurrent neural networks. maintaining full covariance matrix usually costly. however good approximation critical good approximation symmetric positive definite matrix changes slowly enough time yield unbiased trajectory thus aggressive matrix reduction techniques block-diagonal quasi-diagonal approximations. setting main point using covariance matrix sensible scaling learning rate component reparametrization-invariance properties kalman filtering case true underlying parameter extended kalman filter constant better work inverse covariance matrix extended kalman filter rewritten fisher information matrix probability distribution so-called information filter approximates fisher information matrix given observations time basically natural gradient descent approach summarized algorithm describe loosely since matrix approximation schemes depend application. algorithm uses decay factor inverse covariance matrices limit influence computations made outdated values factor also controls effective learning rate algorithm since line kalman filtering included learning rate update step size adapted magnitude grows linearly step size moreover included regularization term matrix inversion; bayesian interpretation kalman filtering corresponds gaussian prior parameters inverse covariance matrix important avoid fast divergence first steps. practice used ⊤𝜕ℓ𝑡 used experiments below. namely simply 𝜕^𝑦𝑡 𝜕^𝑦𝑡 updates simplify become rank-one outer product ⊤𝜕ℓ𝑡 updates using gradient loss namely likewise derivative estimated current gradient estimate parameters maintains algorithm plus representation matrices allowing efficient inversion; subroutines matrix reduction method matrixreduce evaluates small number entries argument returns approximation inverted efficiently; routine fisherapprox returns either positive definite approximation fisher information matrix probability distribution positive definite approximation hessian initialization algorithm end-of-time independent step resulting estimate 𝜕ℎ/𝜕𝜃 unbiased variance grows linearly time. indeed dynamics stationary thanks factor dynamics purely additive 𝑑-dimensional random walk. hand rescaling used rescaled step dynamics becomes stationary variance grow. recurrent neural networks. next example standard recurrent neural network state system pre-activation values activities activation function tanh sigmoid. recurrent dynamics independent symmetric binary random variables taking values probability non-zero choice leads unbiased estimation though values optimized mentioned above. states explicitly appearing equations stay unchanged thus transition function explicitly depends time sparse step. indeed step applying transition function amounts applying corresponding layer leaving layers unchanged. thus derivative respect zero; leaves gradient dealt with algorithm applied little cost. extensions rank-𝐾 reductions. first obvious extension higher-rank reductions. simplest achieve take several independent random rank-one reductions average them. note evaluated case. might slightly efficient first split parameter components blocks 𝑘-th term involves parameters 𝑘-th block indeed applying evolution equation preserves structure requires less memory storage ¯𝑤𝑘. algorithms similar rtrl. algorithms proposed structure shortcomings real-time recurrent learning instance online algorithm hidden markov models principle approach presented extended settings. important case ensures change times random quantity step. expected correct scaling continuous-time stochastic evolution equation corresponding increment wiener process time interval step would evolve times centered random quantity would constant limit.) work needed study continuous-time limit. report series small-scale experiments text prediction tasks. experiments focus questions first learning using rank-one approximation accurately reflect learning based actual gradient computed exactly rtrl noise introduced method detrimental learning? second approach compare truncated backpropagation time? used leaky models described predict sequence characters finite alphabet given past observations time network outputs probability distribution next character explicitly output time defined parameters output defines probability distribution softmax 𝑒^𝑦𝑧 loss function log-loss prediction next character 𝑝^𝑦). internal output parameters trained according algorithms used three datasets. first text representing synthetic music notation several syntactic rhythmic harmonic constraints data file length characters signal cycled file. second dataset classical 𝑎𝑛𝑏𝑛 example synthesized repeatedly picking integer random interval outputting series followed line break another line break. model tests ability learning algorithm learn precise timing time dependencies. benchmarks included gzip standard non-online compression algorithm context tree weighting advanced online text compression algorithm well actual entropy rate generative model synthetic music 𝑎𝑛𝑏𝑛. euclidean nobacktrack. first study whether rank approximation euclidean version nobacktrack impacts gradient descent. first experiments fully connected units described above synthetic music example. compared rtrl euclidean rank-one nobacktrack euclidean nobacktrack using ranktwo rank-ten reductions various algorithms amount time. reflected different curve lengths different algorithms; particular curve rtrl much shorter reflecting higher computational cost. impact stochasticity low-rank approximation using large learning rates highlighted figure euclidean nobacktrack large learning rate displays instabilities even increasing rank approximation. smaller learning rates allow algorithm cope this noise gradients averaged longer time spans. illustrated figure trajectories euclidean nobacktrack track rtrl closely even rank-two approximation. kalman nobacktrack. next report results kalman version nobacktrack experimental setup. quasi-diagonal outer product approximation full kalman inverse covariance matrix used keep complexity low. compare low-rank approximations rtrl. make comparison clear rtrl also quasi-diagonal approximation kalman filtering algorithm exact gradient computed rtrl. figure average log-loss synthetic music function number characters read units trained euclidean version nobacktrack algorithm different rank values rtrl learning rate benchmarked true model entropy rate gzip ctw. qdop-approximated kalman inverse covariance appears fully unstable behaviour. overall low-rank approximations appear roughly qdop rtrl. obvious gain particular example using higher-rank approximations. still particular task particular network size none algorithms match performance context tree weighting. rnns beat task trained using non-online riemannian gradient descent arguably effect imperfect online training. kalman nobacktrack truncated bptt. next experiments aims comparing kalman nobacktrack truncated bptt truncation parameter bptt truncates full gradient version bptt used here algorithm backtrack steps every time step rather waits steps backtracks steps collects gradients interval. otherwise truncated bptt would times slower unacceptable experiments. figure average log-loss synthetic music function number characters read units trained euclidean version nobacktrack algorithm different rank values rtrl learning rate benchmarked true model entropy rate gzip ctw. removing dependencies distances longer truncation parameter expect kalman nobacktrack learn better models datasets presenting long term correlations. algorithms first compared synthetic music dataset experimental setup above amount time learning rate kalman nobacktrack. results shown figure example truncated bptt perfoms better kalman nobacktrack even though algorithms display broadly comparable performance. noticeably rtrl truncated bptt roughly here truncated bptt slightly outperforming rtrl apparently maintaining long term dependencies gradient calculations improve learning synthetic music example. next compare nobacktrack truncated bptt specific ability learn precise middle long term dependencies present experiments 𝑎𝑛𝑏𝑛 example. clearly illustrate biased nature gradients computed truncated bptt. figure average log-loss synthetic music function number characters read units trained kalman/qdop version nobacktrack algorithm different rank values kalman/qdop rtrl benchmarked true model entropy rate gzip ctw. dataset synthesized sequentially picking number uniformly random outputting series followed line break another line break. true entropy rate example. roughly character long input sequence synthesized using standard models seem able deal example whatever training algorithm used leaky presented section fully connected units. algorithms used learning rate results reported figure also includes entropy rate exact 𝑎𝑛𝑏𝑛 model entropy rate 𝑎𝑛𝑏𝑝 model independent kalman nobacktrack clearly outperforms truncated bptt dataset. expected typical time range temporal dependencies exceeds truncation range bptt indeed bits needed encode value 𝑎𝑛𝑏𝑛 block average value average length 𝑎𝑛𝑏𝑛 block including newline symbols parameter lrnn learned sometimes produces numerical instabilities unless cumbersome changes variables introduced. initialized random value separately unit kept fixed. figure average log-loss synthetic music function number characters read units trained kalman/qdop version nobacktrack algorithm different rank values euclidean rtrl truncated bptt benchmarked true model entropy rate gzip ctw. dataset figure average log-loss 𝑎𝑛𝑏𝑛 function number characters read leaky units trained kalman/qdop version nobacktrack algorithm rtrl bptt. figure average log-loss shakespeare’s works function number characters read units trained qdop version nobacktrack algorithm different rank values euclidean rtrl truncated bptt benchmarked gzip ctw. keeping track long term dependencies here rtrl outperforms algorithms epochwise though still penalized high complexity. truncated bptt unable learn full dependencies ends closer entropy 𝑎𝑛𝑏𝑝 model independent values point learning curve truncated bptt appears decrease anymore even goes slightly consistent biased gradient estimate. hand kalman nobacktrack seems mostly successful learning dependencies. confirmed visual inspection output learned model. small remaining true model learned model could related incomplete training imperfect modelling exact uniform finally report performance truncated bptt kalman nobacktrack shakespeare’s works. -unit model used algorithms amount time using learning rate various ranks similar performance; clear whether differences figure statistically significant. proves more stochasticity rank reduction inherent nobacktrack detrimental learning allow keep exact gradient algorithms. conclusion. introduced algorithm computes stochastic provably unbiased estimate derivative current state dynamical system respect parameters fully online fashion. recurrent neural networks computational cost algorithm comparable running network itself. previously known algorithms either fully online significantly higher computational cost. experiments algorithm appears practical alternative truncated backpropagation time especially kalman version euclidean version requires smaller learning rates. noise rank reduction introduced gradient approximation appear prevent learning. interest nobacktrack respect truncated bptt depends situation hand especially scale time dependencies data whether storage past states past data required truncated bptt acceptable not. measure variance hilbert–schmidt norm ˜𝐴⃦⃦ norm satisfies⃦⃦𝑣𝑤⊤⃦⃦hs ‖𝑣‖‖𝑤‖ and⟨︀ hs−⃦⃦e ˜𝐴⃦⃦ evaluate variance norm. since ˜𝐴⃦⃦ fixed enough evaluate second moment ˜𝐴⃦⃦ however handling full covariance matrices would costly. algorithm inverse covariance already approximation matrixreduce. moreover access approximation thus simply replace definition diagonal reduction. leads diag note even approximations above still unbiased estimate indeed choice property; simply approximating optimal minimizes variance", "year": 2015}