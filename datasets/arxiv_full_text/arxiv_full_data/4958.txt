{"title": "Human Trajectory Prediction using Spatially aware Deep Attention Models", "tag": ["cs.LG", "cs.AI"], "abstract": "Trajectory Prediction of dynamic objects is a widely studied topic in the field of artificial intelligence. Thanks to a large number of applications like predicting abnormal events, navigation system for the blind, etc. there have been many approaches to attempt learning patterns of motion directly from data using a wide variety of techniques ranging from hand-crafted features to sophisticated deep learning models for unsupervised feature learning. All these approaches have been limited by problems like inefficient features in the case of hand crafted features, large error propagation across the predicted trajectory and no information of static artefacts around the dynamic moving objects. We propose an end to end deep learning model to learn the motion patterns of humans using different navigational modes directly from data using the much popular sequence to sequence model coupled with a soft attention mechanism. We also propose a novel approach to model the static artefacts in a scene and using these to predict the dynamic trajectories. The proposed method, tested on trajectories of pedestrians, consistently outperforms previously proposed state of the art approaches on a variety of large scale data sets. We also show how our architecture can be naturally extended to handle multiple modes of movement (say pedestrians, skaters, bikers and buses) simultaneously.", "text": "trajectory prediction dynamic objects widely studied topic ﬁeld artiﬁcial intelligence. thanks large number applications like predicting abnormal events navigation system blind etc. many approaches attempt learning patterns motion directly data using wide variety techniques ranging hand-crafted features sophisticated deep learning models unsupervised feature learning. approaches limited problems like inefﬁcient features case hand crafted features large error propagation across predicted trajectory information static artefacts around dynamic moving objects. propose deep learning model learn motion patterns humans using different navigational modes directly data using much popular sequence sequence model coupled soft attention mechanism. also propose novel approach model static artefacts scene using predict dynamic trajectories. proposed method tested trajectories pedestrians consistently outperforms previously proposed state approaches variety large scale data sets. also show architecture naturally extended handle multiple modes movement simultaneously. learning inference visual data gained tremendous prominence artiﬁcial intelligence research recent times. much breakthrough advances deep learning enabled vision image processing systems achieve near human precision many complex visual recognition tasks. paper present method learn predict dynamic spatio-temporal behaviour people moving using multiple navigational modes crowded scenes. humans possess ability effortlessly navigate crowded areas walking driving vehicle. propose end-to-end deep learning system learn constrained navigational behaviour considering multiple inﬂuencing factors neighbouring dynamic subjects also spatial context subject also show architecture naturally extended handle multiple modes simultaneously. subjects likely times initial observation time denotes -dimensional spatial co-ordinate vector target subject time words need predict values assume annotations spatial tracks unique subject participating scene. encoder decoder models initially introduced machine translation tasks followed automated question answering architectures encode incoming sequential data ﬁxed size hidden representation using recurrent neural network decode hidden representation using another produce sequentially temporal output. networks also modiﬁed introduce attention mechanism them. networks inspired attention mechanism humans possess visually. humans adjust focal point time focus speciﬁc region sight higher resolution surrounding area lower resolution. attention networks used successfully automatic ﬁne-grained image description/annotation helbing molnar’s social force model ﬁrst learn interaction patterns different objects attractive repulsive forces. since then several variants agent based modeling human attributes model priors learn behavioral patterns feature engineered approaches like alahi et.al. extract social afﬁnity features learn patterns explored. approaches include ﬁnding common object behaviour means clustering. giannotti analyzed traces several ﬂeets buses extracted patterns trajectories concise descriptions frequent behaviour temporally spatially. recently alahi et.al. captured interactions pedestrians using multiple long short term memory networks social pooling mechanism capture humanhuman interactions. captured dynamic interaction model failed understand static spatial semantics scene. spatial modeling exists include dynamic modeling crowd. none approaches naturally extend multiple classes moving subjects. earlier works include matching-based approaches rely keypoint feature matching techniques. slow compute since need match test image database images. also since direct matching approach semantic understanding scene. conventional approaches tend brittle since rely heavily hand-crafted features. deep learning approach also used spatial context modeling work hypothesizes dynamic objects static objects matched semantically based interaction other. authors assume random image patch scene contains enough evidence based discrimination likely patches unlikely patches made particular object. explore possibility adding additional static context around patches augment model. build distinction later section section describes solution detail organized follows. firstly describe proposed spatially static context network model static spatial context around subject interest. next deﬁne pooling mechanism captures inﬂuence neighboring subjects nearby static artefacts target subject. next describe complete model uses attention mechanism lstms learn patterns spatial co-ordinates subjects preserving spatial dynamic context around subjects interest. though lstms traditionally used model temporal dependencies sequential data along appropriate attention mechanism enables tasks like trajectory planning requires long-term dependency modeling. also show extends principle multiple classes moving subjects. modeling spatial context given scene challenging task since semantically representative also highly discriminative. also important model generalize variety complex scenes enable inferences human-space interactions them. proposed architecture composed convolutional neural networks inspired spatial matching network introduced although architecture similar proposed work differ signiﬁcantly approach ways. first redundant build input branch takes image patches different objects object belonging semantic class ideally spatial matching score particular random patch image. example matching score patch road hence need differentiate different cars. second might difﬁcult network look small scene patch infer matching score instance trained might learned different textures different static artefacts like road pavement textures could occur anywhere image. example texture roof particular scene could match texture pavement different scene image. important network information larger context region surrounding input patch. help network generalize better across different scenes better semantic understanding different complex scenes. incorporate hypothesis proposed network shown ﬁgure call network spatially static context network. network three input streams subject stream patch stream context stream. subject input stream input class label indicate whichever semantic class dynamic subject belongs input passed embedding layer followed dense fully connected layer. patch stream input image grid cell interest incorporate local context around patch also take part image surrounding cell. hence take size grid cell interest annulus width around thus ﬁnal size input patch becomes later re-sized ﬁxed pass input patch stack convolutional layers along pooling local response normalization layer followed dense fully connected layer shown ﬁgure third stream captures overall image context line second hypothesis. stream network incorporated introduce global context around image patch interest. input stream whole scene image re-sized ﬁxed dimension size another stack convolutional layers along pooling local response normalization layer followed dense fully connected layer extract hierarchical features scene image. train network merge input streams concatenating outputs respective dense fully connected layers stack fully connected layers followed fully-connected output layer. output layer consists single sigmoid neuron giving likelihood subject type stepping given patch ground truth likelihood training value associated grid cell interest train model triplets subject type patch image minimizing cross entropy actual likelihood µsρζ predicted likelihood ˆµsρζ log) ground truth likelihood value patch computed counting frequency unique subjects type occupying patch time course individual trajectories dividing total number unique subjects type scene. note constructed annotated videos tracking counting incidence subject video every patch subsample video frames. model trained subsample frames videos formed training dataset. describe pool static dynamic contexts given frame sample along representation historical trajectory. subscript indicate fact pooling done speciﬁc frame. humans moving crowded area adapt motion based behaviour people around them. example pedestrians often completely alter paths someone else group people approaching them. behaviour cannot predicted observing pedestrian isolation without considering surrounding dynamic static context. behaviour motivated pooling mechanism social lstm model. borrow pooling mechanism capture inﬂuences neighbouring subjects model. lstms learn efﬁcient hidden representation temporal behaviour subjects part encoder. since hidden representations would capture subject’s behaviour observed time step representations capture inﬂuence neighbouring subjects would target subject. consider spatial neighbourhood size around moving subject turn subdivided grid grid cell size denote lstm encoded hidden representation subject type time also number subject classes. construct social tensors size capture social context structured described earlier sscn model designed predict likelihood subject like pedestrian stepping speciﬁc input image patch given larger context around patch scene itself. provide surrounding context subject current position turn inﬂuences next position subject. ﬁrst build spatial subject class location frame video probabilities subject class ever visiting location. built ofﬂine using pretrained sscn network described section given subsample frames every frame sample patch subject class build sscn extract reachability tensor subject time static context collection patches size basically construct center. work take encoder-decoder architecture base model apply soft attention mechanism motivation applying attention mechanism straight-forward. subjects often change pre-panned trajectories suddenly ’context’ changes. imagine pedestrian airport walking towards security suddenly realizing he/she needs pick baggage result making sharp course-correction move towards check-in counter. since model proposed alahi takes last time step hidden representation pedestrian interest model responsive immediate instincts like collision avoidance useful long term path planning. moreover model starts predictions even small error prediction could mean erroneous hidden representations propagated future time steps. full architecture spatio-temporal attention model shown ﬁgure embedding matrices sigmoid function. next three embeddings concatenated form input encoder. encoder outputs ﬁxed size hidden state representation context vector depends encoder hidden states occuring ﬁxed size temporal attention window size makes possible network dynamically generate different context vectors different timesteps knowledge encoded states back time. follow previously proposed attention mechanism like bahdanau compute attention weights context vector generated attention mechanism puts emphasis encoder states generates ’behaviour context’ subject interest. context vector feeds decoder unit generate decoder states. decoder turn generates -tuple output representing parameters bivariate gaussian distribution predicted position subject next time step. denoting decoder state time decoder state predicted bivariate gaussian model note position time taken actual ground truth value time training model predicted value inference. model trained multiple classes subjects separate model individual class. model therefore accounts current spatial coordinates social context incorporates moving subjects scene static context accounts reachability subjects across patches scene. train network maximizing likelihood ground truth position generated predicted distribution. hence jointly learn parameters minimizing negative trajectory. important aspect training phase that since lstm layers encoder decoder units shared subjects particular type parameters models learned jointly. thus back-propagate loss trajectory subject type every time step three large scale multi-object tracking datasets stanford drone dataset datasets consist scenes unique pedestrians entering exiting scenes. includes challenging scenarios like groups people walking together different groups people crossing also behaviour pedestrian deviating completely it’s followed path almost instantaneously. hand stanford drone dataset consists multiple aerial imagery comprising different locations around stanford campus objects belonging different classes moving around. trajectories pedestrians train test models. hyperparameters model using cross validation strategy following leave approach. sscn model take size grid patch stream re-sized input dimension input dimension context stream overall network trained using learning rate gradient descent optimizer batch size compare results previous state model s-lstm limit subject type pedestrians. common hyperparameters spatio-temporal attention model theirs. trajectories downsampled retain every frames. observe trajectories period time steps attentional window length time steps predict future time steps reachability distance also limit number pedestrians frame model trained using learning rate rmsprop optimizer. evaluation metrics proposed alahi et.al. average displacement error euclidean distance predicted trajectory actual trajectory averaged time-steps pedestrians final displacement error average euclidean distance predicted trajectory point actual trajectory point time steps. build separate models complete problem statement dynamic context pooling coupled attention mechanism denote d-att model second static context pooling added d-att model denote sd-att. cannot test sd-att model datasets resolution videos datasets makes impossible sscn model static context pooling. still consistently outperform s-lstm o-lstm models evaluation metrics three datasets shown table also show results sd-att model stanford drone dataset much better social lstm model. demonstrate scenarios models perform better s-lstm model. firstly figure show results sscn model. second column ﬁgure shows example constructed saliency shade blue denoting likelihood value corresponding patch. likelihood values near roundabout trees high areas road pavement. rest ﬁgures unique pedestrian depicted unique colour. figure ﬁrst column shows sd-att model learned predict linear trajectories well. next columns depict collision avoidance property learned model. examples model either decelerates pedestrian diverts avoid collision. figure compares predictions sd-att model social lstm model. since s-lstm model considers last time step’s hidden representation thinks pedestrian wants take turn hence follows curved path. hand sd-att model interprets sharp turn since seen change behaviour last time steps hence takes gradual turn. demonstrates advantage using attention mechanism. figure demonstrates advantage static spatial pooling. examples shown pedestrian walks straight time steps s-lstm d-att propose novel deep learning approach problem human trajectory prediction. model successfully extracts motion patterns unsupervised manner. compared previous state works approach models dynamic spatial context around type subject interest results better prediction trajectories. proposed method outperforms previous state method three large scale datasets. addition this also propose novel based sscn architecture helps better semantic understanding scene. future work includes evaluating proposed models multiple classes objects.", "year": 2017}