{"title": "Robustness of classifiers: from adversarial to random noise", "tag": ["cs.LG", "cs.CV", "stat.ML"], "abstract": "Several recent works have shown that state-of-the-art classifiers are vulnerable to worst-case (i.e., adversarial) perturbations of the datapoints. On the other hand, it has been empirically observed that these same classifiers are relatively robust to random noise. In this paper, we propose to study a \\textit{semi-random} noise regime that generalizes both the random and worst-case noise regimes. We propose the first quantitative analysis of the robustness of nonlinear classifiers in this general noise regime. We establish precise theoretical bounds on the robustness of classifiers in this general regime, which depend on the curvature of the classifier's decision boundary. Our bounds confirm and quantify the empirical observations that classifiers satisfying curvature constraints are robust to random noise. Moreover, we quantify the robustness of classifiers in terms of the subspace dimension in the semi-random noise regime, and show that our bounds remarkably interpolate between the worst-case and random noise regimes. We perform experiments and show that the derived bounds provide very accurate estimates when applied to various state-of-the-art deep neural networks and datasets. This result suggests bounds on the curvature of the classifiers' decision boundaries that we support experimentally, and more generally offers important insights onto the geometry of high dimensional classification problems.", "text": "several recent works shown state-of-the-art classiﬁers vulnerable worst-case perturbations datapoints. hand empirically observed classiﬁers relatively robust random noise. paper propose study semi-random noise regime generalizes random worst-case noise regimes. propose ﬁrst quantitative analysis robustness nonlinear classiﬁers general noise regime. establish precise theoretical bounds robustness classiﬁers general regime depend curvature classiﬁer’s decision boundary. bounds conﬁrm quantify empirical observations classiﬁers satisfying curvature constraints robust random noise. moreover quantify robustness classiﬁers terms subspace dimension semi-random noise regime show bounds remarkably interpolate worst-case random noise regimes. perform experiments show derived bounds provide accurate estimates applied various state-of-the-art deep neural networks datasets. result suggests bounds curvature classiﬁers’ decision boundaries support experimentally generally offers important insights onto geometry high dimensional classiﬁcation problems. state-of-the-art classiﬁers especially deep networks shown impressive classiﬁcation performance many challenging benchmarks visual tasks speech processing equally important property classiﬁer often overlooked robustness noisy regimes data samples perturbed noise. robustness classiﬁer especially fundamental deployed real-world uncontrolled possibly hostile environments. cases crucial classiﬁers exhibit good robustness properties. words sufﬁciently small perturbation datapoint ideally result altering estimated label classiﬁer. state-of-the-art deep neural networks recently shown unstable worst-case perturbations data particular despite excellent classiﬁcation performances classiﬁers well-sought perturbations data easily cause misclassiﬁcation since data points often close decision boundary classiﬁer. despite importance result worst-case noise regime studied represents speciﬁc type noise. furthermore requires full knowledge classiﬁcation model hard assumption practice. paper precisely quantify robustness nonlinear classiﬁers practical noise regimes namely random semi-random noise regimes. random noise regime datapoints perturbed noise random direction input space. semi-random regime generalizes model random subspaces arbitrary dimension worst-case perturbation sought within subspace. cases derive bounds precisely describe robustness classiﬁers function curvature decision boundary. summarize contributions follows distance datapoint classiﬁcation boundary provided curvature decision boundary sufﬁciently small. result highlights blessing dimensionality classiﬁcation tasks implies robustness random noise high dimensional classiﬁcation problems achieved even datapoints close decision boundary. quantiﬁcation notably extends general semi-random regime show dimension subspace. result shows particular that even chosen small fraction dimension still possible small perturbations cause data misclassiﬁcation. empirically show theoretical estimates accurately satisﬁed stateof-the-art deep neural networks various sets data. turn suggests quantitative insights curvature decision boundary support experimentally visualization estimation two-dimensional sections boundary. robustness classiﬁers noise subject intense research. robustness properties classiﬁers studied example robust optimization approaches constructing robust classiﬁers proposed minimize worst possible empirical error noise disturbance recently following recent results instability deep neural networks worst-case perturbations several works provided explanations phenomenon designed robust networks authors provide interesting empirical analysis adversarial instability show adversarial examples isolated points rather occupy dense regions pixel space. state-of-the-art classiﬁers shown vulnerable geometrically constrained adversarial examples. work differs works provide theoretical study robustness classiﬁers random semi-random noise terms robustness adversarial noise. formal relation robustness random noise worst-case robustness established case linear classiﬁers. result therefore generalizes many aspects study general nonlinear classiﬁers robustness semi-random noise. finally noted authors conjecture high linearity classiﬁcation models explains instability adversarial perturbations. objective approach follow however different study theoretical relations robustness random semi-random adversarial noise. deﬁnitions notations l-class classiﬁer. given datapoint estimated label obtained argmaxk component corresponds class. arbitrary subspace dimension here interested quantifying robustness respect different noise regimes. deﬁne minimal norm required change estimated label r∗rd adversarial perturbation deﬁned corresponds perturbation minimal norm changes label datapoint words corresponds minimal distance classiﬁer boundary. case perturbations along allowed. robustness along naturally measured norm different choices permit study robustness different regimes random noise regime corresponds case one-dimensional subspace direction random vector sampled uniformly unit sphere sd−. writing explicitly study regime robustness quantity deﬁned mint s.t. vector sampled uniformly random unit sphere sd−. semi-random noise regime case subspace chosen randomly arbitrary dimension semi-random terminology subspace chosen randomly smallest vector causes misclassiﬁcation sought subspace. noted random noise regime special case semi-random regime subspace dimension differentiate nevertheless regimes clarity. remainder paper goal establish relations robustness random semi-random regimes hand robustness adversarial perturbations hand. recall latter quantity captures distance classiﬁer boundary therefore quantity analysis robustness. following analysis datapoint classiﬁed simplify notation remove explicit dependence notations implicitly understood quantities pertain ﬁxed datapoint following result shows precise relation robustness semi-random noise robustness adversarial perturbations theorem random m-dimensional subspace l-class afﬁne classiﬁer. proof found appendix. upper lower bounds depend functions control inequality constants noted independent data dimension fig. shows plots functions ﬁxed noted sufﬁciently large close belong interval settings fig. interval however larger result theorem shows random semi-random noise regimes robustness high probability constants interval results therefore show that high dimensional classiﬁcation settings afﬁne classiﬁers robust random noise even datapoint lies closely decision boundary small). semi-random noise regime sufﬁciently large probability constants sufﬁciently large bounds therefore interpolate random noise regime behaves √dr∗ worst-case noise importantly square root dependence also notable here shows semirandom robustness remain small even regimes chosen small fraction example choosing small subspace dimension results semi-random robustness high probability might still perceptible complex visual tasks. hence semi-random noise mostly random mildly adversarial afﬁne classiﬁers remain vulnerable noise. consider general case nonlinear classiﬁer. derive relations random semi-random robustness worst-case robustness using properties classiﬁer’s boundary. arbitrary classes; deﬁne pairwise boundary boundary binary classiﬁer classes considered. formally decision boundary reads follows assume purpose analysis boundary smooth. interested geometric properties boundary namely curvature. many notions curvature deﬁne hypersurfaces simple case curve two-dimensional space curvature deﬁned inverse radius so-called oscullating circle. deﬁne curvature high-dimensional hypersurfaces taking normal sections hypersurface looking curvature resulting planar curve however introduce notion curvature speciﬁcally suited analysis decision boundary classiﬁer. informally curvature captures global bending decision boundary inscribing balls regions separated decision boundary. formally deﬁne notion curvature. given deﬁne radius largest open ball included region intersects i.e. open ball center radius illustration quantity dimensions provided fig. hard ball centered included tangent space coincide tangent decision boundary point. noted deﬁnition symmetric i.e. radius largest ball inscribe regions need equal. therefore deﬁne following symmetric quantity worst-case ball inscribed regions considered deﬁnition describes curvature decision boundary locally ﬁtting largest ball included regions. measure global curvature worst-case radius taken points decision boundary i.e. case afﬁne classiﬁers possible inscribe balls inﬁnite radius inside region space. classiﬁcation boundary union spheres equal radius curvature general quantity provides intuitive describing nonlinearity decision boundary ﬁtting balls inside classiﬁcation regions. following section show precise characterization robustness semi-random random noise nonlinear classiﬁers terms curvature decision boundaries establish bounds robustness random semi-random noise binary classiﬁcation case. datapoint classiﬁed ﬁrst study binary classiﬁcation problem classes l}\\{ˆk} considered. simplify notation bkˆk decision boundary classes case binary classiﬁcation problem classes considered semi-random robustness adversarial robustness deﬁned re-written follows random semi-random robustness classiﬁer randomly chosen subspace setting classes considered. likewise denotes worst-case robustness setting. noted global quantities obtained provided curvature boundary sufﬁciently small. case linear classiﬁers recover result afﬁne classiﬁers theorem extend result multi-class classiﬁcation special care taken. particular denotes class boundary class previous curvature condition cannot satisﬁed. therefore crucial exclude classes boundary common class generally boundaries class deﬁne excluded classes large note independent depends moreover constants chosen simplicity exposition. assuming curvature constraint close enough classes following result establishes simpliﬁed relation corollary random m-dimensional subspace assume that probability larger curvature condition boundaries classes result shows robustness random semi-random noise exhibits behavior observed earlier linear classiﬁers theorem particular precisely related becomes shows high dimensional classiﬁcation problems classiﬁers sufﬁciently boundaries much robust random noise adversarial noise. precisely addition sufﬁciently small random noise change label image even image lies closely decision boundary small). however semi-random regime adversarial perturbation found randomly chosen subspace dimension shows robustness semi-random noise might achieved even chosen tiny fraction words classiﬁer highly vulnerable adversarial perturbations also vulnerable noise overwhelmingly random mildly adversarial important note curvature condition assumption curvature global decision boundary rather assumption decision boundaries pairs classes. distinction signiﬁcant junction points decision boundaries meet might actually large curvature curvature condition typically hold global curvature deﬁnition. refer experimental section visualization phenomenon. ﬁnally stress results theorem corollary applicable classiﬁer provided decision boundaries smooth. assume prior knowledge considered family classiﬁers decision boundaries similar bounds derived less restrictive curvature conditions evaluate robustness different image classiﬁers random semi-random perturbations assess accuracy bounds various datasets state-of-the-art classiﬁers. chosen randomly sample denotes test set. quantity provides equal since random quantity report mean standard deviation different networks table noted ﬁnding involves solving optimization problem used similar approach subspace minimal perturbations. network estimate expectation averaging random samples also chosen randomly sample. observe suprisingly close even small fraction shows quantitative analysis provide accurate estimates robustness semi-random noise. visualize robustness random noise semi-random noise worst-case perturbations sample image fig. random noise clearly perceptible value thanks factor attenuates required noise misclassify datapoint. noted robustness neural networks adversarial perturbations previously observed empirically provide quantitative generic explanation phenomenon. figure original image classiﬁed cauliﬂower. fooling perturbations vgg-f network random noise semi-random perturbation worst-case perturbation wrongly classiﬁed artichoke. high accuracy bounds different state-of-the-art classiﬁers different datasets suggest decision boundaries classiﬁers limited curvature assumption theoretical ﬁndings. support validity curvature hypothesis practice visualize two-dimensional sections classiﬁers’ boundary fig. three different settings. note opted visualization strategy rather numerical estimation latter quantity difﬁcult approximate practice high dimensional problems. fig. chosen randomly test data decision boundaries random direction different shown plane spanned colors boundary correspond boundaries different classes. observed curvature boundary small except junction points boundary different classes intersect. curvature assumption assumes bound curvature decision boundary pairs classes therefore adequate decision boundaries state-of-the-art classiﬁers according fig. interestingly assumption corollary satisﬁed taking empirical estimate curvature planar curves fig. dimension subspace small fraction e.g. reﬂecting curvature drives assumption theoretical analysis result still seems suggest curvature assumption holds practice curvature classiﬁers therefore small. noted related empirical observation made work however provides precise quantitative analysis relation curvature robustness semi-random noise regime. figure boundaries three classiﬁers near randomly chosen samples. axes normalized corresponding since assumption theoretical bound depends product r∗κ. note difference range axes. note also range horizontal axis much smaller hence illustrated boundary curved. show simple demonstration vulnerability classiﬁers semi-random noise fig. structured message hidden image causes data misclassiﬁcation. speciﬁcally consider span random translated scaled versions words nips spain image resulting perturbations subspace therefore linear combinations words different intensities. perturbed image shown fig. clearly indistinguishable fig. shows imperceptibly small structured messages added image causing data misclassiﬁcation. work precisely characterized robustness classiﬁers novel semi-random noise regime generalizes random noise regime. speciﬁcally bounds relate robustness regime robustness adversarial perturbations. bounds depend curvature decision boundary data dimension dimension subspace perturbation belongs. results show particular decision boundary small curvature classiﬁers robust random noise high dimensional classiﬁcation problems moreover semi-random noise mostly random mildly adversarial results show state-of-the-art classiﬁers remain vulnerable perturbations. improve robustness semi-random noise analysis encourages impose geometric constraints curvature decision boundary shown existence intimate relation robustness classiﬁers curvature decision boundary. this example departs somehow theoretical framework paper random subspaces considered. however empirical example suggests theoretical ﬁndings paper seem approximately hold subspace statistics close random subspace. would like thank anonymous reviewers helpful comments. thank omar fawzi louis merlin fruitful discussions. also gratefully acknowledge support nvidia corporation donation tesla used research. work partly supported hasler foundation switzerland framework cora project. hinton deng dahl mohamed jaitly senior vanhoucke nguyen sainath kingsbury deep neural networks acoustic modeling speech recognition shared views four research groups. ieee signal process. mag. szegedy zaremba sutskever bruna erhan goodfellow fergus intriguing properties neural networks. international conference learning representations tabacof valle exploring space adversarial images. ieee international joint projection ﬁxed vector onto random dimensional subspace equivalent projection random vector uniformly sampled ﬁxed subspace. projection onto ﬁrst coordinates. following result show that curvature planar curve constant sufﬁciently small distance point curve speciﬁc direction well approximated distance straight line lemma planar curve constant curvature denote distance point curve denote moreover tangent closest point angle depicted fig. assume proof lower bound. curve convex shaped desired lower bound holds. focus therefore case concave shape coincides following equation holds using simple geometric arguments figure left prove upper bound consider ball included intersects boundary upper bounds derived boundary also valid upper bounds real boundary right normal section decision boundary along plane tx∗bk tangent space sphere proof upper bound. denote point belonging boundary closest original data point deﬁnition curvature exists point ball centered radius inscribed region fˆk} observe worst-case perturbation along subspace reaches ball larger perturbation along reaches region therefore upper bound derived boundary sphere radius i.e. also valid upper bound boundary therefore sufﬁcient derive upper bound worst case scenario boundary consider case remainder proof upper bound. consider linear classiﬁer whose boundary tangent random subspace worst-case subspace perturbation linear classiﬁer. focus intersection denote ﬁxed point boundary maximal radius might achieved. prove result general case supremum achieved consider instead sequence converging balls radius intersecting boundary included proof results follow taking limit bounds derived ball radius /κn. boundary two-dimensional plane spanned vectors normal section boundary cuts ball center tangent spaces decision boundary ball coincide. fig. clarifying ﬁgure two-dimensional cross-section. deﬁne angle denoted fig. concludes proof upper bound. proof lower bound. consider ball center radius included region rˆk. since ball deﬁnition included region worst-case occurs whenever decision boundary coincides ball scenario lower bound consider case remainder proof. derive lower bound consider cross-section spanned vectors using lower bound lemma obtain figure left prove lower bound consider ball included intersects boundary lower bounds derived boundary sphere also valid lower bounds real boundary right cross section problem along figure worst-case perturbation subspace decision boundary tangent space arbitrary subspace denote worst-case perturbations subspace decision boundaries respectively then perturbations proof. assuming center ball origin points sphere satisfy equation denotes radius. hence perturbation", "year": 2016}