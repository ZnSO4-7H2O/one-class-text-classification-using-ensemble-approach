{"title": "Expressing Implicit Semantic Relations without Supervision", "tag": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "H.3.1; I.2.6; I.2.7"], "abstract": "We present an unsupervised learning algorithm that mines large text corpora for patterns that express implicit semantic relations. For a given input word pair X:Y with some unspecified semantic relations, the corresponding output list of patterns <P1,...,Pm> is ranked according to how well each pattern Pi expresses the relations between X and Y. For example, given X=ostrich and Y=bird, the two highest ranking output patterns are \"X is the largest Y\" and \"Y such as the X\". The output patterns are intended to be useful for finding further pairs with the same relations, to support the construction of lexicons, ontologies, and semantic networks. The patterns are sorted by pertinence, where the pertinence of a pattern Pi for a word pair X:Y is the expected relational similarity between the given pair and typical pairs for Pi. The algorithm is empirically evaluated on two tasks, solving multiple-choice SAT word analogy questions and classifying semantic relations in noun-modifier pairs. On both tasks, the algorithm achieves state-of-the-art results, performing significantly better than several alternative pattern ranking algorithms, based on tf-idf.", "text": "present unsupervised learning algorithm mines large text corpora patterns express implicit semantic relations. given input word pair unspecified semantic relations corresponding output list ranked according patterns well pattern expresses relations example given highest ranking output patterns largest output patterns intended useful finding pairs relations support construction lexicons ontologies semantic networks. patterns sorted pertinence pertinence pattern expected relational similarity given pair typical pairs algorithm empirically evaluated tasks solving multiple-choice word analogy questions classifying semantic relations noun-modifier pairs. tasks algorithm achieves stateof-the-art results performing significantly better several alternative pattern ranking algorithms based tf-idf. widely cited paper hearst showed lexico-syntactic pattern used mine large text corpora word pairs hyponym example search large corpus using pattern find string bird ostrich infer ostrich hyponym bird. berland charniak demonstrated patterns used consider inverse problem given word pair unspecified semantic relations mine large text corpus lexico-syntactic patterns express implicit relations example given pair ostrichbird discover pattern particularly interested discovering high quality patterns reliable mining word pairs semantic relations. experiments corpus pages containing english words co-occurrences pair ostrichbird corpus generate patterns form patterns form patterns useful text mining. main challenge find ranking patterns patterns like highly ranked. another challenge find empirically evaluate performance pattern ranking algorithm. unspecified semantic relations rank corresponding output list patterns order decreasing pertinence. pertinence pattern expected relational similarity given pair typical pairs define pertinence precisely section hearst suggests work useful building thesaurus. berland charniak suggest work useful building lexicon ontology like wordnet. algorithm also applicable tasks. potential applications related problems discussed section pattern high pertinence used text mining tend produce word pairs similar given word pair; follows definition pertinence. believe definition first formal measure quality text mining patterns. hearst describes method finding patterns like method requires human charniak hearst’s manual procedure. riloff jones mutual bootstrapping technique find patterns automatically bootstrapping requires initial seed manually chosen examples class words. miller propose approach relation extraction evaluated seventh message understanding conference algorithm requires labeled examples relation. similarly zelenko supervised kernel method requires labeled training examples. agichtein gravano also require training examples relation. brin uses bootstrapping seed examples authortitle pairs discover patterns mining pairs. yangarber yangarber present algorithm find patterns automatically requires initial seed manually designed patterns semantic relation. stevenson uses wordnet extract relations text also requires initial seed patterns relation. according value mining text support semantic network construction similar tasks. unfortunately difficult measure performance tasks. therefore experiments based tasks provide objective performance measures. section ranking algorithms compared performance solving multiple-choice word analogy questions. section compared performance classifying semantic relations noun-modifier pairs. experiments demonstrate ranking pertinence significantly better several alternative pattern ranking algorithms based tf-idf. performance pertinence tasks slightly best performance reported difference statistically significant. relational similarity pairs words degree semantic relations analogous. example masonstone carpenterwood high degree relational similarity. measuring relational similarity discussed section assume measure relational similarity pairs words examines task expressing implicit relations nominalizations noun compounds whose head noun derived verb whose modifier interpreted argument verb. contrast work algorithm restricted nominalizations. section shows algorithm works arbitrary noun compounds questions section include nine possible pairings nouns verbs adjectives. know algorithm first unsupervised learning algorithm find patterns semantic relations given large corpus moderately sized word pairs members pair appear together frequently short phrases corpus. word pairs seeds since algorithm require pairs labeled grouped; assume homogenous. word pairs need could generated automatically searching word pairs co-occur frequently corpus. however evaluation methods involve predetermined list word pairs. algorithm allowed generate word pairs overlap predetermined lists would likely small. limitation evaluation methods rather algorithm. since word pairs relations common shared algorithm generates unique list patterns input word pair. example masonstone carpenterwood share pattern carves patterns nails bends unique carpenterwood. ranked list patterns word pair gives relations corpus sorted pertinent relations first. turney gives algorithm measuring relational similarity pairs words called latent relational analysis algorithm used solve multiplechoice word analogy questions classify noun-modifier pairs attempt express implicit semantic relations. turney maps pair high-dimensional vector value element based frequency pair relational similarity pairs derived cosine angle vectors. limitation approach semantic content vectors difficult interpret; magnitude element good indicator pertinence builds measure relational similarity turney advantage semantic content interpreted; point specific patterns express implicit relations. furthermore patterns find pairs relations. hearst processed text partof-speech tagger unification-based constituent analyzer. makes possible general patterns. example instead literal string pattern words hearst used abstract pattern represents noun phrase. sake simplicity avoided part-of-speech tagging limits literal patterns. plan experiment tagging future work. algorithm takes input word pairs produces output ranked lists patterns input pair. following steps similar algorithm turney several changes support calculation pertinence. find phrases pair make list phrases corpus contain pair. waterloo multitext system search corpus english words make list phrases begin second list opposite order. phrase must three intervening words first last words phrase need exactly match multitext query language allows different suffixes. veale observed easier identify semantic relations nouns parts speech. therefore wordnet guess whether likely nouns. nouns relatively strict suffixes; allow variation pluralization. parts speech liberal suffixes. example allow adjective inflated match noun inflation. multitext query inflat* matches inflated inflation. generate patterns list phrases generate list patterns based phrases. replace first word phrase generic marker replace last word intervening words phrase weight patterns vary substantially frequency pair. apply entropy transforms apply singular value decomposition decomposes product three matrices tvus column orthonormal form diagonal matrix singular values rank diagonal matrix formed singular values matrices produced selecting corresponding columns matrix matrix rank best approximates original matrix sense approximation errors following landauer dumais think matrix smoothed version original matrix. used reduce noise compensate sparseness calculate cosines relational similarity pairs given cosine angle corresponding matrix calculate pertinence need relational similarity between possible pairs pairs. cosines efficiently derived matrix calculate conditional probabilities using bayes’ theorem frequency data matrix step entropy transforms calculate conditional probability every every column calculate pertinence cosines step conditional probabilities step calculate every possible avoid calculating pertinence cases reasons. first speeds computation because sparse rows columns. second actually appear plies pattern word pair corpus; guessing pattern appropriate word pair could wrong. therefore prefer limit patterns word pairs actually observed corpus. pair output separate ranked lists patterns form another patterns form either left replaced wildcard example phrase carpenter nails wood yields patterns nails nails allow duplicate patterns list note number times pattern generated word pair first last vice versa). call pattern frequency. local frequency count analogous term frequency information retrieval. count pair frequency pair frequency pattern number lists preceding step contain given pattern. global frequency count analogous document frequency information retrieval. note pair yields lists phrases hence lists patterns. given pattern might appear zero lists pairs rows preparation building matrix create mapping word pairs create numbers. pair already contain effectively doubled number word pairs increases sample size calculating pertinence. patterns columns create mapping patterns column numbers. unique pattern form step create column original pattern another column pattern swapped step generate millions distinct patterns. experiment section results distinct patterns yielding columns. many columns matrix operations today’s standard desktop computer. patterns pair frequency. experiment section patterns pair frequency one. keep matrix manageable drop patterns pair frequency less ten. section leaves patterns yielding columns. turney limited matrix columns larger pool patterns better purposes since increases likelihood finding good patterns expressing semantic relations given word pair. build sparse matrix build matrix sparse matrix format. value cell column pattern frequency j-th pattern i-th word pair. calculate entropy apply entropy transformations sparse matrix cell replaced logarithm multiplied weight based negative entropy corresponding column vector matrix. gives patterns lists sorted order decreasing pertinence ranking serves kind normalization. found relative rank pattern reliable indicator importance absolute pertinence. analogous information retrieval documents ranked order relevance query. relative rank document important actual numerical score separate ranked lists helps avoid bias. example ostrichbird generates patterns form patterns form since patterns form slight bias towards patterns. lists merged patterns would disadvantage. experiments evaluate pertinence using college-level multiple-choice word analogies taken test. question target word pair called stem pair five choice pairs. task find choice analogous stem. choice pair called solution choices distractors. since word pairs question pairs input step algorithm double pairs also drop pairs co-occur corpus. leaves rows matrix. mentioned step matrix columns sparse matrix density answer question generate ranked lists patterns word pairs. choice evaluated taking intersection patterns stem’s patterns. shared patterns scored average rank stem’s lists choice’s lists. since lists sorted order decreasing pertinence score means high pertinence. guess choice lowest scoring shared pattern. table shows three examples questions answered correctly followed answered incorrectly. correct answers bold font. first question stem ostrichbird best choice lioncat. highest ranking pattern shared pairs third question illustrates that even answer incorrect best shared pattern plausible. word pair ostrichbird lioncat gooseflock ewesheep cubbear primatemonkey trafficstreet shipgangplank cropharvest cargarage pedestriansfeet waterriverbed locomotivetrain horsesaddle tractorplow rudderrowboat cameldesert gasolineautomobile powered table three examples questions. table shows four highest ranking patterns stem solution first example. pattern lion anomalous patterns seem reasonable. shared pattern ranked pairs hence average score pattern shown table note ostrich largest bird lions large cats largest siberian tiger. table compare ranking patterns pertinence ranking various measures mostly based varieties tf-idf tf-idf measures taken salton buckley comparison also include three algorithms rank pattern ranking algorithms given exactly sets patterns rank. differences performance ranking method alone. algorithms skip questions word pairs co-occur corpus. ranking algorithms skip questions. precision defined percentage correct answers questions answered recall percentage correct answers maximum possible number correct measure harmonic mean precision recall. tf-idf methods table pattern frequency pair frequency maximum patterns given word pair total number word pairs. example mean plays role analogous term frequency plays role analogous inverse document frequency. patterns ranked decreasing order pattern frequency divided pair frequency. table also shows ranking methods based intermediate calculations algorithm section example table gives results patterns ranked order decreasing values corresponding cells matrix step rank patterns. results support claim made section suitable ranking patterns although works well answering questions vectors yield good measure relational similarity magnitude value specific element vector good indicator quality corresponding pattern. best method ranking patterns pertinence point comparison performance average senior highschool student analogies second best method values matrix entropy transformations step difference methods statistically significant confidence. pertinence performs slightly latent relational analysis difference significant. randomly guessing answers yield ranking patterns randomly results stem pair tends share patterns solution pair distractors. minimum large random numbers likely lower minimum small random numbers. experiments evaluate pertinence task classifying noun-modifier pairs. problem classify noun-modifier pair virus according semantic relation head noun modifier example virus classified causality relation experiments manually labeled noun-modifier pairs five general classes labels thirty subclasses. present results five classes; results thirty subclasses follow trends five classes causality temporality spatial participant quality input consists nounmodifier pairs. doubled step drop pairs co-occur corpus leaving rows matrix. distinct patterns pair frequency more resulting columns. matrix density classify noun-modifier pair single nearest neighbour algorithm leave-onecross-validation. split times. pair gets turn single testing example pairs serve training examples. testing example classified according label nearest neighbour training set. distance nounmodifier pairs measured average rank best shared pattern. table shows resulting precision recall ranking patterns pertinence. gain insight algorithm examined best shared patterns pair single nearest neighbour. five classes table lists frequent pattern among best shared patterns given class. patterns seem appropriate respective classes. table gives performance pertinence noun-modifier problem compared various pattern ranking methods. bottom rows included comparison; pattern ranking algorithms. best method ranking patterns pertinence difference pertinence second best ranking method statistically significant confidence. latent relational analysis performs slightly better pertinence difference statistically significant. table shows results would using latent relational analysis rank patterns. again results support claim section suitable ranking patterns. classify nounmodifiers cannot express implicit semantic relations make unlabeled noun-modifier testing similar nearest neighbour training set. computing pertinence took hours experiments section hours section cases majority time spent step using multitext search corpus words. multitext running beowulf cluster sixteen intel xeon cpus. corpus search index require terabyte disk space. seem computationally demanding today’s standards progress hardware soon allow average desktop computer handle corpora size. although performance analogy questions near level average senior highschool student room improvement. applications building thesaurus lexicon ontology level performance suggests algorithm could assist replace human expert. possible improvement would part-of-speech tagging parsing. done preliminary experiments parsing plan explore tagging well. difficulty much text corpus consist properly formed sentences since text comes pages. poses problems part-of-speech taggers parsers. black box. main contribution paper idea pertinence allows take opaque measure relational similarity find patterns express implicit semantic relations words. experiments sections show ranking patterns pertinence superior ranking variety tf-idf methods. word analogy noun-modifier tasks pertinence performs well state-of-the-art pertinence goes beyond making relations explicit.", "year": 2006}