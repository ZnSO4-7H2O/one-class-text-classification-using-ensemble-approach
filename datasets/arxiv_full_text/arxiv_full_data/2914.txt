{"title": "Ensembles of Deep LSTM Learners for Activity Recognition using Wearables", "tag": ["cs.LG", "cs.AI", "cs.CV"], "abstract": "Recently, deep learning (DL) methods have been introduced very successfully into human activity recognition (HAR) scenarios in ubiquitous and wearable computing. Especially the prospect of overcoming the need for manual feature design combined with superior classification capabilities render deep neural networks very attractive for real-life HAR application. Even though DL-based approaches now outperform the state-of-the-art in a number of recognitions tasks of the field, yet substantial challenges remain. Most prominently, issues with real-life datasets, typically including imbalanced datasets and problematic data quality, still limit the effectiveness of activity recognition using wearables. In this paper we tackle such challenges through Ensembles of deep Long Short Term Memory (LSTM) networks. We have developed modified training procedures for LSTM networks and combine sets of diverse LSTM learners into classifier collectives. We demonstrate, both formally and empirically, that Ensembles of deep LSTM learners outperform the individual LSTM networks. Through an extensive experimental evaluation on three standard benchmarks (Opportunity, PAMAP2, Skoda) we demonstrate the excellent recognition capabilities of our approach and its potential for real-life applications of human activity recognition.", "text": "recently deep learning methods introduced successfully human activity recognition scenarios ubiquitous wearable computing. especially prospect overcoming need manual feature design combined superior classiﬁcation capabilities render deep neural networks attractive real-life applications. even though dl-based approaches outperform state-of-the-art number recognition tasks still substantial challenges remain. prominently issues real-life datasets typically including imbalanced datasets problematic data quality still limit eﬀectiveness activity recognition using wearables. paper tackle challenges ensembles deep long short term memory networks. lstm networks currently represent state-of-the-art superior classiﬁcation performance relevant benchmark datasets. developed modiﬁed training procedures lstm networks combine sets diverse lstm learners classiﬁer collectives. demonstrate ensembles deep lstm learners outperform individual lstm networks thus push state-of-the-art human activity recognition using wearables. extensive experimental evaluation three standard benchmarks demonstrate excellent recognition capabilities approach potential real-life applications human activity recognition. additional words phrases activity recognition; deep learning; lstm; ensembles reference format guan thomas pl¨otz. ensembles deep lstm learners activity recognition using wearables article pages. activity recognition core concern ubiquitous wearable computing ever since weiser formulated vision third generation computing related work covers enormous variety innovative sensing analysis approaches target plethora application areas including limited novel interaction techniques situated support smart environments automated health wellbeing assessments health care automation sports tracking coaching name few. fact ﬁeld advanced much already focusing application areas beyond activity recognition automated skill quality assessments still substantial challenges human activity recognition authors’ addresses guan sandyford road newcastle university newcastle upon tyne email yu.guannewcastle.ac.uk; pl¨otz technology square research building georgia institute technology fifth street atlanta email thomas.ploetzgatech.edu permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights components work owned others must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. request permissions permissionsacm.org. acm. -//-art ubiquitous wearable computing remain manifold. first foremost data recorded using wearable pervasive sensing modalities inherently noisy often containing missing even erroneous readings sensor malfunction. furthermore ground truth annotation mobile application scenarios often hard obtain impossible collect. accurate labels however required e.g. supervised learning methods also validation general. stark contrast almost effortless collection sensor data mobile devices. also realworld datasets tend imbalanced regards biased class distribution underlying sensor data causes problems training inference time. encouraged tremendous success deep learning methods recently activity recognition research community started adopting complex modelling inference procedures. deep learning methods proven potential signiﬁcantly push state-of-the-art human activity recognition. importantly allow overcome ever crucial need feature engineering manual deﬁnition feature extraction procedures often erroneous least– poorly generalisable endeavour. biggest advantage contemporary deep learning methods ability simultaneously learn proper data representations classiﬁers. early feature learning methods ubicomp utilised restricted boltzmann machines generative deep learners deriving task agnostic feature representations recently sophisticated models successfully used challenging tasks e.g. convolutional neural networks popular using deep learning methods activity recognition purposes modifying standard processing workﬂow widely adopted community workﬂow comprises sliding window based analysis isolated frames consecutive portions sensor readings. instead manually deﬁning feature representations frames data presented models automatically extract rich representations input data. multiple hidden layers typically fully connected computing nodes allows complex function approximation leads powerful classiﬁers. stands deep learning based systems outperform alternatives standard challenging activity recognition benchmarks opportunity whilst predominant modelling approach deep learning based based recently also sequential modelling methods employed successfully e.g. speciﬁcally so-called long short term memory networks used recurrent neural networks principally inﬁnite memory every computing node. lstm models like recurrent neural network predestined analysis sequential data streams sensor data. processing nodes i.e. neurons also referred cells take spatial also temporal context account determining activation. addition connectivity across network models implement feedback loops outputs neurons directly serve input well. adding speciﬁc elements individual cells effective memory functionalities realised recent works ubiquitous wearable computing arena substantially pushed lstm-based recognition systems rendering state-of-the-art outperforming approaches relevant challenging baseline tasks. such deep learning general lstmbased modelling approaches particular serve reference work presented paper. even though deep learning based approaches activity recognition widely outperform stateof-the-art using non-dl methods aforementioned challenges ubiquitous wearable computing remain. speciﬁcally problematic data situation –noisy erroneous data heavily imbalanced data distributions etc.– remains largely unaddressed. furthermore rather surprising models speciﬁcally designed analysis sequential data widely employed –during inference– traditional sliding-window i.e. frame-based manner. paper present framework deep learning based activity recognition using wearable sensing data. substantially extend previous work alleviated sliding window paradigm sensor data processing employ deep recurrent lstm networks sample-wise prediction. ﬁrst time combine multiple lstm learners ensemble classiﬁers enable substantially improved robustness challenging realistic applications. directly tackling practical issues real-world sensing scenarios develop novel training method lstm models leads derivation robust recognisers. method acknowledges fact noisy possibly ambiguous even erroneous data typical scenarios ubicomp– negatively inﬂuence performance recognition systems. worth mentioning real-world deployments cannot easily identify subsequently ignore null class data belong activities interest rather background. larger context work aims ’open-ended’ activity recognition deriving adapting recognition systems without assumptions limitations would hinder actual ’in-the-wild’ deployments. pre-ﬁltering based prior domain knowledge represent reasonable option rather generalised approach presented paper. training method assumes certain percentage sensor data ’problematic’ thus utilises subset data training iteration. given data issues normally difﬁcult detect specify a-priori subset determination method employs probabilistic selection approach effectively resembles general concept bagging reiterating selection procedure able build ensemble classiﬁers activity recognition. best knowledge paper ﬁrst uses ensembles lstm learners activity recognition scenario. evaluate method three standard benchmark datasets namely opportunity challenge pamap skoda dataset outperforming state-of-the-art results indicate increased robustness ensembles deep lstm learners regards typical challenges human activity recognition ubiquitous wearable computing scenarios. provide detailed analysis models’ performance allows draw conclusions related real-world applications future scenarios. remainder paper structured follows. sec. provide primer relevant background deep learning human activity recognition well ensemble learning. overview serves reference technical developments described later paper subsequently explain detail framework activity recognition using ensembles deep lstm learners. sec. presents experimental evaluation based aforementioned three benchmark datasets discusses results view real-world applications. sec. summarises work discuss detail practical implications well future avenues extensions adaptations. background developing methods robust human activity recognition using ubiquitous wearable sensing modalities. prominently without limiting target inertial measurement units long standing history wider ubiquitous wearable computing community. years multitude methods developed facilitate astonishing variety applications. become pillars third generation computing aiming conciseness refrain reiterating summaries general state-of-the-art activity recognition. argue safely considered common knowledge thus refer seminal papers tutorials importantly follows cover speciﬁc algorithmic background paper spans following main subject areas deep learning ubiquitous wearable computing; ensembles classiﬁers robust recognition challenging settings. deep learning human activity recognition line massive success popularity many application domains deep learning also revolutionise human activity recognition methods ﬁeld ubiquitous wearable computing. attraction deep learning stems fact complex models come great capacity regards classiﬁcation tasks also substantially alleviate need feature engineering learn effective rich representations input data. early deep learning applications ubiquitous wearable computing primarily targeted representation learning aspect. deep belief networks speciﬁcally generative restricted boltzmann machines employed feature learning. based this subsequent works explored effectiveness pre-trained fully-connected networks example automated assessments disease states parkinson’s patients combination traditional sequence models successfully auditory scene analysis ubicomp applications popular ﬁeld human activity recognition using wearables variants deep learning methods deep convolutional neural networks recurrent deep neural networks long short term memory networks. types summarised follows. convolutional neural networks har. arguably widely used deep learning approach ubiquitous computing ﬁeld general human activity recognition using wearables particular employ cnns. cnns typically contain multiple hidden layers implement convolutional ﬁlters extract abstract representations input data. combined pooling and/ subsampling layers fully connected special layers cnns able learn hierarchical data representations classiﬁers lead extremely effective analysis systems. multitude applications based cnns including limited recently sophisticated model optimisation techniques introduced actually allow implementation deep cnns resource constrained scenarios prominently real-time sensor data analysis smartphones even smart watches long short term memory models har. de-facto standard workﬂow activity recognition ubiquitous wearable computing treats individual frames sensor data statistically independent isolated portions data converted feature vectors presented classiﬁer without temporal context. however ignoring temporal context beyond frame boundaries modelling limit recognition performance challenging tasks. instead approaches speciﬁcally incorporate temporal dependencies sensor data streams seem appropriate human activity recognition. response this recurrent deep learning methods gained popularity ﬁeld. prominently models based socalled lstm units used successfully. deep recurrent neural networks used activity recognition opportunity benchmark dataset. lstm model combined number preceding layers deep network learned rich abstract sensor representations effectively could cope non-trivial recognition task. large scale experimentation appropriate training procedures analysed number deep learning approaches including deep lstm networks. previous work including single lstm models used standard training procedures employed parameter estimation. majority existing methods based sliding-window procedures frame extraction. focus paper capturing diversity data training incorporate diverse models ensemble classiﬁers. paper ﬁrst pushes beyond optimisation individual models leads signiﬁcantly improved recognition performance robustness. theoretical background lstms. given lstm networks form algorithmic foundations work presented paper brieﬂy summarise theoretical background. fig. schematically illustrates anatomy lstm units originally introduced order address problem vanishing/ exploding gradients typical large scale vanilla networks based tanh activation functions speciﬁc mechanisms introduced every individual hidden unit lstm network. include forget input cell output gates well speciﬁc internal structure individual hidden units facilitating effective error back-propagation even complex deep model architectures prolonged periods time e.g. hundreds time steps. exemplary one-layer network lstm units take input signal hidden state cell state previous lstm units. output forwarded consists current hidden dimension input signal number lstm units denotes number classes weight matrices bias vectors deﬁne transformation particular gate illustrated fig. given input model parameters forward pass written follows denote outputs forget input cell output gates respectively stands element-wise multiplication. outputs lstm units passed next timestep iterate aforementioned process. given prediction performed class probability vector calculated follows fig. gives illustrative overview prominent deep learning approaches human activity recognition using wearable sensing platforms. shows examples cnn-based systems lstm-based approaches iii) combinations especially latter particular interest combines effectiveness cnn-based representation learning sequence modelling capabilities lstms. combination used successfully activity recognition also exploration transfer learning scenarios using deep learning ensembles classiﬁers bulk general machine learning research directed towards development effective classiﬁcation methodologies applied various recognition tasks. thereby focus typically pushing boundaries individual classiﬁers employed modelling inference. addition this recent years combination multiple learners meta-classiﬁers gained popularity shown classiﬁer ensembles beneﬁcial analysis complex datasets typically range different base classiﬁers estimated either modiﬁed training sets alternative representations training data. inference whole classiﬁers applied original recognition task results multiple predictions aggregated order achieve ﬁnal classiﬁcation. multiple variants developed generating different views training data aggregating individual predictions. shown classiﬁer ensembles great potential outperform traditional single classiﬁer systems especially challenging recognition tasks original formulation concept classiﬁer ensembles principle constraint base classiﬁers rather modest requiring classiﬁcation accuracy ensemble members better random so-called weak learners form classiﬁer ensembles. however recent years shown ensemble classiﬁcation even effective strong base classiﬁers integrated either ensemble approaches lead improved performance underlying base classiﬁers capture substantial mutual diversity modelling different characteristics data set. prominent approach ensemble creation utilises artiﬁcially constrained training sets base learner training. repeated random selection samples training data so-called bagging procedure aggregates classiﬁers estimated bootstrap replicates training samples popular boosting procedure pursues alternative approach generating diversity classiﬁer ensembles namely targeted weighting sample data consideration training procedure. iterative approach boosting gradually focuses samples harder classify i.e. causing higher classiﬁcation errors arguably deep learning methods already interpreted ensemble learning methods. combination multiple hidden layers containing numerous processing nodes eventually contribute aggregated classiﬁcation decision models effectively resemble principle ensemble learning. however focus paper higher level abstraction combining multiple complete networks tackle challenging recognition tasks. little work ensembles deep learning methods. best knowledge paper ﬁrst addresses using ensembles recurrent lstm networks. examples deep learning ensembles include combination support vector machines classiﬁer ensembles shown resulting stacked deep svms outperform non-ensemble approaches variety standard classiﬁcation benchmarks including time series analysis activity recognition though. furthermore stacking methods ensemble learning sets deep neural networks applied successfully speech recognition applications class posterior probabilities computed convolutional recurrent fully-connected deep neural networks integrated ensemble focus work combining deep learning methods date– effective human activity recognition classiﬁer ensembles. speciﬁcally focus lstm networks base learners given superior performance challenging benchmarks line previous work combining strong learners ensembles hypothesise combination diverse individual lstm networks lead robust thus improved activity recognition results challenging ubicomp scenarios. hypothesis supported recent related works application domains lstm models integrated classiﬁer collectives leading improved recognition results encouraging real-world har. related work described system utilises ensembles lstm learners predicting actions video data. unlike approach ensemble based range base learners derived speciﬁcally variants certain activities diversity required building ensembles de-facto prescribed. argue real-world scenarios prescription represents unnecessary potentially harmful limitation regards ﬂexibility robustness resulting classiﬁer collectivce. such whilst general argumentation using strong –lstm– base learners ensembles identical focus data-driven diversity leads effective robust recognition systems. authors referred lstm ensembles well different –somewhat misguiding– interpretation. example employed three variants lstm networks parallel biological sequence analysis applied majority voting ﬁnal classiﬁcation. whilst approach touches upon general idea classiﬁer ensembles constrained leaves substantial room improvement. focus work data-driven generation diversity novel training procedure allows deriving powerful especially robust lstm ensembles relevance real-world scenarios using wearable pervasive sensing modalities. ensembles deep lstm learners activity recognition work mainly motivated following observations. activity recognition based mobile wearable sensing modalities typical ﬁeld– often face substantial challenges regard data quality extent quantity. firstly sensor data inherently noisy. high temporal resolutions sensing facilities used direct movement sensing principle results substantial variations sensor data even within activities i.e. ambiguous representations. additionally faulty sensor operation occasionally leads erroneous sensor readings challenge quality data. secondly widespread adoption mobile computing integrated sensing facilities render collection unlabeled data almost trivial endeavour. however collection ground truth annotation substantially challenging primarily practical well ethical reasons. discrepancy typically leads rather imbalanced datasets non-uniform class distributions represents considerable problems many training validation approaches. thirdly even though popular sliding window frame-based analysis approach effectively circumvents segmentation challenge need locating episodes relevant activities classifying them grained analysis complex activities substantially suffers simpliﬁcation. strictly speaking sequential data shall modelled analysed sequential models. growing maturity ﬁeld increasingly complex recognition tasks research community acknowledging problem. demonstrated recent related work deep recurrent neural networks i.e. sequential models great potential robust analysis beyond predominant sliding window frame based analysis paradigm. response observations improving robustness activity recognition systems developed framework based ensembles lstm learners. combine multiple deep recurrent neural networks meta classiﬁer substantially robust w.r.t. aforementioned challenges ubiquitous wearable computing applications human activity recognition. fig. gives overview system described detail subsequent sections. approach characterised following aspects lstm based har. deep learning successfully used variety application domains including using ubiquitous wearable sensing. line recent related work employ speciﬁc variant namely deep recurrent networks based long short term memory units modiﬁed training sample-wise model evaluation. majority related work utilises well established sliding-window frame-based analysis approach extent also holds emerging ﬁeld deep learning based portions contiguous sensor readings –frames shifted along time series data substantial overlap subsequent frames– analysed complex networks predictions given level frames rather samples. alternative approach namely random sampling frames varying length model training sample-wise model evaluation inference. fusion multiple lstm learners ensembles. based modiﬁed training procedure able train models robust regards aforementioned data challenges. generalise concept repeated iteration combine multiple models derived manner ensembles lstm activity recognition models effectively resembles general concept bagging substantially complex base learners. motivation fusing lstm learners regards error types ideal classiﬁer bias variance. bias corresponds expected error predicted values ground truth whereas variance measures variability model prediction given data point. real world recognition systems need compromise deﬁne tradeoff bias variance classiﬁers suffer under overﬁtting depending representativeness training data classiﬁer complexity example simple linear classiﬁers high bias facing non-linear data. complex non-linear models neural networks empirically tend bias tend overﬁt training datasets large representative enough contrast bias reduction techniques simple models bagging variance reduction technique strong classiﬁers. based bootstrapped training samples strong base classiﬁers initially trained high variance later reduced aggregation e.g. model averaging. popular strong base learners include decision trees neural networks kernel methods corresponding variances signiﬁcantly reduced bagging yielding improved generalisation capabilities. motivated generic considerations recognition system based ensembles lstms. within general ﬁeld pattern recognition machine learning shown individual classiﬁers integrated ensembles used successfully solving challenging recognition tasks despite fact general machine learning literature largely argues w.r.t. static classiﬁers reason observation valid sequential models well consequently employ strong learners –lstms bias high variance owing almost universal function approximation capabilities– deriving recognition ensembles. follow previously described general pipeline bootstrap strong learners followed variance reduction model averaging. since computational complexity quickly become issue training deep neural networks lstms employ epoch-wise bagging scheme. scheme generates lstm base learner epoch. modiﬁed training procedure randomising various parts aiming increased diversity amongst base learners crucial ensembles. aggregating resulting base learners effectively counteract high variance problem i.e. notorious tendency neural networks overﬁt. importantly developed approach effective sequential base learners advantageous analysis time-series data relevant settings. modiﬁed training lstm models activity recognition framework based long short term memory networks summarised sec. whilst employ standard lstm models inference time training procedure different targeted meet challenging real-life data scenarios typical ﬁeld ubiquitous wearable computing. fig. illustrates developed training procedure individual lstm learners alg. summarises procedure formally epoch-wise bagging. aforementioned discussion hypothesis model training procedures challenged noise sensor readings well class imbalance. unfortunately real-world scenarios typically straightforward formalise challenges w.r.t. example quantifying percentage problematic sensor readings alone identifying access recognition results. work acknowledge challenges attempt solve chicken-and-egg problem require prior knowledge challenges speciﬁc application domain. instead assume certain percentage sample data least beneﬁcial used model training thus used. without prior domain knowledge constraints know portions data inferior quality model training. aiming generalisation thus employ method creates effective training probabilistic selection subsets original data mini-batch based learning lstm networks using stochastic gradient descent method presented extends previous work epoch generate subsets shufﬂed training data –so-called mini-batches– used model training. gradient calculated minimising error function model updating. however shown contextual nature time series data uninformed shufﬂing cannot directly applied order construct diverse usable mini-batches training models time series analysis previous work randomly chosen different start positions generating frames contiguous portions sensor data along whole training sequence procedure repeated every epoch model training. mini-batches every training epoch constructed selecting frames sensor data pre-deﬁned window length chosen starting positions within stream sensor data. formally frames contiguous sensor readings selected start/end indices deﬁned follows increased robustness resulting models w.r.t. aforementioned challenges real-world scenarios work extend wrapping around procedure bagging scheme epoch-wise learners. instead using pre-deﬁned ﬁxed numbers training frames frame length –for difﬁcult justiﬁcation little prior knowledge speciﬁc domain available modelling time– randomly choose epoch within epoch also randomly sample various frame lengths worth mentioning general lstm training scheme insensitive speciﬁc window lengths general capability lstms remember contextual temporal information remains unchanged. lstms pass current cell state hidden state inputs next time-step. avoid hard decisions regarding length contextual window used training step difﬁcult make generalised decision upfront. practically related work based ﬁxed window lengths essentially represents sort compromise based heuristics. instead various randomly chosen window lengths well randomised starting points mini-batch sizes speciﬁc goal increase diversity epoch-wise classiﬁers. repeating randomised process make sure –empirically– cover whole sequence input data. however epoch mini-batches cover contiguous signal parts length overall total samples used epoch. speciﬁcally frames contiguous sensor readings generated start/end indices deﬁned follows inevitably procedure results repetitions and/ omission parts original training data which according aforementioned motivation robust model training real-world scenarios. practical experiments found average training data used epoch using standard i.e. uniformly distributed random number generator deﬁning training frames. given omitted portions selected probabilistically method –intended– positive effect yielding less correlated epoch-wise classiﬁers. essentially concept resembles aforementioned idea bagging level bootstrapping epoch-wise lstm learners without speciﬁc model score combination. alternative loss function lstm learners. addition employing popular cross entropy loss function also explore utility alternative loss function. speciﬁcally train base learners using -score loss cost-sensitive loss function negatively correlated approximation score dataset general introduction). different global cost function complete dataset cannot directly used measure individual sample’s losses samples loss deﬁned although loss considers data imbalance problem lstm learners still trained based mini-batches precisely approximate true gradient towards optimal score whole training reasonable approximation. owing aforementioned properties classiﬁers generated loss different combining multiple lstms ensembles modiﬁed training procedure individual lstm learners leads various models varying view training data. mentioned effectively resembles main concepts bagging i.e. –simpliﬁed– variant ensemble learning. general idea ensemble classiﬁers create collectives individual learners trained different views sample data. introducing variation individual learners focus different aspects problem domain combination leads robust typically better recognisers terms average classiﬁcation accuracy. concept epoch-wise bagging described previous section already introduced concept diversifying training activity recognition system. generalise idea combining multiple lstm models classiﬁer committees. focus generating diversity main sources discussed previous sections diversity base learners random selection subsets training data parameter estimation. essentially corresponds combining individual lstms obtained every training epoch. independent cause diversity base classiﬁers meta-optimisation objective classiﬁer ensembles generate classiﬁers diverse minimally correlated actual model combination based score level fusion explained below. axepoch typical deep learning approaches axepoch thereby often large number models marginally correlated substantial variability training sets generated particular epochs training procedure analyses quality axepoch models separate validation set. based results preserve best models inclusion overall ensemble score level fusion. worth reiterating employ ensembles lstm learners sample-wise activity recognition. every sample i.e. every time step ﬁnal softmax layer deﬁned class probability models provide class probability vectors vectors effectively describe probability distributions classes interest speciﬁc task. probability vectors models combined arithmetic means resulting ﬁnal score vector usion fusing best performing typically least correlated lstm learners leads substantially improved model performance. appendix provides formal exploration general concept integrating lstm base learners ensemble classiﬁers. experimental evaluation order validate effectiveness framework conducted experimental evaluation. recognition experiments three benchmark datasets considered standard ﬁeld thus widely used literature. follows ﬁrst describe training evaluation methodology followed summary details datasets used evaluation study ﬁnally present discuss results. model training evaluation protocol experiments conducted using framework introduced paper. share common parameters described follows thereby covering general model conﬁgurations well training evaluation methodologies explained below. dataset speciﬁc modiﬁcations any– discussed dataset description subsections. apart potential subsampling modality fusion sensor data used without employing feature extraction methods based heuristics sophisticated transformations line majority recent deep learning based analysis methods ﬁeld human activity recognition using wearable sensing platforms. model conﬁguration. experiments lstm learners i.e. based individual learners baselines well employing ensembles following lstm model conﬁguration. built two-layer lstm networks layer containing lstm units. dropout performed ﬁrst second hidden layers probability used adam updating function learning rate extending previous work random starting points used epoch training dynamically determined mini-batch size frame lengths randomly within given range test performed inference sample level i.e. implemented framework using lasagne lightweight theano library build deep neural networks. models trained nvidia tesla average training times epoch opportunity/pamap datasets seconds epoch skoda dataset. evaluation. overall interested evaluating robustness proposed method real-world application scenarios. carefully conﬁgured evaluation protocol aiming meaningful practically relevant comparable evaluation results. based standard benchmark datasets described adopted evaluation scenarios used before makes results comparable related work. speciﬁcally avoided commonly used unrealistically over-optimistic evaluation protocols unconstrained n-fold cross-validation accordance previous work used hold-out validation testing protocols ﬁxed disjoint portions datasets used training validation testing. line standard procedures ﬁeld results reported mean -scores experimental evaluation analyse effects parameters approach overall recognition performance. every model conﬁguration repetitions particular experiments report averaged scores experiments given elements –intentional– randomness ensemble creation procedure protocol captures performance expected real-world deployments enables formal statistical signiﬁcance testing. latter employ two-tailed independent ttests report signiﬁcance levels values correspond respectively note report sample-wise prediction results according overall motivation line previous work different frame-wise results example reported comparability reran experiments literature necessary converted frame-based results sample-wise prediction. datasets line related work ﬁeld evaluated system three benchmark datasets widely used within community. datasets contain continuous sensor readings inertial measurement units worn participants particular studies different positions bodies. chosen datasets correspond three diverse time typical tasks human activity recognition ﬁeld. line general ambition develop recognition systems real-world applications primary concern related evaluation challenging realistic benchmark datasets prominently opportunity which arguably represents difﬁcult datasets date. however order avoid potential overﬁtting speciﬁc scenario –more importantly– demonstrate generalisability developed method evaluate approach datasets might directly mirroring real-world deployments still widely used research community fig. shows class distributions three datasets illustrating aforementioned challenges ubiquitous wearable computing. addition fig. gives overview average durations activities interests three datasets shows substantial variability thus challenges automated recognition. especially opportunity dataset substantially imbalanced class distribution additional strong bias towards null class observed unusual mobile application scenarios activities interest often underrepresented overall dataset continuous recording real-life scenarios. prominent examples scenarios health assessments problematic activities behaviours typically rare exception within other less problematic activities. example freeze gait parkinson’s common problem amongst patients throughout freezing episodes rare though critical w.r.t. health wellbeing patient thus require reliable recognition another related example literature automated assessment problem behaviour individuals autism aggressive behaviours occur frequently typically represent minority everyday activities thus resulting imbalanced datasets pamap dataset recorded much rigorously scripted thus constrained manner results well balanced class distribution mainly reasoned absence null class finally skoda dataset shows reasonably well balanced class distribution activities interest however overall dataset still dominated null class rendering biased would expect real-world scenarios discussed before. note real-world deployments rather unrealistic assume simple pre-processing techniques would allow effectively eliminate background data continuous recordings sensor data. reason background activities often diverse classiﬁcation background activities interest typically corresponds non-trivial task itself typically requires simple ﬁltering. furthermore whilst straightforward identify eliminate faulty sensor readings noisy sensor data common mobile scenarios represent different kind challenge require sophisticated measures tackle. follows provide detailed summaries three datasets used experimental evaluations. opportunity. opportunity dataset result concerted effort towards collecting benchmark dataset human activity recognition using body-worn sensors consists annotated recordings total four participants wore armada sensors instructed carry everyday life domestic activities speciﬁcally focusing kitchen routine. data recorded using inertial measurement units attached on-body positions. sampling frequency imus annotations provided mid-level activities open door close door. every participant performed different runs kitchen activities. replicate training validation test protocol accelerometer recordings upper limbs back complete data feet used resulting -dimensional dataset. data normalised zero mean unit variance. second participant used validation runs participants test. remaining data used training pamap. dataset recorded scripted thus rather constrained setting nine participants instructed carry total activities daily living covering domestic activities various sportive exercises full data plus temperature heart rate data recorded body-worn sensing platforms attached hand chest ankle. total hours data collected. resulting dataset dimensions. sensor data down-sampled match temporal resolution datasets used. samples normalised zero mean unit variance. replicating protocol used runs participant validation runs sixth participant test. remaining data used training skoda. third dataset used experimental evaluation recorded manufacturing scenario. speciﬁcally covers problem recognising activities assembly-line workers production environment study collection skoda dataset worker wore number accelerometers undertaking manual quality checks correct assembly parts newly constructed cars. checks translate manipulative gestures interest including checking boot opening/closing engine bonnet boot doors turning steering wheel. accelerometer data down-sampled normalised zero mean unit variance. used data recorded using accelerometers worn right worker resulting -dimensional input data. datasets hold-out validation test protocols. training contains ﬁrst class validation next test contains remainder dataset. results tab. provides overview results experimental evaluation based ensembles lstm learners achieved three benchmark datasets. table contains results various model conﬁgurations number base learners ensembles. analysed effect incorporation lstm models overall recognition framework total performance. every dataset tested ensembles best individual lstm learners. loss functions. evaluated standard cross entropy –’ensemble scores –’ensemble loss functions well combination models based either loss functions fig. illustrates results statistical signiﬁcance tests experiments described sec. furthermore figs. show class-speciﬁc recognition results confusion matrices three recognition tasks. averaged confusion matrices fig. given best model conﬁguration namely ensembles combined ce+f loss function base learners each. results unveil number interesting effects ensemble based modelling approach human activity recognition. first integrating base learner recognition system indeed positive effect hypothesised outset work. line related work seen strong learners –lstm models case– indeed integrated effective ensembles outperform single individual models. recognition results consistent across three tasks indicated relatively small standard deviation essentially demonstrates effectiveness novel training method generates models focus well different aspects sample data. recognition results improve loss functions increasing number base learners. practically three tasks classiﬁcation performance plateaus base learners leads improvements signiﬁcant). classiﬁcation performance increased opportunity injecting additional source variation. dataset –which shows strongly biased class distributions– combination learners trained using different loss functions increases diversity covered resulting ensemble pushes recognition performance signiﬁcant manner ce+f’ tab. ii). pamap beneﬁt diversity loss function attributed homogeneous underlying class distribution thus lesser need diversiﬁcation modelling approach. note lstm based approach still substantially outperforms state-of-the-art three tasks adding diversity harm recognition systems seemingly plateaued classiﬁcation performance value practical applications. fig. statistical signiﬁcance analysis recognition experiments using variants lstm ensembles based trials each. text description best viewed colour. results experiments different loss functions model training interesting itself. cross entropy loss functions widely used literature. however evaluating overall recognition accuracy using scores ideal imbalanced data scenarios– seems intuitive alternative loss function model optimisation. interestingly positive effect individual learners changing loss function. major reason loss global measure models updated based minibatches precisely approximate true gradient towards optimal score whole data set. given features loss functions expected types base learners behave differently certain scenarios likely less correlated. experimental results conﬁrm expectation ensemble leads improved performance challenging recognition task. arguably justiﬁes motivation using ensembles lstms. mixing learners trained different loss functions increase variability importance classiﬁer ensemble approach fig. provides insights activities beneﬁt approach. line original opportunity. given challenging nature dataset variability activity instances nearly target activities beneﬁt approach utilises combination base learners based different loss functions achieves best performance. pamap. rather homogeneous dataset performance gains moderate largely centred ’sitting’ ’stairs’ ’vacuuming’. given humans typically engage range parallel activities performing either three activities result supports hypothesis modelling needs focus diversity. skoda. line previous argumentation skoda task beneﬁts approach opening closing doors activities. overall method –that ensemble combined loss functions ’ce+f’– produces largest performance gains challenging classes almost never detrimental effect activity classes encouraging real-world scenarios. completeness fig. shows confusion matrices three recognition tasks best performing model conﬁguration ce+f’; tab. ii). surprisingly largest confusion caused null class also classes small sample numbers beneﬁt much fact learners simply able capture much variability larger sample sets. contextualise achieved results reference experiments allow compare approach state-of-the-art. note that according literature best results three datasets currently achieved using deep learning methods. consequently comparison focused approaches effectively serve benchmarks time writing. reference experiments based implementations described particular original papers thereby part making source code provided authors replicating model conﬁgurations used tab. summarises results illustrating substantial improvement recognition performance opportunity pamap. analysing results light class distributions particular datasets general quality sensor readings discussed throughout paper main motivation developing ensemble approach– becomes clear method well suited real-world challenging activity recognition tasks. speciﬁcally scenarios imtable iii. comparison recognition results achieved using lstm ensemble baselines using state-of-the-art sample-wise activity recognition however even though method increase recognition accuracy here also cause harm encouraging real world applications neither assumptions prior knowledge underlying class distribution required using approach. discussion main motivation work develop innovative modelling techniques robust reliable human activity recognition deployed real-world scenarios. much general tradition ubicomp original vision strive positive impact people’s lives activity recognition ubiquitous computing forms basis many research endeavours follow vision. such recognition capabilities state-of-the-art methods challenging real-world scenario still leaving substantial room improvement. example even latest generation deep learning modelling techniques benchmark results opportunity challenge –arguably challenging realistic datasets– still suggests substantial research needed towards fulﬁlling ubicomp vision. paper developed activity recognition framework targets challenging real-life scenarios speciﬁcally addressing noisy imbalanced datasets typical mobile applications human activity recognition. framework based integration individual deep long short term memory networks ensemble classiﬁers. chose deep learning general lstm models particular starting point work recent related work employing lstm recognisers demonstrated excellent recognition capabilities including superior classiﬁcation performance many applications wider wearable ubiquitous computing domain. lstms represent variants recurrent neural networks principally inﬁnite memory. line recent related work argue sequential models well suited analysis sensor data streams. combining multiple diverse base lstm learners ensembles able signiﬁcantly increase robustness resulting recognition system illustrated substantial improvements recognition accuracy validated three best knowledge ﬁrst time deep lstm models integrated ensemble based modelling approach human activity recognition using wearables. ensemble framework able signiﬁcantly improve recognition accuracies standard benchmark datasets. datasets represent challenging real-world scenarios signiﬁcantly improving state-of-the-art demonstrates practical value proposed method. basis ensemble framework modiﬁed training procedure deriving diverse sets lstm based activity recognisers speciﬁcally target problematic data situations real-life scenarios. anatomy underlying base lstm learners remains unchanged which together implementation using standard open-source toolkits allows straightforward replication approach system integration. employ ensembles deep lstm networks improved sample-wise activity recognition substantial potential future applications activity prediction time-critical inference. extensive experimental evaluation demonstrates potential presented approach has. three analysed standard benchmark datasets presented approach outperforms state-ofthe-art statistically signiﬁcant manner. speciﬁcally challenging scenarios –exemplarily explored using opportunity dataset– substantial gains classiﬁcation accuracy achieved. method effectively tackles typical problems real-world deployments wearable systems namely imbalanced class distribution often substantially over-represented null background class well noisy faulty sensor readings. argued real-world deployment typically straightforward ﬁlter unwanted samples background null data thus increased robustness provided approach especially encouraging. arguably method greatest potential challenging datasets. addition results experimental evaluation demonstrate method barely lead detrimental results even cases single models already achieve high classiﬁcation accuracies experiments demonstrate generalisable applicability. focus paper development basic methodology. addressed implementation issues would relevance ﬁeld deployments products even. however recently shown even complex deep neural networks effectively used inference substantially resource constrained platforms smartwatches order able implement complex deep neural networks devices sophisticated optimisation techniques necessary. majority correspond pruning efforts regards effective parameter space. ensembles certainly inﬂate parameter space general principle pruning remains accessible change general nature models dependencies introduced would prevent pruning parameter space. conﬁdent models implemented wearable devices interactive scenarios. note ofﬂine analysis scenarios common ubicomp domain example fact analysis health wellbeing domains– affected concerns method directly usable. importantly models operate basis sample-wise prediction. principle advantages future real-time applications appendix reducing loss lstm ensembles recognition approach integrates number vanilla lstm models base learners ensemble framework. means experimental evaluation demonstrated approach leads signiﬁcantly improved robustness thus classiﬁcation performance. follows provide exemplary formal exploration lstm base learners lead improved classiﬁcation performance. sequential model lstm takes current signal previous states inputs performs sample-wise prediction sec. ..). sake clarity without loss generality argue based example reduction cross entropy loss arguably popular loss function ﬁeld. speciﬁcally corresponds negative logarithmic loss predicted probability target class thus –inversely proportionally– predicted class probability. example class probability target class time corresponding loss fusing models fused model i.e. ensemble created score level fusion multiple individual learners corresponding formulated similar way. time step usion acknowledgements would like thank school computing science newcastle university providing computing facilities anonymous reviewers constructive comments helped improving manuscript paper. references gregory abowd. beyond weiser ubiquitous collective computing. ieee computer alsheikh selim niyato doyle deep activity recognition models triaxial accelerometers. akin avci stephan bosch mihai marin-perianu raluca marin-perianu paul havinga. activity recognition using inertial sensing healthcare wellbeing sports applications survey. proc. int. conf. architecture compu. systems. marc bachlin meir plotnik daniel roggen inbal maidan jeffrey hausdorff giladi gerhard troster. wearable assistant parkinson’s disease patients freezing gait symptom. ieee transactions information technology biomedicine l´eon bottou. large-scale machine learning stochastic gradient descent. prco. compstat. breiman. bagging predictors. machine learning breiman. random forests. mach. learn. peter ¨uhlmann. bagging boosting ensemble methods. springer berlin heidelberg andreas bulling blanke bernt schiele. tutorial human activity recognition using body-worn inertial sensors. ricardo chavarriaga hesam sagha alberto calatroni sundara tejaswi digumarti gerhard tr¨oster jos´e mill´an daniel roggen. opportunity challenge benchmark database on-body sensor-based activity recognition. pattern recognition letters deng platt. ensemble deep learning speech recognition.. proc. interspeech. nils hammerla james fisher peter andras lynn rochester richard walker thomas ploetz. disease state trevor hastie robert tibshirani jerome friedman. elements statistical learning. springer. sepp hochreiter ¨urgen schmidhuber. long short-term memory. neural computation jesse hoey thomas ploetz jackson andrew monk cuong pham patrick olivier. rapid speciﬁcation automated generation prompting systems assist people dementia. pervasive mobile computing kingma adam method stochastic optimization. proc. iclr. josef kittler mohamad hatef robert duin jiri matas. combining classiﬁers. ieee trans. pattern analysis matthias kranz andreas moeller nils hammerla stefan diewald luis roalter thomas ploetz patrick olivier. mobile ﬁtness coach towards individualized skill assessment using personalized mobile devices. pervasive mobile computing yann lecun yoshua bengio geoffrey hinton. deep learning. nature mcclelland rumelhart. parallel distributed processing. press. francisco javier ord´o ˜nez morales daniel roggen. deep convolutional feature transfer across mobile activity recogniattila reiss didier stricker. introducing benchmarked dataset activity monitoring. proc. iswc. ronaoo cho. evaluation deep convolutional neural network architectures human activity recognition mark weiser. computer century. scientiﬁc american jianbo yang minh nhut nguyen phyo phyo xiaoli shonali krishnaswamy. deep convolutional neural", "year": 2017}