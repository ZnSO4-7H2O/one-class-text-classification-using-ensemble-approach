{"title": "Generalizable Data-free Objective for Crafting Universal Adversarial  Perturbations", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Machine learning models are susceptible to adversarial perturbations: small changes to input that can cause large changes in output. It is also demonstrated that there exist input-agnostic perturbations, called universal adversarial perturbations, which can change the inference of target model on most of the data samples. However, existing methods to craft universal perturbations are (i) task specific, (ii) require samples from the training data distribution, and (iii) perform complex optimizations. Also, because of the data dependence, fooling ability of the crafted perturbations is proportional to the available training data. In this paper, we present a novel, generalizable and data-free objective for crafting universal adversarial perturbations. Independent of the underlying task, our objective achieves fooling via corrupting the extracted features at multiple layers. Therefore, the proposed objective is generalizable to craft image-agnostic perturbations across multiple vision tasks such as object recognition, semantic segmentation and depth estimation. In the practical setting of black-box attacking scenario, we show that our objective outperforms the data dependent objectives to fool the learned models. Further, via exploiting simple priors related to the data distribution, our objective remarkably boosts the fooling ability of the crafted perturbations. Significant fooling rates achieved by our objective emphasize that the current deep learning models are now at an increased risk, since our objective generalizes across multiple tasks without the requirement of training data for crafting the perturbations.", "text": "abstract—machine learning models susceptible adversarial perturbations small changes input cause large changes output. also demonstrated exist input-agnostic perturbations called universal adversarial perturbations change inference target model data samples. however existing methods craft universal perturbations task speciﬁc require samples training data distribution perform complex optimizations. also data dependence fooling ability crafted perturbations proportional available training data. paper present novel generalizable data-free objective crafting universal adversarial perturbations. independent underlying task objective achieves fooling corrupting extracted features multiple layers. therefore proposed objective generalizable craft image-agnostic perturbations across multiple vision tasks object recognition semantic segmentation depth estimation. practical setting black-box attacking scenario show objective outperforms data dependent objectives fool learned models. further exploiting simple priors related data distribution objective remarkably boosts fooling ability crafted perturbations. signiﬁcant fooling rates achieved objective emphasize current deep learning models increased risk since objective generalizes across multiple tasks without requirement training data crafting perturbations. encourage reproducible research released code proposed algorithm github†. index terms—adversarial perturbations fooling cnns stability neural networks perturbations universal generalizable attacks attacks systems data-free objectives adversarial noise. adversarial perturbations shown signiﬁcantly affect output machine learning systems. neural network based models despite excellent performance observed vulnerable adversarial attacks. particularly deep convolutional neural networks based vision models fooled carefully crafted quasi-imperceptible perturbations. multiple hypotheses attempt explain existence adversarial samples viz. linearity models ﬁnite training data etc. importantly adversarial perturbations generalize across multiple models. perturbations crafted model fools another model even second model different architecture trained different subset training data property adversarial perturbations enables potential intruders launch attacks without knowledge target model attack attack model typically known black-box attacking contrast attack model everything target model known attacker called white-box attacking. recently existing works assumed threat model adversaries directly feed input machine learning system. however kurakin lately showed adversarial samples remain misclassiﬁed even constructed physical world observed sensor given models vulnerable even physical world scenario models’ susceptibility poses serious issues deployability real world. particularly case critical applications involve safety security reliable models need deployed stand strong adversarial attacks. thus effect structured perturbations studied thoroughly order develop dependable machine learning systems. recent work moosavi-dezfooli presented existence image-agnostic perturbations called universal adversarial perturbations fool state-ofthe-art recognition models natural images. method crafting uaps based deepfool attacking method. involves solving complex optimization problem design perturbation. procedure utilizes training images iteratively update universal perturbation objective changing predicted label upon addition dataset images. similar metzen proposed semantic segmentation task. extended iterative fgsm attack kurakin change label predicted individual pixels craft perturbation. craft image-agnostic perturbations fool system order predict pre-determined target segmentation output. converge craft image-agnostic perturbation. moreover fooling performance resulting perturbation proportional available training data similarly objective crafting image-agnostic perturbation semantic segmentation models proposed also requires data. therefore optimization/objectives involve data existing procedures craft perturbations enough data provided. weaker black-box performance since information target models generally available attackers practical study black-box attacks. also black-box attacks reveal true susceptibility models white-box attacks provide upper bound achievable fooling. however black-box attacking performance poor compared white-box performance note that authors analyzed performance perturbations blackbox attack scenario. assumed training data target models known considered case adversary access different data. amounts performing semi white-box attacks. black-box attacks generally mean adversary access target network architecture large training dataset. case semantic segmentation worked targeted attacks observed perturbations generalize models well. task speciﬁcity current objectives craft uaps task speciﬁc. objectives typically designed suit underlying task hand concept fooling varies across tasks. particularly regression tasks depth estimation crowd counting idea fooling straight forward recognition task. order address shortcomings better analyze stability models present novel datafree objective craft universal adversarial perturbations. objective craft image-agnostic perturbations fool target model without knowledge data distribution number categories type data data samples themselves. since access data instead objective reduces conﬁdence predicted label predicted label propose objective learn perturbations adulterate features extracted models. proposed objective attempts over-ﬁre neurons multiple layers order deteriorate extracted features. inference time added perturbations misﬁre neuron activations order contaminate representations eventually predict wrong label. across multiple vision tasks further show apart data-free objective proposed method exploit minimal prior information training data distribution target models order craft stronger perturbations present comprehensive analysis proposed objective crafted perturbations across three different vision tasks covering classiﬁcation regression tasks. rest paper organized follows section presents detailed account related works section discusses proposed data-free objective craft imageagnostic adversarial perturbations section demonstrates effectiveness perturbations comprehensive experimentation section hosts discussion proposed method ﬁnally section concludes paper. related works szegedy demonstrated despite superior recognition performance neural networks susceptible adversarial perturbations. subsequently multiple works studied interesting surprising property machine learning models. though ﬁrst observed recognition models adversarial behaviour noticed models trained tasks semantic segmentation object detection deep reinforcement learning tasks etc. exist multiple methods craft malicious perturbations given data sample. recognition tasks range performing simple gradient ascent cost function solving complex optimizations simple fast methods fgsm gradient loss function determine direction image space perturb input image. iterative version attack presented achieves better fooling performing gradient ascent multiple times. hand complex approaches minimal perturbation move input across learned classiﬁcation boundary order predicted label. robust adversarial attacks proposed recently transfer real world invariant general image transformations moreover observed perturbations exhibit transferability property. means perturbations crafted model fool models different architectures trained disjoint training well further papernot introduced practical attacking setup model distillation understand black-box attacking. black-box attacking assumes information target model training data. proposed target model’s substitute craft perturbations. common underlying aspect techniques intrinsically data dependent. perturbation crafted given data sample independently others. however recent works moosavi-dezfooli metzen showed existence input-agnostic perturbations fool models multiple images. authors proposed iterative procedure based deepfool attacking method craft universal perturbation fool classiﬁcation models. similarly authors craft universal perturbations result target segmentation outputs. however works optimize different task speciﬁc objectives. also require training data craft image-agnostic perturbations. unlike existing works proposed method presents data-free objective craft perturbations without need data samples. also introduce generic notion fooling across multiple computer vision tasks over-ﬁring neuron activations. particularly objective generalizable across various vision models spite differences terms architectures regularizers underlying tasks etc. proposed approach section discuss proposed data-free objective craft uaps detail. first introduce notation followed throughout paper. denotes distribution images denotes function learned maps input image output note output task dependent example label object recognition segmentation semantic segmentation. denotes image-agnostic perturbation learned objective. note similar input also belongs though proposed objective task independent ease understanding explain proposed approach context object recognition. data-free objective fooling objective paper craft image-agnostic perturbation fools images target distribution without utilizing samples words seek universal adversarial perturbation signiﬁcantly alters prediction synthesize order adversarial perturbation imperceptible added images. therefore pixel intensities restricted imperceptibility constraint. typically realized max-norm constraint terms norms paper analysis impose max-norm constraint terms lnorm. thus however focus proposed work craft image-agnostic perturbations without requiring data samples data-free nature approach prohibits optimizing ﬁrst part eqn. learning approach contain data term proposed objective. therefore propose fool contaminating extracted representations input multiple layers architecture. words opposed typical ﬂipping label objective attempt over-ﬁre features extracted multiple layers. craft perturbation leads additional activation ﬁring layer thereby misleading features following layer. accumulated effect contamination eventually leads misclassify input. perturbation essentially causes ﬁlters particular layer spuriously abstract inefﬁcacious information. note presence data order mislead activations retaining useful discriminative information perturbation highly effective. also imperceptibility constraint makes challenging. hence without utilizing data seek image-agnostic perturbation produce maximal spurious activations layer given cnn. order craft start random perturbation optimize following objective activation output tensor layer network note activations considered non-linearity total number layers maximize activations caused perturbation max-norm limit proposed objective computes product activation magnitude individual layers order simultaneously maximize interference layers. observed product resulting stronger forms combining individual layer activations. understandable since product force individual activations rise order loss reduce. avoid working extreme values apply product. note objective open-ended optimum value reach. would ideally want cause much strong disturbance layers possible respecting imperceptibility constraint. implementation details begin target network trained whose parameters frozen random perturbation perform proposed optimization update causing strong activations multiple layers given network. typically consider convolution layers fully connected layers. because conv layers generally considered learn required features extract information series layers perform classiﬁcation. also empirically found efﬁcient optimize conv layers. therefore restrict optimization feature extraction layers. case advanced architectures googlenet resnet optimize last layers inception blocks independent conv layers. observed optimizing layers results fooling capacity similar resulting optimizing layers however since optimizing note optimization updates perturbation network parameters. additionally image data involved optimization process. update gradients computed loss eqn. iteratively till fooling performance learned gets saturated validation images. order validate fooling performance learned compose unrelated substitute dataset since objective utilize data samples training dataset target models randomly select images substitute dataset serve validation images. note that reasonable assumption attacker access unrelated images. crafting perturbations object recognition models trained ilsvrc dataset choose samples pascal voc- dataset. similarly semantic segmentation models trained pascal choose validation samples ilsvrc depth estimation models trained kitti dataset choose samples places- dataset. exploiting additional priors though proposed method data-free optimization crafting image-agnostic perturbations exploit simple additional priors data distribution section demonstrate method utilize simple priors mean value dynamic range input target data samples. mean dynamic range input note proposed optimization consider information present norm limited input maximize resulting activations. optimization input target dynamic range however inference time input lies range. therefore becomes challenging learn perturbations affect neuron activations presence strong input signal hence order make learning easier provide useful information data optimization better explore space perturbations. thus slightly modify objective craft relative dynamic range data. create pseudo data randomly sampling gaussian distribution whose mean equal mean training data variance covers density dynamic range input. essentially solve following essentially operate proposed optimization closer subspace target data distribution words eqn. acts place holder actual data helps learn perturbations over-ﬁre neuron activations presence actual data. iteration optimization process sample normal distribution feed target cnn. also perform typical augmentations ﬂipping cropping slight rotation etc. sampled construct variations. target data samples subsection formulate data-free objective utilize samples target distribution beneﬁt improve fooling ability crafted perturbations. note case data availability design direct objectives reducing conﬁdence predicted label changing predicted label etc. however investigate data-free objective over-ﬁring activations though designed utilize data crafts better perturbations data presented optimization. additionally objective utilize data manipulate predicted conﬁdences labels. rather optimization beneﬁts prior information data distribution dynamic range local patterns etc. provided actual data samples. therefore minimal data samples solve following optimization problem note presenting data samples optimization procedure natural extension presenting dynamic range target data alone case utilize subset training images target models trained improved optimization subsection present improvements propose earlier optimization presented conference paper proposed objective observed quickly accumulate beyond imposed max-norm constraint clipping performed iteration updates futile reaching constraint. order tackle saturation re-scaled half dynamic range regular time intervals iterations. though re-scaling helps learn better inefﬁcient since performs blind re-scaling without verifying scope updating example learning progresses magnitude updates decreases interval iterations values might reach extreme values projecting re-scaling badly affect learning. therefore propose adaptive re-scaling based rate saturation pixel values. optimization iteration compute proportion pixels reached max-norm limit learning progresses since objective open ended number pixels reach max-norm limit clipping eventually saturated hence rate increase decreases saturates. compute rate saturation denoted pixels iteration training. consecutive iterations increase signiﬁcant perform re-scaling half dynamic range. note proposed criterion re-scaling similar typical usage validation performance stop training. observe proposed adaptive re-scaling consistently leads better learning. algorithmic summarization subsection sake brevity summarize proposed data-free objective form algorithm. algorithm presents proposed optimization series steps. note generic form comprising three variations including data-free prior versions. ease reference repeat notation. fooling rate iteration activation caused layer input learning rate used training gradient loss respect input rate saturation pixels perturbation iteration threshold rate saturation fooling rate patience interval validation verifying convergence proposed optimization. generalized fooling rate respect metric notion ‘fooling’ well deﬁned task image recognition tasks measure ‘fooling’ unclear. hence order provide interpretable metric measure ‘fooling’ introduce consider task image recognition. task fooling rate perturbation deﬁned data samples labels changed perturbation. i.e. data samples output label adversarial attack different. fooling rate data samples label adversarial attack remains same. consider labels clean samples ground truth labels perturbed samples predicted labels top- accuracy model. leads introduce following deﬁnition generalized fooling rate. metric measuring performance model task range metric take inputs predicted output ground truth output performance model measured output model input perturbed perturbation then generalized fooling rate respect measure deﬁned fooling rate measure change model’s output caused perturbation. independent ground truth dependant primarily measures change output. methods metric value attack properly capture this. poorly performing model however robust adversarial attacks show poor values highlighting robustness. example equal change output extreme cases reach given task. hence compared across tasks. measures performance perturbation terms damage caused model respect metric. important feature tasks depth estimation multiple performance measures perturbation might cause harm metrics leaving metrics unaffected. experiments section present experimental evaluation demonstrate effectiveness proposed data-free objective. consider three different vision tasks demonstrate generalizability objective namely object recognition semantic segmentation unsupervised monocular depth estimation. note applications include classiﬁcation regression tasks. also supervised unsupervised learning setups. proposed objective without utilizing data samples range prior diagonal rates indicate white-box attack scenario off-diagonal ones represent black-box attack scenario. note highest fooling rate attacking given model shown fig. universal adversarial perturbations crafted proposed data-free objective multiple models trained ilsvrc dataset. perturbations crafted using minimal prior i.e. mean dynamic range input samples corresponding target network architecture mentioned perturbation. images best viewed color. experiments adam optimization algorithm used learning rate threshold rate saturation validation fooling rate measured substitute dataset every iterations threshold rate saturation crossed. crossed still measured every iterations. note none algorithm speciﬁc hyper-parameters changed across tasks across prior scenarios. object recognition worked models trained ilsvrc places- datasets viz. caffenet vggf googlenet vgg- vgg- resnet since approach involve training models experiments work available trained models. also unlike training data data-free case training data used. however explained earlier images randomly chosen pascal voc- train images validation optimization. also case exploiting additional data prior limited data corresponding training set. however evaluating perturbations learned target models trained ilsvrc dataset images validation used. similarly places- dataset contains validation images categories fooling rates computed. centage test images crafted perturbation successfully changed predicted label. higher fooling rate greater perturbation’s ability fool lesser classiﬁer’s robustness. fooling rates table obtained using mean dynamic range prior training distribution table indicates target model employed learning process columns indicate various models attacked using learned perturbations. diagonal fooling rates indicate white-box attacking information model known attacker. off-diagonal rates indicate black-box attacking information model attack revealed attacker. however note dataset models trained same. perturbations cause mean white-box fooling rate mean black-box fooling rate note that given data-free nature optimization fooling rates alarmingly signiﬁcant. high fooling rates achieved proposed approach adversely affect real-world deployement models. figure shows example image-agnostic perturbations crafted proposed method. note perturbations look different target cnns. however perturbations corresponding models look slightly similar owing architectural similarity. figure shows sample perturbed images vgg- ilsvrc validation set. shows clean bottom shows corresponding adversarial images. note adversarially perturbed images visually indistinguishable form corresponding clean images. clean images shown ﬁgure correctly classiﬁed successfully fooled added perturbation. image corresponding fooling rates achieved proposed objective without utilizing prior information training distribution models. comparison provide random baseline existing data-free data dependent objectives. note best fooling rate fig. sample universal adversarial perturbations crafted proposed method multiple settings pair models trained ilsvrc dataset. perturbations crafted data minimal data prior data scenarios. first three perturbations crafted vgg- later three resnet- corresponding setting mentioned perturbation. images best viewed color. exploiting minimal prior section present experimental results demonstrate data-free objective exploit additional prior information target data distribution discussed section note consider cases providing mean dynamic range data samples denoted range prior utilizing minimal data samples optimization denoted data prior table shows fooling rates obtained withutilizing prior information. note fooling rates computed white-box attacking scenario. emphasize effectiveness proposed objective present fooling rates obtained random baseline perturbation. since learned perturbation norm limited sample random compute fooling rates. denote results ‘baseline’ column table also comparison fooling rates obtained data-free objective data dependent objective presented. important observations draw table listed below comparison data-free objectives subsection compare effectiveness proposed objective existing data-free objective proposed conference publication compare maximizing mean versus norm activations caused perturbation table shows comparison fooling rates obtained objectives improved optimization setup chosen representative models across various generations architectures compare effectiveness proposed objective. note improved objective consistently outperforms previous signiﬁcant similar behaviour observed vision tasks also. fig. sample original adversarial image pairs ilsvrc validation generated vgg-. first shows original images corresponding predicted labels second shows corresponding perturbed images along predictions. note shown perturbed images misclassiﬁed. dependent objectives suffer signiﬁcant drop fooling ability perturbations. note that denotes data used craft perturbations fool models trained data also note fooling rates approach crafted without utilizing data samples subsection demonstrate necessity data dependent objective samples target distribution only. methods craft perturbations fooling objective require samples training data distribution optimization. show crafting arbitrary data samples leads signiﬁcantly inferior fooling performance. table shows fooling rates data dependent objective arbitrary data samples utilized place target samples. experiment places- data craft perturbations models trained ilsvrc denoted places- ilsvrc vice versa. setups training images used. note that rates proposed method obtained without utilizing data rates data-free scenario found table clearly fooling rates suffer signiﬁcantly perturbations strongly tied target data. hand proposed method since craft optimizing fooling objective fooling performance decrease. importantly experiments show data dependent objectives effective samples target distribution fig. reliance data dependent objective size available training data samples. fooling rate crafted perturbations monotonically increases number training data samples available optimization. note approach utilizes data samples achieves competitive fooling performance. available. practical scenarios difﬁcult procure training data. also data dependent objectives rely available training data ability crafted perturbations heavily depends size data utilized crafting process. show fooling performance monotonically increases size available samples optimization. figure shows fooling rates obtained perturbations crafted multiple recognition models trained ilsvrc varying size samples available optimization. craft different perturbations utilizing data samples evaluate ability fool various models. note performance crafted perturbations increases drastically available data samples optimization. comparison fooling rates obtained proposed data-free objective shown green. generalized fooling rates achieved perturbations crafted proposed approach various settings. note comparison fooling rates achieved random perturbations also presented. subsection demonstrate effectiveness data-free objective craft universal adversarial perturbations semantic segmentation. consider four network architectures. ﬁrst architectures fcn-alex based alexnet fcn-s-vgg based -layer vggnet last architectures -layer vggnet based dl-vgg dl-rn multi-scale architecture based resnet- architetures trained pascal voc- dataset consisting training samples remaining architectures trained pascal dataset consisting training samples. however testing perturbation’s performance validation provided consist images. semantic segmentation realized assigning label image pixels. models typically trained perform pixel level classiﬁcation categories using crossentropy loss. performance commonly measured terms mean computed predicted ground truth. extending generation framework provided segmentation non-trivial task. however generalizable data-free algorithm applied task semantic segmentation without changes. similar recognition setup present multiple scenarios crafting perturbations ranging data utilizing data samples target distribution. interesting observation respect data samples pascal voc- that training samples pixels belong ‘background’ category. this craft perturbation using training data samples target distribution prior optimization process encounters roughly pixels belonging ‘background‘ category pixels belonging rest categories. result data imbalance perturbation sufﬁciently capable corrupt features pixels belonging categories ‘background’. handle issue curate smaller training samples pascal voc- sample less pixels belonging ‘background’ category. denote data less pixels dataset belong ‘background’ category. perturbations crafted using dataset target distribution prior show higher capability corrupt features pixels belonging rest categories. since mean average categories observe perturbations crafted using data less cause substantial reduction mean measure well. table shows generalized fooling rates respect mean obtained proposed objective various data priors. explained section generalized fooling rate measures change performance network respect given metric case mean iou. note that similar recognition case fooling performance monotonically increases addition data priors. observation emphasizes proposed objective though indirect nonfooling nature rightly exploit additional prior information training data distribution. also models generally data less background scenario results best fooling rate. attributed fact data less background scenario lessen data-imbalance leads perturbations fool background object pixels. also comparison present fooling rates achieved random perturbation sampled note similar recognition experiments segmentation experiments value table present mean metric obtained perturbed images learned various scenarios along original mean obtained clean images. comparison baseline random noise perturbation sampled also provided. clearly observed random perturbation effective fooling segmentation models. however proposed objective crafts perturbations within range signiﬁcantly fool models. also show mean obtained image speciﬁc adversarial perturbation crafting work. note since proposed method image-agnostic approach unfair expect fig. universal adversarial perturbations semantic segmentation crafted proposed data-free objective multiple models. perturbations crafted using less prior. corresponding target network architecture mentioned perturbation. images best viewed color. fig. sample universal adversarial perturbations semantic segmentation crafted proposed method multiple settings fcn-svgg. perturbations crafted priorrange prior data less prior data prior scenarios. corresponding scenario mentioned perturbation. images best viewed color. fig. sample original adversarial images pascal- dataset generated fcn-alex. first shows clean adversarial images various priors. second shows corresponding predicted segmentation maps. similar performance further mean shown dl-vgg dl-rn models denote transfer performance i.e. black-box attacking hence smaller drop mean clean images. however provided means weak comparison instead comparison. finally section providing qualitative results. figure shows sample image-agnostic adversarial perturbations learned objective semantic segmentation. figure show perturbations learned data less prior models. similar recognition case perturbations look different across architectures. figure show perturbations learned fcn-s-vgg model various scenarios ranging prior full data prior. note that even given network perturbations learned various priors look different. figures shows example image predicted segmentation outputs fcn-alex model perturbations crafted various priors. shows clean perturbed images. bottom shows predictions corresponding inputs. note type prior utilized craft perturbation mention predictions. crafted perturbations clearly successful misleading model predict inaccurate segmentation maps. note color shown predictions provides labels. figure shows effect perturbation multiple networks. shows output maps predicted various models input perturbed corresponding learned data less prioir. interesting note figure image uaps crafted using prior different networks different outputs even outputs clean images similar. fig. segmentation predictions multiple models sample perturbed image. perturbations crafted using data less prior. ﬁrst shows perturbed input image second shows segmentation output clean sample image third shows segmentation output perturbed sample image. corresponding target network architecture mentioned column. images best viewed color. recent works show increase convolutional networks regression-based computer vision task. natural question whether susceptible universal adversarial attacks cnns used classiﬁcation. section crafting uaps convolutional networks performing regression show equally susceptible universal adversarial attacks. best knowledge ﬁrst provide algorithm crafting universal adversarial attacks convolutional networks performing regression. many recent works like perform depth estimation using convolutional network. authors introduce monodepth encoder-decoder architecture regresses depth given monocular input image. craft using proposed method variants monodepth monodepth-vgg monodepth-resnet. network trained using kitti dataset form dataset contains rectiﬁed stereo pairs scenes typical image pixels size. show results eigen case object recognition uaps crafted proposed method monodepth also show potential exploit priors data distribution. consider three cases providing priors range prior data prior. providing data priors randomly pick image samples kitti train dataset. attain complete independence target data training procedure crafting perturbation perform validation randomly picked images places- dataset. optimization procedure followed case previous task. table show performance monodepthresnet monodepth-vgg respectively presence various uaps crafted proposed method. observed tables crafted uaps strong impact performance networks. variants monodepth uaps crafted fig. sample original adversarial image pairs kitti dataset generated monodepth-vgg. first shows clean perturbed images various priors. second shows corresponding predicted depth maps. performance crafted perturbations monodepth-resnet using various metrics evaluating depth estimation eigen test-split kitti datset. results presented various scenarios clean data perturbations learned prior various priors train mean. note best fooling results scenario shown bold. evaluation trainset mean performance taken mean. note best fooling results scenario shown bold. evaluation trainset mean performance taken note ﬁrst four metrics error based later three precision based range prior bring accuracy threshold units average. data priors crafted uaps able increase almost times original performance. impact crafted uaps network’s performance drops baseline uses train mean prediction image pixels. table shows generalized fooling rates respect accuracy threshold units surprising observation table performance range prior perturbations networks surpasses data prior perturbations. might lead understand range prior perturbations stronger. however generalized fooling rate measures change network’s outcome respect metric. observed table data prior perturbations much harsher effect error metrics like root mean square error whereas range prior perturbations harsher effect precision metrics like hence ‘which perturbation better?’ rather metric dependant question conclusions based figures show qualitative examples showing perturbed input change output. figure shows input-output pair monodepth-vgg input perturbed various kinds uaps crafted. figure compares input-output pair monodepthvgg monodepth-resnet using range-prior uap. show ﬁgures versions monodepth quasi-imperceptible change input cause large change output. fig. universal adversarial perturbations depth estimation task crafted using proposed algorithm.top shows perturbations learned monodepth-resnet bottom shows monodepth-vgg. perturbations crafted priorrange prior data prior scenarios. corresponding scenario mentioned column. images best viewed color. fig. depth predictions models sample perturbed image. perturbations crafted using range prior.the corresponds monodepth-resnet bottom corresponds monodepth-vgg. ﬁrst column shows perturbed input image second shows depth output clean sample image third shows depth output perturbed sample image. images best viewed color. learned representations layer? features learned cnns robust small changes input small change input layer leads huge change output mentioned earlier ‘fooling’ refers instability terms output independent task hand. earlier works proven cnns fooled small learned noise. works rely data directions input slightly perturbed order fool cnn. approaches simple methods gradient ascent directions network’s conﬁdence falls. recent works moosavidezfooli nearest classiﬁcation boundary given sample perturb moving across boundary thereby achieve fooling. also establish possible learn single perturbation work input images. thus existing works exploit data samples model’s conﬁdence classiﬁcation boundaries input space order craft adversarial perturbations either image speciﬁc agnostic. unlike existing works depict stability issue learned representations cnns. attempt learn optimal perturbation input space cause maximal change output network. fig. percentage relative change extracted representations caused crafted perturbations multiple layers vgg-. note deeper amount perturbation increases drastically results eventual misclassiﬁcation input. demonstrated experimentation section evident proposed algorithm able craft perturbations achieve ‘fooling’ variety computer vision tasks. important question convolutional neural networks stable achieve learning perturbations result maximal change activations intermediate layers architecture. example consider trained object recognition illustrate working objective. figure shows percentage relative change feature activations various layers architecture. also relative change shown variants method utilize prior information training data distribution. note percentage relative change feature activations addition learned perturbation increases monotonically deeper network. accumulated perturbation projection input learned adversaries able fool cnns independent task hand. phenomenon explains fooling achieved objective. also figure shows utilization data priors relative perturbation increases. hence objective achieves better fooling prior information provided during learning. note that comparison baseline perturbation random noise equal max-norm learned perturbations provided. perturbation caused random noise almost negligible layers explains robustness random noise attacks. finally relate relative change caused perturbations input classiﬁcation layer fooling rates achieved various perturbations. table shows relative shift feature activations li−li input classiﬁcation layer adversarial perturbations importantly show proposed objective generalizable across multiple architectures also across diverse computer vision tasks. demonstrated seemingly simple objective injecting maximal adversarial energy learned representations effective fool classiﬁcation regression models. signiﬁcant transfer performances achieved further show objective exploit minimal priors target data distribution craft stronger perturbations. example providing simple information mean dynamic range images proposed objective would craft signiﬁcantly stronger perturbations. though proposed objective data-free nature craft stronger perturbations data utilized. importantly introduced idea generalizable objectives craft image-agnostic perturbations. already established representations learned deep models susceptible. existence generic objectives fool learning based vision model independent underlying task pose critical concerns model deployment. therefore important research direction focused community order build reliable machine learning based systems. biggio fumera roli pattern recognition systems attack design issues research challenges international journal pattern recognition artiﬁcial intelligence vol. biggio corona maiorca nelson ˇsrndi´c laskov giacinto roli evasion attacks machine learning test time joint european conference machine learning knowledge discovery databases szegedy zaremba sutskever bruna erhan goodfellow fergus intriguing properties neural networks arxiv preprint arxiv. goodfellow shlens szegedy explaining harnessing adversarial examples arxiv preprint arxiv. learning scale arxiv preprint arxiv. moosavi-dezfooli fawzi frossard deepfool simple accurate method fool deep neural networks ieee computer vision pattern recognition moosavi-dezfooli fawzi fawzi frossard universal adversarial perturbations ieee conference computer vision pattern recognition mopuri garg babu fast feature fool data independent approach universal adversarial perturbations proceedings british machine vision conference fig. sample failure case object recognition using vgg- model. shows multiple clean images ilsvrc validation set. bottom shows adversarial images generated adding perturbation crafted utilizing data prior. note shown images perturbation fails change predicted label. fig. sample failure case semantic segmentation using fcn-s-vgg model. shows clean corresponding perturbed images prior various priors. bottom shows predicted segmentation maps. note people segments undisturbed addition various perturbations. fig. sample failure case depth estimation using monodepth-vgg model. note that shows clean image corresponding perturbed images data case various prior cases. bottom shows corresponding depth predictions. nguyen yosinski clune deep neural networks easily fooled high conﬁdence predictions unrecognizable images computer vision pattern recognition rozsa rudd boult adversarial diversity hard positive generation proceedings ieee conference computer vision pattern recognition workshops bastani ioannou lampropoulos vytiniotis nori criminisi measuring neural robustness constraints advances neural information processing systems athalye engstrom ilyas kwok synthesizing robust adversarial examples arxiv preprint arxiv. szegedy sermanet reed anguelov erhan vanhoucke rabinovich going deeper russakovsky deng krause satheesh huang karpathy khosla bernstein berg fei-fei imagenet large scale visual recognition challenge international journal computer vision vol. chatﬁeld simonyan vedaldi zisserman return devil details delving deep convolutional nets proceedings british machine vision conference simonyan zisserman very deep convolutional large-scale image recognition arxiv preprint chen papandreou kokkinos murphy yuille deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs international conference learning representations l.-c. chen papandreou kokkinos murphy yuille deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs arxiv preprint arxiv. ricci ouyang wang sebe multi-scale continuous crfs sequential deep networks monocular depth estimation ieee conference computer vision pattern recognition july eigen puhrsch fergus depth prediction single image using multi-scale deep network advances neural information processing systems godard aodha brostow unsupervised monocular depth estimation left-right consistency ieee conference computer vision pattern recognition", "year": 2018}