{"title": "Premise Selection for Mathematics by Corpus Analysis and Kernel Methods", "tag": ["cs.LG", "cs.AI", "68T05", "I.2.6; I.2.3"], "abstract": "Smart premise selection is essential when using automated reasoning as a tool for large-theory formal proof development. A good method for premise selection in complex mathematical libraries is the application of machine learning to large corpora of proofs. This work develops learning-based premise selection in two ways. First, a newly available minimal dependency analysis of existing high-level formal mathematical proofs is used to build a large knowledge base of proof dependencies, providing precise data for ATP-based re-verification and for training premise selection algorithms. Second, a new machine learning algorithm for premise selection based on kernel methods is proposed and implemented. To evaluate the impact of both techniques, a benchmark consisting of 2078 large-theory mathematical problems is constructed,extending the older MPTP Challenge benchmark. The combined effect of the techniques results in a 50% improvement on the benchmark over the Vampire/SInE state-of-the-art system for automated reasoning in large theories.", "text": "abstract smart premise selection essential using automated reasoning tool large-theory formal proof development. good method premise selection complex mathematical libraries application machine learning large corpora proofs. work develops learning-based premise selection ways. first newly available minimal dependency analysis existing high-level formal mathematical proofs used build large knowledge base proof dependencies providing precise data atp-based re-veriﬁcation training premise selection algorithms. second machine learning algorithm premise selection based kernel methods proposed implemented. evaluate impact techniques benchmark consisting large-theory mathematical problems constructed extending older mptp challenge benchmark. combined eﬀect techniques results improvement benchmark vampire/sine state-of-the-art system automated reasoning large theories. paper signiﬁcantly improve theorem proving large formal mathematical libraries using two-phase approach combining precise proof analysis machine learning premise selection. dialogical foundations semantics eurocores programme logiccc research paper partially done visiting fellow isaac newton institute mathematical sciences programme ‘semantics syntax’. brary analysis allows construct precise problems atpbased re-veriﬁcation mizar proofs. importantly precise dependency data used large repository previous problem-solving knowledge premise selection eﬃciently automatically learned machine learning algorithms. second phase complementary improvement achieved using kernel-based machine learning algorithm outperforms existing methods premise selection. means based large number previously solved mathematical problems accurately estimate premises useful proving conjecture. learned knowledge considerably helps automated proving formally expressed mathematical problems recommending relevant previous theorems deﬁnitions large existing libraries thus shielding existing methods considering thousands irrelevant axioms. better symbiosis formal mathematics learningassisted automated reasoning gets better parties improved automated reasoning increases eﬃciency formal mathematicians lowers cost producing formal mathematics. turn leads larger corpora previously solved nontrivial problems learning-assisted extract additional problem-solving knowledge covering larger larger parts mathematics. rest paper organized follows. section describes recent developments large-theory automated reasoning motivates problem. section summarizes recent implementation precise dependency analysis large atp-based cross-veriﬁcation training premise selection. section describes general machine learning approach premise selection eﬃcient kernel-based multi-output ranking algorithm premise selection. section large-theory benchmark related problems deﬁned extending older smaller mptp challenge benchmark techniques evaluated benchmark section section concludes discusses future work extensions. recent years large formal libraries re-usable knowledge expressed rich formalisms built interactive proof assistants mizar isabelle others. formal approaches also used increasingly non-mathematical ﬁelds software hardware veriﬁcation common-sense reasoning real-world knowledge. trends lead growth formal knowledge bases ﬁelds. important development number formal knowledge bases core logics translated ﬁrst-order formats suitable atps ﬁrst-order today routinely used proof assistance systems like isabelle mizar ﬁrst-order translations give rise large semantically rich corpora present signiﬁcant challenges ﬁeld automated reasoning. techniques developed large theories broadly divided categories ﬁrst category sine preprocessor hoder successful. sine particularly strong domains many hierarchical deﬁnitions common-sense ontologies. second category machine learning premise selection done e.g. malarea system eﬀective method hard mathematical domains knowledge bases contain proportionally many nontrivial lemmas theorems simple deﬁnitions previous veriﬁed proofs used learning proof guidance. automated reasoning large mathematical corpora interesting ﬁeld several respects. large theories permit data-driven approaches constructing algorithms; indeed sheer size libraries actually necessitates methods. turns purely deductive bruteforce search methods improved signiﬁcantly heuristic inductive methods thus allowing experimental research combinations inductive deductive methods. large-theory benchmarks like mptp challenge extended version developed section serve rigorous evaluation novel artiﬁcial intelligence methods thousands real-world mathematical problems. apart novel aspect obvious proof assistance aspect automated reasoning large formal mathematical corpora also become tool established ﬁeld reverse mathematics line research already started example solovay’s analysis connection tarski’s axiom axiom choice alama’s analysis euler’s polyhedron formula conducted mml. world automated theorem proving proofs contain essentially logical steps even small ones world interactive theorem proving goals allow users express minimal verbosity. towards interactive theorem proving systems often come mechanisms suppressing steps argument. design suppress logical mathematical steps might necessary complete analysis word inductive denotes inductive reasoning opposed deductive reasoning. http//www.tptp.org/mptpchallenge evaluate casc datasets small allow machine learning techniques. goal help mathematicians work re-use large amounts previously established complex proofs theorems. particular proof depends upon. section summarize recently developed solution problem mml. basis solution refactoring articles one-item micro-articles computing minimal dependencies brute-force minimization algorithm. detailed discussion mizar detailed discussion refactoring minimization algorithms means variable type unary function symbol accepts arguments type suppose that prior assertion theorem proved subtype wellformedness theorem depends subtyping relationship. moreover proof theorem mention fact; subtyping relationship well outright theorem. situation fact suppressed. requiring author formal proof supply subtyping relationships permit focus heart matter proof rather repeating obvious. interested giving complete answer question formalized proof depends upon must expose suppressed facts inferences. complete answer important number applications examples. particular importance work described eﬃcient ﬁrst-order atps used assist high-level formal proof assistants like mizar diﬀerence implicitly used facts explicitly used facts disappears. atps need explicitly know facts necessary ﬁnding proofs. ﬁrst step computation ﬁne-grained dependencies mizar break article sequence mizar texts consisting single top-level item texts can— suitable preprocessing—be regarded complete valid mizar article right. decomposition whole article smaller articles typically requires number nontrivial refactoring steps comparable e.g. automated splitting re-factoring large programs written programming languages complicated syntactic mechanisms. mizar every article begins so-called environment specifying background knowledge used verify article. actual mizar content imported given environment general rather conservative overestimate items article actually needs. apply greedy minimization process environment compute minimal items suﬃcient verify micro-article. produces minimal dependencies mizar item syntactic semantic drawback minimization process greedy approach minimization certain kinds dependencies time consuming. advantage computed dependencies truly minimal include redundant dependencies typically drawn overly powerful proof checking algorithms dependency tracking implemented internally inside proof assistant. dependency minimization particularly important premise-selection applications explained paper routine computation minimal dependencies good time investment provide better guidance fast-growing search space explored atps. another advantage approach also provides syntactic dependencies needed real-world recompilation particular item written article. functionality important fast ﬁne-grained recompilation formal wikis however semantic applications like considering truly semantic dependencies i.e. dependencies result formula translated mptp system ﬁrst-order logic. table provides summary ﬁne-grained dependency data mizar articles coming mptp benchmark developed section used experiments section theorem sequence mizar articles show many explicit dependencies involved proofs many implicit dependencies contains. table also shows much improvement exact dependency calculation compared simple safe ﬁxed-point mptp construction over-approximation truly used proof. reasoning large theory thousands premises available. presence large numbers premises performance systems degrades considerably typically fraction available premises actually needed construct proof. estimating premises likely useful constructing proof research problem article mizar article relevant mptp benchmark. theorems total number theorems article. expl. refs. average number explicit references used items theorem computed dependency analysis. knowledge previous proofs problem-solving techniques used mathematicians guide thinking problems. detailed proof analysis described provides large computer-understandable corpus dependencies mathematical proofs. section present machine learning setting algorithms used train premise selection corpora. goal begin emulating training human mathematicians. translation mizar formats applied mizar theorems proof dependencies translate ﬁrst-order formulas used corresponding problems conjectures premises presentation identify formula ﬁrst-order translation. work following setting tailored easily translated large datasets. ﬁrst order formulas appear mml. words adjacency matrix graph direct proof dependencies. proof matrix together suitably chosen formula features used training machine learning algorithms. mathematical textbook practice typically proof given particular theorem. however obvious example expansion proof dependencies lead alternative proof. general given mathematical theory variety less related alternative proofs particular theorem. variety however typically explicit textbook data mathematicians study. variety formed minds studying textbook proofs typically chosen nice properties hence also plausible proofs training algorithms attempt emulate human proof learning. often refer premises used proof theorem premises concept read premises rather particular premises used human training therefore also likely useful training computers. would diﬃcult relax approach corpora learn contained number good alternative proofs. however case current conduct experiments. also note although training consists formal proofs proofs authored humans found fully automatically atps. evaluation conducted done running atps recommended premises. could case fully automatically found proof would provide better training example human proof mml. major obstacle training however relative weakness existing atps ﬁnding involved proofs theorems thus failure provide training examples large part mml. still comparison power training proofs could interesting future work. note choice feature characterization quite arbitrary. could symbols terms totally diﬀerent features. better features correspond concepts relevant choosing theorems solving particular problem successful machine learning premise selection case using alternative proofs training note ﬁnding suitable feature characterizations interesting problem area current choice seems perform already quite reasonably experiments. particular heuristic justiﬁcation using formula terms premise selection problem treated ranking problem classiﬁcation problem. ranking approach given conjecture rank available premises predicted usefulness automated proof number premises highest ranking classiﬁcation approach standard classiﬁcation premise would used certain threshold. common approach ranking classiﬁcation combine real-valued classiﬁers premises conjecture ranked values choose certain number best ones. approach paper. given training corpus machine learning algorithms automatically learn classiﬁer functions. main diﬀerence learning algorithms function space search classiﬁers measure evaluate good classiﬁer prior work applications machine learning techniques premise selection problem used snow implementation multiclass naive bayes learning method eﬃciency. work experiment state-of-the-art kernel-based learning methods premise selection. present methods show beneﬁts using kernels. naive bayes statistical learning method based bayes’s theorem conditional probabilities strong independence assumptions. naive bayes setting value classiﬁer function premise conjecture probability given expressed features naive bayes algorithm gives rise linear classiﬁer. leads several questions ‘are better parameters?’ ‘can better performance non-linear functions?’. kernel-based learning provides framework investigating questions. subsection give simpliﬁed brief description kernel-based learning tailored present problem; information answer question must ﬁrst deﬁne ‘better’ means. using number problems solved measure feasible cannot practically every possible parameter combination. instead measure good classiﬁer approximates training data. would like compare diﬀerent classiﬁers expected loss. expected loss classiﬁer less expected loss classiﬁer better classiﬁer. noted lower expected loss particular training need necessarily lead solved problems atp. could imagine training contains proofs diﬀerent particular would proceed easily. also happens classiﬁer able predict premises large part them? questions alternative proofs robustness prediction methods. experimental answer provided section seems straightforward complex functions would lead lower expected loss hence desirable. however parameter optimization becomes tedious leave linear case. kernels provide machinery linear optimization non-linear functions. essentially every function compares input formulas using kernel weights determine important comparison kernel function space naturally depends kernel shown klin fklin consists linear functions deﬁned loss functions kernels kernel function spaces deﬁne kernel-based learning algorithms learn classiﬁer functions. given kernel loss function recall measure good classiﬁer expected loss deﬁnitions seems reasonable deﬁne however kernel based learning algorithm does. reasons this. first minimum might exist. second particular using complex kernel functions approach might lead overﬁtting might perform well training data data seen before. handle problems regularization parameter introduced penalize complex functions regularization parameter allows kernel-based methods typically outperform naive bayes algorithm. several reasons this. firstly importantly naive bayes essentially linear classiﬁer kernel based methods learn non-linear dependencies appropriate non-linear kernel function used. advantage expressiveness usually leads signiﬁcantly better generalization performance algorithm given properly estimated hyperparameters secondly kernel-based methods formulated within regularization framework provides mechanism control errors training complexity prediction function. setting prevents overﬁtting algorithm leads notably better results compared unregularized methods. thirdly kernel-based methods eﬃcient procedures hyperparameter estimation therefore result close optimal model classiﬁcation/regression task. reasons kernel-based methods among successful algorithms applied various problems bioinformatics information retrieval computer vision general advantage naive bayes kernel-based algorithms computational eﬃciency particularly taking account fact computing kernel matrix generally quadratic number training data points. however recent advances large scale learning extensions various kernel-based methods svms sublinear complexity provably fast convergence rate generalization performance cannot matched methods ﬁeld experiments deﬁne kernel-based multi-output ranking algorithm relatively straightforward extension preference learning algorithm presented also based regularized least-squares algorithm presented recall classiﬁer single premise. since eventually want rank premises need train classiﬁer premise. need weights premise seem complicate problem quite bit. however fact premise experiments gaussian kernel kgauss deﬁned example ergo regularization parameter kernel parameter optimal weights simple matrix computations. thus fully determine classiﬁers remains good values parameters done common parameter optimization kernel methods simple grid search crossvalidation training data using split. eﬀects using minimized dependency data eﬀect using kernel-based algorithm evaluated newly created large-theory benchmark related problems extends older smaller mptp challenge benchmark. original mptp challenge benchmark created purpose supporting development arlt techniques. contains related problems leading mizar proof implication bolzano-weierstrass theorem. challenge divisions chainy bushy motivation behind given describe analogs mptp benchmark. arlt techniques computing power developed since appropriately deﬁne larger benchmark larger numbers problems premises making precise dependency knowledge. larger number problems together dependencies faithfully mirror setting mathematicians facing typically know number related theorems proofs solving problem. mptp benchmark created follows mizar articles problems previously selected constructing mptp challenge used. however version mizar allowing precise dependency analysis problems articles. yields problems. mptp challenge benchmark create groups problems. chainy versions problems containing previous contents premises. means conjecture attacked existing knowledge without premise selection. common case proving conjectures fully automatically also section mptp challenge name chainy introduced division problems dependencies ordered chronological chain emulating growth library. bushy versions problems premises pruned using ﬁnegrained dependency information. use-case introduced proof assistants harrison’s meson tactic takes explicit list premises large library selected knowledgeable user attempts prove conjecture premises. interested powerful atps precise advice. evaluate beneﬁt precise minimal dependencies additionally also produce work versions problems premises pruned heuristic dependency-pruning method used constructing re-proving problems mptp system. mptp heuristic proceeds taking explicit premises contained original human-written mizar proof. premises used mizar implicitly heuristic watches problem’s symbols adds implicitly used formulas ﬁxpoint manner. heuristic attempts hard guarantee completeness however minimality achievable simple approach. three datasets contain conjectures. diﬀer number redundant axioms. note problems second third dataset considerably smaller unpruned problems. average number premises unpruned problems heuristically-pruned problems problems pruned using ﬁne-grained dependencies table summarizes datasets. vampire system experiments conducted here. adding systems useful recent evaluation) metasystems like malarea attempt exploit joint power diﬀerent systems organized way. however focus work premise selection shown similar eﬀect across main state-of-the-art systems. another reason using recent vampire vampire sine preprocessor suﬃciently tested tuned data providing good baseline comparing learningbased premise-selection methods robust state-of-the-art methods isolated large problem without learning. measurements done intel xeon .ghz server cache. problem always assigned cpu. section evaluate performance ﬁne-grained dependencies used comparing performance mptp heuristic pruning performance large versions mptp problems. results show gain constructing good algorithms premise selection. section snow’s naive bayes machine learning algorithms incrementally trained ﬁne-grained dependency data precision predicting premises problems compared. standard machine-learning comparison section completed running vampire premises predicted snow algorithms. provides information overall theorem-proving performance whole dependency-minimization/learning/atp stack. performance compared performance vampire/sine. ﬁrst experiment evaluates eﬀect ﬁne-grained dependencies reproving mizar theorems automatically. results vampire/sine time limit datasets deﬁned shown table vampire solves unpruned problems. parameter vampire solves problems. things change external premise pruning. vampire solves problems mptp heuristic pruning applied. using pruning based ﬁne-grained analysis vampire solves problems improvement heuristic pruning number problems solved. since heuristic pruning becomes inaccurate grows conjecture improvement even signiﬁcant considering whole mml. also note numbers point signiﬁcant improvement potential gained good premise selection performance pruned dataset doubled comparison unpruned dataset. again ratio grows grows number premises approaches several reasons time limits. first vampire performs reasonably second time limits useful conducting large-scale experiments combining diﬀerent strategies. third typical proof-advice scenarios preferable query response time seconds. fourth seconds much ﬁfteen years casc competition started. parameter limits depth recursion sine algorithm. running vampire pruning parameter resulted signiﬁcant performance improvement large mizar problems. evaluation done whole vampire/sine ratio next experiment emulate growth library considering previous theorems deﬁnitions conjecture attempted. natural advice whole library scenario problems however become large containing thousands previously proved formulas. premise selection therefore help signiﬁcantly. ﬁne-grained dependencies extracted previous proofs train premise-selection algorithms advice problems compare recall problem learning algorithms allowed learn dependencies previous problems corresponds situation general mathematics mathematicians know many previous theorems also re-use previous problem solving knowledge. approach requires training steps problems proofs added library dataset grows. compare algorithm snow’s naive bayes. figure shows average recall snow dataset. rankings obtained algorithms compared actual premises used proof computing size overlap increasing segments ranked predicted premises formally recall recall conjecture premises advised deﬁned seen algorithm performs considerably better snow. e.g. average used premises within highest mor-ranked premises whereas consider snow ranking around used premises highest ranked premises. note kind comparison standard endpoint machine learning applications like keyword-based document retrieval consumer choice prediction etc. however semantic domain like ours further improved prediction performance helps theorem proving process. also interesting example coverage original premises could insuﬃcient constructing proof unless invent alternative proofs. ﬁnal evaluation done next section. evaluate performance learning approximate bushy-old dependencies next subsection. table section already suﬃciently show data less precise ﬁne-grained dependencies. initial exploration phenomenon alternative proofs theorems. fig. comparison snow average recall premises used mizar proofs. x-axis shows number premises asked snow y-axis shows relative overlap premises used original mizar proof. last experiment ﬁnally chain whole itp/learning/atp stack together evaluate inﬂuence improved premise selection reﬂects performance automated theorem proving large-theory conjectures. naive bayes learning algorithms evaluated. figure shows numbers problems solved vampire using diﬀerent numbers premises predicted snow seconds time limit. maximum number problems solved advised premises. snow’s maximum premises. corresponding numbers second time limit solved problems mor- snow-. table compares data overall performance vampire second time limit problems pruning done sine. snow- resp. mor- runs give resp. improvement problems vampire solves auto-mode resp. improvement problems solved vampire using option. fig. comparison number solved problems snow mor. x-axis shows number premises given vampire y-axis shows number problems solved within seconds. number problems solved vampire/sine seconds given baseline. table additionally compares performance vampire/sine performance snow computed union runs largest joint coverage. obtained using advised premises advised premises snow advised premises mor. snow resp. combined runs give resp. improvement problems vampire solves auto-mode resp. improvement problems solved vampire using option. note vampire/sine strategy scheduling internally different sine parameters. thus combining diﬀerent premise selection strategies perfectly comparable vampire’s automated mode constructed used. also note combining diﬀerent ways unadvised vampire/sine productive union unadvised runs problems solved problems running vampire/sine seconds. finally figure figure compare cumulative average performance algorithms diﬀerent points mptp benchmark using chronological ordering mptp problems. average available number premises theorems ordered chronologically grows linearly making later problems harder average. figure shows performance computed initial segments problems using step value last value corresponds performance algorithms whole mptp example value shows performance algorithms ﬁrst mptp problems. figure compares average performance algorithms problems divided four successive segments equal size. note even precise premises problems uniform diﬃculty across benchmark average even bushy versions later problems harder. visualize this also values vampire-bushy comparison. except small deviations ratio solved problems decreases algorithms. vampire/mor- able keep vampire-bushy range initial problems human selection increasingly outperforms algorithms. making small possible obvious challenge path strong automated reasoning general mathematics. analysis large corpus theorems proofs using improved prediction algorithms. particular demonstrated premise selection based learning exact previous proof dependencies improves performance large mathematical theories using oﬀ-theshelf learning methods like naive bayes comparison state-of-the-art general premise-selection heuristics like sine. shown improved employing state-of-the-art kernel-based learning methods. automated reasoning large mathematical libraries becoming complex ﬁeld allowing interplay diﬀerent techniques. manual tuning strategies heuristics scale large complicated domains data-driven approaches becoming useful handling domains. time existing strong learning methods typically developed imprecise domains feedback loops prediction automated veriﬁed conﬁrmation done example malarea possible. stronger systems become closer formally assisted mathematics forward reverse form. obviously another positive feedback loop explore here larger body formally expressed veriﬁed ideas smarter systems learn them. work started improved many possible ways. achieved improvement large problems better premise selection resulting problems proved within seconds know better premise selection possible prove least problems. thus still great opportunity improved premise selection algorithms. dependency analysis ﬁner faster combined machine learning systems basis research tool experimental formal mathematics. interesting problem becoming relevant methods mathematics getting stronger translation proofs human-understandable formats used mathematicians. believe machine learning large human-proof corpora like likely useful task similar useful ﬁnding relevant premises. algorithm number parameterizations ﬁxed experiments done here. experiments diﬀerent loss functions could yield better results. interesting parameterizations right choice features formal mathematical domain. using symbols terms occurring formulas feature characterizations features possible likely used mathematicians. particular problem collections like tptp library symbols used inconsistently across diﬀerent problems formula features abstract particular symbols likely needed. also output learning algorithms limited ranking premises. general kinds relevant problem-solving parameterizations learned attractive candidate treatment large strategies options parameterizing proof search. experiments large number alternative proofs likely obtained interesting task productively learn combination alternative proofs. premise selection instance ubiquitous proof guidance problem recent prototypes like malecop system indicate guidance obtained machine learning considerably help also inside automated theorem provers. finally hope work performance numbers obtained provide valuable feedback cade competition organizers previous proofs theory developments general important part real-world mathematics theorem proving. present division casc recognize proofs recognizing here. organizing large-theory competitions separate theorems proofs like organizing search competitions separate pages link structure believe re-introducing large-theory competition provide large number theorems large number proofs cover important research direction properly evaluate techniques signiﬁcantly improve end-user experience.", "year": 2011}