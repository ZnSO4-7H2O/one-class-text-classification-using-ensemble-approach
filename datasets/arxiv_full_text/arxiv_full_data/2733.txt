{"title": "Interactive Music Generation with Positional Constraints using  Anticipation-RNNs", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "Recurrent Neural Networks (RNNS) are now widely used on sequence generation tasks due to their ability to learn long-range dependencies and to generate sequences of arbitrary length. However, their left-to-right generation procedure only allows a limited control from a potential user which makes them unsuitable for interactive and creative usages such as interactive music generation. This paper introduces a novel architecture called Anticipation-RNN which possesses the assets of the RNN-based generative models while allowing to enforce user-defined positional constraints. We demonstrate its efficiency on the task of generating melodies satisfying positional constraints in the style of the soprano parts of the J.S. Bach chorale harmonizations. Sampling using the Anticipation-RNN is of the same order of complexity than sampling from the traditional RNN model. This fast and interactive generation of musical sequences opens ways to devise real-time systems that could be used for creative purposes.", "text": "recurrent neural networks widely used sequence generation tasks ability learn long-range dependencies generate sequences arbitrary length. however left-to-right generation procedure allows limited control potential user makes unsuitable interactive creative usages interactive music generation. paper introduces novel architecture called anticipation-rnn possesses assets rnn-based generative models allowing enforce user-deﬁned positional constraints. demonstrate efﬁciency task generating melodies satisfying positional constraints style soprano parts j.s. bach chorale harmonizations. sampling using anticipation-rnn order complexity sampling traditional model. fast interactive generation musical sequences opens ways devise real-time systems could used creative purposes. recently number powerful generative models symbolic music proposed. perform well variety different musical datasets monophonic folk-music polyphonic bach chorales models tend face similar limitations provide musically-interesting ways user interact them. time input seed speciﬁed order condition model upon generation ﬁnished user accept result regenerate another musical content. believe restriction hinders creativity since user play active part music creation process. generation generative models often performed left right; recurrent neural networks generally used estimate probability generating next musical event generation done iteratively sampling musical event another. left-to-right modeling seems natural since music unfolds time holds monophonic polyphonic music generation tasks. however match real compositional principles since composition mostly done iterative non-sequential simple example want generate melody ends speciﬁc note generating melodies staying learned style general trivial problem generation performed left right. problem solved generative model markov model remains hard considering arbitrary rnns. order solve issues raised left-to-right sampling scheme approaches based mcmc methods proposed context monophonic sequences shallow models polyphonic musical pieces using deeper models mcmc methods allow generate musically-convincing sequences enforcing many user-deﬁned constraints generation process generally order magnitudes longer simpler left-to-right generation scheme. prevent instance using models real-time settings. problem generating sequences enforcing user-deﬁned constraints rarely considered machine learning literature crucial importance devising interactive generative models. paper propose neural network architecture called anticipation-rnn capable generating style learned database enforcing user-deﬁned positional constraints. architecture general works implementation. furthermore generation process fast requires function calls musical event. sect. precisely state problem consider sect. describes proposed architecture together adapted training procedure. finally demonstrate experimentally efﬁciency approach dataset chorale melodies j.s. bach sect. sect. discuss generality approach future developments. means generative model sequences deﬁned using conditional probabilities only. generation generative model performed iteratively sampling arbitrary. simplicity efﬁciency recurrent neural networks used model conditional probability distributions allow reuse neural network different time steps introducing hidden state vector order summarize previous observations condition precisely writing input outt+ output hidden state time approach successful many applications model conditioned past prevents possible creative models easily beginning sequence generate continuation becomes intricate sequence model generate beginning sequence. write punconstrained probability sequence constraint set. simplicity notation suppose generate sequences ﬁxed length denote sequences paper able enforce positional constraints acceptance-rejection sampling method efﬁcient arbitrary number constraints. exact sampling sconstrained possible conditional probability distributions modeled using models markov models intractable general. problem case markov models fact exactly solved considering complex constraints space sequences imposing equality difference sequences symbols generalizations problem types constraints discussed sect. problem trying enforce constraint imposing constraint time index twists conditional probability distributions however direct computation known) computationally expensive. idea overcome issue introduce neural network order summarize constraints introduce additional token indicating positional constraint given position. this rewrite sequence {nc}. introduce called constraint-rnn order summarize sequence constraints. goes backward outputs used condition second called token-rnn. architecture called anticipation-rnn since token-rnn conditioned come next depicted fig. notated output sequence constraint-rnn output vector summarize information constraints time sequence. vector concatenated input token-rnn time index whose predict approach differs approaches using markov models sense directly take conditional probability distributions rather trying sample sequences sconstrained using punconstrained want probabilistic model able directly enforce hard constraints. anticipation-rnn thus takes input sequence tokens sequence constraints predict shifted sequence requirement constraints coherent sequence since want model able deal positional constraints consider dataset couples token-sequences constraint-sequences dconstraint figure examples generated sequences style soprano parts j.s. bach chorales. examples subject positional constraints indicated using green notes. evaluated architecture dataset melodies four-part chorale harmonizations j.s. bach. dataset available music python package extracted soprano parts chorales. order encode monophonic sequences used melodico-rhythmic encoding described advantage encoding allows encode monophonic musical sequence using sequence tokens. consists adding additional token indicates current note held. furthermore traditional midi pitch encoding used real note names among beneﬁts allows generate music sheets immediately readable understandable musician spelling mistakes. time quantized using sixteenth note smallest subdivision example encoded melody using encoding displayed fig. also perform data augmentation transposing sequences possible keys long transposed sequence lies within original voice range. used -layer stacked lstm constraint-rnn token-rnn using pytorch deep learning framework added dropout input token-rnn. sequences padded start symbols. fig. shows examples enforcement propagation constraints even generation done left right model able generate compelling musical phrases enforcing constraints. particular model able anticipate moment low-pitched note high-pitched vice versa. melodico-rhythmic encoding allows impose note played given time without specifying rhythm. interesting note wide melodic contour unusual chorale melody. nonetheless proposed model able generate convincing bach-like chorale melody. check constraints propagate backwards time constrained model deviates unconstrained model. this compare constrained model pconstrained constraints fig. unconstrained counterpart punconstrained. latter obtained conditioning model fig. sequence constraints special case constraint sequence constraints figure shows evolution pconstrained punconstrained generation example fig. interesting note conditional probability distributions returned pconstrained concentrated speciﬁc values ones returned punconstrained. concentration probability mass pconstrained constrained notes conﬁrms speciﬁc example proposed architecture learned enforce hard positional constraints. assertion experimentally veriﬁed constrained sequences generated. also display fig. difference distributions fig. time step. highlights fact probability mass distribution pconstrained shifted upwards next positional constraint higher current note downwards opposite case. quantify probability distributions pconstrained differ punconstrained computing plot indicates constraints propagated backwards time. oscillation high values divergences zero value encoding chose well singularity musical data figure square root divergence d||pconstrained) kullback-leibler reversed kullback-leibler jeffreys jensen-shannon divergences left-to-right generation example shown fig. highest peaks correspond user-deﬁned constraints smaller ones demonstrate constraints tweaked probability distributions comparison unconstrained model. figure point plot pconstrained versus punconstrained generated sequences length constraints used generations fig. logarithmic scale used. identity displayed blue linear regression data points green. lines closed parallel indicating proportionality distributions desired. considered. seen fig. symbol concentrates probability mass time since soprano parts bach chorales mostly composed half notes quarter notes eighth notes. independent presence absence constraints constrained unconstrained models make similar predictions time steps. evaluate sampling using pconstrained fulﬁlls requirements given constraints generated sequences veriﬁed requirement fulﬁlled sequences order check fulﬁllment requirement plot sequence probability constrained model pconstrained function punconstrained logarithmic space. resulting plot shown fig. translation logarithmic space indicates proportionality distributions desired. presented anticipation-rnn simple efﬁcient generate sequences learned style enforcing positional constraints. method general used improve many existing rnn-based generative models. contrary approaches teach model learn enforce hard constraints training time. believe approach ﬁrst step towards generation musical sequences subjected complex constraints. constrained generation procedure fast since requires calls length generated sequence; require extensive computational resources provides interesting user-machine interaction think architecture paves development creative real-time composition software. also think fast sampling could used jointly mcmc methods order provide fast initializations. future work studying improve training model carefully choosing amount masked notes handling types constraints developing responsive user interfaces possibilities offered architecture used wide audience.", "year": 2017}