{"title": "Large-Scale Automatic Labeling of Video Events with Verbs Based on  Event-Participant Interaction", "tag": ["cs.CV", "cs.AI"], "abstract": "We present an approach to labeling short video clips with English verbs as event descriptions. A key distinguishing aspect of this work is that it labels videos with verbs that describe the spatiotemporal interaction between event participants, humans and objects interacting with each other, abstracting away all object-class information and fine-grained image characteristics, and relying solely on the coarse-grained motion of the event participants. We apply our approach to a large set of 22 distinct verb classes and a corpus of 2,584 videos, yielding two surprising outcomes. First, a classification accuracy of greater than 70% on a 1-out-of-22 labeling task and greater than 85% on a variety of 1-out-of-10 subsets of this labeling task is independent of the choice of which of two different time-series classifiers we employ. Second, we achieve this level of accuracy using a highly impoverished intermediate representation consisting solely of the bounding boxes of one or two event participants as a function of time. This indicates that successful event recognition depends more on the choice of appropriate features that characterize the linguistic invariants of the event classes than on the particular classifier algorithms.", "text": "aschool electrical computer engineering purdue university west lafayette bdepartment computer science university toronto toronto cdepartment computer science engineering university south carolina columbia present approach labeling short video clips english verbs event descriptions. distinguishing aspect work labels videos verbs describe spatiotemporal interaction event participants humans objects interacting other abstracting away object-class information ﬁne-grained image characteristics relying solely coarse-grained motion event participants. apply approach large distinct verb classes corpus videos yielding surprising outcomes. first classiﬁcation accuracy greater -out-of- labeling task greater variety -out-of subsets labeling task independent choice different time-series classiﬁers employ. second achieve level accuracy using highly impoverished intermediate representation consisting solely bounding boxes event participants function time. indicates successful event recognition depends choice appropriate features characterize linguistic invariants event classes particular classiﬁer algorithms. people describe observed visual events using verbs. common assumption linguistics verbs typically characterize interaction event participants terms gross changing motion participants. object class image characteristics participants believed largely irrelevant determining appropriate verb label event. participants simply roles spatiotemporal structure event class described verb. example event participant picks another participant consists sequence subevents during ﬁrst subevent agent moves towards patient patient rest second subevent agent moves together patient away original location patient. matter whether agent human whether patient ball cup. moreover shapes sizes colors textures etc. participants irrelevant. additionally gross motion characteristics relevant; irrelevant whether participants grow shrink bend vibrate etc. pick event. precise linear angular velocities accelerations likewise irrelevant. objective paper evaluate linguistic assumption relevance computer-vision task labeling video events verbs. order evaluate hypothesis focus attention methods classify events solely basis gross changing motion event participants. often expressly discard sources information object class changing human body posture low-level image characteristics shape size color texture. believe information could help event recognition rather allow strongly evaluate hypothesis. surprising result endeavor gross changing motion event participants attains greater accuracy -out-of- forced-choice labeling task signiﬁcantly outperforming chance greater accuracy variety -out-of subsets labeling task signiﬁcantly outperforming chance paper focusses labeling video events verbs methods datasets commonly used prior event-classiﬁcation efforts appropriate. work typically classiﬁes events using object image characteristics ﬁne-grained shape motion features spatiotemporal volumes tracked feature points moreover many datasets commonly used work involve people interacting objects people contain event classes depict common verbs. example distinctions wave wave jump pjump weizmann dataset distinctions golf-swing-back golf-swing-side; golf-swing-front kicking-front swing-bench swing-sideangle sports actions dataset correspond distinctions verb semantics. event classes side jack weizmann dataset event classes swing-bench swing-sideangle sports actions dataset vast majority event classes dataset correspond verbs language. videos dataset reﬂect true meanings verbs alone boxing clapping waving ones hands. typical actions specialized domains like ballet described nouns verbs often part common vocabulary. distinction event classes golf swing tennis swing swing youtube dataset reﬂect distinctions event participants semantics verb swing. siskind morris presented technique labeling video events verbs based changing motion patterns event participants. however applied technique small number event classes small corpus thirty-six videos class. moreover derived changing motion patterns using rudimentary tracker speciﬁc color motion using background subtraction. thus event participants limited people’s hands interacting colored blocks uncluttered desktop environments static backgrounds. paper employ technique labeling video events verbs extend much larger number event classes evaluate much larger corpus videos ranging class. since corpus used present effort exhibits wide variety natural event participants wide variety cluttered environments nonstationary backgrounds paper employs novel general-purpose techniques deriving changing motion patterns. moreover siskind morris used algorithmic method namely hidden markov models classify time series characterize changing motion patterns. thus might conclude performance approach somehow dependent choice classiﬁer. paper employ distinct time-series classiﬁcation methods namely hmms dynamic time warping demonstrate achieve essentially identical performance. thus appears strength approach results general principle classifying events based gross changing motion patterns algorithmic particulars. moreover demonstrate surprising result. front-end tracker abstracts video moving axisaligned rectangles. despite extremely impoverished representation passes small integers frame front-end tracker back-end time-series classiﬁer fact training classiﬁcation performed solely impoverished representation classiﬁers attain greater accuracy -out-of- forced-choice labeling task greater accuracy variety -out-of- subsets task. supports common assumption linguistics meanings many common verbs sensitive gross changing motion patterns event participants object class image characteristics participants. paper organized follows. section describes corpus effort. section describes tracking methods employ abstract video corpus moving axis-aligned rectangles. section describes feature vectors extract impoverished representation particulars training classiﬁcation paradigms. section describes experimental results. section concludes discussion potential improvements. beling videos common verbs. particulars corpus driven desire ground semantics speciﬁc english verbs. date several components corpus released program participants. portion c-da containing videos released late september second portion containing videos released late january videos provided pfps range frames frames length average frames. videos c-da range frames frames length average frames. video intended depict speciﬁc english verbs collectively verbs represented combined corpus video comes labeled intended verb depiction. verbs often exhibit range polysemous homonymous meanings also exhibit synonymy semantic space verb include part semantics space another verb darpa intends eventually solicit human judgements association verb labels video. since human labelings produced paper simply take ‘correct’ label video intended verb label provided video. moreover paper considers c-da portion depicts speciﬁc english verbs. fig. summarizes distribution verbs exemplar videos portion corpus. conformant linguistic observation object identity class tangential task labeling video verb different exemplars verbs c-da often participant roles played different object instances classes. c-da corpus total distinct objects play role depicted verbs enumerated fig. many objects however appear corpus occupying small portion ﬁeld view difﬁcult humans alone machines detect classify reliably. ones difﬁcult detect classify reliably starred fig. remaining ones manually cropped collection exemplars train part-based object detector important stress object detector solely produce bounding-box information deriving gross changing motion patterns event participants. event classiﬁcation expressly discard object-class information conﬁdence scores provided object detector. section discuss could extend methods make information achieve even higher classiﬁcation accuracy. felzenszwalb al.’s part-based object detector detection source produce axis-aligned rectangles function time. however unreliable alone means characterizing gross participant-object motion simultaneously exhibits high false-positive rate high false-negative rate. moreover single detection threshold properly trades false-positive false-negative rates classvideo-independent fashion. additionally detection-conﬁdence values produced detector even rank ordering cannot used isolated frames select desired detection. moreover detector alone cannot distinguish false positives multiple objects class close positions ﬁeld view. likewise detector alone provide temporal-correspondence information situation. problems particularly exacerbated occlusion objects enter leave ﬁeld view pass front behind objects. circumstances detection conﬁdence becomes even less reliable measure presence absence object. particularly egregious limitation verbs describe interaction among participants interaction frequently involves occlusion. address issues novel technique produces coherent object tracks across video collections independent detections frame simultaneously selecting among multiple detections frames video combination selections leads global optimum cost function characterizes overall object-track coherence. employ technique using felzenszwalb al.’s part-based object detector detection source generally applied alternate detection source outputs boxes conﬁdence scores. requirement conﬁdence scores must provide total ordering boxes. conﬁdence scores need normalized particular interval. requirement facilitates integrating boxes produced different detection sources single coherent track simply providing correspondence conﬁdence values produced different detection sources impact total order. avail ourselves potential section provide resilience face appearance change nonrigid motion out-of-plane object rotation. conceivably alternate detection source rely object detector. example might form background subtraction motion-based tracking separate moving objects background form bottom-up foreground/background segmentation contour completion segment salient objects. method could reliably place bounding boxes around event participants function time would sufﬁce purposes. sole reason employ object detector detection source bottom-up methods currently sufﬁciently reliable methods based background subtraction motion detection fail detect non-moving event participants unreliable presence nonstationary backgrounds apply detection source independently frame model biasing detection source yield false negatives expense yielding preponderance false positives tracker ﬁlter false positives. using felzenszwalb al.’s partbased object detector detection source subtracting ﬁxed offset learned detection threshold. particular value offset unimportant long yields sufﬁciently false-negative rate method reliably selects coherent tracks despite extremely high false-positive rate. negative impact choosing high offset increase time. felzenszwalb al.’s part-based object detector default incorporates non-maxima suppression remove detections overlap detections higher conﬁdence. tends foil process biasing detector towards false negatives many false positives. counter effect excessive non-maxima suppression raise overlap threshold allows much better object localization reduces jitter considerably. found amount bias process completely eliminate false negatives. provide robust production coherent object tracks necessary successful event classiﬁcation compensate remaining false negatives projecting detection frame forward ﬁxed number frames using kanade-lucas-tomasi feature tracker. track features reside inside detection frame compute single velocity vector divergence vector detection computing average velocity divergence features tracked box. aggregate velocity divergence vectors project detection forward frame repeat process. limit projection process frames subject drift need compensate false negatives relatively rare result bias process. augment collection detections include forward-projected boxes taking conﬁdence score forward-projected original detection forward projected. select coherent object track across multiple frames construct graph vertex detection frame edges connecting pairs detections adjacent frames. edges weighted cost inversely measures coherence search path ﬁrst last frames minimal total edge weight using dynamic-programming algorithm ﬁnds global optimum. cost formulated linear combination components detection conﬁdence score consistency optical ﬂow. latter taken euclidean distance center detection given frame projection center corresponding detection previous frame forward using optical ﬂow. forward-projection process analogous performed compensate false negatives except average velocity vector computed dense optical instead tracked features. either forward-projection process. that practice features yield better results forward-projection process used compensate false negatives optical yields better results forward-projection process used compute track coherence. also track-coherence measure uses distance detection-box centers thus need divergence measure. could extend track-coherence measure incorporate information yields improvement performance. experiments weight optical-ﬂow component track coherence times less detectionconﬁdence score. bias track-coherence measure towards detection conﬁdence prevent production tracks consistent optical correspond reliable object detections. general bias object tracks produced largely insensitive precise weighting value. algorithm described thus constructs tracks span entire video ﬁrst frame last frame. allow objects enter leave ﬁeld view simply applying algorithm subinterval video. difﬁculty determining subinterval boundaries. take subinterval begin ﬁrst frame detection conﬁdence certain threshold last frame. derive threshold compute histogram maximal detectionconﬁdence scores frame entire video. expects histogram bimodal since frames object present lower conﬁdence scores detections false positives. take threshold minimum value maximizes between-class variance bipartitioning histogram learned detector-conﬁdence threshold offset ﬁxed small amount practice proper selection subinterval largely insensitive number bins precise threshold offset. detect multiple tracks object class repeated application method. must prevent subsequent iterations rediscovering tracks produced earlier iterations. na¨ıve doing would remove detections associated earlier tracks. detection boxes deemed associated earlier tracks centers inside detection boxes included earlier tracks. however removing detections runs risk precluding overlapping tracks would happen objects pass ﬁeld view. instead removing detections rescore maximal detection score lower quartile scores frame. given biasing process towards false positives away false negatives detection source boxes lower quartile likely false positives undesirable include coherent track. rescoring detections fashion biases subsequent iterations distinct tracks allowing tracks brieﬂy overlap. careful crossover points overlap object identity swapped distinct tracks. object-appearance model bias crossover. color histograms computed cielab color space pixel values inside detection boxes shrinking boxes ameliorate inﬂuence background pixels histograms. augment edge-weight function include coherence measure object appearance taking coherence measure earth mover’s distance corresponding histograms. weight object appearance detector conﬁdence equally coherence measure though practice object tracks produced largely insensitive precise weighting. felzenszwalb al.’s part-based object detector unreliable detection source nonrigid motion out-of-plane rotation. tracking framework provide resilience face unreliability integrating detection boxes multiple detection sources. training multiple models felzenszwalb al.’s part-based object detector varying object appearance nonrigid motion out-of-plane rotation union resulting detections. discussed section must insure conﬁdence scores allow comparison detections produced different detection sources. offsetting conﬁdence scores detection source threshold computed section c-da corpus little out-of-plane rotation therefore impact reliability detection source. corpus contain source nonrigid motion namely changing human body posture. corpus sufﬁcient train detectors three distinct postures standing crouching lying down. integrating multiple detection sources single object track allows annotation detections track source. particular allows temporal annotation human motion tracks changing posture. conceivably could information support selection appropriate verb label. wish evaluate hypothesis verbs typically characterize gross changing motion event participants expressly discard information experiments perboxes comprising recovered object tracks suffer jitter. remove jitter ﬁtting piecewise cubic splines widths heights center coordinates tracked boxes. simple selection smoothing parameters sufﬁces c-da corpus. since videos c-da frame length variance constant number spline pieces adequate. center coordinates smoothed pieces move signiﬁcantly tracking accelerating objects example bouncing ball. widths heights smoothed pieces object shape size change less drastically. results tracker runs time recover tracks detection sources yielding detections frame frames forward projection videos length practise time dominated detection process dynamic-programming step. fig. illustrates operation tracker rendering output stage. video clearly robustness tracker light cluttered nonstationary backgrounds motion perpendicular camera axis extremely high falsepositive biased detection rate detection source occlusion results overlapping tracks corresponding interacting objects nonrigid motion results changing human body posture objects entering leaving ﬁeld view multiple instances object class. moreover illustrated fig. fact tracker ﬁnds optimal coherent track processing entire video allows robustly track objects approach recede camera large distance would otherwise small ﬁeld view reliably track methods process entire video. without false-positive bias whole-video approach allows felzenszwalb al.’s part-based object detector would even detect objects. convert collection object tracks video time-series real-valued feature vectors formulate problem labeling video verb time-series classiﬁcation problem. discard object identity body posture information available tracks. inanimate objects bicycles motorcycles suvs likely agents inanimate objects driven people might fail detect occlusion. another track selected patient using heuristic. ties broken selecting track highest track coherence agent second highest track coherence patient. x-coordinate center y-coordinate center aspect ratio derivative aspect ratio magnitude velocity center direction velocity center magnitude acceleration center direction acceleration center videos object tracks also extract feature vector includes absolute motion features representing independent motion agent patient along additional features describe relative motion above temporal derivatives corresponding velocities accelerations computed two-point ﬁnite difference. note label videos verbs using gross changing motion patterns event participants. could principle label videos basis motion patterns event participants present straightforward extension feature-vector computation include absolute features objects relative features object pairs expressly refrain evaluate linguistic hypothesis verbs largely describe interaction agent patient. verbs c-da often different senses causative/inchoative alternation involve different number participants. case train distinct classiﬁers videos characterizing motion agent videos agent patient characterizing motion agent patient. classifying unseen video single object track models trained agents classifying unseen video object track models trained agents patients. figure output stage tracker single frame. detections person model motorcycle model green. forward projections detections previous frames. object tracks maximal coherence selected dynamic-programming algorithm. distinct person tracks shown blue motorcycle track shown green. smoothed tracks. figure four frames tracking people motorcycle. separate person tracks blue motorcycle track green. tracker robust despite fact person occludes motorcycle tracks people overlap three objects become small recede camera. evaluate hypothesis possible classify events solely basis gross changing motion event participants demonstrate insensitivity hypothesis choice time-series classiﬁer parallel sets experiments hmms using hmms train models states independent continuous output distributions feature. gaussian distributions features constitute linear quantities mises distributions features constitute angular quantities. found increasing number states beyond signiﬁcantly improve accuracy. using employ euclidean distance feature vectors distance metric frames extend metric distance frame sequences construct nearest-neighbor classiﬁer unseen videos training exemplars. performed -fold cross-validation entire c-da corpus -out-of- forced-choice classiﬁcation task using hmms dtw. this independently partitioned ‘correct’ exemplars verb random equally sized components cross-validation runs trained exemplars four partitions tested exemplars remaining partition. fig. gives recognition accuracy classiﬁcation algorithm cross-validation run. fig. fig. give aggregate confusion matrices classiﬁcation algorithm across cross-validation runs. note essentially identical performance hmms hmms exhibits aggregate classiﬁcation accuracy exhibits aggregate classiﬁcation accuracy moreover attain greater aggregate classiﬁcation accuracy three different -outof- subsets forced-choice classiﬁcation task hmms arrive bounce drop exchange give jump kick pickup bounce drop exchange give jump kick pickup pull bounce drop exchange give jump kick pass pickup pull results support hypothesis classiﬁcation accuracy depends correct choice features classiﬁcation algorithm. erwise available order evaluate hypothesis. since information might correlate underlying event could extend classiﬁers make information. example might expect detector conﬁdence scores would decrease occlusion thus correlate object interaction indicative event class. similarly might expect object class would correlate event class. indeed shown fig. correlation signiﬁcantly reduces potential verb-label space rendering verb-labeling task almost trivial. likewise discussed section could augment time series feature vectors human body-posture information extracted by-product using multiple detection sources provide resilience face out-ofplane rotation nonrigid motion. quite unexpected attain good results despite expressly discarding information. supports common assumption linguistics verbs typically characterize interaction event participants terms gross changing motion participants. focus paper evaluate hypothesis possible label videos verbs using information solely gross changing motion event participants. numerous places computational methods expressly discard information othm. rodriguez ahmed shah. action mach spatio-temporal maximum average correlation height proceedings ﬁlter action recognition. ieee conf. computer vision pattern recognition schuldt laptev caputo. recognizing human actions local approach. proceedings seventeenth international conf. pattern recognition pages isbn ---. http//dx. doi.org/./icpr... viterbi. convolutional codes performance communication systems. ieee trans. communication october wang mori. human action recognition semiieee trans. pattern analysis latent topic models. machine intelligence issn http//dx.doi.org/./tpami.. number n---g army research laboratory accomplished cooperative agreement number wnf--- computational resources provided information technology purdue rosen center advanced computing. views opinions ﬁndings conclusions recommendations contained expressed document material author necessarily reﬂect represent views ofﬁcial policies either expressed implied naval research laboratory ofﬁce naval research army research laboratory u.s. government. u.s. government authorized reproduce distribute reprints government purposes notwithstanding copyright notation herein.", "year": 2012}