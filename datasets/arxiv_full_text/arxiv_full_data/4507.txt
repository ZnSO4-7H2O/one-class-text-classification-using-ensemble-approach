{"title": "On the monotonization of the training set", "tag": ["cs.LG", "cs.AI", "I.2.6"], "abstract": "We consider the problem of minimal correction of the training set to make it consistent with monotonic constraints. This problem arises during analysis of data sets via techniques that require monotone data. We show that this problem is NP-hard in general and is equivalent to finding a maximal independent set in special orgraphs. Practically important cases of that problem considered in detail. These are the cases when a partial order given on the replies set is a total order or has a dimension 2. We show that the second case can be reduced to maximization of a quadratic convex function on a convex set. For this case we construct an approximate polynomial algorithm based on convex optimization.", "text": "consider problem minimal correction training make consistent monotonic constraints. problem arises analysis data sets techniques require monotone data. show problem nphard general equivalent ﬁnding maximal independent special orgraphs. practically important cases problem considered detail. cases partial order given replies total order dimension show second case reduced maximization quadratic convex function convex set. case construct approximate polynomial algorithm based convex optimization. requirements classifying rule supervised learning problems consist parts. ﬁrst part induced precedents called training set. element training pair object–reply type. classifying rule mapping objects replies objects training pairs consistent replies. second part requirements express common knowledge classifying rule. popular types requirements monotonicity considered paper. cases parts requirements satisﬁed problem minimal correction training set. problem suppose sets given sets partial orders consistently. assume partial order lattice. given mapping pose problem ﬁnding function monotone partial orders minimizes following functional |{x|f maxcms. ﬁnite sets given; partial orders deﬁned consistently function given. every element assigned positive integer weight task maximal weight subset function restricted monotone i.e. deﬁnition orgraph every vertex orgraph positive integer weight vertexes called independent every pair elements connected edge. maximal weight independent denoted proof. independent orgraph satisﬁes condition i.e. function restricted monotone. inverted statement correct also restriction monotone independent obtain proposition theorem. proof. divide equivalence classes predicate naturally deﬁne corresponding mapping factor-set induced partial order easy maxcms reduction done steps. previous chapter shown maxcms equivalent ﬁnding maximal independent special orgraphs. problem ﬁnding acceptable cardinality denoted cms. obviously theorem np-complete. proof. reduce -sat using trick -cnf given variables used clauses clause consists literals diﬀer variables every clause order literals belong fact meeting literal s-th place clause denoted consider orgraph vertex union literals threefold copies clauses u... un}∪{c deﬁne edge equal vertex cover orgraph cardinality exists original -cnf satisﬁable. actually every pair vertexes every triple fall vertex cover pairwise connected. cardinality vertex cover less suppose vertex cover required cardinality exists. literal deﬁne true otherwise alse. variables initialized manner said clear cover excluding them. assignment easily seen satisﬁes original -cnf. reasoning inverted obtain existence satisfying assignment equivalent existence vertex cover cardinality consider orgraph transitive closure suppose edge transitive. deﬁning obtain means problem reduced ﬁnding minimal vertex cover consequently maximal independent special orgraph theorem equivalent maxcms theorem -maxcms reduced ﬁnding maximal independent circuit-free orgraph edge satisfying problem polyfollowing transitivity rule nomially tractable graph obtained transformation oriented edges non-oriented comparability graph partial order known perfect. adduce proofs tractability theorem -maxcms polynomially tractable. proof. deﬁning orgraph seen partially ordered algorithm solves problem reducing task minimizing circuit-free network. denote sets minimal maximal elements consistently. every vertex orgraph introduce copies deﬁne v−}v∈v {}v∈v obtained orgraph minimal edge deﬁned equal corresponding weights edges equals maximal every edge easy every edge orgraph path goes well-known condition apply ﬂow-max theorem. constitute independent weight exactly equal weight set. conversion statement also correct i.e. every independent correspond u−|u r&∃r {r+|r weight equal weight clear result algorithm maximal correspond maximal independent theorem proved. consider problem -maxcms. problem arise partial order replies total example tree structure. know reduced ﬁnding maximal independent circuit-free orgraph predicates transitive. consider problem. since maximum left part inequality achieved boolean vectors clear equality holds. taking account functional convex problem reduced maximization convex quadratic function convex set. turn equalities. optimality xopt yopt clear cone then theorem nξ|a farkas-minkovski conclude ϕξopt expanded positive combinapositive obtain ∇ξoptϕξopt solved polynomial time. actually floidwarshall algorithm longest path orgraphs polynomial time length path mean weights vertexes path. comparing results less besides path length greater give violated inequality deﬁnition polyhedron mentioned above maxcms considered subcase vertex cover problem. point view task ﬁnding maxcms equivalent task removing noisy objects training minimal total weight. compare approximation ratio algorithm well-known standard -approximation vertex cover found graph weighted vertexes polynomial time. clear made arbitrarily small play role bound theorem bounded value integer. simplicity obvious ratio approximation meaning maximal consistent monotonicity special orgraph weight half weights vertexes i.e. axcm case theorem obtain that almost correct data i.e. algorithm approximation ratio close standard noisy data appears better standard. extreme case standard -approximation means guarantee remove objects noise. contrary total weight objects removed algorithm case exceed optimal solution bound theorem shows algorithm good approximations maxcms cases even half training consists noisy data(α", "year": 2007}