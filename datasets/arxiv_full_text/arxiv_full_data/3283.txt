{"title": "IT-map: an Effective Nonlinear Dimensionality Reduction Method for  Interactive Clustering", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "Scientists in many fields have the common and basic need of dimensionality reduction: visualizing the underlying structure of the massive multivariate data in a low-dimensional space. However, many dimensionality reduction methods confront the so-called \"crowding problem\" that clusters tend to overlap with each other in the embedding. Previously, researchers expect to avoid that problem and seek to make clusters maximally separated in the embedding. However, the proposed in-tree (IT) based method, called IT-map, allows clusters in the embedding to be locally overlapped, while seeking to make them distinguishable by some small yet key parts. IT-map provides a simple, effective and novel solution to cluster-preserving mapping, which makes it possible to cluster the original data points interactively and thus should be of general meaning in science and engineering.", "text": "laboratory neuroinformation ministry education china school life science technology university electronic science technology china chengdu china *corresponding author. abstract scientists many fields common basic need dimensionality reduction visualizing underlying structure massive multivariate data low-dimensional space. however many dimensionality reduction methods confront so-called crowding problem clusters tend overlap embedding. previously researchers expect avoid problem seek make clusters maximally separated embedding. however proposed in-tree based method called it-map allows clusters embedding locally overlapped seeking make distinguishable small parts. it-map provides simple effective novel solution cluster-preserving mapping makes possible cluster original data points interactively thus general meaning science engineering. introduction physically inspired structure proposed physically inspired method organize data points sparse effective in-tree structure. previous works shown potential cluster analysis. combinations structure semi-supervised learning concept rodriguez laio’s decision graph frey dueck’s affinity propagation resulted effective cluster analysis methods. example based structure application scope extended spherical non-spherical cluster detection paper show another potential structure nonlinear dimensionality reduction effective combination made isometric mapping proposed tenenbaum isomap simple effective dimensionality reduction method extends application scope multidimensional scaling linear nonlinear structure. contains three steps first construct k-nearest-neighborhood graph compute graph distances lastly compute low-dimensional embedding classical mds. effect constructed graph data points unfolded low-dimensional euclidean space effective especially preserving embedding topology relationship data points manifolds. crux success isomap takes input classical graph distances instead straight-line euclidian ones pairs data points. motivation short would like replace graph isomap physically inspired graph then similarly unfold structure low-dimensional space. consequently structure constructed directly original data points always visualized low-dimensional euclidean space thus undesired edges visualized removed interactively. proposed method it-map step construct structure. original dataset ={xi view point node directed edges defined follows first potential associated point computed here nodes respectively start node directed edge descend means potential node less start node. differentiate case mapping denote structure itχ. step compute graph distance. graph distance pair nodes defined shortest path distance tree structure obtained ignoring directions edges itχ. either certain algorithm search shortest path isomap does however time-consuming follow described utilizing feature tree structure tree structure first transformed structure rooted node shortest path root node node path along edge directions node thus lengths edges elaborate definition ref. practice means node directed edge connected start node equivalent transforming directed edges undirected ones used non‐classic matlab code fig. results slightly better mds. however non‐classic code sometimes risk hard converge sometimes. used classic datasets. input distance matrix ={dt} find low-dimensional embedding original dataset minimize dr=||yi −yj|| refers euclidian distance node space then connection relationships potential values nodes inherited corresponding nodes embedded space consequently mapped space result denoted however prefer visualize space potentials nodes shown additional dimensionality fig. helps users better visualize clusters especially undesired edges. experiments tested power it-map several -dimensional datasets figure shows itrp structures mapping clusters together undesired edges across them distinguishable proving it-map succeeds mapping tasks. friendly beautiful visualized results useful possible users make reliable cluster analysis simple interactive operations edges closest crosses determined undesired ones removed consequently clustering assignments original data points shown upper-right corners quite consistent visual perception. fig. tested high-dimensional synthetic dataset clustering assignments fully match ground truth i.e. vectors original dataset assigned clusters without error. fig. tested high-dimensional real-world mushroom dataset mushrooms assigned clusters error rate much better interactive clustering based isomap mapping result reported first paper discussion conclusion comparing visualization methods visualization required diverse domains many methods reviewed proposed. methods chernoff faces pixel-based techniques require interpretation user symbols embedding thus limitation dealing large volume dataset contrast method represents high-dimensional dataset simply points low-dimensional space also organizes points efficiently structure details method undesired edges identified crosses ref. http//archive.ics.uci.edu/ml/ note mushrooms classified people classes poisonous edible whereas underlying number clusters much that. true number clusters likely revealed another algorithm. help visualization interactive operations paper. comparing dimensionality reduction methods hard dimensionality reduction methods particularly principal components analysis classical multidimensional scaling sammon mapping locally linear embedding stochastic neighbor embedding maximum variance unfolding isomap data points low-dimensional space preserving underlying cluster structure so-called crowding problem previous methods tree preserving embedding variants maximally alleviate crowding overlapping phenomenon clusters. contrast it-map allows local overlapping phenomenon happen fig. seeks make clusters distinguished salient local features instead fully separated image low-dimensional space. reasonable strategy quite similar utilized card players provides simple effective solution general meaning. comparing knnmst-based mapping thing it-map effective application physically inspired structure dimensionality reduction. another like minimal spanning tree based mapping it-map also variant isomap inherits virtue isomap preserving graph distance unfolding graph low-dimensional euclidean space. however it-map effective nonlinear dimensionality reduction method interactive clustering since physically inspired structure salient advantages traditional graph structures compared main difference advantage structure neighbor point constrained local area especially local extreme points terms potential variable. consequently connections clusters generally much longer therefore according step paths connecting nodes clusters generally longer within clusters according step compact distinguishable clusters generally present embedding facilitate cluster analysis compared nodes structure also weighted potential values provides additional useful reference dimensionality make clusters clusters overlapped mutually fact interactively drag overlapped clusters apart low‐dimensional space shown fig. easy place several cards fully separated table easy intends complete task hand. however still hard card players since choose strategy similar distinguishing cards characters numbers upper‐left corners cards allowing rest parts overlapped other. difference potential variable introduced therefore strictly speaking structure neighbor graph like mst. separable unlike directed characteristic structure makes sparser also brings convenience identifying undesired edges searching root nodes interactive clustering. compared tree-shaped feature makes removing edge surely divide graph separate parts makes convenient divide conquer strategy introduced next. problems solutions although don’t seek avoid crowding problem sometimes post-processing main problems encountered practice sometimes embedded structure crowded user easily spot undesired edges; current parameter best fitted test dataset dataset single value well enough lead optimal result. utilize divide conquer strategy decomposed components divide conquer strategies. problem solved divide strategy rerunning step subset distance matrix illustrated fig. namely instead expecting dimensionality space downsize number clusters original structure since burden step it-map mainly derived number clusters. divide strategy doesn’t work encountering problem conquer strategy adjusting value parameter rerunning steps salient result presents. order efficient reliable information constraints several labels semi-supervised learning always welcome provide references. figure. illustrates simple example role several labels conquer strategy used. meaning it-map believe it-map boost interactive clustering method proposed broad meaning. stated shneiderman effective approach human users control since often identify patterns machines cannot...automated analyses work well-understood data visualizations increase efficacy experts frontier topics breakthroughs happen. must‐link denotes nodes exist cluster opposite case cannot‐link. think label given cluster even kmeans work well. however illustration generalized must‐link cannot‐link information impractical kmeans; test data also non‐spherical character‐attributed also impractical kmeans; label cluster generally member also impractical kmeans initialization sensitivity; constraint means reliable cutting behavior necessarily case kmeans. venna peltonen nybo aidos kaski information retrieval perspective nonlinear dimensionality reduction data visualization. journal machine learning research weinberger saul learning kernel matrix nonlinear dimensionality reduction. proceedings twenty‐first international conference machine learning cannistraci ravasi montevecchi ideker alessio nonlinear dimension reduction clustering minimum curvilinearity unfold neuropathic pain tissue embryological classes. bioinformatics i‐i. different potential values. redder lower potential. itrp. bottom-left clustering results original dataset removing undesired edges identified", "year": 2015}