{"title": "Causal Discovery for Manufacturing Domains", "tag": ["cs.LG", "cs.AI"], "abstract": "Yield and quality improvement is of paramount importance to any manufacturing company. One of the ways of improving yield is through discovery of the root causal factors affecting yield. We propose the use of data-driven interpretable causal models to identify key factors affecting yield. We focus on factors that are measured in different stages of production and testing in the manufacturing cycle of a product. We apply causal structure learning techniques on real data collected from this line. Specifically, the goal of this work is to learn interpretable causal models from observational data produced by manufacturing lines.  Emphasis has been given to the interpretability of the models to make them actionable in the field of manufacturing. We highlight the challenges presented by assembly line data and propose ways to alleviate them.We also identify unique characteristics of data originating from assembly lines and how to leverage them in order to improve causal discovery. Standard evaluation techniques for causal structure learning shows that the learned causal models seem to closely represent the underlying latent causal relationship between different factors in the production process. These results were also validated by manufacturing domain experts who found them promising. This work demonstrates how data mining and knowledge discovery can be used for root cause analysis in the domain of manufacturing and connected industry.", "text": "increasing yield improving quality paramount importance manufacturing company. ways achieve discovery causal factors affect quantities. work data-driven causal models identify causal relationships manufacturing. speciﬁcally apply causal structure learning techniques real data collected production line. emphasis given interpretability learned causal models used practitioners take meaningful actions. highlight challenges presented assemblyline data propose ways address challenges. also identify unique characteristics data originating assembly lines leverage characteristics improve causal discovery. standard evaluation techniques causal structure learning show learned models closely match underlying causal relationships diﬀerent factors production process. results also validated manufacturing domain experts found promising. work demonstrates data mining knowledge discovery used root cause analysis domain manufacturing connected industry. permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. copyright x-xxxxx-xx-x/xx/xx ..... increasing interest internet things size complexity data sets collected manufacturing processes grown signiﬁcantly. ability networked devices sensors assembly lines enabled collection data every stage manufacturing process. however collection arbitrarily large amounts data meaningful leads actionable insights especially increase yield eﬃciency. work step direction. work objectives. first identify joint causal structure speciﬁc manufacturing domain. second focus causal factors increase yield. speciﬁc given measurements taken production testing product identify causal relationships domain include inﬂuential factors aﬀecting yield. traditional approach address issue design experiments context manufacturing usually includes carrying experiments real production testing environment. consequence costly time-consuming. therefore practitioners limit number factors examined experiment. process manufacturing becomes complex sometimes comprising hundreds possible factors becomes diﬃcult choose appropriate factors investigation doe. currently experts manufacturing rely domain knowledge intuition along basic statistics guide eﬀorts increase yield improve quality. work aims process using data mining knowledge discovery. speciﬁcally apply techniques learning causal structure real data collected manufacturing line order identify factors aﬀecting yield complex interrelationships amongst them. algorithms learning causal structure construct causal graphical model variables domain. models identify underlying causal mechanisms speciﬁc domain. causal models great value knowing causes target variable speciﬁes interventions variables change target variable desired way. causal models applied areas planning decision making epidemiology social science mention few. follows ﬁrst describe manufacturing domain i.e. manufacturing process structure assembly line. provide short introduction graphical models causal discovery algorithms. show qualitative results obtained application causal discovery algorithms data collected production line. identify speciﬁc challenges presented manufacturing data standard algorithms need modiﬁed order improve causal discovery. finally present evaluation causal structure learning manufacturing based domain expertise synthetic data. typical assembly lines consist multiple stations diﬀerent operations take place. every station several measurements taken product point. components added unﬁnished product diﬀerent production stations assembly line. testing station station product passing inspected. additionally assembly line usually testing stations—called end-of-line testing stations— inspect ﬁnal product. testing stations carry series measurements test quality product. product meet required quality criteria usually rejected. rejected product called scrap accepted product called good part. illustration assembly line shown figure production stations depicted rectangle testing stations rhombus. testing stations shown gray. example figure stations production stations depicted blue rectangles. station test station represented blue rhombus. measurements collected diﬀerent stages production cycle shown orange rectangles. components used main assembly line form ﬁnished product also assembled separately assembly lines. example substations green figure show assembly line component added main product station internet things connected industry information gathered measurements main assembly line augmented information assembly lines individual sub-components. measurements also gathered externally suppliers sub-components. term manufacturing cycle data cover data gathered assembly line component well assembly lines sub-components supplier data. work product investigation fuel injector. measurements recorded assembly line producing injector assembly lines producing sub-components injector. goal leverage plethora measurements learn complex causal relationships factors aﬀecting yield production process. however methodology root cause analysis proposed paper generic easily applied product manufactured assembly line. figure schematic representation assembly line. blue denotes stations main assembly line green stations assembly lines sub-components grey denotes stations orange denote measurements yellow output process. rectangles denote production stations rhombi denote testing stations. data produced assembly line injectors consists factors million parts manufactured within period year. thus massive data manufacturing system terms data points number variables measured. analysis data preprocessed ignore features unique keys features zero variance. moreover considered features single assembly line substation testing line. clean data consists continuous variables normalized mean variance worth mentioning that even preprocessing variables exhibit high pairwise linear correlation shown figure non-linear relationships. characteristics make task causal discovery challenging. however large amount domain knowledge inherent structure data leveraged improve results. section introduce notation basic deﬁnitions throughout paper. upper-case letters denote random variables bold-face fonts denote sets random variables first provide short introduction bayesian networks causal interpretation. then describe learn structure bayesian networks directed graphical models compactly represent sets probability distributions. bayesian network deﬁned random variables consists graph partially directed graph directed undirected edges. skeleton graph undirected graph obtained substituting every edge undirected edge. path nodes sequence nodes exists edge every consecutive nodes path. v-structure collider graph structure bayesian network represents independencies according local markov condition node independent non-descendants given parents graph. independencies derived graphical criterion -separation. nodes d-separated given disjoint variables -connecting paths given path d-connecting given every collider along path descendant nodes worth noting diﬀerent directed acyclic graphs might represent independencies. dags known markov equivalence class independencies. markov equivalence class graphically represented mixed graph every undirected edge possible orientations change conditional independencies induced graph. notion causality subject debate philosophers practitioners since ancient times. work focus semantics causality based probabilistic distributions manipulations following work pearl spirtes framework direct cause respect variables changing value results changes probability distribution assuming values variables held constant causal markov condition markov condition -separation provide connection structure bayesian network independencies hold underlying distribution. want figure causal network learned real data using signiﬁcance level tests conditional independence. graph nodes edges. resulting model dense hard interpret. hypothesis tests learn undirected graph apply series orientation rules retrieve partially directed graph corresponds markov equivalence class true model. algorithms category include grow shrink search-and-score methods search heuristically space possible directed acyclic graphs pick maximizes scoring function. algorithms include greedy hill climbing search search using tabu lists. worth mentioning greedy equivalence search score-based approach searches hybrid algorithms combine elements aforementioned approaches. hypothesis tests limit space available models search constrained space best oriented model. example hybrid algorithm mmhc work focus constraint-based algorithms speciﬁcally focus algorithm operates phases phase starts fully connected undirected graph tests pairs variables conditional independence given conditioning sets increasing size. variables found indeedge removed separating recorded. output phase undirected graph list separating sets missing edge. absence edge denotes exists variables render conditionally independent. phase starts undirected graph produced phase aims orient many edges possible. ﬁrst step orient colliders colliders oriented four orientation rules applied repetitively changes made output phase directed model represents markov equivalence class underlying distribution. assumptions causal markov condition faithfulness causal suﬃciency shown sound complete large sample limit implies algorithm guaranteed maximally oriented graph consistent independencies inferred data aforementioned conditions. first obtain baseline applied standard algorithm data using signiﬁcance value tests conditional independence. algorithm used implementation provided pcalg package used fisher’s z-transformation partial correlation conditional independence test consists nodes edges. simplistic approach demonstrates challenges presented manufacturing data. learned model hard practitioners interpret large number nodes density learned graphical model. present modiﬁcations algorithm leverage properties manufacturing data learn interpretable causal model domain. speciﬁcally consider following adjustments ﬁrst modiﬁcation aims leverage inherent temporal constraints manufacturing process incorporating prior knowledge algorithm. speciﬁcally events manufacturing process strongly sequential. total ordering among assembly testing stations. example figure station precedes station induces partial ordering variables measured across stations. variables measured station precede variables measured station therefore variables station cannot causal variables measured preceding stations. however among variables measured station information ordering. order improve results incorporated available prior knowledge speciﬁcally phase unoriented graph oriented edges temporal information. then second phase orient many remaining edges possible. produce sparse network produce accurate one. algorithm main parameters adjust type conditional independence tests used signiﬁcance level tests. work considered diﬀerent values signiﬁcance level. tests conditional independence computed statistic p-value lower speciﬁed signiﬁcance threshold null hypothesis independence rejected thus edge kept model. higher value edges kept model. words decreasing value results sparser models. given large sample size algorithm detect even weak dependencies data. however many cases weak dependencies interest researchers. order account eﬀect weak dependencies incorporated strength-of-eﬀect cutoﬀ conditional independence tests. used square partial correlation measure strength eﬀect. dependencies weaker speciﬁed threshold ignored. decreasing strength eﬀect threshold results denser models. measurements taken along assembly line exhibit high pairwise correlation shown figure especially true measurements taken station. consequences structure learning algorithms. first features highly correlated remain connected learned model. results dense graph hinders interpretability. moreover noted above large number features factors contribute uninterpretability learned causal model. fact certain features almost perfectly correlated provides starting point decreasing number variables. order reduce number features included causal model clustered highly correlated features together using hierarchical clustering. distance features deﬁned maximum linkage). cluster chose representative feature feature exhibits maximum average correlation every feature cluster. resulting clusters coherent sense cluster contains mostly variables station. provide qualitative evaluation quality resulting clustering figure shows minimum maximum average correlation across clusters number clusters increases. similarly figure shows size clusters varies number clusters increases. moreover figure shows pairwise correlation medoids clusters. case selected medoids exhibit less pairwise correlation compared original features. finally learned causal graph using cluster medoids shown figure signiﬁcantly smaller model compared figure easier interpret. presented qualitative results show clustering domain knowledge improve interpretability learned causal model. below provide quantitative evaluation impact prior knowledge parameter ﬁne-tuning feature clustering causal discovery. ideally performance structure-learning algorithm would evaluated studying eﬀects interventions. example establish cause would intervene observe distribution changes predicted model. practice type direct interventions assembly line comes high cost. evaluate quality models learned manufacturing process used proxies real interventions compared learned model certain true causal relations identiﬁed domain experts. establishes usefulness causal discovery methods manufacturing domains. order evaluate diﬀerent variants algorithm used synthetic models generate data similar real data produced manufacturing line. compared accuracy models learned diﬀerent variants generative model. partially evaluate eﬀectiveness causal structure learning manufacturing domain domain knowledge. noted earlier figure contains causal relationships extracted model reduced feature set. domain experts also provided partial ground truth identiﬁed nine critical features causal target variable interest based expertise knowledge physical properties manufacturing line. indexed features using medoids clusters hierarchical clustering belonged found nine features belonged three clusters medoids figure observe indeed identiﬁed causes target variable figure contains exact paths extracted full causal model contain critical features. conﬁrms causal structure learned data agrees causal paths provided domain experts. fact learned causal model matches intuition knowledge domain experts encouraging. however provides validation small part model unfortunately lack ground truth makes evaluation complete causal model impossible quantify performance causal discovery techniques manufacturing domain given absence ground truth turn synthetic models simulated data. speciﬁcally synthetic model generate data treat generating model ground truth. ideally synthetic model similar actual model describes domain generated data resemble real data produced assembly line. causal model learned using medoids clusters created hierarchical clustering. green node cluster corresponds target variable note feature names anonymized. process followed generate synthetic data assumes features follow gaussian distribution. evaluated assumption calculating skewness kurtosis feature distribution. medoids extracted observed features skewness kurtosis values within range empirically indicates features within acceptable range indicates normality. compared distribution generated features actual features order demonstrate synthetic data produce resemble real data. figure depicts distribution actual feature compared generated features three features. average precision recall values across synthetic data sets phase shown figure algorithm almost perfect recall precision algorithm drops significance level test increases. expected higher values result denser graph therefore edges incorrectly included output. results phase presented figure alpha values increases recall increases algorithm retrieves true directions. however precision drops suggesting making mistakes orientations. explained learned model includes spurious edges. area causal discovery constraint-based algorithms focused retrieve models markov equivalence class authors describe principled ways choose speciﬁc model markov equivalence class. moreover apart structure learning algorithms leverage conditional independence exist techniques retrieve causal relationships observational data. past years group methods based additive noise models proposed anms leverage properties joint distribution conditional independence. short shown observational distribution modeled structural equation model additive noise structure then certain conditions directionality edges becomes identiﬁable. another line related work focuses learning graphical models groupings variables. segal introduce module networks construct groups variables similar behaviour called modules. also present algorithm learn dependency structure modules data. moreover recent work parviainen discusses grouped variables speciﬁc task causal discovery. regarding application causal discovery techniques bayesian networks domains similar manufacturing domain verron variations naive bayes classiﬁer detect errors manufacturing processes. task however distinct ours classify/predict part faulty opposed building joint causal model domain. closely related work applied causal discovery techniques process control data. paper focuses domain expertise feature selection. moreover authors discretize data domain knowledge limit number states every discrete variable. work statistical methods feature selection/construction abundant features. finally nannapaneni bayesian networks uncertainty quantiﬁcation manufacturing domains. however using scorebased methods construction bayesian networks data. work apply causal structure learning techniques ﬁeld manufacturing. highlight challenges opportunities presented manufacturing data show causal algorithms adapted data. implies large feature space variables measured might highly correlated. characteristics make task causal discovery challenging. hand exists large amount domain knowledge including temporal physical properties assembly line well knowledge domain experts leveraged improve results. presented results application algorithm real data produced manufacturing lines. incorporated prior knowledge clustered feature space improve precision model. structures learned models partially evaluated domain experts thus used identify inﬂuential factors eﬀecting production yield. also explored behavior algorithm synthetic data generated similar original data. show that absence ground truth synthetic data evaluate accuracy diﬀerent algorithms learning causal structure. data produced manufacturing lines provide many opportunities future work. potential direction verify learned causal relationships experimentation production line. intervention assembly-line operations determine observed changes match predicted model. cost associated approach potentially high. assembly line stop interventions take place causal relationships could tested manner. however would provide strong evidence validity causal relationships learned data. another direction future work information-theoretic measures dependence instead linear correlation advanced tests conditional independence allow models identify nonlinear relationships data. finally partial ordering variables arises naturally manufacturing domains provides ideal setting application top-down causal discovery algorithms kernel-based conditional independence test application causal discovery. proceedings twenty-seventh conference uncertainty artiﬁcial intelligence pages meek. causal inference causal explanation background knowledge. proceedings eleventh conference uncertainty artiﬁcial intelligence pages morgan kaufmann publishers inc. identiﬁability causal graphs using functional models. cozman pfeﬀer editors proceedings annual conference uncertainty artiﬁcial intelligence pages auai press", "year": 2016}