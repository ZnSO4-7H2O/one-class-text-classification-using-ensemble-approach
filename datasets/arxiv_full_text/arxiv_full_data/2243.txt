{"title": "Two-stage Algorithm for Fairness-aware Machine Learning", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Algorithmic decision making process now affects many aspects of our lives. Standard tools for machine learning, such as classification and regression, are subject to the bias in data, and thus direct application of such off-the-shelf tools could lead to a specific group being unfairly discriminated. Removing sensitive attributes of data does not solve this problem because a \\textit{disparate impact} can arise when non-sensitive attributes and sensitive attributes are correlated. Here, we study a fair machine learning algorithm that avoids such a disparate impact when making a decision. Inspired by the two-stage least squares method that is widely used in the field of economics, we propose a two-stage algorithm that removes bias in the training data. The proposed algorithm is conceptually simple. Unlike most of existing fair algorithms that are designed for classification tasks, the proposed method is able to (i) deal with regression tasks, (ii) combine explanatory attributes to remove reverse discrimination, and (iii) deal with numerical sensitive attributes. The performance and fairness of the proposed algorithm are evaluated in simulations with synthetic and real-world datasets.", "text": "generated credit scores popular many countries interviewees sometimes evaluated assessment algorithms. however potential loss transparency accountability fairness arises decision making conducted basis past data. example dataset indicates direct application fairness could lead reverse discrimination. this take example income adult dataset women average lower incomes men. however women dataset work fewer hours week average. fairness-aware table list fair estimators capabilities. categorical sensitive attrs indicates algorithm deal binary sensitive attributes. numeric sensitive attrs indicates algorithm deal continuous sensitive attributes. explanatory attrs indicates algorithm utilizes attributes justify treatment checkmark indicates capability algorithm corresponding aspect. consider group-level fairness sense preventing disparate impact beneﬁts group disproportionally. ease discussion assume binary real single attribute. note method capable dealing multiple attributes categorical goal predict attributes noise uncorrelated ordinary least square ˆβols x)−xy consistently estimates however consistent property lost correlated namely well-known that mild assumption indicates covariance convergence probability. remove bias term utilize additional attributes independent correlate crux project columns column space theorem samples drawn distribution training dataset corresponding residual learnt training distribution. assumption asymptotically independent moreover independent asymptotically independent proof. assumption well known ﬁrst-stage estimator consistent. assumption independent asymptotically independent independence follows fact function asymptotically independent figure ﬁrst histogram shows percentage people labor force unemployed community dataset horizontal axis pctunemployed vertical axis number corresponding communities. communities categorized ones large portion black people others pctunemployed sharply centered around whereas value shows broader spectrum result variance pctunemployed greatly diﬀer among categories. second histogram shows number people diﬀerent adult dataset horizontal axis vertical axis number people. variances also form distributions diﬀerent women majority women dataset youngest category. details datasets provided section figure correlation coeﬃcient diﬀerent parameters figure result diﬀerent datasize figure result diﬀerent dimension figure result diﬀerent strength correlation figure result diﬀerent variance rmse larger. correlation causes disparate impact whereas keeps fair forces large bias correction correlation large. parameters result averaged independent runs. results synthetic dataset describes results real-world datasets simulation implemented python using scikit-learn library. simulations took several seconds several minutes modern ﬁrst stage. unless speciﬁed parameters follows diagonal matrices diagonal entry matrix entry entry entry number datapoint datapoints used training datasets respectively. ﬁrst show results regression communities crime dataset combines socio economic data crime rate data communities united states. following calders table regression results. scores averaged result -fold cross validation results sem-s sem-mp ones reported calders explanatory attrs shows result explanatory attributes added smaller indicates better fairness close indicates fair regressor. smaller rmse indicates better regression accuracy. table classiﬁcation results adult dataset. column accuracy presents classiﬁcation accuracy. unlike take fairness consideration complies %-rule. table classiﬁcation results german dataset. unlike complies %-rule. result averaged random splits training testing datasets two-thirds datapoints assigned training dataset split. table results compas lsac datasets. balanced training data resampling lsac dataset cope class inbalance problem. compas-r version compas dataset predictive attributes dropped version dropped attributes original dataset whose correlation stronger signiﬁcantly reduces prediction accuracy fairness estimator tries utilize available information much possible. unlike fairness decrease even attributes dropped. conducts quantile-based transformation. also combined transformation sdr. k-th attribute quantile-based transformation maps attribute quantile rank among sensitive attributes table classiﬁcation results adult dataset without ordinal transformation with ordinal trans. indicates ordinal transformation conducted attribute. cont. only indicates non-numeric attributes discarded beforehand.", "year": 2017}