{"title": "Virtual to Real Reinforcement Learning for Autonomous Driving", "tag": ["cs.AI", "cs.CV"], "abstract": "Reinforcement learning is considered as a promising direction for driving policy learning. However, training autonomous driving vehicle with reinforcement learning in real environment involves non-affordable trial-and-error. It is more desirable to first train in a virtual environment and then transfer to the real environment. In this paper, we propose a novel realistic translation network to make model trained in virtual environment be workable in real world. The proposed network can convert non-realistic virtual image input into a realistic one with similar scene structure. Given realistic frames as input, driving policy trained by reinforcement learning can nicely adapt to real world driving. Experiments show that our proposed virtual to real (VR) reinforcement learning (RL) works pretty well. To our knowledge, this is the first successful case of driving policy trained by reinforcement learning that can adapt to real world driving data.", "text": "xinlei pan∗ xinleipanberkeley.edu yurong you∗ yurongyousjtu.edu.cn ziyan wang zy-wangmails.tsinghua.edu.cn cewu lu-cwcs.sjtu.edu.cn indicates equal contribution. reinforcement learning considered promising direction driving policy learning. however training autonomous driving vehicle reinforcement learning real environment involves non-affordable trial-and-error. desirable ﬁrst train virtual environment transfer real environment. paper propose novel realistic translation network make model trained virtual environment workable real world. proposed network convert non-realistic virtual image input realistic similar scene structure. given realistic frames input driving policy trained reinforcement learning nicely adapt real world driving. experiments show proposed virtual real reinforcement learning works pretty well. knowledge ﬁrst successful case driving policy trained reinforcement learning adapt real world driving data. autonomous driving aims make vehicle sense environment navigate without human input. achieve goal important task learn driving policy automatically outputs control signals steering wheel throttle brake etc. based observed surroundings. straight-forward idea end-to-end supervised learning trains neural network model mapping visual input directly action output training data labeled image-action pairs. however supervised approach usually requires large amount data train model generalize different environments. obtaining amount data time consuming requires signiﬁcant human involvement. contrast reinforcement learning learns trial-and-error fashion require explicit supervision human. recently reinforcement learning considered promising technique learn driving policy expertise action planing however reinforcement learning requires agents interact environments undesirable driving actions would happen. training autonomous driving cars real world cause damages vehicles surroundings. therefore current research autonomous driving reinforcement learning focus simulations rather training real world. agent trained reinforcement learning achieves copyright document resides authors. distributed unchanged freely print electronic forms. figure framework virtual real reinforcement learning autonomous driving. virtual images rendered simulator ﬁrst segmented scene parsing representation translated synthetic realistic images proposed image translation network agent observes synthetic realistic images takes actions. environment give reward agent. since agent trained using realistic images visually similar real world scenes nicely adapt real world driving. near human-level driving performance virtual world applicable real world driving environment since visual appearance virtual simulation environment different real world driving scene. virtual driving scenes different visual appearance compared real driving scenes share similar scene parsing structure. example virtual real driving scenes roads trees buildings etc. though textures signiﬁcantly different. therefore reasonable translating virtual images realistic counterparts obtain simulation environment looks similar real world terms scene parsing structure object appearance. recently generative adversarial network drawn attention image generation. work proposed image-to-image translation network translate images domain another using paired data domains. however hard paired virtual-real world images driving making difﬁcult apply method case translating virtual driving images realistic ones. paper propose realistic translation network help train self-driving entirely virtual world adapt real world driving environment. proposed framework converts virtual images rendered simulator realistic train reinforcement learning agent synthesized realistic images. though virtual realistic images different visual appearance share common scene parsing representation therefore translate virtual images realistic images using scene parsing representation interim. insight similar natural language translation semantic meaning interim different languages. speciﬁcally realistic translation network includes modules. ﬁrst virtual-to-parsing virtual-to-segmentation module produces scene parsing representation input virtual image. second parsing-to-real network translates scene parsing representations realistic images. realistic translation network reinforcement learning model learnt realistic driving data nicely apply real world driving. demonstrate effectiveness method trained reinforcement learning model using realistic translation network ﬁlter virtual images synthetic realistic images feed realistic images state inputs. compared supervised learning reinforcement learning approaches domain randomization experiments illustrate reinforcement learning model trained translated realistic images better performance reinforcement learning model trained virtual input virtual real reinforcement learning domain randomization. supervised learning autonomous driving. supervised learning methods obviously straightforward ways train autonomous vehicles. alvinn provides early example using neural network autonomous driving. model simple direct maps image inputs action predictions shallow network. powered deep learning especially convolutional neural network nvidia recently provides attempt leverage driving video data simple lane following task. another work learns mapping input images number perception indicators closely related affordance driving state. however learned affordance must associated actions hand-engineered rules. supervised methods work relatively well simple tasks lane-following driving highway. hand imitation learning also regarded supervised learning approach agent observes demonstrations performed experts learns imitate actions experts. however intrinsic shortcoming imitation learning covariate shift problem generalize well scenes never experienced before. reinforcement learning autonomous driving. reinforcement learning applied wide variety robotics related tasks computer games robot locomotion autonomous driving challenges practical realworld applications reinforcement learning high-dimensionality state space well non-trivial large action range. developing optimal policy highcomplexity space time consuming. recent work deep reinforcement learning made great progress learning high dimensional space power deep neural networks however deep q-learning method policy gradient method require agent interact environment reward feedback. however unrealistic train autonomous vehicle reinforcement learning real world environment since hurt surroundings takes wrong action. reinforcement learning wild. performing reinforcement learning driving simulator transferring learned models real environment could enable faster lower-cost training much safer training real car. however real-world driving challenge usually spans diverse range often signiﬁcantly different training environment driving simulator terms visual appearance. models trained purely virtual data generalize well real images recent progress transfer domain adaptation learning robotics provides examples simulation-toreal reinforcement training models either ﬁrst train model virtual environment ﬁne-tune real environment learn alignment virtual images real images ﬁnding representations shared domains randomized rendered virtual environments train test real environment work proposes progressive network transfer network weights model trained virtual data real environment ﬁnetune model real setting. training time real environment greatly reduced ﬁrst training virtual environment. however still necessary train agent real environment thus solve critical problem avoiding risky trial-and-error real world. methods learn alignment virtual images real images could fail generalize complex scenarios especially hard good alignment virtual images real images. recent work proposed framework training reinforcement learning agent virtual environment. work proved possibility performing collisionfree ﬂight real world training model simulator. however mentioned conclusion paper manual engineering work design suitable training environments nontrivial reasonable attain better results combining simulated training real data though unclear paper combine real data simulated training. image synthesis image translation. image translation aims predict image speciﬁc modality given image another modality. treated generic method predicts pixels pixels. recently community made signiﬁcant progress generative approaches mostly based generative adversarial networks name work explored vae-gan generating voxel models work proposed cascade generate natural images structure style. recently work developed general simple framework image-to-image translation handle various pixel level generative tasks like semantic segmentation colorization rendering edge maps etc. scene parsing. part network semantic image segmentation network. already many great works ﬁeld semantic image segmentation. many based deep convolutional neural network fully convolutional neural network paper segnet image segmentation structure network revealed composed main parts. ﬁrst part encoder consists convolutional batch normalization relu pooling layers. second part decoder replaces pooling layers upsampling layers. successfully apply driving model trained entirely virtual environment realworld driving challenges. major gaps agent observes frames rendered simulator different real world frames terms appearance. therefore proposed realistic translation network convert virtual frames realistic ones. inspired work image-to-image translation network network includes modules namely virtual-to-parsing parsing-to-realistic network. ﬁrst maps virtual frame scene parsing image. second translates scene parsing realistic frame similar scene structure input virtual frame. modules generate realistic frames maintain scene parsing structure input virtual frames. architecture realistic translation network illustrated figure finally train self-driving agent using reinforcement learning method realistic frames obtained realistic translation network. approach adopt developed asynchronous actor-critic reinforcement learning algorithm train self-driving vehicle racing simulator torcs section ﬁrst present proposed realistic translation network discuss train driving agent reinforcement paired virtual real world image direct mapping virtual world image real world image using would awkward. however types images express driving scene translate using scene parsing representation. inspired realistic translation network composed image translation networks ﬁrst image translation network translates virtual images segmentations second image translation network translates segmented images real world counterparts. image-to-image translation network proposed basically conditional gan. difference traditional gans conditional gans gans learn mapping random noise vector output image conditional gans take image noise vector generate another image {xz} usually different domain compared network consists image-to-image translation networks networks loss function equation ﬁrst network translates virtual images segmentations {xz} second network translates segmented images realistic counterparts {sz} noise terms avoid deterministic outputs. neural network structures generator discriminator architectures used conventional solver asynchronous advantage actor-critic train self driving vehicle performed well various machine learning tasks. algorithm fundamental actor-critic algorithm combines several classic reinforcement learning algorithms idea asynchronous parallel threads. multiple threads time unrelated copies environment generating sequences training samples. actors-learners proceed though exploring different parts unknown space. thread parameters synchronized iteration learning updated ﬁnishing details algorithm implementation found speed agent time step angle agent’s speed tangent line track dist center distance center agent middle track. constants determined beginning training. take training. performed sets experiments compare performance method reinforcement learning methods well supervised learning methods. ﬁrst sets experiments involves virtual real reinforcement learning real world driving data. second sets experiments involves transfer learning different virtual driving environments. virtual simulator used experiments torcs. figure examples virtual real image translation. columns virtual images captured torcs. even columns synthetic real world images corresponding virtual images left. experiment trained proposed reinforcement learning model realistic translation network. ﬁrst trained virtual real image translation network used trained network ﬁlter virtual images simulator realistic images. realistic images feed train driving policy. finally trained policy tested real world driving data evaluate steering angle prediction accuracy. comparison also trained supervised learning model predict steering angles every test driving video frame. model deep neural network architecture design policy network reinforcement learning model. input network sequence four consecutive frames output network action probability vector elements vector represent probability going straight turning left turning right. training data supervised learning model different testing data used evaluate model performance. addition another baseline reinforcement learning model also trained. difference b-rl method virtual world images directly taken agent state inputs. baseline also tested real world driving data. dataset. real world driving video data collected sunny detailed steering angle annotations frame. total around images dataset selected training supervised learning model another selected held testing. train realistic translation netfigure transfer learning different environments. oracle trained cgtrack tested cgtrack performance best. model works better domain randomization method. domain randomization method requires training multiple virtual environments imposes signiﬁcant manual engineering work. work collected virtual images segmentations aalborg environment torcs. total images collected covers entire driving cycle aalborg environment. scene segmentation. used image semantic segmentation network design trained segmentation network cityscape image segmentation dataset segment real world driving images network trained cityscape dataset classes trained iterations. image translation network training. trained virtual-to-parsing parsingto-real network using collected virtual-segmentation image pairs segmentation-real image pairs. translation networks encoder-decoder fashion shown ﬁgure image translation network used u-net architecture skip connection connect separate layers encoder decoder respectively output feature shape. input size generator convolutional layer kernel size striding size leakyrelu applied every convolutional layer slope relu applied every deconvolutional layer. addition batch normalization layer applied every convolutional deconvolutional layer. ﬁnal output encoder connected convolutional layer yields output shape followed tanh. used virtual-segmentation image pairs train virtual segmentation network. redundancies real images selected images segmentations images train parsing-to-real image translation network. train image translation models used adam optimizer initial learning rate momentum batchsize iterations convergence. reinforcement training. network structure used training similar actor network -layer convolutional network relu activation functions in-between. network takes consecutive frames state input output discrete actions corresponds straight acceleration left acceleration right acceleration straight brake left brake right brake straight left right. trained reinforcement learning agent asynchronous threads rmsprop opevaluation. real world driving dataset provides steering angle annotations frame. however actions performed torcs virtual environment contain \"going left\" \"going right\" \"going straight\" combinations \"acceleration\" \"brake\". therefore deﬁne label mapping strategy translate steering angle labels action labels virtual simulator. relate steering angle action \"going straight\" steering angle less action \"going left\" steering angle action \"going right\". comparing output actions generated method ground truth obtain accuracy driving action prediction. performed another sets experiments obtained results transfer learning different virtual driving environments. experiments trained three reinforcement learning agents. ﬁrst agent trained standard cg−track environment torcs evaluated performance frequently environments. reasonable expect performance agent best call \"oracle\". second agent trained proposed reinforcement learning method realistic translation network. however trained e-track environment torcs evaluated cg-track. necessary note visual appearance e-track different cg-track. third agent trained domain randomization method similar agent trained different virtual environments evaluated cg-track. training methods obtain segmented images e-track cg-track train virtual-to-parsing parsing-to-real image translation networks. image translation training details reinforcement learning details section image segmentation results. used image segmentation model trained cityscape dataset segment virtual real images. examples shown ﬁgure shown ﬁgure although original virtual image real image look quite different scene parsing results similar. therefore reasonable scene parsing interim connect virtual images real images. qualitative result realistic translation network. figure shows representative results image translation network. columns virtual images torcs even columns translated realistic images. images virtual environment appears darker translated images real images used train translation network captured sunny day. therefore model succeed synthesize realistic images similar appearance original ground truth real images. reinforcement training results. results virtual real reinforcement learning real world driving data shown table results show proposed method better overall performance baseline method reinforcement training agent trained virtual environment without seeing real data. supervised method best overall performance however trained large amounts supervised labeled data. result transfer learning different virtual environments shown ﬁgure obviously standard trained tested environment gets best performance. however model performs better domain randomization method requires training multiple environments generalize. mentioned domain randomization requires lots engineering work make generalize. model succeeds observing translated images e-track cg-track means model already gets training environment looks similar test environment thus performance improved. proved experiments using synthetic real images training data reinforcement learning agent generalizess better real environment pure training virtual data training domain randomization. next step would design better image-to-image translation network better reinforcement learning framework surpass performance supervised learning. thanks bridge scene parsing virtual images translated realistic images maintain scene structure. learnt reinforcement learning model realistic frames easily applied real-world environment. also notice translation results segmentation unique. example segmentation indicates assign color therefore future work make parsing-to-realistic network output various possible appearances bias reinforcement learning training would largely reduced. provide ﬁrst example training self-driving vehicle using reinforcement learning algorithm interacting synthesized real environment proposed imageto-segmentation -to-image framework. show using method training possible obtain self driving vehicle placed real world.", "year": 2017}