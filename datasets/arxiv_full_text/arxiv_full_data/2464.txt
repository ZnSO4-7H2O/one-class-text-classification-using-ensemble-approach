{"title": "Interactive Elicitation of Knowledge on Feature Relevance Improves  Predictions in Small Data Sets", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "Providing accurate predictions is challenging for machine learning algorithms when the number of features is larger than the number of samples in the data. Prior knowledge can improve machine learning models by indicating relevant variables and parameter values. Yet, this prior knowledge is often tacit and only available from domain experts. We present a novel approach that uses interactive visualization to elicit the tacit prior knowledge and uses it to improve the accuracy of prediction models. The main component of our approach is a user model that models the domain expert's knowledge of the relevance of different features for a prediction task. In particular, based on the expert's earlier input, the user model guides the selection of the features on which to elicit user's knowledge next. The results of a controlled user study show that the user model significantly improves prior knowledge elicitation and prediction accuracy, when predicting the relative citation counts of scientific documents in a specific domain.", "text": "models problem requires regularizing model’s regression coefﬁcients typically level regularization tuned estimating hyperparameter data neglects prior information could available problem prior information referring knowledge problem user inspecting data. knowledge features’ effects target could signiﬁcantly improve predictions prior knowledge prediction often straightforward. example prior information available format easily plugged prediction model. nevertheless domain expert possess tacit knowledge written anywhere relationships features target variable. take example task predicting number citations scientiﬁc document receives certain domain. expert easily indicate presence term ‘neural’ document implies higher relative citation count machine learning domain. however eliciting tacit knowledge difﬁcult number putative features large checking individual feature excessively laborious. present novel approach extracts tacit knowledge domain expert uses knowledge prior information improved predictions. prediction model still responsible generating predictions target variable. however user model selects features whose relevance indicated user domain expert using interactive visualization. here relevant feature feature positively correlated target value. user model iteratively elicits information build model user’s tacit knowledge select features would beneﬁt user’s input. user input encoded prior knowledge prediction model improve accuracy. contributions present novel method interactively models user’s tacit knowledge relevance features predicted target uses elicited information prior knowledge accurate prediction model. user study demonstrate using user model select features require input domain expert signiﬁcantly improves prior knowledge elicitation compared randomly selected features. abstract providing accurate predictions challenging machine learning algorithms number features larger number samples data. prior knowledge improve machine learning models indicating relevant variables parameter values. prior knowledge often tacit available domain experts. present novel approach uses interactive visualization elicit tacit prior knowledge uses improve accuracy prediction models. main component approach user model models domain expert’s knowledge relevance different features prediction task. particular based expert’s earlier input user model guides selection features elicit user’s knowledge next. results controlled user study show user model signiﬁcantly improves prior knowledge elicitation prediction accuracy predicting relative citation counts scientiﬁc documents speciﬁc domain. introduction address machine learning problem predicting values target variable given training data target variable values known. training data needs representative underlying population size must large enough machine learning model accurately learn predict target variable. applications like personalized medicine brain imaging textual document categorization number features exceeds number samples leading small large problem classical models inaccurately predict target. fitting regression permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights components work owned others author must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. request permissions permissionsacm.org. march limassol cyprus. copyright held owner/author. publication rights licensed acm. isbn ----// ..... http//dx.doi.org/./. figure overview approach. user interface implementation approach. flow data prediction model user model interactive visualization various iterations prior knowledge elicitation prediction improvement process. ‘method’ section details. related work expert knowledge integrated prediction models deﬁning prior distributions model parameters. typically prior elicitation full prior distributions deﬁned experts time consuming infeasible high-dimensional problems even interactive tools. simpler method bayesian networks required experts indicate presence absence uncertain causal relationships information retrieval interactive intent modeling ﬁnds relevant resources based user’s previous input deciding features user input done iteratively balancing exploitation currently promising features exploration uncertain possibly interesting ones. balancing done linear bandit algorithms previously interactive visualization used classiﬁcation tasks however underlying classiﬁcation model directly modiﬁed approaches limited cases samples features. possibly important features visualized user included interactively classiﬁer user shown features best explained predictions classiﬁer allowing reject irrelevant features. semisupervised clustering considered users indicated pairs items belong cluster. however simply including excluding feature sensitive errors sufﬁcient small large problems. method tackles problem simplifying assumption expert give noisy input directly regression coefﬁcients performed non-interactively direct elicitation logistic regression coefﬁcients. recent works considering similar problem user speciﬁed similarity features input features chosen based information gain approach interactive visualization purpose knowledge elicitation improve accuracy prediction model. approach differs methods using ’user model’ adaptively learns domain user’s expert knowledge. automatically guides interaction towards features would likely beneﬁt user’s input based current representation expert’s knowledge. furthermore user model exploit training data also additional auxiliary data features important scaling method small data sets. method fig. shows main components approach namely prediction model user model interactive visualization implementation approach shown fig. ivis displays training data features user indicate relevance particular prediction task. models user’s knowledge feature relevances uses user input training data improve predictions. training data small samples large number features target. additional data referred auxiliary feature descriptors required provide information features available training data. events approach follows initialize. initialized initialized input prediction model takes training data points features value target variable sample addition vector relevances provided feature relevant i.e. received positive user input otherwise. assume linear prediction model vector regression coefﬁcients variance gaussian noise. relevances features enter prediction model modifying prior distribution elements follows half-n denotes half-normal distribution. intuition feature deemed relevant presence assumed increase value output variable multiplier determines overall ratio effect sizes relevant non-relevant features. fig. shows impact formulation estimated regression coefﬁcients. user model efﬁcient interaction balances querying additional input either promising relevant features uncertain ones achieved using upper conﬁdence bound criterion select features show user algorithm linrel iteration user shown features highest ucbs previous iteration. user speciﬁes binary relevance value feature iteration user model updates estimated feature relevances using linear model feature descriptor feature determines default relevance. vector regression coefﬁcients estimated inputs given using standard regularized least squares solution. relevances converted interval using logistic transformation. feature descriptors chosen depending problem domain constructed training data and/or auxiliary data features necessarily target variable available. example evaluation study tf-idf keywords clusters scientiﬁc documents. intuition keywords appear similar documents similar effect prediction task thus correlated feature descriptors. finally ucbs deﬁned rucb high probability bound relevance uncertainty computed using suplinucb interactive visualization heatmap using color-blind safe color scale depicts training data rows indicate categories samples grouped columns indicate features selected user model user input required cell color indicates strongly average feature associated samples category total bars heatmap showing total number samples value based idea reliability training data. clicking feature labels user relevance bars either indicating whether feature respectively relevant predicted target relevance bars provide domain expert means input tacit knowledge. even though heatmap total bars showing training data could help domain expert decide feature relevances essential approach. nonetheless still evaluated usefulness post-questionnaire user study experiment conditions included non-interactive prediction model; interactive prediction model features user interactive prediction model features user intask predict relative citation count scientiﬁc document domain artiﬁcial intelligence given certain words title abstract keywords. participants indicate whether suggested features relevant target iterations. data used subset tang al.’s citation data containing scientiﬁc documents manually retrieved author provided keywords; automatically extracted additional keywords title abstract documents using python rake kpminer lemmatized keywords obtained using python natural language toolkit resulted unique keywords used features. data collection evenly split training test set. training used train prediction model test used evaluate accuracy predictions using mean squared error hypotheses were provide accurate predictions provides accurate predictions adopted between-participant design participants participants participants least years research experience machine learning; undertaking postdoc least somewhat familiar heatmaps charts; aged participant trained system introduced prediction task asked complete task iteration. answers discussed experimenter participant given explore system actual experiment. participants ﬁlled questionnaire. experiment took ≈mins movie ticket awarded. details supplementary material. results discussion ﬁnal predictions accurate participants i.e. user input always increased prediction accuracy mean squared error decreased participants provided input without user input user input interaction average performance signiﬁcantly different performance without user input conﬁrming thus without user input prediction model explained variance target variable user input evaluate difference giving user input random order user model computed average curves groups random order improves predictions approximately linearly w.r.t. number user input whereas user model predictions improve rapidly early stages interaction expected. used maximum distance average curves test statistic characterize difference computed distribution test statistic assuming difference groups using permutations group labels shows difference signiﬁcant thus conﬁrming results post-questionnaire indicate that visualization training data used user uncertain feature relevance heatmap referred total bars carefully analysed verify reliability figure mean squared error w.r.t. number inputs provided study participants. test statistic maximum distance average performance curves. distribution test statistic permutations. displayed data visualization familiar simple enough domain expert understand use. summary ﬁndings suggest visualizing data useful eliciting expert feedback inspiring develop visualization future. approach query user whether feature relevant i.e. positively correlated target variable. compromise detailed input regression coefﬁcients full prior simple input discarding subset features kind user input easy give powerful improving predictive performance. however model potentially sensitive errors user input. also although providing user input positive effects natural prediction task considered here cases negative user input useful. consider issues future work. user model formulation additional beneﬁt allowing integration auxiliary data deﬁning feature descriptors. particularly important sample size decreases training data alone would provide enough information guide user interaction. conclusion presented novel approach eliciting tacit knowledge domain experts using prior knowledge improve accuracy prediction models small large problems. user study indicates effectiveness approach contrast non-interactive prediction model interactive suggests features user input random. future will evaluate approach real-word data; explore visualizations facilitate knowledge elicitation; investigate ways extend prediction model multiple output learning. acknowledgments thank participants user study. acknowledge computational resources provided aalto scienceproject. work funded academy finland jenny antti wihuri foundation. costello heiser georgii gönen menden wang bansal hintsanen khan mpindi j.-p. community effort assess improve drug sensitivity prediction algorithms. nature biotechnology denham martin mengersen comparison three expert elicitation methods logistic regression predicting presence threatened brush-tailed rock-wallaby. environmetrics bontempi aerts quackenbush haibe-kains comparison validation genomic predictors anticancer drug sensitivity. journal american medical informatics association tian alizadeh gentles tibshirani simple method estimating interactions treatment large number covariates. journal american statistical association prediction model input prediction model takes training data points vector relevances {}kwhere feature relevant i.e. received positive feedback. otherwise assume target depends linearly predictor multiplier determines ratio variance parameters relevant non-relevant features given prior distribution constrains greater mean according weakly informative prior corresponds expectation regression coefﬁcients relevant features greater magnitude coefﬁcients nonrelevant features. term appearing prior variances regression coefﬁcients relevant non-relevant features speciﬁed investigating variance linear predictions. direct integration regression weights conditional parameters numbers relevant non-relevant features relevant features covariance features. practice second term equation less ﬁrst term therefore retain ﬁrst term keep computations simple denote proportion variance explained prediction model. assuming normalized proportion variance explained given equation solve shown fig. corresponds expectation approximately variance target explained prediction model. imposes prior equation finally place following prior noise variance user model efﬁcient interaction balances querying additional input either promising relevant features uncertain ones upper conﬁdence bound criterion select features show user achieves this algorithm linrel iteration user shown features highest ucbs previous iteration. user speciﬁes binary relevance value feature denote inputs collected user iteration iteration user model updates estimated feature relevances using linear model regularizer rknz feature descriptor matrix sub-matrix contains descriptors corresponding features received user input thus far. furthermore convert relevances interval using logistic transformation. high probability bound relevance uncertainty true relevance derived using suplinucb parameter determines exploration-exploitation trade-off. evaluation user model selects features largest ucbs selected avoid querying feature twice. initialize user model pseudo-input order choose relevant ﬁrst features possible. feature’s regression coefﬁcient non-interactive prediction model pseudo-input since input features highest regression coefﬁcients greatest potential improving predictions impact pseudo-input weak pseudo-inputs correspond real user input. therefore impact pseudo-feedback decreases user input received. pseudo-input included expressed explicitly regression coefﬁcients feature descriptors evaluation evaluation study tf-idf words clusters scientiﬁc documents feature descriptors. intuition words appear similar documents similar effect prediction task thus correlated feature descriptors. furthermore words appear evenly clusters likely useful prediction. feature descriptors constructed using auxiliary data keywords combination prediction data set. auxiliary data documents least common keyword prediction data used. results unique documents unique keywords features. data available features target variables used constructing feature descriptors. utilize maximal amount information available without risking over-ﬁtting model. documents clustered clusters hierarchical clustering based cosine distance feature space. randomly chosen documents used train model rest documents assigned clusters based distance cluster centers. results feature descriptor matrix element tf-idf word cluster -score word computed cluster-wise document-wise. evaluation following documents provided participants controlled experiment training phase actual experiment task phase questionnaire participants experiment together results.", "year": 2016}