{"title": "Training Restricted Boltzmann Machine by Perturbation", "tag": ["cs.NE", "cs.LG", "stat.ML"], "abstract": "A new approach to maximum likelihood learning of discrete graphical models and RBM in particular is introduced. Our method, Perturb and Descend (PD) is inspired by two ideas (I) perturb and MAP method for sampling (II) learning by Contrastive Divergence minimization. In contrast to perturb and MAP, PD leverages training data to learn the models that do not allow efficient MAP estimation. During the learning, to produce a sample from the current model, we start from a training data and descend in the energy landscape of the \"perturbed model\", for a fixed number of steps, or until a local optima is reached. For RBM, this involves linear calculations and thresholding which can be very fast. Furthermore we show that the amount of perturbation is closely related to the temperature parameter and it can regularize the model by producing robust features resulting in sparse hidden layer activation.", "text": "approach maximum likelihood learning discrete graphical models particular introduced. method perturb descend inspired ideas perturb method sampling learning contrastive divergence minimization. contrast perturb leverages training data learn models allow efﬁcient estimation. learning produce sample current model start training data descend energy landscape perturbed model ﬁxed number steps local optima reached. involves linear calculations thresholding fast. furthermore show amount perturbation closely related temperature parameter regularize model producing robust features resulting sparse hidden layer activation. common procedure learning probabilistic graphical model maximize likelihood observed data updating model parameters along gradient likelihood. gradient step requires inference current model performed using deterministic markov chain monte carlo procedure intuitively gradient step attempts update parameters increase unnormalized probability observation decreasing unnormalized probabilities states –i.e. partition function. ﬁrst part update known positive phase second part referred negative phase. efﬁcient alternative contrastive divergence training negative phase decreases probability conﬁgurations vicinity training data. practice neighboring states sampled taking steps markov chains initialized training data. recently perturbation methods combined efﬁcient maximum posteriori solvers used efﬁciently sample pgms basic idea extreme value theory used states assignments particular perturbations gibbs distribution replace unbiased samples unperturbed model practice however models perturbed ideal form approximations used hazan show lower order approximations provide upper bound partition function suggest perturb sampling procedure used negative phase maximize lower bound log-likelihood data. however feasible efﬁcient estimation possible even repeated estimation step learning could prohibitively expensive. data lower perturbed-energy conﬁgurations. conﬁgurations fantasy particles negative phase learning. although scheme used arbitrary discrete pgms without hidden variables consider application task training restricted boltzmann machine bipartite markov random field variables partitioned visible hidden units. representation power relative ease training increasing used various applications. example generative model movie ratings speech topic modeling importantly used construction deep neural architectures ﬁrst second terms line correspond positive negative phase respectively. easy calculate required positive phase. negative phase however requires unconditioned samples current model require long mixing markov chain. note form update appears learning markov random field regardless form graph presence hidden variables. general gradient update following form sufﬁcient statistics corresponding parameter example sufﬁcient statistics variable interactions vihj. note calculating expectation ﬁrst term appears hidden variables present. estimating second term update sample model training data mind. samples model initializing markov chain data points running steps. repeated time calculate gradient. limit gives unbiased samples current model however using steps performs well practice markov chain simply block gibbs sampler visible hidden units sampled alternatively using also possible initialize chain training data beginning learning calculation gradient chain previous state. known persistent stochastic maximum likelihood unbiased sample means sample repeatedly perturbing ﬁnding assignment. obtain samples gumbel distribution transform samples uniform distribution log). unary potentials. case rbm’s parametrization corresponds adding difference random samples standard gumbel distribution limited class mrfs allow efﬁcient energy minimization propose alternative perturb suitable inference employed within context learning. since ﬁrst second order perturbations perturb upper bound partition function likelihood optimization using method desirable hand since model trained data-set leverage training data sampling model. similar step gradient start training data. order produce fantasy particles negative phase perturb current model take several steps towards lower energy conﬁgurations. take enough steps reach local optima stop midway. effect amount perturbations simply multiplied noise constant i.e. means perturbed model larger noise values. going back lemma multiplication noise compensated change temperature energy function i.e. remains same. however changing noise without changing energy. provide intuition potential effect increasing perturbations. experimental results seem conﬁrm view. negative phase learning lowering probability conﬁgurations larger distance training data compared training make model robust puts effort removing false valleys distant training data less effort made remove valleys closer training data. second order perturbation perturb subset non-overlapping pairwise potentials well unary potentials remaining variables. desirable select pairwise potentials higher inﬂuence i.e. larger |wij values. visible hidden variables hungarian maximum bipartite matching algorithm inﬂuential interactions inﬂuential interactions selected need perturb corresponding factors gumbel noise well bias terms variables covered. simple calculation shows perturbation potentials corresponds perturbing well follows", "year": 2014}