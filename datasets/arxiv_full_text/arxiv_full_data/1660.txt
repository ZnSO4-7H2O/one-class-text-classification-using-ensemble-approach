{"title": "The BURCHAK corpus: a Challenge Data Set for Interactive Learning of  Visually Grounded Word Meanings", "tag": ["cs.CL", "cs.AI", "cs.LG", "cs.RO"], "abstract": "We motivate and describe a new freely available human-human dialogue dataset for interactive learning of visually grounded word meanings through ostensive definition by a tutor to a learner. The data has been collected using a novel, character-by-character variant of the DiET chat tool (Healey et al., 2003; Mills and Healey, submitted) with a novel task, where a Learner needs to learn invented visual attribute words (such as \" burchak \" for square) from a tutor. As such, the text-based interactions closely resemble face-to-face conversation and thus contain many of the linguistic phenomena encountered in natural, spontaneous dialogue. These include self-and other-correction, mid-sentence continuations, interruptions, overlaps, fillers, and hedges. We also present a generic n-gram framework for building user (i.e. tutor) simulations from this type of incremental data, which is freely available to researchers. We show that the simulations produce outputs that are similar to the original data (e.g. 78% turn match similarity). Finally, we train and evaluate a Reinforcement Learning dialogue control agent for learning visually grounded word meanings, trained from the BURCHAK corpus. The learned policy shows comparable performance to a rule-based system built previously.", "text": "motivate describe freely available human-human dialogue data interactive learning visually grounded word meanings ostensive deﬁnition tutor learner. data collected using novel character-by-character variant diet chat tool novel task learner needs learn invented visual attribute words tutor. such text-based interactions closely resemble face-to-face conversation thus contain many linguistic phenomena encountered natural spontaneous dialogue. include selfother-correction mid-sentence continuations interruptions overlaps ﬁllers hedges. also present generic n-gram framework building user simulations type incremental data freely available researchers. show simulations produce outputs similar original data finally train evaluate reinforcement learning dialogue control agent learning visually grounded word meanings trained burchak corpus. learned policy shows comparable performance rulebased system built previously. world recently surge interest signiﬁcant progress made variety related tasks including generation natural language descriptions images identifying images based descriptions another strand work focused incremental reference resolution model word meaning modeled classiﬁers however none prior work focuses concepts/word meanings learned adapted interactive dialogue human common setting robots home automation devices smart spaces etc. operate indeed richest resource devices could exploit adaptation time idiosyncrasies language used users. made hand-constructed synthetic dialogue examples thus lack variation many characteristic consequential phenomena observed naturalistic dialogue indeed knowledge existing data real human-human dialogues domain suitable training multimodal conversational agents perform task actively learning visual concepts human partner natural spontaneous dialogue. natural spontaneous dialogue inherently incremental thus gives rise dialogue phenomena selfother-corrections continuations unﬁnished sentences interruptions overlaps hedges pauses ﬁllers. phenomena interactionally semantically consequential contribute directly dialogue partners coordinate actions emergent semantic content conversation. also strongly mediate conversational agent might adapt partner time. example self-interruption subsequent selfcorrection well hesitations/ﬁllers aren’t simply noise used listeners guide linguistic processing similarly simultaneous speech bane dialogue system designers interruptions subsequent continuations performed deliberately speakers demonstrate strong levels understanding despite importance phenomena excluded many dialogue corpora glossed over/removed state speech recognisers google’s web-based baumann comparison). reason naturalistic spoken interaction excessively expensive timeconsuming transcribe annotate level granularity ﬁne-grained enough reﬂect strict time-linear nature phenomena. paper present dialogue data burchak corpus collected using incremental variant diet chat-tool enables character-by-character text-based interaction pairs participants circumvents transcription effort data including timing information character level automatically recorded. chat-tool designed support elicit record ﬁne-grained level dialogues resemble face-to-face setting turns constructed displayed incrementally typed; transient; potentially overlapping participants type time; editable i.e. deletion permitted sec. fig. thus able collect many important phenomena mentioned arise inherently incremental nature language processing dialogue table presented data introduce generic n-gram framework building user simulations either task-oriented non-task-oriented dialogue systems dataset others constructed using tool. apply framework train robust user model able simulate tutor’s behaviour interactively teach word meanings reinforcement learning dialogue agent. several existing corpora humanhuman spontaneous spoken dialogue switchboard british national corpus consist open unrestricted telephone conversations people speciﬁc tasks achieved. datasets contain many incremental dialogue phenomena interested shared visual scene between participants meaning cannot data explore learning perceptually grounded language. relevant maptask corpus dialogue participants maps shared. dataset allows investigation negotiation dialogue object names agreed support work language grounding. however maptask grounded word meanings taught ostensive deﬁnition case dataset. diet chat tool designed elicit conversational structures resemble face-to-face dialogue circumvents need expensive time-consuming step spoken dialogue transcription nevertheless produces data ﬁne-grained level. also includes tools creating abstract representations conversation. training dialogue strategy fundamental tasks user simulation. approaches user simulation categorised based level abstraction dialogue modeled intention-level become popular user model predicts next possible user dialogue action according dialogue history user/task goal word/utterance-level instead dialogue action user simulation also built predicting full user utterances sequence words given speciﬁc information semanticlevel whole dialogue modeled sequence user behaviors semantic representation also user simulations built multiple levels. instance jung integrated different data-driven approaches intention word levels build novel user simulation. user intent simulation generating user intention patterns two-phase data-driven domain-speciﬁc user utterance simulation proposed produce structured utterances sequences words given user intent select best using bleu score. user simulation framework present generic train user simulations word-by-word utterance-by-utterance action-by-action levels used goal-oriented non-goal-oriented domains. diet experimental toolkit custom-built java application allows participants communicate shared chat window. supports live ﬁne-grained highly local experimental manipulations ongoing human-human conversation variant supports text-based character-by-character interaction pairs participants solely data-collection everything participants type passes diet server transmits utterance clients character level displayed row/track chat window means participants type time interruptions turn overlaps utterances jumbled simulate transience speech face-to-face conversation characteristic phenomena utterances chat window fade second. furthermore like speech deletes permitted character typed cannot deleted. chat-tool thus designed support elicit record ﬁne-grained level dialogues resemble faceto-face dialogue turns constructed displayed incrementally typed; transient; potentially overlapping; editable i.e. deletion permitted. task materials learning/tutoring task given participants involves pair participants talk visual attributes sequence visual objects time. objects created based visual attribute matrix task assumed second-language learning scenario visual attribute instead standard english words assigned unknown word madelanguage e.g. sako burchak square participants allowed usual colour shape words english language. design task collect data situations robot learn meaning human visual attribute terms. setting robot learn perceptual groundings words red. however humans already know groundings collect data teaching perceptual meanings invented attribute terms whose groundings learner must discover interaction. overall goal task learner identify shape colour presented objects correctly many objects possible. tutor initially needs teach learner using presented objects. this tutor provided visual dictionary colour shape terms learner ever sees object itself. learner thus gradually learn able identify them initiative conversation tends reversed later objects learner making guesses tutor either conﬁrming correcting them. participants forty participants recruited among students research staff various disciplines heriot-watt university including native speakers non-native speakers. procedure participants pair randomly assigned experimental roles given written instructions task opportunity questions procedure. seated back-to-back room desk displaying appropriate task window chat client window asked visual objects minutes learner assessed check many colour shape words learned. participant paid participation. best performing pair also given amazon voucher prize. noted diet chattool designed elicit record conversations resemble face-toface dialogue. paper report speciﬁcally variety dialogue phenomena arise incremental nature language processing. following annotating self-corrections self-repetitions continuations loosely followed protocols purver figure shows frequently incremental phenomena occur burchak corpus. ﬁgure excludes overlaps much frequent total amounts dialogue. purpose annotation dialogue actions subsequent training user simulation reinforcement learning described below cleaned original corpus follows ﬁxed spelling mistakes repaired participants themselves; also removed snippets conversation participants misunderstood task well removing emoticons inform action inform correct attribute words object partner including statement question-answering correction e.g. this suzuli burchak this sako; fig. shows often dialogue action occurs data set; fig. shows frequencies actions learner tutor individually dialogue turn. contrast previous work assumes single action turn multiple actions turn terms learner behavior learner mostly performs single action turn. hand although majority dialogue turns tutor side also single action dialogue turns perform action. describe generic user simulation framework based n-grams building user simulation type incremental corpus. apply framework train teachbot user simulator used train interactive concept learning agent here future work. model trained cleaned version corpus. n-gram user simulation compound proposed user model probability n-gram simulation item predicted based sequence recent words previous utterance additional dialogue context parameters speciﬁc task additional dialogue conditions follows color state whether color attribute identiﬁed correctly shape state whether shape attribute identiﬁed correctly well previous context attribute currently discussion. order reduce mismatch risk simulation model able back-off smaller n-grams cannot n-grams matched current word sequence conditions. eliminate search restriction additional conditions applied nearest neighbors algorithm search n-gram matches calculating hamming distance pair n-grams. n-gram user simulation generic designed handle item prediction multiple levels predicted item assigned either full user utterance utterance level; combined sequence dialogue actions alternatively next word/lexical token. simulation n-gram model chooses next item according distribution n-grams. terms action level user utterance chosen upon distribution utterance templates collected corpus combined given dialogue actions dast. tutor simulation train level action utterance evaluated levels below. however framework used train predict fully incrementally word-by-word basis. case contain sequence words previous system utterance also words current speaker probability distribution equation induced corpus using maximum likelihood estimation count many times occurs speciﬁc combination conditions divide total number times occurs evaluate proposed user simulation based turn-level evaluation metrics evaluation done turn-byturn basis. evaluation done based cleaned corpus investigate performance user model levels utterance level action level. evaluation done comparing distribution predicted actions utterances actual distributions data. report measures accuracy kullback-leibler divergence quantify closely simulated user responses resemble real user order demonstrate burchak corpus used train evaluate prototype interactive learning agent using reinforcement learning collected data. follow previous task experiment settings compare learned rl-based agent rule-based agent best performance previous work. instead using hand-crafted dialogue examples before train agent interaction user simulation trained burchak data above. experiment setup responses burchak corpus. accuracy measures proportion times utterance dialogue sequence predicted correctly simulator given particular conditions calculate this existing combinations data values variables tried. predicted action utterance occurs data given conditions count prediction correct. table shows results user simulation utterance action levels achieves good performance. action-based user model abstract level would likely better less sparse produces variation resulting utterances. ongoing work involves using burchak train word-by-word incremental tutor simulation capable generating incremental phenomena identiﬁed earlier. ment setup including visual data-set crossvalidation method. also follow evaluation metrics provided overall performance ratio measures trade-offs cost tutor accuracy learned meanings i.e. classiﬁers ground colour shape concepts. cost ctutor measure reﬂects effort needed human tutor interacting system. skocaj point comprehensive teachable system learn autonomously possible rather involving human tutor frequently. several possible costs tutor might incur cinf refers cost tutor providing information single attribute concept cack/rej cost simple conﬁrmation rejection ccrt cost correction single concept results discussion fig. plots accuracy tutoring cost directly. gradient curve corresponds increase accuracy unit tutoring cost measure trade-off accuracy learned meanings tutoring cost. table shows example dialogue learned concept learning agent tutor simulation user model simulates tutor behaviour learning tasks. example utterance produced simulation presented data collection tool data associated dialogue simulation framework focuses visual language grounding natural incremental dialogue phenomena. tools data freely available easy use. collected human-human dialogue data visual attribute learning tasks used create generic n-gram user simulation future research development. used n-gram user model train evaluate optimized dialogue policy learns grounded word meanings human tutor incrementally time. dialogue policy optimisation learns complete dialogue control policy data contrast earlier work optimised conﬁdence thresholds dialogue control entirely rule-based. ongoing work uses data simulation framework train word-by-word incremental tutor simulation learn complete incremental dialogue policies i.e. policies choose system output lexical level deal uncertainty system addition takes visual classiﬁers’ conﬁdence levels directly features continuous space mdp. acknowledgments", "year": 2017}