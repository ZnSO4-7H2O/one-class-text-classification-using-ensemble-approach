{"title": "Programs as Black-Box Explanations", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Recent work in model-agnostic explanations of black-box machine learning has demonstrated that interpretability of complex models does not have to come at the cost of accuracy or model flexibility. However, it is not clear what kind of explanations, such as linear models, decision trees, and rule lists, are the appropriate family to consider, and different tasks and models may benefit from different kinds of explanations. Instead of picking a single family of representations, in this work we propose to use \"programs\" as model-agnostic explanations. We show that small programs can be expressive yet intuitive as explanations, and generalize over a number of existing interpretable families. We propose a prototype program induction method based on simulated annealing that approximates the local behavior of black-box classifiers around a specific prediction using random perturbations. Finally, we present preliminary application on small datasets and show that the generated explanations are intuitive and accurate for a number of classifiers.", "text": "increasing complexity machine learning systems used crucial need providing insights models doing. model-agnostic approaches baehrens ribeiro shown insights complex black-box models come cost accuracy accurate local explanations successfully provided number complex classiﬁers domains interpretable models performed competitively. however still need identify interpretable representation would suitable convey local behavior model accurate succinct manner existing model-agnostic approaches focused linear models. work interpretable machine learning hand proposed many representations designing models ranging additive models decision rules trees sets lists amongst others number open questions selecting representations model-agnostic explanations. clear single representations itself provides necessary tradeoff expressivity interpretability. further adequate studies understanding tradeoff exception) likely different representations appropriate different kinds users domains. thus clear picking single intrepretable representation choice model-agnostic representation ideal. position paper propose using programs explain local behavior black-box systems. number advantages explanations provide using single existing representation. first programming languages designed capture complex behavior using high-level syntax succinct intuitive growing group users already trained reading writing them. second programs represent turing-complete behavior; existing interpretable representation used literature written program further programs also represent arbitrary combinations multiple representations. also possible trade expressivity comprehensibility program example simple programs programmers detailed longer program accurate explanation behavior. finally potentially apply research program/software analysis evaluate various aspects complex systems automatically characterizing complexity security privacy providing programs model-agnostic explanations essentially proposing approach decompile local behavior black-box complex systems. following sections ﬁrst demonstrate program snippets provide uniﬁed comprehensible syntax commonly used interpretable representations decision trees linear models. formalize problem inducing programs local explanations black-box models describe simulated-annealing based prototype implementation. finally provide examples generated programs datasets using multiple classiﬁers demonstrating expressivity comprehensibility using programs approximate complex black-box behavior. figure example decision tree corresponding program syntax showing complexity similar level. also show versions linear model latter compact easier understand. programs manually written. section provide simple examples interpretable models currently used literature describe programmatic equivalent would look like. become apparent existing interpretable models retain readability written programs. fairly simple expressive language programs consists boolean constants operators absence/presence features input instance real valued constants algebraic operators real-valued features if-then-else conditions. language fairly expressive lack looping recursion variables still complete programming language. python syntax render programs slightly abused conserve space. commonly used interpretable representations decision trees simple decision tree figure along program figure clear program fairly intuitive representation. along decision trees sparse linear models also used number applications interpretable representations machine learning figure shows programs ﬁrst exactly captures behavior relevant features second demonstrates simpler program behavior features binary prediction true linear model evaluates positive score. respillness smoker lungcancer elif riskdepression depression elif diabetes elif headaches dizziness depression elif docvisits diabetes elif disptiredness depression else diabetes respillness smoker lungcancer risklungcancer lungcancer riskdepression pastdepression depression insurance none depression smoker diabetes riskdiabetes probinfections diabetes docvisits childobesity diabetes recently decision lists decision sets introduced comprehensible representations decision trees much powerful linear models. since often presented using pseudo code program representations language looks essentially same shown figure examples clear programs able represent different interpretable representations succinctly programming language much expressive single representation. challenges actually synthesize appropriate program i.e. make sure good approximation black-box model readable examples shown here. next section formalize problem describe prototype solution. section brieﬂy outline ideas generate programs explanations complex systems along description prototype implementation using simulated annealing. local model-agnostic explanations goal explain individual predictions complex machine learning system treating black-box manner. advantages generating model-agnostic explanations described ribeiro proposed work builds upon ideas ribeiro black-box system interested explaining speciﬁc prediction i.e. order generate explanation describes behavior around generate number random perturbations denoted induce program accurately models behavior samples interpretable user. speciﬁcally solve following optimization compatible programs loss outputs samples weighted denotes complexity program program induction challenging combinatorial optimization potentially complex surface related thread research program induction programs synthesized automatically match desired goal number different variations problem introduced depending syntax program formalism desired goals solvers ranging genetic programming mcmc also recent work using probabilistic programs identify programs mentioned possibility mansinghka using church recent implementation gaunt however unable identify off-the-shelf program inducer support arbitrary loss order identify appropriate explanation. prototype implementation implemented prototype program inducer approximately solves order generate program explanations. syntax used section i.e. boolean constants operators input features real-valued constants algebraic operators if-then-else conditions. order encapsulate complexity program number nodes expression tree otherwise i.e. implicitly considering family short programs negative weighted score loss implementation supports arbitrary function evaluated outputs combinatorial optimization solved using simulated annealing logarithmically decreasing temperature schedule proposal function randomly grows shrinks replaces nodes express tree create valid perturbed expression trees. using program induction technique described previous section present example program explanations number classiﬁers datasets repository adult hospital readmission. order evaluate whether programs accurate explanations also provide visualization decision tree models. figure adult dataset show learned tree path instance blue show education doesn’t really matter instance. shows explanations three classiﬁers particular showing explanation decision tree gets compact form. figure hospital readmission data shows learned tree path instance blue. again shows explanations three classiﬁers compact explanation tree almost correct except assumes patient alive. figures show learned decision tree datasets. also trained random forest classiﬁer logistic regression model. figures show generated program explanations datasets demonstrating programs compact readable ones decision trees accurate model well. further clear random forests much complex structure trees linear models requires complicated programs explanations however programs still make sense paper motivated need programs model-agnostic explanations programs designed intuitive humans incredibly expressive. presented prototype implementation induces programs local explanations classiﬁer ﬁtting classiﬁer’s predictions perturbations instance explained. demonstrated example explanations generated multiple datasets classiﬁers. number exciting avenues future work ideas. investigate methods inducing programs much expressive syntax including example loops variables. instead relying combinatorial optimization techniques scale applications complex domains syntax systems explore recently introduced differentiable program induction techniques neelakantan riedel finally real-world applications using user studies thoroughly evaluate interpretability utility using programs local explanations complex machine learning systems. references david baehrens timon schroeter stefan harmeling motoaki kawanabe katja hansen klaus-robert müller. explain individual classiﬁcation decisions. journal machine learning research alexander gaunt marc brockschmidt rishabh singh nate kushman pushmeet kohli jonathan taylor daniel tarlow. terpret probabilistic programming language program induction. arxiv preprint arxiv. johan huysmans karel dejaeger christophe mues vanthienen bart baesens. empirical evaluation comprehensibility decision table tree rule based predictive models. decis. support syst. april issn ./j.dss.... http//dx.doi.org/./j.dss.... cynthia rudin julie shah. bayesian case model generative approach casebased reasoning prototype classiﬁcation. ghahramani welling cortes n.d. lawrence k.q. weinberger editors advances neural information processing systems pages curran associates inc. himabindu lakkaraju stephen bach jure leskovec. interpretable decision sets joint framework description prediction. proceedings sigkdd international conference knowledge discovery data mining pages york acm. isbn ----. ./.. http//doi.acm.org/./ benjamin letham cynthia rudin tyler mccormick david madigan. interpretable classiﬁers using rules bayesian analysis building better stroke prediction model. annals applied statistics", "year": 2016}