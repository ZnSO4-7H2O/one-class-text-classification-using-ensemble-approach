{"title": "Improving Multi-Step Traffic Flow Prediction", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "In its simplest form, the traffic flow prediction problem is restricted to predicting a single time-step into the future. Multi-step traffic flow prediction extends this set-up to the case where predicting multiple time-steps into the future based on some finite history is of interest. This problem is significantly more difficult than its single-step variant and is known to suffer from degradation in predictions as the time step increases. In this paper, two approaches to improve multi-step traffic flow prediction performance in recursive and multi-output settings are introduced. In particular, a model that allows recursive prediction approaches to take into account the temporal context in term of time-step index when making predictions is introduced. In addition, a conditional generative adversarial network-based data augmentation method is proposed to improve prediction performance in the multi-output setting. The experiments on a real-world traffic flow dataset show that the two methods improve on multi-step traffic flow prediction in recursive and multi-output settings, respectively.", "text": "abstract—in simplest form trafﬁc prediction problem restricted predicting single time-step future. multi-step trafﬁc prediction extends set-up case predicting multiple time-steps future based ﬁnite history interest. problem signiﬁcantly difﬁcult single-step variant known suffer degradation predictions time step increases. paper approaches improve multi-step trafﬁc prediction performance recursive multi-output settings introduced. particular model allows recursive prediction approaches take account temporal context term time-step index making predictions introduced. addition conditional generative adversarial network-based data augmentation method proposed improve prediction performance multi-output setting. experiments real-world trafﬁc dataset show methods improve multi-step trafﬁc prediction recursive multi-output settings respectively. accurate timely trafﬁc prediction essential trafﬁc management allows travelers make betterinformed travel decisions. applications often necessary predict trafﬁc accurately also several steps ahead future. example order trafﬁc patch manage congested road develop contingency plans trafﬁc dispatch need estimate trafﬁc conditions least minutes advance. however trafﬁc prediction approaches developed singlestep prediction methods. multi-step prediction problem signiﬁcantly difﬁcult single-step variant known suffer degradation predictions farther future time-steps. therefore essential develop multi-step prediction approaches achieve accurate multi-step trafﬁc prediction. multi-step time series prediction tasks deﬁned tasks predicting next values given historical time series denote past future horizons. generally three main strategies multi-step time series prediction recursive direct multi output recursive strategy onestep model ﬁrst trained following function learned model predicts multi-step time-series trajectory repeatedly passing predictions time step input next time step. simple case history predictions length- scalars given model predicts accumulating errors shifting input distribution model predictions farther future increasingly drift ground truth trajectories moreover mismatch model optimized i.e. single-step error used i.e. multi-step prediction gives rise optimistic error estimates training weaknesses present true single-step model identiﬁed training almost always case non-linear problems. recent work showed learned model tuned learn corrections drift patterns seen training data iterative training process training repeatedly augmented additional data points form represents predictions model applied training set. model applied recursively training points generates prediction trajectories length. intuition iterative training process augmenting training samples predicted trajectories coupled next-step ground truth values model learn correct drift patterns predicted trajectories. predictions horizon. strategy multi-step predictions obtained concatenating predictions. unlike recursive strategy direct strategy suffer accumulating errors since predicted values subsequent predictions. however major weaknesses possessed strategy. first since model learned independently dependencies distant horizons modeled. second strategy requires large computational resources i.e. time space since number models depends size prediction horizon. third strategy multi-output strategy. strategy deﬁned problem ﬁnding model predicts future given historical data x]⊤. strategy requires model able produce multi-step predictions simultaneously depicted figure prediction uses actual observations rather predicted ones. therefore accumulated errors concern strategy. moreover strategy learn dependency inputs outputs well among outputs. hence strategy involves complex models recursive does directly translates slower training process requires training data avoid over-ﬁtting. cases direct multi-output strategies avoid pitfalls recursive strategy models still suffer degrading performance farther timesteps. intuitively higher uncertainty associated farther future makes difﬁcult forecast. moreover direct models suffer higher variance researchers attempted analyze theoretically empirically differences recursive direct/multi-output approaches understand would appropriate given problem results effort inconclusive. practice approaches continue suffer increasingly drifting predictions farther timesteps. recently approach counter drifts trajectories multi-step predictions called data demonstrator proposed speciﬁcally context recursive prediction models. underlying idea approach drift patterns seen trained model applied training data tune model compensate drifts. another look data augmentation technique alleviates mismatch training testing distributions. inspired this approaches enhance multi-step prediction accuracy introduced thesis. context recursive models time-step-augmented model implicitly learns associate different corrective action different future time-steps proposed. model extension approach proposed also related rectify method proposed direct model trained correct predictions recursive model time-step prediction trajectory. second approach data augmentation method enhances multi-step prediction accuracy multi-output models proposed. here conditional generative adversarial network used learn generator model mimic historical patterns corresponding future patterns seen training data. subsequently model used generate history-future pairs aggregated original training data. comprehensive trafﬁc prediction experiments involving recursive direct multi-output strategies. recursive strategy vanilla approach c-dad experimented. furthermore vanilla direct strategy modiﬁcation using recursive strategy namely hybrid method also presented. finally proposed method c-gan compared noiseaugmented training strategy well vanilla multioutput strategy. rest paper structured follows. section introduces proposed approaches. section describes experimental setup data sets used evaluate proposed models. section experimental results presented discussed. finally paper concluded observations section section methods improve multi-step timeseries prediction introduced. approach improving recursive multi-step prediction called conditional-dad followed conditional-gan-based data augmentation approach improving multi-output multi-step prediction introduced. weakness approach presented recursive prediction generally take consideration number steps predicted model far. amount correction model needs differs time-step another along multi-step prediction trajectory since deviation ground truth less acute early steps. therefore model stands beneﬁt information current time-step along prediction trajectory. particular amount correction model needs affected number timesteps passed model used prediction input next time-step. input augmented representation current time-step proposed. length- scalar history single-step prediction model modiﬁed accept augmented vector vn]⊤ prediction time-step representation presentation experiments used. illustration shown fig. x—time-series points predict recursively—procedure takes input sequence points integer single-step prediction model outputs length-n recursive predictions applied data points output form indicates recursion index. predict recursively aug—similar procedure predict recursively except model applied timestep-augmented inputs xaug form n]⊤. —number recursive time steps use. epochs—number iterations train model. build training form initialize single-step-prediction base model mbase framework estimating distribution adversarial manner. simultaneously trains models namely generative model discriminative model discriminative model trained maximize probability assigning appropriate labels samples coming training data generative model. simultaneously generative model trained minimize log) random sample input noise distribution. playing two-player minimax game value function given follows extension namely conditional generative adversarial nets proposed extension conditioned extra information kind auxiliary information class labels. research applying c-gan discrete labels text images work c-gan trained generate inputs given actual labels generative discriminative models actual labels concatenated noise. idea illustrated figure label generated inputs pair input depending current time-step along prediction trajectory hence allows model learn different corrections different time-steps. setup differs parameterized recursive prediction approach different parameters learned time-step future. training c-dad model follows similar process meta-algorithm proposed difference addition time-step representation. algorithm describes process. short time-step-augmented training data generated forward-passing original training data base model. next c-dad model iteratively trained augmented training data generated every epoch passing original data previous c-dad model. furthermore ﬁnal model selected based performances models validation data set. applications recursive models perform well compared approaches multi-output models nonetheless performance multi-output models suffers degradation prediction time-step increases. section c-gan-based data augmentation approach improve multi-output multi-step time series prediction introduced. multi-output strategy requires model able produce multi-step predictions simultaneously. prediction uses actual observations rather predicted ones. therefore accumulated errors concern strategy. moreover strategy learn dependency inputs outputs well among outputs. hence strategy involves complex models recursive does directly translates slower training process requires training data avoid over-ﬁtting. recursive strategy data augmentation method applied improve multi-step time series prediction. simple augment data contaminate features noise pair actual labels. method increase multi-step prediction performance noise carefully chosen. poor choice noise however signiﬁcantly degrade prediction performance. work alternative method i.e. generative adversarial network augment data learning distribution input conditioned output proposed. ﬁrst experiments three recursive approaches applied dataset. approach uses similar base predictor deep neural network fair comparisons conﬁgurations approaches terms number hidden layers number hidden units activation function tricks used training kept identical. main difference c-dad approach input augmented time-step information means extra weights associated input. base conﬁgured hidden layers layer contains hidden units activation function selected relu. since regression problem linear activation used output layer loss function. furthermore data min-max normalized moreover avoid model overﬁtting easily drop-out regularizers rate equals implemented layer. addition adam algorithm used gradient-based optimization. summary performance recursive approaches seen table table shows that respect vanilla recursive approach c-dad approaches successfully improved overall mae. shows reusing prediction results input data together original training data leads improvement performances. furthermore augmenting information time step model i.e. c-dad approach improve performances times almost times seen table. performances achieved iterations c-dad approaches respectively. figure depicts error occurs time step. shows that early step c-dad approaches perform signiﬁcantly better vanilla recursive does. however time step equals approach worse vanilla recursive c-dad approach able maintain performances last step. case c-dad approaches able maintain performances time steps. results trafﬁc predictions recursive approaches seen figure ﬁgure presents trafﬁc predictions time step time step approaches produce similar predictions close actual trafﬁc ﬂow. however time cdad approach showing acceptable prediction. indeed using method inﬁnite amount data enhance predictor performance generated. addition using generated data need special treatments training process. done standard multi-output training without iterative training processes. trafﬁc flow data downloaded caltrans performance measurements systems original trafﬁc sampled every seconds. data aggregated -min duration pems. highway capacity manual recommends aggregate data -min duration. collected trafﬁc data freeway january december data january -from august training september -december validation rest testing. three sets experiments conducted using data set. ﬁrst vanilla recursive strategy c-dad implemented dataset. main goal experiments investigate strategy performs better recursive setting. next vanilla direct strategy hybrid approach applied dataset. subsequently proposed c-gan data augmentation applied compared vanilla multi-output strategy noise data augmentation model. number time steps multi-step prediction chosen furthermore performances best models strategy compared analyzed. performance experiments evaluated using mean squared error mean absolute error illustrate superiority proposed methods percentages improvement errors respect baselines computed. augmentation time-step information provides extra dimension model helps model understand state prediction learn better. concluded adding extra dimension worth effort. second experiments direct approaches namely vanilla direct hybrid approaches tested. similar base predictors previous experiments used. number models trained approach depends size future horizon. since number time steps number models approach main difference vanilla direct hybrid approaches size input. number input hybrid increases time step increases number input vanilla direct static. direct approach smaller errors vanilla recursive does. expected since vanilla direct approach accumulating error problem exist. timestep prediction handled independently model. furthermore hybrid approach improves vanilla direct performance considerably. however compared best performance recursive approach c-dad still shown superiority. attributed accumulating errors previous predictions used inputs subsequent models. figure seen errors ﬁrst step identical. possible models step practically since previous predictions utilized yet. overall hybrid approach improves prediction errors time steps. however closer look suggests hybrid model performances degrade time step increases. indeed accumulating errors dominate input model. type approach performance next step highly depends previous model. figure shows that initially hybrid approach produces acceptable prediction case last step. reciprocal errors shown figure almost improvement achieved last step. comparison c-dad method computationally inefﬁcient since requires several models multi-step predictions. times less computational efforts c-dad approaches perform considerably well hybrid method does. last experiments involves three multi-output approaches vanilla multi noise-augmented c-gan approaches. base conﬁgured hidden layers layer contains hidden units activation function selected relu. three approaches identical models including output layer size. noise-augmented approach data contaminated gaussian noise mean equals variance equals several trials variance found produce best performance validation data set. meanwhile discriminative generative models c-gan similar conﬁguration base dnn. important aspect training c-gan learning rates discriminative generative models. usually discriminative model conﬁgured learn faster generative model. discriminative loss stays makes stays ahead discriminating strange representations generative model. evolution losses dc-gan depicted figure seen losses discriminative generative models converge. furthermore c-gan accuracy converges means discriminator able distinguish data generated generative model actual data. therefore concluded generative model acts distribution mimics training data. overall performances multi-output trafﬁc prediction approaches summarized table iii. lowest using vanilla approaches obtained multi-output approach. attributed fact multi-output setting accumulating errors problem exist dependencies time steps modeled. noise-augmented approach poor choice noise signiﬁcantly degrade prediction performances. however experiment noise successfully chosen evident prediction performances improvements. furthermore best improvement achieved original data augmented generated generative model. therefore c-gan seen intelligent data augmentation. predictions time steps. furthermore figure seen performances vanilla multi noise-augmented approaches poor ﬁrst time step. indeed learning several time-steps simultaneously difﬁcult learning step done recursive direct approaches. however proposed cgan approach able signiﬁcantly improve early time step predictions overall performances. finally comparison c-dad hybrid c-gan approaches depicted figure ﬁgure shows c-gan approach shown superiority term time steps. however term c-dad approach better later steps compared c-gan approach. indeed based prediction plots figure figure seen c-dad approach produce better trafﬁc prediction c-gan does. suggested natural quite often misleading good indicator average model performance function characteristics errors rather one. addition demonstrates appropriate represent model performance error distribution expected gaussian. paper proposed methods improve multi-step trafﬁc predictions c-dad c-gan approaches. ﬁrst approach developed using recursive strategy inspired previous work approach augments information current time step follows similar training process meta-algorithm proposed second model developed using multi-output strategy utilizes ability mimicking data distribution. c-gan model developed generate historical data conditioned future data. original data enriched inﬁnite amount historical-future pairs data training purposes. experiments show proposed approaches able improve multi-step trafﬁc predictions relative vanilla approaches. moreover term c-gan approach performs better approaches. however latter steps c-dad lower experimented approaches. compared c-dad training c-gan approach fairly simpler since require iterative training data generated. however applications efﬁcient recursive model video sequence prediction application recursive prediction beneﬁt improvement offered c-dad approach. taieb bontempi atiya sorjamaa review comparison strategies multi-step ahead time series forecasting based forecasting competition expert systems applications vol. goodfellow pouget-abadie mirza warde-farley ozair courville bengio generative adversarial nets advances neural information processing systems denton chintala fergus deep generative image models using laplacian pyramid adversarial networks advances neural information processing systems", "year": 2018}