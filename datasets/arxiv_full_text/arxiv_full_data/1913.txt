{"title": "Write a Classifier: Predicting Visual Classifiers from Unstructured Text", "tag": ["cs.CV", "cs.CL", "cs.LG"], "abstract": "People typically learn through exposure to visual concepts associated with linguistic descriptions. For instance, teaching visual object categories to children is often accompanied by descriptions in text or speech. In a machine learning context, these observations motivates us to ask whether this learning process could be computationally modeled to learn visual classifiers. More specifically, the main question of this work is how to utilize purely textual description of visual classes with no training images, to learn explicit visual classifiers for them. We propose and investigate two baseline formulations, based on regression and domain transfer, that predict a linear classifier. Then, we propose a new constrained optimization formulation that combines a regression function and a knowledge transfer function with additional constraints to predict the parameters of a linear classifier. We also propose a generic kernelized models where a kernel classifier is predicted in the form defined by the representer theorem. The kernelized models allow defining and utilizing any two RKHS (Reproducing Kernel Hilbert Space) kernel functions in the visual space and text space, respectively. We finally propose a kernel function between unstructured text descriptions that builds on distributional semantics, which shows an advantage in our setting and could be useful for other applications. We applied all the studied models to predict visual classifiers on two fine-grained and challenging categorization datasets (CU Birds and Flower Datasets), and the results indicate successful predictions of our final model over several baselines that we designed.", "text": "classes) e.g. approaches exploit similarity seen classes unseen ones describe unseen classes terms learned vocabulary semantic visual attributes. contrast lack reasonably sized training sets large number real world categories subordinate categories abundant textual descriptions categories. comes form dictionary entries encyclopedia articles various online resources. example possible several good descriptions bobolink encyclopedias birds images available bird online. main question address paper purely textual description categories training images learn visual classiﬁers categories. words zero-shot learning object categories description unseen categories comes form typical text encyclopedia entry; fig. explicitly address question automatically decide information transfer classes without need human intervention. contrast related work beyond simple tags image captions apply standard natural language processing techniques typical text learn visual classiﬁers. fine-grained categorization refers classiﬁcation highly similar objects. similarity natural intrinsic characteristics subordinates category objects artiﬁcial subcategories object class diverse applications ﬁne-grained categories range classiﬁcation natural species retrieval different types commercial products problem learn expert different species birds teacher give sample images species class labels; teacher tell discriminative visual non-visual features species similarities abstract—people typically learn exposure visual concepts associated linguistic descriptions. instance teaching visual object categories children often accompanied descriptions text speech. machine learning context observations motivates whether learning process could computationally modeled learn visual classiﬁers. speciﬁcally main question work utilize purely textual description visual classes training images learn explicit visual classiﬁers them. propose investigate baseline formulations based regression domain transfer predict linear classiﬁer. then propose constrained optimization formulation combines regression function knowledge transfer function additional constraints predict parameters linear classiﬁer. also propose generic kernelized models kernel classiﬁer predicted form deﬁned representer theorem. kernelized models allow deﬁning utilizing rkhs kernel functions visual space text space respectively. ﬁnally propose kernel function unstructured text descriptions builds distributional semantics shows advantage setting could useful applications. applied studied models predict visual classiﬁers ﬁne-grained challenging categorization datasets results indicate successful predictions ﬁnal model several baselines designed. main challenges scaling object recognition systems lack annotated images real-world categories. typically images available training classiﬁers categories. reﬂected number images category available training object categorization datasets which pointed shows zipf distribution. problem lack training images becomes even severe target recognition problems within general category i.e. ﬁne-grained categorization example building classiﬁers different bird species ﬂower types largest bird image datasets contain hundred categories however descriptions living birds available textual form researchers exploit shared knowledge categories target scalability issue. motivated many researchers looked approaches learn visual classiﬁers examples e.g. even motivated recent works zero-shot learning visual categories training images available test categories small world blackbird member genus dolichonyx. description adults long short ﬁnch-like bills. weigh adult males mostly black although display creamy napes white scapulars lower backs rumps. adult females mostly light brown although coloring includes black streaks back ﬂanks dark stripes head; wings tails darker. collective name group bobolinks chain. distribution movement birds migrate argentina bolivia paraguay. bird tracked ﬂying course year day. often migrate ﬂocks feeding cultivated grains rice leads considered pest farmers areas. although bobolinks migrate long distances rarely sighted europe-like many vagrants americas overwhelming majority records british isles. fall bobolinks gather large numbers south american rice ﬁelds inclined grain. earned name ricebird parts. however called something entirely different jamaica collected food pass migration. fig. example wikipedia article painted bunting example image. bottom proposed learning setting. category give textual description training images. goal able predict classiﬁer category based narrative differences species hierarchical relations species many aspects. learning experience takes place read book page learn different species birds; example fig. shows example narrative bobolink. typically narrative tells bird’s taxonomy highlights discriminative features bird discusses similarities differences species well within-species variations narrative might eventually show example images often selected wisely illustrate certain visual aspects might hard explain narrative. learning strategy using textual narrative images makes learning effective without huge number images typical visual learning algorithm would need learn class boundaries. however narrative speciﬁc species contain visually relevant information also gives abundant information species’s habitat diet mating habits etc. relevant visual identiﬁcation. sense information might textual clutter task. problem takes place images. image effective highlighting important feature learning many images might visual clutter makes uses learning effective. thus picture worth thousand words always abundant number pictures might effective learning. similarly text paragraph worth thousand pictures learning concept always large amounts text might necessarily effective. computer vision community earlier version work learn image corpus textual corpus however form image-caption pairs instead alignment corpora level category. particular address problem formulating visual classiﬁer prediction function predicts classiﬁer unseen visual class given text description; ﬁgure part work published extend work study formulations solve problem sec. addition propose kernel method explicitly predict kernel classiﬁer form deﬁned representer theorem kernelized prediction advantage opens door using kind side information classes long kernels used side information representation. side information form textual parse trees grammar visual representations concepts ontologies form. focus unstructured text descriptions. image features also need vectorized format. kernelized classiﬁers also facilitate combining different types features multikernel learning paradigm fusion different features effectively achieved. beyond introduction related work sections paper structured follows section details problem deﬁnition relation regression knowledge transfer models. section shows different formulations studied predict linear visual classiﬁer; ﬁgure section presents kernelized version approach predicts kernel classiﬁer form deﬁned representer theorem section presents proposed distributional semantic kernel unstructured text description applicable kernel formulation useful applications well. section viii presents experiments flower dataset caltech-ucsd dataset linear kernel classiﬁer predictions. zero/few-shot learning motivated practical need learn visual classiﬁers rare categories researchers explored approaches learning single image even images recognizing object instances previously unseen test categories leveraging knowledge common attributes shared parts. typically intermediate semantic layer introduced enable sharing knowledge classes facilitate describing knowledge novel unseen classes e.g. instance given adequately labeled training data learn classiﬁers attributes occurring training object categories. classiﬁers used recognize attributes object instances novel test categories. recognition proceed basis learned attributes attribute-based knowledge transfer approaches intermediate visual attribute representation enable describing unseen object categories. typically attributes manually deﬁned humans describe shape color surface material e.g. furry striped etc. therefore unseen category speciﬁed terms used vocabulary attributes. rohrbach investigated extracting useful attributes large text corpora. approach introduced interactively deﬁning vocabulary attributes human understandable visually discriminative. huang relaxed attribute independence assumption modeling correlation attributes achieve better zero shot performance opposed prior models. similar setting zero-shot learning classes training data predict classiﬁers classes training data contrast attributes based method work explicit attributes. description category purely textual process completely automatic without human annotation beyond class labels. visual knowledge transfer work seen context knowledge sharing inductive transfer. general knowledge transfer aims enhancing recognition exploiting shared knowledge classes. existing research focused knowledge sharing within visual domain only e.g. exporting semantic knowledge level category similarities hierarchies e.g. beyond state-of-the-art explore cross-domain knowledge sharing transfer. explore knowledge visual textual domains used learn across-domain correlation facilitates prediction visual classiﬁers textual description. language vision relation linguistic semantic representations visual recognition explored. example shown strong correlation semantic similarity classes based wordnet confusion classes. linguistic semantics terms nouns wordnet used collecting large-scale image datasets imagenet tiny images also shown hierarchies based wordnet useful learning visual classiﬁers e.g. earliest work learning images text corpora work barnard showed learning joint distribution words visual elements facilitates clustering images semantic generating illustrative images caption generating annotations novel images. increasing recent interest intersection computer vision natural language processing researches focus generating textual description images videos e.g. includes generating sentences objects actions attributes spatial relation objects contextual information images scene information etc. based success sequence sequence training neural nets machine translation impressive works recently proposed image captioning contrast work different fundamental ways. terms goal target generating textual description images instead target predicting classiﬁers text zero-shot setting. terms learning setting textual descriptions level category come form imagecaption pairs typical datasets used text generation images e.g. several recent works studies unannotated text images. word embedding language models adopted represent class names vectors require training using text-corpus. goal embed images language space perform classiﬁcation. similar multimodal approach adopted multimedia event detection videos instead object classiﬁcation. several differences works method. first limitation adopted language model produces vector word causes problems word multiple meanings. second methods assumes class represented few-words hence represent class text description typically contains multiple paragraphs setting. third goal different text description explicit classiﬁer visual domain i.e.the opposite direction goal. fourth models support non-linear classiﬁcation supported kernelized version proposed work. finally focus ﬁne-grained recognition challenging task. illustrates learning setting. information problem comes different domains visual domain textual domain denoted respectively. similar traditional visual learning problems given training data form test image image training data b]t. learned class class label test image predicted similar linear case. also shows related linear classiﬁer feature explicitly deﬁned given deﬁnition hence goal kernel classiﬁer prediction predict instead since sufﬁcient deﬁne text description unseen class given clear could learned classes training data since examples seen classes; denote kernel-classiﬁer parameters seen classes {βj}nsc∀j. however obvious predict unseen class given text description similar linear classiﬁer prediction main notion text description associated unseen class training data directly predict unseen kernel-classiﬁer parameters. words kernel classiﬁer parameters unseen class function text description image training data text training data {tj} nsc; i.e. could used classify points belong unseen class follows one-vs-all setting multi-class prediction case table contrast linear classiﬁer prediction need explicitly represent image text description features denoted bold symbols previous section. rather must deﬁned leads general classiﬁers. introduce possible frameworks problem discuss potential limitations them. background section focus predicting linear classiﬁers simplicity motivates evaluated linear classiﬁer formulations follow straightforward solve problem pose regression problem goal textual data learned classiﬁers {}j=···nsc learn regression function textual feature domain visual classiﬁer domain i.e. function rdv. question regression model would suitable image {··· nsc} class label. denote number classes available training indicates seen classes. typically done visual classiﬁcation setting learn binary one-vs-all classiﬁers classes. goal able predict classiﬁer category based learned classes textual description category. order achieve that learning process also include textual description seen classes depending domain might couple little textual description class. denote textual training data class paper assume dealing extreme case textual description available class makes problem even challenging. simplicity text description class denoted however formulation propose paper directly applies case multiple textual descriptions class. similar visual domain textual descriptions feature extraction process. denote linear extracted textual feature rdt}j=···nsc features text description given textual description unseen category linear feature vector representation problem deﬁned predicting one-vs-all linear classiﬁer parameters directly used classify test image according generalized representer theorem minimizer regularized empirical risk function rkhs could represented linear combination kernels evaluated training set. adopting representer theorem classiﬁcation risk function deﬁne kernel-classiﬁer visual class follows typical regression model ridge regression gaussian process regression learns regressor dimension output domain separately i.e. functions clearly capture correlation visual classiﬁer dimensions. instead structured prediction regressor would suitable since would learn correlation input output domain. however even structured prediction model learn correlation textual visual domain information available input-output pairs visual domain information encapsulated prelearned classiﬁers prediction access original data visual domain. instead need directly learn correlation visual textual domain prediction. another fundamental problem regressor would face sparsity data; data points textual description-classiﬁer pairs typically number classes small compared dimension classiﬁer space dv). setting like that regression bound suffer ﬁtting problem. model best explained terms regression predictive variance increases regions input space data points. result poor prediction classiﬁers regions. alternative formulation pose problem domain visual domain. adaptation textual computer vision context domain adaptation work focused transferring categories learned source domain given distribution images target domain different distribution e.g. images videos different sources need approach learns correlation textual domain features visual domain features uses correlation predict visual classiﬁer given textual features. particular approach learning cross domain transformation introduced. work regularized asymmetric transformation points domains learned. approach applied transfer learned categories different data distributions visual domain. particular attractive characteristic domain adaptation models source target domains share feature spaces dimensionality. totally different setting studied inspired formulate zero-shot learning problem domain transfer problem. achieved learning linear transfer function transformation matrix learned optimizing suitable regularizer constraints form ttwx belong class ttwx otherwise. model parameters. transfer function acts compatibility function textual features visual features gives high values class value different classes. hard transfer function classiﬁer. given textual feature test image represented classiﬁcation decision obtained tt∗wx decision boundary hence desired predicted classiﬁer obtained tt∗w however since learning done seen classes only clear predicted classiﬁer behave unseen classes. guarantee classiﬁer seen data side unseen class side hyperplane. proposed formulations section aims predicting linear hyperplane parameter one-vs-all classiﬁer unseen class given textual description encoded feature vector knowledge learned training phase seen classes. start deﬁning learning components used formulations described section following subsections show different approach predict linear classiﬁer iii-a. ﬁnal approach achieves best performance combines regression domain transfer additional constraints. compare alternative formulations experiments. hyper-parameter selection detailed supplementary materials approaches. different regressors used however need regressor provide probabilistic estimate preg). reasons explained also need structure prediction approach able predict dimensions classiﬁers together. reasons twin gaussian process encodes relations inputs structured outputs using gaussian process priors. achieved minimizing kullback-leibler divergence marginal outputs observations estimated regressor output learn domain transfer function adapted approach follows. textual feature data matrix visual feature data matrix feature vector amended notice amending feature vectors essential formulation since need classiﬁer. need solve following optimization problem ci’s loss functions constraints matrix regularizer. shown condition regularizer optimal form xxt. computed minimizing following minimization problem cp)) class pairs index otherwise one-hot vector zeros except element work used used frobenius norm regularizer. energy minimized using second order bfgs quasi-newton optimizer. computed computed using transformation above. finally tt∗w simplifying gaussian kernel respectively. kc]t. regularization parameters avoid overﬁtting. optimization problem solved using second order bfgs quasi-newton optimizer cubic polynomial line search optimal step size selection case classiﬁer dimensions predicted jointly. hence preg deﬁned normal distribution. reason provide predictive variance unlike gaussian process regression. however advantage handling dependency dimensions classiﬁers given textual features similarity function hyperplanes e.g. product used work constant weight weight soft constraints existing images negative examples call class methods constrained gpr/tgp since initially predicted tgp. training ﬁrstly learn {βj} svm-kernel classiﬁers based training data deﬁned visual kernel. then learn kernel domain transfer function transfer text description information kernel-classiﬁer parameters domain. call domain transfer function form g]t; matrix transforms kernel classiﬁer parameters class represents. learn {tj} gtψk correspond class gtψk otherwise. controls similarity lowerbound correspond class controls similarity upper-bound belong different classes. setting term classiﬁer parameter class training data. therefore introduce penalization constraints minimization function distant corresponds class classiﬁes. model kernel domain transfer function follows where symmetric matrix column equal nsc; matrix column equal ck’s loss functions constraints deﬁned class pairs index otherwise vector zeros except index vector zeros except index leads class pairs index u)))otherwise number pairs different classes similar pairs respectively. finally used frobenius norm regularizer objective function controls involvement constraints term multiplied controls importance; call clu. while trained classiﬁers penalty captured term multiplied call important observation reaches zero g−bt since could rewritten −·maxt correspond class maxt otherwise. another approach used minimize alternating projection using bregman algorithm updated single constraint every iteration. illustrates ﬁnal framework combines regression domain transfer additional constraints. formulation combines three learning components described beginning section. components contains partial knowledge problem. question combine knowledge predict classiﬁer given textual description. classiﬁer consistent seen classes. classiﬁer seen instances side hyperplane consistent learned domain transfer function. leads following constrained optimization problem ﬁrst term regularizer classiﬁer second term enforces predicted classiﬁer high correlation tt∗w; learnt third term favors classiﬁer high probability given prediction regressor. constraints −ctxi enforce seen data instances negative side predicted classiﬁer hyperplane missclassiﬁcation allowed slack variables constraint t∗twc enforces correlation predicted classiﬁer t∗tw less enforce minimum correlation text visual features. solving quadratic program according deﬁnition preg quadratic term form reduce −ct˜c) since ˜ct˜c constant already included regularizer equation setting product better similarity measure hyperplanes. hence −ct˜c minimized. given reduces quadratic program linear constraints. tried different quadratic solvers however cplex solver gives best performance speed optimization problem. propose distributional semantic kernel deﬁne similarity text descriptions domain. kernel applicable kernel classiﬁer predictors presented could used applications. start distributional semantic models represent semantic manifold function maps word vector main assumption behind class distributional semantic model similar words share similar context. mathematically speaking models learn vector word maximized training corpus context window size. hence similarity high co-occurred context size training text-corpus. normalize word vectors length norm i.e. assume text description represent triplets word occurs frequency corresponding word vector drop stop words deﬁne vec]t vector term frequencies matrix corresponding term vectors. given text descriptions contain terms respectively. compute finally deﬁned advantage similarity measure captures semantically related terms. standard term frequency similarity could thought special case kernel vectvec otherwise i.e. different terms orthogonal. however case word vectors learnt distributional semantic model makes semantically related terms higher product tvec). datasets features datasets evaluated methods using large datasets widely used ﬁne-grained categorization birds dataset oxford flower dataset augmented datasets textual description category. birds image dataset created based birds corresponding wikipedia article developed tool automatically extract wikipedia articles given class name. tool succeeded automatically generate articles remaining articles extracted manually wikipedia. mismatches happen article title different synonym bird class. hand flower dataset tool managed generate classes wikipedia since flower classes necessarily corresponding wikipedia articles. study ways infer ﬁnal kernel-classiﬁer prediction. direct kernel domain transfer prediction denoted dt-kernel one-class adjusted prediction denoted svm-dt kernel. hyper-parameter selection attached supplementary materials. source code available https//sites.google.com/site/mhelhoseiny/ computer-vision-projects/write kernel classiﬁer. direct domain transfer prediction construction classiﬁer unseen class directly computed trained domain transfer model follows one-class-svm adjusted prediction order increase separability seen classes adopted inverse idea class kernel-svm whose main idea build conﬁdence function takes positive examples class. setting opposite scenario; seen examples negative examples unseen class. order introduce proposed adjustment method start presenting one-class objective function. lagrangian dual one-class written objective function one-negative class inspires idea adjust kernel-classiﬁer parameters increase separability unseen kernel-classiﬁer points seen classes leads following objective function ˆβdt ˆβdt ﬁrst elements ˜βdt vector ones. objective function pushes classiﬁer unseen class highly correlated domain transfer prediction kernel classiﬁer putting points seen classes negative examples. hard quadratic program could solved using quadratic solver. worth mention linear classiﬁer prediction predicts classiﬁers solving optimization problem size variables linearclassiﬁer parameters slack variables. contrast kernelized objective function solves quadratic program variables predicts kernel-classiﬁer instead fewer parameters. using high-dimensional features affect optimization complexity. remaining articles generated manually class wikipedia plant database plant encyclopedia articles collected textual descriptions flowers birds datasets available https//sites.google.com/ site/mhelhoseiny/-elhoseiny-sup.zip textual feature extraction textual features extracted phases. ﬁrst phase indexing phase generates textual features tf-idf conﬁguration tf-idf measure important word text corpus. tf-idf value increases proportionally number times word appears document offset frequency word corpus helps control fact words generally common others. used normalized frequency term given textual description inverse document frequency measure whether term common; work used standard logarithmic second phase dimensionality reduction step clustered latent semantic indexing algorithm used. clsi low-rank approximation approach dimensionality reduction used document retrieval. flower dataset tf-idf features clsi ﬁnal textual features birds dataset tf-idf features clsi ﬁnal textual features visual features extraction used classemes features visual feature experiments provide intermediate semantic representation input image. classemes features output classiﬁers corresponding category labels drawn appropriate term list deﬁned related textual features. category {··· training images gathered issuing query category label image search engine. coarse feature descriptors extracted subset feature dimensions selected one-versus-all classiﬁer trained category. classiﬁer output real-valued implies similar class given image feature vector used represent classemes vector kernel classiﬁer prediction evaluated features also additional representations text descriptions images. text performed experiments proposed distributional semantic kernel using recurrent nets. images evaluated features combined kernel different features learnt details discussed later subsection viii-c. experimental results linear classiﬁer prediction evaluation methodology following zero-shot learning literature evaluated performance unseen classiﬁer one-vs-all setting test images unseen classes considered positives test images seen classes considered negatives. computed curve report area curve comparative measure different approaches. zeroshot learning setting test data seen classes typically large compared unseen classes. makes measures accuracy useless since high accuracy obtained even unseen class test data classiﬁed incorrectly; hence used curves independent problem. training/testing splits super category unseen split). zeroshot setting split flower datasets five-fold cross validation classes performed fold classes considered seen classes used training classes considered unseen classes classiﬁers predicted tested. within class-folds data seen classes split training test sets. hyperparameters approach selected another ﬁve-fold cross validation within class-folds made seen-unseen folds used experiments available https//sites.google.com/site/ mhelhoseiny/computer-vision-projects/write classiﬁer. contrast sc-seen split discussed next split designed bird subspecies belong super-category either belong either training test split. super category seen split split dataset also evaluate work another zero-shot learning split dataset used recent works investigated difference training/testing split found unseen/test classes split deﬁned actually seen some-perspective. particular found common feature split group related subordinate categories majority group subspecies used training left unseen. instance subspecies albatrosses included among training classes except testing test time zero-shot learning model asked discriminate black_footed_albatross classes related albatross relatively easier given model seen already albatrosses training. hence name split super category seen split. instead super category unseen split whole albatrosses unseen subordinate categories completely unseen test time model asked discriminate different types albatrosses text. make sc-unseen split much difﬁcult sc-seen split. dataset based version sc-unseen split wikipedia articles order show results comparison recently published work applied methods sc-seen split discuss ﬁndings viii-f). fig. linear left middle curves best predicted classes ﬁnal formulation bird flower datasets respectively right improvement three baselines flower dataset improvement sorted increasing order baseline separately baselines since work ﬁrst predict classiﬁers based pure textual description reported results compare against. however comparisons designed three state-of-the-art baselines compare against designed inline argument iii. namely used gaussian process regressor twin gaussian process structured regression method domain transfer baselines particular importance since incorporated formulation. noted also evaluate alternative formulations proposing problem none used context before. results table shows average aucs ﬁnal linear approach comparison three baselines datasets. performed poorly classes data sets expected since structure prediction approach. formulation outperformed ﬂower dataset slightly underperformed bird dataset. proposed approach outperformed baselines datasets signiﬁcant improvement ﬂower dataset. also clear performance improved bird dataset since classes shows curves approach best predicted unseen classes birds dataset left flower dataset middle. shows classes flower dataset. right shows improvement class improvement calculated baseline table shows percentage classes approach makes prediction improvement three baselines. table shows classes flower dataset approach made best average improvement. table shows cases performed poorly formulation based signiﬁcant improvement. shows formulation simply combine best approaches signiﬁcantly improve prediction performance. evaluate effect constraints objective function removed constraints enforces seen examples negative side predicted classiﬁer hyperplane evaluated approach. result ﬂower dataset reduced average auc=. compared auc=. constraints. similarly evaluated effect constraint tt∗wc result reduced average auc=. compared auc=. constraint. illustrates importance constraint formulation. constrained baselines table also shows average aucs constrained baseline formulations namely constrained regression constrained regression constrained section previously discussed performed poorly while expected performed better. adding constraints gpr/tgp improved performance. combining regression gave signiﬁcantly better results classes approaches individually perform poorly seen table performed additional experiment computed using constrained domain transfer then unseen classiﬁer predicted using equation performs worse. indicates adding constraints align seen classiﬁers hurts learnt domain transfer function unseen classes. conclusion ﬁnal formulation combines additional constraints performs best birds flower datasets. effect limited since trained sparse points reﬂected setting respectively hyper parameter tuning validation set. additional evaluation metrics addition discussed previous section report additional metrics evaluating comparing kernel classiﬁer prediction linear classiﬁer prediction detailed follows |nsc| |nsc recall metric check learned classiﬁers seen classes confuse predicted classiﬁers involved multi-class classiﬁcation problem classes. predict label maximum conﬁdence image label ground truth unseen class seen class labels. compute recall setting. metric computed predicted unseen classiﬁer average reported. multiclass accuracy unseen classes setting evaluate performance unseen classiﬁers others. firstly classiﬁers unseen categories predicted. then predict label maximum conﬁdence test image unseen label class labels text descriptions. comparisons linear classiﬁer prediction compare kernel methods linear prediction discussed earlier predicts linear classiﬁer textual descriptions goal check whether predicted kernelized classiﬁer outperforms predicted linear classiﬁer. used features visual domain textual domains detailed subsection viii-a. dt-kernel svm-dt-kernel respectively. compared linear classiﬁer prediction approach denoted linear classiﬁer). also compared linear direct domain transfer denoted dt-linear). kernel approaches used gaussian rbf-kernel similarity measure spaces exp||)). recall metric recall svm-dt kernel approach birds dataset flower dataset birds flower best linear classiﬁer prediction indicates predicted classiﬁer less confused classiﬁers seen categories compared linear classiﬁer prediction; table metric worth mention multiclass accuracy trained seen classiﬁers using classeme features flower dataset birds dataset respectively. table shows average metric three seen/unseen splits flower dataset split birds dataset respectively. furthermore relative improvements svm-dt-kernel approach reported baselines. flower dataset interesting approach achieved showing improvement random guess predicting unseen classiﬁers using textual features privileged information important mention achieved also splits similarly birds dataset achieved text features random guess performance addition unseen class performance report performance seen classes upper bound zero-shot learning flower birds datasets proposed approach performs marginally similar baselines perspective. however clear improvement recall metrics. results show advantage predicting classiﬁers kernel space. furthermore table shows svm-dt-kernel approach outperforms dt-kernel model. indicates advantage class separation adjusted svm-dt-kernel model. multiple kernel learning experiment experiment shows added value proposing kernelized zero-shot learning approach. conducted experiment ﬁnal kernel visual domain produced multiple kernel learning images extracted kernel descriptors birds dataset. kernel descriptors provide principled turn pixel attribute patch-level features able generate rich features various recognition cues. speciﬁcally used four types kernels introduced follows gradient match kernels captures image variation based predeﬁned kernels image gradients. color match kernel describes patch appearance using kernels normalized regular images intensity grey images. kernels capture image variation visual apperances. modeling local shape local binary pattern kernels applied. computed kernel descriptors local image patches ﬁxed size sampled densely grid step size spatial pyramid setting four layers. dense features vectorized using codebooks size process ended dimensional feature image extracted four types descriptors compute kernel matrix type separately. learn bandwidth parameters kernel cross validation seen classes. wiki) weight assigned kernel. learn weights applying bucak’s multiple kernel learning algorithm then applied approach mkl-kernel used visual domain kernel text domain similar previous experiments. compare kernel prediction approach linear prediction approach setting concatenated kernel descriptors form dimensional feature vector visual domain. highlighted kernel approach section linear prediction approach solves quadratic program variables unseen class. large dimensionality data tractable. make setting applicable reduced dimensionality feature vector using pca. highlights beneﬁt kernelized approach since quadratic program depend dimensionality feature space. table shows kernel prediction approaches setting linear prediction. results show beneﬁt zero-shot kernel prediction arbitrary kernel could used improve performance. experiment elaborates performance kernel approach different representations text visual domains experiment extracted convolutional neureal network image features visual domain. used caffe implementation then extracted sixth activation feature since found works best standard classiﬁcation setting. found consistent results different layers. using tfidf feature text description features images achieved linear version kernel text images. improved performance using proposed distributional semantic kernel text domain kernel images. experiment used distributional semantic model trained googlenews corpus resulting vocabulary size million words word vectors dimensions. experiment shows value kernelized approach proposed kernel vii. also applied zero shot learning approach lowest performance settings; table vii. attributes experiment goal attribute prediction. however interesting behavior method space deﬁned attributes instead text. contrast attribute-based models fully utilize attribute information build attribute classiﬁers learn attribute classiﬁers. experiment method uses ﬁrst moment information attributes decided compare attribute-based approach perspective. particular applied attribute-based model birds dataset widely adopted many applications visual domain used classeme features experiment table viii. contrast multiclass accuracy using approach setting also measured average recall. found recall measure svm-dt-kernel approach reﬂects better true positive rate importantly achieved results without learning attribute classiﬁers comparing results approach using attributes textual description space used prediction clear attribute features give better predictions. support hypothesis meaningful domain better performance domain. indicates better textual representation used better performance achieved. attributes good semantic representations classes difﬁcult deﬁne attributes arbitrary class measure conﬁdence one. contrast much easier unstructured text description visual classes. used state model image-sentence similarity breaking text document sentences considering positive sentence images corresponding class. measure similarities image class averaging similarity sentences class. images encoded using vggnet sentences encoded activations birds dataset experiments resulted better linear classiﬁer table vii. however kernel method deep features still performing better report zero-shot performance sc-seen split detailed subsection applied linear kernel method compare recently published results setting performed experiments previous sections hard performance methods sc-seen split signiﬁcantly better sc-unseen split designed kernel approach results sc-seen split best performing methods shown table used binary version term frequency performance performance shows challenging sc-unseen split compared sc-seen split. important mention assumption using existing images negative examples valid split. hence enforce constraint scseen split hence prediction dominated domain transfer function. added constraints performance goes expected incorrectness assumption split. based result encourage future researchers problem report performance sc-unseen split sc-seen split showed sc-unseen split challenging. explored problem predicting visual classiﬁers textual description classes training images. investigated experimented different formulations problem within ﬁne-grained categorization context. ﬁrst proposed novel formulation captures information visual textual domains involving knowledge transfer textual features visual features indirectly leads predicting linear visual classiﬁer described text. also proposed zero-shot learning technique predict kernel-classiﬁers unseen categories using information privilege space. formulated problem domain transfer function text description visual classiﬁcation space supporting kernels domains. proposed one-class adjustment domain transfer function order improve prediction. validated performance model several experiments. illustrated value proposing kernelized version applying kernels generated multiple kernel learning achieved better results. future improve model learning unseen classes jointly larger scale. acknowledgment. research funded award iis- iis-. rohrbach stark szarvas schiele combining language sources robust semantic relatedness attribute-based knowledge transfer parts attributes workshop eccv parikh grauman interactively building discriminative merri¨enboer gulcehre bahdanau bougares schwenk bengio learning phrase representations using encoder-decoder statistical machine translation emnlp karpathy fei-fei deep visual-semantic alignments socher ganjoo sridhar bastani manning zero shot learning cross-modal transfer nips mikolov sutskever chen corrado dean distributed representations words phrases compositionality nips mohamed elhoseiny postdoc researcher facebook research. primary research interest computer vision machine learning intersection natural language vision language guided visual-perception visual reasoning received degree rutgers university brunswick prof. ahmed elgammal. mohamed received fellowship write-a-classiﬁer project best intern award international doctoral consortium award cvpr ahmed elgammal professor department computer science rutgers university. primary research interest computer vision machine learning. research focus includes human motion analysis tracking human identiﬁcation statistical methods computer vision. elgammal senior member ieee. elgammal received ph.d. university maryland college park. babak saleh works computer vision machine learning human perception rutgers university. interested build visual recognition systems human-level capability image understanding. line research recognized major media outlets received outstanding student paper award aaai", "year": 2015}