{"title": "Fitted Learning: Models with Awareness of their Limits", "tag": ["cs.AI", "cs.LG", "cs.NE"], "abstract": "Though deep learning has pushed the boundaries of classification forward, in recent years hints of the limits of standard classification have begun to emerge. Problems such as fooling, adding new classes over time, and the need to retrain learning models only for small changes to the original problem all point to a potential shortcoming in the classic classification regime, where a comprehensive a priori knowledge of the possible classes or concepts is critical. Without such knowledge, classifiers misjudge the limits of their knowledge and overgeneralization therefore becomes a serious obstacle to consistent performance. In response to these challenges, this paper extends the classic regime by reframing classification instead with the assumption that concepts present in the training set are only a sample of the hypothetical final set of concepts. To bring learning models into this new paradigm, a novel elaboration of standard architectures called the competitive overcomplete output layer (COOL) neural network is introduced. Experiments demonstrate the effectiveness of COOL by applying it to fooling, separable concept learning, one-class neural networks, and standard classification benchmarks. The results suggest that, unlike conventional classifiers, the amount of generalization in COOL networks can be tuned to match the problem.", "text": "curacy score. unlike machines humans sense limits knowledge fact easily exposed ﬁxed test drawn similar distribution training examples. example confronted adversarially-selected images reminiscent random noise human easily recognize resultant image familiar hence belongs known class all. deep learning contrast proven easily fooled images assigning class conﬁdence phenomenon called fooling fooled examples outside training distribution raises concerns mistakes alone conﬁned scenarios might dismissed relatively unlikely. example often real world might encounter image unlike anything real world adversarially optimized trigger mistaken classiﬁcation? however experiments paper show fooling foreshadowing shortcomings conventional neural networks fall short human-level capabilities. example tendency classify images conﬁdence among training classes means adding class already-learned model unlikely work thereby precluding continual learning classes. also means combining separatelytrained classiﬁers similarly untenable. single-class neural networks learn whether training instance within single class outside also prohibitive train similar reasons. problems result tendency conventional neural networks draw well-informed discriminative borders different classes fail conﬁning regions classes span examples dataset. consequences include fooling also real practical divergence natural ability learn classes seamlessly throughout lifetime. neural networks could brought learn better ﬁtted regions i.e. ones overgeneralize problems cited fooling continual learning would largely mitigated even cases solved. though deep learning pushed boundaries classiﬁcation forward recent years hints limits standard classiﬁcation begun emerge. problems fooling adding classes time need retrain learning models small changes original problem point potential shortcoming classic classiﬁcation regime comprehensive priori knowledge possible classes concepts critical. without knowledge classiﬁers misjudge limits knowledge overgeneralization therefore becomes serious obstacle consistent performance. response challenges paper extends classic regime reframing classiﬁcation instead assumption concepts present training sample hypothetical ﬁnal concepts. bring learning models paradigm novel elaboration standard architectures called competitive overcomplete output layer neural network introduced. experiments demonstrate effectiveness cool applying fooling separable concept learning one-class neural networks standard classiﬁcation benchmarks. results suggest that unlike conventional classiﬁers amount generalization cool networks tuned match problem. hope machine learning often match even exceed performance humans tasks prohibitive machines. measure success frequently expressed accuracy learning algorithm test separate examples experienced training. example ilsvrc- dataset roughly million images spanning thousand different classes success measured separate images test conventional approach measuring success makes possible compare machine human performance assess humans test set. fact imagenet humans achieve test level recently exceeded deep learning algorithms thus narrative emerges whereby machines creeping past abilities humans visual recognition remarkable proposition. capture idea paper later introduces formal framework ﬁtted learning refers algorithms learn good discriminative borders distribution training data time. moreover major contribution work simple mechanism achieving ﬁtted learning within conventional apparatus deep learning neural networks. main idea called competitive overcomplete output layer assign output class also force outputs compete respond correctly. resulting dynamic achieved usual process stochastic gradient descent pushes competing neurons within class respond overlapping non-identical regions input space yielding sufﬁcient consensus conﬁdent classiﬁcation within tight-ﬁtting region around training data. simple mechanism ﬁtted learning thereby step towards natural style learning neural networks. mnist digitclassiﬁcation domain conﬁrm cool approach mitigates fooling expected also indeed enables combining multiple separatelylearned classiﬁers even makes possible effective one-class neural networks otherwise prohibitive conventional convolutional neural networks moreover cool networks actually outperform cnns identical architectures cifar- cifar- reaching higher level test accuracy converging signiﬁcantly faster thanks opportunistic steps taken cool networks gradient descent. covering background material next paper introduces components cool architecture intuitively demonstrates advantage visualizations cool non-cool networks simple twodimensional classiﬁcation problem. cool mechanism justiﬁed formally tested within context fooling images ﬁtted learning connected generalized classiﬁcation problem also formalized. series experiments mnist follow learning separate classiﬁers later combined including ﬁrst demonstration working one-class neural networks. experiments conclude head-to-head classiﬁcation comparisons cifar- cifar- followed discussion implications ﬁtted learning cool. closest conceptual framework ﬁtted learning probably open recognition problem vision community unknown classes appear testing phase learning model able detect unknowns. however recognition task osrp learning model focused single class ﬁtted learning learning models handle several classes together. ﬁtted model able discriminate time capturing data distribution class. unlike common practice open recognition ﬁtted model learn tight halo around different class regions unless border friction another class therefore sensitive choice threshold parameter. visualization experiments follow indeed illustrate properties cool low-dimensional spaces. established method applied osrp anomaly detection one-class tries capture data distribution technically support probability distribution turning one-class problem classiﬁcation problem. main difference one-class ﬁtted models one-class discriminative model core border around data points rather capturing underlying distribution. example learning regions feature space hollow inside difﬁcult one-class model. fitted learning also viewed inverse generative model learning sampling particular class involves searching input instance highly activates corresponding class hypothetical ﬁtted model. input highly activates output node trained ﬁtted model example class output node procedure generate instances leads generative model. analogy drawn generative adversarial nets capture distribution data generative model competes discriminative model. cool potential ﬁtted model induces form competition well unlike gans entail careful training competing models explicit separate models. another method conceptual connection cool dropout exponential number models trained together randomly dropping hidden units training phase. similarly cool effect trains exponential number models well also learn concept. however cool also employs mechanism encourage diversity ﬁnal subset models contrast dropout usually results training speedup. cool effect expands traditional output layer assigning several output units class concept. furthermore forcing group neurons compete ensures diversity partitioning input space among output units class. result output units ultimately agree within regions proximal training instances. words unlike conventional architectures cool captures distribution training instances class time learning discriminate between instances different classes. neuron aggregate neuron aggregate collection units called member units intended learn single concept. sense neuron aggregate acts ensemble inspired hypothesis biological neural networks neuron involved recognizing concept internally-competitive aggregate neuron aggregate whose member units’ activations mutually inhibitory modeled cool softmax function applied member units. note accordingly sufﬁces neuron aggregate part softmax layer become internally-competitive aggregate. competitive overcomplete output layer cool consists simple change traditional output layer setup neural networks. particular output unit replaced internally-competitive aggregate. elaborate architecture rest paper assume one-hot neural encoding target output labels. also deﬁne expected maximum activation value unit expected highest activation value single unit have; example normally traditional logistic sigmoid saturates emav one. output unit softmax layer normally trained values either indicating deactivation/activation corresponding unit respectively. framework traditional unit replaced neuron aggregate cool accepts lower values indicate activation member units. speciﬁcally indicates activation member unit zero indicates deactivation hyperparameter called degree overcompleteness indicates number member units neuron aggregate. paper neuron aggregates output layer degree overcompleteness. effect emav value member unit aggregate training phase member units neuron aggregate trained value i.e. zero depending desired activation corresponding aggregate. algorithm shows procedure formally. note combined one-hot encoding class labels ensure member units always equals cross-entropy cost function applied straightforwardly train network. activation values member units cool setup interpreted scaled probability inclusion input instance particular class. figure output layer conventional neural network cool. conventional output layer three neurons learn three concepts. overcomplete output layer task shown training. yellow rectangle depicts aggregate gray units aggregate show aggregates architecture. cool output layer computes decisions multiplication test phase. effect adds dimensions output layer second enforces continuing competition among member units active neuron aggregate. section cool mechanism works shows detail components enforce beneﬁcial competition among member units. visualization experiments come ﬁrst provide initial intuition competition lead fundamental change output layer behavior effect preventing output units overgeneralizing regions away training instances. experiments suggest internally-competitive aggregates able learn appropriate probability distribution assigned concepts critical property many learning tasks. inference phase outputs member units aggregate combined multiplication calculate total activation value aggregate. idea member units trained minimize variance therefore expected exhibit least variance highest activation network inputs within proximity training instances. time softmax enforces constant total member units. figure compares conventional output layer cool including multiplications happen inference. multiplication helps maximize activation member units computational cost product variables constrained ﬁnite maximized variables equal. finally control degree generalization particular class output values exponentiated softness parameter application multiplication. operation allows tuning decision boundaries individual classes arbitrarily. role parameter clear separable concept learning later revealed consequence cool. optionally ﬁnal results form probability values aggregate output multiplied algorithm describes procedure section low-dimensional artiﬁcial dataset helps visualize behavior cool networks compare traditional neural networks. experiments suggest cool networks able successfully capture underlying distribution training instances still preserving generalization ability conventional neural networks. words construct notion limits knowledge; recognize instances inside scope expertise addition behaving like traditional learning model. problem deﬁnition major obstacle understanding neural networks inability visualize behavior large cross-section input space. address challenge simple twodimensional classiﬁcation problem introduced allows broad visualization. problem involves classifying points located within perimeters concentric circles points instance space different radii centered training includes points within bands point within circle member class point within circle member class two. uniform sampling circles generates training set. visualization experiments section train neural networks different architectures two-class problem. trained network’s output possible twodimensional instances high resolution plotted traditional neural networks discriminative classiﬁcation models look discriminative border. twoclass problem objective means typically partition whole input space regions assigned available classes. possible choice partitioning max-margin border depicted ﬁgure line. ﬁrst experiment shallow architecture compared deep consisting three hidden layers neurons respectively figure depicts activation output unit assigned inner circle shallow deep neural networks. pictures show adding hidden layers result ﬁnding better decision boundary. however deep approach also tends preserve high activation output units regions training points problem described overgeneralization. classiﬁcation problems every possible input instance member known classes overgeneralization exist deﬁnition real-world applications complete classes known possible inputs instance class. fact possible inputs valid input instances likely drawn training data distribution considered valid. naive solution overgeneralization problem extra class including inputs member class. major drawbacks approach figure generalization ability conventional deep shallow neural networks visualization problem. activation output unit assigned learn points within inner circle shown networks. highly-activated area inside circle plots indicates ineffectiveness conventional neural networks preventing overgeneralization. abundance highly activated points outside inner circle usually interpreted shortcoming shallow neural networks generalizing well. activation deep architecture ﬁnds better approximation max-margin decision border. outcome conventionally considered good behavior also hints deep models easier fooled. contrast cool provides alternative solution require modiﬁcation training data. demonstrate capability next visualization cool network trained two-circle problem. figure depicts activation maps output units corresponding inner outer circles respectively pictures clearly show cool mechanism effectively prevent overgenaralization suggesting ability types network capture implicit understanding data generation process. experiments raise concern whether cool networks restrictive generalize well. accordingly next experiments suggest three means modulate generalization cool namely changing degree overcompleteness changing depth architecture changing softness parameter. short choosing right hyperparameters tune generalization ability model pure discriminative networks spectrum behaving like histogram approximation data distribution side. insight paves toward ﬁtted learning i.e. learning models right amount generalization. figure depicts activation maps concept trained networks different degrees overcompleteness two-circle problem. networks architecture except output layer. visualizations suggest higher result less overgeneralization. words less network likely generalize unseen regions. observation also supported intuition simply traditional neural network. next cool networks different depth output layer compared. figure shows adding hidden layers lead generalization ability higher risk overgeneralization. fact experiment sometimes deep architectures lead generalization unwanted regions finally brief experiment iris dataset provides opportunity show behavior cool presence sparse datasets. general sparse datasets opposed dense datasets figure activation output units cool conventional neural network images depict highly active area inner circle cool versus conventional mlp. notice presence donut hole images show highly active region outer circle. highest outputs cool within correct band around training data conventional neural network generalizes inﬁnity. plots depict cool prevent overgeneralization time learning solve problem. training instances even excluding examples lead signiﬁcant negative impact training. deep learning techniques mainly effective dense datasets sparse datasets still important many domains training instances scarce. visualization purposes experiment ﬁrst input features iris dataset included training set. figure depicts dataset reduced space features whereas activation maps output units cool networks assigned three different types iris shown ﬁgure plots show changing softness parameter shrink/extend activation regions class lead signiﬁcantly better generalization. conclusion experiments section provide intuitive empirical evidence ability cool learn underlying data distribution training instances retaining usual discriminative ability. figure effect applying deeper architectures generalization ability cool. activation maps associated inner circle cool networks hidden layers shown respectively. section explains components cool setup i.e. overcompleteness competition work together overgeneralization. particular turns overcomplete architecture leads simultaneous training exponential number models together competition preserves diversity member units neuron aggregate trying learn concept. argument begins aggregate member units xn}. overcompleteness idea behind overcomplete layer produces dynamic akin training exponential number models once echoes motivation behind dropout assume output member unit scaled multiplication test phase i.e. output member unit transformed according =max doo. figure generalization ability tailored cool changing softness parameter. three pictures depict activation three different classes cool network softness parameter bottom pictures depict activation maps network softness parameter cost function. words gradient competing gradients member units. ignoring speciﬁc parameters member unit possible cases ﬁnal parameter updates follow gradient descent neurons results gradient ascent neuron short assigning several competing units concept thought game changing model parameters member units active aggregate lead different partitioning input space among them. result expect units preserve diversity arbitrary inputs training instances maintain consensus regions proximal training set. illustrate principle ﬁgure depicts activation cool network lacks competition component. neural network trained two-circle problem visualization experiments. compared cool ﬁgure shows without competition member units associated concept easily converge finally note plots ﬁgure exact complement other indicates even without competition still advantage conventional neural networks. replace original aggregate decision-maker. consequently training aggregate hard analogous training neuron sub-aggregates activation behavior time. challenge exacerbated aggregate class cool. competition competition among member units aggregate instrumental mechanism cool yields protection overgeneralization. recall training particular instance active aggregate i.e. aggregate whose member units trained non-zero values. member units active aggregate trained learn function might expect converge weights neuron aggregate. interestingly competition induced softmax prevents outcome. elaborate assume current active aggregate input instance different member units practice gradient descent least nonzero gradient amongst softmax function implies within neighborhood figure effect removing competition cool. plots depict activation aggregates corresponding inner outer circles twocircle problem softmax removed phenomenon called fooling recently attracted attention deep learning community main observation neural networks tricked outputting conﬁdence wrong class instances well outside training distribution. words fooling problem direct consequence overgeneralization prominent deep architectures. clarify fooling problem begin simple example classiﬁcation task determine whether fruit watermelon apple based weight fruit kilograms. possible training discriminative model decision boundary translated weight watermellon otherwise apple. often discriminative models output probability values based underlying decision boundary well example model input close would classiﬁed apple lower probability fruit weight fooling problem occurs input drawn underlying data distribution e.g. fruit weighs discriminative models trained would classify watermelon even though fruit possibly exist. worth noting ensemble techniques almost mitigating effect fooling problem merely generate better decision boundary form larger margin. however fooling problem margin. provides simple measure easily trained neural network fooled based generative adversarial approach. finally compares fooling cool versus conventional neural networks mnist dataset. results suggest cool mechanism capable preventing fooling neural networks. reasons behind fooling goodfellow shlens szegedy postulate linear explanation existence adversarial examples small perturbations existing training example lead signiﬁcant changes output high-dimensional problem. also extend explanation appendix general case arbitrary fooling example i.e. necessarily similar training example nguyen yosinski clune paper focuses latter case. general suppose training instances sampled unknown probability distribution consider classiﬁcation arbitrary input example neural network fooling example classiﬁed high conﬁdence network drawn probability distribution signiﬁcant factor behind fooling discriminative classiﬁers tend overgeneralize. classify conﬁdence many input instances regardless resemblance training data. several active output units single instance implies conﬁdence classiﬁer single dominant output unit outlier example implies fooling model. kinds learning models implicitly draw borders instance space distance input points region effect ignored resulting degree classiﬁcation conﬁdence input instances away. interestingly cool networks inherently address issue. generating fooling instances previous methods generating fooling images szegedy nguyen yosinski clune search directly images fool network. contrast introduce third option require solving constrained optimization problem random input instance trainable neural network called fooling generator network whose output passed actual model words fooling input network instead gradient descent train network generates good fooling image. procedure parameters ﬁxed trained. formally mapping input vectors probabilistic target vector space invertible mapping discrete labels mapping input vectors size vectors size idea thus solve optimization problem inimize||f) h−|| given input target label denotes inverse note ||.|| refigure example fooling images generated fooling generator network cnn. left right image represents digits respectively. images generated consisting fully connected layer produce plausible images. classiﬁed trained conventional cool least conﬁdence. image blank could generate fooling image trials digit. even though none images close real digits qualitative difference images bottom evident. cool offered mechanism prevent overgeneralization neural networks. consequence cool networks able prevent fooling least make relatively difﬁcult adversary. natural question follows measure amount overgeneralization model. section deﬁnes measure introducing generalized classiﬁcation problem leads notion extended empirical risk natural extension empirical risk recall classical statistical learning theory assume access ﬁnite collection i.i.d. samples training input space training output space data distribution canonical classiﬁcation problem also assume ﬁnite objects size given non-negative real-valued loss function measures loss predicting risk function called hypothesis deﬁned goal classiﬁcation hypothesis minimal. note every hypothesis associated underlying interpretation avoid trivial solutions hypotheses usually restricted class functions words approach several advantages first need constrained optimization control outputs network choosing right activation function. example sigmoid function give output range second good choice architecture indirectly impose desirable constraints generated fooling examples e.g. dealing images convolutional imposes natural image properties generated fooling images. finally almost components approach already provided machine learning packages. mnist fooling experiment experiment ﬁrst cool network conventional trained mnist dataset. trials attempted generate fooling instances model. trial consists training activated random input trick model considered successful model classiﬁes generated fooling image conﬁdence. however fooling example found parameter updates trial failure. details experiment appendix. cool preserves generalization ability cnns task classiﬁcation accuracies cool conventional cnns respectively. time overall trials approach fooled conventional success rate versus fooling rate cool cnn. figure depicts examples typical generated fooling images conventional cool cnn. interestingly average conventional fooled updates parameters whereas cool needs updates suggests drastic shrinkage high conﬁdence classiﬁcation regions within cool cnn. another interesting observation often conventional conﬁdently classiﬁes random image digit cool never fooled random image evidence severity fooling problem conventional neural networks. also conventional fooling rate individual digit approach exhibits variable success different digits cool. example failed trick cool digit attempts. result suggests effective approach preventing fooling involve speciﬁc aggregate. finally important note experiment assumes complete access models meant fooled. real-world scenario fooling likely based limited access training input/output samples trained model. fooling rate cool networks experiment complete access model therefore hints effect prevent fooling many real scenarios. introducing generalized classiﬁcation problem conventional classiﬁcation learning model simply draws border different concepts. drawback strategy discussed earlier inherent overgeneralization. generalized classiﬁcation introduced here addresses issue asking right amount generalization. moreover many real-world applications comprehensive knowledge concepts available training even worse concepts might emerge time. example classiﬁcation certain species cannot rely current knowledge because species discovered time. thus ideally want models adapt emerging concepts without signiﬁcant retraining. another aspect conventional classiﬁcation intuitive interpretation. fair assumption classiﬁers conﬁdent dealing familiar test instances whereas conﬁdence degrade amid novel cases. however counter-intuitively learning models’ conﬁdence merely based test instance’s distance decision border similarity training instances insigniﬁcant effect idea generalized classiﬁcation remedy limitation taking account underlying training data distribution outputing conﬁdence values. finally arguably ﬁnal role learning models assigned classiﬁcation task rather components broader construct. generalized classiﬁcation aims provide models perform subtasks conﬂicting components broader construct also properly responding unexpected circumstances. canonical classiﬁcation problem assume predeﬁned known objects correspond class labels available training set. contrast generalized classiﬁcation assume access subset objects training actual size unknown. problem closely related open recognition problem learning model respond unknown classes test time. however unlike open recognition generalized classiﬁcation involves learning arbitrary number concepts simultaneously single learning model plays dual roles density estimation discrimination. similarly deﬁnition risk deﬁne extended risk follows given non-negative real-valued loss function measures loss predicting function call strong hypothesis extended risk deﬁned thus words strong hypothesis conventional hypothesis example known concept model constant mapping otherwise. informally augmented member known classes represents unknown concepts strong hypothesis assign test instance outputting generalized classiﬁcation fooling deactivation output units points proximity training data initial experiments two-dimensional space two-circle domain suggested cool networks able provide strong hypotheses. experiments showed significantly reduce fooling. worth highlighting relationship strong hypotheses fooling. particular fool learning model instance however definition strong hypothesis extended risk tends assign therefore closer learning model strong hypothesis extended risk less likely fooled. note discussion distinguish adversarial examples drawn classiﬁed correctly arbitrary fooling examples. also note proposition valid hypothesis strong because deﬁnition assign member obligation imposed output hypothseparable concept learning unfortunately straightforward formulate generalized classiﬁcation problem using approximation extended risk samples training partial knowledge however possible evaluate performance strong hypothesis framework classical statistical learning. evaluation consists components model performance instance call latter inhibition ability model must inhibit tendency activate least output class. ﬁrst component evaluated classiﬁcation metric e.g. classiﬁcation accuracy inhibition ability introduce idea separable concept learning advantage metric previous evaluation procedures applied open recognition object detection tasks rely threshold measures rejection ability model implicitly simpliﬁes evaluation procedure reduces processing time signiﬁcantly. intuitively strong hypothesis able learn different concepts separately aware limits knowledge. result models learn nonoverlapping concepts simply accepting output nodes separately trained strong hypothesis. words possible train several strong hypotheses different concepts merge together single model whole concepts. capability turn makes knowledge transfer possible. imagine situation models recfigure test performance different learning models separable concept learning mnist. experiment performance neural networks trained different pair digits mnist evaluated merged. main result improvement cool conventional neural networks. trained different subsets mnist. speciﬁcally partition training subsets etc. train architecture forth. words equation training details found appendix. results figure shows average test/validation error conventional versus cool epochs. cool models signiﬁcantly outperform conventional cnns improvement recognition rate figure also shows accuracy architectures task improvement performance achieved simply applying cool. interestingly cool achieves competitive performance conventional task. overall results suggest cool signiﬁcantly improve inhibition ability learning models turn leads accurate representation knowledge embedded dataset robustness learned concepts. based cool architecture following similar approach one-class section proposes one-class neural networks another possibility created cool. alternative one-class learning model enables direct application deep learning methods ﬁeld one-class recognition. experiments suggest approach promising allow neural networks enter ognize {people animals plants} {sea ground sky} respectively. model ﬁnds people simply built applying conjunctive operator corresponding output nodes models. similar manner disjunctive concepts built based previously learned concepts. another closely related subject incremental concept learning concepts presented learning model incrementally. separable concept learning conceived extreme case learning concepts training instances diminish memory. interestingly reminiscent human learning current full concept learning approach. furthermore realistic applications size unknown beginning could grow time makes practically important subject supervised learning. formally evaluate inhibition ability model concat concatenation operator partition every subset least size extended empirical risk deﬁned strong hypothesis respect assume strong hypothesis learning model trained subset training samples whose classes included corresponding note case equation. reduce classiﬁcation accuracy measure. addition merging outputs different models usually necessitates outputs form probability values. abstractly comparing learning models strictly better ∀ρrρ however possible ways partitioning grows exponentially size thus practice approximation used sampling possible partitions. informally apply equation. train several components model different subsets classes measure performance whole model test set. approach provides simple procedure evaluate different learning models terms acting strong hypothesis. evaluate feasibility consolidate results fooling section number experiments conducted mnist dataset. results show cool mechanism dramatically improve ability neural networks learn subsets concepts separately. results support cool networks able successfully prevent overgeneralization highdimensional spaces. approach capture underlying distribution unlabeled data sch¨olkopf proposed one-class origin treated member second class. algorithm tries maximum margin mapped features instances ﬁrst class origin. best knowledge version extensions off-the-shelf methods capturing notion data distribution high-dimensional spaces applied anomaly detection among tasks. cool network one-class neural networks constructed similar manner including instances within single class. words following notation introduced previous section member second class drawn algorithm summarizes procedure. algorithm one-class neural network algorithm. input underlying probability distribution non-members single class number samples second class available instances experiments experiments follow demonstrate abilities oneclass neural networks. ﬁrst experiment similar problem two-circle problem visualization experiments section introduced. speciﬁcally form training points sampled uniformly within circle form instance second class arbitrary point within selected. figure depicts activation output aggregates assigned class respectively. comparison result experiment also shown typical neural networks applied instead cool ones. plots support validity proposed one-class neural network low-dimensional spaces regular neural network fails. next mnist tests performance one-class neural networks high-dimensional problem. experiment separate one-class neural networks trained learn different classes mnist. furthermore image random pixel values supplied instance figure one-class neural network visualizations. visualizations depict activation maps output aggregates one-class version visualization problem. plots show accurately one-class neural networks capture distribution data present class comparison depict activation maps cool component one-class neural network replaced conventional neural network outputs. second class models. model supposed capture data distribution single digit. later test instance models assigned model maximum probability inclusion manner model treated unnormalized probability distribution function. main results average test accuracies runs achieved cool conventional respectively. however classiﬁcation accuracy solely based maximum activation good representative magnitude probability values. furthermore one-class learning problem performance model based correct detection rejection easily violated classic discriminative model thus better demonstrate difference cool conventional cnns experiment ﬁgure depicts average accuracy rejection rate cool versus regular cnns different epochs activation threshold rejecsection conduct experiments different network architectures cifar- cifar- datasets evaluate effect cool rate convergence performance. using torch unlike previous experiments architectures section apply latest techniques deep learning check synergy cool though learning procedure kept simple possible. cifar- experiment experiment convolutional layers followed fully-connected layers trained ﬁrst training instances cifar- dataset. hidden layer followed batch normalization layer relu applied activation functions layers. details appendix. figure depicts average classiﬁcation accuracy runs cool network versus runs conventional network architecture except last layer. main result cool networks converge times faster performing signiﬁcantly better preliminary experiments variety different architectures yielded similar results. figure average classiﬁcation accuracy cool conventional architecture cifar- runs. cool speeds learning significantly also improving test accuracy. result suggest robust gradient updates training. figure average accuracy rejection rate oneclass experiment. plots show average accuracy rejection rates models test instances ﬁrst epochs mnist one-class experiment applied threshold value. plots show though regular cnns reach level accuracy correct rejection rate make interesting one-class model. tion words model’s activation test instance interpreted rejecting inclusion corresponding class notice ﬁgure rejection rate regular near implausible value zero cool drops accuracy rate ﬂattens. interestingly jain scheirer boult report supplemental material accuracy one-class similar experiment conducted classes mnist. results afﬁrm advantage cool networks ability capture underlying distribution data. moreover support effectiveness proposed one-class neural networks. focused ability cool capture underlying distribution data generalize adequately. another potential advantage cool ability train larger architectures. noted earlier cool effect trains exponential number competing models together. intriguing consequence possible train large architectures without overﬁtting. results section show property alone sometimes lead performance improvements. light augmentation dataset according procedure clevert unterthiner hochreiter image padded four zero pixels borders randomly cropped extract image also randomly horizontally ﬂipped. keep training procedure simple dropout rate kept constant momentum weight decay applied. details appendix. classiﬁcation accuracy conventional versus cool neural network without dropout different epochs shown ﬁgure results suggest expected dropout slows learning process signiﬁcantly improving performance. however also show cool converges faster higher level accuracy. comparison table lists state-of-the-art results cifar- including alexnet all-cnn highway network fractional max-pooling elu-network formulating notion generalized classiﬁcation helps illuminate rigidness conventional classiﬁcation plays central role many impactful benchmark results deep learning. generalized classiﬁcation arguably closely aligned natural setting classes concepts ﬂuid subject expansion. also enshrines notion unknown fundamental ingredient framework learning intuitive idea humans deep networks nevertheless falter fitted learning thereby becomes natural response problem generalized classiﬁcation lighting path towards approaches architectures. approach cool network introduced paper. introductory experiments disclosed initial hint investigation necessary taking signiﬁcant step towards better ﬁtted learning cool shows mechanisms enable dynamic form learning necessarily complex intricate. rather overrepresentation output layer combined competition precipitates partitioning input space among multiple overlapping models simultaneously yielding better data aggregate. cool effect produces ensemble exponential number learning models reminiscent dropout. even outside separable learning one-class neural networks results cifar- cifar- advantages modiﬁcation seem extend conventional classiﬁcation. interesting question whether main insights cool might bolster case single-neuron concepts general including brain. practical level ability classes model without need retrain opens door class continual lifetime learners expand repertoire concepts indeﬁnitely. power deep learning naturally brought bear lifetime learning exciting proposition. simple form continual learning demonstrated paper different modules learn different classes independently before later combined sophisticated variations idea conceivable likely emerge near future. example modules address concepts added also potentially share hidden layers modules allowing safe form expansion also builds accumulated knowledge. tuning hidden knowledge aggregate learner expands also offers breadth possible investigations. furthermore potential beneﬁts recurrent neural networks remain unexplored promising. kind learning. cool accurate classiﬁcation different perspective classiﬁcation towards generalized classiﬁcation. progress sometimes follows path quantitatively increasing performance recent advances accuracy deep learning often also requires perspective reimagine status light. results cool paper preliminary declare victory problem generalized classiﬁcation hope cool provide productive shift perspective least path yield learners dynamic continual spirit humans.", "year": 2016}