{"title": "A Multichannel Convolutional Neural Network For Cross-language Dialog  State Tracking", "tag": ["cs.CL", "cs.AI", "cs.LG"], "abstract": "The fifth Dialog State Tracking Challenge (DSTC5) introduces a new cross-language dialog state tracking scenario, where the participants are asked to build their trackers based on the English training corpus, while evaluating them with the unlabeled Chinese corpus. Although the computer-generated translations for both English and Chinese corpus are provided in the dataset, these translations contain errors and careless use of them can easily hurt the performance of the built trackers. To address this problem, we propose a multichannel Convolutional Neural Networks (CNN) architecture, in which we treat English and Chinese language as different input channels of one single CNN model. In the evaluation of DSTC5, we found that such multichannel architecture can effectively improve the robustness against translation errors. Additionally, our method for DSTC5 is purely machine learning based and requires no prior knowledge about the target language. We consider this a desirable property for building a tracker in the cross-language context, as not every developer will be familiar with both languages.", "text": "ﬁfth dialog state tracking challenge introduces cross-language dialog state tracking scenario participants asked build trackers based english training corpus evaluating unlabeled chinese corpus. although computer-generated translations english chinese corpus provided dataset translations contain errors careless easily hurt performance built trackers. address problem propose multichannel convolutional neural networks architecture treat english chinese language different input channels single model. evaluation dstc found multichannel architecture effectively improve robustness translation errors. additionally method dstc purely machine learning based requires prior knowledge target language. consider desirable property building tracker cross-language context every developer familiar languages. dialog state tracking sub-tasks dialog management whose goal transfer human utterances slot-value representation easy computer process track information appeared dialog. provide common testbed task series dialog state tracking challenges initiated challenge already held four times during provided valuable shared recourse research ﬁeld helped improve state-of-theart. since forth challenge target dialog state tracking shifted human-machine dialog human-human dialog signiﬁcantly increases difﬁculty dialog state tracking task variety ambiguity human-human dialog. lesson learned dstc difﬁculty building high performance tracker human-human dialog limited training corpus matter whether using machine learning hand-crafted rule-based approaches .this unfavorable situation building hand-annotated training corpus expensive time-consuming requires human experts. mention collection corpus language english need build trackers language. dstc proposed challenge based using rapidly advancing machine translation technology able adapt built tracker language limited training development corpus language. idea attractive reduce cost language adaptation also provides possibility building tracker cross-language corpus. example useful developing tourist information systems corpus collected different language speakers language amount corpus limited together large enough good training. hand although machine translation technology achieved great progress recently translation quality still satisfactory conventional monolingual tracker trained computer-generated translations lead imperfect model accept translations languages input also degrade performance. address problems propose model trained different languages time original utterances translations input source dialog state tracking. avoid building tracker based computer-generated translations maximize possible input languages increase robustness translation errors. paper organized follows. sect. brieﬂy describes dataset dialog state tracking problem; sect. presents overview method explains detail multichannel model. sect. presents evaluation results analysis discussion. sect. concludes work proposes future improvements. guide let’s okay? tourist okay. guide it’s inncrowd backpackers hostel singapore. take dorm person twenty dollars. take room it’s single beds ﬁfty nine dollars tourist that’s good. guide prices based person dorm. room. ﬁfty nine room. you’re actually paying dollars person only. tourist okay. that’sprice reasonable actually. it’s good. dstc training dataset. dataset contains dialog sessions tourist information singapore collected english speakers. besides training dataset development includes dialog sessions collected chinese speakers provided testing tuning trackers’ cross-language performance ﬁnal evaluation. training development sets labelled dialog state tags come -best hypothesis english chinese translations machine translation systems. evaluation phase challenge test including unlabeled chinese dialogs distributed participant prediction results submitted participant evaluated comparing true labels. test dataset also includes -best english translations generated machine translation system training/development dataset. dialog state challenge deﬁned ontology used dstc contains topic branches different slot sets topic-slot combinations indicate important information mentioned topic example ‘cuisine’ slot topic ‘food’ refers cuisine types ‘station’ slot topic ‘transportation’ refers train stations. total topic-slot combinations possible values topic-slot given list ontology. main task dstc predict proper value slot given current utterance topic dialog history prior turn dstc proposed method based convolutional neural networks originally proposed method able achieve best performance tracking info slot. model used method modiﬁed origin adding structure multi-topic convolutional layer better handle information presented different dialog topics. model characterized high performance limited training data trained across various topics. details multi-topic model found dstc training data dstc therefore situation limited training data improved. order focus cross-language problem keep method simple instead using complex multi-topic model proposed last time trained individual model slot-topic combination. example ‘info’ slot topic ‘food’ ‘info’ slot topic ‘shopping’ trained independent models. major difference last time trained single model topics. scheme hyperparameters model slot/topic exactly same method scalable universally applicable easy tune. simple diagram illustrating method. info cuisine type place drink place meal time dish neighbourhood info type place activity place time neighbourhood info type place place neighbourhood time info from station line type ticket info type place place neighbourhood computer-generated chinese english translation provided training test dataset respectively straightforward approach train model english corpus english translation test data. alternatively model trained chinese translations training dataset used chinese utterances test data. however methods waste originally collected utterances either training test data. order fully utilize corpus resource english chinese languages proposed following multichannel model regarded combination english chinese models. model inspired multichannel convolutional neural networks commonly used image processing instead channels used color images apply input channel different language source. model input channel dimensional matrix embedding vector corresponding word notice original paper multi-channel architecture also proposed. main difference between model model different sets ﬁlters channel model ﬁlter applied channels. reason modiﬁcation word embedding different languages embedding vector i-th word input text. -dimensional array matrix representation input text. used three different word embedding model chinese english. details embedding explained later sect. channel feature rn−d+ obtained convolving trainable ﬁlter rd×k embedding matrix rn×k using following equation non-linear activation function; convolution operator bias term. maximum value feature max{h} selected max-pooling layer. process ﬁlter extracts important feature input matrix. model multiple ﬁlters used channel extract multiple features. features form pooling layer passed fully connected layer prediction. idea multichannel model connect extracted features different channels ﬁnal output model richer information obtained different channels. fully connect layer multichannel model follows equation vary greatly example embedding vector different language models correspond irrelevant words different meanings. using different sets ﬁlters ensures proper features extracted channel matter word embedding varies among different languages. wordvec common methods producing word embeddings. dstc applied method trained three different models different training corpus. details models listed below chinese word model -dimension wordvec model trained chinese wikipedia text split word boundary using ‘jieba’ module. model contains chinese words english words appeared chinese wikipedia. chinese character model -dimension wordvec model trained chinese wikipedia text split single chinese character. model contains chinese characters english words appeared chinese wikipedia. reason trained models chinese language identifying word boundaries chinese trivial task. chinese smallest element meaning varies single chinese character several concatenated chinese characters task chinese word splitting usually involves parsing sentence state-of-the-art method still cannot achieve perfect accuracy. reason chinese word model contain incorrect vocabularies capable handling unseen chinese character combinations. hand chinese character model rely word segmentation model error-free also easily deal unseen words. however since chinese character model ignores word boundaries resulting embedding vector able reﬂect precise meaning word. accuracy fmeasure sub-dialog evaluation. submitted entries results different hyperparameters settings determined rough grid search settings summarized table compared results other easily tell among hyperparameters dropout rate factor. dropout known technique reducing overﬁtting neural networks case reducing dropout rate always improves precision degrading recall score. explanation over-ﬁtted model outputs labels data similar training data therefore decreases generalization unseen data. hand decreasing dropout rate improve overall performance whose results parameter settings also shown table ‘additional expt. results proposed method along scores teams shown table multichannel model achieves best score among teams result entry- outperforms second best team investigate much proposed multichannel architecture contributes results compared performance multichannel ordinary single channel models. comparison trained three different monolingual single channel models using embedding models mentioned section.. models used parameter setting ‘multichannel table trained -best machine translation results. fig. shows comparing results chinese character model achieves best overall accuracy among single channel models multichannel model outperforms three single channel models. earlier dstc simple model combination technique used improve predictive performance ﬁnal output computed averaging scores output different models also applied method combine output three single channel models result also shown fig.. simple model combination method perform good multichannel model considering simplicity still consider good alternative improve performance. example described using different feature sets provide different complementary information instance. fully connected layer multichannel model provides optimization information prediction therefore resulting model principle better deal translation errors appeared different channels. table examples demonstrate idea. particular sub-dialog segment none single channel models able output correct labels multichannel model gives correct prediction. seen example model combination behaves like simple voting means picks labels supported majority single channel models. multichannel model hand able selectively choose language source trust particular slot value. result label ‘walking’ correctly predicted despite appearing english model’s output ‘exhibit’ label correctly rejected even though supported single channel models three. however real situation complex. look overall predictive accuracy slot performance model varies slots. consider ambiguity caused machine translation varies different subjects. example time expression english word evening word night translated chinese word shang. although chinese word meanings evening night chinese precise chinese terms representing word. english chinese translation ambiguity immediately increases difﬁculty identifying values evening night chinese leads poor performance chinese model slot time. another problem translation quality often varies reversing translation direction difference inﬂections word order grammars since training corpus contains translation direction multichannel model means optimized reverse translation direction. cause multichannel model bias certain channels explain certain slots model combination treats channel equally works better. sophisticated train multichannel model ﬁrstly training model translation direction ﬁne-tuning model other. unfortunately difﬁcult dstc development dataset used tuning limited. proposed multichannel convolutional neural network treat multiple languages different input channels. multichannel model found robust translation errors outperforms single channel models. furthermore method require prior knowledge languages therefore easily applied available corpus resources different languages. reduce cost adaption language also offers possibility build multilingual dialog state trackers large-scale cross-language corpora. work applied three different embedding models english character model. several character-aware language models proposed recently superior dealing subword information rare words misspelling believe integrating multichannel model promising research direction. hand since method purely machine learning based cannot handle unseen labels test data. important issue especially large ontology difﬁculty obtaining large training corpus covers concepts. overcome disadvantage future work include combining machine learning approaches hand-craft rules data argumentation hongjie takashi ushio mitsuru endo katsuyoshi yamagami noriaki horii convolutional neural networks multi-topic dialog state tracking proceedings international workshop spoken dialogue systems alex krizhevsky ilya sutskever geoffrey hinton imagenet classiﬁcation deep convolutional neural networks advances neural information processing systems geoffrey hinton nitish srivastava alex krizhevsky ilya sutskever ruslan salakhutdinov improving neural networks preventing co-adaptation feature detectors arxiv preprint arxiv. matthew henderson blaise thomson steve young word-based dialog state tracking recurrent neural networks proceedings annual meeting special interest group discourse dialogue", "year": 2017}