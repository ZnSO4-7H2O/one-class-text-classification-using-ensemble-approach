{"title": "The Conditional Analogy GAN: Swapping Fashion Articles on People Images", "tag": ["stat.ML", "cs.AI", "cs.CV"], "abstract": "We present a novel method to solve image analogy problems : it allows to learn the relation between paired images present in training data, and then generalize and generate images that correspond to the relation, but were never seen in the training set. Therefore, we call the method Conditional Analogy Generative Adversarial Network (CAGAN), as it is based on adversarial training and employs deep convolutional neural networks. An especially interesting application of that technique is automatic swapping of clothing on fashion model photos. Our work has the following contributions. First, the definition of the end-to-end trainable CAGAN architecture, which implicitly learns segmentation masks without expensive supervised labeling data. Second, experimental results show plausible segmentation masks and often convincing swapped images, given the target article. Finally, we discuss the next steps for that technique: neural network architecture improvements and more advanced applications.", "text": "products sort magic mirror give totally exciting possibilities customers near future. however currently technical challenge solved convincingly. approach would model humans articles objects render photo-realistically computer graphics methods. however engineering challenges computational costs make approach expensive build maintain. instead rich image collections characteristic fashion companies contain rich structure exploited modern generative deep learning methods. learning generative model dressing image human model given fashion article photo specifying wear allow novel image editing method great potential fashion businesses. method enable lean system capable creating thousands images second using image data available typical fashion e-commerce companies produced standard content production processes. thus potential allow scaling parts current fashion businesses. convolutional neural networks powerful deep learning models solve problems example. however usual architectures require prespeciﬁed loss functions losses suitable outputting sharp realistic images e.g. euclidean loss leads blurry images. present novel method solve image analogy problems allows learn relation paired images present training data generalize generate images correspond relation never seen training set. therefore call method conditional analogy generative adversarial network based adversarial training employs deep convolutional neural networks. especially interesting application technique automatic swapping clothing fashion model photos. work following contributions. first deﬁnition end-toend trainable cagan architecture implicitly learns segmentation masks without expensive supervised labeling data. second experimental results show plausible segmentation masks often convincing swapped images given target article. finally discuss next steps technique neural network architecture improvements advanced applications. modern fashion e-commerce scale speed opportunity challenge. creation image content huge amount various articles means traditional methods bottleneck they’re slow expensive. suppose several thousands articles arrive batch. shooting cloth hangers standalone relatively easy cheap making photoshoots professional models time consuming expensive. leveraging available data reusing images human models products would therefore useful fashion business. networks train model learns data distribution example data discriminator attempts distinguish generated training data. models learn loss functions adapt data makes perfectly suitable image-to-image translation tasks desired result create sharp images look indistinguishable training examples. conditional version learns generate images function conditioning information dataset instead random noise prior standard gans. excellent overview imageto-image translation methods using cgans. improves type losses available image-to-image translation models allows advanced sketch texture control interactive image editing. requirement datasets paired input output images ground truth sometimes limitation. many interesting image translation problems datasets paired data exist. presents novel method unpaired training cases presenting image domains regularizing generator function allows learn mapping image domains without requiring explicitly paired examples. example getting horse images second zebra images model accurately swap textures. task painting given image human given image certain article could potentially train supervised learning methods. however ground truth data corresponding desired outcome exist practical generate manually. instead typical fashion company there’s rich image content material produced constantly photo-shoots millions photos humans models wearing articles clothing also closepictures articles without humans. cagan image data form i.e. yi}n index indicates pair human article. images relation image contains human wearing certain fashion product body another image fashion product shown alone. mapping standalone article image appearance rendered human typically distorted occlusion illumination rotation deformation. data learn relation then given clothing article create image human body wearing appropriately rendered article. image analogy problem relation training data pairs note method contrast standard however generating completely photorealistic image containing human wears fashion article image complex task. particular plausible faces hard generate fortunately case beneﬁcial restrict problem staying close input image described next section. need make sure fashion article looks well painted reuse existing human model image instead creating complete output image scratch. easier machine learning point view. addition also corresponds fashion customization use-case introduction i.e. particular customer look piece clothing? want train image-to-image translation network exchange piece clothing given human image note never examples modiﬁed human image swapped fashion item would like see. infer indirectly data allows learn relation article properly dressed model. priors model architecture force neural model augment human image paint parts article consider implicit relation learning. note complex case image domains speciﬁed implicitly conditioning rather given explicitly image domarginalise indices spatial dimensions output discriminator output single number image whole spatial ﬁeld classiﬁcations. network typical discriminative network. local consistency discriminator works quite well also discuss discriminating patches bigger image marginalizing spatial positions fast efﬁcient many image discrimination tasks. terms loss similar classical loss learn distinguish true data generated examples. however last term lcgan deﬁnes another type negative examples come distribution pdata swapped data human article different appearing human. motivation term need whether article really worn human i.e. discriminator needs learn relation corresponding dataset. also ﬁnds negative examples beneﬁcial conditional generative models. designed output channel output channel matting mask ﬁnal generated image human swapped clothes convex combination predicted original image )xi. order ensure range mask values transform sigmoid function. prediction blending mask predicted image similar term regularizes outputs change little possible original human image since know change piece clothing time. effect avoid model painting parts human body relevant swapped clothes method incorporates end-to-end learning side step localization segmentation challenges directly predict images suitable properties smooth looking fashion models wear speciﬁed fashion articles. this need article located replace articles. conditioning directly article stand-alone image type usually available online shop. show article detail transformation correct illumination occlusion rotation deformation output known. method automatically infers appropriate segmentation article human image uses generate appropriate looking image consistent conditioning. image look reasonable i.e. indistinguishable training distribution human images {xi}? article look well-painted human relation conmodel image i.e. sistent relations observed dataset yi}n second criteria cannot modeled directly euclidean loss since ground truth examples combinations article human data examples speciﬁc humans wearing clothes. figure encoder-decoder generator skip connections patch discriminator. display values channels width height illustration image size pixel experiments did. note discriminator outputs spatial ﬁeld classiﬁcation values so-called patchgan approach. figure illustrates cycle loss deﬁned similar motivation make generator stable changing clothes human swap relevant articles leave parts image unchanged. generator creates image modiﬁes original image regions unrelated article reverse swapping operation generate image penalized deviating setup used nvidia memory code implemented theano. training adam settings learning rate minibatch size instance normalisation layers except ﬁrst last relu activation function layers. usually several hours training enough reasonable results. strengths regularizations experience regularizations beneﬁcial article swapping task investigate detail optimal values are. uses convolutions stride also convolutions stride deconvolutions stride double number channels spatial resolution decreases. figure shows spatial sizes channels training pixel images. enough layers receptive ﬁeld pixels enforcing local consistency discriminating images. figure changing upper-body garment human original wears article want paint wearing article generated image property results pixels resolution. note not-in-place transformations also generated cagan. encoder-decoder architecture skip connections addition always last channels intermediate layer store downsampled copies inputs improves convergence models image quality. suppose information conditioning better preserved deep network. training data used contained images humans paired upper-body garments data given zalando biggest e-commerce fashion companies. used data color space tested pixel resolutions data. general model correct behavior generated images keep looks human image swap relevant article. figure shows results randomly chosen models. in-place color changes easier texture geometric deformations figure shows results higher resolution. masks really good quality impressive given segmentation learned implicitly cagan objective. note images obtained zalando consistent background street view images would likely difﬁcult since background figure alpha mask implicitly learned cagan quite accurate original image allows accurate repainting another fashion article human resulting results pixels resolution. figure shows swap different clothes human apply fashion article different humans also shows clearly model generalizes well combine human article visually appealing way. sidenote could obtain similar performance using images contained original training long photoshoot style consistent training data cagan memorize training data. note however model good transferring colors rough structures clothes textures figure image bottom image. another recent method generating people clothes uses segmented data chictopia dataset applies auto-encoders image translation cgan generate images humans using segmented body regions conditioning images. however lack ability specify piece clothing generate exactly e.g. generate upper body garment speciﬁed segmentation mask region cannot control looks exactly. addition requirement semantic segmentation data limitation practice fashion companies usually gather data. inferring labeling data lead extra costs perpixel segmentation expensive. contrast using available fashion images cagan natural fashion domain data already available huge quantities also allows precisely specify article paint. future work want data exciting fashion article swapping scenarios. able change fashion item categories human picture essential full virtual try-on experience. also examine detail much good segmentations human model images improve overall results. least foregroundbackground segmentation indeed beneﬁcial easily augment cagan segmentation masks provided human model pictures either directly overwriting mask using prior. plan improve neural network architecture several ways. examine color spaces e.g. instead rgb. test whether using texture descriptors improve results swapping clothing speciﬁc textile patterns currently cagan inaccurate complex textures. analyze whether embedding conditioning information lead better information neural network faster convergence right generator needs analyze visual descriptors localize article image human image embedding visual description article help earlier layers focus correct region fashion article located.", "year": 2017}