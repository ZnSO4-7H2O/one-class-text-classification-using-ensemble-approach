{"title": "Information Pursuit: A Bayesian Framework for Sequential Scene Parsing", "tag": ["cs.CV", "cs.AI", "stat.ML"], "abstract": "Despite enormous progress in object detection and classification, the problem of incorporating expected contextual relationships among object instances into modern recognition systems remains a key challenge. In this work we propose Information Pursuit, a Bayesian framework for scene parsing that combines prior models for the geometry of the scene and the spatial arrangement of objects instances with a data model for the output of high-level image classifiers trained to answer specific questions about the scene. In the proposed framework, the scene interpretation is progressively refined as evidence accumulates from the answers to a sequence of questions. At each step, we choose the question to maximize the mutual information between the new answer and the full interpretation given the current evidence obtained from previous inquiries. We also propose a method for learning the parameters of the model from synthesized, annotated scenes obtained by top-down sampling from an easy-to-learn generative scene model. Finally, we introduce a database of annotated indoor scenes of dining room tables, which we use to evaluate the proposed approach.", "text": "past years seen dramatic improvements performance object recognition systems especially object detection classiﬁcation. much progress driven deep learning techniques allow end-to-end learning multiple layers low- midhigh-level image features used predict e.g. object’s class location pose provided sufﬁciently many annotations desired output provided training corresponding deep net. hand automatic semantic parsing natural scenes typically exhibit contextual relationships among multiple object instances remains core challenge computational vision. example consider dining room table scene shown figure fairly common collections objects appear speciﬁc arrangement table. instance plate setting often involves plate knife fork spoon left right plate glass front plate. also knife fork spoon often appear parallel rather random conﬁguration. complex spatial relationships among object poses often captured existing deep networks tend detect object instance independently. argue modeling contextual relationships essential highly accurate semantic parsing because detecting objects context objects potentially provide coherent interpretations abstract despite enormous progress object detection classiﬁcation problem incorporating expected contextual relationships among object instances modern recognition systems remains challenge. work propose information pursuit bayesian framework scene parsing combines prior models geometry scene spatial arrangement objects instances data model output high-level image classiﬁers trained answer speciﬁc questions scene. proposed framework scene interpretation progressively reﬁned evidence accumulates answers sequence questions. step choose question maximize mutual information answer full interpretation given current evidence obtained previous inquiries. also propose method learning parameters model synthesized annotated scenes obtained top-down sampling easy-to-learn generative scene model. finally introduce database annotated indoor scenes dining room tables evaluate proposed approach. proposed bayesian framework propose leverage recent advances object classiﬁcation especially deep learning low- midhigh-level features build high-level generative models reason objects scene rather features image. speciﬁcally assume disposal battery classiﬁers trained answer speciﬁc questions scene propose model output high-level classiﬁers. proposed model bayesian seen hybrid learning-based model-based approaches. former refer parsing image scanning battery trained classiﬁers latter refer identifying likely states under posterior distribution bayesian framework combines prior model interpretations data model based low-level image features. nutshell maintain battery classiﬁers bayesian framework replacing low-level features high-level classiﬁers. enabled deﬁning latent variables one-to-one correspondence classiﬁers. particular low-level mid-level features model; variables hidden measured semantic content. refer indexes latent variables corresponding classiﬁers queries latent variables annobits. example annobits might lists binary indicators presence absence visible instances subset object categories speciﬁc image patch corresponding classiﬁers might cnns output vector weights categories. annobits seen perfect classiﬁer vice-versa classiﬁer seen imperfect annobit. data model conditional distribution family classiﬁers given family annobits. prior model encodes expectations scenes structured example encoding preferred spatial arrangements among objects composing dining room table setting. hence posterior distribution serves modulate contextualize classiﬁer output. propose prior models. ﬁrst combines prior model scene camera geometry whose parameters encoded homography markov random ﬁeld model spatial arrangement object instances given homography. model motivated particular application parsing dining room table scenes objects table plane. model easy sample posterior hard learn tabula-rasa lack modularity therefore need great many training samples. second model based attributed graph node corresponds object instance attributed category label pose world coordinate system. attributed graph built random skeleton encodes spatial relationships among different object instances. model easy learn sample sampling posterior much harder. best worlds using second model synthesize large number annotated scenes used learn parameters ﬁrst model. proposed scene parsing strategy depending scene running relatively small subset classiﬁers might already provide substantial amount information scene perhaps even sufﬁcient amount given purpose. therefore propose annotate data sequentially identifying applying informative classiﬁer step given accumulated evidence previously applied. selection queries task-dependent general principles articulated. want structure allow parsing procedure move freely among different levels semantic geometric resolution example switch analyzing scene whole local scrutiny discrimination perhaps back depending current input changes target probabilities evidence acquired. processing terminated point ideally soon posterior distribution peaked around coherent scene description occur small fraction classiﬁers executed. bayesian framework provides principled deciding evidence acquire step coherently integrating evidence updating likelihoods. step select classiﬁer achieves maximum value conditional mutual information global scene interpretation classiﬁer given existing evidence consequently order execution determined online scene parsing solving corresponding optimization problem step. proposed information pursuit strategy alternates selecting next classiﬁer applying image data updating posterior distribution interpretations given currently collected evidence. application object detection pose estimation table-setting dataset proposed strategy detect instances multiple object categories image estimate poses. precisely consider scene semantic description consisting variable-length list identities poses visible instances pre-determined family object categories. want recover list applying high-level classiﬁers observed image scene acquired unknown viewpoint. proof concept focus indoor scenes dinning room tables speciﬁc categories plate glass utensil bottle. scenes challenging severe occlusion complex photometry intra-class variability. order train models classiﬁers collected manually labeled images table settings web. dataset learning model training testing classiﬁers evaluating system’s performance. show make accurate decisions existing object instances processing small fraction patches given test image. also demonstrate coarse-to-ﬁne search naturally emerges paper contributions summary core contribution work bayesian framework semantic scene parsing combines data model output highlevel classiﬁers opposed low-level image features prior models scene captures rich contextual relationships among instances multiple object categories progressive scene annotation strategy driven stepwise uncertainty reduction dataset table settings. paper outline remainder paper organized follows. section summarize related work. section deﬁne main system variables formulate information pursuit mathematical terms. section introduce annobits annocell hierarchy. section introduce prior model scenes includes prior model interpretation units prior model scene geometry camera parameters. section introduce novel scene generation model synthesizing scenes used learn parameters prior model. algorithm sampling posterior distribution crucial step spelled section particular classiﬁers data model experiments described section section introduce table-setting dataset composed fully annotated scenes training prior model classiﬁers. section present comprehensive experiments including comparisons using cnns alone. finally concluding discussion section strategy proposed work partially motivated divide-and-conquer search strategy employed humans playing parlor board games twenty questions classiﬁers would represent noisy answers well capacity human visual system select potential targets scene ignore items acts selective attention online algorithm implementing strategy ﬁrst introduced geman jedynak name active testing designed speciﬁcally road tracking satellite images. since then variations active testing appeared face detection localization ﬁne-grained classiﬁcation instrument tracking retinal microsurgery. however applied problems complexity scene interpretation. cnns generally deep learning feature hierarchies everywhere. current cnns designed based principles introduced years past decade efﬁcient ways train neural networks layers together larger annotated training sets efﬁcient implementations high-performance computing systems gpus large-scale distributed clusters resulted success deep learning speciﬁcally cnns. resulted impressive performance cnns number benchmarks competitions including imagenet large scale visual recognition challenge achieve better performance network size grown constantly past years taking advantage newer powerful computational resources. shick faster rcnn initially generate proposal boxes likely contain object instances; boxes processed classiﬁcation regressed obtain better bounding boxes positive detections. rcnn girshick proposals generated using selective search algorithm uijlings selective search algorithm generates candidates various ways grouping output initial image segmentation. faster region-based selective search algorithm generate candidate boxes; network generates proposals internally forward path. approaches contextual relations improve disambiguation prevent inconsistent interpretations allow progressive annotation accommodate representations. image segmentation approach. considerable amount work attempting incorporate contextual reasoning object recognition. frequently accomplished labeling pairs regions obtained segmentation image patches using conditional random fields markov random fields compositional vision embeds context broader sense considering general non-markovian models related context-sensitive grammars. work discriminative learning reasoning several attempts made recently designing models reason surfaces scenes interaction objects supporting surfaces shown reasoning underlying layout scene expected useful recognizing interactions objects surfaces however current models encode contextual relations among objects supporting surfaces beyond coplanarity. scenes queries limited possible interpretations descriptions physical scene image scene. paper description records identities poses visible instances pre-determined family object categories scene description unknown image observed determined scene together other typically unobserved variables including camera’s intrinsic extrinsic parameters. assume random variables deﬁned common probability space. goal reconstruct much information possible observation generate corresponding semantic rendering scene visualizing object instances. setting information supplied noisy answers series image-based queries speciﬁed assume true answer query determined hence function dependency allows queries depend locations relative observed image. regard providing small unit information scene hence assuming small possible values even i.e. corresponding answers binary query. refer every annobit whether binary query. also subset queries denote corresponding subset annobits similarly classiﬁers progressively estimate states annobits matched family image-based predictors. speciﬁcally query corresponding classiﬁer function assume classiﬁer computational cost; necessary sequential exploration based information alone meaningful also seen bayesian model. prior model composed scene model encodes knowledge spatial arrangements scene objects camera model combining prior model data model allows develop inference methods based posterior speciﬁc form models naturally depends application information pursuit strategy generally applicable prior data models explained next. ordered sequence ﬁrst distinct queries possible answers corresponding classiﬁers consider event where index query step process observed result applying classiﬁer therefore accumulated evidence queries. strategy deﬁned recursively. ﬁrst query determined conditional joint distribution given evidence date i.e. given ek−. according classiﬁer maximum expected information gain given currently collected evidence greedily selected step denotes shannon entropy. since ﬁrst term right-hand side depend sees next query chosen adding evidence result applying test image minimize average uncertainty point caution regarding notation residual uncertainty given current evidence slightly differ residual uncertainty soon residual uncertainty given small reasonable assumption number annobits large enough. pass speciﬁc description variables distributions. particular next section provides driving principles choice annobits. discuss related classiﬁers followed construction prior data models training associated sampling algorithms. depending structure joint distribution conditional entropies easy compute. possible simpliﬁcation make approximation neglecting error rates selection stage therefore replacing approximation leads simpler deﬁnition namely notice assumed coincide conditioning event accuracy classiﬁers still accounted evaluating implications current evidence. again prefers asking questions whose answers unpredictable. example would urban scene? already positive response skyscraper? would object instance category patch already know highly likely object instance category patch subset removing previous questions search important approximation since mutual information vanishes case necessarily conditional entropy choice functions deﬁne annobits naturally depends speciﬁc application. annobits mind scene interpretation used previous related work visual turing test fall mainly three categories scene context annobits indicate full scene labels indoor outdoor street; since application focused entirely dinning room table settings illustrate these. existence annobits relate presence absence object instances certain properties attributes. numerous annobits system whether instances given object category visible inside speciﬁed region. functions elementary descriptors also interest. example rely heavily annobits providing list object categories visible given image region described section recall section scene description consists object categories poses visible instances pre-determined family object categories. here motivated application dining room table scenes objects table plane representation object pose one-to-one correspondence pose homography relating image plane table plane speciﬁcally object instance triple denotes object category predeﬁned categories denotes locations centers instances image domain denotes sizes image apparent pose space therefore reﬁned poses could obviously considered. deﬁne queries divide apparent pose space cells. speciﬁcally consider ﬁnite distinguished subset sub-windows subset size intervals index queries triplet every category sub-window size interval ycam instance category size visible ycam otherwise. simply write yca. refer annocell. speciﬁcally assuming consists square patches four sizes patches level overlap level column shift ratio i.e. overlap nearest windows. leads patches levels respectively total patches. figure shows regions selected four levels hierarchy. using hierarchical annocell structure advantage allowing coarse-to-ﬁne exploration pose space. note also that construction annocells resolution unions certain high-resolution ones. implies value annobits resolution turn derived maximums high-resolution annobits. addition also category-independent size-related annobits annocell size interval deﬁne binary annobit indicates whether average size objects present belongs subset additional variables also introduced. designed predict information units half overlaps table. observe classiﬁer assigned necessarily assume value however problem since interested conditional distribution given following section joint distribution annobits derived prior model scene description camera parameters assume variables independent model separately. motivated application dining room table scenes assume ﬁxed dominant plane model choose coordinate system oxyz xyplane coincides dominant plane. scene represented object instances assumed sitting bounded region dominant plane case centered rectangular table characterized length width. recall section object instance represented category location size image. here assume objects given category ﬁxed size {zi} distribution deﬁned conditional since example size directly impact number objects support. generally table replaced variable representing complex properties global scene geometry. convenience sometimes drop notation. however model components introduced depend proposed model understood conditional conﬁguration obviously discrete representation scene layout restricted object categories location letting denote space conﬁgurations gibbs distribution associated family feature functions scalar parameters gibbs distribution following form existence features indicate whether instance given category centered anywhere given cells therefore taking form consider sets three different granularity levels illustrated figure level singleton zjc. also consider middle-level sets coarse-level sets cover reference plane without intersection. second component prior model determines probability distribution extrinsic intrinsic camera parameters pose focal length respectively. deﬁnition parameters fairly standard computer vision deﬁnition generative models parameters not. follows summarize typical deﬁnitions leave details generative model appendix. remember assumed ﬁxed coordinate system xy-plane coincides dominant horizontal plane. consider also second camera coordinate system oxyz xy-plane equal image plane. extrinsic camera parameters deﬁned pose camera coordinate system oxyz relative ﬁxed coordinate system oxyz camera rotation maps unit axis vectors oxyz unit axis vectors oxyz translation vector. parametrize rotation three angles representing respectively counter-clockwise rotations camera’s coordinate system x-axis y-axis z-axis world coordinate system conversion unit vectors angles). observe express coordinates point world coordinate system functions coordinates camera coordinate system form since case points plane normal plane measured camera coordinate system distance plane camera center homography camera plane world plane. intrinsic camera parameters deﬁned coordinates focal point focal length intersection principal axis camera image plane well pixel sizes directions denoted invariance symmetry assumptions scene encoded equality constraints among model parameters thereby reducing model complexity. grouping binary features identical parameters equivalent considering features count number layout conﬁgurations satisfying conditions locations categories. table settings natural assume invariance rotation around center table. hence assume existence features whose domain size located distance closest table edge weights hence probability depends number instances. remark model generalized include pose attributes location e.g. orientation size height. denotes space poses extend state space interpreting presence object category pose cell absence object category irrelevant. features extended state space provide joint distribution includes pose. simplest approach would extend univariate features object poses attributes conditionally independent given categories locations assume follows beta distribution then letting denote distance horizontal projection table plane center table assume follows beta distribution. assume independence invariance rotation around vertical axis speciﬁes distribution distribution rotation angles deﬁned conditionally speciﬁcally assume camera roughly points towards center scene horizontal direction image plane also horizontal coordinate system. additional details model provided appendix. assume scene geometry takes value ﬁnite template geometries coarsely cover possible situations. note templates deﬁned translation since always assume reference frame placed given position relative geometry. table settings geometry represents table itself templates simply square tables size distributed according shifted scaled beta distribution ranging meters. rough approximation sufﬁcient purposes even though tables real scenes obviously much variable shape size. allow train scene model independently unknown transformation maps image. done several ways. example given four points image projections corners square reference plane reconstruct scale factor homography mapping plane image. reasonable accuracy relatively easy general human annotator allows invert outline every object image lies reference plane shape scale ambiguity. ambiguity removed knowing true distance points reference plane positions image. used level annotation representation table settings based fact objects interest either horizontal easily identiﬁable horizontal components assumed plates standard diameter remove scale ambiguity. seen level annotation required train prior model quite high. able produce rich annotations images dining room table settings insufﬁcient train model. address issue next section propose scene generation model generate large number annotations many synthetic images needed. given annotations synthetic images well real images parameters prior model learned using accelerated version robust stochastic approximation match empirical statistics calculated based top-down samples scene generation model details). models simple enough speciﬁed model parameters manually described before. therefore fundamental challenge learn prior model scene interpretations purpose assume training annotated images available. annotation image consists list object instances labeled category apparent pose represented ellipse image plane. also assume sufﬁcient information provided propagate image annotation scene annotation coordinates; section propose scene generation model used generate large number annotations train prior model described section proposed model mimics natural sequence steps composing scene. first create spontaneous instances placing objects randomly scene; distribution locations depends scene geometry. then allow instances trigger placement ancillary objects whose categories attributes sampled conditionally creating groups contextually related objects. recursive process terminates children created number iterations reaches upper-bound. assume probability distribution n|c| family distributions distributions used decide number objects placed scene step. speciﬁcally conditional joint distribution number object instances category placed initially scene. category joint distribution numbers object instances triggered addition object instance category distributions thought basis distributions multi-type branching process complexity process controlled master graph restricts subset categories created step. formally directed graph vertices supported categories children node {}∪c. adjoining node labels avoids treating special case derivations below. master graph used table settings provided figure regard plate bottle children category note since allow spontaneous instances categories every category child category output branching process represented directed tree vertex attributed category denoted edges. root node tree hereafter denoted essentially represents empty scene whose category also denoted nodes categories non-terminal node children children category refer skeleton tree needs completed object attributes corresponding skeleton graph categories color-coded graph. root nodes initialize generative process; six. terminal nodes instance according base graph complete description need associate attributes objects important poses world focus now. designed experiments relevant information pose location table parameter. however possible design top-down generative model includes richer information using example ellipsoid. representations involve small number parameters denoted generically vertex skeleton graph attributed parameters pose denoted using ellipsoids involves eight free parameters fewer parameters would needed objects vertical ones objects rotational symmetry. case obvious distribution object pose depends heavily category. model contextual information important placing object relative parent pose also depends parent’s pose category. captured conditional distribution pose parameters category relative parent category pose simplify notation allow case irrelevant. complete attributed graph associated scene distribution interested objects visible scene scene description obtained discarding graph structure i.e. retaining object categories poses. complex scene descriptors could interesting well like object relationships groupings case whole graph structure also interest; compositions experiments. ﬁnal point mention samples require pruning ﬁnal stage since previous model avoid object collisions overlaps generally wants avoid. removed physically impossible samples vertical object categories overlapping world coordinate system. general undirected edges children parent incorporate context single setting. details scene model used table-settings found appendix. even though annotation assumed describe scene world coordinate system information provides still incomplete include graph structure. learn parameters branching process used algorithm precisely monte-carlo version stochastic expectation-maximization algorithm usually referred mcem literature framework conditional expectation complete log-likelihood maximized step update parameters approximated monte-carlo sampling averaging sufﬁcient number realizations conditional distribution fig. top-view icon visualization table-settings considering plate bottle glass utensil categories. upper panel visualization annotated images dataset roughly match size table lower panel samples generative attributed graph model square table size orphan. conﬁgurations form subset ∪{∅} given constraints imposed master graph fact acyclic. gibbs sampling algorithm iteratively updates according conditional distribution given observed variables easily computed using equation recall graph distribution learned conditional given scene geometry figure shows top-view visualization annotated images dataset roughly match size table samples drawn generative attributed graph model square table size metropolis-hastings sampling strategy estimate conditional distribution scene variables given history. reminder algorithm relies fact transition probability modiﬁed rejection sampling placed detailed balance letting provided metropolishastings strategy assumes family elementary moves represented transition probabilities {ψm)}. step algorithm move chosen conﬁgura tion created probability current conﬁguration. elementary moves updating scheme must chosen appropriately ensure chain ergodic. feasibility method relies whether ratio intervening tractable. equation terms relatively easily computed exception probabilities normalizing constant depends constant cancels ratio whenever values coincide i.e. elementary move change scene geometry. among moves satisfy property moves involving camera properties generally computationally demanding modify annobits elementary changes local impact. learned matching annotated images. visual similarity samples taken generative attributed graph model natural scene samples conﬁrm suitability model table setting scenes although proposed model quite general used model different types scenes. remark developed algorithms unconditional conditional sampling graph model context unconditional sampling top-down easy fast. however conditional sampling based metropolishastings metropolis relatively complex slow adapt condition i.e. long burn-in period; partly innate acceptance rate metropolis-hastings algorithm normally jahangiri details). used model directly framework relying instead model described section feature expectations learned scenes generated generative attributed graph model. sampling posterior distribution hidden variables given evidence central method necessary performance evaluation. writing unobserved scene-related variables prior distribution given recall annobits deterministically related scene discussion work simplifying assumption classiﬁers conditionally independent given that given conditional distribution given variables depends recall also step order compute conditional mutual information determine next query require mixture weights xqk− xk−} evidence steps. clearly then estimated samples given history. trained three deep cnns. ﬁrst catnet object category classiﬁcation; second scalenet estimate size detected object instances third scenenet estimate scene geometry given image. cnns borrow network architecture last weight layer i.e. layer vgg- network last fully-connected layer following softmax layer three cnns modiﬁed accommodate design needs. cnns rely transfer learning initializing ﬁrst weight-layers corresponding weights vgg- network trained million images imagenet dataset however since last layer’s architecture three cnns different vgg- corresponding weights randomly initialized training. cnns trained tested using caffe deep learning framework using nvidia tesla desktop computer intel quad-core processor running ubuntu operating system. processing time patch seconds end-of-the-line intel seconds tesla gpu. since input patches size namely pass network classiﬁers computational cost test time. describe design training performance cnns following subsections. catnet object category want detect least instance given patch done simultaneously categories including background. moreover patches resized trained independently original size image. sufﬁces framework since patches restricted -level annocell hierarchy smallest annocells remain scale objects except extreme cases. catnet softmax output layer returns vector scores conﬁdence level presence least object corresponds category patch empty patch scores non-negative interpreted probability existence since events represent incompatible i.e. co-occur. application however used simpler approach relying good estimator ﬁxed rest computation. letting estimator sampled small neighborhood making additional approximation constant neighborhood. camera properties proposal distribution taking form p|i) coordinates coincide observed image. dependency implemented estimator limiting camera parameters described next section. proposal distribution assumed uniform ﬁnite scene geometries considered. taken independent modeled dirichlet distribution separately possible conﬁgurations cat. used ﬁxed-point iterative schemes perform parameter estimation figure illustrates samples learned dirichlet distribution versus sample outputs corresponding annobit conﬁgurations. therefore estimated conditional distributions. ﬁgure shows stacked visualization samples drawn randomly data collected running catnet patches samples taken dirichlet model learned catnet output data corresponds annobit conﬁgurations. shown stacked bars four conﬁgurations example. length colored represent proportion category; therefore total length stacked equal interesting observations length bars corresponding present categories comparable usually considerably larger length absent categories; color distribution catnet outputs dirichlet model samples similar conﬁguration. supports argument using dirichlet distribution modeling data distribution stacked bars good means visually inspect compare true empirical distribution versus dirichlet model. deﬁne scale object image patch ratio longest side patch size completely visible. scalenet predictor designed estimate average scale object instances given patch independent category. assume quantization unit interval modiﬁed vgg- network assigning output values softmax layer trained assigning patch training data index closest average scale objects contains using nonempty patches. output vector non-negative weights summing one. initial sequence consistency labels across annotators veriﬁed synonymous labels consolidated. annotation task carried careful supervision resulting high quality annotations better normally crowd-sourcing tools like amazon mechanical turk. figure shows annotation histogram annotated categories. average number annotations image estimate homography least four pairs corresponding points needed according direct linear transformation algorithm four pairs corresponding points located image coordinate system annotators’ best visual judgment four corners square real world whose center coincides origin table coordinate system. able undo projective distortion perspective effect backprojecting table surface image coordinate system onto world coordinate system. homography matrices scaled appropriately back-projection distance object instances world coordinate system computed. figure shows typical images dataset rectiﬁed versions. clearly main distortions occur objects table plane. object instance annotated object category label plus enclosing polygon. then ellipse vertices polygon estimate object’s shape pose image plane. figure shows example annotated image; figure shows corresponding back-projection vertices annotation polygons plates glasses utensils note non-planar objects often distorted back projection since homography transformation perspective projection points table surface camera’s image plane. hence estimated base vertical objects estimate location table coordinate system since center ﬁtting ellipse back-projection objects’ annotation points good estimate location real world. figure shows top-view visualization annotated scene left using top-view icons corresponding object instances plates glasses utensils scenenet combines binary classiﬁers predicting whether input patch belongs dominant plane. basic architecture catnet scalenet. returns region image plane. given scene geometry camera properties representation image plane. discretize image plane non-overlapping patches corresponding scenenet outputs. corresponding patch belongs zero otherwise. collected annotated table-setting dataset consists images dining room table settings object categories. images dataset collected multiple sources fig. left annotated image table-setting dataset. middle back-projection table plates glasses utensils unit axes centimeter. right top-view visualization table-setting also utilized synthetic table-setting scene renderer veriﬁcation purposes. synthetic image renderer inputs camera’s calibration parameters rotation translation camera’s extrinsic parameters table length width object poses table’s coordinate system outputs corresponding table setting scene. figure shows synthetic images generated renderer. ﬁne-tuned catnet using patches. training contained patches object category patches plate category patches bottle category patches glass category patches utensil category. patch includes multiple object instances repeated training instance. train test patches extracted table-setting dataset using image partitioning scheme explained section object category patches selected annocell patches whose overlap table area less patch. number background training patches chosen twice number patches frequent category evaluated performance catnet test patches. results output catnet provided table shows average scores vector softmax scores returned catnet’s applied patch corresponding class different levels hierarchy. unsurprisingly category scores category increase patch size decreases category present patch leads higher classiﬁcation accuracy achieved patches ﬁner levels annocell hierarchy. evaluated performance scalenet test patches. figure shows confusion matrices test cases classiﬁcation based maximum score class top- score classes. match declared case top- score classiﬁcation true class among scores. seen common mistakes made consecutive classes makes sense since consecutive classes associated consecutive scale ratios closer output distributions. table) test patches background table patches deﬁned having respectively least overlap table surface area. training test patches selected level- level- annocell hierarchy. classify level- patch part table associated level- patches contain report positive detection. ﬁnal table area prediction deﬁned convex hull largest connected component union detected level patches. figure shows estimated table area example images. figure shows examples misdetected off-table patches removed post-processing. figure shows poor table detection example seem happen lack sufﬁcient texture tables. tested table detector images observed fewer poor table detections. estimate table size appropriately scaling diameter length convex hall. scale calculated running scalenet patches level classiﬁed table assuming table-setting objects average size figure shows histogram absolute relative errors made table size estimator. calculated true table size back-projecting annotated table surface using homography estimated annotation images. histogram centered roughly around meaning table size estimator relatively unbiased. experiments conditional inference posterior distribution given accumulated evidence steps described section templates used geometry square tables whose sizes range meters intervals. selected template closest estimated table size nearest neighbors proposed section calculate corresponding homography matrix. then project four corners table image coordinate system using homography matrix check resulting polygon well detected table area using similarity measure d–shapes. declare good homographies obtained sampling camera model ﬁne-tuning parameters exit loop soon met; otherwise condition trials output camera parameters resulting minimum figure shows example consistent homography samples. recall step maximizes mutual information queries mutual information difference moreover under conditional independence assumptions reduces entropy mixture minus mixture entropies cases mixture weights conditional probabilities annobit given evidence. current case queries indexed annocells assumes sixteen possible values corresponding possible subsets four object categories. also scale annobits correspondence classiﬁers consider selection queries; course time execute catnet classiﬁer annocell also execute corresponding scalenet classiﬁer catnet scalenet results shapes distance deﬁned satisﬁes min. attempt efﬁciently sample homography distribution consistent detected table area ﬁrst camera parameters result table projection meeting relaxation namely soon sample start greedily ﬁne–tune camera parameters ﬁnally satisfy ﬁne-tuning randomly choose camera parameter change slightly sampling normal distribution small variance centered previous value; accept change resulted smaller distance total y|ek−) part evidence. weights posterior immediately evaluate mixture entropies since entropy dirichlet distribution closed-form solution. entropy mixture namely y|ek−) dirichlet densities estimate integral monte carlo integration. generate sample mixture distribution monte carlo integration ﬁrst select dirichlet densities probabilities y|ek−) generate cording posterior projecting samples image coordinate system using sampled homography. speciﬁcally projection sampled locations table plane obviously allows answer queries locations image plane appearing deﬁnition annobit. however order determine instances objects contained given annocell measure average sizes instances present need estimate pixels constitute image realization instance sampled. plates utensils effectively simply projected circle plates projected ellipse utensils course ellipses image plane. glasses bottles three-dimensional know image representation larger image ellipse obtained projecting base circle determined sample. also projection objects oriented perpendicular orientation base circle projection. hence estimate projection would obtain instances categories fully image mapping moving center projection center projected base upward along vector orthogonal main axis projected base ellipse; place updated object center distance projected base center equal half size size proportional main diameter projected base. dataset images. step informative questions corresponding annobits maximum mutual informations asked i.e. patches processed cnns. figure shows annocells selected ﬁrst four steps given test image. figure show selected annocells later steps. patches selected later usually ﬁner levels follows coarse-to-ﬁne scene analysis paradigm. however completely plausible actually happened experiments back coarser question asking sequence ﬁner questions. analogously humans focus particular area analyzing scene depending collected evidence zoom collect evidence coarser level. worthy mention difference selection criterion approximate criterion terms resolution level selected patches. according experiments approximate selection criterion usually starts selecting coarser patches compared selection criterion speciﬁcally approximate criterion starts level- whereas exact criterion starts level- mainly fact approximate criterion ignores error rates classiﬁers selection stage replacing know classiﬁers accurate ﬁner levels leads encouragement selection using criterion note criterions questions selected early steps usually coarser progressively reﬁne interesting contrast criterions. support criterion assume alice walks bookstore brooklyn bookstore clerk search novel remember title. wants book alice looking asking questions informative time alice provide answer them. point asking informative question alice cannot provide accurate answer e.g. alice able tell color cover probably able mention name non-ﬁrst characters novel. selection criterion trying strike tradeoff information gain questions accuracy classiﬁer providing answer them. section consider parsing image results classiﬁers alone i.e. without bayesian model. catnet softmax layer output estimate categories present annocell follows. denote weight category input patch order weights starting categories difference weights previous greater threshold three categories selected cessed images. hence classiﬁers involved explains ripples period ﬁgure. second informative question asked step usually slightly lower conditional mutual information compared informative question next step. naturally mutual information smaller conditional entropy. order deﬁne visualize detections generated sampling posterior distribution superimpose uniform grid size image plane. earlier explained associate pixles projection sampled object instance turn generates rectangular bounding box. center bounding falls cells. cell category aggregate samples category whose center lies cell compute average top-left corner width/height corresponding bounding boxes; take average bounding detection cell. score every detection proportional number projections contributing detection non-maximum suppression detections object category separately; bounding boxes considered neighbors intersection size minimum size greater yields ﬁnal scored detections labeled true positive intersection ground-truth bounding estimated bounding least minimum boxes ratio longest sides otherwise labeled false positive. pose selection criterion declare appropriate bounding detection ensuring particular objects present patch occupy signiﬁcant portion requiring that cˆσsr choice made ˆσsr favors large differences scales. note scalenet returns correct scale among ratios time test set. also assign score output scalenet namely sscale exp/ˆσ finally patch annocell hierarchy given mixed category–scale score category. mixed score given patch scale score sscale c-th category score sscale. declare annocell patch bounding positive detection c-th category sscale among catnet’s top- scores score perform non-maximum suppression mixed scores positive detections category obtain sparse boxes. non-maximum suppression performed picking conﬁdent detection removing neighboring detections; then picking second conﬁdent detection left removing neighbors continuing process positive detections left. consider patches neighbors least smaller patch overlaps bigger patch noted object instance necessarily fall completely inside cell annocell hierarchy certain level even might exist patch size outside hierarchy completely includes object instance. annocell hierarchy constructed overlap neighboring cells level resolution therefore miss object instances given level even cell size large enough include object avoid make hierarchy exhaustive resolution i.e. shifting patches pixel time. figure illustrates detection examples running non-maximum suppression combined scores catnet scalenet. generate pr-curves thresholding scores surviving detections non-maximum suppression. note would like detect many true instances possible mistakes possible invariably necessitates trade-off. figure shows precision–recall curves twelve different methods data images object categories. according figure model-based detection performance improves classiﬁers incorporated model. however full posterior detector seems perform worse information pursuit questions seems counterintuitive expect achieve better performance incorporating evidence. note incorporating classiﬁers necessarily better results classiﬁers’ noise increased likelihood inconsistencies classiﬁers’ output. example consider figure conﬁdent plate detections actually plate bottom glasses; annocells corresponding detections ﬁnest level annocell hierarchy expected chosen later selection criterion potentially degrade detection performance. hence integrating classiﬁers would result poorer inference added classiﬁers inconsistency. note model integrates scalenet outputs attempt suppress conﬁgurations scale inconsistency however since multiplication catnet scalenet data model used posterior sampling consider conditional independence assumption catnet scalenet dirichlet distributions) model able completely suppress conﬁguration output catnet scalenet networks large enough compensate smaller one. figure included curves modelbased detection variations rand. rand. number questions tests except questions chosen random; also included result classiﬁers patches randomly chosen processed. result randomly selected questions almost questions asked emphasizes importance efﬁcient question selection bayesian approach. bayesian approach provides natural framework unifying evidence collected running tests prior knowledge encoding contextual relations different scene entities. experiments demonstrate makes significant difference choose patches appropriately using strategy versus randomly choosing them. addition saving time takes process patches provide much information monitor conﬁdence detections stop processing patches uncertainty saturates starts increase case conﬂicting evidence. modelbased approach enough questions asked outperforms classiﬁers result running classiﬁer small fraction randomly selected annocells achieve high recall figure show qualitative model based detections based full posterior random selection patches. detections based outperform random selection number patches. proposed approach multi-category object recognition called information pursuit sequentially investigates patches input test image order come accurate description processing patches possible. approach follows bayesian framework prior model incorporates contextual relations different scene entities spatial distributions modeled non-parametrically chosen follows lplateutensil lplateglass lutensilutensil lbottleglass means example allow three utensils adopted plate instance. describe pose distributions starting root objects. category table region divided parts rectangular strip width starting edges remainder interior region. object’s center placed central region probability outer strip probability conditionally choice distribution uniform within area. plates represented circles table glasses bottles ellipsoids vertical principal direction rotation invariant around axis. utensils represented horizontal ellipses orientation following mises distribution whose mean degrees orientation nearest table edge. dispersion parameter mises distribution zero instance located farther centimeters sides table greater zero otherwise. note mises distribution zero dispersion parameter basically uniform distribution simplicity object sizes ﬁxed specify pairwise pose distributions category pose parent object radial distribution conditional angular distribution polar system centered location parent object. model relative pose parent-child object pair assuming relative location independent relative orientation. chose scaled beta distribution radial distance pairs parent-child objects either mises uniform distribution angular location child periphery parent object. normally expect c-category parent c-category child within distance order justify local contextual relationship. denote user-deﬁned distance. scale semantic relations among object instances consistency scales constraints imposed coplanarity objects etc. proof concept applied approach tablesetting scenes. designed novel generative model attributed graphs ﬂexible structure node graph corresponds object instance attributed category label pose. scene generation model model directly used framework statistics calculated samples used learn markov random field model employed directly whereas scene generation model could learned efﬁciently limited number annotated images model offered faster conditional inference. entropy pursuit search strategy selects patches input image sequentially investigates collect evidence scene. investigate patch utilized stateof-the-art convolutional neural networks introduced dataset fully annotated tablesetting scenes learn scene generation model train battery classiﬁers test performance algorithm. summary studied possibility generating scene interpretation investigating fraction patches input image using entropy pursuit bayesian approach. bayesian framework natural approach integrating contextual relations evidence collected using tests. able show choosing right patches right order identify accurate interpretation processing fraction patches input image. work categories {plate bottle glass utensil} amongst annotated categories table-setting dataset. instances placed table whose geometric properties denoted simpliﬁed case table rectangular respectively represent length width table. consider world coordinate system whose origin located center table’s surface whose axis orthogonal table’s surface assuming rectangular table axes parallel edges table illustrated figure also deﬁne coordinate systems attached camera shown figure beta distribution used radial distance object pair kept ﬁxed throughout design learning. pose distribution parameters therefore includes beta mises distributions’ parameters different categories. distribution rotation angles deﬁned conditionally translation denote orthonormal axes world coordinates axes camera coordinates following constraints used letting denote angle deﬁning rotation angles mapping take conditionally independent given translation marginals mises distribution means angles explicitly given formula sin−", "year": 2017}