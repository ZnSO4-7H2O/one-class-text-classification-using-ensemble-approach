{"title": "The Web as a Knowledge-base for Answering Complex Questions", "tag": ["cs.CL", "cs.AI", "cs.LG"], "abstract": "Answering complex questions is a time-consuming activity for humans that requires reasoning and integration of information. Recent work on reading comprehension made headway in answering simple questions, but tackling complex questions is still an ongoing research challenge. Conversely, semantic parsers have been successful at handling compositionality, but only when the information resides in a target knowledge-base. In this paper, we present a novel framework for answering broad and complex questions, assuming answering simple questions is possible using a search engine and a reading comprehension model. We propose to decompose complex questions into a sequence of simple questions, and compute the final answer from the sequence of answers. To illustrate the viability of our approach, we create a new dataset of complex questions, ComplexWebQuestions, and present a model that decomposes questions and interacts with the web to compute an answer. We empirically demonstrate that question decomposition improves performance from 20.8 precision@1 to 27.5 precision@1 on this new dataset.", "text": "neural models trained large datasets great progress nearing human-level performance however analysis models revealed mostly excel matching questions local contexts struggle questions require reasoning. moreover assumes documents information relevant answer available questions complex even retrieving documents difﬁcult. conversely work semantic parsing focused primarily compositionality questions translated compositional programs encode sequence actions ﬁnding answer knowledge-base however reliance manually-curated limited coverage applicability semantic parsers. paper present framework broad i.e. assume information retrieved documents compositional i.e. compute answer must perform computation reasoning. thesis answering simple questions achieved answering complex questions timeconsuming activity humans requires reasoning integration information. recent work reading comprehension made headway answering simple questions tackling complex questions still ongoing research challenge. conversely semantic parsers successful handling compositionality information resides target knowledge-base. paper present novel framework answering broad complex questions assuming answering simple questions possible using search engine reading comprehension model. propose decompose complex questions sequence simple questions compute ﬁnal answer sequence answers. illustrate viability approach create dataset complex questions complexwebquestions present model decomposes questions interacts compute answer. empirically demonstrate question decomposition improves performance precision precision dataset. humans often want answer complex questions require reasoning multiple pieces evidence e.g. from country winner australian open women’s singles answering questions broad domains quite onerous humans requires searching integrating information multiple sources. combining search engine model. thus answering complex questions addressed decomposing question sequence simple questions computing answer corresponding answers. figure illustrates idea. model decomposes question ﬁgure sequence simple questions submitted search engine answer extracted search result. answers gathered ﬁnal answer computed using symbolic operations union intersection. evaluate framework need dataset complex questions calls reasoning multiple pieces information. adequate dataset missing created complexwebquestions dataset complex questions builds webquestionssp dataset includes pairs simple questions corresponding sparql query. take sparql queries webquestionssp automatically create complex queries include phenomena function composition conjunctions superlatives comparatives. then amazon mechanical turk generate natural language questions obtain dataset question-answer pairs data analysis shows examples diverse workers perform substantial paraphrasing original machine-generated question. propose model answering complex questions question decomposition. model uses sequence-to-sequence architecture utterances short programs indicate decompose question compose retrieved answers. obtain supervision model perform noisy alignment machine-generated questions natural language questions automatically generate noisy supervision training. evaluate model complexwebquestionsand question decomposition substantially improves precision humans able reach precision limited time budget leaving ample room improvement future work. figure computation tree what city birthplace author ‘without end’ hosted euro leaves strings inner nodes functions applied children produce answers goal learn model given question black model answering simple questions simpqa produces computation tree decomposes question computes answer. model trained question-computation tree pairs ti}n question-answer pairs ai}n computation tree tree leaves labeled strings inner nodes labeled functions. arguments function children sub-trees. compute answer denotation tree recursively apply function root children. formally given tree rooted node labeled function children defigure provides example computation tree running example. notice words leaves necessarily original question e.g. city paraphrased cities. broadly framework allows paraphrasing questions helpful function simpqa. paraphrasing better interaction model recently suggested buck nogueira deﬁned function simpqa answering simple questions fact comprises components work. first question submitted search engine retrieves list snippets. next model extracts answer snippets. possible train model jointly question decomposition work pre-train separately later treat black box. functions formal language take arguments return values strings sets strings sets numbers. functions includes simpqa model answering simple questions takes string argument returns strings numbers answer. comp function takes string containing unique variable answers. e.g. figure ﬁrst argument birthplace second argument {ken follett adam zagajewski}. function replaces variable answer string representation returns union. formally comp ∪a∈asimpqa denotes string produced replacing similar function composition join operation λ-dcs string function applied previously-computed values. takes sets returns intersection. operations deﬁned analogously. syntactic sugar allow conj take strings input means simpqa obtain perform intersection. root node figure illustrates application conj. logical operations semantic parsing superlative comparative questions like what highest european mountain? what european mountains higher mont blanc? answered joining european mountains elevation. could functions formal language answering questions cumbersome would extract list entities numerical value each. instead handle constructions using simpqa directly assuming mentioned verbatim document. evaluating framework requires dataset broad complex questions examine importance question decomposition. many datasets developed recently lack focus importance question decomposition. datasets contain simple questions answered short input document. recently triviaqa presented larger portion complex questions still require reasoning. moreover focus triviaqa answer extraction documents given. conversely highlight question decomposition ﬁnding relevant documents. differently complementary question decomposition used part implementation simpqa. section demonstrate question decomposition useful different approaches. dataset collection generate complex questions dataset webquestionssp contains questions paired sparql queries freebase questions broad simple. thus sample question-query pairs automatically create complex sparql queries generate automatically questions understandable workers paraphrase natural language compute answers executing complex sparql queries freebase obtain broad complex questions. figure provides example procedure elaborate next. generating sparql query create four types complex queries conjunctions superlatives comparatives compositions. table gives exact rules generation. conjunctions superlatives comparatives identify queries webquestionssp whose denotation a|a| generate query whose denotation strict subset conjunctions done traversing looking sparql triplets added yield valid comparatives superlatives numerical property common triplet restrictor accordingly. compositions entity replace variable triplet denotation triplet {e}. machine-generated questions workers paraphrase sparql queries natural language need present understandable form. therefore automatically generate question paraphrase. generate sparql queries predicates added query manually annotated templates mapping predicates text different compositionality types templates modify original webquestionssp question according meaning generated sparql query. e.g. template nsbook.author.works written author wrote obj. brevity provide details supplementary material. question rephrasing used workers paraphrase questions natural language question paraphrased worker validated workers. generate diversity workers bonus edit distance paraphrase high compared question. total workers involved examples produced average cost question. table gives example compositionality type. drawback method generating data queries generated automatically question distribution artiﬁcial semantic perspective. still developing models capable reasoning important direction natural language understanding complexwebquestions provides opportunity develop evaluate models. summarize examples contains question answer sparql query snippets harvested model attempting answer question. renders complexwebquestions useful semantic parsing communities. dataset analysis complexwebquestions builds webquestions questions webquestions usually properties entities often ﬁlter semantic type answer webquestions also contains questions refer events multiple entities complexwebquestions contains semantic phenomena four compositionality types generating composition questions conjunctions superlatives comparatives which school ernest rutherford attended latest founding date? which countries bordering mexico army size less where river originates shannon pot? table rules generating complex query query query returns variable contains entity denote replacement entity variable pred pred predicates entity numerical value variable type freebase refers events. last column provides example question type. tion. similarity lemmas match cosine similarity according glove embeddings threshold otherwise. matrix allows estimate whether parts question re-ordered paraphrased conjunction questions composition questions word re-ordering happened illustrating substantial changes question made. figure illustrates matrix pair questions re-ordering. last webquestions almost questions start wh-word complexwebquestions questions start another word showing substantial paraphrasing original questions. qualitative analysis randomly sampled examples development manually identiﬁed prevalent phenomena data. present types table along frequency. examples conjunct question becomes modiﬁer wh-word question substantial word re-ordering questions occurred minor word re-ordering occurred workers used synonym examples omitted words examples added lexical material obtain intuition operations useful model analyzed examples types operations applied question question decomposition. found splitting question insufﬁcient cases word question needs copied multiple questions decomposition moreover words appear question need added cases questions examined similarity. using normalized edit-distance dice coefﬁcient found questions different questions similarity distribution wide support also found workers tend shorten question richer vocabulary created heuristic approximating amount word re-ordering performed workers. every question constructed matrix similarity token question token quesmovies howard play minutes long? actor played hancock high school? vienna austria number building ﬂoors body water kineshma bridge start movies miley cyrus play involves organization cirkus? bangkok place amusement park opened earliest? would like develop model translates questions arbitrary computation trees arbitrary text tree leaves. however requires training denotations using methods maximum marginal likelihood reinforcement learning difﬁcult optimize. moreover approaches involve issuing large amounts queries search engine training time incurring high costs slowing training. instead develop simple approach paper. consider subset possible computation trees allows automatically generate noisy full supervision. follows describe subset computation trees considered representation method automatically generating noisy supervision pointer network model decoding. representation represent computation trees sequence tokens consider trees compositional operation. denote sequence question tokens decoded sequence consider following token sequences comp sequence tokens corresponds following computation tree comp) concatenation operator. used questions substring answered simpqa answers replace variable computing ﬁnal answer. representation supports compositional operation single copying operation allowed without re-phrasing. future work plan develop general representation require training denotations. supervision training denotations difﬁcult involves querying search engine frequently expensive. therefore take advantage original sparql queries questions generate noisy programs composition conjunction questions. note noisy programs used supervision avoid costly process manual annotation model assume sparql queries way. generate noisy programs sparql queries following manner first automatically identify composition conjunction questions. generated question exactly identify split points question. then rulebased algorithm takes alignment matrix approximates split points question index copy conjunction questions. line figure corresponds known split point question blue approximated split point question. details rulebased algorithm supplementary material. thus obtain noisy supervision composition conjunction questions train model translates questions representations {comp conj} integer indices. pointer network representation points indices input thus pointer networks sensible choice. because also need decode tokens comp conj augmented pointer networks every question augmented question created appending tokens comp conj allows decode representation pointer network decoding step points token augmented question. encode onelayer decode one-layer attention liang difference decode tokens augmented question rather ﬁxed vocabulary. trained model decodes comp conj representations sometimes using simpqa without decomposition better. handle cases following assume always access score every answer provided ﬁnal invocation simpqa following rule decide decoded representation simpqa. given scores answers given scores given simpqa return single answer highest score. intuition conﬁdence provided scores simpqa correlated answer correctness. future work train directly denotations handle logical functions uniform manner. experimental setup used examples complexwebquestions training development test training pointer network composition conjunction examples. hidden state dimension pointer network used adagrad combined regularization dropout rate initialize -dimensional word embeddings using glove learn embeddings missing words. simple model simpqa function download web-based model talmor model sends question google’s search engine extracts distribution answers top- snippets using manually-engineered features. re-train model data feature every question candidate answer mention snippet rasor model output logit score feature. found combining web-facing model talmor rasor resulted improved performance. human sample random development questions manually answer questions google’s search engine including available information. limit amount time allowed answering minutes. table presents results development test sets. simpqa decompose questions obtained performing question decomposition substantially improve performance upper bound perfect knowledge decompose given splitqaoracle rcqa obtained lower performance simpqa trained data different distribution. importantly splitrcqa outperforms rcqa points illustrating model also beneﬁts question decomposition despite fact created question decomposition mind. shows importance question decomposition retrieving documents model extract answers. googlebox ﬁnds correct answer cases showing complex questions challenging search engines. found answer correct exact string match gold answers failed; time required compute answer beyond capabilities; could answer web; ambiguous nature; involved paraphrasing errors workers; additional contain correct gold answer. splitqa decides decompose questions based conﬁdence simpqa. questions model chooses decompose question rest sends question as-is search engine. strategies works model chooses right cases. moreover answerable questions strategy yields correct answer. evaluate ability pointer network mimic labeling heuristic development set. model outputs exact correct output sequence time allowing errors word left right accuracy token-level accuracy allowing one-word errors shows splitqa learned identify decomposition points questions. also observed often splitqa produced decomposition points better heuristic e.g. what place birth lyricist roman holiday splitqa produced lyricist roman holiday heuristic produced place birth lyricist roman holiday. additional examples splitqa question decompositions provided table complexquestions examine ability web-based models experiment complexquestions small dataset question-answer pairs designed semantic parsing freebase. simpqa dataset obtained slightly lower compq best system operates directly freebase. analyzing training data found decompose comp questions rule splits question words when during appear e.g. vice president question find actress played hailey rogers label signed what colors sports team whose arena stadium at&t stadium what amusement park located madrid spain includes stunt fall ride which university whose mascot trojan derek fisher attend president?. decomposed questions rule obtained analyzing development errors found occasionally splitqarule returns correct answer fails string-match gold answer. manually ﬁxing cases development reaches note compq suffer string matching issue operates directly freebase thus guaranteed output answer correct form. short experiment shows web-based model rival semantic parser works simple question decomposition beneﬁcial leads results comparable state-of-the-art. work related body work semantic parsing particular datasets focus complex questions triviaqa wikihop race distinction proposing framework complex focuses question decomposition. work related chen watanabe combined retrieval answer extraction large documents. work entire propose question decomposition ﬁnding information. work also closely related dunn buck start questions directly assume documents given. buck also learn phrase questions given black model focus paraphrasing address decomposition. using black model challenging assume differentiability reproducibility difﬁcult black boxes change time. nevertheless argue setups provide holistic view problem shed light important research directions going forward. another important related research direction iyyer answered complex questions decomposing them. however used crowdsourcing obtain direct supervision gold decomposition assume supervision. moreover work tables interact search engine entire web. paper propose framework answering complex questions based question decomposition interaction web. develop model framework demonstrate improves complex performance datasets using models. also release dataset complexwebquestions including questions sparql programs answers snippets harvested model. believe dataset serve semantic parsing communities drive research compositionality push community work holistic solutions references artzi zettlemoyer. weakly supervised learning semantic parsers mapping instructions actions. transactions association computational linguistics bollacker evans paritosh sturge taylor. freebase collaboratively created graph database structuring human knowledge. international conference management data pages buck bulian ciaramita gesmundo houlsby gajewski wang. right questions active question reformulation reinforcement learning. arxiv preprint arxiv. polosukhin fandrianto kelcey berthelot. wikireading novel large-scale language understanding task wikipedia. association computational linguistics hill bordes chopra weston. goldilocks principle reading children’s books international explicit memory representations. conference learning representations joshi choi weld zettlemoyer. triviaqa large scale distantly supervised challenge dataset reading comprehension. association computational linguistics krishnamurthy mitchell. weakly emsupervised training semantic parsers. pirical methods natural language processing computational natural language learning pages zettlemoyer collins. learning sentences logical form structured classiﬁcation probabilistic categorial grammars. uncertainty artiﬁcial intelligence pages generating types sparql query create four complex queries conjunctions superlatives comparatives compositions. conjunctions superlatives comparatives identify sparql queries webquestionssp whose denotation a|a| generate query whose denotation strict subset also discard questions contain answer within machine-generated questions. machine-generated questions workers paraphrase sparql queries natural language need present understandable form. therefore automatically generate question paraphrase. generate sparql queries predicates added query manually annotate templates mapping predicates text different compositionality types annotate templates context several machine-generated questions ensure result templates understandable language. templates original webquestionssp cording meaning sparql query. nsbook.author.works written author wrote obj. table shows various examples templates. replaced turn actual name according freebase object hand. freebase represents events contain multiple arguments using special node knowledge-base called represents event connected figure overview data collection process. blue text denotes different stages term addition green represents value intermediate text connect term seed question fuse templates original webquestionssp natural language questions templates contain lexical material glues back question conditioned compositionality type. example conj questions coordinating phrase author wrote produce born london author wrote obj. first word distribution webquestions almost questions start wh-word complexwebquestions questions start another word showing substantial paraphrasing original questions. figure shows distribution ﬁrst words questions. which school ernest rutherford attended latest founding date? which countries bordering mexico army size less where river originates shannon pot? table rules generating complex query query query returns variable contains entity denote replacement entity variable pred pred predicates entity numerical value variable type freebase refers events. last column provides example question type. freebase predicate nsbook.author.works written nsaviation.airport.airlines nsaviation.airline airport presence.airline nsaward.competitor.competitions nsﬁlm.actor.ﬁlm nsﬁlm.performance.ﬁlm figure illustrates ﬁnding split point conj questions using equation line figure corresponds known split point question blue estimated split point question. created heuristic approximating amount global word re-ordering performed workers creating noisy supervision. every question constructed matrix similarity token question token question. similarity lemmas match cosine distance according glove embedding threshold otherwise. allows compute approximate word alignment question question tokens assess whether word re-ordering occurred. natural language conj question length machine-generated question length known split point index algorithm ﬁrst computes best point split question assuming re-ordering. done iterating candidate split points returning split point figure heat similarity matrix question. line indicates known split point. blue line approximated split point. below graph candidate split point score.", "year": 2018}