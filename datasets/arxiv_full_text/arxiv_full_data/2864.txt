{"title": "ARMDN: Associative and Recurrent Mixture Density Networks for eRetail  Demand Forecasting", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Accurate demand forecasts can help on-line retail organizations better plan their supply-chain processes. The challenge, however, is the large number of associative factors that result in large, non-stationary shifts in demand, which traditional time series and regression approaches fail to model. In this paper, we propose a Neural Network architecture called AR-MDN, that simultaneously models associative factors, time-series trends and the variance in the demand. We first identify several causal features and use a combination of feature embeddings, MLP and LSTM to represent them. We then model the output density as a learned mixture of Gaussian distributions. The AR-MDN can be trained end-to-end without the need for additional supervision. We experiment on a dataset of an year's worth of data over tens-of-thousands of products from Flipkart. The proposed architecture yields a significant improvement in forecasting accuracy when compared with existing alternatives.", "text": "tens millions sale events frequent discounting price geographically distributed customer base competitive interactions positive side pervasive nature eretail huge customer bases online mode transactions wealth data could exploited build accurate models demand prediction. example flipkart active catalogue million products daily footfall million page visits sells average million units day. much previous demand prediction methods relied statistical time-series methods arima state space models capture parameters like seasonality trends. however traditional time-series models incapable taking account number associative factors strong inﬂuence short term buying decisions including factors like deep-discounting bundle offers aggressive merchandising campaigns competitor trends factors lead wild ﬂuctuations weekly basis sharp spikes. non-trivial nature problem dictates advanced machine learning approaches capable handling multidimensional feature space drives demand. ﬁrst method choice boosted cubist model powerful regression model combines four learning ideas regression tree capture non-linear feature interaction linear regression model leaves nearest neighbor reﬁnement ﬁnally boosted ensemble. this related models like gradient boosted decision trees found highest performing many prediction challenges. failing cubist similar regressors scalar prediction model requires special pre-processing capture sequential predictions time-series. also motivated impressive success modern deep learning methods various speech text image processing tasks next focused neural network model demand forecasting problem. however soon found straight-forward deployment recurrent neural networks time series forecasting failed provide gains beyond existing regression models flipkart’s challenging dataset. paper present many design engineering challenges tackle implementing modern deep-learning model substantially out-performed ﬁrst generation boosted cubist model. accurate demand forecasts help on-line retail organizations better plan supply-chain processes. challenge however large number associative factors result large non-stationary shifts demand traditional time series regression approaches fail model. paper propose neural network architecture called ar-mdn simultaneously models associative factors time-series trends variance demand. ﬁrst identify several causal features combination feature embeddings lstm represent them. model output density learned mixture gaussian distributions. ar-mdn trained end-to-end without need additional supervision. experiment dataset year’s worth data tens-of-thousands products flipkart. proposed architecture yields signiﬁcant improvement forecasting accuracy compared existing alternatives. pvldb reference format srayanta mukherjee devashish shankar atin ghosh nilam tathawadekar pramod kompalli sunita sarawagi krishnendu chaudhury. ar-mdn associative recurrent mixture density networks eretail demand forecasting. pvldb xxxxyyyy https//doi.org/tbd retail industry accurate sales forecasts essential timely buying replenishment inventory top-line demand planning eﬀective supply-chain utilization errors predicting demand adversely aﬀects multiple business critical metrics out-of-stock percentage inventory health wastage power logistical resources. paper present tackle challenges demand forecasting inventory management flipkart india’s largest eretail company. permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. articles volume invited present results international conference large data bases august janeiro brazil. proceedings vldb endowment vol. copyright vldb endowment -//. https//doi.org/tbd mdn) eﬀectively combine time-series associative factors. ar-mdn outputs probability distribution demands mixture gaussians show crucial capture unpredictable trends demands heterogeneous settings ours. provide engineering solutions training models along hierarchies products geography demonstrate role carefully designed feature sets. point sales data contains sales transaction number properties potentially inﬂuenced purchase event. span various properties item sold geography sold events/properties characterizing time sale. creating forecast model ﬁrst decision choosing level granularity representing dimensions item geography time. work focus demand prediction inventory management replenishment demand needs estimated level. inventory typically replenished weekly basis hence generate weekly forecast demand. further supply chain perform eﬃciently customer demands nearest warehouse. therefore along geography dimension assess demand warehouse fulﬁllment center level. succinctly make predictions highlight main contributions work here. present design ar-mdn deep-learning based forecast model grapple scale heterogeneity largest eretail store india. proposed model incorporates number careful design ideas including mixture gaussians output layer practical training methodology trade-oﬀ sparsity diversity staged feed-forward recurrent layer fuse associative temporal features. experiments flipkart’s sales data show wellengineered deep learning models indeed live hype signiﬁcantly better state nondeep learning based method. ar-mdn causes reduction error compared boosted cubist. show speciﬁc neural architecture significantly better oﬀ-the-shelf deep learning time series models. somewhat surprisingly observe feature engineering continues useful even deep learning models improvement performance engineered features. section present overview extensive literature forecasting models. section present ar-mdn proposed deep learning based model. section compare performance proposed model stateof-the-art traditional model time series forecasting traditional time series methods. traditional time series methods like box-jenkins variations state space models like arima holt-winters used demand forecasting industry long time. reason popularity simplicity. methods produce admirable results many cases retail demand forecasting methods perform poorly. primary reason failure presence several exogeneous casual factors make demand curve highly erratic sharp peaks valleys. further sales time series often non-stationary heteroscedastic thus violating core assumptions classical methods. additionally large eretail stores like flipkart product landscape huge making demand curve function substitutable complementary products well. alleviate problems number innovations attempted recent years review next. wavelet-based approaches. popular approach tackle non-stationarity time-series data wavelet transforms advantage eﬀectively decompose time series component frequency time thereby allowing identiﬁcation primary frequency components. example ﬁnancial time series prediction multiple approaches used modeling market fractional brownian motion. also used preprocessing multiple methods artiﬁcial neural network kalman ﬁltering model variant proposed stolojescu using stationary preprocessing step arima linear regression random walk. overall combined performed best among four models eﬀectively capturing non-linearity. also compared various mother wavelets concluded haar reverse biorthogonal suitable task. zheng soltani renauld also explored haar mother wavelet time-series forecasting problems. however wavelet based methods unsuccessful producing acceptable results case primarily inability account causal features lead sharp changes demand. regression-based methods. another approach generic machine learning regressors along autoregressive features capture time-series comparison diﬀerent classes regression methods found work wang torgo regression methods rely minimizing squared errors similar objective functions achieving balance bias variance model. particularly robust high-performing models traditionally support vector regression uses non-linear kernel functions random forests averages independent individual decision trees iii) gradient boosting iteratively reduces residual errors using models. cubist hybrid decision trees linear regression models predictions reﬁned nearest neighbor adjustment. cubist regression method also found perform admirably compared popular regression techniques forecasting problems highlighted works zhang meyer walton however cubist regression based methods designed explicitly model time-series data. instead extract intermediate features based time-series treated independent variables learning model. deep learning methods. deep neural networks recently proven tremendous potential modeling tough classiﬁcation regression problems. ﬁrst work time-series based forecasting using deep neural networks busseti energy load forecasting. implemented compared multiple methods including deep feed-forward network deep recurrent network amongst found perform best. similarly extended fully connected lstm convolution like features problem precipitation forecasting localized region short time period future. experiments able capture spatio-temporal features better outperformed traditional methods. andeep learning methodology used time-series forecasting problems deep belief networks applied ensemble dbns aggregated together support vector regression model problem energy load forecasting. takashi kuremoto used multiple restricted boltzmann machines optimized particle swarm optimization aninnovative approach proposed mocanu used factored conditional energy load forecasting. method also used additional associative features like electricity price weather conditions time series only. retail forecasting requires probabilistic forecasting output results mostly mixed using modern deep-learning techniques recently though flunkert used probabilistic lstm deepar autoregressive recurrent able demonstrate signiﬁcant improvements. success learn global model across time-series items instead relying time-series single product alone. similar strategy follow work. second propose model output gaussian likelihood real-valued data negative binomial likelihood positive count data. contrast approach mixture gaussians output density model. importantly article holds particular signiﬁcance ﬁeld able eﬀectively demonstrate applicability modern deep learning techniques problem demand forecasting eretail. figure proposed three-stage architecture associative recurrent mixture density networks model unrolled across time using lstm. time instant associative features modeled mlp. ﬁnal prediction layer uses loss. details given section geographical region time series weekly demand values point time measured weeks. point time series also associated causal features. features ﬁxed properties product change along time. describe below. features capture large variety properties product time product’s price time advertisements surrounding sales event table presents features extracted point sales data grouped diﬀerent clusters. further feature could numerical categorical binary. features data e.g. price product also large number interesting features derived based intuitive understanding consumer behavior. example consider derived feature called time since last price change. observed price decreased demand increases brief time period. beyond time period even price maintained demand rate decays quickly stabilizes back section show tremendous impact derived features. figure architecture multi-layer perceptron network models associative layer. causal associative features grouped buckets described table embeddings learned represent categorical -hot features. fully-connected layer used compress concatenated embeddings dense dimensional space. embeddings lstm models time-series information. forecasting given consecutive future time horizons corresponding input features xit+ them. need predict corresponding demand values ˆyit+ ˆyit order capture uncertainty associated predictions propose output distribution instead ﬁxed value. parametric model trains parameters predict distribution proposed model combines multi-layer perceptron long-short term memory network simultaneous handling associative time-series features mixture density network output ﬂexibly capture output uncertainty. ﬁnal model ar-mdn therefore associative recurrent probabilistic. figure shows representation overall deep architecture. follows present detailed descriptions three main stages model. associative layer primary motivation behind layer treat associative variables drive demand. thus associative layer functionally analogous regression-based figure representation mixture density network layer also output layer ar-mdn. receives input output recurrent lstm layer. learns fully-connected layer predicts mixture gaussians along probability choosing gaussian. eﬀectively models multi-modal output space predicted value could sampled several gaussians. representative architecture feed-forward neural network models associative layer presented figure features ﬁrst bucketed types illustrated figure table features price time buckets continuous simply normalized zero mean unit variance. rest feature buckets composed categorical -hot features embedded suitable feature space size following this entire features concatenated embedded lower-dimensional space ﬁnal embedding executed using single fclayer exponential linear unit activation shown better numerical stability popular relu recurrent layer mentioned earlier weakness regression based models explicitly model time-series data. model needs capture short-term longterm signals present time-series data. achieve this output associative layer recurrent neural network popular type lstm associates cell input gate output gate forget gate. memory unit lstm cell stores hidden representation sequence input data seen till given time instant. lstm cell learns either update reset memory unit depending given sequence values. lstm model integrates output associative model along previous demand inputs along time-series captures seasonality mean past weeks’ price mean past weeks’ sale units sales peak price changes reverts quickly previous volume units sold dips immediately after sale event captures newness product table list associative features identiﬁed model demand given product. features extracted time instant includes features recorded sale data derived features computed signals. multi-modality signals need modeled task clear data-type column. vector next output layer state stored layer used computing outputs next time step. view auto-regressive features automatically computed deep network. hence combining ability factor associative features explicit treatment sequential nature time-series lstm ar-mdn able harness signals embedded within data better either layers alone. layer output typical neural network minimizes meansquared softmax loss function. however neither losses suitable towards modeling variation demand curve seen example figure minimizing squared error yields output follows single gaussian distribution would powerful enough model variation output space. softmax hand generalization sigmoid function models multinoulli output distribution. instead central hypothesis used modeling output distribution case regression performed multi-modal. figure density plot time-series data figure clearly multi-modal results multiple values similar values since gaussian mixtures natural representation kind problems mixture density network output layer hypothesis intuitively robust considering many external factors accounted model. therefore considering gaussian mixtures conditional distribution equated figure example time-series demand particular sku. observe large number peaks valleys time-series. obvious simple time-series model cannot explain data needs model associative factors contribute variance. gaussian mixture density time-series obvious values time series best represented multi-modal gaussian motivates layer output model. along geography dimension handle hierarchies diﬀerently. train ﬁrst total demand national level subsequent step distributed level according historical ratios. necessitated fact data level quite sparse causal factors like oﬀers additional visibility applied national level implemented regional levels. historical sales data available regional granularity. remove outliers data based weeks history compute percentage sales contribution region respect overall national demand. using ratios divide national level forecast regional level sales demand. loss function. since last layer outputs probability distribution demand values resort maximum likelihood principle training model parameters. given parameter deﬁnition output layer loss function model given loss known highly unstable essentially because division sigma equation since predicted value neural network become arbitrarily small. lead exploding activations consequently exploding gradients. prevent employed activation clipping. value sigma clipped range allowed successfully train model. number mixtures empirically chosen hyper-parameter tuning. learned parameters output layer corresponding mixture probability variance mean respectively. softmax function equation ensures values required probabilities. model distribution factorized product likelihood factors time. conditional distribution network therefore trying model function ar-mdn output given equation likelihood terms expressed given scale diversity products sold large eretail store like flipkart single model parameters products store appropriate given large ﬂuctuations sale patterns products within store. extreme training separate model raises challenges data sparsity particularly emerging products. next discuss strategy balancing conﬂicting challenges product heterogeneity data sparsity training learned model. trading data heterogeneity sparsity training. ﬁrst trained joint model combining skus across verticals. vertical products belong category. example verticals could laptops headphones etc. ﬁnetuned model vertical training skus within vertical. augment relative sparsity data table comparison weekly wmape ar-mdn boosted cubist across four weeks three diﬀerent test windows. ar-mdn clearly out-performs cubist model test cases. performance widens prediction horizon increases ar-mdn stable time. weeks contain major sale event marked asterix please section discussion. note wmape measure lesser better. section show detailed evaluation diﬀerent forecasting models flipkart’s operational data. compare best eﬀort traditional model modern deep learning based model aware earlier comparisons families models large-scale industrial setup ours. next justify various design choices ar-mdn model showing comparisons existing simpler variants. experiments particularly signiﬁcant rich diversity feature space stresses limits state-ofthe-art approaches smaller public domain datasets cannot. evaluation metric. since downstream business usecase forecasting pipeline buying replenishment inventory forecasting errors skus sell larger number units larger negative impact equivalent error skus sell lesser units. hence error metric chosen weighted mean absolute percentage error time given equation training test data. data used experiments collected october march evaluate model three distinct test periods duration weeks each weeks test data remaining data used training data. experiment example week demands weeks week ar-mdn predictions obtained week compared actual demand weeks respectively. implementation. ar-mdn implemented using tensorflow trained single titan cores ram. used adam optimizer exponential learning decay policy decaying learning rate every iterations. training combined model took around days vertical ﬁne-tuning took additional days. total training process therefore took around week. time includes evaluation carried epoch. running trained model takes ms/sku -core intel xeon machine. also used dropout lstm input cells prevent overﬁtting. used mini batch gradient descent sampling skus minibatch randomly. sequence length chosen maximum sequence length mini batch. zero padding done rows less data sequence length batch. later masked loss zero padded data points. lstm dynamically unrolled sequence length. methods compared. section discussed number methods demand forecasting. present comparisons existing methods stages ﬁrst select best breed non-deep learning based method compare that. next compare various architectures among deep learning models. eliminated pure time-series based models like arima early inability capture eﬀect large number exogeneous factors causing large swings outputs. among regression methods best performing method committee cubist models. cubist extension quinlan’s model model skillfully combines three learning structures decision trees top-level capture non-linearity regression models leaves encourage smooth predictions ﬁnally nearest neighbor based reﬁnement. trained committee cubist models boosting. values ﬁxed time-slice validation. cubist models used features ar-mdn outlined table however since cubist scalar regression model time series model created autoregressive features temporal features figure comparison ar-mdn cubist across vertical level sample categories test dataset. ar-mdn model performs better cubist categories insights experiment discussed section along time. speciﬁcally used auto-regressive features like mean sale previous week mean sale previous month; temporal features like week year time since ﬁrst sale/launch. figure towards deploying model prediction wmape less considered reliable enough automate replenishment process. show percentage skus actionable across various weekly time horizons compared across ar-mdn solution baseline cubist. ar-mdn predictions clearly actionable across larger skus. performance also slightly worse weeks multi-day large sale event occurred opposed business usual weeks i.e. weeks feature large sale events. discuss event weeks section another important parameter success called hits deﬁned number skus forecasts actionable i.e. average percentage error less across three testing windows. cutoﬀ chosen based business inputs. ar-mdn %/%of skus hits -week-out -weeks-out forecasts respectively corresponding numbers cubist model %/%. hence similar trend holds ar-mdn outperforms cubist diﬀerence notable prediction time horizon larger. finally measure quality models level. figure show number skus lesser cutoﬀ error across weeks. based figure concluded almost skus actionable replenishment completely automated based described models. figure performance ar-mdn model compared actual sale values baseline example skus. training data left vertical line test period right. shown week contained major sale event hence spike number units sold. sale event week testing. discussion section better across certain verticals consistent performance across product classes. figure show performance models vertical level becomes clear performance fairly consistent models. however verticals ar-mdn better cubist model verticals. since verticals homogeneous skus decision making unit business process perspective signiﬁcant data point. decision models would adopted business process depends overall performance models vertical. given number skus numerous practically possible make choice model level. therefore given performance ar-mdn would widely integrated business process opposed cubist. figure show performance ar-mdn cubist representative skus test window ﬁrst skus time. point week contains large sale event. general skus dataset show sharp increase demand event week trend observed well. however skus represent slightly diﬀerent classes terms sale trend discuss individually below. conﬁdentiality reasons unable reveal actual product corresponding sku. representative products demand business-as-usual weeks. however show orders-of-magnitude jump demand sale event response associative factors drive large event. ar-mdn clearly outperforms cubist picking drastic change demand. cubist pick increasing figure comparison ar-mdn alternative neural-network model architectures level. clear complete ar-mdn architecture outperforms ablated models. note -weeks-out test case contained major sale event hence particularly large error. represents generally show moderate steady sales week demand jumps sharply event week. here ar-mdn cubist well picking trend non-event time points ar-mdn clearly outperforms cubist estimating magnitude demand jump event week. sharp jumps prior event increasing trend maintained event week. skus typically warm-up offers actual event cater interests additional visitors website response marketing campaigns. cubist ar-mdn successful modeling pre-event week rise demand. however ar-mdn correctly detects continuing increasing tread correctly cubist fails example representative skus relatively products. show overall increasing trend boosted sale event. cubist ar-mdn moderately successful ar-mdn slightly better predicting nonevent event week demand. representative products display wildly ﬂuctuating demands weekly basis sharp peaks deep valleys various known latent associative factors. event weeks show sharp rises magnitude rise observed non-event weeks well. cubist fails detecting inherent ﬂuctuating trends forecasts steady decrease ar-mdn much better modeling sharp rises falls. figure comparison prediction error without derived features. though derived features obtained features model cannot explicitly capture novel signals. model beneﬁts including several expert-designed features could lessen complexity machine learning. ar-mdn model composed three modular subparts; associative layer lstm recurrent layer iii) output layer. stated above rationale modular architecture useful associative features aﬀecting demand lstm handles sequential aspects demand necessary handle multi-modality output space. question naturally arises whether hypothesis fact correct whether three subparts integral performance machine. further much performance aﬀected without particular sub-part. quantify series experiments performed removing component time armdn model. therefore developed r-mdn a-mdn compared complete ar-mdn model. existing deep learning models time series predictions based purely lstm neither mixture gaussian multilayer associative model overall experiments prove layers hybrid ar-mdn architecture integral performance layers working tandem unleash full modeling prowess machine. deep learning promises remove need feature engineering many speech image processing tasks promise largely experiments show environment highly heterogeneous features products features engineered domain experts continue extremely useful. section described number derived functions. features used capture inherent easily derivable properties time series price discounting related observations. figure plot error without hand engineered features. features signiﬁcant impact reducing error. features particularly useful predictions future recurrent features tend less useful. flipkart tends hold small large scale events frequently spanning multiple days characterized larger usual discounts aggressive marketing campaigns strong word-of-mouth advertising. event weeks also tend higher number unknowns latent variables like regional festivals matching competitor events launch popular coveted product etc. importantly weeks also time maximizing opportunity supply-chain stressed higher volumes. business planning events also happen earlier usual generally weeks advance. therefore error forecasts event weeks disproportionately aﬀects business critical metrics compared business-as-usual weeks. test windows weeks contain events. comparison cubist table amply clear ar-mdn better models weeks contain major sales event. average wmape weeks ar-mdn cubist respectively. given volume sales observed weeks diﬀerence performance alone suﬃcient motivation production scale armdn. highlights potency hybrid architecture deployed ar-mdn. snapshot provided figure weeks window test set. event week weeks-out represented time point figure. r-mdn worst performing alternatives models omit associative layer beats vanilla lstm model. reinforces intuitive belief eﬀect associative factors largest event weeks. another interesting observation though a-mdn retain associative layer models outperforms single gaussian. mentioned above event weeks also peppered latent variables noise tolerance brought clear advantages. complete ar-mdn machine signiﬁcantly outperforms architectures including a-mdn highlighting even weeks associative factors hold greater importance additional temporal features captured recurrent layer adds value. observations also hold true weeks test windows. work develop uniﬁed architecture simultaneously model causal factors time-series trends multi-modal output spaces. machine trained end-to-end reasonable time large real-world dataset. results show proposed architecture easily outperforms state-of-the-art model based boosted decision trees. deep learning based solutions found adept automatic feature learning structured data images speech. however problems multimodal data spans numerical categorical binary time-series modalities deep learning beneﬁts heavily so-called expert-designed features. similar observation also made previously aspects evaluate future eﬀect prediction errors metrics logistics cost adherence overall customer satisfaction. modeling evaluating aspects interesting beyond scope work. future work shall focus forecasting diﬀerent would interesting examine solution proposed work could apply directly granularities; would require non-trivial redesign architecture. similarly interesting exploration would re-use learned model certain granularity initialize model diﬀerent granularity. mocanu nguyen gibescu larsen pinson. demand forecasting aggregation levels using factored conditional restricted boltzmann machine. power systems computation conference pages moody lizhong. true price? state space models high frequency data. proceedings ieee/iafe conference computational intelligence financial engineering pages mohamed jaitly senior vanhoucke nguyen sainath kingsbury. deep neural networks acoustic modeling speech recognition shared views four research groups. ieee signal processing magazine carlsson. features oﬀ-the-shelf astounding baseline recognition. proceedings ieee conference computer vision pattern recognition workshops cvprw pages wong chun woo. convolutional lstm network machine learning approach precipitation nowcasting. proceedings international conference neural information processing systems predict internet traﬃc. communications circuits systems west sino expositions senior. deep mixture density networks acoustic modeling statistical parametric speech synthesis. proceedings ieee international conference acoustics speech signal processing pages", "year": 2018}