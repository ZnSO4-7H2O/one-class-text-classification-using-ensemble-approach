{"title": "PAC-Bayesian Majority Vote for Late Classifier Fusion", "tag": ["stat.ML", "cs.CV", "cs.LG", "cs.MM"], "abstract": "A lot of attention has been devoted to multimedia indexing over the past few years. In the literature, we often consider two kinds of fusion schemes: The early fusion and the late fusion. In this paper we focus on late classifier fusion, where one combines the scores of each modality at the decision level. To tackle this problem, we investigate a recent and elegant well-founded quadratic program named MinCq coming from the Machine Learning PAC-Bayes theory. MinCq looks for the weighted combination, over a set of real-valued functions seen as voters, leading to the lowest misclassification rate, while making use of the voters' diversity. We provide evidence that this method is naturally adapted to late fusion procedure. We propose an extension of MinCq by adding an order- preserving pairwise loss for ranking, helping to improve Mean Averaged Precision measure. We confirm the good behavior of the MinCq-based fusion approaches with experiments on a real image benchmark.", "text": "literature often consider kinds fusion schemes early fusion late fusion. paper focus late classiﬁer fusion combines scores modality decision level. tackle problem investigate recent elegant well-founded quadratic program named mincq coming machine learning pac-bayes theory. mincq looks weighted combination real-valued functions seen voters leading lowest misclassiﬁcation rate making voters’ diversity. provide evidence method naturally adapted late fusion procedure. propose extension mincq adding orderpreserving pairwise loss ranking helping improve mean averaged precision measure. conﬁrm good behavior mincq-based fusion approaches experiments real image benchmark. combining multimodal information important issue multimedia research effort dedicated problem survey). indeed fusion multimodal inputs bring complementary information various sources useful improving quality multimedia analysis method semantic concept detection audio-visual event detection object tracking etc. different modalities correspond generally relevant features grouped different views. example classical visual textual features commonly used multimedia based tf-idf words texture color sift spatio-temporal descriptors etc. features extracted another step consists using machine learning methods order build classiﬁers able discriminate given concept. main schemes generally considered snoek early fusion approach available data/features merged feature vector learning classiﬁcation steps. seen unimodal classiﬁcation. however kind approach deal heterogeneous data features sometimes difﬁcult combine. late fusion model works decision level combining prediction scores available modality. usually called multimodal classiﬁcation classiﬁer fusion. late fusion always outperform unimodal classiﬁcation. especially modality provides signiﬁcantly better results others deal imbalanced input features. however late fusion scheme tends give better results learning semantic concepts case multimodal video snoek several methods based ﬁxed decision rule proposed combining classiﬁers product kittler approaches often referred stacking wolpert need extra learning step. paper address problem late multimodal fusion decision level stacking. classiﬁer gives score associated modality instance classical method consists looking weighted linear combination different scores linear weighting scheme seen majority vote. approach widely used robustness simplicity scalability small computational costs atrey also appropriate exist dependencies views important issue optimal combine scores. solution machine learning methods assess weights atrey machine learning standpoint considering classiﬁers high diversity generally desirable property dietterich illustration given algorithm adaboost freund schapire frequently used multimodal fusion method. adaboost weights classiﬁers according different distributions training data introducing diversity requires least weak classiﬁers perform well. another recent approach based portfolio theory wang kankanhalli proposes fusion procedure trying minimize risks different modalities correlation measure. well-founded needs deﬁne appropriate functions completely fully adapted classiﬁer fusion problem since directly take account diversity outputs classiﬁers. propose study machine learning method namely mincq introduced laviolette proposes quadratic program learning weighted majority vote real-valued functions called voters algorithm based minimization generalization bound takes account risk committing error diversity voters offering strong theoretical guarantees learned majority vote. article show interest algorithm classiﬁer fusion. provide evidence mincq able good linear weightings also performing non-linear combination extra kernel layer scores. since multimedia retrieval performance measure related rank positive examples propose extend mincq improve mean average precision. base extension additional order-preserving loss verifying ranking pairwise constraints. paper organized follows. section deals theoretical framework mincq. extend mincq late fusion method section concluding section evaluate empirically mincq late fusion section section present algorithm mincq laviolette laviolette learning q-weighted majority vote real-valued functions method based pac-bayes theory mcallester ﬁrst recall setting mincq. consider binary classiﬁcation tasks feature space dimension label space training sample example drawn i.i.d. ﬁxed unknown probability distribution deﬁned consider space real-valued voters given voter predicted label given sign] sign otherwise. then learner aims choosing distribution weights leading q-weighted majority vote lowest risk. deﬁned constraint restrictive since every distribution represented quasi-uniform distribution laviolette assumptions actually elegant trick avoid prior distribution often required usual pac-bayesian method mcallester making algorithm easily applicable. pac-bayesian mincq proposed particular context binary classiﬁcation objective minimize misclassiﬁcation rate q-weighted majority vote taking account diversity voters. multimedia indexing standpoint mincq thus appears natural late classiﬁers fusion combine predictions classiﬁers separately trained different modalities. −hn} associated prediction functions opposites. step fusion achieved mincq learn q-weighted majority vote lowest risk. however many applications multimedia document retrieval people interested performance measures related precision recall. since low-error vote necessarily good ranker propose adaptation mincq improve popular mean averaged precision recj percentage positive examples intuition behind deﬁnition prefer positive examples score higher negative ones. achieve goal propose learn pairwise preference f¨urnkranz h¨ullermeier pairs positive-negative instances. indeed pairwise methods known good compromise accuracy complex performance measure like map. especially notion order-preserving pairwise loss introduced zhang context multiclass classiﬁcation. following idea proposed svm-based method hinge-loss relaxation map-loss. speciﬁc case mincq multimedia fusion design orderpreserving pairwise loss correctly ranking positive examples. actually pair want forced minimizing following hinge-loss relaxation previous equation deal hinge-loss consider m+×m− additional slack variables ξs+×s− ≤j+≤m+≤j−≤m− weighted parameter make little abuse notation highlight difference since ξs+×s− appear linear term simply formulation. obtain quadratic program unit vector size however drawback method incorporation quadratic number additive variables makes problem harder solve. overcome problem propose relax constraints considering average score negative examples force positive examples higher average negative scores. leads following alternative section show empirically interest mincq extension late fusion method stacking experiment mincq-based approaches pascalvoc’ benchmark everingham goal list visual concepts identify images. corpus constituted training test images. general ratio positive negative examples less concept generate training sample constituted training positive examples negative examples independently drawn positive ratio keep original test set. objective provide best results benchmark rather evaluate mincq-based methods could helpful late fusion step multimedia indexing. split training sample subsets size. consider different visual features sift percepts local color histograms color moments. then train svm-classiﬁer visual feature kernel parameters tuned cv). ﬁnal classiﬁer fusion learned second series propose introduce non-linear information kernel layer. represent example vector scores svm-classiﬁers kernels sample seen voter compare method stacking tuned note report results context computational cost much higher performance lower. full pairwise version implies many variables penalize resolution right ﬁrst experiments clearly linear mincq-based algorithms outperform average linear baselines. least mincq-based method produces highest except boat hbest best. note order-preserving hinge-loss really helpful classical shows best map. fact explained limited number voters. left kernel layer least mincq-based method achieves highest better svm. moreover incqrbf averaged pairwise preference best concepts showing order-preserving loss good compromise improving keeping reasonable computational cost. globally kernel-based mincq methods outperform methods. moreover least mincq-based approach best concept showing pac-bayesian mincq good alternative late classiﬁers fusion. propose paper make well-founded learning quadratic program called mincq novel multimedia late fusion method. pac-bayesian mincq originally developed binary classiﬁcation aims minimizing error rate weighted majority vote considering diversity voters laviolette context multimedia indexing claim mincq thus appears naturally appropriate late classiﬁer fusion order combine predictions classiﬁers trained different modalities. experiments show mincq competitive alternative classiﬁer fusion. moreover incorporation average order-preserving constraints sometimes able improve map-performance measure. beyond results pac-bayesian methods open door deﬁne theoretically well-founded frameworks design algorithms many multimedia tasks multi-modality indexing multi-label classiﬁcation ranking etc.", "year": 2012}