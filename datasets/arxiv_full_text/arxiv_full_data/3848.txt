{"title": "CUNI System for the WMT17 Multimodal Translation Task", "tag": ["cs.CL", "cs.NE", "I.2.7"], "abstract": "In this paper, we describe our submissions to the WMT17 Multimodal Translation Task. For Task 1 (multimodal translation), our best scoring system is a purely textual neural translation of the source image caption to the target language. The main feature of the system is the use of additional data that was acquired by selecting similar sentences from parallel corpora and by data synthesis with back-translation. For Task 2 (cross-lingual image captioning), our best submitted system generates an English caption which is then translated by the best system used in Task 1. We also present negative results, which are based on ideas that we believe have potential of making improvements, but did not prove to be useful in our particular setup.", "text": "paper describe submissions multimodal translation task. task best scoring system purely textual neural translation source image caption target language. main feature system additional data acquired selecting similar sentences parallel corpora data synthesis back-translation. task best submitted system generates english caption translated best system used task also present negative results based ideas believe potential making improvements prove useful particular setup. recent advances deep learning allowed inferring distributed vector representations textual visual data. models combining text vision modalities representation used shared data type. unlike classical natural language processing tasks everything happens within language across languages multimodality tackles language entities relate extra-lingual reality. tasks multimodal translation whose goal using cross-lingual information automatic image captioning. system-description paper describe submission multimodal translation task. particular discuss effect mining additional training data usability advanced attention strategies. report results rest paper organized follows. section introduces tasks handle paper datasets provided task. section summarizes state-of-the-art methods applied task. section describe models results achieved. section presents negative results section concludes paper. challenge multimodal translation task exploit cross-lingual information automatic image caption generation. stateof-the-art models machine translation automatic image caption generation similar architectures generating target sentence. simplicity combine learned representations various inputs single deep learning model inevitably leads question whether combining modalities lead interesting results. shared task explored subtasks different roles visual textual modalities. multimodal translation task input model image caption english. system output german french translation caption. evaluated using meteor bleu scores computed single reference sentence. question task tries answer whether possible visual information disambiguate translation. supplied english caption during training. evaluation method differs task using reference captions instead single one. task german target language. motivation task explore ways easily creating image captioning system language existing system another language assuming information transfer less complex across languages visual textual modalities. flickrk image described independently acquired captions english. images multik dataset enriched crowdsourced german captions. additionally single german translation english captions added image. round competition additional french translation included task test sets developed. test sets provided task ﬁrst consists instances similar test used previous round competition second consists images captions translastyle structure reference sentences flickrmscoco-based test sets differs. sentences multik dataset similar structure relatively simple subject active verb present tense simple object location information contrastingly captions mscoco dataset less formal capture annotator’s uncertainty image content last year’s submission employed neural system combined multiple inputs image source caption smt-generated caption. used attention mechanism textual sequences concatenated context vectors decoder step. knowledge huang ﬁrst showed improvement textual-only neural system model utilizing distributed features explicit object recognition. calixto improved state using model initializing decoder state image vector maintaining rest neural architecture unchanged. promising results also shown delbrouck dupont made small improvement using bilinear pooling. elliott k´ad´ar brought improvements introducing imagination component neural network architecture. given source sentence network trained output target sentence jointly predicting image vector. model uses visual information regularization thus able additional parallel data without accompanying images. figure overall picture multimodal model using hierarchical attention combination input. here normalized coefﬁcients computed attention models i-th input decoder. models based encoder-decoder architecture attention mechanism implemented neural monkey decoder uses conditional grus hidden units word embeddings dimension target sentences decoded using beam search beam size exponentially weighted length penalty parameter empirically estimated german french. rate used vocabularies maximum tokens sub-word units. textual encoder bidirectional network units direction word embeddings dimension last convolutional layer vgg- network dimensionality image processing. model optimized using adam optimizer learning rate early stopping based validation bleu score. multimodal context vector concatenation decoder multimodal hierarchical attention combination context vectors computed independently modality combined together using another attention mechanism depicted figure task cross-lingual captioning conducted sets experiments subtask. them used attentive image captioning model crosslingual captioning decoder ﬁrst subtask. ﬁrst idea experimented using multilingual decoder provided image language identiﬁer. based identiﬁer decoder generates caption either english german. speculated information transfer visual language modality difﬁcult part task might similar english german. second approach tried steps. first trained english image captioning system larger datasets. second translated generated captions multimodal translation system ﬁrst subtask. trained neural character-level language model german sentences available training part multik dataset. used network hidden units character embedding size select sentence pairs also parallel data. scoring german part several parallel corpora news commentary commoncrawl able retrieve hundreds in-domain sentences. reason also included sentences lower scores ﬁltered using following rules sentences must tokens must present tense must contain non-standard punctuation numbers multiple digits acronyms named entities must rate w.r.t. multik training vocabulary. extracted additional indomain parallel sentences using rules. examples additional data given table applying approach french versions corpora pable extract additional in-domain sentences. thus trained english-to-french models constrained setup only. following calixto backtranslated german captions german side multik dataset sentences retrieved sdewac corpus. included back-translated sentence pairs additional training data textual multimodal systems task back-translation system used architecture textual systems trained multik dataset only. additional parallel data data sdewac corpus used text-only systems because accompanied images. zwei m¨anner unterhalten sich talking kleines m¨adchen sitzt einer schaukel little girl sitting swing eine katze braucht unterhaltung discussion dieser knabe streichelt schlagzeug professional petting drums task best performing system textsystem trained additional data. acquired data selection method described back-translation. results setups task given table surprisingly including data task training decreased meteor score test sets. might caused domain mismatch. however case additional parallel sdewac data problem likely outweighed advantage training data. case multimodal systems adding approximately amount data increased performance case text-only system. suggests sufﬁcient amount data multimodal system would eventually outperform textual one. hierarchical attention combination brought major improvements concatenation approach test sets. test concatenation approach yielded better results considered somewhat strange result given similarity flickr test sets. baseline system nematus trained textual part multik only. however score suspect model trained suboptimal parameters principle model identical constrained textual submission. table results task bleu meteor points. denotes constrained conﬁguration unconstrained test ‘flickr’ ‘mscoco’ denote test sets. unconstrained textual models differ using additional textual data used training multimodal systems. task none submitted systems outperformed baseline captioning system trained directly german captions multik dataset. results systems task shown table english captioning trained models. first trained flickrk data only. second included also mscoco dataset. although captioning system trained data achieved better performance english side extremely performance plugged multimodal translation systems hypotheinterestingly systems task scored poorly bleu score relatively well meteor score. attribute fact unlike bleu puts emphasis precision meteor considers strongly also recall. addition submitted systems tried number techniques without success. describe techniques since believe might relevant future developments ﬁeld despite current negative result. beam rescoring similarly lala oracle experiments validation data showed rescoring decoded beam width potential improvement meteor points. oracle experiment always chose sentence highest sentence-level bleu score. motivated observation conducted several experiments beam rescoring. trained classiﬁer predicting whether given sentence suitable caption given image. classiﬁer hidden layer units inputs last layer vgg- network processing image last state bidirectional network processing text. used hyperparameters bidirectional network textual encoders experiments. training data taken parts multik dataset negative examples randomly sampled dataset classes represented equally. classiﬁer achieved validation accuracy german french. rescoring hypotheses beam selected highest predicted probability image’s caption. experiments tried train regression predicting score given output sentence. unlike previous experiment built training data scored hypotheses output beams obtained translating training part multik dataset. tested architectures ﬁrst concatenates terminal states bidirectional networks encoding source hypothesis sentences image vector; second performs attentive average pooling hidden states rnns image using encoders terminal states queries concatenates context vectors. regression estimating either sentence-level bleu score chrf score another technique tried without success self-critical sequence training modiﬁcation reinforce algorithm sequenceto-sequence learning uses reward training-time decoded sentence baseline. systems pre-trained word-level cross-entropy objective hoped ﬁnetune systems using reinforce towards sentence-level bleu score gleu score appeared difﬁcult right moment optimization criterion switched optimal mixing factor cross-entropy loss reinforce loss. hypothesize complex objective mixing strategy submission multimodal task tested advanced attention combination strategies challenging context achieved competitive results compared submissions. explored ways acquiring additional data task tested promising techniques bring improvement system performance. ozan caglayan walid aransa yaxing wang marc masana mercedes garc´ıa-mart´ınez fethi bougares lo¨ıc barrault joost weijer. multimodality help human machine translation image captioning? proceedings first conference machine translation. association computational linguistics berlin germany pages http//www.aclweb.org/anthology/w-. systematic comparison smoothing techniques sentence-level bleu. ninth workshop statistical machine translation. association computational linguistics baltimore maryland pages http//www.aclweb.org/anthology/w-. jean-benoit delbrouck st´ephane dupont. multimodal compact bilinear pooling mulcorr timodal neural machine translation. abs/.. http//arxiv.org/abs/.. michael denkowski alon lavie. meteor automatic metric reliable optimization evaluation machine translation systems. proceedings sixth workshop statistical machine translation. association computational linguistics edinburgh united kingdom pages http//www.aclweb.org/anthology/w-. desmond elliott stella frank khalil sima’an lucia specia. multik multilingual englishgerman image descriptions. corr abs/.. http//arxiv.org/abs/.. jindˇrich helcl jindˇrich libovick´y. neural monkey open-source tool sequence learnprague bulletin mathematical lining. guistics https//doi.org/./pralin-. po-yao huang frederick sz-rung shiang attentionjean chris dyer. translation. based multimodal neural machine proceedings first conference machine translation. association computational linguistics berlin germany pages http//www.aclweb.org/anthology/w/w/w. chiraag lala pranava madhyastha josiah wang lucia specia. unraveling contribution image captioning neural machine translation multimodal machine translation. prague bulletin mathematical linguistics https//doi.org/doi ./pralin--. jindˇrich libovick´y jindˇrich helcl. attention strategies multi-source sequence-to-sequence learning. proceedings annual meeting association computational linguistics association computational linguistics vancouver canada. tsung-yi michael maire serge belongie lubomir bourdev ross girshick james hays pietro perona deva ramanan piotr doll´ar lawrence zitnick. microsoft coco common objects context. corr abs/.. http//arxiv.org/abs/.. kishore papineni salim roukos todd ward wei-jing zhu. method automatic evaluation machine translaproceedings annual meeting tion. association computational linguistics. association computational linguistics philadelphia pennsylvania pages https//doi.org/./.. bryan plummer liwei wang chris cervantes juan caicedo julia hockenmaier svetlana lazebnik. flickrk entities collecting region-to-phrase correspondences richer int. comput. vision image-to-sentence models. https//doi.org/./s--. character n-gram fproceedscore automatic evaluation. ings tenth workshop statistical machine translation. association computational linguistics lisbon portugal pages http//aclweb.org/anthology/w-. marc’aurelio ranzato sumit chopra michael auli wojciech zaremba. sequence level training recurrent neural networks. corr abs/.. http//arxiv.org/abs/.. steven rennie etienne marcheret youssef mroueh jarret ross vaibhava goel. self-critical corr sequence training image captioning. abs/.. http//arxiv.org/abs/.. rico sennrich orhan firat kyunghyun alexandra birch barry haddow julian hitschler marcin junczys-dowmunt samuel l¨aubli antonio valerio miceli barone jozef mokry maria nadetoolkit neural majde. nematus softchine translation. ware demonstrations conference european chapter association computational linguistics. association computational linguistics valencia spain pages http//aclweb.org/anthology/e-. rico sennrich barry haddow alexandra birch. improving neural machine translation proceedmodels monolingual data. ings association computational linguistics association computational linguistics berlin germany pages http//www.aclweb.org/anthology/p-. international conference machine learning jmlr workshop conference proceedings lille france pages http//jmlr.org/proceedings/papers/v/xuc.pdf. raivis skadin¸ˇs j¨org tiedemann roberts rozis daiga deksne. billions parallel words free building using bookshop corpus. proceedings international conference language resources evaluation european language resources association reykjavik iceland. jason smith herve saint-amand magdalena plamada philipp koehn chris callison-burch adam lopez. dirt cheap web-scale parproallel ceedings annual meeting association computational linguistics association computational linguistics soﬁa bulgaria pages http//www.aclweb.org/anthology/p-. lucia specia stella frank khalil sima’an desmond elliott. shared task multimodal machine translation crosslingual image description. proceedings first conference machine translation. association computational linguistics berlin germany pages http//www.aclweb.org/anthology/w-. j¨org tiedemann. parallel data tools interfaces opus. nicoletta calzolari khalid choukri thierry declerck mehmet ugur dogan bente maegaard joseph mariani odijk stelios piperidis editors proceedings eight international conference language resources evaluation european language resources association istanbul turkey. yonghui mike schuster zhifeng chen quoc mohammad norouzi wolfgang macherey maxim krikun yuan klaus macherey jeff klingner apurva shah melvin johnson xiaobing lukasz kaiser stephan gouws yoshikiyo kato taku kudo hideto kazawa keith stevens george kurian nishant patil wang cliff young jason smith jason riesa alex rudnick oriol vinyals greg corrado macduff hughes jeffrey dean. google’s neural machine translation system bridging human machine translation. corr abs/.. http//arxiv.org/abs/.. jimmy ryan kiros kyunghyun aaron courville ruslan salakhudinov rich zemel yoshua bengio. show atimage caption genertend tell neural david blei ation visual attention. francis bach editors proceedings", "year": 2017}