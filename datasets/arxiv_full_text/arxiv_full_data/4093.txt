{"title": "Sparse distributed localized gradient fused features of objects", "tag": ["cs.CV", "cs.AI"], "abstract": "The sparse, hierarchical, and modular processing of natural signals is related to the ability of humans to recognize objects with high accuracy. In this study, we report a sparse feature processing and encoding method, which improved the recognition performance of an automated object recognition system. Randomly distributed localized gradient enhanced features were selected before employing aggregate functions for representation, where we used a modular and hierarchical approach to detect the object features. These object features were combined with a minimum distance classifier, thereby obtaining object recognition system accuracies of 93% using the Amsterdam library of object images (ALOI) database, 92% using the Columbia object image library (COIL)-100 database, and 69% using the PASCAL visual object challenge 2007 database. The object recognition performance was shown to be robust to variations in noise, object scaling, and object shifts. Finally, a comparison with eight existing object recognition methods indicated that our new method improved the recognition accuracy by 10% with ALOI, 8% with the COIL-100 database, and 10% with the PASCAL visual object challenge 2007 database.", "text": "sparse hierarchical modular processing natural signals characteristics relate ability humans recognise objects high accuracy. paper report sparse feature processing encoding method targeted improving recognition performance automated object recognition system. randomly distributed selection localised gradient enhanced features followed application aggregate functions represents modular hierarchical approach detect object features. object features combination minimum distance classifier results object recognition system accuracies using aloi using coil- databases using pascal visual object challenge database respectively. robustness object recognition performance tested variations noise object scaling object shifts. finally comparison existing object recognition methods indicated improvement recognition accuracy aloi case coil- databases pascal visual object challenge database. humans identify objects naturally recorded images even diverse range natural variability noise pose changes missing features high accuracy speed. robustness accuracy recognition attributed structural functional organisation brain processing. understood hierarchical structure brain processing ability integrate information modular form attributes innate robustness. past idea neuroscience explored computer scientist successfully develop techniques hierarchical temporal networks memory networks cognitive algorithms useful pattern recognition applications. paper inspire hierarchical processing modularity additional constraint sparsity developing features useful automated object recognition. demonstrate incorporating ideas automated object recognition task result improved recognition accuracies. ability brain process information sparse manner allows freedom recognising objects even feature descriptions partial incomplete. property tightly linked functional aspect rather also structural organisation brain. brain constituted billions interconnected neurons information specific object represented activation small number neurons. depending strength signal i.e. frequently object observed human neuron responds distributed manner across neuron network encode store object features. features sparse representation offer several advantages primary advantage ability identify store discriminative information limited number features. since neuronal firing charge governed operation overall energy consumption reduced minimising number neurons used representation object. computing terms reduced complexity data resulting localised feature processing sparsity constraints hierarchy often results lower complexity implementing real-time systems often appreciate data driven scalable parallel computing solution. terms signal processing literature sparse representation sparse coding consists generating basis signal represented linear combination elements main feature sparse representation small number features required representation signals. analogous small number active neurons within large scale neural network corresponds discriminant object features. disadvantage sparse coding technique signal dependant i.e. basis generated signals cannot used others. another major disadvantage associated sparse coding techniques computational complexity possessed techniques. basis computed optimization problem requiring complex computations seen application sparse representation images currently sparse coding images applied many fields image denoising super-resolution face recognition background modelling image classification sparse representation objects inspires number biological vision theories shown result improved computational efficiency sparse representations reduces dimensionality input data thereby simplifying processing data. although reduction redundant information lead reduced feature dimensionality philosophy sparse processing warrant reduction data itself instead reflective preservation useful information. term useful strictly dependent application itself. example object compression useful information reveal reconstruct details object object recognition identifying preserving distinct discriminative features object become useful. paper inspire sparse processing ability human brain developing method hierarchical modular processing features involve sparse pixel selection feature grouping feature encoding feature fusion. resulting features used object recognition application view increase intra-class similarities increase inter-class differences object representations reflected reported recognition accuracies. show steps results improved recognition accuracy object recognition task supports view inspire vision processing biological systems object recognition problems. image features represented pixels represented linear regression problem unknown feature values projected onto lower dimensional space feature vector measurement vector <m×n measurement matrix additive noise. measurement matrix formed random selection feature values images consideration. extraction general ill-posed would non-trivial null space. would mean infinitely many solutions identifying true problem importance question hand signal recovery much serious issue object recognition problem. however discriminative information preserved signal recovery mechanisms ignoring redundant information useful object recognition. direct sparse representation basis <n×n coefficients sufficient approximate signal seen basis pursuit problem. determination process encoding process recovering referred decoding. operations wide range applications nonetheless paper attempt developing encoding scheme. development decoding scheme ignored paper practically required object recognition problem. among leading examples encoding decoding compressive sensing techniques used variety signal processing applications. addition exists several algorithms solving basis pursuit problems treating subset convex optimisation problem applications include signal component separation missing data estimation deconvolution denoising signal representation. although sparsity widely used signal processing view find generic model representing object features much thoughts correlate sparsity constraints critical learning biologically plausible models. common approach impose constraint inhibiting less dominant responses using dominant responses feature encoding incorporate idea biological systems ignore components signals least dominant enforce sparsity criteria. localised nature features another peculiarity object features geometrically spatially connected. however connectedness always ensure distinctiveness recorded images even minor variability test training images results statistically significant differences them. opposed approaches impose geometric constraints ignore geometric constraints form randomised selection features create group features. idea feature groups observed prominent object recognition methods hierarchical processing another major component human brain visual system accommodate feature encoding process. opposed idea hierarchical processing observed propose implement multi-level processing selection dominant features along feature planes followed digital analog conversion. digital analog conversion seen subset aggregate feature fusion method implemented using weighted aggregate operator function proposed feature extraction process inspires hierarchy modular processing sparsity constraints reflect typical characteristics brain cognitive processing. pixels images form primary unit representation object. units arranged spatially across dimensions form region object several regions geometrically placed visually perceptive manner leads image representation object. object information encoded sparse manner within physically functionally localised neuron modules. process encoding features incorporates sparseness constraints enable modular hierarchical processing features. proposed approach creates pixel groups randomly selecting pixels original image across planes. feature groups processed parallel using localised sparse selection aggregation binarization planes fused obtain encoded features. list steps involved proposed system shown fig. formally described algorithm consider quantised model pixels algorithm integers converted binary representation used form image planes. example consider image pixel representation used create planes binary images. image divided several regions feature cells formed distinct regions randomly selecting bits element feature cell formed repeated sparse selection bits random locations region followed summation selected bits. process obtaining feature cell requires stages outlined fig. image binarized along planes binary images given region image binary pixel binary feature randomly selected number times aggregated form binary feature vector partitioned several subsets binary feature element plane determined suppose pixels selected generating feature subset several cells form feature vector image. length feature vector given height width image. value determines whether overlap pixels among cells referred degree overlap. value equal pixels equally shared among cells. value less pixels image selected pixel selection step. contrast value greater pixels selected multiple cells. shows pixel location selected cell cell selected inputs combined using aggregation operator result feature values cell. computing feature values cell elements arrange entire cells several groups group contains number cells. cells computed parallel considered first level modular processing. inside group cell highest value changed remaining cell’s value changed binary operation signify identification dominant value inspired idea neurons brain respond dominant input responses often referred winner-take-all principle repeat operation groups planes. resulting binary feature groups across planes represent dominant feature locations consider second stage modular processing analogy limited number fired neurons across neuron network. final stage final feature vector obtained converting planes integer form. fusion process essentially weighted aggregate operation results global encoded feature vector object. multiple stages localised operations pixel groups indicate hierarchical processing encoded features reflect sparse representation object. human ability detect spatial change neighbourhood pixels. sensory neurons responsible detecting changes responds inter-pixel intensity changes across image space. idea widely used image processing community developing first second order gradient filters calculate gradient features summation weighted differences neighbourhood pixels across entire image. incorporate aspect feature encoding scheme extend idea sparse selection pixel bits aggregative operators gradients pixel intensities. proposed method three different variants features extracted images capture different types object features. first feature vector extracted directly pixel intensity features outlined section remaining feature vectors extracted gradient image. gradient images formed using sobel prewitt operator vector gradient magnitude gradient angles figure proposed feature extraction encoding process illustrated first step input image converted planes second step selects pixels randomly plane region adds values form cell feature third step cells divided groups. example four cells selected form groups. value cell maximum value replaced remaining cells within group form finally i.e. step binary feature vectors combined using weighted addition operation obtain final feature vector where represents convolution operation kernel matrix defines sobel prewitt operators. gradient images horizontal vertical directions respectively. gradient magnitude image formed feature vector generated gradient magnitude image using sparse distributed representation technique illustrated second feature vector generated gradient direction. gradient direction formulated resulting gradient direction image values range avoid complement computations resulting negative numbers range values normalised adding remove negative values. feature vector generated gradient direction image. vector consisting pixel values gradient magnitude gradient direction form primary input algorithm instead pixel values results feature vector three times bigger dimensions however incorporates spatial change features improving robustness feature representation. number times pixels selected number elements feature subset degree overlap factor major parameters proposed object feature extraction method. length feature vector determined parameters. window size determines number pixels used determine value element within feature subset. value greater limited number pixels present image. larger value number pixel values encoded single feature vector cell. larger value ensures wider coverage variations pixels object ensure robustness feature value calculation expense higher computational cost. feature subset cell size determines number inputs given winner take network. number feature vector cells selected value cell highest value changed values remaining cells changed zero. process continued next cells feature vector values changed zero one. cell size increases number pixels applied winner take method also increases result effectiveness algorithm combating local global variations reduced. degree overlap determines whether single pixel used number cells. value greater means single pixel used feature vector cell. less pixel values selected feature representation result loose discriminative information forming object features. optimal parameter values selected experiments explained section explanations given section developed sparse distributed localised gradient fused features along minimum distance nearest neighbour classifier form modules object recognition experiment. minimum distance classification distance test feature vector training feature vectors computed pair least distance selected similar. paper nearest neigbour classification performed three different metrics namely cityblock distance euclidean distance shepard’s similarity measure equations show cityblock distance euclidean distance shepard’s similarity function feature vectors ftrain ftest pair least distance value selected similar pair cityblock distance euclidean distance shepard’s similarity measure pair highest value selected similar pair. shepard’s similarity measure represents perceptive degree similarity sequences rather distance given cityblock euclidean distances. order check performance proposed method object recognition experiments performed three different standard databases namely amsterdam library object images columbia object image library pascal visual object challenge database aloi database contain images different objects coil- database contain images objects. aloi database contains images dimension pixels dimension images coil- database pixels. databases object different images present taken different rotation angle steps training formed choosing images taken intervals. i.e. object class eight images used training set. remaining images used test set. pascal visual object challenge dataset contains images different objects. training consists images test consist images. image required object cropped using given annotations dimension cropped object changed standard size pixels. recognition accuracy calculated percentage images correctly classified. figure shows sample images aloi coil- database. experiments mentioned section feature vector consists pixel values gradient magnitude gradient direction parameter values figure sample images aloi coil- databases. shows object rotations respectively aloi database. shows object rotations respectively coil- database performance system evaluated terms recognition accuracy. recognition accuracy computed ratio number images correctly classified total number images used classification. seven different feature vectors used object recognition formed using different combinations three feature vectors explained section recognition accuracies feature vectors listed table table feature represents feature vector generated image feature represents feature vector generated gradient magnitude image feature represents feature vector generated gradient direction image. features pixmag pixdir magdir pixmagdir represents different combinations features. mentioned section three parameters determine robustness object feature thereby recognition performance. figure shows recognition accuracy proposed method different window sizes different values graph shows effect window size number cells recognition performance. degree overlap determines whether pixel values chosen feature extraction. order analyse effects value fixed values varied value fixed pixel values used atleast computation feature vector. graph seen recognition accuracy increased window size increased. mentioned section feature vector length longer smaller hand recognition accuracy gets increased increases later gets decreased. recognition accuracy higher value value selected final value figure shows variation recognition accuracy different values values fixed respectively. observed slight increase recognition accuracy value increased. value selected pixel value selected twice computation feature vector. experiments feature vector pixmagdir prewitt gradient used. figure graph shows recognition accuracy various window sizes number cells. graph shows recognition accuracy different values feature vector consists pixel values gradient magnitude gradient direction. test effect noise recognition accuracy test images degraded noise recognition accuracy computed. robustness proposed method gaussian noise salt pepper noise speckle noise studied. figures shows recognition accuracy gaussian noise speckle noise different variances added test images. figure shows recognition accuracies salt pepper noise different noise density added test images. observed increase noise levels results reduced recognition accuracy result increased intra-class variability test training images. feature vector consists pixel values gradient magnitude gradient direction parameter values figure shows impact translation recognition accuracy. here test images first subjected pixel translations recognition accuracy computed. shifting done horizontal direction well vertical directions. graph observed recognition accuracy least affected horizontal shifting test images. test robustness proposed technique scaling effect images test images scaled recognition accuracy computed. evident figure proposed method resilient minor changes scaling recognition performance drops increasing variability scaling. figure graphs shows recognition accuracies gaussian noise speckle different noise variances added test images respectively. graph shows recognition accuracies salt pepper noise different noise densities added test images. feature vector consists pixel values gradient magnitude gradient direction. seen graph recognition accuracy gets increased number classes reduced. figure shows plot recognition accuracy number training images class varied. performance system much improved increase number training images. recognition accuracy reaches number training images used which. i.e. images used training recognition accuracy achieved. also accuracy reached images used training. figure graph shows change recognition accuracies test images subjected translation i.e. pixel shifts horizontal vertical directions. graph shows change recognition accuracy test images subjected scaling. feature vector consists pixel values gradient magnitude gradient direction. figure graph shows change recognition accuracies number classes varied. graph shows change recognition accuracy number training images varied. feature vector consists pixel values gradient magnitude gradient direction. proposed method aeroplane bicycle bird boat bottle chair diningtable horse motorbike person pottedplant sheep sofa train tvmonitor average accuracy table shows comparison proposed method commonly used recognition algorithms object recognition aloi coil- databases evident table proposed object recognition algorithm improved recognition accuracy aloi case coil databases compared previous object recognition algorithms. table compares performance proposed method pascal visual object challenge database several algorithms parameters used prewitt mask gradient filter. thus proposed method outperformed previous object recognition methods terms object recognition accuracy. several reasons improved recognition accuracy. distributed pixel selection technique feature extraction provides robustness local variations image. local variations image defined changes occur small regions image. pixel selection step pixels random positions selected added together stored cells. since pixels selected distributed manner local variations also gets distributed among cells effect feature vector gets nullified. type variation occur images global variations causes change pixel values throughout image resulting scaling shifting images illumination changes. inhibition step fig. helps minimising global effect images. inhibition step cells grouped together group cell highest value changed others changed global variation occur values cells increased. inhibition step eliminate effect since cells increased almost value. selection distances measures shepard’s similarity measure also important role increased recognition accuracy. example shepard’s similarity measure known eliminate effect outliers present feature vectors thereby reducing intra-class mismatches improving recognition accuracy. human visual processing system applied develop proposed object recognition system. hierarchy implemented using multi-levels processing involved feature grouping plane processing followed feature encoding. modularity incorporated arranging randomly selecting features groups repeating process several times form multiple feature groups. sparsity constraints imposed random selection features groups binarization within group result exclusion least important information original image. demonstrated improved recognition accuracies proposed method tested amsterdam library object images database columbia object image library database pascal visual object challenge database validating claims hierarchy modular processing sparsity constraints useful concepts implementing automated object recognition. robustness proposed method variability noise scaling horizontal shifts tested. comparison different methods indicated statistically significant improvement recognition accuracies. addition proposed method modular processing ability supports implementation scalable parallel processing architectures. results indicate like object matching methods proposed method scale shift invariant larger variations test train images. addition noise also would impact recognition accuracies linear difference operations gradient filtering improves feature diversity however cannot inhibit noise. remains challenge necessary future work improve robustness method.", "year": 2014}