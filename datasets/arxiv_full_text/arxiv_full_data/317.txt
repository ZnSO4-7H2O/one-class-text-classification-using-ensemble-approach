{"title": "Validation of nonlinear PCA", "tag": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "abstract": "Linear principal component analysis (PCA) can be extended to a nonlinear PCA by using artificial neural networks. But the benefit of curved components requires a careful control of the model complexity. Moreover, standard techniques for model selection, including cross-validation and more generally the use of an independent test set, fail when applied to nonlinear PCA because of its inherent unsupervised characteristics. This paper presents a new approach for validating the complexity of nonlinear PCA models by using the error in missing data estimation as a criterion for model selection. It is motivated by the idea that only the model of optimal complexity is able to predict missing values with the highest accuracy. While standard test set validation usually favours over-fitted nonlinear PCA models, the proposed model validation approach correctly selects the optimal model complexity.", "text": "linear principal component analysis extended nonlinear using artiﬁcial neural networks. beneﬁt curved components requires careful control model complexity. moreover standard techniques model selection including cross-validation generally independent test fail applied nonlinear because inherent unsupervised characteristics. paper presents approach validating complexity nonlinear models using error missing data estimation criterion model selection. motivated idea model optimal complexity able predict missing values highest accuracy. standard test validation usually favours over-ﬁtted nonlinear models proposed model validation approach correctly selects optimal model complexity. nonlinear principal component analysis nonlinear generalization standard principal component analysis restricted linear components nonlinear generalizes principal components straight lines curves hence describes inherent structure data curved subspaces. detecting describing nonlinear structures especially important analysing time series. nonlinear therefore frequently used investigate dynamics diﬀerent natural processes validating model complexity nonlinear diﬃcult task over-ﬁtting caused often limited number available samples; moreover nonlinear over-ﬁtting also occur intrinsic geometry data shown fig. cannot solved increasing number samples. good control complexity nonlinear model required. optimal ﬂexibility curved components. component little ﬂexibility almost linear component cannot follow complex curved trajectory real data. contrast ﬂexible component non-relevant noise data hence gives poor approximation original process illustrated fig. objective model whose complexity neither small large. even though term nonlinear often referred auto-associative neural network approach many methods visualise data extract components nonlinear manner locally linear embedding isomap visualise high dimensional data projecting three-dimensional space. principal curves self organising maps describe data nonlinear curves nonlinear planes dimensions. kernel kernel approach used visualise data noise reduction linear subspaces replaced manifolds neural network approach used nonlinear mapping. work focused auto-associative neural network approach nonlinear model validation problem. supervised methods standard validation technique cross-validation. even though neural network architecture used supervised nonlinear unsupervised method requires validating techniques diﬀerent used supervised methods. common approach validating unsupervised methods validate robustness components moderate modiﬁcations original data e.g. using resampling bootstrap corrupting data small amount gaussian noise techniques motivation reliable components robust stable small random modiﬁcation data. principle techniques could adapted nonlinear methods. would diﬃculty measuring robustness nonlinear components. robustness linear components measured comparing directions slightly diﬀerent conditions since comparing curvature nonlinear components trivial task nonlinear methods require techniques model validation. similar neural network based nonlinear model termed nonlinear factor analysis bayesian framework used weights inputs described posterior probability distributions leads good regularisation. bayesian learning inputs explicitly modelled gaussian distributions maximum likelihood approach work attempts single values network weights inputs. weight-decay regulariser used control model complexity. several attempts model selection auto-associative nonlinear pca. based criterion good local neighbour relation preserved nonlinear transformation nearest neighbour inconsistency term penalises complex models added error function standard test validation used model pre-selection. alternative network architecture proposed solve problems over-ﬁtting non-uniqueness nonlinear solutions. consider natural approach validates model ability estimate missing data. missing data validation used e.g. validating linear models comparing probabilistic nonlinear models based gaussian processes here missing data validation approach adapted validate auto-associative neural network based nonlinear pca. figure problem mis-validation nonlinear using test data set. training samples generated quadratic function plus noise. nonlinear model high complexity leads overﬁtted component validating over-ﬁtted model independent test data gives better test error using original model data generated validate supervised methods standard approach independent test controlling complexity model. done either using data number samples limited performing cross-validation repeatedly splitting original data training test set. idea model best represents underlying process provide optimal results model previously unknown data. test validation works well exist clear target value supervised methods fails unsupervised methods. test data cannot used validate optimal number components standard linear test data also cannot used validate curvature components nonlinear even though nonlinear performed using supervised neural network architecture still unsupervised method hence validated using cross-validation. increasing complexity nonlinear able provide curved component better data space coverage. thus also test data projected onto curve decreased distance hence give incorrect small error. eﬀect illustrated fig. using training test samples generated quadratic function plus gaussian noise standard deviation mean square error given mean squared distances data points projections onto curve. over-ﬁtted well-ﬁtted ideal model compared using test data set. turns test error true original model almost three times larger test error overly complex model over-ﬁts data. test validation clearly favours over-ﬁtted model correct model hence fails validate nonlinear pca. understand contradiction distinguish error superfigure standard auto-associative neural network nonlinear pca. network output required approximate input illustrated ---- network architecture. three-dimensional samples compressed component value middle extraction part. inverse generation part reconstructs sample noise-reduced representation located component curve. vised learning fulﬁlment speciﬁc criteria unsupervised learning. test validation works well supervised methods measure error diﬀerence known target since unsupervised methods target unknown optimize speciﬁc criterion. nonlinear criterion project data shortest distance onto curve. complex over-ﬁtted curve covers data space hence also achieve smaller error test data true original curve. nonlinear performed using multi-layer perceptron auto-associative topology also known auto-encoder replicator network bottleneck sand-glass type network fig. auto-associative network performs identity mapping. output forced approximate input minimising squared reconstruction error extraction function φextr whereas second part represents inverse function generation reconstruction function φgen hidden layer part enables network perform nonlinear mapping functions. using additional units component layer middle network extended extract component. ordered components achieved using hierarchical nonlinear proposed validation approach adapt nonlinear able estimate missing data. done using inverse nonlinear model estimate weights also inputs represent values nonlinear component. optimised simultaneously minimise reconstruction error shown complexity model controlled weight-decay penalty term added since classical test validation fails select optimal nonlinear model illustrated fig. propose evaluate complexity model using error missing data estimation criterion model selection. requires adapt nonlinear missing data done inverse nonlinear model following model selection procedure used optimal weight-decay complexity parameter nonlinear model choose speciﬁc complexity parameter apply inverse nonlinear training data set. validate nonlinear model performance missing data estimation sample randomly independent test elements rejected. mean squared errors randomly moved values nonlinear model used validation generalization error. applied range diﬀerent weight-decay complexity parameters optimal model complexity given lowest missing value estimation error. robust result complexity setting nonlinear repeatedly applied using diﬀerent weight-initializations neural network. median used validation shown following examples. ﬁrst example nonlinear data shows model validation based missing data estimation performance provides clear optimum complexity parameter. second example demonstrates proposed validation ensures nonlinear describe data nonlinear inherent data structure fact linear. figure helical data set. data generated dimensional helical loop embedded three dimensions additive gaussian noise. nonlinear component plotted line. circles show projections data onto curve. nonlinear data consist data one-dimensional manifold helical loop embedded three dimensions plus gaussian noise standard deviation illustrated fig. samples generated uniformly distributed factor range represents angle nonlinear applied using network architecture optimized iterations using conjugate gradient descent algorithm evaluate diﬀerent weight-decay complexity parameters nonlinear applied complete samples generated helical loop function validated using missing data incomplete samples randomly value three dimensions rejected sample easily estimated dimensions nonlinear component correct helical curve. comparison standard test validation samples used. figure model selection. missing data estimation compared standard test validation using helical data nonlinear network model complexity almost linear results high error expected training test data. missing data approach shows expected increase validation error over-ﬁtted models repeatedly done times model complexity newly generated data time. median missing data estimation runs ﬁnally taken validate speciﬁc model complexity. fig. shows results comparing proposed model selection approach standard test validation. turns missing data approach able show clear minimum performance curve. test validation contrast shows small error even complex models. contrary experience supervised learning test error becomes large model over-ﬁts. thus test validation cannot used determine optimal model complexity unsupervised methods. contrast missing value validation approach shows optimal complexity setting weight-decay coeﬃcient range nonlinear also used answer question whether high-dimensional observations driven unimodal multimodal process e.g. atmospheric science analysing ni˜no-southern oscillation applying nonlinear figure nonlinear applied data two-dimensional gaussian distribution. over-ﬁtted models. weight-decay forces nonlinear describe data linear component. even stronger penalty forces single point solution. below missing data approach shows would best impose strong penalty forces network linear solution. misleading model complexity insuﬃciently controlled multimodality incorrectly detected data inherently unimodal pointed christiansen fig. illustrates model complexity high even linear data described nonlinear components. therefore obtain right description data controlling model complexity important. fig. shows validation error curves standard test proposed missing data validation diﬀerent model complexities. median diﬀerently initialized networks plotted. again shown standard test validation fails validating nonlinear pca. increasing model complexity classical test validation shows decreasing error hence favours over-ﬁtted models. contrast missing value estimation error shows correctly optimum would strong penalty gives linear even point solution thereby conﬁrming absence nonlinearity data. correct data consists principle gaussian noise centred point test validation favours over-ﬁtted models produce components incorrectly show multimodal distributions missing data validation conﬁrms unimodal characteristics data. nonlinear combination missing data validation therefore used whether high-dimensional data generated unimodal multimodal process. standard test validation nonlinear model trained using training independent test used compute validation error output nonlinear given test data input. test validation reconstructs test data test data itself. problem approach increasingly complex functions give approximately thus favouring complex models. test validation standard approach supervised applications unsupervised techniques suﬀers lack known target highly complex nonlinear models over-ﬁt original training data principle also able test data better would possible true original model. higher complexity model able describe complicated structure data space. even test samples likely short projecting distance onto curve covers data space almost complete curve moderate complexity problem project data onto position curve. restriction pure test validation. missing data estimation contrast required position curve ﬁxed given remaining available values sample. artiﬁcially removed missing value test sample gives exact target predicted available values test sample. test validation predicts test data test data itself missing data validation predicts removed values remaining values sample. thus transform unsupervised validation problem kind supervised validation problem. paper missing data validation approach model selection proposed applied auto-associative neural network based nonlinear pca. idea behind approach true generalization error unsupervised methods given missing value estimation error classical test error. proposed missing value validation approach therefore seen adaptation standard test validation applicable unsupervised methods. absence target value unsupervised methods replaced using artiﬁcially removed missing values expected target values predicted remaining values sample. shown standard test validation clearly fails validate nonlinear pca. contrast proposed missing data validation approach able validate correctly model complexity. mating missing data available http//www.nlpca.org/matlab.html example apply proposed validation approach found http//www.nlpca.org/validation.html", "year": 2012}