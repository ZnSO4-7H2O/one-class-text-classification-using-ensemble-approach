{"title": "Linking Generative Adversarial Learning and Binary Classification", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "In this note, we point out a basic link between generative adversarial (GA) training and binary classification -- any powerful discriminator essentially computes an (f-)divergence between real and generated samples. The result, repeatedly re-derived in decision theory, has implications for GA Networks (GANs), providing an alternative perspective on training f-GANs by designing the discriminator loss function.", "text": "note point basic link generative adversarial training binary classiﬁcation powerful discriminator essentially computes divergence real generated samples. result repeatedly re-derived decision theory implications networks providing alternative perspective training -gans designing discriminator loss function. imagine given real data distribution feature space wish learn distribution close possible closeness measured divergence function probability distributions. generator typically solving examine method highlighting diﬀerences feeding binary classiﬁer corresponding labels equal proportion typical setup data input discriminator assigned positive label real data optimization problem standard binary classiﬁcation. typically chosen fairly rich class deep binary classiﬁers. means performance close bayes risk i.e. minimum risk measurable functions excess risk changing model class changes second term thm. therefore rich enough excess risk small loss function discrimination problem corresponds almost exactly -divergence. related work manuscript -gan approach knowledge. solves problem minimizing -divergence true distribution changing discriminator objective binary classiﬁcation risk fact convex function well-deﬁned convex conjugate function supt∈r following true correspondences fundamentally link generative adversarial training generation problem well known decision theory. however within literature appear well known lack references address note.", "year": 2017}