{"title": "Not-So-CLEVR: Visual Relations Strain Feedforward Neural Networks", "tag": ["cs.CV", "cs.AI", "cs.LG", "q-bio.NC"], "abstract": "The robust and efficient recognition of visual relations in images is a hallmark of biological vision. Here, we argue that, despite recent progress in visual recognition, modern machine vision algorithms are severely limited in their ability to learn visual relations. Through controlled experiments, we demonstrate that visual-relation problems strain convolutional neural networks (CNNs). The networks eventually break altogether when rote memorization becomes impossible such as when the intra-class variability exceeds their capacity. We further show that another type of feedforward network, called a relational network (RN), which was shown to successfully solve seemingly difficult visual question answering (VQA) problems on the CLEVR datasets, suffers similar limitations. Motivated by the comparable success of biological vision, we argue that feedback mechanisms including working memory and attention are the key computational components underlying abstract visual reasoning.", "text": "matthew ricci∗ junkyung kim∗& thomas serre department cognitive linguistics psychological sciences brown university providence {matthew ricci junkyung thomas serre}brown.edu robust efﬁcient recognition visual relations images hallmark biological vision. here argue that despite recent progress visual recognition modern machine vision algorithms severely limited ability learn visual relations. controlled experiments demonstrate visual-relation problems strain convolutional neural networks networks eventually break altogether rote memorization becomes impossible intra-class variability exceeds capacity. show another type feedforward network called relational network shown successfully solve seemingly difﬁcult visual question answering problems clevr datasets suffers similar limitations. motivated comparable success biological vision argue feedback mechanisms including working memory attention computational components underlying abstract visual reasoning. consider images fig. image left correctly classiﬁed ﬂute deep convolutional neural network quite remarkable feat complicated image includes distractors partially occlude object interest. network trained millions photographs many images accurately categorized thousand natural object categories surpassing ﬁrst time accuracy human observer imagenet classiﬁcation challenge. consider image right. face quite simple compared image left. binary image containing curves. further rather distinguishing property least human curves same. relation items figure images image panel classiﬁed high conﬁdence containing ﬂute contemporary computer vision algorithms. however algorithms struggle learn concept sameness exempliﬁed image curves shown panel image panel sampled svrt challenge task difﬁcult even sometimes impossible contemporary computer vision algorithms including cnns known overlooked. make matters worse issue overshadowed recent success novel class neural networks called relational networks seemingly challenging visual question answering benchmarks. however tested using datasets like sort-of-clevr dataset depicts combinations items handful colors shapes show suffer limitations cnns same-different task shown fig. failure modern computer vision algorithms striking given widespread ability recognize visual relations across animal kingdom human non-human primates rodents birds even insects examining failures existing models critical step path understanding computational principles underlying visual reasoning. knowledge systematic exploration limits contemporary machine learning algorithms relational reasoning problems. previous work fleuret showed black-box classiﬁers fail tasks synthetic visual reasoning test battery twenty-three visual-relation problems despite massive amounts training data. recent work ellis stabinger showed different architectures could solve handful twentythree svrt problems. similarly g¨ulc¸ehre bengio showing cnns fail learn same-different task simple binary sprite items managed train multi-layer perceptron task providing carefully engineered training schedules. however results ellis g¨ulc¸ehre bengio stabinger inconclusive inability feedforward neural networks solve various visual-relation problems reﬂect poor choice hyperparameters particular implementation rather systematic failure entire class feedforward models? here propose systematically probe limits cnns state-of-the-art visual reasoning networks visual-relation tasks. series controlled experiments demonstrate visual-relation tasks strain cnns limitations alleviated speciﬁcally designed tackle visual-relation problems. brief review biological vision literature suggests brain mechanisms working memory attention underlie primates’ ability reason visual relations. argue mechanisms possibly feedback mechanisms needed extend current computer vision models efﬁciently learn solve complex visual reasoning tasks. contributions threefold perform ﬁrst systematic performance analysis architectures twenty-three svrt problems. yields dichotomy visual-relation problems hard same-different problems easy spatial-relation problems. describe novel controlled visual-relation challenge convincingly shows cnns solve same-different tasks rote memorization. show simple modiﬁcation sort-of-clevr challenge similarly breaks state-of-the-art relational network architectures. overall wish motivate computer vision community reconsider existing visual question answering challenges turn neuroscience cognitive science inspiration help design visual reasoning architectures. svrt challenge challenge collection twenty-three binary classiﬁcation problems opposing classes differ based whether stimuli obey abstract rule example problem number positive examples feature items translation whereas negative examples problem positive examples three items largest smaller ones stimuli depict simple closed black curves white background. high-throughput screening approach tested cnns three different depths three different convolutional receptive ﬁeld sizes total nine networks. networks used pooling kernels size convolutional strides pooling strides three fully connected layers. pooling layers used relu activations. twenty-three problems generated million examples split evenly training test sets using code publicly provided fleuret http//www.idiap.ch/˜fleuret/ svrt/. trained nine networks problem total conditions. networks trained using adam optimizer base learning rate results accuracy best networks obtained problem individually shown fig. best-case performance twenty-three problems obtained sorted problems accuracy colored bars blue according svrt problem descriptions provided problems whose descriptions words like same identical colored red. same-different problems items congruent transformation spatial-relation problems whose descriptions phrases like left next touching colored blue. resulting dichotomy across svrt problems striking. evident fig. fact cnns fare much worse problems problems. many problems learned satisfactorily whereas problems resulted accuracy substantially chance. analysis appears tasks pose particularly difﬁcult challenge cnns. result matches earlier evidence visual-relation dicohtomy provided stabinger unknown time experiments. additionally hyperparameter search revealed problems generally equally well-learned across network conﬁgurations less difference ﬁnal accuracy worstcase best-case. hand larger networks generally yielded signiﬁcantly higher accuracy problems smaller ones. results single architecture reported visible dichotomy would stronger. experiment corroborates results previous studies found feedforward models performed badly many visual-relation problems suggests performance cannot simply attributed poor choice hyperparameters. limitations svrt challenge svrt challenge useful surveying efﬁcacy algorithm diverse range visual relations important limitations. first twenty-three problems used challenge constitute somewhat arbitrary sample large conceivable visual relations. obvious connections different problems direct comparison problems generally hard often assume different image structures requiring unique image generation methods resulting different image distributions. example problem requires image contains large object small object. necessary conﬁguration naturally conﬂicts problems problem items must identically-sized positioned without contained other. cases problems simply require different number objects single image instead better compare visual-relation problems would deﬁne various problems images. second using simple closed curves items svrt images makes difﬁcult quantify control image variability function image generation parameters. closed curves perceptually interesting objects procedure used generate prevents quantiﬁcation image variability effect task difﬁculty. result even within single problem svrt unclear whether difﬁculty inherent classiﬁcation rule simply results particular choice image generation parameters unrelated rule. figure synthetic visual reasoning test. show example pair problem problem respectively. nine cnns corresponding different combinations hyper-parameters trained twenty-three svrt problems. shown ranked accuracies best-performing network problem. x-axis indicates arbitrary problem label provided cnns high-throughput analysis found produce uniformly lower accuracies same-different problems spatial-relation problems single purple corresponds problem required detecting samedifferent relation spatial relation simultaneously. figure sample psvrt images. four images shown representing four joint categories image considered different depending whether contains identical different square patterns. image considered horizontal vertical depending whether orientation displacement between items greater images generated baseline image parameters psvrt challenge address issues associated svrt constructed dataset consisting idealized problems dichotomy emerged experiment spatial relations same-different image classiﬁed according whether items image arranged horizontally vertically measured orientation line joining centers image classiﬁed according whether contains identical items. long limit problems simple rules image dataset used problems simply labeling image according different rules image generator produces gray-scale image placing square binary patterns blank background generator uses three parameters control image variability item size image size number items single image. item size refers side-length square patterns controls image variability item level. image size refers side-length input image. thus controls image variability setting spatial extent placement individual items. lastly number items controls item spatial variability since adding item image increase total number possible images factor equal number different patterns item times number positions placed. category label determined whether least identical items image category label determined according whether average orientation displacements pairs items greater equal parameters allowed quantify number possible images dataset denotes number possible permutations elements size highlight parametric nature image samples call test parametric svrt psvrt. image generated ﬁrst drawing joint class label uniform distribution {different same} {horizontal vertical}. ﬁrst item sampled uniform distribution }m×m. then sampled label same identical copies ﬁrst item created. sampled label different identical copies made. rest unique items consecutively sampled. items randomly placed image ensuring least background pixel spacing items. generating images always drawing class labels problems ensures image distribution identical problem types. method architecture details goal experiment examine difﬁculty learning psvrt problems range image variability parameters. first found baseline architecture could easily learn same-different spatial-relation psvrt problems parameter conﬁguration then combination item size image size item number trained instance architecture scratch. training session measured number training examples required architecture reach accuracy measure problem difﬁculty. conditions network trained scratch training accuracy measured. simply wanted estimate difﬁculty ﬁtting training data various conditions hence holdout test set. instance baseline trained scratch condition million training images batch size throughout report best-case result experimental condition random initializations. baseline convolutional network four convolution pool layers four fully-connected layers. ﬁrst convolution layer kernels size followed kernels size subsequent convolution layers. four pool layers interleaved convolution step kernel size strides size fully-connected layers units layer. used dropout last fully-connected layer probability used adam optimizer base learning rate weights initialized xavier method. examine effect network size learnability also repeated experiments larger network control times number units convolution layers times number units fully-connected layers. results conditions found strong dichotomy observed learning curves. conditions learning occurs training accuracy suddenly shoots chance-level gradually approaches accuracy. call sudden dramatic rise accuracy chance-level learning event. although observed variation point learning event takes place rate accuracy eventually reached training runs exhibited learning event also almost invariably reached accuracy within million training images. hand accuracy never reached learning event also almost never took place entire length training. thus ﬁnal accuracy different experimental conditions exhibited strong bi-modality chance-level close fig. report minimum experimental condition random initializations. figure training-to-acquisition curves psvrt image parameters. denotes number training examples needed reach training accuracy. training used million images accuracy never reached random initializations consider problem never learned. ﬁgures show minimum ttas random initializations condition. three curves large plotted. three ﬁgures display curves three image variability parameters item size image size number items found straining effect across image parameters random initializations. learning event took place immediately training begins accuracy reached soon thereafter. however found signiﬁcant straining effect image parameters image size number items example increasing image size progressively increases also making learning event less likely. result network learned random initializations baseline parameter conﬁguration learned images. image size above network never exhibited learning event thus never learned problem. increasing number items produced even stronger straining effect. network never learned problem items image. additionally repeated three sub-experiments considering items congruent rotation multiple relaxation strict same-different rule effectively quadruples number matching images data set. never learned parameter conﬁguration. even though rule technically relaxation strict samedifferent rule concomitant increase number same templates imposes severe strain cnns. hypothesize straining effects reﬂect parameters image size item number contribute image variability. shown above image variability exponential function image size base number items exponent. thus increasing image size keeping number items results quadratic-rate increase image variability increasing number items leads exponential-rate increase image variability. straining effect equally strong cnns twofold difference network width constant rightward shift curve image sizes; transition problem essentially impossible delayed step image size parameter. contrast increasing item size produced visible straining effect cnn. similar learnability preserved stable range item sizes considered. realize possible construct feedforward feature detectors generalize coordinated item variability subtraction templates distinct excitatory inhibitory regions particular spatial arrangement although direct supporting evidence features actually learned training taken together results imply that cnns learn psvrt condition simply building feature tailored particular data instead learning rule network able learn features capture visual relation hand features should deﬁnition minimally sensitive image variations irrelevant relation. experiment suffered increasing increasing image variability simply learn within allotted number training examples. suggests features learned invariant rule-detectors rather merely collection templates covering particular distribution image space. relational network recently santoro proposed relational network architecture explicitly designed detect visual relations tested several tasks. simple feedforward network sits learns pairs high-level feature vectors answers relational questions. relational questions either provided model natural language processed long short-term memory simply hardcoded binary strings. entire system trained endto-end. approach found substantially outperform baseline various visual reasoning problems. sort-of-clevr limitations particular able beat sort-ofclevr task using images simple items scenes items shapes colors trained answer relational questions non-relational questions sort-of-clevr tasks suffers shortcomings. first although solving task requires comparing attributes cued items necessitate learning concept sameness second twelve possible items item variability might encourage model solve relational problems using rote memorization possible item conﬁgurations. indeed johnson found recurrent model struggles learn type generalization task identify attribute object searching using another attribute here understand perform handicaps removed; trained model two-item sort-of-clevr same-different task psvrt stimuli. former task goal measure ability transfer concept same-different training novel objects classic well-studied paradigm animal psychology thus important benchmark models visual reasoning. latter task goal generalization learned item variability high rote memorization longer effective solution. architecture details used software relational networks publicly available https //github.com/gitlimlab/relation-network-tensorflow. convolutional network component model four convolutional layers kernel sizes relu activations intermittent pooling. stride ﬁrst convolutional layers second two. features layer. part system comprised -layer units layer followed -layer units layer. fully connected layers system except last used relu activations. penultimate layer trained dropout. output ﬁnal layer passed softmax function whole system trained cross-entropy loss adam optimizer base learning rate weights initialized using xavier initialization. essentially exact architecture training procedure used original authors conﬁrmed model able reproduce results sort-of-clevr task. results constructed twelve different versions sort-of-clevr dataset missing twelve possible color+shape combinations. images dataset depicted figure example two-item same-different problem posed sort-of-clevr image. accuracy curves trained two-item same-different problem sort-ofclevr dataset twelve item types left out. curve shows accuracy validation data generated using items used training. blue dashed line shows accuracy validation data generated using left-out items. items. half time items dataset trained cnn+rn architecture detect possible sameness scene items measuring validation accuracy left-out images. learning terminated model reached training accuracy. averaged training accuracy validation accuracy across left-out conditions. found cnn+rn generalize average left-out color+shape combinations sort-of-clevr task since color+shape combinations given setup model need learn generalize across many items therefore learns orders magnitude faster cnns psvrt stimuli. however average training accuracy curve rises rapidly around average validation accuracy remains chance. words average transfer same-different ability left-out condition even though attributes condition represented training combination next replaced simple shapes sort-of-clevr psvrt patterns. experiment varied image size pixels increments measuring tta. trained images. repeated training three different runs make sure results stable. found combined cnn+rn behaves essentially like vanilla cnn. long period chance-level performance several million images cnn+rn leaps greater accuracy long image size below. image sizes system learn. speculate cutoff point corresponds representational capacity particular architecture. although demonstrated capacity sufﬁcient solve original sort-of-clevr task clearly enough same-different tasks psvrt. results indicate visual-relation problems quickly exceed representational capacity cnns. learning templates individual objects appears quite tractable today’s deep networks learning templates arrangements objects become rapidly intractable combinatorial explosion number templates needed. stimuli combinatorial structure difﬁcult represent feedforward networks long acknowledged cognitive scientists least early fodor pylyshyn however limitation seems somehow overlooked current computer vision scientists. compared feedforward networks study biological visual systems excel detecting relations. fleuret found humans capable learning rather complicated visual rules generalizing instances svrt training examples. instance participants could learn rule underlying hardest svrt problem cnns experiment problem average examples. moreover problem rather complicated involving shapes shape obtained reﬂection around perpendicular bisector line joining centers. contrast best performing network problem high-throughput search could signiﬁcantly chance million training examples. visual reasoning ability found humans. example birds primates trained recognize same-different relations transfer knowledge novel objects recent striking example same-different learning animals comes martinho kacelnik essentially showed ducklings perform one-shot version experiment birth. training phase newly hatched ducklings exposed single pair simple objects either different. later demonstrated preference novel objects obeying relationship observed training phase. result suggests animals either rapidly learn abstract concepts different single example simply possess concepts innately. contrast behavior ducklings cnn+rn experiment demonstrated ability transfer concept same-different novel objects even hundreds thousands training examples. recent review similar literature wright kelly substantial evidence neural substrate visual-relation detection depend reentrant/feedback signals beyond feedforward pre-attentive processes. relatively well accepted that despite widespread presence feedback connections visual cortex certain visual recognition tasks including detection natural object categories possible near absence cortical feedback based primarily single feedforward sweep activity visual cortex however psychophysical evidence suggests feedforward sweep spatially coarse localize objects even recognized implication object localization clutter requires attention difﬁcult imagine could recognize spatial relation objects withspatial information. indeed converging neuroscience evidence suggests processing spatial relations pairs objects cluttered scene requires attention even participants able detect presence individual objects pre-attentively presumably single feedforward sweep. another brain mechanism implicated ability process visual relations working memory particular imaging studies highlighted role working memory prefrontal premotor cortices participants solve raven’s progressive matrices require spatial same-different reasoning. computational role attention working memory detection visual relations? assumption mechanisms allow ﬂexible representations relations constructed dynamically run-time sequence attention shifts rather statically storing visual-relation templates synaptic weights representations built on-the-ﬂy circumvent combinatorial explosion associated storage templates possible relations helping prevent capacity overload associated feedforward neural networks. humans easily detect objects transformation objects exist given spatial relation generally humans effortlessly construct unbounded structured descriptions visual world around given vast superiority humans modern computers ability detect visual relations exploration attentional mnemonic mechanisms important step computational understanding visual reasoning. authors would like thank drs. drew linsley sven eberhardt advice along shiebler earlier work. research supported early career award darpa young faculty award additional support provided center computation visualization brown university. supported graduate research fellowship. kroger sabb fales bookheimer cohen holyoak recruitment anterior dorsolateral prefrontal cortex human reasoning parametric study relational complexity. cereb. cortex", "year": 2018}