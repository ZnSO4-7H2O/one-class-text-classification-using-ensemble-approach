{"title": "Efficient Optimization of Performance Measures by Classifier Adaptation", "tag": ["cs.LG", "cs.AI"], "abstract": "In practical applications, machine learning algorithms are often needed to learn classifiers that optimize domain specific performance measures. Previously, the research has focused on learning the needed classifier in isolation, yet learning nonlinear classifier for nonlinear and nonsmooth performance measures is still hard. In this paper, rather than learning the needed classifier by optimizing specific performance measure directly, we circumvent this problem by proposing a novel two-step approach called as CAPO, namely to first train nonlinear auxiliary classifiers with existing learning methods, and then to adapt auxiliary classifiers for specific performance measures. In the first step, auxiliary classifiers can be obtained efficiently by taking off-the-shelf learning algorithms. For the second step, we show that the classifier adaptation problem can be reduced to a quadratic program problem, which is similar to linear SVMperf and can be efficiently solved. By exploiting nonlinear auxiliary classifiers, CAPO can generate nonlinear classifier which optimizes a large variety of performance measures including all the performance measure based on the contingency table and AUC, whilst keeping high computational efficiency. Empirical studies show that CAPO is effective and of high computational efficiency, and even it is more efficient than linear SVMperf.", "text": "loss function quantiﬁes loss subsequently notation denote convenience. since intractable compute expectation discriminative learning methods usually approximate expected risk using empirical risk svmperf codes svmperf provided joachims linear kernel svmperf respectively. parameter methods kernel width svmperf selected -fold cross validation following kernels kernel exp; polynomial kernel laplacian kernel exp; inverse distance kernel √γkxi−xjk+ inverse squared distance kernel γkxi−xjk+ kernels default parameters", "year": 2010}