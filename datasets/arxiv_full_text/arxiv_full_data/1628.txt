{"title": "CommAI: Evaluating the first steps towards a useful general AI", "tag": ["cs.LG", "cs.AI", "cs.CL"], "abstract": "With machine learning successfully applied to new daunting problems almost every day, general AI starts looking like an attainable goal. However, most current research focuses instead on important but narrow applications, such as image classification or machine translation. We believe this to be largely due to the lack of objective ways to measure progress towards broad machine intelligence. In order to fill this gap, we propose here a set of concrete desiderata for general AI, together with a platform to test machines on how well they satisfy such desiderata, while keeping all further complexities to a minimum.", "text": "marco baroni armand joulin allan jabri germ´an kruszewski angeliki lazaridou∗ klemen simonic tomas mikolov facebook artiﬁcial intelligence research {mbaroniajoulinajabrigermankangelikilklementmikolov}fb.com machine learning successfully applied daunting problems almost every general starts looking like attainable goal however current research focuses instead speciﬁc applications image classiﬁcation machine translation. believe largely lack objective ways measure progress towards broad machine intelligence. order propose concrete desiderata general together platform test machines well satisfy desiderata keeping complexities minimum. communication natural language useful able communicate assigning tasks understanding information returns teaching skills. since natural language easiest communicate require useful endowed basic linguistic abilities. language machine exposed testing environment inevitably limited. however given want machine also powerful fast learner humans later able teach sophisticated language skills become important instruct machine domains. concrete environment expose machine tasks provide instructions feedback tasks simple natural language. machine rely form linguistic interaction efﬁciently solve tasks. learning learn useful ﬂexible. needs change help challenges face solving scientiﬁc problem morning work stocking fridge night. progress towards thus measured ability master continuous tasks data-efﬁciency solving tasks fundamental evaluation component without distinguishing train test phases. must distinguish learning learn ability pertaining generalization across tasks -shot learning challenging limited ability generalize classes within task it’s generally agreed that order generalize across tasks program capable compositional learning storing re-combining solutions sub-problems across tasks testing environment thus feature sets related tasks compositional learner bootstrap skills task other. finally mastering language skills might crucial component learning learn since understanding linguistic instructions allows quickly learn accomplish tasks never performed before. feedback grow learn master complex tasks decreasing amounts explicit reward. useful possess similar capabilities. consequently testing environment reward decrease time. conversely machine able learn performance cues directly linked explicit reward score purely linguistic feedback observing agents correctly performing task testing environment include cues. interface interface machine world maximally general. machine learn best process different kinds input output streams need manual re-programming apply different domains. thus assume simplest possible interface. time step machine receives sends without structure imposed stream call evaluation framework satisfying desiderata commai given prominence give communication skills. developed open source commai-env platform implement sets commai tasks. concrete example simple tasks already satisfying many requirements above brieﬂy present commaimini tasks commai-mini task environment presents regular expression learner. asks either recognize produce string matching expression. environment listens learner response provides linguistic feedback learner’s performance exchanges take place level. examples follow learning-to-learn must since learner rarely ever tested exactly target grammar grammars become complex time learner asked grammar different ways compositionality plays important role multiple levels skills chunking sequences characters parsing messages predictable parts greatly help learner generalize across tasks. succeeding recognition tasks help solving equivalent production tasks control moreover complexity stringsets descriptions incrementally adding operators regular expressions. example checking string contains n-grams requires checking presence n-grams string compositional learner faster task involving n-gram conjunction solved task disjunction tasks. tasks different standard artiﬁcial grammar learning learner given explicit instructions simpliﬁed english target stringset well verbal feedback performance. thus satisfy linguistic communication desideratum. importantly although commai-mini tasks fully linguistic sense pertain character string recognition production chose regular grammar domain it’s simple well-understood satisﬁes language desideratum nature tasks fact environment provides meta-information simpliﬁed english. commai task sets could example based simple physics tasks sensory information would passed bit-based channel together instructions feedback would still expressed simpliﬁed english despite simplicity conjecture solving commai-mini tasks without astronomical amounts training examples scope current machine learning methods hope commai-mini challenge right level complexity stimulate researchers develop genuinely models. identify broad approaches benchmarking general researchers like take top-down view deriving requirements psychological mathematical considerations sympathize principled approach aware others emphasized practical desiderata outlined above proposing concrete framework evaluation like commai-env. others focus existing applications considered sufﬁcient complexity measure progress towards general-purpose intelligence. example games starcraft require sophisticated planning skills intuitively associated intelligence. current results domains impressive think approach time simple complex general benchmark. hand focus shifts domain-independent skills limited game-speciﬁc strategies. other input pre-processing adapting game-speciﬁc dynamics might require heavy computational resources advanced domain-speciﬁc know-how high entry cost researchers already working target domains. issues partially addressed platforms provide uniﬁed interface multiple games programs. however simply pooling large number existing applications make ragtag collection benchmarks clear uniﬁed goal terms evaluating general intelligence. abstract summarizes reﬁnes ideas originally presented unpublished manuscript thank gemma boleda stan dehaene emmanuel dupoux feyereisl amac¸ herda˘gdelen jos´e hern´andez-orallo iasonas kokkinos martin poliak marek rosa fair colleagues participants mainnips workshop feedback. adams itamar arel joscha bach robert coop furlan goertzel storrs hall alexei samsonovich matthias scheutz matthew schlesinger stuart shapiro john sowa. mapping landscape human-level artiﬁcial general intelligence. magazine gerhard j¨ager james rogers. formal language theory reﬁning chomsky hierarchy. philosophical transactions royal society london biological sciences james rogers jeffrey heinz margaret fero jeremy hurst dakotah lambert sean wibel. cognitive sub-regular complexity. glyn morrill mark-jan nederhof formal grammar international conferences springer berlin germany daniel silver qiang yang lianghao lifelong machine learning systems beyond learning algorithms. proceedings aaai spring symposium lifelong machine learning stanford david silver huang christopher maddison arthur guez laurent sifre george driessche julian schrittwieser ioannis antonoglou veda panneershelvam marc lanctot sander dieleman dominik grewe john nham kalchbrenner ilya sutskever timothy lillicrap madeleine leach koray kavukcuoglu thore graepel demis hassabis. mastering game deep neural networks tree search. nature commai-mini tasks based hierarchy sub-regular languages turn subset regular languages sub-regular languages useful characterize pattern recognition skills humans animals strictly local languages simplest class sub-regular languages recognized ngram lookup table only. example stringset accepted regular expression strictly local lookup table containing bigram sufﬁcient recognize strings language also strictly local recognized lookup table containing n-grams next class ascending hierarchy locally testable languages. latter recognized imposing logical constraints n-grams occur occur string. example at-least-one-b language recognized using lookup table containing unigrams plus checking device veriﬁes unigram occurred least once. strictly local languages strict subset locally testable languages. locally testable languages complex kind sub-regular languages still exploiting full expressive power regular languages combining strictly local locally testable languages already obtain interesting challenge commai learners. importantly efﬁcient solution commai-mini tasks involve stringset recognition/production learning description language speciﬁes rules legal strings. tasks organized task sets constituting videogame-like level. tasks presented random order. recognition-based could also seen single recognition task relevant class stringsets prefer granular structure outlining below facilitate analysis. example learning strictly local unigram languages special case learning strictly local maximally--gram languages however treating separate tasks make easier check learner memory limitations doesn’t scale n-grams beyond certain length. task deﬁned structure description actual symbols deﬁning acceptable stringset change exposure exposure. example second task consists recognizing string arbitrary upper-case letters description description different instances task. follows tasks illustrated string produced environment beginning task instance remarked target language change instance instance task. moreover show illustrative tasks set. tasks generated varying maximum n-gram size except number n-gram terms present description. tasks involve strictly local descriptions. natural hierarchy within terms length n-grams must memorized verifying language requires less memory verifying language. tasks also based strictly local descriptions. however operator solving requires storing multiple n-grams memory. tasks thus imply abilities necessary solve tasks generalize tasks involve locally testable languages. verifying target string contains ngrams description longer sufﬁces. learner must check whether n-grams description used. tasks thus generalize tasks. also require storing multiple n-grams memory need device check n-grams lookup table used. obvious hierarchy terms many distinct n-grams must stored memory length. tasks also distinguished terms whether include anything operator not. considering tasks mixing conjunction disjunction except implicit anything-denoted disjunction. exclude general case avoid implement complex scope conventions. tasks also involve locally testable languages. however conjunction include negation operator. setup conjunction always takes scope negation avoid need overt bracketing descriptions. fact negated n-gram equivalent afﬁrmation complement explicitly expressed always adding anything condition. time being consider general combinations conjunction disjunction negation. consider production counterparts recognition tasks. learner asked generate string matching conditions description. expect compositional learner solve production tasks much faster already exposed recognition tasks production tasks solved always generating shortest string description. simpler tasks amounts producing ﬁrst upper-case string description. force learner strategy asking produce distinct strings matching description e.g.", "year": 2017}