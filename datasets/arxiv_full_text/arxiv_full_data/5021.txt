{"title": "Random Projection and Its Applications", "tag": ["cs.LG", "cs.AI"], "abstract": "Random Projection is a foundational research topic that connects a bunch of machine learning algorithms under a similar mathematical basis. It is used to reduce the dimensionality of the dataset by projecting the data points efficiently to a smaller dimensions while preserving the original relative distance between the data points. In this paper, we are intended to explain random projection method, by explaining its mathematical background and foundation, the applications that are currently adopting it, and an overview on its current research perspective.", "text": "abstract—random projection foundational research topic connects bunch machine learning algorithms similar mathematical basis. used reduce dimensionality dataset projecting data points efﬁciently smaller dimensions preserving original relative distance data points. paper intended explain random projection method explaining mathematical background foundation applications currently adopting overview current research perspective. data transformation projection fundamental tool used many application analyze data sets characterize main features. principal component analysis square matrices generalization singular-value decomposition rectangular real complex matrices examples orthogonal data transformation techniques used many ﬁelds signal processing statistics. used transform sparse matrices condensed matrices order high information density pattern discovery space efﬁciency ability visualize data set. despite popularity classical dimensionality reduction tecniques limitations. first resultant directions projection data dependent make problems size data increased future. second require high computational resources impractical high dimensional data. instance r-svd fastest algorithms requires matrix third applications access data restricted streams frame sequences available every period time. last algorithms approximate data dimensional space near linear subspace. random projection presented address limitation idea project data points random directions independent dataset. random projection simpler computationally faster classical methods especially dimensions increased. regarding computational requirement random projection projected dimensions. means compromises processing time controlled accuracy intended application. interesting fact random projection preserve distance original projected data points high probability. therefore beside geometric intuition random projection viewed local sensitivity hashing method used data hiding security applications another task frequently involves random projection data dimensionality high nearest neighbor search target return group data points closely related given query. argue textual search methods like inverted index work large document data sets can’t work images. main reasons. first textual data sparse means picked document contains tokens language vocabulary however images data dense image useful pixels spans image. second tokens features document three words enough describe document unlike pixels. reasons make random projection appealing nearest neighbor searching applications. idea that given search query instead similarity matching brute force search data points dataset need search region surrounds query. searching done stages namely candidate selection candidates evaluation every data point search space evaluated. core idea partition search space dynamic variable size regions. force close data points mapped regions increases probabilities candidates given search query region. addition increase search success rate search region partitioned several time depending required accuracy processing time. figure shows example random projection using approximate nearest neighbors method dimensional data regions different colors. practice companies utilized random projection systems. spotify digital music platform uses method approximate nearest neighbors music recommendations part open source system esty e-commerce platform uses random projection user/product recommendation model adapted ways ﬁnding people similar interests ﬁnding products bought together random projection based upon johnson-lindenstrauss lemma proposed states points high-dimensional space projected lower dimension subspace relative distances data points nearly preserved. noted lower dimension subspace selected randomly based distribution. furthermore recent faster remainder paper organized follows. mathematical background theorem proof discussed section faster computationally efﬁcient random projections methods discussed section iii. applications current research perspective discussed section finally draws conclusion section latter equation called random projection theorem bounds upper bound probability difference projected vector original vector shall exceeds certain threshold. interesting ultimate data transformation data transformation/projection technique perserve much information possible original transformed data sets better presents data form. essential step towards proof random projection gaussian vector. addition assume step ui.v value independent gaussian random variable zero mean unit variance. easily uijvj independent gaussian random variables therefore result random variable ui.v also gaussian mean equal individual means variance obtained following interesting facts poof. first number projected dimensions completely independent original number dimension space proved depends number points dataset logarithmic form selected error threshold however error quadratic effect denominator equation means error range tens thousands high. second unlike projection function independent original data completely. addition projection dimensions don’t need orthogonal. despite simplicity random projection method showed section applications databases proposed method costly. achlioptas proposed method computationally efﬁcient kind applications. achlioptas show random wasteful. compressed sensing idea take random measurements high probability still able reconstruct measured signal. candes proposed exact reconstruction principle gives bounds reconstructing signal using random compressed samples. lets consider discrete time signal addition assume rn×n basis matrix signal represented linear combination columns particular suppose signal deﬁned johnson-lindenstrauss embedding property implies restricted isometry property above. matrix order however order measure compressed vectors yand reconstructed. analogy equation random projection theorem. like linear algebra problem solve correctly original signal reconstructed. however random noise sparse recovery inverse problem random projection basic building block behind compressed sensing matrix completion. section deﬁne application showing inspired random projection idea. according shannon-nyquist sampling theorem order able reconstruct signal bandwidth samples need sampling rate compressed sensing sampling rate used signal construction achievable. let’s consider camera megabyte pixels resolution capture high quality image automatically converts storage efﬁcient extension jpeg resultant image stored compressed format kilobyte acceptable human resolution. seems large waste captured data. idea that unlike traditional acquiring high quality measurements store efﬁcient compressed sensing working different shown ﬁgure sampling compression stages merged together receiver decode incoming message. compressed sensing sensor acquire quality measurement example ’single-pixel camera’ nevertheless able combine decompress sensed data acceptable quality compared megabyte camera. nutshell classical overview sensing measure much data possible coherence goal align rows and/or columns basis vectors. interested coherence subspace assumed column spaces positive value coherence factor. addition matrix tracking state actions elderly disabled people using sensors attached bodies considerable importance health-care applications. facilitate monitoring detecting abnormal condition patient body report authors proposed method working ofﬂine recognize daily human activities. system three main stages de-noising sensor data feature extraction feature dimensionality reduction using computationally efﬁcient random projection presented section classiﬁcation using jaccard distance kernel density probabilities. reported results usc-had dataset within-person classiﬁcation interperson identiﬁcation accuracy many data mining applications health care fraud detection customer segmentation bio-informative privacy security concerns immense importance dealing different types sensitive data. call privacy preserving techniques work encrypted noisy data able compute accurately efﬁciently predeﬁned operations euclidean distance product correlation etc. authors introduced data perturbation technique using random projection transformation noise added data sent cloud server. proposed technique preserves statistical properties dataset also allows dimensionality reduction considered value distortion approach data entries perturbed directly using multiplicative random projection noise. advantage technique many elements mapped element totally different traditional individual data perturbation technique therefore even harder adversary reconstruct plain text data. technique depends lemmas explained follows reconstruction difﬁcult problem also worth mention that foundation compressed sensing research prove randomly generated sensing matrix follow criteria. baraniuk aimed give condition different random sensing matrices follow criteria. addition proved random matrix follow gaussian distribution inherently obey criteria. another interested task rank matrix completion. used many applications like image in-painting goal recover deteriorated pixels image shown ﬁgure addition netﬂix problem goal complete customer-movie rating matrix given customers rating order build robust recommendation system. netﬂix million dollar grand prize given bellkor team recommendation system. lets consider partially observed matrix rm×n rank matrix rm×n best approximates matrix removing limitation matrix completion problem undetermined solution missing values assigned random values. mathematical formulation problem deﬁned solution problem minimize nuclear norm ||x||∗ deﬁned singular values candes proposed assumptions number observed entries recovered high probability. nuclear norm minimization given authors considered three applications paper relies product estimation namely distance estimation k-mean clustering linear perceptron. result random projection-based multiplicative perturbation technique keeps statistical properties conﬁdentiality data. paper explained random projection mathematical foundation behind addition explained related applications compressed sensing made breakthrough traditional communication theorems sampling rate used signal construction achievable. also explained matrix completion problem basis many data mining tasks recommendation systems image inpainting algorithms. bingham mannila random projection dimensionality reduction applications image text data proceedings seventh sigkdd international conference knowledge discovery data mining. kargupta ryan random projection-based multiplicative data perturbation privacy preserving distributed data mining ieee transactions knowledge data engineering vol. thus number attributes data reduced random projection statistical dependencies among observations maintained. worth mention that given projected data original data retrieved number possible solutions inﬁnite. jassim al-assam sellahewa improving performance security biometrics using efﬁcient stable random projection techniques image signal processing analysis ispa proceedings international symposium ieee yang hartung simoens busch dynamic random projection biometric template protection biometrics theory applications systems fourth ieee international conference arya mount netanyahu silverman optimal algorithm approximate nearest neighbor searching ﬁxed dimensions proc. acm-siam sympos. discrete algorithms candès romberg robust uncertainty principles exact signal reconstruction highly incomplete frequency information ieee transactions information theory vol. damaševiˇcius vasiljevas šalkeviˇcius wo´zniak human activity recognition environments using random projections computational mathematical methods medicine vol.", "year": 2017}