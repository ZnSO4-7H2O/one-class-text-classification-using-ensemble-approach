{"title": "Deep Markov Random Field for Image Modeling", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Markov Random Fields (MRFs), a formulation widely used in generative image modeling, have long been plagued by the lack of expressive power. This issue is primarily due to the fact that conventional MRFs formulations tend to use simplistic factors to capture local patterns. In this paper, we move beyond such limitations, and propose a novel MRF model that uses fully-connected neurons to express the complex interactions among pixels. Through theoretical analysis, we reveal an inherent connection between this model and recurrent neural networks, and thereon derive an approximated feed-forward network that couples multiple RNNs along opposite directions. This formulation combines the expressive power of deep neural networks and the cyclic dependency structure of MRF in a unified model, bringing the modeling capability to a new level. The feed-forward approximation also allows it to be efficiently learned from data. Experimental results on a variety of low-level vision tasks show notable improvement over state-of-the-arts.", "text": "abstract. markov random fields formulation widely used generative image modeling long plagued lack expressive power. issue primarily fact conventional mrfs formulations tend simplistic factors capture local patterns. paper move beyond limitations propose novel model uses fully-connected neurons express complex interactions among pixels. theoretical analysis reveal inherent connection model recurrent neural networks thereon derive approximated feed-forward network couples multiple rnns along opposite directions. formulation combines expressive power deep neural networks cyclic dependency structure uniﬁed model bringing modeling capability level. feed-forward approximation also allows eﬃciently learned data. experimental results variety low-level vision tasks show notable improvement state-of-the-arts. generative image models play crucial role variety image processing computer vision tasks denoising super-resolution inpainting image-based rendering repeatedly shown previous work success image modeling large extent hinges whether model successfully capture spatial relations among pixels. existing image models roughly categorized global models lowlevel models. global models usually rely compressed representations capture global structures. models typically used describing objects regular structures e.g. faces. generic images low-level models popular. thanks focus local patterns instead global appearance low-level models tend generalize much better especially vast variations image content. past decades markov random fields evolved popular models low-level vision. speciﬁcally clique-based structure makes particularly well suited capturing local relations among pixels. whereas mrfs generic mathematical framework ﬂexible provide immense expressive power performance many mrf-based methods still leaves desired faced challenging conditions. fig. present class markov random ﬁeld models whose potential functions expressed powerful deep neural networks. show applications model texture synthesis image super-resolution image synthesis. recent years rise deep neural networks profoundly reshaped landscape many areas computer vision. success dnns primarily attributed unparalleled expressive power particularly strong capability modeling complex variations. however dnns computer vision mostly formulated end-to-end convolutional networks classiﬁcation regression. modeling local interactions among pixels crucial many low-level vision tasks suﬃciently explored. respective strengths mrfs dnns inspire explore approach low-level image modeling bring expressive power dnns formulation. speciﬁcally propose generative image model comprised grid hidden states corresponding pixel. latent states connected neighbors together form mrf. unlike classical formulations fully connected layers express relationship among variables thus substantially improving model’s ability capture complex patterns. theoretical analysis reveal inherent connection formulation opens alternative formulation. however still diﬀer fundamentally dependency structure acyclic cyclic. consequently hidden states cannot inferred single feed-forward manner rnn. posts signiﬁcant challenge derive back-propagation procedure without well-deﬁned forward function? strategy tackle diﬃculty unroll iterative inference procedure feed-forward function. motivated observation inference iterative cycle updates still feed-forward procedure. following carefully devised scheduling policy call coupled acyclic passes inference unrolled multiple rnns operating along opposite directions coupled together. local information eﬀectively propagated entire network hidden state complete picture context directions. primary contribution work generative model uniﬁes mrfs dnns novel well learning strategy makes possible learn model using mainstream deep learning frameworks. worth noting proposed method generic adapted various problems. work test variety low-level vision tasks including texture synthesis image super-resolution image synthesis. paper develop generative image model incorporates expressive power deep neural networks mrf. work related several streams research eﬀorts moves beyond respective limitations. generative image models. generative image models generally fall categories parametric models non-parametric models. parametric models typically compressed representation capture image’s global appearance. recent years deep networks autoencoders adversarial networks achieved substantial improvement generating images regular structures faces digits. non-parametric models including pixel-based sampling patch-based sampling instead rely large exemplars capture local patterns. whereas methods produce high quality images local patterns directly sampled realistic images. exhaustive search large exemplar limits scalability often leads computational diﬃculties. work draws inspiration lines work. using dnns express local interactions model capture highly complex patterns maintaining strong scalability. markov random ﬁelds. decades mrfs widely used low-level vision tasks including texture synthesis segmentation denoising super-resolution classical models earlier work simple hand-crafted potentials gaussian mrfs link neighboring pixels. later ﬂexible models frame fields experts proposed allow potential functions learned data. however methods potential functions usually parameterized linear ﬁlters therefore expressive power remains limited. recurrent neural networks. recurrent neural networks special family deep models chain nonlinear units capture sequential relations. computer vision rnns primarily used model sequential changes videos visual attention hand-written digit recognition previous work explores multi-dimensional rnns scene labeling well object detections related work perhaps fig. graphical model deep mrfs. left hidden states pixels together form mrf. right hidden state connects neighboring states neighboring pixels pixel location. rnns generating gray-scale textures color images distinction models rnns rely acyclic graphs model spatial dependency e.g. pixel depends left upper neighbors severely limits spatial coherence. model instead allows dependencies directions iterative inference unrolling. neural networks. connections models discussed long rise deep learning recent work image segmentation uses mean ﬁeld method approximate conditional random ﬁeld layers. hybrid model also proposed human pose estimation works primarily target prediction problems eﬀective capturing complex pixel patterns purely generative way. primary goal work develop generative model images express complex local relationships among pixels tractable inference learning. formally consider image denoted undirected graph grid structure shown figure left. node corresponds pixel capture interactions among pixels introduce hidden variable pixel denoting hidden state corresponding dependency hidden state neighboring pixel respectively captured factors addition introduce regularization factor hidden state gives leeway encourage certain distribution state values. bringing choices factors. whereas provides principled express dependency structure expressive power model still largely depends speciﬁc forms factors choose. example modeling capacity classical models limited simplistic factors. below discuss factors choose proposed model. first factor determines pixel values generated hidden states. considering stochastic nature natural images formalize generative process gaussian mixture model rationale behind pixel values low-dimensional space small number components usually provide good approximation empirical distribution. speciﬁcally number components consider concatenation component parameters linear transform hidden state weight matrix model parameters. factor written here element-wise nonlinear function dimension summary eﬀectively accounts variations pixel generation fully-connected factors enable modeling complex interactions among neighbors regularization term provides explicitly control distribution hidden states. together substantially increase capacity model. fig. left shows numerical simulation approximated inference hidden variables. right shows relu sigmoid activation function corresponding regularizations hidden variables. here depends neighboring states corresponding pixel values well neighbors. since pixel neighboring pixels highly correlated simplify later computations approximate posterior distribution performed numerical simulations approximation. indeed close other illustrated figure consequently estimate approximately computed neighbors. turns optimization problem analytic solution given connections rnns. observe form similar feed-forward computations recurrent neural networks sense view feed-forward inference process models. particularly given computations form formulate regularization function derived according relation arbitrary constant. connection provides alternative formulate model. importantly models proven successful readily transferred formulation. figure shows regularization functions corresponding popular activation functions rnns sigmoid relu except special cases inference learning mrfs generally intractable. conventional estimation methods either take overly long time train tend yield poor estimates especially models highdimensional parameter space. work consider alternative approach learning allows draw deep learning techniques proven highly eﬀective variational learning principle. estimation probabilistic models based maximum likelihood principle often intractable model contains hidden variables. expectation-maximization widely used ways tackle problem iteratively calculates posterior distribution optimizes learning objective model. here function approximately infers latent state given observed image posterior distribution highly concentrated often case vision tasks good approximation. image problem learning principle interpreted terms encoding/decoding hidden states understood representation encodes observed patterns image measures well explains observations. coupled acyclic passes. proposed model dependencies among neighbors cyclic. hence estimate cannot computed single forward pass. instead needs applied across graph multiple iterations. strategy unroll iterative inference procedure multiple feed-forward passes along opposite directions passes together provide complete context local estimate. fig. coupled acyclic passes. decouple undirected cyclic graph directed acyclic graphs allowing feed-forward computation. inference performed alternately traversing acyclic graphs coupling information step. speciﬁcally decompose underlying dependency graph undirected acyclic directed graphs illustrated figure undirected edge corresponds uniquely edge opposite edge neighborhood expressed parents respectively along given decomposition derive iterative computational procedure cycle couples forward pass applies along backward pass along t-th cycle state updated updated state would incorporate information neighbors. note given graph decomposed many diﬀerent ways. work speciﬁcally choose forms zigzag path. advantage simple raster line order zigzag path traverses nodes continuously conserves spatial coherence making dependence node previous nodes visited before. forward backward passes resulted decomposition shown figure algorithm important properties first acyclic decomposition allows feed-forward computation applied. result entire inference procedure viewed feed-forward network couples multiple rnns operating along diﬀerent directions. therefore learned similar deep neural networks using stochastic gradient descent second feedback mechanism embodied backward pass facildiscussions d-rnn. previous work explored two-dimensional extensions often referred d-rnn. extensions however formulated upon acyclic graph considered trimmed version algorithm. major drawback d-rnn scans image raster line order able provide feedback path. therefore inference hidden state take account context recover poor inference. show experiments cause undesirable eﬀects. whereas bidirectional rnns partly mitigate problem decouple hidden states multiple ones independent apriori would lead consistency issues. recent work also ﬁnds diﬃcult generative modeling. implementation details inference learning make computation feasible take forward pass backward pass. thus node updated twice able information possible contexts. training patch size varies depending speciﬁc experiment. overall unroll full inference procedure model thousands layers deep. rmsprop optimization don’t dropout regularization oscillates training. following experiments test proposed deep scenarios modeling natural images. ﬁrst study basic properties texture synthesis apply prediction problem image super-resolution. finally integrate global models local deep natural image synthesis. task texture synthesis synthesize texture images possess similar patterns statistical characteristics given texture sample. study problem originated graphics successful texture reproduction learned previous work eﬀectively capture local patterns variations. therefore task perfect testbed assess model’s capability modeling visual patterns. texels natural images. initialize zeros train model back-propagation along coupled acyclic graph. trained model generate textures running derive work texture datasets brodatz grayscale images vistex color images. results shown figure synthesis visually resembles high resolution natural images quality close non-parametric approach also compare d-rnn. results obtained using d-rnn synthesizes based left upper regions exhibit undesirable eﬀects often evolve blacks bottom-right parts. fundamental parameters control behaviors texture model. training patch size decides farthest spatial relationships could learned data. number gaussian mixtures control dynamics texture landscape. analyze model changing parameters. shown figure bigger training patch size bigger number mixtures consistently improves results. non-parametric approaches bigger patch size would dramatically bring computation cost. model inference time holds regardless patch size model trained moreover parametric model able scale large dataset without bringing additional computations. unlike texture synthesis generation task driven lowresolution image. incorporate information introduce additional connections hidden states corresponding pixels low-resolution image shown figure noteworthy input single pixel site test whether model propagate information across spatial domain. task deterministic single component variance. testing stage output mean gaussian component location inferred high-resolution pixel. approach generic model speciﬁcally tuned task prepost-processing steps needed. train model widely used super-resolution dataset contains images test training psnr quantitative evaluation. following previous work consider luminance channel ycrcb color space. chrominance channels upsampled bicubic interpolation. shown table table approach outperforms cnn-based baseline compares favorably state-of-the-art methods dedicated task possible explanation success model learns mapping also learns image statistics high resofig. adapting deep mrfs speciﬁc applications. image super-resolution hidden state receives additional connection low-resolution pixel. image synthesis deep renders ﬁnal image spatial feature jointly learned variational auto-encoder. lution images. training procedure unrolls thousands steps share parameters also reduces risk overﬁtting. results also demonstrate particular strength model handling large upscaling factors diﬃcult images. figure shows several examples visually. images roughly considered composition textures guidance scene object structures. task move beyond synthesis homogeneous textures generate natural images structural guidance. model excels capturing spatial dependencies learning weak dependencies across entire image computationally infeasible analytically ineﬃcient. instead adopt global model capture overall structure provide contextual guidance mrf. speciﬁcally incorporate variational auto-encoder purpose generates feature maps location model uses feature render ﬁnal image features contain information scene layouts objects texture categories. latent states deep mrf. total loss deﬁned addition gaussian mixtures image space divergence high-level latent space. training randomly extracts patches feature map. gradients deep back thus cover patches extracted. testing randomly samples latent space decodes generate global feature maps. output pixels sampled mixtures along coupled acyclic graph. work msrc database select scene categories rich natural textures mountains valleys. category contains hundred images. approach generalizes much better data-hungry approaches. train model images dcgan paper ensure fair comparison. model successfully captures variety local patterns water clouds wall trees. global appearance also looks coherent real dynamic. state-of-the-art based models focuses much global structures often yield sub-optimal local eﬀects. present class model whose potential functions expressed powerful fully-connected neurons. theoretical analysis draw close connections probabilistic deep mrfs end-to-end rnns. tackle diﬃculty inference cyclic graphs derive framework decouples cyclic graph multiple coupled acyclic passes. experimental results show state-of-the-art results variety low-level vision problems demonstrate strong capability mrfs expressive potential functions. acknowledgment. work supported data collaboration research grant early career scheme grant also thank aditya khosla helpful discussions comments draft manuscript.", "year": 2016}