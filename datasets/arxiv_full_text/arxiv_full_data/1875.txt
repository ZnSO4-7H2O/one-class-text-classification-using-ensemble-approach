{"title": "Impact of Batch Size on Stopping Active Learning for Text Classification", "tag": ["cs.LG", "cs.CL", "cs.IR", "stat.ML", "H.3.3; I.2.6; I.2.7; I.5.4"], "abstract": "When using active learning, smaller batch sizes are typically more efficient from a learning efficiency perspective. However, in practice due to speed and human annotator considerations, the use of larger batch sizes is necessary. While past work has shown that larger batch sizes decrease learning efficiency from a learning curve perspective, it remains an open question how batch size impacts methods for stopping active learning. We find that large batch sizes degrade the performance of a leading stopping method over and above the degradation that results from reduced learning efficiency. We analyze this degradation and find that it can be mitigated by changing the window size parameter of how many past iterations of learning are taken into account when making the stopping decision. We find that when using larger batch sizes, stopping methods are more effective when smaller window sizes are used.", "text": "base learner implementation support vector machine scikit-learn python library. sampling algorithm closest-to-hyperplane algorithm shown recent work compare favorably sampling algorithms binary words representation consider words show dataset three times. stop word list remove common english words. analyzing impact batch size stopping methods method stop ﬁrst training iteration within speciﬁed percentage maximum achievable performance. denote method oracle method percentage denote oracle. percentage typical leading stopping methods able achieve level performance although oracle method cannot used practice useful contextualizing stopping results practical stopping methods. considered different batch sizes experiments based percentages entire training data. results batch sizes corresponding training data newsgroups dataset summarized table results consistent past ﬁndings learning efﬁciency decreased larger batch sizes however open question whether changing parameters associated actual stopping methods make experience less degradation performance larger batch sizes used. particular important parameter stopping methods window size previous iterations consider. abstract—when using active learning smaller batch sizes typically efﬁcient learning efﬁciency perspective. however practice speed human annotator considerations larger batch sizes necessary. past work shown larger batch sizes decrease learning efﬁciency learning curve perspective remains open question batch size impacts methods stopping active learning. large batch sizes degrade performance leading stopping method degradation results reduced learning efﬁciency. analyze degradation mitigated changing window size parameter many past iterations learning taken account making stopping decision. using larger batch sizes stopping methods effective smaller window sizes used. active learning sharply increases performance iteratively trained machine learning models selectively determining unlabeled samples annotated. number samples selected annotation iteration active learning called batch size. important aspect active learning process stop active learning process. stopping methods enable potential beneﬁts active learning achieved practice. without stopping methods active learning process would continue annotations labeled defeating purpose using active learning. accordingly interest development active learning stopping methods another important aspect active learning process batch size use. previous work shown using smaller batch sizes leads greater learning efﬁciency tension using smaller batch sizes optimize learning efﬁciency using larger batch sizes optimize development speed ease annotation. analyze batch size affects leading stopping method stopping method parameters changed optimize performance depending batch size. denote stopping method published stopping method stop active learning process mean three previous kappa agreement values consecutive models threshold. larger batch percents note stops later optimal oracle method point. smaller window sizes different batch sizes. results summarized window size table using window size able stop smaller number annotations using window size three. done without losing much f-measure. next subsection provides explanation smaller window sizes effective larger window sizes larger batch sizes used. window size user deﬁned. kappa agreement metric models. therefore needs models generated begins check average threshold. necessarily mean stops models generated. rather represents ﬁrst point active learning process even chance stop. using larger batch percents fewer models generated using smaller batch percents. gives stopping method less points test whether stop. also note kappa agreement scores generally ﬁrst models trained. this combined fewer points stop causes stop somewhat sub-optimally using large batch percents. usage large batch sizes data common sub-optimal performance stopping methods situations major problem. learning process stop iterative process asking labeled data large batch size asking additional labels iteration. found stopping methods degrade performance larger batch sizes used. degradation performance larger amount explained degradation learning efﬁciency results using larger batch sizes. important parameter used stopping methods window size earlier iterations consider making stopping decision. results indicate making window size smaller helps mitigate degradation stopping method performance occurs larger batch sizes. work supported part college jersey support scholarly activities program college jersey mentored undergraduate summer experience program usage college jersey high performance computing system. mishler wonus chambers bloodgood filtering tweets social unrest proceedings ieee international conference semantic computing diego ieee january available http//ieeexplore. ieee.org/stamp/stamp.jsp?tp=&arnumber=&isnumber= bloodgood vijay-shanker taking account differences actively passively acquired data case active learning support vector machines imbalanced datasets proceedings human language technologies annual conference north american chapter association computational linguistics companion volume short papers. boulder colorado association computational linguistics june available http//www.aclweb.org/anthology/n/n/n.pdf laws sch¨utze stopping criteria active learning international named entity recognition proceedings conference computational linguistics manchester august available http//www.aclweb. org/anthology/c- bloodgood vijay-shanker method stopping active learning based stabilizing predictions need useradjustable stopping proceedings thirteenth conference computational natural language learning boulder colorado association computational linguistics june available http//www.aclweb.org/anthology/w- bloodgood grothendieck analysis stopping active learning seventeenth based stabilizing predictions proceedings conference computational natural language learning. soﬁa bulgaria association computational linguistics august available http//www.aclweb.org/anthology/w- vlachos stopping criterion active learning computer speech brinker incorporating diversity active learning support vector machines machine learning proceedings twentieth international conference august washington fawcett mishra eds. aaai press bloodgood support vector machine active learning algorithms query-by-committee versus closest-to-hyperplane selection proceedings ieee international conference semantic computing laguna hills ieee january", "year": 2018}