{"title": "Skopus: Mining top-k sequential patterns under leverage", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "This paper presents a framework for exact discovery of the top-k sequential patterns under Leverage. It combines (1) a novel definition of the expected support for a sequential pattern - a concept on which most interestingness measures directly rely - with (2) SkOPUS: a new branch-and-bound algorithm for the exact discovery of top-k sequential patterns under a given measure of interest. Our interestingness measure employs the partition approach. A pattern is interesting to the extent that it is more frequent than can be explained by assuming independence between any of the pairs of patterns from which it can be composed. The larger the support compared to the expectation under independence, the more interesting is the pattern. We build on these two elements to exactly extract the k sequential patterns with highest leverage, consistent with our definition of expected support. We conduct experiments on both synthetic data with known patterns and real-world datasets; both experiments confirm the consistency and relevance of our approach with regard to the state of the art. This article was published in Data Mining and Knowledge Discovery and is accessible at http://dx.doi.org/10.1007/s10618-016-0467-9.", "text": "abstract paper presents framework exact discovery top-k sequential patterns leverage. combines novel deﬁnition expected support sequential pattern concept interestingness measures directly rely skopus branch-and-bound algorithm exact discovery top-k sequential patterns given measure interest. interestingness measure employs partition approach. pattern interesting extent frequent explained assuming independence pairs patterns composed. larger support compared expectation independence interesting pattern. build elements exactly extract sequential patterns highest leverage consistent deﬁnition expected support. extracting interesting patterns data core data mining task. paper introduces method eﬃciently exactly identify top-k patterns sequential database using measure interest leverage diﬀerence pattern’s observed expected frequency. deﬁne expected frequency maximum-likelihood estimate assumption independence pair patters composed. notion interestingness core paper. early work pattern mining patterns considered interesting appeared frequently data underlying idea fact something happens often useful information data practitioner. however mature body research shown frequency often poor proxy interestingness. reason many patterns expected frequent real data. instance traditional market basket case people apples people pears pattern handling large databases phenomenon creates deluge frequent uninteresting patterns. especially problematic real-world applications frequent patterns often well-known; less frequent interactions within data likely provide novel insights. signiﬁcant problem real-world data even relatively short sequences. simple demonstration this report table frequent sequential patterns book adventures sawyer every sentence constituting record database observe frequent sequential patterns interesting simply correspond permutations frequent word ‘and’ next frequent words ‘to’ ‘of’. motivated several approaches mining interesting sequential patterns detail section example illustrates main points incompatibility frequency proxy interestingness sequential pattern discovery sentence would contain several occurrences those. sequences long enough sequence independent events become frequent. fact pattern probability occurring time data probability repetition tends length sequences database increases clearly demonstrates frequency good proxy interestingness sequential databases. consider second third frequent sequential patterns and. patterns similar frequency. directly questions relevance frequency interestingness measure. sequential patterns order items determining whether pattern interesting. orderings terms sequential pattern equally frequent unordered pattern itemset captures information potentially interesting regularity data. argue sequential pattern reserved regularities canfully captured unordered patterns. case simple patterns length frequency ranks possible orderings scoring expected support core element standard pattern mining measures interest leverage lift measures interest involve comparison observed support pattern data expected support introduce deﬁnition expected support sequential pattern present algorithm computation. following motivation above approach tries model local tested pattern considering re-orderings. search introduce skopus sequential extension branch-and-bound opus algorithm skopus extract exactly eﬃciently sequential patterns highest leverage i.e. patterns highest diﬀerence observed expected support. note show algorithm limited deﬁnition expected support directly used extract top-k patterns deﬁnition expected support. paper divided main sections. present related research section section detail proposed framework discovery top-k patterns highest leverage. section present results experiments conducted synthetic data control patterns actually present real-world datasets. conclude paper present future work section mature body research non-sequential frequent pattern mining raised introduction long identiﬁed major issue whether derive complete frequent patterns certain constraints whether derive compact high-quality patterns useful applications major focus eﬃcient discovery frequent patterns growing body research identifying interesting patterns. several methods ﬁnding patterns best describe dataset using variety methods scoring entropy information theoretic frameworks approaches rather deﬁne measures interest patterns perform extraction interesting patterns diﬀerent measures refer reader complete survey frequent pattern mining discovering interesting patterns. sequential pattern mining extends frequent pattern mining sequential databases real-world applications numerous include analysis purchase behaviour customers time analysis clickstreams study biological sequences. algorithms mining frequent sequential patterns sequential databases ﬁrst proposed seminal papers researchers quickly moved development algorithms extraction frequent sequential patterns higher complexity note diﬀerent researchers used diﬀerent deﬁnitions support directly inﬂuence patterns extract. methods like ours consider support number sequences sequential pattern subsequence others consider number times pattern occurs sequences dataset multiple counting sequence embeds subsequence multiple times. application domains problems beneﬁt approach others approach. techniques extend directly second deﬁnition approach desirable primary change simply counting support pattern sub-patterns. minimum description length methods scoring patterns authors propose minimum description length approach scoring patterns relative dataset well heuristic search method construct set. idea score pattern instead individual patterns; patterns explain data well time non-redundant. goals quantiﬁed scores derived principles. methods based expected support deriving expected support null hypothesis particularly complex sequential patterns. several approaches made independence assumptions elements composing sequential patterns. null hypothesis data generated -order markov model stationary independent stochastic process approaches deriving expected support markov chains proposed particular statistical signiﬁcance extracted patterns studied complex markov models studied statistical signiﬁcance studied tatti takes diﬀerent approach interestingness posits applications interesting patterns ones occur short window. builds model expected length sequence pattern occur compares actual one. finally recent work tatti introduces approach related ours. aproach takes inspiration webb’s approach ﬁnding interesting itemsets builds expected support looking diﬀerent partitions sequential pattern. uses derived score rank strict episodes. diﬀerence work paper tatti information expectation derived tatti uses item probabilities well number gaps subpattern derive expectation whereas work compare pattern alternative orderings items. among technical diﬀerences tatti deﬁnes measure strict episodes whereas focus sequential patterns serial episodes. finally measure diﬀerence observed support expected support allows monotonic bound essentially mine top-k episodes without ﬁrst generating candidate whereas previously discussed methods require candidate ﬁrst generated typically frequent patterns mined threshold. interestingness measure leverage. finally introduce eﬃcient search algorithm extract interesting sequential patterns measures. note made code freely available allow independent conﬁrmation extensions work https//github.com/fpetitjean/skopus. note paper focuses sequential patterns extracting patterns type either mentioned related work patterns refer general class episodes seek patterns form sequences contain likely contain irrespective order. patterns already addressed substantial literature itemset discovery. introduce model expected frequency given sequential pattern well interestingness measures derive start providing intuition framework introduce formal deﬁnition. sub-patterns interesting frequency greater explained frequency stituent sequential sub-patterns example lowed buying belt pattern shoes jeans socks belt shoes socks jeans belt occur sequences perhaps expected however ignores also occur order suggesting need complication occur sequences length cannot. length sequences pattern appears must taken account exactly aﬀect expectation greatly dependent upon type distribution data drawn. clear simple models might take account factors without making strong assumptions form distribution. seek develop simple null hypothesis tested without making assumptions. well understood context non-sequential patterns unless speciﬁc steps taken prevent patterns accepted composition multiple interesting sub-patterns inclusion frequent singletons interesting pattern results pattern discovery system often swamped myriads spurious byproducts core patterns eﬀective approach prevent test pattern every partition counterpart test sequential patterns thus want test ‘partition’ compose three sequential patterns interweaving patterns obvious criteria might imposed determine whether supa explained supa supc. supa must greater least supports compositions generator. supa must greater mean supc supa supa approaches credible. latter stronger constraint former still allows three patterns composed two-element one-element sequential pattern found ‘interesting’. current work choose stronger approach software supports both. thus give intuition deﬁnition. consider possible pairs subsequences respect order target sequence partitions corresponds potential generator targeted sequence. example determine interestingness take maximum expected support potential binary sequential partitions ﬁnding pair ‘explains’ support enough establish pattern interesting. important note need consider expected support compositions subsequences relevant pairwise partitions subsume compositions subsequences. paper extract top-k sequential patterns leverage i.e. maximum diﬀerence observed expected support ﬁnally important note pattern considered interesting framework sub-patterns might also considered interesting. example case singular patterns expected reordering never occurs either thus making pattern interesting well. however interesting note approach rank full pattern higher compositions patterns length completely deﬁned proposed deﬁnition expected support important take step back look achieving. null hypothesis frequency pattern explained frequency sub-patterns imbricated elements deﬁne expected frequency pair sub-patterns null hypothesis possible ways interweave patterns order respected equally likely. expected frequency pair generators average frequency observed possible ways interweave patterns. null hypothesis frequency pattern explained pair generators expected frequency framework simply considers partition produces greatest expectation. note diﬃculty assessing framework’s statistical signiﬁcance demonstrate section framework eﬀective extracting interesting patterns. important note extracting measure statistical signiﬁcance patterns model diﬃcult task requires able assess probability pattern given null model. although easily obtain expected frequency computing probability requires assumptions form distribution data drawn. sequence indeed certain length unclear model would best match framework. however feel consequence strength framework; assume simplistic model underlying distribution patterns. sense partitioning approach allows dedicated model independently sequence makes extraction powerful cost failing support simple test assessing statistical signiﬁcance. templates. ﬁrst interesting note either case results depend length considered pattern independent actual letters themselves. partitions compositions thus generated templates depending function length. indexing templates. ﬁrst optimization directly follows observation; every time create template particular length index length computed length. employ similar indexing compositions diﬀerence associated lengths; thus index using matrix. note template composition length identical upper triangle matrix. generating bsps. generating binary sequential partitions template length enumeration exercise. ﬁrst element note knowing pattern left partition completely determines right partition conversely. means that construct template bsps particular length need left partition i.e. sequence positions elements original pattern. furthermore pattern length need consider generating combinations. generating combinations simpler bsps. symmetry observations hold here i.e. template combinations lengths combinations lengths generate possible l-combinations positions; standard algorithm described algorithm explore space sequential patterns exactly extract top-k sequential patterns highest leverage based opus miner algorithm ﬁrst introduced mining non-sequential databases. opus miner ﬁnds top-k itemsets given interestingness measures non-sequential database regard given measure interest. opus miner depth-ﬁrst branch-and-bound algorithm exploits monotonicity space sequential patterns except prune parts search space cannot contain itemsets top-k respect measure interest. example minimum value top-k know specialization itemset score lower sub-tree root need explored. opus miner’s depth-ﬁrst search advantage number open nodes time minimized. allows extensive data maintained every open node ensures record stored given time level depth explored. also promotes locality memory access nodes opened minor variants recently explored node. input sequential database measure interest integer queue items descending order supi); topk empty queue contain top-k sequential patterns; return expandsequence topk algorithm simply initializes necessary data structures call algorithm systematically explores entire space sequential patterns branches search space determined top-k contained therein. correctness skopus follows correctness opus. skopus investigates pattern maintains list topk top-k patterns found far. thus termination entire search space upper bound. note that possibly surprisingly lower bound expsupport tight. consider example database sequences start pattern length elements composing pattern rest sequence. sequential compositions possible binary sequential partitions frequency except actual pattern. highest frequency lowest number compositions deﬁnitions above exploit fact support expected support positive. interesting note that long deﬁnition expected support allow negative values elements remain valid. follows skopus algorithm directly used sensible deﬁnition expected support. practice time requirements skopus depend eﬃciency pruning mechanisms vary greatly dataset dataset. skopus traverses search space maintaining top-k sequential patterns discovered search space explored far. search space pruned branches cannot contain pattern higher leverage best leverage found far. thus eﬃcient pruning relies critically ability quickly topk high-scoring patterns much search space pruned possible. open. eﬃciently compute cover node important store cover parent update respect item appended sequence. minimizing number open nodes minimizes number covers must stored. however store cover every item issue aﬀect two-item sequences. second strategy uses hybrid search. first breadth-ﬁrst search performed two-item sequences. regular depth-ﬁrst search employed sequences length three greater. present two-item breadth-ﬁrst bootstrap algorithm algorithm remains correct still systematically searches search space might contain top-k patterns changes order explored. section present results skopus exact extraction sequential patterns highest leverage. synthetic experiments compare performance skopus using leverage measure interest skopus using support measure interest state-of-the-art sequential pattern discovery algorithm rprt baseline rind synthetic experiments clearly show baseline less eﬀective either skopus using leverage rprt include real-world experiments. shall start section making general observation availability interpretable sequential databases. applications sequential pattern mining methods numerous include datasets associated applications however extremely valuable hence rarely made available freely scientiﬁc community. addition assessing quality technologies pattern discovery requires knowledge patterns actually present data. therefore start evaluating discovery sequences sampled known distributions speciﬁc patterns. compare discovered interactions true structure data sampled. ﬁrst experiments present section then section assess relevance scalability approach public domain literary works. selected several books believe characteristics quite representative many types datasets. important note main objective paper prove extracting patterns sequential databases important topic; fact largely motivated data mining community. rather demonstrating interestingness-based sequential pattern extraction critical relevance approach. dataset random sequences vocabulary tokens; probability tokens follows dirichlet distribution dir. generate random sequence dataset choosing length distributed accordingly shifted poisson distribution pois makes then pattern embedded sequentially according associated probability. embedding performed uniformly random selecting insertion points sequence. used using indepdence model proposed baselines require candidate patterns used frequent patterns threshold note threshold potentially helps methods none injected patterns support lower threshold thus potential prune signiﬁcant number patterns could ranked top-. report recall rates table proportions patterns embedded included top- patterns returned approach. expected support-based method perform well. fact ever extracted patterns length mainly correspond sequential patterns frequent composing items well. similar behaviour explained introduction patterns composed frequent items appear frequently chance without interesting. means top-k extraction based support diﬃculty extracting patterns length single embedded pattern embedded sequences pattern ranked support pattern leverage rprt rind generally table shows approaches outperform support-based approaches recovering much larger number embedded patterns. also observe method skopus leverage outperforms rprt rind obtaining signiﬁcantly higher recall embedded patterns. also interesting note experiments conﬁrm ones showing poorer performance rind compared rprt note last points actually complicate extraction patterns within top- well. three elements best exempliﬁed sequential patterns corresponding dataset containing patterns illustrate table table report exact matches subpatterns discovered adopting elements appropriate sequential patterns approach pioneered zimmermann non-sequential patterns. them. method extract actual patterns within top- support-based method extracts pattern methods actual patterns. also interesting note similarity ﬁrst patterns extracted method rprt part top- support quite frequent pattern actually mostly support pattern introduced probability; diﬀerence explained fact tokens sampled relatively high probability means support method extracts top- frequent start with; infrequent tokens support wouldn’t ranked pattern high. exactly happens pattern approach correspond subsequences actual patterns also extracted. mainly illustrates ﬁrst elements noted slots top- consumed sub-patterns high leverage. although falls scope ﬁrst attempt extracting top-k sequential patterns leverage naturally echoing work done ﬁltered-top-k association discovery generally results call reﬂection evaluation sequential pattern mining procedures similarly work performed area non-sequential pattern mining compared patterns several works literature jmlr abstract dataset. brevity discuss patterns obtained jmlr. information results section supplementary material manuscript. study detail results diﬀerent methods jmlr dataset represents abstracts papers published journal machine learning research. dataset holds abstracts words average length abstracts words algorithm algorithm learn learn learn algorithm algorithm learn data data learndata model model problem problem learn result problem algorithm rprt support vector support vector machin support machin real world vector machin state reproduc hilbert high dimension ﬁrst second larg scale ﬁrst present results detail computation times next subsection. top- patterns presented table method support reference results rprt shown previous section method rprt outperform rind focus methods keep top-support patterns reference. ﬁrst critical observation echoes ones made introduction inconsistency support-based extraction using support patterns correspond repetitions frequent words algorithm learn data model problem. moreover using support measure interest pattern learn algorithm reversed version algorithm learn appear similar scores contrast observe method rprt present patterns seem higher general interest support. interestingly patterns extracted seem diﬀer signiﬁcantly methods. beyond highlighting importance synthetic data experiments also re-conﬁrms subjectivity interestingness. interesting examine elements overlap skopus rprt method examine percentage top-k found top-k other. figure presents overlap analysis skopus rprt top- top-. example point coordinates top- tells percent top-x ﬁrst method found top- other. similar results would slowly decreasing rate. case observe quite opposite little overlap methods less overlap within top- top-. interestingly skopus seem patterns ranked rprt opposite supports relevance method. analysis representative diﬀerences signiﬁcant diﬀerences exist even patterns clearly appears figure shows patterns early skopus’ third position part top- patterns ranked rprt detail example patterns highly contrasting diﬀerences skopus rprt patterns skopus ranks high rprt paper algorithm extracted pattern highest leverage ranked rprt pattern extracted skopus leverage succession appears times dataset reversed pattern algorithm paper appears times. seems reasonable highly rank pattern occurs twice frequency reverse. rprt ranks pattern much lower paper algorithm probable individually similar phenomenon seen base result skopus ranks rprt learn result— skopus patterns rprt ranks high skopus reproduc hilbert extracted pattern rprt ranked skopus. pattern extracted rprt consists relatively rare items reproduc occurs times hilbert occurs times. hand skopus ranks pattern relatively appears abstracts. measure expected support pattern high lift leverage latter measure favors patterns appear greatest number times excess expected. also interesting note skopus ranks followed space pattern length interesting. skopus’ rank respects ordering rprt case pattern reproduc hilbert spac ranked note also pattern hilbert spac occurs less frequently reproduc hilbert papers results reported table surprisingly extracting top- support skopus extremely fast frequent elements encountered early exploration search space; top- actually presenting patterns length regardless experiments. methods observed synthetic data extremely challenging mostly included patterns reasonable probability. results obtained hours skopus leverage less minute rprt main reason rprt faster high mining threshold without extraction cannot performed lower threshold mining step take considerate time frequent pattern explosion. hand skopus require threshold. finally approach exhibits extremely competitive running time compared support real-world datasets interesting patterns present. takes skopus extract top- patterns jmlr dataset; slightly twice time taken support-extraction signiﬁcantly faster rprt minimum support literary works skopus ﬁnishes less minutes rprt generally ﬁnishes seconds required minimum support threshold ﬁnally interesting note algorithmic complexity skopus rprt varies diﬀerent elements. skopus function interesting patterns data data holds patterns high interest prune signiﬁcantly large parts search space rprt interests patterns data holds almost neutral complexity mostly vary function number frequent closed patterns. described intuition behind deﬁnitions well eﬃcient algorithms computation expected support exact exploration search space. together contributions allowed introduce skopus constitutes best knowledge ﬁrst framework exact mining sequential patterns highest leverage data. using background knowledge deﬁne model joint distribution extract patterns diﬀer approach investigated jaroszewicz non-sequential patterns models joint distribution bayesian network many domains hold patterns type admission biopsy blood-test surgery. work focuses extraction chains events believe extension general classes episodes major interest. material based upon work supported force oﬃce scientiﬁc research asian oﬃce aerospace research development award number fa---. research also supported china special fund meteorological research public interest grant gyhy jiangsu government scholarship overseas studies; australian research council grant", "year": 2015}