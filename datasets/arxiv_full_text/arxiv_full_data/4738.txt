{"title": "A Brief Introduction to Temporality and Causality", "tag": ["cs.LG", "cs.AI"], "abstract": "Causality is a non-obvious concept that is often considered to be related to temporality. In this paper we present a number of past and present approaches to the definition of temporality and causality from philosophical, physical, and computational points of view. We note that time is an important ingredient in many relationships and phenomena. The topic is then divided into the two main areas of temporal discovery, which is concerned with finding relations that are stretched over time, and causal discovery, where a claim is made as to the causal influence of certain events on others. We present a number of computational tools used for attempting to automatically discover temporal and causal relations in data.", "text": "causality non-obvious concept often considered related temporality. paper present number past present approaches definition temporality causality philosophical physical computational points view. note time important ingredient many relationships phenomena. topic divided main areas temporal discovery concerned finding relations stretched time causal discovery claim made causal influence certain events others. present number computational tools used attempting automatically discover temporal causal relations data. causality sources mystery sometimes treated philosophical curiosities. however much benefit able automatically extract temporal causal relations practical fields artificial intelligence data mining. requires rigorous treatment temporality causality. paper present causality different view points list number methods automatic extraction temporal causal relations. arrow time unidirectional part space-time continuum verified subjectively observation remember past future. regard time different spatial dimensions obviously move back forth spatially. however contradiction empirical observation time irreversible time-reversibility physical laws. laws physics expressed time-reversible manner meaning applied either temporal direction. example relationship force acceleration enforce specific direction time. formula might suggest force caused mass acceleration re-arrange formula read interpret formula saying acceleration caused mass force. fact many physical laws exhibit temporal asymmetry prompted researchers consider incomplete approximations others assume distinct types physical laws. time-symmetrical laws hold backwards time asymmetrical laws valid direction falling table breaking observed often reverse always older younger. irreversible phenomena explained second thermodynamics states entropy closed system decrease sufficient long period time physics entropy definition makes time unidirectional define direction time increasing entropy. time unidirectional observed quantum level evident quantum de-coherence irreversible collapse superposition states single state quantum decoherence caused measurement. note nothing forbids broken reassemble table molecules gather small part room probability events happening extremely small. causality hard define concept. studied many different disciplines including physics philosophy statistics computer science. time usually essential part intuitive understanding causality often consider necessary cause existed time effect lthough causality subject debate value trying discover possibly causal relations events. system study cannot change variables understanding causal relations help predict future observing value current variable. change certain variables knowing casual relations allow exert control behavior system. follows discuss problems defining discovering temporal causal relations. show computer science allowed beyond philosophical discussions attempt discover temporal causal relations different degrees success. rest paper organized follows. section briefly discuss temporal data mention different techniques processing them. section provides different definitions causality. section presents number algorithms causal discovery data section concludes paper. emporal data often represented sequence sorted temporal order. examples studies sequential data sequential rules given number general fields study sequential data. time series time-ordered sequence numerical observations taken time example series numbers univariate time series observation consists value single variable multivariate time series observation consists values several variables. approaches time series processing assumed presence distinguished variable representing time numeric values variables. attempts made constant time-varying mathematical functions time series data time series regular irregular regular time series data collected predefined intervals. irregular time series property data arrive time arbitrary temporal gaps between. deterministic time series predicted exactly future values stochastic time series determined probabilistically. former characteristic artificial controlled systems latter applies many natural systems. simple operations like determining minimum maximum values certain variables finding trends cyclic patterns forecasting common applications time series data. approaches discovery rules time series data involve pre-processing input extracting global local features data. global features include average value maximum value local features include upward downward change local maximum value another example discovering temporal traits pre-processing time series data discovery increasing decreasing trends rule extraction study time series pursued widely hints cases results useful even meaningful phrase multiple streams data used describe simultaneous observations variables. streams data come different sensors robot monitors intensive care united example. values coming streams recorded time form time series. algorithm presented find rules called \"structures\" authors relating previous observations future observations. temporal data appear many application areas good review found event sequence series temporally ordered events either ordinal time variable gives order real-valued time time variable. main difference event sequence time series time series sequence real numbers event sequence contain variables symbolic domains. event specifies values variables. recurring pattern event sequence called frequent episode recent research emphasized finding frequent episodes varying number events events identify event sequence. algorithms dynamic time warping variants measure similarity patterns stretched differently time emporal sequences often considered passive indicators presence temporal structure data claim made whether represent causal relationships. despite different terminology domains listed section common characteristic recording values variables placing together record. time series event sequences streams data find temporal rules called patterns episodes structures respectively input data. extensive review methods discovering knowledge sequential data found ausality studied many different disciplines. philosophy’s look causality changed greatly time reflecting scientific understanding era. hume’s notion causality close common sense understanding concept. states three conditions causality causes precedes time contiguous space time always co-occur neither occurs main problem definition argue causing night vice versa three conditions satisfied case. ill’s definition causality also three conditions temporal precedence association cause effect absence plausible causes last criterion fixes problem night. rubin believes causality limited specific contexts conditions. according relationship derived experimentation certain variables changed experimental group fixed control group causal relation idea basis many empirical studies sciences medicine. causality importance areas religion too. religions causeless creator considered ultimate cause everything. many religions people still cause events punished rewarded based effects intentions behind them. heavenly court believed followers certain religions apparent need assign responsibility certain events every-day life. reason lawyers often need establish sufficient causal link hold person entity responsible. lawyers assume entity caused unlawful event action performed entity could lead event without action event would happened. people usually consider necessary cause existed time effect however modern physics based intuitive ideas time. universal clock constant speed light. observer perceives time differently according speed relative another observer. physicists consider speed light upper limit speed event cause another event theories particles move faster light. example tachyon macroscopic world moving faster light lead contradictions effect appear cause possibility lead paradoxes person move faster light return past change causes travel time. effect happening cause called backward causation. shown philosophers consider impossible paradoxical. possible absence free will could back past change anything interferes time travel. implication assumption since able change anything would travel past again thus stuck never-ending time loop. classical newtonian physics causality well-defined. exemplified claim laplace believed knows initial states particles universe plus applicable rules predict future retrodict past perfectly specifically given current position value current momentum vector plus acting forces classical physics plot trajectory particle predict future position momentum uantum theory however placed severe restrictions predictability classical physics sense. consequence heisenberg uncertainty principle cannot know position momentum particle arbitrary precision. precisely operator denotes uncertainty value operand another example quantum physics disagreement intuitive understanding causality classical physics interaction cause effect requires spatial proximity quantum physics allows apparently instantaneous causal interactions particles arbitrary distances other. example given entangled electrons measuring spin direction instantly determines spin direction thus establishing causal non-locality ranger causality used mainly economics puts clear emphasis temporal precedence granger causal relationship exists previous values variables improve prediction decision variable’s value. suppose observing variables time variables considered relevant granger-causes natural number measures conditional probability given i.e. probability event happening given event already happened. example knowing previous value variable political scandal today? past days increase ability predict value variable does stock market lose value today?. granger causality subject errors. example event person leaves building always followed minutes later everybody leaves building granger causality consider person leaving building cause everybody leaving building true. major trend development concepts causality become computationally verifiable time. complex world providing clear-cut definitions measures causality hard consideration present recent statistical approaches granger causality conditional dependence implemented computers. robabilistic causality defined follows. considered cause formula implies temporal precedence cause regards effect. practice however definition brittle possible errors gathering data example real-world data would satisfy attempt remedy brittleness assume cause example weakness second definition comes view seeing lightning hearing thunder. suppose hear thunder seeing lightning would lead believe seeing lightning causes hearing thunder. example lighting thunder created time description statement event considered already happened consideration enforce automatic temporal ordering according bayesian rule left hand side equation event assumed already happened right hand side event assumed happened. words using algebraic manipulation change order events supposed happened thus reverse original possibly natural order events. conditional probability value expresses reverse temporal ordering called likelihood. suppose create model data measure conditional probability data given model since data existed model probability called likelihood given indicates reversing temporal order model explains data instead around. discussions discovering causality especially statistical point view refer utomatic discovery causal relations among number variables active research field. specifically automated methods applied determining whether value variable caused variables. input computational approach usually consists data records containing values variables observed together. bayesian approach definition discovery causality currently enjoying much attention introduced section also briefly present minimum message length method causal discovery section none methods take temporal information consideration introduce approach works based explicit temporal ordering among variables section prevalent approach discovery causality consider problem creating graph parent nodes denote causes children denote effects. argue variables graph form mere temporal associations interpreting relation causal requires justification. main trend causality mining involves using statistical concept conditional independence measure control variable another example given three variables independent given conclude direct cause words separates other. basic concept used build bayesian networks show conditional dependence variables arcs arcs interpreted signifying causal relations. bayesian networks thus directed acyclic graphs represent conditional dependency variables. tetrad well-known application causal discovery uses bayesian networks attempting find causal relations. causal bayesian network used tetrad assumes links graph denote causal relationships. tetrad first assumes variables causally related beginning causal network fully connected. uses conditional independence tests remove revise edges. remaining edges form causal bayesian network. constructing bayesian network simplify joint probability distributions using products marginal probability distributions conditional probabilities. simple example written case corresponding bayesian network graph consisting nodes parent case event parent event directed link node node general chain rule probability written formula simplified information conditional independence variables either given user computed data. figure shows example bayesian network corresponding simplifying bayesian network implies property node independent nondescendant nodes conditioned parents. implication called causal markov condition similar graphs appear belief networks probabilistic networks knowledge maps causal networks emphasize notion conditional independence defined statistics devoid time. proponents method temporal information available place constraints relationships among variables time essential working algorithms. practical problem bayesian networks constructing network observed data np-hard task becomes increasingly time-consuming impossible number combination variables increase. introduced based maximizing posterior probability model. want good model fitted data want maximize posterior probability according bayes’ rule maximize recall likelihood given since given consider constant model must chosen numerator maximized. employ information theory’s method taking negative natural logarithm probability values convert problem minimizing expression –ln) ln). information theory formula expresses minimum length necessary encode model –ln) plus minimum length necessary encoding exceptions rules data expressed –ln). hence name mml. amml application attempts learn best causal bayesian structure explain observed data using metric selecting causal bayesian network. explained measures goodness-of-fit causal model data given observed variables camml finds causal relationships causes single effect. amml searches space possible causal models using markov chain monte carlo method finds best explains data. markov process transition state next depends current state only. words transition markov process depends history moves lead current state. markov chain characterized transition matrix gives probability moving state system next one. starting initial state multiplying markov transition matrix enough number times settle final state. monte carlo methods work simulating unknown function using probabilistic means. sample values probability distribution compute function points. mcmc obtain specific probability distribution generates markov chain whose long-term equilibrium distribution. discovering causality sequential observations temporal investigation method enregistered record sequences method takes classification approach discovery causality input method considered consist sequence records containing values number variables. records observed other. example would record sequences true> false> values three variables noted. time interval registering records determined problem domain. assuming effects take time manifest timers merges consequent records together. number records merged together determined window size. merging allows potential causes effects appear record making possible time-agnostic learning algorithm used causal discovery. using window size merging records would result true false> corresponds values variables added subscript denote temporal order variables help distinguish variable appears different time. generates decision rules merged records using conventional classifiers find causality intends find rules predict current value single variable using past values variables. generating decision rules merged records algorithm notes quality rules using training predictive accuracies. success failure attempt explain value decision variable using previous values depends quality rules training predictive accuracy values user-defined threshold explanation considered satisfactory target variable’s value said caused values variables used decision rule. example previous observations used explain current observation timers defines causality. considers possibilities relation instantaneous acausal. first case simultaneous observations used make prediction second case future observations used predict current value. decision type relationship depends accuracy resulting rule sets. example acausal rules results better accuracy instantaneous causal rules acausal relationship said work. acausal relationship considered backward causal future supposed caused present. consider acausality denote presence hidden common causes past. words timers acausal relation considered imply temporal co-occurrence events happening time form temporal pattern none causing other. paper briefly presented many different approaches defining discovering temporal causal relations number fields emphasis computational methods. none presented method claim solved problem reliable causal discovery results subject verification. agrawal srikant mining sequential patterns proceedings international conference data engineering taipei taiwan march. antunes oliveira using context-free grammars constrain apriori-based algorithms mining temporal association rules workshop temporal data mining edmonton canada july baggott meaning quantum theory guide students chemistry physics oxford science publications berndt clifford finding patterns time series dynamic programming approach advances knowledge discovery data mining. u.m. fayyad piatetskyshapiro smyth aaai press/ press chatfield analysis time series introduction chapman hall chickering geiger heckerman learning bayesian networks np-hard technical report msr-tr-- microsoft research feinberg possibility faster-than-light particles physical review pp.-. freedman humphreys algorithms discover causal structure? technical report department statistics university california berkeley granger investigating causal relations econometrics models cross-spectral methods econometrica volume grefenstette j.j. ramsey c.l. schultz learning sequential decision rules using simulation models competition machine learning guralnik wijesekera srivastava pattern directed mining sequence data proceedings fourth international conference knowledge discovery data mining hawking s.w. universe nutshell bantam books heckerman bayesian approach learning causal networks microsoft technical report msr-tr-- microsoft corporation heckerman geiger chickering d.m. learning bayesian networks combination knowledge statistical data machine learning holland p.w. statistics causal inference journal american statistical association höppner knowledge discovery sequential data dissertation fachbereich mathematik informatik technischen universität braunschweig höppner discovery temporal patterns learning rules qualitative behaviour time series principles data mining knowledge discovery humphreys freedman grand leap british journal philosophy science kadous learning comprehensible descriptions multivariate time series international conference machine learning karimi hamilton h.j. timesleuth tool discovering causal temporal rules ieee international conference tools artificial intelligence washington november", "year": 2010}