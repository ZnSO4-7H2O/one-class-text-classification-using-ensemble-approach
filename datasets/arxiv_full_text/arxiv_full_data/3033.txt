{"title": "Generating Visual Representations for Zero-Shot Classification", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "This paper addresses the task of learning an image clas-sifier when some categories are defined by semantic descriptions only (e.g. visual attributes) while the others are defined by exemplar images as well. This task is often referred to as the Zero-Shot classification task (ZSC). Most of the previous methods rely on learning a common embedding space allowing to compare visual features of unknown categories with semantic descriptions. This paper argues that these approaches are limited as i) efficient discrimi-native classifiers can't be used ii) classification tasks with seen and unseen categories (Generalized Zero-Shot Classification or GZSC) can't be addressed efficiently. In contrast , this paper suggests to address ZSC and GZSC by i) learning a conditional generator using seen classes ii) generate artificial training examples for the categories without exemplars. ZSC is then turned into a standard supervised learning problem. Experiments with 4 generative models and 5 datasets experimentally validate the approach, giving state-of-the-art results on both ZSC and GZSC.", "text": "paper addresses task learning image classiﬁer categories deﬁned semantic descriptions others deﬁned exemplar images well. task often referred zero-shot classiﬁcation task previous methods rely learning common embedding space allowing compare visual features unknown categories semantic descriptions. paper argues approaches limited efﬁcient discriminative classiﬁers can’t used classiﬁcation tasks seen unseen categories can’t addressed efﬁciently. contrast paper suggests address gzsc learning conditional generator using seen classes generate artiﬁcial training examples categories without exemplars. turned standard supervised learning problem. experiments generative models datasets experimentally validate approach giving state-of-the-art results gzsc. zero-shot classiﬁcation addresses classiﬁcation problems classes represented training examples. made possible deﬁning high-level description categories relating classes classes training examples available learning usually done leveraging intermediate level representation attributes provide semantic information categories classify. pointed paradigm compared human identify object description leveraging similarities description previously learned concepts. figure method consists learning image feature generator capable generating artiﬁcial image representations given attributes learning discriminative classiﬁer artiﬁcially generated training data. image maxy compatibility function part often deﬁned projections bilinear function relating common embedding. different variants recent literature projections similarity measure computed cases class chosen maximizing compatibility score. embedding maximal compatibility approach however exploit learning phase information potentially contained semantic representation unseen categories. step discriminating capability exploited ﬁnal label selection uses maxy decision scheme setting compatibility score itself. machine learning community. generative models estimate joint distribution images classes often learning class prior probability class-conditional density separately. however observed long time discriminative approaches trained predicting directly class label better performance model-based approaches long learning database reliably samples target distribution. despite expect discriminative methods give better performance can’t used directly case obvious reasons images available categories discriminative classiﬁers cannot learned out-of-the-box. paper proposes overcome difﬁculty generating training features unseen classes standard discriminative classiﬁers learned generating data machine learning tasks studied literature e.g. compensate imbalanced training sets. generating novel training examples existing ones also heart technique called data augmentation frequently used training deep neural networks training data categories underlying parametric representation used generate missing training data assuming mapping underlying representation image space. generated images applying warping geometric photometric transformations prototypical logo exemplars. similar idea also presented text spotting images. capture call gist gesture recording human gestures representing model model generate large realistic gestures. build direction context underlying representation attribute text based description unseen categories transformation attributes image features learned examples seen classes. relevant learn transformation generative models denoising auto encoders generative adversarial nets variants gans consist estimating generative models adversarial process simultaneously learning models generative model captures data distribution discriminative model estimates probability sample came training data rather generator. conditional generative adversarial nets relevant variant adapted problem. addition advantage using discriminative classiﬁers expected give better performance approach nature address realistic task generalized zero-shot classiﬁcation problem introduced assumes seen unseen categories present test time making traditional approaches suffering bias decision issues. contrast proposed approach uses training examples seen unseen classes training avoiding aforementioned issues. another reason perform classiﬁcation inference directly visual feature space rather abstract attribute embedding space data usually easily separated former especially using discriminant deep features commonly available. paper experimentally validates proposed strategy standard zero-shot classiﬁcation datasets attributes apascal&ayahoo caltech-ucsd birds-- gives insight approach scales large datasets imagenet shows state-of-the-art performance datasets gzsc. motivated introduction address paper problem learning classiﬁer capable discriminating given classes empirical data available subset so-called seen classes. vocabulary zero-shot classiﬁcation problem usually qualiﬁed inductive access data unseen classes opposed transductive unseen data available associated labels. address paper transductive setting considering availability target data constraint practice. learning dataset deﬁned series triplets data rich semantic representation class belonging semantic representation expected contain enough information discriminate classes itself predictable data iii) infer unambiguously class label inductive problem known regarding target domain semantic class representations unseen classes. goal information structure semantic representation space design classiﬁcation function able predict class label classiﬁcation function usually parametric settled optimization empirical learning criterion. paper artiﬁcially generate data unseen classes given seen classes semantic representations provide enough information apply discriminative approach learn class predictor. availability data unseen classes main advantages make classiﬁcation seen unseen classes single homogeneous process allowing address generalized zero shot classiﬁcation single supervised classiﬁcation problem; potentially allows larger number unseen classes instance required datasets imagenet generators unseen data build recently proposed approaches conditional data generation presented section idea learn globally parametric random generative process using differentiable criterion able compare whole target data distribution generated one. given random sample ﬁxed multivariate prior distribution typically uniform gaussian parameters sample data consistent semantic description generated applying function generative moment matching network ﬁrst approach adapt generative moment matching network proposed conditioning. generative process considered good semantic description random populations imum mean discrepancy probability divergence measure distributions. divergence approximated using hilbert kernel based statistics typically linear combination gaussian functions various widths advantage differentiable thus exploited machine learning cost. network parameters obtained optimizing differentiable statistics stochastic gradient descent using batches generated real data conditioned semantic description conditional generative adversarial models second model builds principles generative adversarial networks learn discrepancy measure true generated distributions discriminator simultaneously data generator. extension allowing produce conditional distributions ac-gan generated true distributions compared using binary classiﬁer quality conditional generation controlled performance auxiliary task. model bears similarities gmmn model difference gmmn distributions true generated data compared using kernel based empirical statistics ac-gan case measured learned discriminative parametric model. denoising auto-encoder third generator relies work presented encoder/decoder structure proposed design data generator latent code playing role random prior used generate data. simple extension able introduce conditional data generation control developed concatenating semantic representation code decoder practice model learned standard autoencoder except noise added input semantic representation concatenated code hidden layer. generating novel examples decoder part i.e. head network using encoder. introduces adversarial criterion control latent code produced encoder part code distribution matches ﬁxed prior distribution. extra constraint expected ensure parts sampling prior space produce meaningful data. implemented generative models neural networks whose architectures illustrated fig. hidden layers fully connected leaky-relu nonlinearity models using classiﬁer classiﬁer linear classiﬁer loss used measure quality reconstruction autoencoders norm. section presenting datasets experimental settings start comparing different generative models described previous section. show approach used generalized zero-shot classiﬁcation task contributions paper provide experiments large scale zero shot classiﬁcation task ﬁnally compare approach state-of-the zero-shot approaches regular zero-shot classiﬁcation task. ﬁrst experimental evaluation done standard datasets animals attributes attributes apascal&ayahoo caltech-ucsd birds-- benchmarks exhibit great diversity concepts; ﬁne-grained categorization include respectively birds scenes images; contains images animals different categories; ﬁnally ap&y broader concepts cars animals. dataset attributes descriptions given either class level image level. ap&y image binary attributes average produce class real valued representations. order make comparisons works follow training/testing splits ap&y experiment different settings unseen classes image features computed using deep networks vgg-verydeep- googlenet networks. vgg- -dim top-layer hidden unit activations googlenet -dim top-layer pooling units. keep weights learned imagenet ﬁxed i.e. don’t apply ﬁne-tuning. classiﬁers obtained adding standard fully connected softmax layer pre-trained networks. purposively chose simple classiﬁer better observe behavior generators. experiments generated artiﬁcial image features class consider reasonable trade-off accuracy training time; observed signiﬁcant improvement adding images. architecture hyper-parameters obtained trough ’zero-shot’ cross-validation procedure. procedure seen classes considered unseen allowing choose hyperparameters maximizing accuracy so-obtained practice typical values number validation set. neurons range model parameters initialized according centered gaussian distribution optimized adam solver cross-validated learning rate using mini-batches size except gmmn batch contains training images class make estimation statistics reliable. order avoid over-ﬁtting used dropout every layer input data scaled applying afﬁne transformation. tensorflow framework running nvidia titan pascal learning stage takes around minutes given hyper-parameters. code made publicly available. code made publicly available. comparing different generative models ﬁrst round experiments consists comparing performance generative models described section regular zero-shot classiﬁcation task. intention select best experiments. performance validation reported table gmmn model outperforms others average noticeable improvement ap&y. optimization also computationally stable explain superiority gmmn model fact aligns distributions using explicit model divergence distributions adversarial autoencoder ac-gan learn part denoising autoencoder doesn’t guaranty distributions aligned explaining weak performance compared generators. section follow generalized zero-shot learning protocol introduced chao protocol test data classes seen unseen. task realistic harder number class candidates larger. recent works e.g. focused improving embedding scoring function. however shown type approach unpractical gzsc. indeed scoring function case biased toward seen classes leading accuracy unseen classes. seen table accuracy drops signiﬁcantly compared regular performance. data distribution datasets strongly subject bias unseen classes similar seen classes terms visual appearance attribute description. seen unseen classes candidates becomes much harder distinguish them. example horse zebra classes dataset cannot distinguished standard methods. table generative approach hardest outperforms previous approach. case gives accuracy higher state-of-the-art approaches dataset. easily explained fact doesn’t suffer scoring function problem mentioned softmax classiﬁer learned discriminate seen unseen classes offering decisive solution bias problem. compared approach state-of-the-art methods large-scale zero-shot classiﬁcation task. experiences mirror presented classes imagenet chosen training others considered unseen classes image available. image features computed googlenet network contrast datasets attributes provided deﬁning unseen classes. represent categories using skip-gram language model model learned dump wikipedia corpus skip-gram language model learned predict context words. neural network input layer hidden layer output layer size vocabulary hidden layer neurons implementation. literature hidden layer reported interesting embedding space representing word. consetable zero-shot classiﬁcation accuracy runs. report results vgg- googlenet features. dataset evaluated different splits features extracted places pretrained model. motivations generating training images make training discriminative classiﬁers possible assuming would result better performance. section aims validating hypothesis regular task. table summarizes experiments reporting accuracy obtained state methods datasets different deep image features. entry mean/standard deviation computed different runs. network method give state-ofthe-art performance dataset noticeable improvement cub. dataset changpinyo seems give better performance used places dataset learn features. recently pointed sec. xiang database intersects training test classes could explain better results compared ours. paper introduces novel address zeroshot classiﬁcation generalized zero-shot classiﬁcation tasks learning conditional generator seen data generating artiﬁcial training examples categories without exemplars turning standard supervised learning problem. novel formulation addresses main limitation previous method i.e. intrinsic bias generalized zero-shot classiﬁcation tasks limitations using discriminative classiﬁers deep image feature space. experiments generative models datasets experimentally validate approach give state-of-the-art performance. frome norouzi changpinyo ours. frome norouzi ours. frome norouzi changpinyo ours. frome norouzi ours. frome norouzi changpinyo ours. frome norouzi ours. quently hidden layer describe class label embedding class name -dimensional space. classes cannot represented name contained vocabulary established parsing wikipedia corpus. classes ignored bringing number classes classes. fair comparison take language model classes excluded. table summarizes performance hops. model gets state-of performance conﬁguration. observed experiments generative model suitable large scale gzsc problem e.g. approach improves best competitors flat-hit metric -hop scenario.", "year": 2017}