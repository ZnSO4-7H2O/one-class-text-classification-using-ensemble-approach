{"title": "MarrNet: 3D Shape Reconstruction via 2.5D Sketches", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "3D object reconstruction from a single image is a highly under-determined problem, requiring strong prior knowledge of plausible 3D shapes. This introduces challenges for learning-based approaches, as 3D object annotations are scarce in real images. Previous work chose to train on synthetic data with ground truth 3D information, but suffered from domain adaptation when tested on real data. In this work, we propose MarrNet, an end-to-end trainable model that sequentially estimates 2.5D sketches and 3D object shape. Our disentangled, two-step formulation has three advantages. First, compared to full 3D shape, 2.5D sketches are much easier to be recovered from a 2D image; models that recover 2.5D sketches are also more likely to transfer from synthetic to real data. Second, for 3D reconstruction from 2.5D sketches, systems can learn purely from synthetic data. This is because we can easily render realistic 2.5D sketches without modeling object appearance variations in real images, including lighting, texture, etc. This further relieves the domain adaptation problem. Third, we derive differentiable projective functions from 3D shape to 2.5D sketches; the framework is therefore end-to-end trainable on real images, requiring no human annotations. Our model achieves state-of-the-art performance on 3D shape reconstruction.", "text": "object reconstruction single image highly under-determined problem requiring strong prior knowledge plausible shapes. introduces challenges learning-based approaches object annotations scarce real images. previous work chose train synthetic data ground truth information suffered domain adaptation tested real data. work propose marrnet end-to-end trainable model sequentially estimates sketches object shape. disentangled two-step formulation three advantages. first compared full shape sketches much easier recovered image; models recover sketches also likely transfer synthetic real data. second reconstruction sketches systems learn purely synthetic data. easily render realistic sketches without modeling object appearance variations real images including lighting texture etc. relieves domain adaptation problem. third derive differentiable projective functions shape sketches; framework therefore end-to-end trainable real images requiring human annotations. model achieves state-of-the-art performance shape reconstruction. humans quickly recognize shapes single image. figure shows number images chairs; despite drastic difference object texture material environment lighting background humans easily recognize similar shapes. essential information makes happen? researchers human perception argued perception could rely recovering sketches include intrinsic images like depth surface normal maps intrinsic images disentangle object appearance variations texture albedo lighting etc. shape retains information observed image reconstruction. humans combine sketches shape prior learned past experience reconstruct full shape ﬁeld computer vision also abundant works exploiting idea reconstruction shapes faces objects scenes recently researchers attempted tackle problem single image reconstruction deep learning. approaches usually regress shape single image directly contrast propose two-step end-to-end trainable pipeline sequentially recovering sketches shape. figure objects real images subject appearance variations regarding color texture lighting material background etc. despite this sketches like surface normal depth maps remain constant sketches seen abstraction image retaining information shape object inside. combine sketches learned shape priors reconstruct full shape encoder-decoder structure component framework also enforce reprojection consistency estimated sketch shape. name marrnet close resemblance david marr’s theory perception approach offers several unique advantages. first sketches releases burden domain transfer. single image reconstruction highly under-constrained problem strong prior knowledge object shapes needed. poses challenges learning-based methods accurate object annotations real images rare. previous methods turned training purely synthetic data however approaches often suffer domain adaption issue imperfect rendering. learning sketches images comparison much easier robust transfer synthetic real images shown section further second step recovers shape sketches abstraction input image trained purely relying synthetic data. though rendering diverse realistic images challenging straightforward obtain almost perfect object surface normals depths graphics engine. relieves domain adaptation issue. also enforce differentiable constraints sketches shape making system end-to-end trainable even real images without annotations. given unlabeled images algorithm pre-trained synthetic data infer sketches objects image reﬁne estimation objects’ shape. self-supervised feature enhances performance images different domains. evaluate framework synthetic images objects shapenet real images pascal dataset demonstrate framework performs well shape reconstruction qualitatively quantitatively. contributions three-fold inspired visual cognition theory propose two-step disentangled formulation single image reconstruction sketches; develop novel end-to-end trainable model differentiable projection layer ensures consistency shape mid-level representations; demonstrate effectiveness sketch transfer shape reconstruction synthetic real data. sketch recovery estimating sketches long-standing problem computer vision. past researchers explored recovering shape shading texture color images development depth sensors larger scale rgb-d datasets also papers estimating depth surface normals intrinsic images three major components sketch estimation shape estimation loss function reprojection consistency. marrnet ﬁrst recovers object normal depth silhouette images image. regresses shape sketches. steps uses encoding-decoding network. ﬁnally employs reprojection consistency loss ensure estimated shape aligns sketches. entire framework trained end-to-end. single image reconstruction problem recovering object shape single image challenging requires powerful recognition systems prior shape knowledge. development large-scale shape repository like shapenet researchers developed models encoding shape prior task extension scenes methods typically regress voxelized shape directly input image rely synthetic data masks training. comparison formulation tackles domain difference better end-to-end ﬁne-tuned images without annotations. consistency intuitive practically helpful constrain reconstructed shape consistent observations. researchers explored idea decades idea also widely used shape completion depths silhouettes recently papers discussed enforcing differentiable constraints shape silhouettes enabling joint training deep networks reconstruction paper exploit idea develop differentiable constraints consistency various sketches shape. recover structure single view image marrnet contains three parts ﬁrst sketch estimator predicts depth surface normal silhouette images object second shape estimator infers object shape using voxel representation third reprojection consistency function enforcing alignment estimated structure inferred sketches ﬁrst component network takes image input predicts sketch surface normal depth silhouette. goal sketch estimation step distill intrinsic object properties input images discarding properties non-essential task reconstruction object texture lighting. encoder-decoder network architecture sketch estimation. encoder resnet- encoding image feature maps size decoder contains four sets fully convolutional relu layers followed four sets convolutional relu layers. outputs corresponding depth surface normal silhouette images also resolution second part framework infers object shape estimated sketches. here network focuses learning shape prior explains input well. takes surface normal depth images input trained synthetic data without suffering domain adaption problem straightforward render nearly perfect sketches much harder render realistic images. network architecture inspired network d-vaegan encoding-decoding style. takes normal image depth image input maps -dim vector sets convolutional relu pooling layers followed fully connected layers. detailed encoder structure found girdhar vector goes decoder consists fully convolutional relu layers output voxel-based reconstruction input. detailed encoder structure found works attempting enforce consistency estimated shape representations neural network here explore novel ways include reprojection consistency loss predicted shape estimated sketch consisting depth reprojection loss surface normal reprojection loss. vxyz represent value position voxel grid assuming vxyz denote estimated depth position denote estimated surface normal. assume orthographic projection work. depths projected depth loss tries guarantee voxel depth vxydxy voxels front ensures estimated shape matches estimated depth values. illustrated figure deﬁne projected depth loss follows depth criterion reduces special case silhouette criterion. shown figure line intersection shape voxels surface normals vectors orthogonal norx vector normalize obtain vectors estimated surface plane projected surface normal loss tries guarantee voxels match estimated surface normals. constraints apply target voxels inside estimated silhouette. shown figure projected surface normal loss deﬁned employ two-step training paradigm. ﬁrst train sketch estimation shape estimation components separately synthetic images; ﬁne-tune network real images. pre-training synthetic images shapenet objects. sketch estimator trained using ground truth surface normal depth silhouette images loss. interpreter trained using ground truth voxels cross-entropy loss. please section details data preparation. reprojection consistency loss used ﬁne-tune estimation component model real images using predicted normal depth silhouette. observe straightforward implementation leads shapes explain sketches well unrealistic appearance. estimation module overﬁts images without preserving learned shape prior. figure examples section details. therefore choose decoder estimator ﬁne-tune encoder. testing method self-supervised i.e. ﬁne-tune even single image without annotations. practice ﬁne-tune model separately image iterations. test image ﬁne-tuning takes seconds modern gpu; without ﬁne-tuning testing time around milliseconds. optimization batch size learning rate momentum implemented framework torch section present qualitative quantitative results single image reconstruction using variants framework. evaluate entire framework synthetic real-life images three datasets. data start experiments synthesized images shapenet chairs objects front random backgrounds database render corresponding depth surface normal silhouette images. physics-based renderer mitsuba obtain realistic images. shapenet chairs render images random viewpoints. figure results rendered images shapenet objects left right input estimated normal estimated depth prediction baseline algorithm predicts shape directly input without modeling sketch ground truth. normal depth maps masked predicted silhouettes. method able recover shapes smoother surfaces ﬁner details. methods follow training paradigm described section without ﬁnal ﬁne-tuning stage ground truth shapes available synthetic dataset. speciﬁcally sketch estimator trained using ground truth depth normal silhouette images reconstruction loss. shape estimation module takes masked ground truth depth normal images input predicts voxels size binary cross entropy loss. compare marrnet baseline predicts shape directly image without modeling sketches. baseline employs architecture shape estimator show qualitative results figure estimated surface normal depth images abstract non-essential information like textures lighting image preserving intrinsic information object shape. compared direct prediction baseline model outputs objects details smoother surfaces. quantitative evaluation previous works usually compute intersection-over-union full model achieves higher direct prediction baseline methods follow paradigm described section ﬁrst train module separately shapenet dataset ﬁne-tune pascal dataset. unlike previous works model requires silhouettes input ﬁne-tuning; instead estimates silhouette jointly. ablation study compare three variants model ﬁrst model trained using shapenet data only without ﬁne-tuning; second ﬁne-tuned model whose decoder ﬁxed figure present ablation study compare variants models. left right input estimated normal estimated depth prediction ﬁne-tuning views prediction ﬁne-tuning without ﬁxing decoder views prediction ﬁne-tuning decoder ﬁxed. decoder ﬁxed model explains sketch well fails preserve learned shape prior. fine-tuning ﬁxed decoder resolves issue. results results ablation study shown figure model trained synthetic data provides reasonable shape estimate. ﬁne-tune model pascal without ﬁxing decoder output voxels explain sketch data well fail preserve learned shape prior leading impossible shapes certain views. ﬁnal model ﬁne-tuned decoder ﬁxed keeps shape prior provides details shape. show results figure compare state-of-the-art provided ground truth shapes. quantitatively algorithm achieves higher methods however metric sub-optimal three reasons. first measuring shape similarity challenging unsolved problem prefers models predict mean shapes consistently emphasize details. second object shape reconstructed scale single image requires searching possible scales computation making less efﬁcient. third discussed tulsiani pascal rough annotations computing shapes would thus informative evaluation metric. instead conduct human studies show users input image reconstructions choose looks closer shape image. show test image human subjects. shown table reconstruction preferred time time ground truth showing clear advantage. present failure cases figure algorithm perform well recovering complex thin structure sometimes fails estimated mask inaccurate. also beneﬁt multi-view supervision evaluated marrnet given single view shape though adapting formulation multi-view data straightforward. figure reconstructions chairs pascal dataset. left right input ground truth shape dataset estimation views marrnet predictions. model recovers accurate shapes. table human preferences chairs pascal compare marrnet state-of-the-art ground truth provided dataset. number shows percentage humans prefer left method one. marrnet preferred time time ground truth. data ikea dataset contains images ikea furniture along accurate shape pose annotations. images challenging objects often heavily occluded cropped. also evaluate model ikea dataset. results show qualitative results figure compare estimations d-vaegan ground truth. shown ﬁgure model deal mild occlusions real life scenarios. also conduct human studies ikea dataset. results show subjects prefer reconstructions d-vae-gan. figure reconstruction chairs ikea dataset. left right input ground truth estimation d-vae-gan views marrnet predictions. modelrecovers details compared d-vae-gan. proposed marrnet novel model explicitly models sketches single image shape reconstruction. sketches enhanced model’s performance made easily adaptive images across domains even categories. also developed differentiable loss functions consistency shape sketches marrnet end-to-end ﬁne-tuned real images without annotations. experiments demonstrated model performs well preferred human annotators competitors. thank shubham tulsiani sharing results chengkai zhang help shape visualization. work supported muri center brain minds machines toyota research institute samsung shell.", "year": 2017}