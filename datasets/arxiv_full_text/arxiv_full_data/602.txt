{"title": "Multi-task Recurrent Model for True Multilingual Speech Recognition", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "Research on multilingual speech recognition remains attractive yet challenging. Recent studies focus on learning shared structures under the multi-task paradigm, in particular a feature sharing structure. This approach has been found effective to improve performance on each individual language. However, this approach is only useful when the deployed system supports just one language. In a true multilingual scenario where multiple languages are allowed, performance will be significantly reduced due to the competition among languages in the decoding space. This paper presents a multi-task recurrent model that involves a multilingual speech recognition (ASR) component and a language recognition (LR) component, and the ASR component is informed of the language information by the LR component, leading to a language-aware recognition. We tested the approach on an English-Chinese bilingual recognition task. The results show that the proposed multi-task recurrent model can improve performance of multilingual recognition systems.", "text": "possible solution multilingual decoding problem inform decoder language processing. language information multilingual decoding essentially falls back monolingual decoding performance recovered. however language recognition subject recognition mistakes requires sufﬁcient signal give reasonable inference leading unacceptable delay. another possibility invoke monolingual decoding language decide result correct either conﬁdence language recognizer. approach obviously requires computing resource. deepspeech english chinese jointly decoded end-to-end learning framework. however based fact training data languages abundant language identities learned deep structure. certainly migrated low-resource languages difﬁcult accommodate languages. paper introduce multi-task recurrent model multilingual decoding. model model model treated components uniﬁed architecture output component propagated back extra information. speciﬁcally component provides speech information component deliver accurate language information turn helps component produce better results. note collaboration among takes places model training inference model particularly attractive multilingual decoding. model component provides language information component decoding utterance. language information produced frame frame becomes accurate decoding proceeds. information decoder becomes conﬁdent language processing gradually removes decoding paths hopeless languages. note multi-task recurrent model proposed found learn speech speaker recognition models collaborative way. idea also proposed abstract—research multilingual speech recognition remains attractive challenging. recent studies focus learning shared structures multi-task paradigm particular feature sharing structure. approach found effective improve performance individual language. however approach useful deployed system supports language. true multilingual scenario multiple languages allowed performance signiﬁcantly reduced competition among languages decoding space. paper presents multi-task recurrent model involves multilingual speech recognition component language recognition component component informed language information component leading language-aware recognition. tested approach english-chinese bilingual recognition task. results show proposed multi-task recurrent model improve performance multilingual recognition systems. recent years partly powerful deep learning approach interesting important task within research recognizing multiple languages. reason makes multilingual research attractive people different countries communicating frequently today. another reason limited resources languages multilingual techniques help improve performance low-resource languages. much work multilingual especially deep neural architecture. mostly studied architecture feature-shared deep neural network input low-level hidden layers shared across languages top-level layers output layer separated language insight design human languages share commonality acoustic phonetic layers signal patterns levels abstraction shared. despite brilliant success feature-sharing approach useful model training decoding. means although part model structure shared recognition models used independently individual languages language models. whenever language supported performance languages signiﬁcantly decreased rest paper organized follows section describes model architectures section reports experiments. conclusions plus future work presented section consider feature-sharing bilingual asr. represent primary input feature represent targets language respectively extra input obtained component information model estimates probability respectively makes decoding languages absolutely separate. truly required multilingual decoding means targets languages. regard extra input language indicator model language-aware. note languageaware model conditional model context condition. contrast feature-sharing model formulated essentially marginal refer bilingual single task respect single task actually compute proposed model jointly training indicates languages gaussian mixture model system generative modeling though languages still phone sets. promising architecture recurrent neural network especially long short-term memory ability modeling temporal sequences long-range dependencies. modiﬁed lstm structure proposed used. network structure shown fig. equations terms denote weight matrices associated cells diagonal implementation. terms denote bias vectors. input output symbols respectively; represent respectively input forget output gates; cell cell output. output components derived recurrent next time step recurrent contributes present output only. logistic sigmoid function non-linear activation functions often chosen hyperbolic. denotes element-wise multiplication. multi-task recurrent model basic idea multi-task recurrent model output task current frame auxiliary information supervise tasks processing next frame. many alternatives need carefully investigated. study recurrent lstm model following setting build component component shown fig. components identical structure accept input signal. difference trained different targets phone discrimination language discrimination. importantly inter-task recurrent links combine components single network shown dash lines fig. fig. simple example recurrent information extracted recurrent projection nonrecurrent projection information applied non-linear function superscript denote tasks respectively. computation expressed follows system built largely following kaldi nnet recipe except used single lstm layer simplicity. dimension cell dimensions recurrent nonrecurrent projections target delay frames. natural stochastic gradient descent algorithm employed train model input feature dimensional fbanks symmetric -frame window splice neighboring frames. output layer consisted units equal total number pdfs conventional system trained bootstrap lstm model. baseline monolingual presented table languages trained decoded separately. present baseline bilingually-trained system table uniﬁed system shared. latter ﬁrst decoded languages english chinese language models respectively denoted ‘mono-lm’ merged together mixture weight using tool ngram languages decoded within single uniﬁed graph built weighted ﬁnite-state transducers denoted ‘bi-lm’. proposed method tested aurora thchs databases labelled word transcripts. language identities english chinese. ﬁrst present single-task baseline report multi-task joint training model. experiments conducted kaldi toolkit training involves train sets aurora thchs. consists utterances. used train lstm-based single-task bilingual system proposed multi-task recurrent system. subsets also used train monolingual respectively. ﬂexibility multi-task recurrent lstm structure possible evaluate conﬁgurations. explored typical ones report results table iii. note last conﬁgure recurrent information gates non-linear activation augmenting information input variable results shown table decoded mono-lm bi-lm respectively ﬁrst observe multi-task recurrent model improves performance english chinese. attribute several reasons. first auxiliary component designed language recognition expected provide extra language information only english chinese databases source speech signal involves much channel information makes effect auxiliary language information decrease channel classiﬁcation done time. moreover channel classiﬁcation easily achieved regular superiority additional component decays. second results table using respective english gets gains performance obvious chinese even considering monolingual results table results mono-lm chinese table away monolingual bilingual baselines. imply method improving speech recognition wanting remarkable improvement database conﬁguration work well. it’s strange performance chinese could improved much enhanced model. furthermore done another test part train multi-task recurrent models perform better baseline english chinese means recurrent models overﬁt train extremely demonstrates ability proposed model. also observe multi-task recurrent model still potential exceed baseline recurrent information extracted recurrent projection activation function better performance english chinese. suppose many carefully-designed architectures baseline surpassed easily. report multi-task recurrent learning architecture language-aware speech recognition. primary results bilingual experiments aurora/thchs database demonstrated presented method employ commonality diversity different languages languages extent learning models simultaneously. future work involves using ideal databases source developing suitable architecture language-aware recurrent training introducing languages including source-scarce ones. hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath deep neural networks acoustic modeling speech recognition shared views four research groups signal processing magazine ieee vol. deng automatic speech recognition deep learning approach ser. signals communication technology. springer j.-t. huang deng gong cross-language knowledge transfer using multilingual deep neural network shared hidden layers proceedings ieee international conference acoustics speech signal processing ieee ghoshal swietojanski renals multilingual training deep neural networks proceedings ieee international conference acoustics speech signal processing ieee heigold vanhoucke senior nguyen ranzato devin dean multilingual acoustic models using distributed deep neural networks proceedings ieee international conference acoustics speech signal processing ieee amodei anubhai battenberg case casper catanzaro chen chrzanowski coates diamos deep speech end-to-end speech recognition english mandarin arxiv preprint arxiv. modeling speaker variability using long shortterm memory networks speech recognition proceedings annual conference international speech communication association senior beaufays long short-term memory based recurrent neural network architectures large vocabulary speech recognition arxiv preprint arxiv. senior beaufays long short-term memory recurrent neural network architectures large scale acoustic modeling proceedings annual conference international speech communication association povey ghoshal boulianne burget glembek goel hannemann motlicek qian schwarz kaldi speech recognition toolkit proceedings ieee workshop automatic speech recognition understanding. ieee signal processing society", "year": 2016}