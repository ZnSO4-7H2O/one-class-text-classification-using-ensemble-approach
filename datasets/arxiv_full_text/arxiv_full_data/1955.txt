{"title": "StackGAN: Text to Photo-realistic Image Synthesis with Stacked  Generative Adversarial Networks", "tag": ["cs.CV", "cs.AI", "stat.ML"], "abstract": "Synthesizing high-quality images from text descriptions is a challenging problem in computer vision and has many practical applications. Samples generated by existing text-to-image approaches can roughly reflect the meaning of the given descriptions, but they fail to contain necessary details and vivid object parts. In this paper, we propose Stacked Generative Adversarial Networks (StackGAN) to generate 256x256 photo-realistic images conditioned on text descriptions. We decompose the hard problem into more manageable sub-problems through a sketch-refinement process. The Stage-I GAN sketches the primitive shape and colors of the object based on the given text description, yielding Stage-I low-resolution images. The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high-resolution images with photo-realistic details. It is able to rectify defects in Stage-I results and add compelling details with the refinement process. To improve the diversity of the synthesized images and stabilize the training of the conditional-GAN, we introduce a novel Conditioning Augmentation technique that encourages smoothness in the latent conditioning manifold. Extensive experiments and comparisons with state-of-the-arts on benchmark datasets demonstrate that the proposed method achieves significant improvements on generating photo-realistic images conditioned on text descriptions.", "text": "synthesizing high-quality images text descriptions challenging problem computer vision many practical applications. samples generated existing textto-image approaches roughly reﬂect meaning given descriptions fail contain necessary details vivid object parts. paper propose stacked generative adversarial networks generate photo-realistic images conditioned text descriptions. decompose hard problem manageable sub-problems sketch-reﬁnement process. stage-i sketches primitive shape colors object based given text description yielding stage-i low-resolution images. stage-ii takes stage-i results text descriptions inputs generates high-resolution images photo-realistic details. able rectify defects stage-i results compelling details reﬁnement process. improve diversity synthesized images stabilize training conditional-gan introduce novel conditioning augmentation technique encourages smoothness latent conditioning manifold. extensive experiments comparisons state-of-the-arts benchmark datasets demonstrate proposed method achieves signiﬁcant improvements generating photo-realistic images conditioned text descriptions. figure comparison proposed stackgan vanilla one-stage generating images. given text descriptions stage-i stackgan sketches rough shapes basic colors objects yielding low-resolution images. stage-ii stackgan takes stage-i results text descriptions inputs generates high-resolution images photo-realistic details. results vanilla simply adds upsampling layers state-of-the-art gan-int-cls unable generate plausible images resolution. generating photo-realistic images text important problem tremendous applications including photo-editing computer-aided design etc. recently generative adversarial networks shown promising results synthesizing real-world images. conditioned given text descriptions conditionalhowever difﬁcult train generate high-resolution photo-realistic images text descriptions. simply adding upsampling layers state-ofthe-art models generating high-resolution images generally results training instability produces nonsensical outputs main difﬁculty generating high-resolution images gans supports natural image distribution implied model distribution overlap high dimensional pixel space problem severe image resolution increases. reed succeeded generating plausible images conditioned text descriptions usually lack details vivid object parts e.g. beaks eyes birds. moreover unable synthesize higher resolution images without providing additional annotations objects analogy human painters draw decompose problem text photo-realistic image synthesis tractable sub-problems stacked generative adversarial networks low-resolution images ﬁrst generated stage-i stage-i stack stage-ii generate realistic high-resolution images conditioned stage-i results text descriptions conditioning stage-i result text again stage-ii learns capture text information omitted stage-i draws details object. support model distribution generated roughly aligned low-resolution image better probability intersecting support image distribution. underlying reason stage-ii able generate better high-resolution images. addition text-to-image generation task limited number training text-image pairs often results sparsity text conditioning manifold sparsity makes difﬁcult train gan. thus propose novel conditioning augmentation technique encourage smoothness latent conditioning manifold. allows small random perturbations conditioning manifold increases diversity synthesized images. contribution proposed method threefold propose novel stacked generative adversarial networks synthesizing photo-realistic images text descriptions. decomposes difﬁcult problem generating high-resolution images manageable subproblems signiﬁcantly improve state art. stackgan ﬁrst time generates images resolution photo-realistic details text descriptions. conditioning augmentation technique proposed stabilize conditional training also improves diversity generated samples. extensive qualitative quantitative experiments demonstrate effectiveness overall model design well effects individual components provide useful information designing future conditional models. code available https//github.com/hanzhanggit/stackgan. generative image modeling fundamental problem computer vision. remarkable progress direction emergence deep learning techniques. variational autoencoders formulated problem probabilistic graphical models whose goal maximize lower bound data likelihood. autoregressive models utilized neural networks model conditional distribution pixel space also generated appealing synthetic images. recently generative adversarial networks shown promising performance generating sharper images. training instability makes hard models generate high-resolution images. several techniques proposed stabilize training process generate compelling results. energy-based also proposed stable training behavior. built upon generative models conditional image generation also studied. methods utilized simple conditioning variables attributes class labels also work conditioned images generate images including photo editing domain transfer super-resolution however super-resolution methods limited details low-resolution images correct large defects proposed stackgan does. recently several methods developed generate images unstructured text. mansimov built aligndraw model learning estimate alignment text generating canvas. reed used conditional pixelcnn generate images using text descriptions object location constraints. nguyen used approximate langevin sampling approach generate images conditioned text. however sampling approach requires inefﬁcient iterative optimization process. conditional reed successfully generated plausible images birds ﬂowers based text descriptions. follow-up work able generate images utilizing additional annotations object part locations. besides using single generating images also work utilized series gans image generation. wang factorized indoor scene generation process structure generation style generation proposed s-gan. contrast second stage stackgan aims complete object details correct defects stage-i results based text descriptions. denton built series gans within laplacian pyramid framework. level pyramid residual image generated conditioned image previous stage added back input image produce input next stage. concurrent work huang also showed generate better images stacking several gans reconstruct multi-level representations pre-trained discriminative model. however succeeded generating images method utilizes simpler architecture generate images photo-realistic details sixty-four times pixels. stacked generative adversarial networks generate high-resolution images photo-realistic details propose simple effective stacked generative adversarial networks. decomposes text-to-image generative process stages stage-i sketches primitive shape basic colors object conditioned given text description draws background layout random noise vector yielding low-resolution image. stage-ii corrects defects low-resolution image stage-i completes details object reading text description again producing highresolution photo-realistic image. generative adversarial networks composed models alternatively trained compete other. generator optimized reproduce true data distribution pdata generating images difﬁcult discriminator differentiate real images. meanwhile optimized distinguish real images synthetic images generated overall training procedure similar two-player min-max game following objective function conditional extension generator discriminator receive additional conditioning variables yielding formulation allows generate images conditioned variables conditioning augmentation shown figure text description ﬁrst encoded encoder yielding text embedding previous works text embedding nonlinearly transformed generate conditioning latent variables input generator. however latent space text embedding usually high dimensional limited amount data usually causes discontinuity latent data manifold desirable learning generator. mitigate problem introduce conditioning augmentation technique produce additional conditioning variables contrast ﬁxed conditioning text variable randomly sample latent variables independent gaussian distribution mean diagonal covariance matrix functions text embedding proposed conditioning augmentation yields training pairs given small number imagetext pairs thus encourages robustness small perturbations along conditioning manifold. enforce smoothness conditioning manifold avoid overﬁtting following regularization term objective generator training σ)||n kullback-leibler divergence standard gaussian distribution conditioning gaussian distribution. randomness introduced conditioning augmentation beneﬁcial modeling text image translation sentence usually corresponds objects various poses appearances. stage-i instead directly generating high-resolution image conditioned text description simplify task ﬁrst generate low-resolution image stage-i focuses drawing rough shape correct colors object. text embedding given description generated pre-trained encoder paper. gaussian conditioning variables text embedding sampled capture meaning variations. conditioned random variable stage-i trains discriminator generator alternatively maximizing minimizing real image text description true data distribution pdata. noise vector randomly sampled given distribution regularization parameter balances terms experiments. using reparameterization trick introduced learned jointly rest network. figure architecture proposed stackgan. stage-i generator draws low-resolution image sketching rough shape basic colors object given text painting background random noise vector. conditioned stage-i results stage-ii generator corrects defects adds compelling details stage-i results yielding realistic high-resolution image. fully connected layer generate gaussian distribution sampled gaussian distribution. dimensional conditioning vector computed element-wise multiplication then concatenated dimensional noise vector generate image series up-sampling blocks. discriminator text embedding ﬁrst compressed dimensions using fully-connected layer spatially replicated form tensor. meanwhile image series down-sampling blocks spatial dimension. then image ﬁlter concatenated along channel dimension text tensor. resulting tensor convolutional layer jointly learn features across image text. finally fullyconnected layer node used produce decision score. low-resolution images generated stage-i usually lack vivid object parts might contain shape distortions. details text might also omitted ﬁrst stage vital generating photo-realistic images. stage-ii built upon stage-i results generate high-resolution images. conditioned low-resolution images also text embedding correct defects stage-i results. stage-ii completes previously ignored text information generate photo-realistic details. different original formulation random noise used stage assumption randomness already preserved gaussian conditioning variables used stage used stage-i share pre-trained text encoder generating text embedding however stagestage-ii conditioning augmentation different fully connected layers generating different means standard deviations. stage-ii learns capture useful information text embedding omitted stage-i gan. model architecture. design stage-ii generator encoder-decoder network residual blocks similar previous stage text embedding used generate dimensional text conditioning vector spatially replicated form mg×mg×ng tensor. meanwhile stage-i result generated stage-i several down-sampling blocks until spatial size image features text features concatenated along channel dimension. encoded image features coupled text features several residual blocks designed learn multi-modal representations across image text features. finally series up-sampling layers discriminator structure similar stage-i discriminator extra down-sampling blocks since image size larger stage. explicitly enforce learn better alignment image conditioning text rather using vanilla discriminator adopt matching-aware discriminator proposed reed stages. training discriminator takes real images corresponding text descriptions positive sample pairs whereas negative sample pairs consist groups. ﬁrst real images mismatched text embeddings second synthetic images corresponding text embeddings. implementation details up-sampling blocks consist nearest-neighbor upsampling followed stride convolution. batch normalization relu activation applied every convolution except last one. residual blocks consist stride convolutions batch normalization relu. residual blocks used stackgan models four used models. down-sampling blocks consist stride convolutions batch normalization leakyrelu except ﬁrst batch normalization. default training ﬁrst iteratively train stage-i epochs ﬁxing stage-ii gan. iteratively train stage-ii another epochs ﬁxing stage-i gan. networks trained using adam solver batch size initial learning rate learning rate decayed previous value every epochs. validate method conduct extensive quantitative qualitative evaluations. state-of-the-art methods text-to-image synthesis gan-int-cls gawwn compared. results compared methods generated using code released authors. addition design several baseline models investigate overall design important components proposed stackgan. ﬁrst baseline directly train stage-i generating images investigate whether proposed stacked structure conditioning augmentation beneﬁcial. modify stackgan generate images investigate whether larger images method result higher image quality. also investigate whether inputting text stages stackgan useful. contains bird species images. since birds dataset object-image size ratios less pre-processing step crop images ensure bounding boxes birds greater-than-. object-image size ratios. oxford- contains images ﬂowers different categories. show generalization capability approach challenging dataset coco also utilized evaluation. different oxford coco dataset contains images multiple objects various backgrounds. training images validation images. image coco descriptions descriptions provided every image oxford datasets. following experimental setup directly training validation sets provided coco meanwhile split oxford- class-disjoint training test sets. difﬁcult evaluate performance generative models choose recently proposed numerical assessment approach inception score quantitative evaluation denotes generated sample label predicted inception model intuition behind metric good models generate diverse meaningful images. therefore divergence marginal distribution conditional distribution large. experiments directly pre-trained inception model coco dataset. ﬁne-grained datasets oxford- ﬁne-tune inception model them. suggested evaluate metric large number samples model. although inception score shown well correlate human perception visual quality samples cannot reﬂect whether generated images well conditioned given text descriptions. therefore also conduct human evaluation. randomly select text descriptions class oxford- test sets. coco dataset text descriptions randomly selected validation set. sentence images generated model. given text descriptions users asked rank results different methods. average ranks human users calculated evaluate compared methods. quantitative qualitative results datasets. inception scores average human ranks proposed stackgan compared methods reported table representative examples compared figure figure erage human rank three datasets. compared gan-int-cls stackgan achieves improvement terms inception score dataset improvement oxford- better average human rank stackgan also indicates proposed method able generate realistic samples conditioned text descriptions. shown figure samples generated gan-int-cls reﬂect general shape color birds. results lack vivid parts convincing details cases make neither realistic enough sufﬁciently high resolution. using additional conditioning variables locaing short beak white color described text well details tail legs. examples different degrees details added stage-ii images. many cases stage-ii able correct defects stage-i results processing text description again. example stage-i image column blue crown rather reddish brown crown described text defect corrected stage-ii gan. extreme cases even stage-i fails draw plausible shape stage-ii able generate reasonable objects. also observe stackgan ability transfer background stage-i images ﬁne-tune realistic higher resolution stage-ii. importantly stackgan achieve good results simply memorizing training samples capturing complex underlying language-image relations. extract visual features generated images training images stage-ii discriminator stackgan. generated image nearest neighbors training retrieved. visually inspecting retrieved images conclude generated images similar characteristics training samples essentially different. subsection analyze different components stackgan dataset baseline models. inception scores baselines reported table design stackgan. shown ﬁrst four rows table stage-i directly used generate images inception scores decrease signiﬁcantly. performance drop well illustrated results figure shown ﬁrst figure stage-i fails generate plausible samples without figure generated images retrieving nearest training images utilizing stage-ii discriminator extract visual features. distances features calculated nearest-neighbor retrieval. tion constraints gawwn obtains better inception score dataset still slightly lower ours. generates higher resolution images details gan-int-cls shown figure however mentioned authors gawwn fails generate plausible images conditioned text descriptions comparison stackgan generate photo-realistic images text descriptions. figure illustrates examples stage-i stage-ii images generated stackgan. shown ﬁrst figure cases stage-i able draw rough shapes colors objects given text descriptions. however stage-i images usually blurry various defects missing details especially foreground objects. shown second stageii generates higher resolution images convincing details better reﬂect corresponding text descriptions. cases stage-i generated plausible shapes colors stage-ii completes details. instance column figure satisfactory stage-i result stage-ii focuses drawfigure conditioning augmentation helps stabilize training conditional improves diversity generated samples. without stage-i fails generate plausible samples. although different noise vector used column generated samples collapse input text description. ﬁxing noise vectors methods still able generate birds different poses viewpoints. using conditioning augmentation although stage-i able generate diverse samples samples realistic samples generated stackgan. demonstrates necessity proposed stacked structure. addition decreasing output resolution inception score decreases note images scaled calculating inception score. thus stackgan increases image size without adding information inception score would remain samples different resolutions. therefore decrease inception score stackgan demonstrates stackgan details larger images. stackgan text input stage-i inception score decreases indicates processing text descriptions stage-ii helps reﬁne stage-i results. conclusion drawn results stackgan models. conditioning augmentation. also investigate efﬁcacy proposed conditioning augmentation removing stackgan inception score decreases figure also shows stage-i generate birds different poses figure images generated interpolating sentence embeddings. gradual appearance changes ﬁrst sentence’s meaning second sentence observed. noise vector ﬁxed zeros row. viewpoints text embedding. contrast without using samples generated stagegan collapse nonsensical images unstable training dynamics gans. consequently proposed conditioning augmentation helps stabilize conditional training improves diversity generated samples ability encourage robustness small perturbations along latent manifold. sentence embedding interpolation. demonstrate stackgan learns smooth latent data manifold generate images linearly interpolated sentence embeddings shown figure noise vector generated image inferred given text description only. images ﬁrst generated simple sentences made sentences contain simple color descriptions. results show generated images interpolated embeddings accurately reﬂect color changes generate plausible bird shapes. second illustrates samples generated complex sentences contain details bird appearances. generated images change primary color blue change wing color black brown. paper propose stacked generative adversarial networks conditioning augmentation synthesizing photo-realistic images. proposed method decomposes text-to-image synthesis novel sketch-reﬁnement process. stage-i sketches object following basic color shape constraints given text descriptions. stage-ii corrects defects stage-i results adds details yielding higher resolution images better image quality. extensive quantitative qualitative results demonstrate effectiveness proposed method. compared existing text-to-image generative models method generates higher resolution images photo-realistic details diversity.", "year": 2016}