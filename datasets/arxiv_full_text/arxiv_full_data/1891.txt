{"title": "Are You Talking to a Machine? Dataset and Methods for Multilingual Image  Question Answering", "tag": ["cs.CV", "cs.CL", "cs.LG", "I.2.6; I.2.7; I.2.10"], "abstract": "In this paper, we present the mQA model, which is able to answer questions about the content of an image. The answer can be a sentence, a phrase or a single word. Our model contains four components: a Long Short-Term Memory (LSTM) to extract the question representation, a Convolutional Neural Network (CNN) to extract the visual representation, an LSTM for storing the linguistic context in an answer, and a fusing component to combine the information from the first three components and generate the answer. We construct a Freestyle Multilingual Image Question Answering (FM-IQA) dataset to train and evaluate our mQA model. It contains over 150,000 images and 310,000 freestyle Chinese question-answer pairs and their English translations. The quality of the generated answers of our mQA model on this dataset is evaluated by human judges through a Turing Test. Specifically, we mix the answers provided by humans and our model. The human judges need to distinguish our model from the human. They will also provide a score (i.e. 0, 1, 2, the larger the better) indicating the quality of the answer. We propose strategies to monitor the quality of this evaluation process. The experiments show that in 64.7% of cases, the human judges cannot distinguish our model from humans. The average score is 1.454 (1.918 for human). The details of this work, including the FM-IQA dataset, can be found on the project page: http://idl.baidu.com/FM-IQA.html", "text": "paper present model able answer questions content image. answer sentence phrase single word. model contains four components long short-term memory extract question representation convolutional neural network extract visual representation lstm storing linguistic context answer fusing component combine information ﬁrst three components generate answer. construct freestyle multilingual image question answering dataset train evaluate model. contains images freestyle chinese question-answer pairs english translations. quality generated answers model dataset evaluated human judges turing test. speciﬁcally answers provided humans model. human judges need distinguish model human. also provide score indicating quality answer. propose strategies monitor quality evaluation process. experiments show cases human judges cannot distinguish model humans. average score details work including fm-iqa dataset found project page http//idl.baidu.com/fm-iqa.html. recently increasing interest ﬁeld multimodal learning natural language vision. particular many studies made rapid progress task image captioning built based deep neural networks recurrent neural network long short-term memory large-scale image datasets sentence annotations play crucial role progress. despite success methods still many issues discussed explored. particular task image captioning requires generic sentence descriptions image. many cases care particular part object image. image captioning task lacks interaction computer user paper focus task visual question answering. task method needs provide answer freestyle question content image. propose model address task. inputs model image question. model four components ﬁrst component lstm network encodes natural language sentence dense vector representation. second component deep convolutional neural network extracted image representation. component pre-trained imagenet classiﬁcation task ﬁxed training. third component another lstm network encodes information current word previous words answer dense representations. fourth component fuses information ﬁrst three components predict next word answer. jointly train ﬁrst third fourth components maximizing probability groundtruth answers training using log-likelihood loss function. lower risk overﬁtting allow weight sharing word embedding layer lstms ﬁrst third components. also adopt transposed weight sharing scheme proposed allows weight sharing word embedding layer fully connected softmax layer. train method construct large-scale freestyle multilingual image question answering dataset based coco dataset current version dataset contains images chinese question-answer pairs corresponding english translations. diversify annotations annotators allowed raise question related content image. propose strategies monitor quality annotations. dataset contains wide range related questions action recognition object recognition positions interactions among objects image reasoning based commonsense visual content variability freestyle question-answer pairs hard accurately evaluate method automatic metrics. conduct visual turing test using human judges. speciﬁcally question-answer pairs generated model questionanswer pairs labeled annotators. human judges need determine whether answer given model human. addition also give score results show model passes test average score discussion analyze failure cases model show combined m-rnn model model automatically question image answer question. recent work made signiﬁcant progress using deep neural network models ﬁelds computer vision natural language. computer vision methods based convolutional neural network achieve state-of-the-art performance various tasks object classiﬁcation detection segmentation natural language recurrent neural network long short-term memory network also widely used machine translation speech recognition structure model inspired m-rnn model image captioning image-sentence retrieval tasks. adopts deep vision language. extend model handle input question image pairs generate answers. experiments learn good question image using m-rnn model question answered model. recent effort visual question answering task however pre-deﬁned restricted questions. questions generated template. addition fm-iqa dataset much larger respectively). figure illustration model architecture. input image question image model. model trained generate answer question weight matrix word embedding layers lstms shared. addition weight matrix also shared transposed manner weight matrix softmax layer. different colors ﬁgure represent different components model. concurrent independent works topic propose largescale dataset also based coco. also provide simple baseline methods dataset. compared them propose stronger model task evaluate method using human judges. dataset also contains different kinds language useful tasks machine translation. different annotators different requirements annotation dataset complementary other lead interesting topics dataset transferring visual question answering. model containing single lstm cnn. concatenate question answer answer single word. also prefer single word answer) feed lstm. different them separate lstms questions answers respectively consideration different properties questions answers allow sharing word-embeddings. dataset adopt dataset proposed much smaller fm-iqa dataset. utilize annotations coco synthesize dataset four pre-deﬁned types questions also synthesize answer single word. dataset also complementary ours. multimodal model show architecture model figure model four components long short-term memory extracting semantic representation question deep convolutional neural network extracting image representation lstm extract representation current word answer linguistic context fusing component incorporates information ﬁrst three parts together generates next word answer. four components jointly trained together details four model components described section effectiveness important components strategies analyzed section inputs model question reference image. model trained generate answer. words question answer represented one-hot vectors sign sign spatial words word dictionary beginning training answers respectively. used generating answer question testing stage. testing stage input image question image model ﬁrst. generate answer start start sign model calculate probability distribution next word. beam search scheme keeps best candidates maximum probabilities according softmax layer. repeat process model generates sign answer boa. four components model semantic meaning question extracted ﬁrst component model. contains dimensional word embedding layer lstm layer memory cells. function word embedding layer one-hot vector word dense semantic space. feed dense word representation lstm layer. lstm recurrent neural network designed solving gradient explosion vanishing problem. lstm layer stores context information memory cells serves bridge among words sequence model long term dependency data effectively lstm three gate nodes traditional structure input gate output gate forget gate. input gate output gate regulate read write access lstm memory cells. forget gate resets memory cells contents date. different image representation feed lstm component. believe reasonable questions another input source model images supervision them. information stored lstm memory cells last word question treated representation sentence. second component deep convolutional neural network generates representation image. paper googlenet note models alexnet vggnet also used component model. remove ﬁnal softmax layer deep connect remaining layer model. third component also contains word embedding layer lstm. structure similar ﬁrst component. activation memory cells words answer well word embeddings fusing component generate next words answer. concatenate training question answer single lstm. different properties question answer paper separate lstms questions answers respectively. denote lstms question answer lstm lstm respectively rest paper. weight matrix lstm shared lstm ﬁrst components. note semantic meaning single words questions answers share parameters word-embedding layer ﬁrst third component. denotes element-wise addition stands activation lstm memory cells last word question denotes image representation denotes activation lstm memory cells word embedding word answer respectively. weight matrices need learned. element-wise non-linear function. fusing layer build intermediate layer maps dense multimodal representation fusing layer back dense word representation. build fully connected softmax layer predict probability distribution next word answer. strategy allows weight sharing word embedding layer fully connected softmax layer introduced similar sigmoid function activation function three gates adopt relu non-linear function lstm memory cells. non-linear activation function word embedding layer fusing layer intermediate layer scaled hyperbolic tangent function tanh. training details used pre-trained imagenet classiﬁcation task component ﬁxed training. adopt log-likelihood loss deﬁned word sequence answer. minimizing loss function equivalent maximizing probability model generate groundtruth answers training set. jointly train ﬁrst second fourth components using stochastic gradient decent method. initial learning rate decrease factor every epoch data. stop training loss validation decrease within three epochs. hyperparameters model selected cross-validation. freestyle multilingual image question answering dataset method trained evaluated large-scale multilingual visual question answering dataset. section describe process collect data method monitor quality annotations. statistics examples dataset given section latest dataset available project page http//idl.baidu.com/fm-iqa.html data collection start images newly released coco training validation testing initial image set. annotations collected using baidu’s online crowdsourcing server. make labeled question-answer pairs diversiﬁed annotators free give type questions long questions related content image. question answered visual content commonsense annotators need give answer question themselves. hand freedom give annotators beneﬁcial order freestyle interesting diversiﬁed questions. hand makes harder control quality annotation compared detailed instruction. monitor annotation quality conduct initial quality ﬁltering stage. speciﬁcally randomly sampled images quality monitoring dataset coco dataset initial annotators sample annotations rate quality annotator ﬁnishes labeling quality monitoring dataset select small number annotators whose annotations satisfactory also give preference annotators provide interesting questions require high level reasoning give answer. selected annotators permitted label rest images. pick good examples annotated question-answer pairs quality monitoring dataset show selected annotators references. also provide reasons selecting examples. annotation images ﬁnished reﬁne dataset remove small portion images badly labeled questions answers. statistics dataset currently images chinese question-answer pairs english translations. image least question-answer pairs annotations. average lengths questions answers respectively measured chinese words. sample images shown figure randomly sampled question-answer pairs corresponding images test set. questions dataset diversiﬁed requires vast capabilities order answer them. contain relatively simple image understanding questions e.g. actions objects object class relative positions interactions among objects attributes objects addition dataset contains questions need high-level reasoning clues vision language commonsense. example answer question park there? know question parked image holding tools back. based commonsense guess might problems image trying repair questions hard answer believe actually interesting part questions dataset. categorize questions types show statistics project page. recent works visual question answering test method datasets answer question single word short phrase. setting plausible automatic evaluation metrics measure single word similarity wu-palmer similarity measure however newly proposed dataset answers dataset freestyle complete sentences. cases numerous choices answers correct. possible alternatives bleu score meteor cider metrics widely used image captioning task problem metrics words answer semantically critical. metrics tend give equal weights different weights according tf-idf frequency term words sentence hence cannot fully show importance keywords. evaluation image captioning task suffers problem avoid problems conduct real visual turing test using human judges model described details section addition rate generated sentences score section gives ﬁne-grained evaluation method. section provide performance comparisons different variants model validation set. visual turing test visual turing test human judge presented image question answer question generated testing model human annotators. need determine based answer whether answer given human machine practice images questions test fm-iqa dataset. model generate answer question. also implement baseline model question answering without visual information. structure baseline model similar except feed image information extracted fusing layer. denote blind-qa. answers generated model blind-qa model groundtruth answer mixed together. leads question answering pairs corresponding images randomly assigned human judges. results shown table shows answers generated model treated answers provided human. blind-qa performs badly task. generated answers pass test. questions actually multi-choice questions possible correct answer random guess based pure linguistic clues. study variance evaluation across different sets human judges conduct additional evaluations different groups judges setting. standard deviations passing rate human blind-mqa model model respectively. shows stable reliable evaluation metric task. score generated answer visual turing test gives rough evaluation generated answers. also conduct ﬁne-grained evaluation scores mean answer totally wrong perfectly correct respectively. means answer partially correct makes sense human judges. human judges task necessarily people visual turing test. collecting results human judges also rate answer question hard answer even human without carefully looking image possibly make mistakes. show randomly sampled images whose scores figure results shown table show among answers perfectly correct half partially correct. similar evaluation process also conducts additional groups scoring evaluation. standard deviations human model respectively. addition cases three groups give score human model respectively. performance comparisons different variants order show effectiveness different components strategies model implement three variants figure ﬁrst variant replace ﬁrst lstm component model average embedding words question using wordvec used show effectiveness lstm question embedding learner extractor. second variant shared-weights lstms model question answer. used show effectiveness decoupling strategy weights lstm lstm model. third variant adopt transposed weight sharing strategy. used show effectiveness tws. word error rates losses three variants complete model shown table three variants performs worse model. discussion paper present model able give sentence phrase answer freestyle question image. validate effectiveness method construct freestyle multilingual image question answering dataset containing question-answer pairs. evaluate method using human judges real turing test. shows answers given model treated answers provided human. fm-iqa dataset used tasks visual machine translation visual information serve context information helps remove ambiguity words sentence. also modiﬁed lstm ﬁrst component multimodal lstm shown modiﬁcation allows generate free-style question content image provide answer question. show sample results figure show failure cases model figure model sometimes makes mistakes commonsense reasoning background scenes incorrect another interesting example image question ﬁfth column figure answering question hard since needs high level reasoning based experience everyday life. model outputs sign special word model meets word seen", "year": 2015}