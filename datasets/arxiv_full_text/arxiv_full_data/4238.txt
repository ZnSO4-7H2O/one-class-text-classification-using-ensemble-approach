{"title": "End-to-end 3D shape inverse rendering of different classes of objects  from a single input image", "tag": ["cs.CV", "cs.AI"], "abstract": "In this paper a semi-supervised deep framework is proposed for the problem of 3D shape inverse rendering from a single 2D input image. The main structure of proposed framework consists of unsupervised pre-trained components which significantly reduce the need to labeled data for training the whole framework. using labeled data has the advantage of achieving to accurate results without the need to predefined assumptions about image formation process. Three main components are used in the proposed network: an encoder which maps 2D input image to a representation space, a 3D decoder which decodes a representation to a 3D structure and a mapping component in order to map 2D to 3D representation. The only part that needs label for training is the mapping part with not too many parameters. The other components in the network can be pre-trained unsupervised using only 2D images or 3D data in each case. The way of reconstructing 3D shapes in the decoder component, inspired by the model based methods for 3D reconstruction, maps a low dimensional representation to 3D shape space with the advantage of extracting the basis vectors of shape space from training data itself and is not restricted to a small set of examples as used in predefined models. Therefore, the proposed framework deals directly with coordinate values of the point cloud representation which leads to achieve dense 3D shapes in the output. The experimental results on several benchmark datasets of objects and human faces and comparing with recent similar methods shows the power of proposed network in recovering more details from single 2D images.", "text": "paper semi-supervised deep framework proposed problem shape inverse rendering single input image. main structure proposed framework consists unsupervised pre-trained components signiﬁcantly reduce need labeled data training whole framework. using labeled data advantage achieving accurate results without need predeﬁned assumptions image formation process. three main components used proposed network encoder maps input image representation space decoder decodes representation structure mapping component order representation. part needs label training mapping part many parameters. components network pre-trained unsupervised using images data case. reconstructing shapes decoder component inspired model based methods reconstruction maps dimensional representation shape space advantage extracting basis vectors shape space training data restricted small examples used predeﬁned models. therefore proposed framework deals directly coordinate values point cloud representation leads achieve dense shapes output. experimental results several benchmark datasets objects human faces comparing recent similar methods shows power proposed network recovering details single images. inverse rendering stands speciﬁc class machine learning techniques recovering properties scene like camera’s extrinsic parameters scene lighting shape scene existing measurements attracted high interest recent academic research wide applications computer vision inverse rendering well posed problem existing inﬁnite number structure result image facing problems needs additional assumptions prior knowledge class structures recovered images. instance statistical model used determine solution likely speciﬁc class objects intensity pixels image) represents object surface reﬂects lights various spatial angular positions describes lighting scene measurement showing light transferred existing surfaces scene light reﬂected surfaces scene aﬀecting knowing quantities means properties scene known computed using quantities direct problem solve. inverse rendering problem arises information available compute values right-hand side paper focus recovering shape geometry object single input image diﬀerent poses implicitly embedded variable spatial properties surface light reﬂection. selection model selection model main necessities solving machine learning problems free lunch theorem case recovering structures images step important problems deal ill-posed problem based hadmard deﬁnition well-posed problems might solutions give image solution depends continuously data means small errors measurements cause large errors solutions solving kinds problems assumptions usually made properties solutions restrict solution space feasible regions. selection suitable model deﬁning target scene serves prior knowledge solution space search performed reliable. like using assumptions method costs like losing promising regions spanned selected model. inverse rendering problems various types models prior knowledge target scene literature make existing methods diﬀerent other approaches additional information like multiple images video sequence landmarks scene unique solution work certain statistical model determine feasibility solutions perform regressing techniques relates output measurements structures paper focus pose invariant recovering structure object single image help model describing properties object. main structure proposed framework based ﬁnding relation measurements i.e. single image scene structure scene constrained used model. deﬁning score criterionafter selection suitable model describing solution space optimum solution searched space. ﬁrst criterion deﬁned guides search toward ﬁnding optimum solution satisfying constraints problem hand. instance case inverse rendering human face image face recognition task ﬁrst main objective recover distinctiveness characteristics face image good solution generic determined tradeoﬀ properties objective criterion paper since objective minimize reconstruction error used root mean square error loss function training evaluation. deﬁning search strategythere exist diﬀerent types search mechanisms search solution based deﬁned score criterion. case convex criteria closed form solution exists search done linear time. however nature inverse rendering problem highly nonlinear inference ﬁnding relation image corresponding structure intractable. assumptions incorporated problem like deterministic models formulating behavior variables rendering equation deﬁned accurately solution computed closed form however cannot strong assumptions inverse rendering problems. cases learning based methods training models test samples. popular learning framework recent years deep networks show power solving nonlinear problems. deep networks like learning based structures trained ways supervised unsupervised semi-supervised. supervised methods labeled data guide training. result accurate availability ground truth training procedure suﬀer lack enough labeled training data domains. case inverse rendering applications providing enough realistic training data deep network impractical. solution problem generative model generating synthetic training data trained network another solution found attempts recent literature unsupervised training network reconstruction structure generated part network rendering mechanism used transform generated structure something form input measurement network reduce diﬀerence input rendered output. network need labeled data training. existing unsupervised methods literature used analytical form rendering structure assumptions image formation process. characteristic although signiﬁcant improvement reducing need training data aﬀects quality solutions existing assumptions rendering mechanism case inverse rendering problem well known models help generate enough data training deep networks. paper propose mechanism parts network trained using unlabeled data whole network ﬁne-tuned using labeled training data aggregation components. believe properties reduces nedd deep network large training data. therefore semi-supervised framework inverse rendering problem. section review analyze recent related works. proposed framework network structure deﬁne details section experimental results verify performance proposed structure several benchmarks demonstrated section ﬁnally discussions conclusions found sections proposed framework composed main components based fact inverse rendering problem look transforming input image corresponding structure. mapping input image corresponding structure suitable representations ﬁnding transformation obtained representations. show experimentally nonlinear mapping suitable representations results accurate solutions. ﬁnding suitable representations done using autoencoders unsupervised tools ﬁnding representations pre-trained convolutional networks ﬁnding suitable representations. either diﬀerent types autoencoder existing well known networks literature. case using autoencoders ﬁnding representations inspired morphable models network extracts basis vectors training data size uses basis functions reconstruct accurate shape object rather using pre-deﬁned dmm. figure shows overall structure proposed framework. details proposed idea found section richardson proposed deep iterative framework inverse rendering human faces. iteration framework output network input additional information ﬁne-tune previous result. training process method supervised using generating synthetic labeled training data. ﬁnal output ﬁne-tuned using form shape shading method achieve details.the authors improve work where component network implemented another deep network. output framework coeﬃcients predeﬁned computed using hundred samples framework directly deal shape structures. supervised framework reconstruction human faces single image proposed also used generating training data. ﬁtted images optimization method used model ground truth training data. strategy ﬁnding ground truth cause found solutions dependent power optimization method powers work ignored. loss function also used training network human faces tuned make trade-oﬀ generic face generation overdetermined suitable purpose face recognition. unsupervised framework reconstruction objects single multiple input images volumes proposed. authors suggested inference network encoding input data dimensional representation generative network generating objects using encoded data. obtained object rendered image using ﬁxed diﬀerentiable rendering method. objective training network minimize diﬀerence rendered input images. using ﬁxed rendering component restrict accuracy generated shapes input image rendering mechanism diﬀers network rendering mechanism.the authors also suggested using convolutional network rendering component. using another deep network rendering component overcome mentioned limitation. autoencoder network proposed reconstruction human faces using unsupervised training mechanism. network encoder part autoencoder convolutional network like well-known alexnet vgg-face networks decoder part analytical diﬀerentiable formula uses encoded data assumptions image formation process form face render image. paper objective also minimize diﬀerence input image rendered shape using rendering method. generative adversarial network trained generating shapes diﬀerent objects. method unsupervised training approach random vector distribution network shape object generated rendered form image input discriminator. discriminator need shape control process learning shapes. rendering method ﬁxed network used generate training data inverse rendering frameworks objects. designed recover geometry texture human faces single image. framework directly works coordinates form proposed binary volumes maps images directly coordinates binary volume. using binary volume coordinates representing human face result blur shapes. paper design deep framework shape inverse rendering diﬀerent types shape representations point clouds volume representations single input image. training process utilizes labeled unlabeled realistic data improving quality resulted shapes. following section demonstrates proposed approach details. main idea work end-to-end mapping representation single input image representation corresponding shape structure. deﬁning structure actually based main functionality deep networks using diﬀerent layers nonlinear computations order feature extraction transformation proposed framework also made components feature extraction transformation. stated section used three main components framework ﬁrst component trained compute representations input images. second component trained reconstructing shape representations third components used representation computed ﬁrst component used second component. representations component satisfy objective. instance component computing representation image computes representation suitable mapped representation. hand representation suitable reconstructing shape form point cloud binary volume. observed experiments complex representations representation component achieve better performance decoder part linear autoencoder reconstruction component suitable reconstructing shape form point cloud. third component structure mapping low-dim representation corresponding representation. actually proposed component manifold images diﬀerent manifold shapes especially case complicated shapes like human faces therefore nonlinear mapping function found obtain accurate representation image representation. note proposed frameworks deals directly dense shapes objects instead using predeﬁned models representing face. characteristic advantage restricted spanning obtained samples using larger training data extracting suitable basis vectors shape spaces. main contributions paper follows using deep structures diﬀerent components interpretable framework mapping representations manifold another directly reconstructing results. using deep structures component improves handling non-linearity stage. possibility unsupervised pre-training component using unlabeled data representations improved using realistic data in-the-wild therefore reducing need labeled data training suitable initialization training. fact labeled data needed ﬁnal aggregation pre-trained components. section analytically describe proposed idea paper simplest case i.e. linear case. calculations gives mathematical insight motivation proposing framework. section evaluate idea using diﬀerent datasets compare possible method case solving shape inverse rendering problem. assume linear case component linear autoencoder encoder decoder components linear feedforward network mapping component. proven that optimal representation space resulted linear autoencoder using l-norm loss function spanning sub-space resulted performing data. therefore consider linear autoencoder equivalent performing training data. therefore inferred weights hidden output layer trained linear autoencoder fact bases resulted representation subspace found using training data autoencoder. characteristic means that using linear autoencoder obtain bases representation space data size without concern basis vector decomposition large data matrix. where matrix columns representing eigenvectors diagonal matrix eigenvalues diagonal elements denotes matrix eigenvectors columns. therefore columns basis vectors resulted representation subspace images k-dimensional representation resulting sub-space spanned ﬁrst eigenvectors largest eigen values expressed similarly considering column matrix containing p-dimensional vectorized training samples shape structures represented point clouds binary volumes resulted k’-dimensional representation using another autoencoder expressed bk×n transformation obtained representations inverse rendering problem linear feedforward used equivalent performing least square mechanism linear relation approaches look subspace best describes shape objects image. ﬁrst approach ﬁrst tries dimensional representation input image corresponding structure training data linear solution found transforming representation least squares. note matrices ˆband used mapping functions test data. examples used calculating necessarily correspond used obtain mechanism shows possibility unsupervised training diﬀerent components method. second closed form approach directly ﬁnds linear mapping input image corresponding structure. believe ﬁrst approach signiﬁcantly improves process ﬁnding solution inverse rendering problem table section veriﬁed claim experimentally compared second approach loss function mentioned before purpose proposed framework paper recover shape object. deal regression problem. therefore used root mean squared error loss criterion training components proposed framework. criterion standard deviation prediction error standard regression analysis where denote prediction ground truth training sample stands sample size. here sample size stands size mini batch. diﬀerent loss functions proposed used inverse rendering problems diﬀerent researches diﬀerent applications like reconstruction recognition. binary voxel representation used representing faces sigmoid cross entropy loss function used training network. framework deal mesh representation voxel representations. choose standard rmse training networks. section perform experiments evaluate performance proposed framework diﬀerent inverse rendering scenarios. used types datasets objects human faces diﬀerent shape representations like point clouds binary volumes order report compare reconstruction results. also analyse structures diﬀerent components framework. datasets report results performance proposed framework types datasets objects human faces. case trained separate structure using type data representation. also used unlabeled datasets order unsupervised pre-training components. case human faces used dataset unlabeled data unsupervised pre-training besel face model generating synthetic data labeled training data along bosphorus dataset realistic labeled data training ﬁne-tuning respectively. note aggregating components using supervised training used faces generated besel face model natural expression rendered poses i.e. degrees axis. therefore objective human face shape inverse rendering work pose invariant identity recovering faces single image. faces framework represented point clouds vertices space normalized dimension. generated training test samples natural expression rendered images size mentioned poses input images. case objects used categories imagenet dataset unlabeled data pretraining modelnet shapenet datasets labeled training data best knowledge well-known datasets object reconstructions. used categories training networks form binary voxel grid rendered training sample gray scale image viewpoints case linear autoencoders vectorized voxel grid binary column vector size incorporate well-known alexnet experiments evaluating deep computing representations face dataset. case rendered used colored images faces existing dataset size standard input size alexnet framework. parameter setting table includes conﬁguration structure used type dataset type used structure. since applied inverse rendering diﬀerent data types diﬀerent structures network components case. learning rate conﬁguration gives better performance. cases uses epochs reduce another epochs. case mesh representation learning slower needed smaller learning rate longer training time. batch size constant cases equal training. trained networks scratch waterloo university servers gpu-pr- gpu-pt- saspc sharcnet-graham machines well-known servers several gpus suitable training deep networks. evaluation mechanism used rmse evaluation criterion test validation sets diﬀerent parts experiments. case face datasets also showed rmse form heat maps showing point-wise rmse reconstructed face ground truth face suitable tool error visualization diﬀerent regions reconstructed face. start experiments ﬁrst reporting evaluation results closed form linear solutions described section using diﬀerent data types. next step equivalent deep structure changing mapping component nonlinear structure show results signiﬁcantly improved. nonlinear component encoder part framework ﬁne-tuned alexnet using labeled human face dataset report results. show reconstruction results realistic human face dataset compare results recent methods reconstruction. results solving linear closed form formula inverse rendering regarding analytical description proposed idea section show ﬁnding linear mapping dimensional representations data achieves signiﬁcantly better results rather ﬁnding direct linear mapping table ﬁgures include numerical visual results applying methods diﬀerent datasets using representation stands ﬁnding mapping dimensional representations data using least squares directly ﬁnding stands ﬁnding least squares solution direct mapping input images data. numerical results table indicate eﬀectiveness proposed idea mapping dimensional representations instead direct mapping terms rmse existing datasets. looking figure ﬁrst clear using linear methods powerful enough addressing shape inverse rendering problem single input image need nonlinear tools ﬁelds especially case human face inverse rendering. second using dimensional representation mapping works better direct mapping visually. next step experiments deep structure consist linear autoencoders ﬁnding representations nonlinear feedforward network mapping representations strat point using nonlinearity proposed framework. start point using nonlinear deep structure framework used nonlinear feedforward network mapping component trained network using samples besel face model dataset training modelnet dataset epochs. figures show results test data face object datasets respectively. observed using nonlinearity mapping component framework results signiﬁcant improvement visually numerically. instance case face datasets face-like reconstructions. observation also shows relation subspaces representations nonlinear relation. next subsection ﬁxing nonlinear feedforward network mapping component consider complicated representations data. this ﬁne-tuned alexnet encoder input image. transfer learning alexnet encoder figure shows proposed framework uses alexnet pre-trained model encoder component. model trained million images categories images imagenet database like human chair pencil many categories well-known model extracting rich features images classiﬁcation object categories. using model encoder component ﬁrst verify possibility using pre-trained components framework second analyze complicated representations solving inverse rendering problem proposed framework. ﬁne-tuned alexnet using colored input images samples generated besel face dataset samples modelnet results shown figures respectively. case modelnet since texture associated object rendered color image represent input images size feed network. figures observable using conﬁguration computing complex representations input images accuracy reconstruction improved compared linear autoencoder. actually objective encoder component compute representations suitable mapped representation results show complicated representations appropriate aim. tations. therefore representation component shape inferred from. case point cloud shapes directly deal real coordinate values linear decoder gives promising result compared nonlinear convolutional structures blur results. case binary volume shapes output digitized using threshold value nonlinear structures show promising performances. ﬁgure shows digaram rmse epoch using diﬀerent mentioned structures diﬀerent types shapes. reconstruction results realistic datasets evaluated ﬁnal conﬁguration framework bosphorus face dataset realistic face dataset. figure shows results heat terms rmse bosphorus dataset.we also compared visual reconstruction results proposed framework realistic images. figure validation error epoch diﬀerent structures used components proposed frameworks modelnet dataset face dataset linear encoder decoder nonlinear feedforward network conv convolutional encoder decoder case realistic images ﬁrst manually cropped face input image aligned intensity image sample image training samples framework using procrustes analysis used input image framework. note order compute rmse heat computed minimum rmse ground truth network reconstruction. results figure show network could successfully recover main features face. note using linear decoder case face datasets equivalent performing training samples causes achieving better results compared predeﬁned using small training data. figure shows visual reconstruction results using realistic images obtained proposed framework compared similar recent reconstruction methods described section results obtained proposed framework comparable unsupervised raining methods detect shape details compared binary volume representation shapes. believe dealing directly point clouds extracting basis vectors large training data. observed experiments using convolutional network encoder mapping component framework signiﬁcantly improves performance. however case decoder using non-convolutional network results better reconstruction results. believe convolutional autoencoder reconstruction representation another property proposed framework autoencoder directly reconstruct shape structure learning large examples. structure uses training data extract bases shape space. believe characteristic leads unbiased reconstructions rather using predeﬁned model biased toward mean shape training samples. hand working directly point cloud representation representing shape helps framework achieve detailed results. disadvantage regressing process framework mention existing loss case situation output network exact values functions. regression need deﬁne suitable loss function guide learning process toward ﬁnding desired solution. turn problem regression form classiﬁcation problem using losses like cross entropy achieve desirable solutions like results obtained generator adversarial netwok frameworks. paper semi-supervised interpretable framework proposed pose invariant shape inverse rendering single input image. using autoencoder based mapping suitable dimensional representations computed data components extracting representations reconstruction ﬁnal shapes proposed framework hand makes possible unlabeled data unsupervised pre-training therefore reducing need large sets labeled data training framework hand helps achieve promising detailed reconstructions extraction bases vector shape space large training data compared predeﬁned models. proposed framework types shape representations used reconstruction point cloud binary volumes. obtained results show binary volumes suitable representations complicated deep networks. however express blur shapes high dimensional representation express less details compared point cloud representations. hand working exact coordinates point clouds easy deep networks linear structures preferred shape reconstructions.", "year": 2017}