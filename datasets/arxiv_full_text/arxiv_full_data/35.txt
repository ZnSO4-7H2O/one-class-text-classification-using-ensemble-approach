{"title": "Sentiment Classification using Images and Label Embeddings", "tag": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "stat.ML"], "abstract": "In this project we analysed how much semantic information images carry, and how much value image data can add to sentiment analysis of the text associated with the images. To better understand the contribution from images, we compared models which only made use of image data, models which only made use of text data, and models which combined both data types. We also analysed if this approach could help sentiment classifiers generalize to unknown sentiments.", "text": "project analysed much semantic information images carry much value image data sentiment analysis text associated images. better understand contribution images compared models made image data models made text data models combined data types. also analysed approach could help sentiment classiﬁers generalize unknown sentiments. nowadays people tend images videos gifs express emotions opinions alongside text. example images shared websites flickr instagram often accompanied short description augment explain post. hybrid multimodal data particularly prevalent social media users frequently express opinions wide range topics. accurate sentiment classiﬁcation many applications. help companies understand customers feel products politicians understand people responding policy proposal used investigate cultural differences effectively making multi-modal data sentiment classiﬁcation images text example valuable since expands sources information available organizations understand people engaging products. sentiment classiﬁcation interesting hard problem inherent subjectivity identifying sentiment. perception sentiment often shaped one’s culture. different cultures exhibit varying degrees positivity description image evoke different sentiment depending person from. furthermore sentiment classiﬁcation hard ambiguous. image evoke mixed feelings viewer. contradiction look image feel happy time. notion also reﬂected language phrases bittersweet nicely capture ambiguity sentiment. consequently datasets gathered sentiment analysis either small weakly labeled. result tend noisy examples exhibiting large variation within sentiment classes well examples mislabeled. sentiment analysis research focused text. whilst still hard problem signiﬁcant progress made direction however increasing multiple modes express opinions means important learn recognise sentiment using sources information text. ultimately goal combine sources information produce nuanced accurate picture sentiment. objective project determine whether images helpful identifying sentiment multi-modal data consisting images text. since sentiment classiﬁcation often clear also looked better understand outputs models. took inspiration increased word embeddings dense representation word vector space encourages information sharing similar words across wide range natural language processing tasks application idea output label space frome socher forcing models output results embedded space better able assess predicted sentiment different examples data related other whether aligned intuition datapoints difﬁcult easy classify. ﬁnal goal project approach could help sentiment classiﬁers generalize unknown sentiments. ﬁnal models able generalize unknown classes. however believe interesting area work models output results embedded space step right direction. original dataset work based large-scale multilingual visual sentiment concept ontology dataset consists million ﬁles flickr images metadata. original dataset contains multilingual data project restricted english subset data. contains following informaxml associated related sentiment-based adjective-noun sentiment score. example inﬁnite sadness sentiment score nice smile associated score english subset data contains distinct english anps. example data entry shown figure evaluation metric primary metric used compare models accuracy. worth noting embedding classiﬁer cosine distance used measure similarity generated word embeddings true labels embeddings. feature extraction images input models used features extracted images running image data though state-of-art pre-trained models alexnet resnet models trained image recogintion/classiﬁcation task since many ﬁrst layers neural networks learn image speciﬁc information before learning classify them utilized models’ architecture make models less complex. limited amount work done sentiment analysis images. works inspired project frome frome proposed model matches a-state-of-art performance -class imagenet object recognition challenge utilizing semantic information learned text labels. frome used pretrained neural language model pre-trained state-of-the-art deep neural network visual object recognition complete traditional softmax output layer. took lower layers pre-trained visual object recognition network re-trained predict vector representation image label text learned language model. work ﬁnal model performed sentiment classiﬁcation flickr twitter images convolutional neural networks model. best knowledge ﬁrst apply deep learning methods image sentiment classiﬁcation achieved state results explore image-text sentiment classiﬁcation. extracted image features using convolutional neural network text features using docvec model. compare three different approaches combining models concatenating sets features building logistic regression model features taking average predicted sentiment score across models cross-modality consistent regression latter achieving best results. take different approach using tree structured lstm combine image text features achieved state results combined textual-visual sentiment analysis dataset. used similar approach combine models differ using lstm model generate text features. additionally explore gates control much information text image features used ﬁnal classiﬁcation task. finding well labeled sentiment dataset challenging. readily available large datasets contain images associated captions sentiment labels. therefore used dataset conduct experiments mvso dataset. used pairs associated scores assign labels particular datapoints although speciﬁc translated score sentiment labels. furthermore approach could improved upon since datapoints labeled indirectly pair associated rather speciﬁc content image text. initial idea label dataset labeling images sentiment label associated caption carries. discuss section generated labels reliable requiring ﬁlter dataset much smaller improve reliability training examples results obtained approach state art. therefore decided another labeling approach section pairs associated sentiment scores label image-caption pairs. approach taken comparable experiments methodology gathering images similar applying ﬁlters exclude examples image text example. dataset also comparable size compared ours datapoints split almost equally positive negative classes. research utilized dataset example used much larger million images. therefore results benchmarks image only text only combined models. also include results image sentiment classiﬁcation state comparison task. finally whilst experimented three sentiment classiﬁers provide results classes. consequently benchmarks three class sentiment classiﬁers. classical classiﬁer embedding classiﬁer networks created relatively simple feed-forward networks. assumption using that since image features obtained sophisticated network like alexnet features would sufﬁciently elaborate provide enough distinguishing power classiﬁer networks. ﬁrst tool tried labeling dataset stanford sentiment predictor stanford core package tool works building parse tree given sentence using parse tree generate sentiment scores/labels sentences details). stanford package assumes incoming sentences proper punctuation sentence structuring dataset even pre-processing text ﬁelds represent short phrases lack proper punctuation structure. analysis produced labels made disregard labels generated package google cloud natural language instead. tool provides sentiment scores given text. manually thresholds range possible scores distinguish assign sentiment labels. easier generate fairly accurate labels multi-sentence text input using however case machine labeling scheme labeled data contained quite noisy data. also produced overwhelmingly large number neutral labels order overcome approximately equally balanced classes dataset reduced samples. ﬁer) ﬁrst type network feed-forward neural network takes input dimensional vector image features obtained prerained alexnet output softmax layer every node representing probability particular sentiment class fixed parameters data-points approximately class number epochs batch size loss function categorical cross-entropy optimizer stochastic gradient descent learning rate momentum architecture relu relu d-out relu d-out relu d-out s-max model relu relu d-out relu d-out relu d-out s-max model fine tuned model samples prob fine tuned model samples prob both class three class classiﬁcation schemes observed ﬁtting training data difﬁcult training accuracy almost always often close however validation results show model overﬁts fails generalize. attempts ﬁght overﬁtting regularization dropout particular prove useful. reason could relatively small training data balancing classes. softmax classiﬁer sentiment classes accuracy accurate hoped classiﬁer able achieve accuracy better visual classiﬁer implemented also used mvso dataset achieved accuracy conﬁrms initial hypothesis relatively simple feed-forward networks enough capacity given sufﬁciently good features fairly complex training generalizing still challenge. besides classical classiﬁer trained predict classes trained model predict dense representation sentiment label. word embeddings label obtained pre-trained word vector representations provided glove global vectors word representation used word embeddings dimension obtained model trained wikipedia gigaword corpus. embedding classiﬁer also used feed-forward neural network takes -dimensional vector image features generated alexnet input outputs dimensional projection vector associated particular label validation/testing time label assigned whose embedding closest -dimensional output. data-points approximately class number epochs batch size loss function cosine proximity optimizer root mean square propagation embedding similarity measure cosine simihypothesized reasons models able generalize could result noise machine-labeled data small size training dataset. remedy this next approach labeling technique also yields larger training dataset. using scores label dataset combat noise machine-labeled data tried labeling using adjective-noun pairs. appears popular labeling technique used several related works. note approach addition input -dimensional feature vectors obtained alexnet also places used pixel data dimensions images. input type speciﬁed describing results. case ﬁrst type network feed-forward neural network takes input -dimensional vector image features output softmax layer every node representing sentiment class. fixed parameters data-points approximately class epochs batch size loss function categorical cross-entropy optimizer stochastic gradient descent learning rate momentum relu relu relu relu s-max relu dropout=. relu dropout=. relu dropout=. relu dropout=. s-max relu dropout=. relu dropout=. relu dropout=. relu s-max image features extracted alexnet yielded better results compared using images. consistent expectations given well alexnet image features performed range image classiﬁcation tasks. cosine proximity loss function also signiﬁcantly effective mean squared error whilst changes features minor effects. furthermore results obtained approach examined adjective-noun pairs associated image order assign labels better previous machinelabeling approach. again ﬁtting training data difﬁcult achieving high accuracy validation data was. combined model images text explore contribution images multimodal sentiment classiﬁer combined image features extracted pretrained resnet neural network lstm model used title description associated image predict sentiment. architecture conv maxpool batchnorm conv maxpool batchnorm relu relu relu s-max convolution maxpool batchnorm conv maxpool batchnorm relu d-out relu d-out relu d-out s-max relu relu relu relu s-max relu d-out relu d-out relu d-out relu d-out s-max used layer model resnet extracted features penultimate layer network. features dimension preprocessed images since model takes input image size images converted required dimension. generate textual model experimented number different lstm architectures hyperparamters. text data preprocessed way. first title description concatenated period separating components. tokenized resulting text retaining punctuation removing whitespace. datapoints tokens truncated reduce computation time encourage learning model since reduces maximum history could stored lstm hidden state. practically datapoints tokens however examples long. datapoints fewer tokens postpadded zeros. finally sorted words based frequency converted token integer using adaptation yasumasa miyamoto’s code creating word dictionary text ﬁles. final vocabulary size words. external internal links occurred quite relu relu d-out relu dropout relu relu d-out linear relu relu d-out relu dropout relu d-out relu d-out linear relu relu d-out relu dropout relu d-out linear relu relu d-out relu dropout relu d-out linear often given special ’href’ ’rel’ tokens. lstm models consisted embedding layer learnt dense representation dimension token. models trained single c.xlarge instance model took hours train experiments running parallel. varied number layers directionality layers size hidden state number training epochs optimizer. found increasing size hidden layer adding bi-directionality improved results whereas adding layers adding dropout help. suggests model sufﬁcient capacity further improvements likely come sources data better treatment input data. best classical classiﬁer model single bidirectional layer hidden state size dense layer softmax actibest image-only classiﬁer relu relu d-out relu d-out relu d-out smax best text-only classiﬁer text sequences post padding embedding layer bidirectional lstm layer dense feature concatenation linear layer txtgl imggl imgshape retained d-out none txtgl imggl imgshape retained d-out txtgl imggl imgshape retained d-out none txtgl imggl imgshape retained d-out none txtgl imggl imgshape retained d-out txtgl imggl imgshape compressed none txtgl imggl imgshape compressed none txtgl imggl imgshape compressed table combined test text images classes dimension input dense layer dropout s-max softmax txtgl gated layer text model imggl gated layer image model imgshape shape image since lstm models took long time train instead training embedding model scratch used best classical model starting point removed softmax layer added linear projection layer dimensional embedding space. models trained using stochastic gradient descent learning rate found hinge loss trained epochs yielded best results adding complexity model form additional dense layers projection layer signiﬁcantly degraded performance. best result achieved validation set. interestingly projecting results embedded space added model’s performance. further.% signiﬁcantly outperforms textual baseline even outperforms simplest tree-lstm combined visual-textual model achieved combine types data extracted text features text model using output layer softmax layer. first concatenated text image features implemented simple linear regression concatenated feature vector. achieved accuracy validation compared best previous classical model result since textual model best model wanted architecture would make model mostly would information image model relevant. tried implement writing custom gating layer keras trainable weights. layer simply multiplied inputs weights elementwise producing output dimensions input. hoped would enable network learn information image text features. practically experimented types gating layer ﬁrst constraints weight values. second constrained weights take values best model applied textual features compressed visual features vector dimension using dense layer relu activation applied visual features. after that results concatenated dropout applied ﬁnal dense layer softmax activation function give predicted sentiment class. achieved validation slight improvement linear model. given time constraints restricted experiments sentiment classes positive negative. full summary results displayed table number embedding space used output layer softmax best model. unfortunately results slightly classical classiﬁer best text-only embedding model accuracy however result still compares favourably reported combined models outperforming early late fusion combined models accuracy respectively. table contains summary results. best classical model achieved accuracy validation test set. encouraging test performance slightly higher validation performance indicating overﬁtting validation set. class accuracy positive class negative class. whilst accuracy class fairly balanced shows model slightly better identifying positive sentiment negative sentiment. investigate results applied t-distributed stochastic neighbor embedding reduce dimensionality data. appendix figure shows result best embedding classiﬁer trained classes. plot depicts data point title folder data point contained colored based true labels model trained text description images interestingly able cluster data points coming folder. aligns intuition different folders share similar nuanced sentiments. particularly exciting model able recognize clusters without explicit information them trained output either positive negative word embedding. folder names shown bold font meaning data points folder plotted close vector space. example cluster following folders ecological disaster global protest wonderful nature beautiful day. mvso dataset clearly challenging dataset image sentiment classiﬁcation. chart appendix compares model performance benchmarks dataset. whilst disappointed approach closer state performance image classiﬁcation achieved reasonable results beat baseline accuracy despite smaller dataset. textual model yielded excellent results clearly beat benchmark could sentiment classiﬁcation using text data dataset. finally best combined model accuracy approaching state accuracy much simpler model architecture. however small proportion contribution appears coming image component model .ppts. area work. given time would interesting further explore circumstances images contain useful information text data purposes sentiment classiﬁcation best take advantage this. given time would liked output best image model instead resnet features generate image features. following this natural next step would larger dataset image model achieves closer state results part combined model architecture. plotting datapoints sentiment embedding space also yielded interesting intuitive results. based seem distances sentiment embedding space meaning given time data possible classify unknown sentiment class using approach.", "year": 2017}