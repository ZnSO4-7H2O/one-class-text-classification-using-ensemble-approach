{"title": "Disentangling Space and Time in Video with Hierarchical Variational  Auto-encoders", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "There are many forms of feature information present in video data. Principle among them are object identity information which is largely static across multiple video frames, and object pose and style information which continuously transforms from frame to frame. Most existing models confound these two types of representation by mapping them to a shared feature space. In this paper we propose a probabilistic approach for learning separable representations of object identity and pose information using unsupervised video data. Our approach leverages a deep generative model with a factored prior distribution that encodes properties of temporal invariances in the hidden feature set. Learning is achieved via variational inference. We present results of learning identity and pose information on a dataset of moving characters as well as a dataset of rotating 3D objects. Our experimental results demonstrate our model's success in factoring its representation, and demonstrate that the model achieves improved performance in transfer learning tasks.", "text": "many forms feature information present video data. principle among object identity information largely static across multiple video frames object pose style information continuously transforms frame frame. existing models confound types representation mapping shared feature space. paper propose probabilistic approach learning separable representations object identity pose information using unsupervised video data. approach leverages deep generative model factored prior distribution encodes properties temporal invariances hidden feature set. learning achieved variational inference. present results learning identity pose information dataset moving characters well dataset rotating objects. experimental results demonstrate model’s success factoring representation demonstrate model achieves improved performance transfer learning tasks. deep neural networks many recent breakthroughs learning representations complicated high dimensional input images video text audio however deep models learn complex feature representations easily understood. transferability deep neural network representations studied underlying factors affect transferability well known. interesting application domains challenging obtain enough labeled data fully train deep model. thus great importance design models feature transferability mind. demonstrated features decompose semantic categories successfully transferred novel tasks since attend high level factors variation input data instead solving training task. paper investigate probabilistic approach learning semantically meaningful image features exploiting temporal properties video data. video semantic information identity tracked face category moving object persists long frame sequences. contrast conﬁgurations objects locations typically change smoothly vary frame frame. propose unsupervised approach learns separate distinct semantic categories separate factors representation. learn separate factors propose model video frame features inspired slow feature analysis factors latent representation distinct parts; temporal component varies smoothly time static component remains near constant throughout video sequence. approach modeling factors bayesian. contrast work slow feature analysis propose generative model encodes separability assumptions prior distribution latent state deﬁne generative distribution frame contents given latent representation. closely related work developed probabilistic interpretation slow feature analysis. work proposed generative framework learning called slow features sequential data. model could learn slowly varying features corresponding static features learned model. though extensions proposed separately represent static changing video contents efﬁcient means inferring decomposed representations known. extend work ways; introduce prior distribution decomposing latent state propose efﬁcient method inferring deep separable representations. work viewed second extension recent contributions learn meaningful features using variational auto-encoders. whereas work slow feature analysis attempts encode concept invariance model recent work variational auto-encoders focused learning independent features. example demonstrated enforcing independence features latent state possible learn representations generalize well tasks. model combines concepts single probabilistic model. empirical results demonstrate model able learn better feature representations comparison models enforce either invariance independence alone. paper present hierarchical probabilistic model learns decompose static temporally varying semantic information video. deﬁne prior learned frame embeddings responsible representation’s semantic factoring. describe prior distribution explain inference performed present derivations needed train model obeys distribution. demonstrate proposed model successfully learns separable features humaninterpretable meanings. moreover demonstrate simple illustrative prediction tasks beneﬁt transfer learning learned disentangle static temporally varying semantic information. model draws heavily variational auto-encoders slow feature analysis. approach inspired previous work learning factored human-interpretable representations. outline concepts below. slow feature analysis slow feature analysis technique learning representations time-series data motivated intuition high-level semantic information likely change much slower rate input data. given dimensional time-series slow feature analysis seeks mapping features subject variance constraint equation important avoid degenerate solution encourage learned features de-correlated. deep networks used learn slow feautures past knowledge work ﬁrst fully probabilistic way. probabilistic reformulation slow feature analysis presented showed slow feature analysis motivated placing gaussian random walk prior model’s latent variables variational auto-encoders originally presented probabilistic extension auto-encoders. reformulate auto-encoder model variational inference problem. framework assume latent features drawn prior distribution data drawn distribution intractability computing posterior seek variational approximation ﬁnding values maximize loglikelihood observing data also intractable optimize instead maximize lower bound log-likelihood −dkl||p) interpreted optimizing reconstruction term minimizing kl-divergence variational approximation posterior prior traditionally normal modeled neural network outputs normal diag)). form decoder depends type data modeled. dealing image data transpose-convolutional neural network typically used pixel intensities typically modeled bernoulli random variables. recent work demonstrated neural networks capable learning separable features correspond distinct factors variation input data. presented modiﬁed training procedure variational auto-encoders capable achieving goal. model requires ability sample batches dataset speciﬁc latent features held ﬁxed across batch. example learning model human faces must possible sample batch faces oriented different identities lighting conditions. supervised unsupervised learning environments possible. demonstrated speciﬁc conditions separable features learned variational auto-encoder simply re-weighting loss heavily penalize kl-divergence prior. modify variational left deﬁne optimizing variational auto-encoder interested priors exists analytic solution kl-divergence between reason deﬁne hierarchical gaussians. lower-bound seen equation −βdkl||p) hyper-parameter typically chosen greater given dataset dense latent factors variation prior independent features simple modiﬁcation shown induce model’s individual features attend distinct factors. model extends variational auto-encoder framework operate video sequences. differing standard approach deﬁne prior latent framefeatures entire frame sequences individual frames. prior factors parts; information remains relatively constant throughout video information changes temporally. model variational auto-encoder must parameters maximize lower bound log-likelihood given equation choose equation equation since interested investigating effect strength variational regularization semantics learned representation. previous work variational auto-encoders example single image latent state vector. work example sequence frames latent state sequence latent state vectors corresponding frame. thus meaning interpretation term equation different model. motivate derive term below. prior interested simple assumptions encoded prior change semantics representation. example focused statistical independence features. encoded using gaussian prior diagonal covariance. given working time-series data focus rate change latent features time. begin assumption within short video sequences high level semantic information factored discrete sets; information remains static throughout sequence information changes smoothly throughout sequence. also assume factors independent another. thus frame latent representation. deﬁne sequence temporally changing latent features obtain similar cross-entropy term representing terms time differences gaussian means variance thus computing crossentropy time-delta distributions normal distributions mean variance full kl-divergence computed adding terms. verbose kl-divergence term easy compute well conditioned gradients simple minimize. initially experimented estimating kl-divergence monte-carlo simulation found variance estimate high optimize. model seeks prior learn factored representation. reason limit expressive power variational approximation frame’s latent features independent given others. leads kl-divergence term equation approximated monte-carlo simulation known high variance make training difﬁcult. deﬁned model exists analytic solution present here. ease notation ignore parameter following equations. model intuitive features constitute compute disentanglement score. benchmarks compute score maximum possible combinations features shown equation experiments important quantitative metric determining success model disentangle static temporal information. in-the-wild video data difﬁcult come metric. reason restricted experimentation datasets exists clean high-level distinction temporal static information. artiﬁcially generated datasets test success algorithm bouncing mnist dataset dataset rotating chair models taken shapenet dataset example sequences datasets seen ﬁgure information factored such compare approach baselines; standard variational auto-encoder operates individual frames probabilistic variant slow feature analysis. variant similar model prior latent features gaussian markov random walk. prior identical prior temporal factor model present method quantify model’s success disentangling representation. train simple linear classiﬁers subsets representation classify inputs based latent factors variation. compute geometric mean accuracies model’s score value divisions representation’s variables. given encoder encode dataset rn×d size dataset number features representation. split features datasets train l-svm train video models iterations batch size videos. video frames. adam learning rule. learning rate multiplied every iterations. benchmark trained batch size ensure images batch consistent. trained versions model bouncing mnist dataset features factor. compare benchmark models trained features total. rotating chairs dataset trained model features factor compare tables outline chosen model architectures. encoder convolutional architecture batch normalization applied nonlinearity every layer except model output layers. rectiﬁed-linear nonlinearity layers. decoder output second linear layer reshaped tensor. subsequent layers transpose convolutional layers form ﬁrst model architecture tested. believe better results could obtained experimenting model architecture beyond scope work. experiments value parameσ ters tested. believe better results could also obtained optimizing parameter leave work well. demonstrated strength distributional regularization term lowerbound greatly impact semantics learned features. this models regularization strength qualitative results ﬁgure show frame embeddings drawn prior pass decoder model trained bouncing mnist dataset. swap static factors embeddings pass decoder again. seen image character identities swap locations remain same demonstrating different semantic interpretations factor features. ﬁgure show sequences frames. images generated using sequence temporal factor encodings different ﬁxed static factor encodings. sequences show chairs rotating angle along roughly axis chair’s appearance starting orientations different. indicates model learned represent rotations given angle around axis sequence temporal factor encodings representing little information chair’s identity. points static factor holding sample temporal factor ﬁxed. bouncing mnist example location character remains constant character’s identity smoothly transforms. demonstrates static factor embedding encodes spatial information. rotating chairs example characteristics decoded chair change orientation chair remains roughly constant. demonstrates static factor embedding encodes orientation information. ﬁgures present outputs decoder inputs similarly interpolate sampled points temporal factor holding sample static factor ﬁxed. bouncing mnist example appearance character remains constant character’s location smoothly translates. demonstrates temporal factor embedding encodes information regarding identity character. rotating chairs example chair appears smoothly rotate shape chair remains roughly constant demonstrating temporal factor encodes little information regarding shape chair encodes mainly orientation information. ﬁgure draw videos testing sample encodings model’s parametrized output distribution. plot factor separately demonstrate differences underlying distributions. points color drawn video connected display temporal order video frames. compare model benchmark models disentanglement score deﬁned section table displays results. versions model outperform benchmarks. seen regularization strength increases models increase number transfer learning experiments demonstrate model’s ability learn superior features frame classiﬁcation. results viewed tables comparison carried follows. given dataset number features regularization strength slow feature benchmark models features regularization strength model factor features regularization strength model encode obtain features train l-svm targets present results. noted using half features model exactly number parameters benchmarks used comparfigure plots encoded videos drawn testing set. ﬁrst column plots static factor learned embedding second column plots temporal factor learned embedding. points color-coded video drawn from. colors consistent across static temporal factors. model trained features factor. model trained features factor mapped -dimensions t-sne. table disentanglement results. disentanglement score metric deﬁned section mnist models latent features rotating chair models latent features. results model taken natural static-temporal factoring results models taken maximum subsets features. found models latent features results sensitive regularization strength parameter bayes solution observed little disentanglement. models temporal factor mainly used encode data indicating static features much challenging learn slow features. best illustrated results table bayes solution model greatly underperforms benchmarks proper variational regularization model’s performance begins surpass benchmarks. believe performance would continue increase paper presented neural network model learns decompose static temporally varying semantic information video. demonstrated success model factoring representation quantitatively qualitatively. aware model sensitive hyper-parameters; mainly size latent representation. interested carrying experiments better understand relationship effect semantics model’s learned representation. aware rather naive assumption information video perfectly factors static temporal information. work could extended prior multiple factors factor changes varying rates fast slow static. believe accurately describe information real-world videos. also interested exploring kinds assumptions sparsity orthogonality encoded priors enforced upon model. wealth previous work properties applied factored representation learning.", "year": 2016}