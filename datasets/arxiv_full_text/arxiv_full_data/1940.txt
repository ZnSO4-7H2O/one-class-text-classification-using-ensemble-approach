{"title": "Learning Modality-Invariant Representations for Speech and Images", "tag": ["cs.LG", "cs.CL", "cs.CV"], "abstract": "In this paper, we explore the unsupervised learning of a semantic embedding space for co-occurring sensory inputs. Specifically, we focus on the task of learning a semantic vector space for both spoken and handwritten digits using the TIDIGITs and MNIST datasets. Current techniques encode image and audio/textual inputs directly to semantic embeddings. In contrast, our technique maps an input to the mean and log variance vectors of a diagonal Gaussian from which sample semantic embeddings are drawn. In addition to encouraging semantic similarity between co-occurring inputs,our loss function includes a regularization term borrowed from variational autoencoders (VAEs) which drives the posterior distributions over embeddings to be unit Gaussian. We can use this regularization term to filter out modality information while preserving semantic information. We speculate this technique may be more broadly applicable to other areas of cross-modality/domain information retrieval and transfer learning.", "text": "paper explore unsupervised learning semantic embedding space co-occurring sensory inputs. speciﬁcally focus task learning semantic vector space spoken handwritten digits using tidigits mnist datasets. current techniques encode image audio/textual inputs directly semantic embeddings. contrast technique maps input mean variance vectors diagonal gaussian sample semantic embeddings drawn. addition encouraging semantic similarity co-occurring inputs loss function includes regularization term borrowed variational autoencoders drives posterior distributions embeddings unit gaussian. regularization term ﬁlter modality information preserving semantic information. speculate technique broadly applicable areas cross-modality/domain information retrieval transfer learning. high-level goal paper train neural model learn semantic embedding space speech audio image inputs mapped. goal inspired fact children able learn associating stimuli early years. example child hearing mother pronounce seven write might learn think concept upon hearing seeing either. fact showed temporoparietal cortex human brain produces content-speciﬁc modalityinvariant neural responses audio visual stimuli method image audio inputs parameterizations diagonal gaussians representing posterior distribution semantic embeddings. sample embeddings distribution loss function encourages samples paired audio image inputs similar mismatched pairs audio images. although objective shown encourage embedding space rich semantically paper explore methods better encouraging modalityinvariance. semantically relevant content clustered embedding space distributions embeddings semantically equivalent audio images same. goal based assumption information concerning modality noise tasks requiring semantic content sensory input. drive posterior distributions embeddings semantically equivalent inputs across modalities introduce term objective regularizes amount information encoded semantic embedding. term borrowed variational autoencoders divergences posterior distributions unit gaussian. results suggest regularization term increased zero hyperparameter tuning modality-information tends ﬁltered prior semantic-information. believe technique potential useful modality-invariant domaininvariant applications. unsupervised problem learning semantic relations co-occurrence lack co-occurrence sensory inputs increasingly attractive pursuit researchers attraction primarily expense attaining labels data. ability learn semantic relevance input pairings alone unlocks potential training models using inexpensively-collected data supervisory signal co-occurrence sensory inputs addition learned semantic space direct practical applications. particular application semantic space cross-modality transfer learning using paired inputs modalities labels modality learn predict labels unlabeled modality. aydrive distribution embeddings minimal deviation unit gaussian prior distribution embeddings found encoders deceive discriminator without using gradient reversal. addition believe problem modality-invariant embeddings using speech modalities explored research makes novel contribution area. ﬁrst formalize problem. given co-occurring images captions functions chosen optimize objective promotes encoding semantic information contained inputs picture handwritten audio recording someone saying seven considered highly semantically related similarity metric. increase margin similarity representations co-occurring inputs similarity representations non-co-occurring inputs. similarity loss function given equation contrast encoders nondeterministic. learn deterministic functions parameterize diagonal gaussian representing posterior distribution embeddings addition lsim deﬁned equation average divergence predicted posteriors embeddings prior embeddings regularization term call information gain loss vondrick torralba teacher-student model videos transfer knowledge pretrained imagenet places convolutional neural networks identifying object scene information images train audio waveform video recognize information. aytar al.’s model shared semantic space consists distributions objects scenes opposed arbitrary semantic space case model. wang gave comprehensive overview existing approaches another practical application shared semantic spaces cross-modality information retrieval. task formulated follows given input modality related instances another modality. harwath presented method learn semantic embedding space images spoken audio recordings captions images could mapped. evaluated method looking cross-modality retrieval recall scores e.g. given image audio captions audio captions describes image? saito developed adversarial neural architecture learn modality-invariant representations paired images text modality-invariance encouraged using adversarial setup discriminator given representations sample drawn unit gaussian. discriminator tasked determining modality input originated whether drawn unit gaussian. encoders trained gradient reversal used previously adversarial domain adaptation generative adversarial networks kashyap also applied harwath al.’s approach mnist tidigits dataset focusing primarily using embeddings cross-modality transfer learning. work focuses embeddings themselves methods promote modality-invariance. designed convolutional variational autoencoder melﬁlterbanks speech drawn timit dataset. work convolutional network architecture audio encoder. network architecture loss function based harwath instead deterministically mapping inputs embeddings inputs parameterization diagonal gaussian sample embeddings addition regularization term posterior distributions. regard method takes similar approach achieving modality-invariance saito insofar images used mnist dataset handwritten digits dataset contains training images test images. images -bit grayscale images preprocess image pixel values audio used tidigits dataset spoken utterances sampled used digit strings containing single number used utterances women children. ﬁltering utterances contain number training utterances test utterances validation utterances. using kaldi speech recognition toolkit generated dimensional mel-ﬁlterbank features window size frame shift multiplied povey window. create inputs size crop spectrogram frames frame longer mean frame length available utterances. preprocessed ﬁlterbank zero mean unit variance. longer utterances center cropped. shorter utterances zero padded adjusting ﬁlterbank zero mean. tidigits also combined utterances labeled zero class purpose labeling clusters analysis. used convolutional neural networks predict parameterizations ˆpfv trained networks minimize equation mnist tidigits datasets described section compared embedding spaces produced gauge effect regularizing information gain posterior. embedding dimension consistent latent embedding dimensionality used variational autoencoder phones. explore values encoders images audio convolutional networks produce parameterization posterior distribution embeddings. audio encoder uses architecture encoder portion al.’s variational autoencoder dimensional mel-ﬁlterbank speech image encoder also convolutional taking fol. conv. ﬁlters padding conv. strides ﬁlters padding conv. strides ﬁlters padding unit fully connected unit linear output used convolutional fully connected layers. initial learning rate decayed factor every epochs. adam optimization algorithm used distinct imageaudio pairs used batch. processing image audio input respective encoder produce posterior distribution embeddings sampled input. produced total image-audio embedding pairs batch. negative sampling performed selecting sample pairs batch. would ﬁrst seem reasonable disallow negative samples training pair drawn underlying digit class mechanism implies ground truth digit labelling examples within batch. words knowledge negative example pairs sample equivalent network possessing oracle knows audio/visual sample pairs within batch drawn underlying digit class. oracle would allow network trivially recover ground truth digit labelling examples within batch. effort avoid this allow negative samples chosen digit class regardless initial example’s digit class. empirically found points cluster points class metric represents accuracy classiﬁer classiﬁes point according majority class cluster whose mean closest using euclidean distance. used subset sample embeddings performed classiﬁcation task predict original input point’s modality embeddings using gaussian kernel. examples used training remaining used test set. used -fold validation select value svm. comparing modality classiﬁcation test accuracy prior modality allows gauge extent embeddings modalityinvariant. perfectly modality-invariant embeddings would result modality classiﬁcation test accuracy evaluated effect cluster purity modality invariance embeddings learned model. results using modality classiﬁer cluster purity analysis shown figure table weight positive examples easily overcome contradictory signals introduced sampling scheme allowing model produce semantically rich embedding space. model trained epochs. epoch deﬁned number batches required cover training examples larger datasets exactly once. training required minutes nvidia titanx gpu. analyze learned semantic space sampled embeddings inputs unseen test sampling samples input point. k-means clustering calculated cluster purity resulting clusters deﬁned accuracy shown table although metric ideal accuracy truly modalityinvariant embeddings embedding space produced using much closer modality-invariant space produced lsim alone. figure shows minimizing divergence posterior embeddings prior improves modality invariance. could fact divergence represents amount information embedding conveyed input limiting amount information force encoders ﬁlter information. reason variational autoencoders exhibit de-noising behavior since semantic information important minimizing lsim modality information tends ﬁltered semantic information. applications figure shows empirically observed ideal cutoff point increasing limit total information conveyed posterior begins also overly restrict semantic information conveyed resulting drop cluster purity. figure shows trend qualitatively. shows sampled embeddings resulting under-regularized model; well regularized; regularized. work goal learn joint modality-invariant semantic embedding space speech images unsupervised manner. focused spoken utterances images handwritten digits. found sampling encodings rather predicting directly regularizing posterior distribution embeddings able learn modality-invariant semantic embedding space. adversarial perspective able deceive adversarial discriminator without gradient reversal adversarial setup training. leads suspect useful regularization term generative adversarial approaches learning domain modality invariant embeddings. research could done attempt combine techniques used vaes gans. potential direction vein multimodal learning semantic space replace product similarity symmetric divergence variational distributions matched mismatched inputs. would allow probabilistically theoretical formulation loss function could general implications areas research. fig. effects tuning weight divergence regularization term. shaded region considered ideal modality classiﬁcation nearly random cluster purity reaches peak. addition used samples modality compute dimensional t-sne projection embeddings produced hyperparameter setting. plotted samples figure colored according class label. cells tsne model used embeddings modalities projected two-dimensional space. additional term resulted greater cluster purity shown figure lower cluster purity lsim alone visually evident ﬁrst figure though clear semantic clusterings samples digit typically clusters digit—one images audio. possible explanation cluster purity k-means performed half number digit clusters embedding space resulting k-means clusters members nearly evenly split digits. ﬁnding shows using lsim alone embeddings originating modality still signiﬁcantly closer together embeddings different modalities regardless similarity semantic content. accuracy predicting modality embeddings shown figure supports ﬁnding embedding space produced using lsim alone modality invariant. trend conducive modality invariance embeddings. contrast embeddings produced using training able classiﬁed daniel povey arnab ghoshal gilles boulianne lukas burget ondrej glembek nagendra goel mirko hannemann petr motlicek yanmin qian petr schwarz kaldi speech recognition toolkit ieee workshop automatic speech recognition understanding. ieee signal processing society number epfl-conf-. kingson jonas kaplan antonio damasio kaspar meyer sight sound converge form modality-invariant representations temporoparietal cortex journal neuroscience vol. david harwath antonio torralba james glass unsupervised learning spoken language visual context advances neural information processing systems yusuf aytar carl vondrick antonio torralba soundnet learning sound representations unlabeled video advances neural information processing systems yaroslav ganin evgeniya ustinova hana ajakan pascal germain hugo larochelle franc¸ois laviolette mario marchand victor lempitsky domainjournal adversarial training neural networks machine learning research vol. goodfellow jean pouget-abadie mehdi mirza bing david warde-farley sherjil ozair aaron courville yoshua bengio generative adversarial nets advances neural information processing systems", "year": 2017}