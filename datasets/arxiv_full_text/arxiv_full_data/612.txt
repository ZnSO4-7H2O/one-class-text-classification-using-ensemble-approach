{"title": "Phonetic Temporal Neural Model for Language Identification", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "Deep neural models, particularly the LSTM-RNN model, have shown great potential for language identification (LID). However, the use of phonetic information has been largely overlooked by most existing neural LID methods, although this information has been used very successfully in conventional phonetic LID systems. We present a phonetic temporal neural model for LID, which is an LSTM-RNN LID system that accepts phonetic features produced by a phone-discriminative DNN as the input, rather than raw acoustic features. This new model is similar to traditional phonetic LID methods, but the phonetic knowledge here is much richer: it is at the frame level and involves compacted information of all phones. Our experiments conducted on the Babel database and the AP16-OLR database demonstrate that the temporal phonetic neural approach is very effective, and significantly outperforms existing acoustic neural models. It also outperforms the conventional i-vector approach on short utterances and in noisy conditions.", "text": "familiarity language important factor affecting accuracy longer speech samples easier identify. moreover people easily tell cues identiﬁcation including phonemic inventory word usage prosody. thorough investigations conducted others modifying speech samples promote several factors. example mori found people able identify japanese english fairly reliably even phone information reduced. argued non-linguistic cues intensity pitch used decide language. navratil evaluated importance various types knowledge including lexical phonotactic prosodic asking humans identify languages chinese english french german japanese. subjects presented unaltered speech samples samples randomly altered syllables samples vocal-tract information removed leave amplitude. navratil found speech samples random syllables difﬁcult identify compared original samples removing vocal-tract information leads signiﬁcant performance reduction means -language task lexical phonotactic information important human decision making. experiments summarised suggest languages discriminated multiple cues different levels cues used differentiate different language pairs different. general cues categorized three levels feature level token level prosody level. feature level different languages implementation phones transitions phones also different. acoustic speciality short-time property identiﬁed certain spectral analysis feature extraction auditory system. token level distribution transition patterns linguistic tokens various levels signiﬁcantly different. tokens phones/phonemes syllables words even syntactic semantic tags. prosody level duration pitch stress patterns often differ languages. example patterns stress provide important discriminating stressed languages duration also potentially useful tone patterns syllables words offer clear discriminate tonal languages. based different types cues multiple approaches proposed. early work generally focused feature-level cues. feature-based methods strong statistical models built acoustic features make abstract—deep neural models particularly lstm-rnn model shown great potential language identiﬁcation however phonetic information largely overlooked existing neural methods although information used successfully conventional phonetic systems. present phonetic temporal neural model lstm-rnn system accepts phonetic features produced phone-discriminative input rather acoustic features. model similar traditional phonetic methods phonetic knowledge much richer frame level involves compacted information phones. experiments conducted babel database ap-olr database demonstrate temporal phonetic neural approach effective signiﬁcantly outperforms existing acoustic neural models. also outperforms conventional i-vector approach short utterances noisy conditions. language identiﬁcation lends wide range applications mixed-lingual speech recognition. humans many cues discriminate languages better accuracy achieved cues. various approaches developed based different types cues. languages world language distinct properties different levels acoustic semantics number studies investigated humans properties cues distinguish languages example muthusamy found work supported part national natural science foundation china projects part national basic research program china grant part doctoral fund ministry education china project tang chengdu institute computer applications chinese academy sciences university chinese academy sciences beijing china also center speech language technologies tsinghua university beijing china wang chen tsinghua national laboratory information science technology center speech language technologies tsinghua university beijing china department computer science software engineering xi’an jiaotong-liverpool university suzhou china decision. instance cimarusti used features foil investigated formant features. dynamic features involve temporal information also demonstrated effective statistical models used include gaussian mixture models hidden markov models neural networks support vector machines recently lowrank model known i-vector model proposed achieved signiﬁcant success model constrains mean vectors components lowdimensional space improve statistical strength model training uses task-oriented discriminative model improve decision quality run-time leading improved performance. short-time property features feature-based methods model distributional characters rather temporal characters speech signals. token-based approach based characters highlevel tokens. since dynamic properties adjacent tokens stable adjacent features temporal characters learned token-based approach additional distributional characters. typical approach convert speech signals phone sequences build n-gram language model target language evaluate conﬁdence input speech matches language. famous phone recognition language modelling approach. multiple prlm variants proposed parallel phone recognition followed phone recognition multilingual phone tokens syllables words also investigated. prosody-based approach utilizes patterns duration pitch stress discriminate languages. example foil studied formant prosodic features found formant features discriminative. rouas modeled pure prosodic features gmms found system worked well read speech could deal complexity spontaneous speech prosody. muthusamy used pitch variation duration syllable rate. duration pitch patterns also used hazen cases prosodic information used additional knowledge improve feature token-based lid. methods matter information used heavily rely probabilistic models accumulate evidence long speech segment. example prlm method requires n-gram probability phonetic sequence gmm/i-vector method requires distribution acoustic feature. therefore approaches require long test utterances leading inevitable latency decision. latency serious problem many practical applications e.g. code-switching multiple languages contained within single block speech. quick frame-level decision highly desirable therefore cannot rely probabilistic models. recently emerging deep learning approach solves problem using various deep neural networks produce frame-level decisions. early successful deep neural model developed lopez-moreno proposed approach based feed-forward deep neural network accepts acoustic features produces frame-level decisions. score utterance-based decision calculated averaging scores frame-level decisions. extended others various neural model structures e.g. tdnn models featurebased consider large context window therefore learn feature’s temporal information possible conventional feature-based models learn distributional information. temporal information better learned recurrent neural networks proposed gonzalez-dominguez using structure based longshort term memory unit authors reported better performance fewer parameters. approach developed others e.g. noted dnns used ways lid. example song used extract phonetic feature i-vector system ferrer proposed i-vector approach uses posteriors produced phone-discriminative ffdnn compute baum-welch statistics. tian extended using produce posteriors. methods neural models part system basic framework still probabilistic share problem decision latency. paper focus pure neural approach uses neural models basic framework short-time language information learned frame-level discriminative training. present neural methods based acoustic features e.g. ﬁlter banks frequency cepstral coefﬁcients phonetic information largely overlooked. signiﬁcantly hindered performance neural lid. intuitively long-standing hypothesis languages discriminated phonetic properties either distributional temporal; additionally phonetic features represent information higher level acoustic features invariant respect demonstrated phonetic information either form phone sequences phone posteriors phonetic bottleneck features signiﬁcantly improve accuracy conventional prlm approach modern ivector system paper investigate utilization phonetic information improve neural lid. basic concept phone-discriminative model produce frame-level phonetic features features enhance systems originally built acoustic features. initial step therefore feature combination phonetic feature used auxiliary information assist acoustic lid. improved further additional research identiﬁed simpler model using phonetic feature input provides even better performance. call model based phonetic features phonetic temporal neural approach lid. well simpliﬁed model structure offers deeper insight task rediscovering value phonetic temporal property language discrimination. property historically widely successfully applied token-based approaches e.g. prlm largely overlooked popularity i-vector approach. table summarizes different systems deep neural models lid. probabilistic approach uses dnns part probabilistic system e.g. i-vector neural approach uses various types dnns decision architecture. approaches either acoustic features phonetic features. proposed approach bottom-right table. remainder paper organized follows model structures approach presented section followed implementation details section iii. experiments results reported section conclusions future work presented section section present models employ phonetic information lid. although phonetically aware approach treats phonetic information auxiliary knowledge approach uses phonetic information input system. depicted fig. fig. models employing phonetic information phonetically aware model; model. models consist phonetic produce phonetic features make decisions. call phonetically aware approach. intuitively regarded knowledge-fusion method uses phonetic acoustic features learn models. fig. shows model. phonetic model used produce frame-level phonetic features. read anywhere phonetic output last hidden layer propagated model lstm-rnn study. propagated phonetic information accepted model different ways. example part input additional term gate non-linear activation functions. second model call model completely replaces acoustic feature phonetic feature thus entirely relies properties phonetic representation. learning based model therefore temporal patterns phonetic features learned. system shown fig. although model special ‘aggressive’ case phonetically aware approach success model offers deeper insight task rediscovers importance temporal properties phonetic representations. rationality approach understood perspectives phonetic perspective relates information important transfer learning perspective relates information learned. phonetic perspective approach adopts longstanding hypothesis languages discriminated phonetic rather spectral properties. however largely overlooked since success i-vector approach achieved good performance using acoustic features. however song recently rediscovered value phonetic features i-vector model. approach proposed follows idea rediscovers value phonetic features neural model. argue value important neural model probabilistic model decision based small number frames thus requires feature involves language-related information less noise uncertainties. i-vector model contrast utilize speech signals hence discover language-related information distributional patterns even acoustic features. token-based approach share idea utilizing phonetic information modelling temporal patterns fundamentally different. firstly phonetic information approach frame-level conventional tokenbased methods information unit-level. therefore approach represent phonetic properties higher temporal resolution. secondly conventional token-based methods represent phonetic information sequences derived phone recognition approach represents phonetic information feature vector involves information contributed phones thus detailed phonetic information represented. finally back-end model conventional token-based approach n-gram based discrete tokens trained maximum likelihood criterion back-end model approach functions similarly based continuous phonetic features trained taskoriented criterion discriminates target languages. transfer learning perspective second perspective understand approach transfer learning perspective well known dnns perform well learning task-oriented features data. hypothesis behind conventional acoustic methods neural model successfully trained learn useful information acoustic features layer layer including phonetic information. therefore initially seems unnecessary design phonetic feature learning modelling architecture. however argue using language labels alone learn lid-related information acoustic features highly ineffective labels coarse provide sufﬁcient supervision. model feature extraction trained speech data labelled phones words highly informative ﬁne-grained leading strong model phonetic feature extraction. importantly phone discrimination language identiﬁcation naturally correlated means phonetic features learned strong phone/word supervision involves rich information suitable lid. example transfer learning related task used learn features another task approach also involves another transfer learning schemes cross language cross condition means phonetic learned speech data language. property identiﬁed token-based however important phonetic neural models training phonetic requires large amount speech data often available target languages operating conditions test. moreover also possible train phonetic multilingual multi-conditional data resulting robust reliable phonetic feature extraction. summary approach utilizes detailed phonetic representation powerful temporal model capture phonetic temporal properties language high temporal resolution. also utilizes three types transfer learning ensure phonetic feature representative robust. approach therefore powerful ﬂexible reconﬁrms belief many researchers phonetic temporal information highly valuable language discrimination humans also machines. neural model choose lstm-rnn. reason choice lstm-rnn demonstrated perform well pure neural approach neural-probabilistic hybrid approach another reason model learn temporal properties speech signals accordance motivation model phonetic dynamics conventional prlm approach ﬁrst describe lstm-rnn structure used present model structures phonetically aware acoustic model model. equations terms denote weight matrices associated cells constrained diagonal implementation. terms denote bias vectors. input output symbols respectively; represent input forget output gates respectively; cell cell output. output components derived recurrent next time step recurrent contributes present output only. logistic sigmoid function study lstm layer consists cells dimensionality recurrent non-recurrent projections natural stochastic gradient descent algorithm employed train model. training decoding cells reset frames ensure short-time patterns learned. phonetically aware model phonetic feature read phonetic propagated additional information assist acoustic neural lid. phonetic feature read either output last hidden layer propagated different components model e.g. input/forget/output gates and/or non-linear activation functions. fig. illustrates simple conﬁguration phonetic tdnn model feature read last hidden layer. phonetic feature propagated non-linear function conﬁguration calculation similar except cell value updated follows phonetically aware acoustic model acousticbased approach phonetic feature used auxiliary information. contrast approach assumes phonetic temporal properties cover information language discrimination acoustic feature important more. therefore removes acoustic features uses phonetic features input shown fig. interesting compare approach approaches. firstly regarded version conventional prlm approach particularly recent prlm implementation using major difference approach uses frame-level phonetic features prlm approach uses token-level phonetic sequences; addition phonetic information approach much richer prlm represented continuous phonetic vector rather discrete phonetic symbols. approach also correlated neuralprobabilistic hybrid approach phonetic used produce phonetic features ivector model constructed. approach uses phonetic features employs model describe dynamic property feature instead modelling distributional property using i-vector models. fig. phonetically aware system system phonetic feature read last hidden layer phonetic tdnn. phonetic feature propagated function phonetically aware system input system. finally compared conventional acoustic model uses phonetic features rather model acoustic features. since phonetic features learned large speech database much robust noise uncertainties acoustic features. suggests approach robust noise conventional acoustic approach. experiments conducted databases babel database ap-olr database. babel database collected part iarpa babel program aimed develop speech technologies low-resource languages. sampling rate sample size bits. paper chose speech data seven languages babel database assamese bengali cantonese georgian pashto tagalog turkish. language ofﬁcial training development dataset provided. training datasets contain conversational scripted speech development datasets contain conversational speech. used entire training language model training randomly selected utterances development language perform testing. training data sets seven languages follows assamese hours bengali hours cantonese hours georgian hours pashto hours tagalog hours turkish hours. average duration test utterances seconds ranging seconds seconds. ap-ol database originally created speechocean inc. targeted towards various speech processing tasks used ofﬁcial data ap-olr challenge. database contains seven datasets particular language. mandarin cantonese indonesian japanese russian korean vietnamese. data volume language approximately hours speech signals recorded speakers speaker recording approximately utterances reading style mobile phones sampling rate sample size bits. dataset split training consisting speakers test consisting speakers. mandarin cantonese vietnamese indonesian recording conducted quiet environment. russian korean japanese recording conditions speaker quiet noisy. average duration test utterances seven languages seconds ranging seconds seconds. phonetic tdnn structure model based lstm-rnn. feature used models consists -dimensional fbanks symmetric -frame window symmetric -frame window tdnn splice neighboring frames. experiments conducted kaldi default conﬁgurations kaldi nnet recipe used train phonetic rnn. ﬁrst report experiments based babel database experiments ap-olr database. language collection release iarpa-babelb-v.a. language collection release iarpa-babelb-v.b. language collection release iarpa-babelb-v.c. language collection release iarpa-babelb-v.a. language collection release iarpa-babelb-v.by. language collection release iarpa-babel-v.g. language collection release iarpa-babelb-v.. http//cslt.riit.tsinghua.edu.cn/mediawiki/index.php/olr challenge i-vector baseline involves gaussian components dimensionality i-vectors static acoustic features consists -dimensional mfccs energy. static features augmented ﬁrst second order derivatives resulting -dimensional feature vectors. experiment train language determine score test i-vector belonging language. svms trained i-vectors training segments following one-versus-rest strategy. baselines standard system discriminates languages output multi-task system trained discriminate languages well phones. precisely output units ag-rnn-mlt separated groups group involves units corresponding assamese georgian respectively group involves bilingual senones inherited hmm/gmm system trained speech data assamese georgian following standard hmm/gmm recipe kaldi. nnet recipe kaldi used train ag-rnn-lid ag-rnn-mlt systems. task conducted either ag-rnn-lid ag-rnn-mlt frame-level using frame-level language posteriors produce. evaluate utterance-level performance frame-level posteriors averaged form utterance-level posterior language decision made. performance results three baseline systems terms cavg equal error rate shown table results indicate multi-task capable language discrimination multi-task signiﬁcantly outperforms i-vector baseline. indicates phone information useful neural even simply used auxiliary objective model training hence supporting transfer learning perspective described section multi-task learning approach interesting involve phonetic information lid. however limitation requiring training data labelled languages words/phones. costly feasible scenarios. phonetic neural models suffer problem. phonetically aware architecture uses phonetic features auxiliary information improve lid. experimented various architectures phonetic found tdnn structure good choice. experiment tdnn structure composed time-delay layers followed p-norm layer reduces dimensionality activation dimension recurrent layer lstm-rnn. activations last hidden layer tdnn read phonetic feature. tdnn models trained. ag-tdnn-mlt model multi-task model trained assamese georgian data groups output targets phone labels language labels. performance ag-tdnn-mlt model assamese georgian respectively. swb-tdnn-asr model model trained switchboard database. database involves hours telephone speech signals english recorded speakers. performance swb-tdnn-asr eval dataset. another design decision made choose component receive phonetic information. series preliminary experiments found function best receiver. choice tdnn phonetic dnns therefore build phonetically aware system. results shown table iii. several conclusions obtained results. phonetically aware system signiﬁcantly outperforms baseline system suggests involving phonetic information clear beneﬁts. phonetically aware system signiﬁcantly outperforms multi-task note multi-task phonetic knowledge used auxiliary task assist training shown great beneﬁts. advantages phonetically aware system demonstrated using phonetic knowledge produce phonetic features seems better method using knowledge directly assist model training. phonetic trained assamese georgian data shows better performance trained switchboard dataset surprising assamese georgian languages chosen discriminate experiments presented section ag-tdnn-mlt consistent task. nevertheless still highly interesting observe clear beneﬁts obtained using phonetic features produced swb-tdnn-asr trained completely irrelevant dataset terms languages environmental conditions. conﬁrmed transfer learning perspective theory demonstrated phonetic features largely portable phonetic trained data languages. observation particularly interesting tasks low-resource languages phonetic trained data rich-resource languages. experiments phonetic feature used auxiliary information. here evaluate architecture phonetic feature entirely replaces acoustic features experiment conducted phonetic models ag-tdnn-mlt swb-tdnn-asr. results presented table ﬁrst observe systems perform well best phonetically aware system table even better terms utterance-level eer. better comparison also test special case phonetically aware phonetic acoustic features used input model involves additional acoustic features. results shown second group table seen feature combination provide notable improvement phonetic feature sufﬁcient represent distinctiveness language language characters mostly phonetic. also attempted tdnn model learn static patterns phonetic features. found model failed converge. phenomenon also observed ap-olr experiment important observation suggests that phonetic feature temporal properties informative language discrimination. transfer learning perspectives jointly state main advantage phonetic knowledge learned transfer learning. however another possible reason deeper architecture consisting phonetic help learn abstract features. latter reason important similar deep structure labels work similarly well. answer question design following three experiments test contributions results phonetic information deep architecture tdnn-lstm. phonetic tdnn experiment initialized randomly trained together rnn. means tdnn trained labels part neural model trained end-to-end. pre-trained tdnn-lstm. tdnn-lstm except tdnn initialized ag-tdnn-mlt. -layer lstm-rnn. -layer lstm-rnn model strong enough learn useful information acoustic features hence leading suboptimal performance table experiment -layer lstm-rnn system test simple deeper network obtain performance phonetic feature. results three deep models shown table tdnn-lstm model completely fails. using phonetic tdnn initialization helps training results worse directly using phonetic model. means phonetic feature almost optimal require lid-oriented end-to-end training. finally involving lstm layers improve performance little compared one-layer lstm baseline results indicate improvement architecture mainly phonetic information learned asroriented training rather deep network structure. words transfer learning instead deep learning improves performance architecture. evaluate various models seven languages babel database. first i-vector lstm-rnn baselines presented. i-vector system linear discriminative analysis employed promote languagerelated information training svms. dimensionality projection space phonetically aware systems phonetic dnns evaluated ag-tdnn-mlt swb-tdnn-asr. phonetically aware system function lstm-rnn model chosen receiver. results shown table seen phonetically aware systems outperform i-vector baseline acoustic baseline system ag-tdnn-mlt phonetic performs best. swbtdnn-asr performs slightly worse ag-tdnn-mlt indicating familiarity language environment beneﬁcial discriminating languages. however phonetic dnns trained data foreign languages mismatched environment conditions still work well. section test phonetic approach ap-olr database. compared babel database speech signals ap-olr broadband acoustic environment less noisy. additionally speech data language much limited assume training phonetic model feasible data target languages. therefore utilize transfer learning i.e. using phonetic dnns trained data languages. test conditions language babel experiment. trained phonetic dnns tdnn model size ag-tdnn-asr model section iv-c trained database denoted ‘wsj-tdnn-asr’. also tdnn taken industry project trained speech database involving hours chinese speech signals dimensional fbanks. network contains rectiﬁer tdnn layers containing hidden units. model denoted ‘ch-tdnn-asr’. weight matrix last hidden layer ch-tdnn-asr decomposed rank -dimensional activations read low-rank layer used phonetic feature. test results seven languages database shown table vii. seen phonetic models either phonetically aware approach signiﬁcantly outperform acoustic baseline system. system seems much effective differs babel database results. attributed limited training data simpler architecture preferred. comparing wsj-based phonetic chinese phonetic chinese model better. attributed several reasons chinese database contains larger volume training data; chinese seven languages ap-olr; chinese similar remaining target languages comparison english languages ap-olr oriental languages. another observation i-vector system outperforms phonetic systems ap-olr experiment inconsistent observations babel experiment phonetic systems signiﬁcantly outperform i-vector system. discrepancy attributed different data proﬁles databases possible factors utterances ap-olr longer babel making i-vector system effective; speech signals ap-olr cleaner babel. system robust noise advantage less prominent clean data. examine conjectures following experiments. show relative advantage ivector systems utterances different length select utterances least seconds ap-olr test create test sets dividing small utterances different durations seconds seconds steps seconds. group contains utterances utterance group random segment excerpted original utterance. performance i-vector systems test sets shown fig. terms cavg respectively. clear system effective short utterances utterance duration seconds i-vector system best performer especially terms eer. duration distribution test utterances babel database ap-olr database shown fig. clear test utterances generally longer apolr babel. explains relative performance i-vector system system inconsistent databases. ap-olr test different levels noiseaugmented data tested systems i-vector baseline best performing system table i.e. ch-tdnn-asr phonetic dnn. results systems different levels white noise shown table viii. seen system noise-robust noise corruption i-vector system system becomes muthusamy jain cole perceptual benchmarks automatic language identiﬁcation proceedings ieee international conference acoustics speech signal processing vol. mori toba harada arai komatsu aoyagi murahara human language identiﬁcation reduced spectral information. proceedings european conference speech communication technology navratil spoken language recognition-a step toward multilinguality speech processing ieee transactions speech audio processing vol. cimarusti ives development automatic identiﬁcation system spoken languages phase proceedings ieee international conference acoustics speech signal processing vol. foil language identiﬁcation using noisy speech proceedings ieee international conference acoustics speech signal processing vol. torres-carrasquillo singer kohler greene reynolds deller approaches language identiﬁcation using gaussian mixture models shifted delta cepstral features. proceedings annual conference international speech communication association zissman automatic language identiﬁcation using gaussian mixture hidden markov models proceedings ieee international conference acoustics speech signal processing vol. willmore price roberts comparing gaussian mixture neural network modelling approaches automatic language identiﬁcation speech australasian international conference speech science technology less signiﬁcant system better ivector system terms cavg noise level high observed clearly fig. performance degradation rates compared noise-free condition shown. ﬁgure shows noise increases performance degradation system less signiﬁcant compared degradation ivector system. babel speech data much noisy ap-olr speech noise robustness approach partly explains relative performance inconsistent databases. paper proposed phonetic temporal neural approach language identiﬁcation. approach acoustic features substituted phonetic features build model. experiments conducted babel ap-olr databases demonstrated approach provide dramatic performance improvement baseline system even better results phonetically aware approach treats phonetic feature additional auxiliary information. demonstrated phonetic temporal information much informative acoustic information discriminating languages. long-standing belief researchers prlm doubted since increased popularity utilization i-vector approach recent years. future work improve performance neural approach long sentences enabling lstm-rnn learn long-time patterns e.g. multi-scale rnns kwasny kalman engebretson identifying language speech example high-level statisticallybased feature extraction proceedings annual conference cognitive science society dehak a.-c. pedro reynolds dehak language recognition i-vectors dimensionality reduction proceedings annual conference international speech communication association martınez plchot burget glembek matejka language recognition ivectors space proceedings annual conference international speech communication association matejka burget schwarz cernocky brno university technology system nist language recognition evaluation ieee odyssey speaker language recognition workshop. ieee adda-decker antoine different size multilingual phone inventories context-dependent acoustic models language identiﬁcation. proceedings annual conference international speech communication association schultz rogina waibel lvcsr-based language identiﬁcation proceedings ieee international conference acoustics speech signal processing vol. ieee hieronymus kadambe robust spoken language identiﬁcation using large vocabulary speech recognition proceedings ieee international conference acoustics speech signal processing vol. j.-l. rouas farinas pellegrino andr´e-obrecht modeling prosody language identiﬁcation read spontaneous speech proceedings ieee international conference acoustics speech signal processing vol. lopez-moreno gonzalez-dominguez plchot martinez gonzalez-rodriguez moreno automatic language identiﬁcation using deep neural networks proceedings ieee international conference acoustics speech signal processing ieee lozano-diez zazo candil gonz´alez dom´ınguez toledano gonzalez-rodriguez end-to-end approach language identiﬁcation short utterances using convolutional neural networks proceedings annual conference international speech communication association garcia-romero mccree stacked long-term tdnn spoken language recognition proceedings annual conference international speech communication association gonzalez-dominguez lopez-moreno gonzalezrodriguez moreno automatic language identiﬁcation using long short-term memory recurrent neural networks. proceedings annual conference international speech communication association gelly j.-l. gauvain messaoudi divide-andconquer approach language identiﬁcation based recurrent neural networks proceedings annual conference international speech communication association zazo lozano-diez gonzalez-dominguez toledano gonzalez-rodriguez language identiﬁcation short utterances using long short-term memory recurrent neural networks plos vol. ferrer mclaren scheffer study senone-based deep neural network approaches spoken language recognition ieee/acm transactions audio speech language processing vol. wang zheng transfer learning speech language processing proceedings asia-paciﬁc signal information processing association annual summit conference ieee j.-t. huang deng gong cross-language knowledge transfer using multilingual deep neural network shared hidden layers proceedings ieee international conference acoustics speech signal processing ieee waibel hanazawa hinton shikano lang phoneme recognition using time-delay neural networks ieee transactions acoustics speech signal processing vol. senior beaufays long short-term memory recurrent neural network architectures large scale acoustic modeling proceedings annual conference international speech communication association povey ghoshal boulianne burget glembek goel hannemann motlicek qian schwarz kaldi speech recognition toolkit proceedings ieee workshop automatic speech recognition understanding epfl-conf. chung bengio hierarchical multiscale recurrent neural networks arxiv preprint arxiv.", "year": 2017}