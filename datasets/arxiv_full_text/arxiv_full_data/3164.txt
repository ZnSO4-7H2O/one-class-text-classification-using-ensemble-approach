{"title": "On multi-view feature learning", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Sparse coding is a common approach to learning local features for object recognition. Recently, there has been an increasing interest in learning features from spatio-temporal, binocular, or other multi-observation data, where the goal is to encode the relationship between images rather than the content of a single image. We provide an analysis of multi-view feature learning, which shows that hidden variables encode transformations by detecting rotation angles in the eigenspaces shared among multiple image warps. Our analysis helps explain recent experimental results showing that transformation-specific features emerge when training complex cell models on videos. Our analysis also shows that transformation-invariant features can emerge as a by-product of learning representations of transformations.", "text": "sparse coding common approach learning local features object recognition. recently increasing interest learning features spatio-temporal binocular multi-observation data goal encode relationship images rather content single image. provide analysis multi-view feature learning shows hidden variables encode transformations detecting rotation angles eigenspaces shared among multiple image warps. analysis helps explain recent experimental results showing transformation-speciﬁc features emerge training complex cell models videos. analysis also shows transformation-invariant features emerge by-product learning representations transformations. feature learning gained considerable attention computer vision recent years yield image representations useful recognition. however although recognition important variety tasks problems vision involve encoding relationship observations single observations. examples include tracking multi-view geometry action understanding dealing invariances. variety multi-view feature learning models recently suggested learn features encode relations images. basic idea behind models hidden variables products ﬁlter responses applied observations thereby correlate responses. adapting ﬁlters based synthetic transformations images shown yield transformationspeciﬁc features like phase-shifted fourier components training shifted image pairs circular fourier components training rotated image pairs task-speciﬁc ﬁlterpairs emerge training natural transformations like facial expression changes natural video shown yield state-of-the-art recognition performance domains. multi-view feature learning models also closely related energy models complex cells which turn successfully applied video understanding also used learn within-image correlations letting input output images common methods deploy products ﬁlter responses learn relations. paper analyze role multiplicative interactions learning relations. also show hidden variables multi-view feature learning model represent transformations detecting rotation angles eigenspaces shared among transformations. focus image transformations here analysis restricted images. analysis variety practical applications investigate detail experimentally train complex cell energy models using conditional sparse coding models vice versa possible extend multi-view feature learning model sequences three images instead mandatory hidden variables pool multiple subspaces work properly invariant features learned separating pooling within subspaces pooling across subspaces. analysis related previous investigations energy models complex cells extends line work general transformations local translation. feature learning amounts encoding image patch using vector latent variables column viewed linear feature corresponds hidden variable non-linearity sigmoid exp− adapt parameters based example patches {xα} variety methods including maximizing average sparsity minimizing form reconstruction error maximizing likelihood observations gibbs sampling others references therein). obtain hidden variables encode relationship images needs represent correlation patterns images instead. commonly achieved computing products ﬁlter responses contain image ﬁlters learned along data again apply element-wise non-linearity hidden units multi-view variables encode transformations content single images commonly referred mapping units. multi-view feature learning closely related energy models models complex cells activity hidden unit energy model typically deﬁned squared ﬁlter responses written contains image ﬁlters columns. usually constrained hidden variable computes subset products. hidden variables thought encoding norm projection onto subspace. energy models also referred subspace square-pooling models. analysis important note that apply energy model concatenation images obtain response closely related response multi-view sparse coding model denote single column matrix furthermore denote part ﬁlter gets applied image denote part gets applied image hidden unit activities take form training model parameters achieved minimizing conditional reconstruction error keeping ﬁxed vice versa conditional variants maximum likelihood training model transforming randomdot patterns yields transformation-speciﬁc features phase-shifted fourier features case translation circular harmonics case rotation also derived factorizing parameter tensor conditional sparse coding model illustration model shown figure terms feature learning dictionary learning sparse coding synonymously paper. term tends come slightly diﬀerent meaning literature purpose work diﬀerences negligible. practice common constant bias terms linear mapping. following shall refrain avoid cluttering derivations. shall instead think data hidden variables homogeneous notation extra constant -dimension. thus quadratic terms hidden unit activities multi-view feature learning model shall discuss section quadratic terms signiﬁcantly change behavior hidden units compared multi-view sparse coding models. illustration energy model shown figure show hidden variables turn subspace rotation detectors models trained transformed image pairs. simplify analysis shall restrict attention transformations orthogonal identity matrix. words linear transformations pixel-space also figure modeling image pair using gated sparse coding model. modeling image pair using energy model applied concatenation images. projections images onto complex plane spanned eigenfeatures. absorbing eigenvalues input-features amounts performing projection rotation image hidden units detect brings projections alignment known warp. note practically relevant spatial transformations like translation rotation local shifts expressed approximately orthogonal warp orthogonal transformations subsume particular permutations important fact orthogonal matrices eigen-decomposition complex eigenvalues absolute value multiplying complex number absolute value amounts performing rotation complex plane illustrated figure eigenspace associated also referred invariant subspace applying orthogonal warp thus equivalent projecting image onto ﬁlter pairs performing rotation within invariant subspace projecting back image-space. words decompose orthogonal transformation independent -dimensional rotations. well-known examples translations dtranslation matrix contains ones along secondary diagonals zero elsewhere. eigenvectors matrix fourier-components rotation invariant subspace amounts phase-shift corresponding fourierfeature. leaves norm projections onto fourier-components constant well known property interesting note imaginary real parts eigenvectors translation matrix correspond sine cosine features respectively reﬂecting fact fourier components naturally come pairs. commonly referred quadrature pairs literature. true gabor features represent local translations however property eigenvectors come pairs speciﬁc translations. shared transformations represented orthogonal matrix. term generalized quadrature pair refer eigen-features transformations. central observation analysis eigenspaces shared among transformations. eigenspaces shared transformations diﬀer angles rotation within eigenspaces. case represent multiple transformations single features shall show. example shared eigenspace fourier-basis shared among translations less obvious examples gabor features thought eigenbases local translations features represent spatial rotations. formally matrices share eigenvectors commute seen considering matrices eigenvalue/eigenvector pair multiplicity one. holds λav. importance commuting transformations analysis that since share eigenbasis transformations diﬀer angles rotation joint eigenspaces. result extract transformation given image pair simply recovering angles rotation projections onto eigenspaces. consider real complex parts trigonometric identity. equivalent computing inner product normalized projections words estimate angle rotation projections need product ﬁlter responses. note however normalizing projection amounts dividing squared ﬁlter responses operation highly unstable projection close zero. case whenever images almost orthogonal invariant subspace. this turn means rotation angle cannot recovered given image image close axis rotation. view subspace-generalization wellknown aperture problem beyond translation orthogonal transformations. normalization would ignore problem provide illusion recovered angle even aperture problem makes detection transformation component impossible. next section discuss preferred angle rotation however like before normalizing projections good idea subspace aperture problem. show mapping units well-suited detecting subspace rotations number conditions met. features data contrast normalized projections depend well image pair represents given subspace rotation. value turn depend transformation content images thus output detector factors both presence transformation ability discern fact depends image content makes suboptimal representation transformation. however note conservative detector takes large value input image pair complies transformation. therefore deﬁne content-independent representation pooling multiple detectors represent transformation respond diﬀerent images. furthermore following conditions need images contrast-normalized exists corresponding written expuf words ﬁlter pairs related rotations only. takes form inference multiview feature learning model absorb within-subspace pooling matrix learning amounts identifying subspaces pooling matrix training multi-view feature learning model thought performing multiple simultaneous diagonalizations transformations. dataset contains transformation class learning involves partitioning orthogonal warps commutative subsets simultaneously diagonalizing subset. note that practice complex ﬁlters represented learning two-dimensional subspaces form ﬁlter pairs. uncommon albeit possible learn actually complex-valued features practice. interesting note condition ﬁlters normalized implies lengths. imposing norm constraint common approach stabilizing learning susskind clear imposing norm constraints help. pooling multiple subspaces addition providing contentindependent representations also help deal edge eﬀects noise well fact learned transformations exactly orthogonal. practice also common apply sigmoid nonlinearity computing mapping unit activities output hidden variable interpreted probability. note diagonalizing single transformation would amount performing kind canonical correlations analysis learning multi-view feature learning model thought performing multiple canonical correlation analyzes tied features. similarly modeling within-image structure setting would amount learning mixture tied weights. neural networks used implement linear transformation result training multi-view feature learning model simultaneous diagonalization linear transformation. equivalent four quadratic terms. four quadratic terms equal squared norms projections onto invariant subspace. thus like norm projections contribute information discernibility transformations. makes energy response depend alignment images subspace. however like inner product detector peak response attained images reside within detector’s subspace projections rotated detectors preferred angle pooling multiple rotation detectors obtain equivalent energy response shows energy models applied concatenation images well-suited modeling transformations too. interesting note both multiview sparse coding models energy models recently shown yield highly competitive performance action recognition tasks require encoding motion videos. figure shows random subsets input/output ﬁlter pairs learned rotations random images mixed dataset consisting random rotations random translations separate layers pooling constrain band-diagonal entries pii+ elsewhere. thus ﬁlters need come pairs expect approximately quadrature figure shows indeed case training. here modiﬁcation higher-order autoencoder training expect simiverify training videos leads ﬁlters approximately satisfy condition follows gated autoencoder concatenation frames. contrast section single pooling matrix figure shows subsets learned ﬁlters after training model shifted random dots natural movies cropped hateren database learned ﬁlter-sequences represent repeated phaseshifts expected. thus form eigenmovies respective transformation class. implies learning videos requires consistency ﬁlters across time. factor corresponding sequence ﬁlters model repeated application transformation. inhomogeneous sequence involves multiple different types transformation modeled devoting separate ﬁlter sets homogeneous subsequences. verify happens during training using -frame videos showing random dots ﬁrst rotate constant speed frames translate constant speed remaining frames. orientation speed direction vary across movies. trained gated autoencoder like previous experiment. bottom plot figure shows model learns decompose movies fourier ﬁlters quiet ﬁrst half movie rotation features quiet second half movie. analysis suggests detector responses aﬀected transformations tuned cause rotation within detector’s subspace leaving norm projections unchanged. transformation however change representation projections larger smaller transformation changes degree alignment images invariant subspaces. results hold multi-view models. discuss application separating pooling detail section note mixed dataset rotations translations sets commuting warps rotations commute translations vice versa. ﬁgure shows model learned separate types transformation devoting subset ﬁlters encoding rotations another subset modeling translations. energy models cross-correlation models applied images modiﬁed contain cross-terms ones deemed relevant alternatively energy mechanism compute square concatenation images place case obtain detector response figure subsets ﬁlters showing frames eigenmovies synthetic movies showing translating randomdots natural movies cropped hateren broadcast database synthetic movies showing random-dots rotate frames translate frames degrees; train- test-cases classes since number training cases fairly large exemplars represented angles even linear classiﬁers perform well however reducing number training cases number potential matches test case dramatically reduces classiﬁcation error rates become much worse using images standard features. used gated auto-encoder factors mapping units trained image pairs showing rotating random-dots. figure shows error rates using subspace features subspace dimension used features logistic regression classiﬁer k-nearest neighbors original images learned features similar features shown figure tuned digits trained discriminatively. nevertheless consistently perform well better than nearest neighbor. also even half original dataset size subspace features still attain classiﬁcation performance images whole training set. parameters using ﬁxed hold-out images. experiment shows rotation detectors aﬀected suﬃciently aperture problem selective image content invariant rotation. shows harness aperture problem learn invariant features. analyzed multi-view sparse coding models terms joint eigenspaces transformations. analysis helps understand fourier features circular fourier features emerge training transformation models shifts rotations square-pooling models work well action hyv¨arinen aapo hoyer patrik. emergence phaseshift-invariant features decomposition natural images independent feature subspaces. neural computation july larochelle hugo erhan dumitru courville aaron bergstra james bengio yoshua. empirical evaluation deep architectures problems many factors variation. proceedings international conference machine learning ranzato marc’aurelio hinton geoﬀrey modeling pixel means covariances using factorized thirdorder boltzmann machines. computer vision pattern recognition susskind memisevic hinton pollefeys modeling joint density images variety transformations. proceedings ieee conference computer vision pattern recognition independent component analysis natural image sequences yields spatiotemporal ﬁlters similar simple cells primary visual cortex. proc. biological sciences fact squaring nonlinearities multiplicative interactions support learning relations suggests help increase role statistical learning vision general. learning relations extend applicability sparse coding models beyond recognizing objects static single images towards tasks involve fusion multiple views including inference geometry.", "year": 2012}