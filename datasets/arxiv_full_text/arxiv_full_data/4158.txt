{"title": "Exploiting inter-image similarity and ensemble of extreme learners for  fixation prediction using deep features", "tag": ["cs.CV", "cs.AI"], "abstract": "This paper presents a novel fixation prediction and saliency modeling framework based on inter-image similarities and ensemble of Extreme Learning Machines (ELM). The proposed framework is inspired by two observations, 1) the contextual information of a scene along with low-level visual cues modulates attention, 2) the influence of scene memorability on eye movement patterns caused by the resemblance of a scene to a former visual experience. Motivated by such observations, we develop a framework that estimates the saliency of a given image using an ensemble of extreme learners, each trained on an image similar to the input image. That is, after retrieving a set of similar images for a given image, a saliency predictor is learnt from each of the images in the retrieved image set using an ELM, resulting in an ensemble. The saliency of the given image is then measured in terms of the mean of predicted saliency value by the ensemble's members.", "text": "paper presents novel ﬁxation prediction saliency modeling framework based inter-image similarities ensemble extreme learning machines proposed framework inspired observations contextual information scene along low-level visual cues modulates attention inﬂuence scene memorability movement patterns caused resemblance scene former visual experience. motivated observations develop framework estimates saliency given image using ensemble extreme learners trained image similar input image. retrieving similar images given image saliency predictor learnt images retrieved image using resulting ensemble. saliency given image measured terms mean predicted saliency value ensemble’s members. ﬁxation prediction also known saliency modeling associated estimation saliency probability locations observer looking long enough period time meanwhile viewing scene. part computational perspective visual attention process narrowing available visual information upon focus enhanced processing. computer vision community investigating ﬁxation prediction saliency modeling extensively wide range applications including recognition detection compression tracking segmentation supperresolution advertisement perceptual designing image quality assessment motion detection background subtraction scene memorability visual search many applications saliency facilitate selection subset regions scene elaborate analysis reduces computation complexity improves energy eﬃciency human centric point view formation saliency pure bottom-up process inﬂuenced several factors assigned task level expertise observer scene familiarity memory. shown human relies prior knowledge scene long-term memory crucial components construction maintenance scene representation similar vein suggests abstract visual representation retained memory upon short exposure scene representation inﬂuences movements later. study role scene memory guiding movements natural experience entailing prolonged immersion three-dimensional environments suggests observers learn location objects time spatial-memory-guided search scheme locate them. ﬁndings basis research measuring memorability scenes pure observer movements similar images alike movement patterns statistics. inspired ﬁndings scene memorability research incorporate similarity images inﬂuencing factor ﬁxation prediction. besides fact similar images induce similar movement patterns memory recall well agreed interaction low-level visual cues aﬀect saliency formation contextual information scene modulate saliency imagine watching pairs images pair street scene pair nature beach images meanwhile movements recorded. surprising similar salient regions images alike scenes because similar low-level cues contextual data mostly present pair. figure depicts examples scenario. case street scene observers tend converge traﬃc sings tend spot low-level structural information beach images. motivates exploit learning saliency inter-image similarities. paper presents novel ﬁxation prediction algorithm based interimage similarities ensemble saliency learners using features deep convolutional neural networks. meet ﬁrst investigate beneﬁts inter-image similarities ﬁxation prediction. then introduce image similarity metric using gist descriptor classemes ﬁxation prediction algorithm using ensemble extreme learning machines given image member ensemble trained image similar input image. report performance proposed framework saliency benchmarks databases along evaluations databases publicly available ground-truth. rest paper brieﬂy review related work. afterwards using problem demonstrate beneﬁt inter-image similarity. section explain proposed model. continue experiments assess performance model. paper ends discussion conclusion remarks. ﬁeld computer vision replete numerous variety saliency models. widely recognized group models apply feature integration theory consider center-surround interaction features models consider information theoretic foundations frequency domain aspect diﬀusion random walk techniques etc. investigating extent saliency modeling approaches beyond scope article readers advised consult relevant surveys however brieﬂy review relevant techniques. learning-based techniques large group methods establishing relation feature space human ﬁxations. example uses nonlinear transformation associate image patches human movement statistics. linear classiﬁer used establish relation three channels these databases ground-truth unavailable public order provide fair model evaluation. thus scores computed saliency research team using submitted maps. high-level features human movements order produce saliency map. similar vein employs multiple-instance learning. learning classiﬁer estimate optimal weights fusing several conspicuity maps observers’ movement data. approaches often learn probabilistic classiﬁer determine probability feature being salient. then employ estimated saliency probability order build saliency map. recent saliency modeling methods akin computer vision techniques revolutionized advanced signiﬁcantly applying deep convolutional neural networks exists signiﬁcant number models employ cnns many relevant proposed model. ensembles deep networks adopts neural ﬁlters learned image classiﬁcation task deep neural networks learns classiﬁer perform ﬁxation prediction. considered extension features obtained layers deep neural network. layer deep neural network ﬁrst learns optimal blend neural responses previous layers current layer guided hyperparameter search. then concatenates optimal blend layers form feature vector learning linear classiﬁer. deep gaze utilizes cnns ﬁxation prediction task treating saliency prediction point processing. despite model justiﬁed diﬀerently practice boils framework. nonetheless objective function minimized slightly diﬀerent explicit incorporation center-bias factor imposed sparsity constraint framework. salnet another technique employs cnn-based architecture last layer deconvolution. ﬁrst convolution layers initialized deconvolution learnt ﬁne-tuning architecture ﬁxation prediction. multiresolution designs deep cnn-based technique discriminate image patches centered ﬁxations non-ﬁxated image patches multiple resolutions. hence trains convolutional neural network scale results three parallel networks. outputs networks connected together common classiﬁcation layer order learn best resolution combination. salicon develops model ﬁne-tuning convolutional neural network trained imagenet using saliency evaluation metrics objective functions. feeds image architecture resolutions coarse ﬁne. then response last convolution layer obtained scale. responses concatenated together linear integration scheme optimizing kullback-leibler divergence network output ground-truth ﬁxation maps regression setup. error back-propagated convolution layers ﬁne-tuning network. proposed method considered learning-based approach. many learning-based techniques essentially solving classiﬁcation problem proposed model regression ideology mind. thus closer recent deep learning approaches treat problem estimation main motivation behind proposed model people similar ﬁxation patterns exposure alike images. words inter-image saliency beneﬁts saliency prediction. order investigate assertion build problem tell well saliency image predicts saliency similar image. choose common saliency database computed gist scene image. afterwards similar image pairs dissimilar pairs identiﬁed. image pair ﬁxation density predicted saliency other. assessment reveals ﬁxation prediction scheme produces signiﬁcantly diﬀerent pairs score prediction dissimilar image pairs results indicate degree prediction similar pairs dissimilar pairs better chance. observe performance diﬀerence metrics correlation score normalized scanpath score given observation foundation saliency model ﬁxation prediction. high-level conceptual schematic proposed model depicted figure framework components include image feature transform similar image retrieval engine scene repository bank ensemble neural saliency predictors. image feature transform performs feature extraction produces pool features used units system. similar image retrieval ﬁnds similar images stored scene bank corresponding given image. retrieves predictors trained using images order facilitate formation ensemble saliency predictors. rest section explained details mentioned components. image feature transform unit extracts several features image feeds forward units. recent surge application features learnt image statistics deep convolutional neural networks wide range computer vision related applications. work adopt ﬁlter-bank approach cnns saliency prediction. thus build image pyramid compute cnns’ responses scale using architecture combine convolution responses scale employ upsampling procedure furthermore compute classemes deep pipeline probability thousand classes imagenet computed using fully-connected layers vgg. classemes complemented low-level scene representation make gist scene classemes low-level scene features build spatial representation outside world rich enough convey meaning scene envisioned feature vector obtained concatenating classemes gist features used recognition retrieval similar images. similar image retrieval unit fetches information required building ensemble neural predictors scene bank. scene bank holds images terms scene representation feature vector consisting classemes feature gist descriptor neural ﬁxation predictor unit image. given scene representation vector input image denoted retrieval method fetches similar images scene vectors {v··· using euclidean distance disti fetches neural ﬁxation predictor units corresponding figure demonstrates results retrieval system. visualizes query image corresponding similar retrieved image diﬀerent databases observer gaze information overlaid. interestingly retrieved images share similar objects bottom-up structures also similar attention grabbing regions. worth noting closest scene necessarily scene category however often contains similar low-level and/or high-level perceptual elements. corresponds saliency prediction image features represents spatial prior. estimate using ensemble neural predictors learnt human gaze information. figure depicts ensemble neural saliency predictors. ensemble neural predictors consists several neural units equal contributions. training phase train neural unit image training store scene bank. test phase retrieval unit fetches several neural units corresponding images similar input image. ensemble then computes responses units aggregates neural saliency predictor utilizes randomly-weighted single-layer feedforward networks order establish mapping feature space saliency space. idea randomly-weighted single-hidden-layer feedforward networks traced back gamba perceptron followed others like neural saliency predictor adopt recent implementation extreme learning machines theory facilitates implementation neural network architecture hidden layer weights chosen randomly meanwhile output layer weights determined analytically motivated better function approximation properties elms employ primary entity neural saliency prediction. node. conventional solution gradient-based slow iterative process requires tune parameters like γγγj ωωωj iterative scheme prone divergence local minima overﬁtting. ﬁxation data. learn spatial prior using gaze data number kernels corresponds number ﬁxation points. spatial prior puts weight regions agreed observers. demonstrated many saliency research papers spatial prior introduces center-bias eﬀect phenomenon observed figure depicting spatial prior. exist arguments getting advantage location priors address issue selecting proper evaluation metrics benchmarks. also worth noting using summation prior integration generally boosts regions center image equally. conduct several experiments order evaluate model. test databases include database consists images indoor outdoor scenes movements observers. consists natural indoor outdoor scenes consists images divided sets train test images set. includes categories images including action aﬀective black white cartoon fractal indoor outdoor inverted jumbled line drawings resolution noisy object outdoor made outdoor natural pattern random satellite sketch social. allow ground-truth access order provide fair comparison. moment widely accepted benchmarks results presented provided saliency benchmark team using submitted maps. results proposed model also accessible benchmark website acronym iseel. learn ensembles ensembleosie ensemblecat ﬁrst trained osie database latter trained using training cat. employ ensemblecat predicting test images. system parameters optimized ensemble. section ﬁrst explain system parameters. evaluate performance generalization proposed model comparison baseline model using database. continue benchmark results databases. system parameters number neural units ensemble denoted number hidden layers unit attenuation factorα. furthermore learn post processing smoothing gaussian kernel denoted used smooth model’s maps. parameters except number hidden nodes learnt. ensembles number hidden nodes neural unit ﬁxed equal rest parameters system optimized toronto database tuning cost function minimizes kl-divergence maps model ground-truth ﬁxation density maps. figure depicts eﬀect number neural units conjunction value attenuation factor ensemble performance. based observations ensemble size required obtain acceptable result. optimization parameters however recommend following parameters ensemble ensembleosie ensemblecat ﬁxed. test generalization model evaluate performance using database choose ensemble deep neural networks baseline model deep features classiﬁers. proposed model however utilizes ensemble regression units. also evaluate several models including gbvs judd sake comparison traditional models. order ease interpretation evaluation choose subset scores complement other. employ shuﬄed similarity metric normalized scanpath saliency sauc scores utilized borrow part scores from complement score. figure reports results. depicted proposed model outperforms models metrics outperforms three metrics. highest gain compared score indicating high consistency human ﬁxation locations explains high score well. summarize proposed model generalizes well edge traditional models. later compare proposed model recent state-of-the-art models well-established benchmarks. figure performance generalization performance proposed model compared traditional models baseline model. dashed vertical line indicates performance gaussian dummy model. human score respectively. many recent deep saliency models codes maps unavailable public making comparisons diﬃcult. hence rely available benchmarks. report performance using metrics published works reported benchmark. brevity focus recent top-performing models. results also include performance inﬁnite human mean human indicate well model performs comparison mean position several human average performance human respectively. results mit. table summarizes performance comparison proposed model among published works benchmark basis nss. largest benchmark models time writing. however report best performing models recent state-of-the-art ones. comparison indicates models becoming powerful enough capture ﬁxation location. hence diﬃcult distinguish many metrics. however seems informative metric determines models’ performance well particularly top-performing models judging auc-based metrics similarity-based metrics diﬃcult. results cat. table contains performance comparison database. models mostly traditional ones evaluated database. proposed model ensemblecat ranks similarly ranking. models produce highest score among models average indistinguishable values auc-based similarity-based metrics. also evaluate ensembleosie along ensemblecat order investigate improvements caused incorporating similar images training phase. backing hypothesis ensemble trained outperforms ensemble learnt indoor outdoor images osie terms overall scores. ensembleosie three best performing models using three metrics shuﬄed nss. results summarized figure proposed model ensemblecat ensembleosie outperforming resolution noisy outdoor black white action aﬀective social categories. seems performing better particular contextual information low-level feature interactions matter e.g. fractal category pattern. categories however diﬃcult judge. overall seems three models complement areas falls behind others. demonstrated usefulness scene similarity predicting saliency motivated eﬀect familiarity scene observer’s movements. idea however easily extended utilization observers’ movements task-speciﬁc models model trained speciﬁc task experts’ movements incorporated. expert approach solving speciﬁc task diﬀerent naive observer. thus consider encoding expert observers’ movements implicit expert knowledge utilization handy scenarios scene analysis spotting object-speciﬁc anomalies saliency maps order reduce search time. introduced saliency model motive exploiting eﬀect immediate scene recall human perception. proposed model uses randomly-weighted neural networks ensemble architecture. establishes mapping feature space consisting deep features saliency space. saliency prediction relies neural units corresponding images similar input image. neural units pretrained stored scene bank handful images. neural unit scene bank also stores scene descriptor consisting classemes gist descriptor. similar images scene bank proposed model employs distance scene descriptor input image neural units. proposed model evaluated several databases. results reported well-established benchmark databases benchmark team namely cat. among published methods basis consistency locations human ﬁxation proposed method ranked respectively. results indicate beneﬁt learning saliency images similar input image. code proposed model available http//github.com/hrtavakoli/iseel. hamed r.-tavakoli jorma laaksonen supported finnish center excellence computational inference research authors would like thank saliency benchmark team particularly zoya bylinskii quick response benchmark request.", "year": 2016}