{"title": "Improving Semantic Embedding Consistency by Metric Learning for  Zero-Shot Classification", "tag": ["cs.CV", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "abstract": "This paper addresses the task of zero-shot image classification. The key contribution of the proposed approach is to control the semantic embedding of images -- one of the main ingredients of zero-shot learning -- by formulating it as a metric learning problem. The optimized empirical criterion associates two types of sub-task constraints: metric discriminating capacity and accurate attribute prediction. This results in a novel expression of zero-shot learning not requiring the notion of class in the training phase: only pairs of image/attributes, augmented with a consistency indicator, are given as ground truth. At test time, the learned model can predict the consistency of a test image with a given set of attributes , allowing flexible ways to produce recognition inferences. Despite its simplicity, the proposed approach gives state-of-the-art results on four challenging datasets used for zero-shot recognition evaluation.", "text": "abstract. paper addresses task zero-shot image classiﬁcation. contribution proposed approach control semantic embedding images main ingredients zero-shot learning formulating metric learning problem. optimized empirical criterion associates types sub-task constraints metric discriminating capacity accurate attribute prediction. results novel expression zero-shot learning requiring notion class training phase pairs image/attributes augmented consistency indicator given ground truth. test time learned model predict consistency test image given attributes allowing ﬂexible ways produce recognition inferences. despite simplicity proposed approach gives state-of-the-art results four challenging datasets used zero-shot recognition evaluation. paper addresses question zero-shot learning image classiﬁcation i.e. classiﬁcation images belonging classes represented training examples. problem attracted much interest last decade clear practical impact many applications access annotated data categories considered often diﬃcult requires ways increase interpretation capacity automated recognition systems.the eﬃciency relies existence intermediate representation level eﬀortlessly understandable human designers suﬃciently formal support algorithmic inferences. studies considered representation form semantic attributes mainly provides easy describe compact discriminative descriptions classes. also observed attribute representations provided humans ideal embedding space lack informational quality necessary conduct reliable inferences structure attribute manifold given data distribution rather complex redundant noisy unevenly organized. attribute descriptions although semantically meaningful useful introduce category necessarily isomorphic image data image processing outputs. compensate shortcomings induced attribute representations recent trends studies aiming better controlling classiﬁcation inference well attribute prediction learning criteria. indeed attribute classiﬁers learned independently ﬁnal classiﬁcation task direct attribute prediction model might optimal predicting attributes necessarily predicting novel classes. work proposed paper instead suggest better controlling structure embedding attribute space least important constraining classiﬁcation inference step. fundamental idea empirically disentangle attribute distribution learning metric able select transform original data distribution according informational criteria. metric obtained optimizing objective function based pairs attributes/images without assuming training images assigned categories; semantic annotations used training. specifically empirically validated idea optimizing jointly attribute embedding classiﬁcation metric multi-objective framework makes performance better even simple linear embedding distance mean attribute classiﬁcation. approach experimentally validated recent datasets zero-shot recognition i.e. ‘apascal&ayahoo’ ‘animals attributes’ ‘cub- ‘sun attribute’ datasets excellent results obtained despite simplicity approach. image representation i.e. mechanisms allowing transform image pixel intensities representations suitable recognition tasks plays important role image classiﬁcation. state-of-the image representations were couple years mainly based pooling hard/soft quantized local descriptors bag-of-words fisher vectors models. however work krizhevsky opened area state-of-the-art image descriptors nowadays rely deep convolutional neural networks follow trend experiments so-called ‘vgg-verydeep-’ descriptors recent papers exhibited existing links features semantic attributes. ozeki showed units predict semantic attributes ‘animals attributes’ dataset fairly accurately. interesting conclusion paper visual semantic attributes predicted much accurately non-visual ones nodes cnn. recently showed existence attribute centric nodes within cnns trained recognize objects collectively encoding information pertinent visual attributes unevenly sparsely distributed across layers network. despite recent ﬁndings could certainly make performance method better don’t experiments stick standard features intention making results directly comparable recent zero-shot learning papers zero-shot learning methods rely intermediate representations usually given attributes. term however encompass diﬀerent concepts. lampert denotes presence/absence given object property assuming attributes nameable properties advantage so-deﬁned attributes used easily deﬁne classes expressed shared semantic vocabulary. however ﬁnding discriminative meaningful attributes sometimes diﬃcult. addressed issue proposing interactive approach discovers local attributes discriminative semantically meaningful employing recommender system selects attributes human interactions. alternative identifying attribute vocabulary without human labeling mine existing textual description images sampled internet proposed line thought presented model classifying unseen categories textual description. proposed approach zero-shot learning description unseen categories comes form typical text encyclopedia entries without need explicitly deﬁne attributes. another drawback human generated attributes redundant adapted image classiﬁcation. issues addressed automatically designing discriminative category-level attributes using tasks cross-category knowledge transfer work finally attributes also structured hierarchies obtained text mining textual descriptions beside papers consider attributes meaningful humans authors denoted attributes latent space providing intermediate representation image hidden descriptions used transfer information images unseen classes. typically case jointly learn attribute classiﬁers attribute vectors intention obtaining better attribute-level representation converting undetectable redundant attributes discriminative ones retaining useful semantic attributes. also introduced concept discriminative attributes taking form random comparisons. space class names also constitute interesting embedding works represent images mixtures known classes distributions. training set. existing methods rely computation similarity consistency function linking image descriptors semantic description classes. links given learning embeddings ﬁrst image representation semantic space second class space semantic space deﬁning describe constraints class space image space strongly interdependent. indirect attribute prediction ﬁrst proposed layer attributes variables decoupling images layer labels. independent attribute predictors used build embedding image similarity semantic representations given probability class attribute knowing image. attributes form connecting layer layers labels classes known training time classes known. case attributes predicted class predictions. lampert concluded gives much better performance iap. however mentioned introduction problems ﬁrst model correlation attributes predicted independently. second mapping classes attribute space weight relative importance attributes correlations them. inspired learns linear embedding image features annotations tried overcome limitation. work akata introduced function measuring consistency image label embedding parameters function learned ensure that given image correct classes rank higher incorrect ones. consistency function form bilinear relation associating image embedding label representation romera proposed simple closed form solution assuming speciﬁc form regularization chosen. comparison work none papers metric learning framework control statistical structure attribute embedding space. coeﬃcients consistency constraint also predicted semantic textual description image. example goal predict classiﬁer category based learned classes textual description category. solve problem regression function learnt textual feature domain visual classiﬁer domain. builds ideas extending using expressive regression function based deep neural network. take advantage architecture cnns learn features diﬀerent layers rather learning embedding space modalities. proposed model provides means automatically generate list pseudo-attributes visual category consisting words wikipedia articles. contrast aforementioned methods hamm introduced idea ordinal similarity classes claiming type similarity suﬃcient distinguishing truck also seems natural representation since ordinal similarity invariant scaling monotonic transformation numerical values. also worth mentioning work jayaraman proposed leverage statistics attribute error tendencies within random forest approach allowing train zero-shot models explicitly account unreliability attribute predictions. exploit natural language processing technologies generate event descriptions. measure similarity images projecting common high-dimensional space using text expansion. similarity expressed concatenation distances diﬀerent modalities considered. strictly speaking metric learning involved concatenation distances. finally frome leveraging semantic knowledge learned text domain transfer model trained visual object recognition learning metric aligning modalities. however contrast work explicitly control quality embedding. previously mentioned approaches consider embedding consistency function learned training data known classes used second time infer predictions images classes available training. however diﬀerent problem addressed images unknown classes already available training time hence used produce better embedding. case problem cast transductive learning problem i.e. inference correct labels given unlabeled data only semi-supervised learning problem i.e. inference best embedding using labeled unlabeled data. wang forsyth proposed framework jointly learning attributes object classiﬁers weakly annotated data. wang mori treated attributes object latent variables captured correlations among attributes using undirected graphical model allowing infer object class labels using information test image attributes. class information incorporated attribute classiﬁer attribute-level representation generalizes well unseen examples known classes well unseen classes assuming unlabeled images available learning. considered introduction unseen classes novelty detection problem multi-class classiﬁcation problem. image known category standard classiﬁer used. otherwise images assigned class based likelihood unseen category. rectiﬁed projection domain shift auxiliary target datasets introducing multi-view semantic space alignment process correlate diﬀerent semantic views low-level feature view projecting onto latent embedding space learnt using multi-view canonical correlation analysis. recently learned embedding input data semi-supervised large-margin learning framework jointly considering multi-class classiﬁcation observed unseen classes. finally formulated regularized sparse coding framework used target domain class label projections semantic space regularize learnt target domain projection overcoming projection domain shift problem. contributions exploit metric learning zero shot class description. mensink learn metric adapted measure similarity images context k-nearest neighbor image classiﬁcation apply fact shot learning show generalize well classes. don’t attribute embedding space consider work. kuznetsova learn metric infer pose object class single image. expression zero-shot actually denote transfer learning problem data unevenly sampled joint pose class space zero-shot classiﬁcation problem classes known attribute descriptions. given sample modality e.g. image features extracted consistent association another modality e.g. vector attribute indicators textual description measure able quantify joint consistency observations modalities. formulation smaller score consistent samples. think score negative likelihood. geneous nature compared. space abstract i.e. structure obtained optimization process semantically interpretable e.g. ﬁxed list attributes properties indexed referring shared knowledge ontology leading p-dimensional vector space. embeddings modality taking values producing outputs common embedding space precisely mahalanobis like description metric parametrized linear mapping mahalanobis mapping interpreted linear embedding abstract m-dimensional vector space natural metric euclidean distance acts multivariate whitening ﬁlter. expected property improve empirically reliability consistency score choosing appropriate linear mapping. main problem addressed work able discriminate series hypotheses speciﬁed using single modality notations. many zero-shot learning studies modality often expressed existence presence several attributes properties ﬁxed given set. simplest embedding space think precisely attribute space implying modality embedding identity simple formulation proposed here question hypotheses speciﬁed target modality external source information attributes semantically organized space leave problem correcting original attribute description construction metric common embedding space. proposed approach consists building empirically objects examples appling metric learning techniques. training supposed contain pairs data sampling joint distribution modalities vector representing image features extracted denotes attribute-based description. notice introduce class information formulation link class attribute representations assumed speciﬁed case considered. rationale behind metric learning transform original representational space resulting metric takes account statistical structure data using pairwise constraints. usual express problem binary classiﬁcation pairs samples role metric separate similar dissimilar samples thresholding survey m.l.). easy build pairs similar dissimilar examples annotated examples sampling randomly also interpreted multi-objective learning approach since mixes optimal dependent issues attribute embedding metric embedding space. solve optimization problem follow approach proposed since also learn attribute embedding part jointly metric embedding instead global stochastic gradient descent formulation classifying made equivalent identifying classes best attribute description. variant scheme exploit voting process identify best attribute among candidates inspired few-shot learning learning metric embedding space conveniently used specialize consistency score data available. study simple tuning approach using stochastic gradient descent criterion applied novel triplets unseen classes only starting model learned seen classes. makes few-shot learningpossible. decision framework identical one. section presents experimental validation proposed method. section ﬁrst introduces datasets evaluated well details experimental settings. method empirically evaluated three diﬀerent tasks described section zero-shot-learning few-shot learning zero-shot retrieval experiments evaluating capability proposed model predict unseen classes. section also evaluates contribution diﬀerent components model performance makes comparisons state-of-the-art results. experiments show model serve good prior learning classiﬁer samples unknown classes available. finally evaluate model task illustrating capability algorithm retrieve images using attribute-based queries. experimental valuation done public datasets widely used community allowing compare results recently proposed literature apascal&ayahoo animals attributes cub-- attribute datasets theses datasets exhibit large number categories attributes datasets introduced training evaluating methods contain images annotated semantic attributes. speciﬁcally image ap&y datasets attribute description meaning images class diﬀerent attributes. case images given class share attributes. consequence experiments ap&y regarding representation images used vgg-verydeep- alexnet models pre-trained imagenet without tuning attribute datasets penultimate fully connected layer representing images. deep models generic feature extractors demonstrated work well object recognition. also used many recent experiments exactly descriptors characteristics model requires image/attributes pairs training. positive pairs obtained taking training images associated provided attribute vector assigned class label order bound size training generate pairs training image positive negative. model three hyper-parameters weight dimensionality space distance computed regularization parameters hyper-parameters estimated grid search validation procedure randomly keeping training classes cross-validating hyper-parameters choosing parameters giving best accuracy so-obtained validation classes. parameter searched followoptimization done stochastic gradient descent parameters initialized randomly normal distribution. size mini-batch objective function non-convex diﬀerent initializations give diﬀerent parameters. addressed issue estimations parameters starting diﬀerent initializations selecting best validation optimizer provided tensorflow framework using mode nvidia learning model performance reported diﬀerent features i.e. vgg-verydeep- alexnet fair comparisons. images public anymore possible features available download. four datasets model achieves state-of-the-art performance published submission) noticeable improvement ap&y. explained previous section model based multi-objective function trying maximize metric discriminating capacity well attribute prediction. interesting observe performance degrades terms missing. table ‘ours setting makes euclidean distance i.e. ‘ours constraint’ setting attribute prediction term missing criterion. term gives improvement average. figure shows accuracy function embedding dimension. projection maps original data space euclidean distance good task considered. seen exploit select correlation structure attributes. experimented best fig. accuracy function dimensionality metric space; best results obtained dimension metric embedding less image space dimension. also shows improvement attribute prediction term objective function. few-shot learning classiﬁcation accuracy function amount training examples unseen classes. few-shot learning corresponds situation annotated example unseen classes available test time. case model ﬁrst trained using seen classes introduced examples unseen class data ﬁne-tuning model parameters learning iterations using data only. figure shows accuracy evolution given function number additional images unseen classes. please note dataset used maximum additional examples unseen classes contain images. observed knowing even number annotated examples signiﬁcantly improves performance. encouraging behavior large-scale applications annotations large number categories hard expensive get. task zero-shot image retrieval consists searching image database attribute-based queries. this ﬁrst train model standard zsl. take attribute descriptions unseen classes queries rank images unseen classes based similarity query. table reports mean average precision datasets. model outperforms state-of-the-art method average. figure shows average precision class datasets. ap&aya dataset ‘donkey’ ‘centaur’ ‘zebra’ classes average precision. explained strong visual similarity classes diﬀer attributes. paper presented novel approach zero-shot classiﬁcation exploiting multi-objective metric learning techniques. proposed formulation nice property requiring ground truth category level learning consistency score image semantic modalities requiring weak consistency information. resulting score used versatility various image interpretation tasks shows close stateof-the-art performance four standard benchmarks. formal simplicity approach allows several avenues future improvement. ﬁrst would provide better embedding semantic side consistency score second would explore complex functions linear mappings tested work introduce instance deep network architectures.", "year": 2016}