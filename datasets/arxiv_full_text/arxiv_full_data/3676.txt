{"title": "A Monte Carlo Algorithm for Universally Optimal Bayesian Sequence  Prediction and Planning", "tag": ["nlin.AO", "cond-mat.dis-nn", "cs.AI", "cs.LG", "stat.ML"], "abstract": "The aim of this work is to address the question of whether we can in principle design rational decision-making agents or artificial intelligences embedded in computable physics such that their decisions are optimal in reasonable mathematical senses. Recent developments in rare event probability estimation, recursive bayesian inference, neural networks, and probabilistic planning are sufficient to explicitly approximate reinforcement learners of the AIXI style with non-trivial model classes (here, the class of resource-bounded Turing machines). Consideration of the effects of resource limitations in a concrete implementation leads to insights about possible architectures for learning systems using optimal decision makers as components.", "text": "work address question whether principle design rational decision-making agents artiﬁcial intelligences embedded computable physics decisions optimal reasonable mathematical senses. recent developments rare event probability estimation recursive bayesian inference neural networks probabilistic planning sufﬁcient explicitly approximate reinforcement learners aixi style non-trivial model classes consideration eﬀects resource limitations concrete implementation leads insights possible architectures learning systems using optimal decision makers components. hutter deﬁnes universal algorithmic agent aixi pareto-optimal policy arbitrary computable stochastic environments. consider monte carlo algorithm sequence prediction planning turing-universal model class seeks statistically approximate resource-bounded aixi avoiding enumerative search similarly powerful algorithms replacing statistical approximations governing probability distributions. hutter held aixi computationally intractible however aixi serve gold standard research. main diﬃculty computing aixi universal model class obtaining algorithmic probabilities hypotheses since algorithmic probabilities limit-computable. previous approaches learning class enumerate proofs enumerate programs hypothesis space executions interleaved take diﬀerent approach characterized main points computation runs tandem environmental process succeed must produce correct result time environment demands thus implicit speed prior imposed model parameterized frequency operation model respect environment alternatively approximating aixi-tl time bound equal relative frequencies model’s cycle environmental inputs length bound determined space available model representation rely directly statistically valid approximations rather proofs valid approximation. otherwise hypotheses weighted according representation-length complexity aixi. using equivalence recurrent neural networks turing machines choose recurrent neural networks model class. additional information relationships recurrent neural network architectures computational classes available main advantages representation parameterized vectors dense numbers therefore straightforward sample meaningful statistically eﬃcient using established monte carlo techniques recurrent neural networks embed class turing machines counted produce meaningful outputs point operation suﬀer halting problem presents algorithmic diﬃculties. among class recurrent neural networks choose modiﬁed version long short-term memory established state-of-theart performance benchmark tasks easily seen continuously-parameterized ﬂip-ﬂop controlled perceptrons making interpretation model straightforward constraining perform known useful. diﬀerent motivation original prevent premature decay error signals training. modiﬁcation bypass gate mixes computation directly output rather forcing computation ﬁrst stored state output cell either memory computational element according circumstance. network outputs made predict network inputs next time step. network inputs presented binary encoding network outputs treated directly probability without less general assumptions probability distributions network inputs. plan present input network concatenation observed environmental inputs agent’s outputs make network generate samples likely continuation sequences predicting distribution inputs outputs next timestep sampling predicted distribution predicting taking sample observed recursively generated samples likely continuation sequences plan generating speciﬁed horizon selecting next action continuation yields ﬁrst obtain sample universal prior model class. must done certain choice model class thereafter algorithm operates discrete timesteps. timestep current environmental inputs agent’s recent outputs presented inputs network network updates estimate neural network parameters according probabilities previously assigned observed inputs. action called current timestep current estimate network parameters used generate likely continuation sequences speciﬁed time horizon generating likely continuation sequence network inputs consist pairs environmental input contains reward signal. next action chosen agent output serves partial preﬁx continuation sequences expected reward. prediction components ﬁrst obtaining useful sample universal prior second recursively updating sample reﬂect posterior distribution light data. sample universal prior face practical diﬃculty wish signiﬁcant numbers samples regions sample space exponentially decreasing probability turn techniques rare-event probability estimation. computation posterior probability rely standard techniques recursive bayesian inference. seek sample models model class large weights following distribution universal posterior predictor take prior probabilities hypotheses universal probabilities maintain posterior likelihoods bayes’ rule measure encoding-length complexity mapping current states inputs subsequent states outputs quantity flat minimum search gives number bits required encode network’s parameters maintain certain amount precision mapping represents. general case multiple inputs going multiple outputs full quantity required implementation weight directly inﬂuences output within iteration following simpliﬁcation obtains quantity reminiscent fisher information algorithm sampling universal prior choose sample size number levels desired quantile suggested parameterspacecardinality parameterspacecardinality generate initial samples metropolis-hastings repeatedly drawing multivariate gaussian laplacian proposal centered current sample accepting samples bounded likelihood ratio min+k greater draw uniform random variable. might also following determination gradient rtrl algorithm equivalent technique given diﬀerent choice architecture case might maintain prior posterior terms weighting separately recompute prior term recursive formula rtrl partial derivatives update posterior term recursively according formula given previously however previous paragraph’s method appropriate interpretation recurrent neural network turing machine states serving bounded work tape neural network serving state-transition dynamics preferred here. using approximate initialize sample size rareevent probability estimation strata acceptance rejection according universal prior distribution parameterized given proportion zero half generate samples according −b+k metropolis-hastings encoding complexity state vector sampled jointly weights within upper quantile sample construct kernel density estimator recursively repeat quantile sample quantile recording boundary value quantile step recursion sequence levels. given sequence levels repeat process level thresholds replacing quantiles. notably obtain process estimate normalization constant universal distribution though unused here. thus obtained sample universal prior must done instantiation network certain architecture update posterior term recursively according formula given previously upon degeneration sample indicated variance weights falling given threshold resample replicating replacing samples samples kernel density estimate according weights sequential monte carlo literature especially include algorithm recursive bayesian posterior update denote current observation previous weights then compute probability sample sample propagating current weighted state samples network evolution represented taking likelihood resulting multivariate bernoulli respect observed bits; then sample replacement probabilies assign unit weight form sample distribution; form kernel density estimator sample take sample assigning unit weight. suggested shrunk kernel density estimator given kernel bandwidth computing translating parameter sample towards sample mean taking linear combination sampling kernel parameterized eachν representation state vector sample states dynamics block maintain separate estimates conditional another common kalman-ﬁltered recurrent neural networks. choose latter. choose multiple simulation steps time step environment relax time bound computation. estimate probability input given -weighted samples model observable state-determined prerequisites application approximately optimal stochastic planning algorithm satisﬁed. plan jointly model environmental inputs including reward signal agent actions sample continuations joint sequence these. obtain distribution future rewards certain actions action sequences grouping continuation samples according actions action sequences contain plan selecting time step next action highest expected total future reward. arbitrary discounting easily accomodated applying appropriate factor step continuation sequence. optimization environment suﬃciently stationary suﬃciently well-approximated model conceivable preﬁxes longer timestep length could chosen executed without re-running planner considered here. algorithm planning time step action called generate probability distribution continuations network input sequences making copy state samples iterating steps algorithm state copy without modifying estimate network parameters sample continuation sequences produced desired time horizon. group continuation sequences according sharing common next agent action take expected discounted future reward within group. perform action highest expected discounted future reward. algorithmic-complexity-based parameter smoothing accomplishes form principled dimensionality reduction within upper bound imposed dimension representation. reversible-jump monte carlo sampler could used select dimensionality without explicit upper bound model input-output relationships input-output pairs presented network inputs planner unnecessary although typical approach analogous operation neural networks giving input network input calling output agent action giving reward signal inversely related output error also work waste planning eﬀort. compute partial derivatives network outputs respect weights input computation using forward-mode automatic diﬀerentiation choice made mostly implementation convenience because general case here input dimension equals output dimension simply-implemented forward-mode diﬀerentiation eﬃcient reverse-mode commonly encountered neural network algorithms. paper applies sampling eﬀect aixi-style learning speciﬁc turinguniversal model class analogous techniques apply model class parameters sampled appropriate modiﬁcations take account needs sampling another model class particularly determination encoding complexity resulting mixture estimate close true distribution model class permits recurrent network setting encoding complexity system dynamics equivalent information rate corresponding process topological entropy corresponding dynamical system. together sampling method presented universal prior could approximately neglecting encoding complexity structure parameter space size parameter space sampled grows exponentially network dimension thus cost associated maintaining sample costs implementation details jacobian accumulation peephole connections across modules lstm grow faster linearly. mitigate costs large network constructed small network modules ability view another’s outputs states additional environmental inputs perhaps probabilistic locality structure imposed limit interconnection costs maintaining bandwidth among computational nodes network topology power-law node degrees. analogy drawn decoupled extended kalman ﬁlter training recurrent neural networks though interactions modules require powerful theoretical framework analyze bounded-universal power models. computability logic framework wherein network modules take oracles. additionally consider allowing modules capable arbitrary computation interact special-purpose modules smoothers system input output pattern-associative memories chess programs etc. depending problem domain. motivation decoupling large network modules view interactions modules environment terms computabilty logic suggests model mammalian brain cortical columns identiﬁed resource-bounded general-purpose-computation modules parts brain either computational oracles ﬁlters input output environment. suppose thalamus serves communication network modules connected another long ranges oracles ﬁlters brain environmental inputs agent controls responsible distributing reward signal information across computational modules; hippocampus serves pattern-associative memory tandem cortical ensemble; cerebellum serves motor output consolidation smoothing. working under hypothesis functional specialization diﬀerent regions cortex might derived considerations computational capacity individual modules information bandwidth connections groups modules region regions relevant function locations network relevant environmental inputs outputs rather sort priori enforced anatomical specialization. also brain thus seen implement solution prediction planning problems optimal resource-bounded stochastic sense quite general. separately also based idea architecture intelligent agent built around communication network transmits data environment computational units permits computational units communicate another transmits commands back executed upon environment agent’s eﬀectors agent architecture suggest means quantifying boyd’s observe-orient-decide-act loop conceptual framework analyzing strategic interactions observation capacity units bits second provide sensory information computational units orientation capacity computational units inform", "year": 2010}