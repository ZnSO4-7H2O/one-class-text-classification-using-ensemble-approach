{"title": "Learning to Track at 100 FPS with Deep Regression Networks", "tag": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "abstract": "Machine learning techniques are often used in computer vision due to their ability to leverage large amounts of training data to improve performance. Unfortunately, most generic object trackers are still trained from scratch online and do not benefit from the large number of videos that are readily available for offline training. We propose a method for offline training of neural networks that can track novel objects at test-time at 100 fps. Our tracker is significantly faster than previous methods that use neural networks for tracking, which are typically very slow to run and not practical for real-time applications. Our tracker uses a simple feed-forward network with no online training required. The tracker learns a generic relationship between object motion and appearance and can be used to track novel objects that do not appear in the training set. We test our network on a standard tracking benchmark to demonstrate our tracker's state-of-the-art performance. Further, our performance improves as we add more videos to our offline training set. To the best of our knowledge, our tracker is the first neural-network tracker that learns to track generic objects at 100 fps.", "text": "abstract. machine learning techniques often used computer vision ability leverage large amounts training data improve performance. unfortunately generic object trackers still trained scratch online beneﬁt large number videos readily available oﬄine training. propose method oﬄine training neural networks track novel objects test-time fps. tracker signiﬁcantly faster previous methods neural networks tracking typically slow practical real-time applications. tracker uses simple feed-forward network online training required. tracker learns generic relationship object motion appearance used track novel objects appear training set. test network standard tracking benchmark demonstrate tracker’s state-of-the-art performance. further performance improves videos oﬄine training set. best knowledge tracker ﬁrst neural-network tracker learns track generic objects fps. given object interest marked frame video goal singletarget tracking locate object subsequent video frames despite object motion changes viewpoint lighting changes variations. single-target tracking important component many systems. person-following applications robot must track person move environment. autonomous driving robot must track dynamic obstacles order estimate moving predict move future. generic object trackers traditionally trained entirely scratch online oﬄine training performed. trackers suﬀer performance cannot take advantage large number videos readily available improve performance. oﬄine training videos fig. using collection videos images bounding labels train neural network track generic objects. test time network able track novel objects without ﬁne-tuning. avoiding ﬁne-tuning network able track many areas computer vision image classiﬁcation object detection segmentation activity recognition machine learning allowed vision algorithms train oﬄine data learn world cases performance algorithm improves iterates training images. models beneﬁt ability neural networks learn complex functions large amounts data. work show possible learn track generic objects real-time watching videos oﬄine objects moving world. achieve goal introduce goturn generic object tracking using regression networks. train neural network tracking entirely oﬄine manner. test time tracking novel objects network weights frozen online ﬁne-tuning required oﬄine training procedure tracker learns track novel objects fast robust accurate manner. although initial work done using neural networks tracking eﬀorts produced neural-network trackers slow practical use. contrast tracker able track objects making best knowledge fastest neural-network tracker to-date. real-time speed factors. first previous neural network trackers trained online however training neural networks slow process leading slow tracking. contrast tracker trained ofﬂine learn generic relationship appearance motion online training required. second trackers take classiﬁcation-based approach classifying many image patches target object contrast tracker uses regression-based approach requiring single feed-forward pass network regresses directly location target object. combination oﬄine training one-pass regression goturn ﬁrst generic object neural-network tracker able fps. standard tracking benchmark demonstrate tracker outperforms state-of-the-art trackers. tracker trains labeled training videos images require class-level labeling information types objects tracked. goturn establishes framework tracking relationship appearance motion learned oﬄine generic manner. code additional experiments found http//davheld.github.io/goturn/goturn.html. online training tracking. trackers generic object tracking typically trained entirely online starting ﬁrst frame video typical tracker sample patches near target object considered foreground patches farther target object also sampled considered background. patches used train foreground-background classiﬁer classiﬁer used score patches next frame estimate location target object unfortunately since trackers trained entirely online cannot take advantage large amount videos readily available oﬄine training potentially used improve performance. researchers also attempted neural networks tracking within traditional online training framework showing state-of-the-art results unfortunately neural networks slow train online training required resulting tracker slow test time. trackers range performing neural-network trackers running hence trackers usable practical applications. tracker trained oﬄine generic manner online training tracker required enabling track fps. model-based trackers. separate class trackers model-based trackers designed track speciﬁc class objects example interested tracking pedestrians train pedestrian detector. test-time detections linked together using temporal information. trackers trained oﬄine limited track speciﬁc class objects. tracker trained oﬄine generic fashion used track novel objects test time. neural network tracking frameworks. related area research patch matching recently used tracking running fps. approach many candidate patches passed network patch highest matching score selected tracking output. contrast network passes images network network regresses directly bounding location target fig. network architecture tracking. input network search region current frame target previous frame. network learns compare crops target object current image prior attempts made neural networks tracking various ways including visual attention models however approaches competitive state-of-the-art trackers evaluated diﬃcult tracker datasets. high level feed frames video neural network network successively outputs location tracked object frame. train tracker entirely oﬄine video sequences images. oﬄine training procedure tracker learns generic relationship appearance motion used track novel objects test time online training required. track. case multiple objects video network must receive information object video tracked. achieve this input image target object network. crop scale previous frame centered target object shown figure input allows network track novel objects seen before; network track whatever object input crop. crop allow network receive contextual information surroundings target object. width height respectively. crop tells network object tracked. value determines much context network receive target object previous frame. look. target object current frame tracker know object previously located. since objects tend move smoothly space previous location object provide good guess network expect currently object. achieve choosing search region current frame based object’s previous location. crop current frame using search region input crop network shown figure goal network regress location target object within search region. expected mean location target object. equivalent constant position motion model although sophisticated motion models used well. crop current frame width height respectively width height predicted bounding previous frame deﬁnes search radius target object. practice long target object become occluded moving quickly target located within region. fast-moving objects size search region could increased cost increasing complexity network. alternatively handle long-term occlusions large movements tracker combined another approach online-trained object detector framework visual attention model leave future work. network output. network outputs coordinates object current frame relative search region. network’s output consists coordinates left bottom right corners bounding box. single-target tracking deﬁne novel image-comparison tracking architecture shown figure model input target object well search region sequence convolutional layers. output convolutional layers features capture high-level representation image. outputs convolutional layers number fully connected layers. role fully connected layers compare features target object features current frame target object moved. frames object undergone translation rotation lighting change occlusion deformation. function learned fully connected layers thus complex feature comparison learned many examples robust various factors outputting relative motion tracked object. detail convolutional layers model taken ﬁrst convolutional layers caﬀenet architecture concatenate output convolutional layers single vector. vector input fully connected layers nodes. finally connect last fully connected layer output layer contains nodes represent output bounding box. scale output factor chosen using validation network hyperparameters taken defaults caﬀenet fully-connected layer dropout relu non-linearities caﬀenet. neural network implemented using caﬀe predict object located frame continue re-crop feed pairs frames network remainder video network track movement target object throughout entire video sequence. train network combination videos still images. training procedure described below. cases train network loss predicted bounding ground-truth bounding box. training consists collection videos subset frames video labeled location object. successive pair frames training crop frames described section training time feed pair frames network attempt predict object moved ﬁrst frame second frame also augment training examples using motion model described section training procedure also take advantage still images labeled location object. training images teaches network track diverse objects prevents overﬁtting objects training videos. train tracker image take random crops image according motion model between crops target object undergone apparent translation scale change shown figure treat crops taken diﬀerent frames video. although motions crops less varied types motions found training videos images still useful train network track variety diﬀerent objects. fig. examples training videos. goal network predict location target object shown center video frame shifted bottom row. ground-truth bounding marked green fig. examples training images. goal network predict location target object shown center image crop shifted bottom row. ground-truth bounding marked green objects real-world tend move smoothly space. given ambiguous image location target object uncertain tracker predict target object located near location previously observed. especially important videos contain multiple nearly-identical objects multiple fruit type. thus wish teach network that else equal small motions preferred large motions. width height respectively bounding previous frame. terms random variables capture change position bounding relative size. training objects change position modeled laplace distribution mean current width height bounding previous width height bounding box. terms random variables capture size change bounding box. training modeled laplace distribution mean distribution gives higher probability keeping bounding size near size previous frame. teach network prefer small motions large motions augment training random crops drawn laplace distributions described training examples sampled laplace distribution small motions sampled large motions thus network learn prefer small motions large motions else equal. show laplace cropping procedure improves performance tracker compared standard uniform cropping procedure used classiﬁcation tasks train network training example alternately taken video image. video training example randomly choose video randomly choose pair successive frames video. crop video according procedure described section additionally take random crops current frame described section augment dataset additional examples. next randomly sample image repeat procedure described above random cropping creates artiﬁcial motions time video image gets sampled random crops produced on-the-ﬂy create additional diversity training procedure. experiments batch size convolutional layers network pre-trained imagenet limited training size ﬁne-tune layers prevent overﬁtting. train network learning rate hyperparameters taken defaults caﬀenet described section train network using combination videos still images. training videos come alov++ collection video sequences. remove videos overlap test leaving videos used training. dataset approximately every frame video labeled location object tracked. videos generally short ranging seconds minutes length. split videos training validation hyper-parameter tuning. training consists total images diﬀerent objects average frames object. validation consists images diﬀerent objects. choosing hyperparameters retrain model using entire training removing overlapping videos overlap videos training test sets. training procedure also leveraged still images used training described section images taken training imagenet detection challenge objects labeled bounding boxes. randomly crop images training time described section create apparent translation scale change between random crops. random cropping procedure useful labeled object entire image; thus ﬁlter images bounding ﬁlls least size image either dimension leaves total annotations images. images help prevent overﬁtting teaching network track objects appear training videos. test consists videos tracking challenge could test method challenge would much overlap test training set. however expect general trends method still hold. tracking challenge standard tracking benchmark allows compare tracker wide variety state-of-the-art trackers. trackers evaluated using standard tracking metrics accuracy robustness range also compute accuracy frame video annotated number attributes occlusion illumination change motion change size change camera motion. trackers also ranked accuracy robustness separately attribute rankings averaged across attributes ﬁnal average accuracy robustness ranking tracker. accuracy robustness rankings averaged overall average ranking. performance tracker shown figure demonstrates tracker good robustness performs near accuracy. further overall ranking outperforms previous trackers benchmark. thus demonstrated value oﬄine training improving tracking performance. moreover results obtained training short videos. figure well analysis appendix suggests gains could achieved training size increased labeling videos. qualitative results well failure cases found project page http//davheld.github.io/; currently tracker fail occlusions overﬁtting objects training set. fig. tracking results tracking challenge. tracker’s performance indicated blue circle outperforming previous methods overall rank points shown along black line represent training videos number training images used case nvidia geforce titan cudnn acceleration tracker runs frame fps. tracker runs average frame fps. available tracker runs fps. tracker able perform training oﬄine test time tracker requires single feed-forward pass network thus tracker able real-time speeds. compare speed rank tracker compared trackers submitted tracking challenge figure using overall rank score described section show runtime tracker units normalizes type hardware tracker tested figure demonstrates fastest trackers compared baselines outperforming methods overall rank note trackers thunderstruck also gpu. detailed analysis speed function accuracy robustness appendix. fig. rank runtime tracker compared baseline methods tracking challenge blue represents performance separate baseline method accuracy robustness metrics shown appendix tracker able track objects real-time aspects model first learn generic tracking model oﬄine online training required. online training neural networks tends slow preventing real-time performance. online-trained neural network trackers range performing trackers running second trackers evaluate ﬁnite number samples choose highest scoring tracking output sampling approach accuracy limited number samples increasing number samples also increases computational complexity. hand tracker regresses directly output bounding goturn achieves accurate tracking extra computational cost enabling track objects fps. diﬀerentiate hypotheses comparing performance network performance network receive previous frame input experiment train networks separately. network receive previous frame input tracker local generic object detector fig. overall tracking errors network receives input current previous frame compared network receives input current frame comparison allows disambiguate hypotheses explain neural-network tracker works accuracy robustness metrics shown appendix figure shows degree hypotheses holds true diﬀerent tracking conditions. example occlusion large camera motion tracker beneﬁts greatly using previous frame enables tracker remember object tracked. figure shows tracker performs much worse cases previous frame included. cases hypothesis plays large role i.e. tracker comparing previous frame current frame target object. hand size change variation tracker performs slightly worse using previous frame large size change corresponding appearance change drastic network perform accurate comparison previous frame current frame. thus tracker acting local generic object detector case hypothesis dominant. hypothesis holds true varying degrees diﬀerent tracking conditions shown figure well tracker generalize novel objects found training set? analysis separate test objects least videos class appear training objects fewer videos class appear training set. figure shows that even test objects similar objects training tracker performs well. performance continues improve even videos unrelated objects added training since tracker able learn generic relationship object’s appearance change motion generalize novel objects. fig. overall tracking errors diﬀerent types objects test function number videos training class labels used tracker; labels obtained purpose analysis. accuracy robustness metrics shown appendix additionally tracker also specialized track certain objects particularly well. figure shows that test objects least videos class appear training obtain large improvement training videos types objects added. allows user specialize tracker particular applications. example tracker used autonomous driving user objects people bikes cars training tracker learn track objects particularly well. time figure also demonstrates tracker track novel objects appear training important tracking objects uncontrolled environments. table show components system contribute performance. train network random cropping laplace distribution teach tracker prefer small motions large motions explained section table shows beneﬁt approach compared baseline uniformly sampling random crops typically done classiﬁcation shown reduce errors drawing random crops laplace distribution. table also shows beneﬁt using loss compared loss. using loss signiﬁcantly reduces overall tracking errors penalty relatively near network suﬃciently penalize outputs close correct network would often output bounding slightly large small. applied sequence frames bounding would grow shrink without bound predicted bounding single point entire image. contrast loss penalizes harshly answers slightly incorrect keeps bounding size closer correct size prevents bounding shrinking growing without bound. train tracker using combination images videos. table shows that given choice images videos training videos gives much bigger improvement tracker performance. time training videos images gives maximum performance tracker. training small number labeled videos taught tracker invariant background motion out-of-plane rotations deformations lighting changes minor occlusions. training large number labeled images taught network track wide variety diﬀerent types objects. training videos images tracker learns track variety object types diﬀerent conditions achieving maximum performance. demonstrated train generic object tracker oﬄine performance improves watching training videos. test time network purely feed-forward manner online ﬁnetuning required allowing tracker fps. tracker learns oﬄine generic relationship object’s appearance motion allowing network track novel objects real-time speeds. acknowledgments. acknowledge support toyota grant -udaro grant --tdauz.", "year": 2016}