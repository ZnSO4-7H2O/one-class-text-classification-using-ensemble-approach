{"title": "Learning how to learn: an adaptive dialogue agent for incrementally  learning visually grounded word meanings", "tag": ["cs.CL", "cs.AI", "cs.LG", "cs.RO"], "abstract": "We present an optimised multi-modal dialogue agent for interactive learning of visually grounded word meanings from a human tutor, trained on real human-human tutoring data. Within a life-long interactive learning period, the agent, trained using Reinforcement Learning (RL), must be able to handle natural conversations with human users and achieve good learning performance (accuracy) while minimising human effort in the learning process. We train and evaluate this system in interaction with a simulated human tutor, which is built on the BURCHAK corpus -- a Human-Human Dialogue dataset for the visual learning task. The results show that: 1) The learned policy can coherently interact with the simulated user to achieve the goal of the task (i.e. learning visual attributes of objects, e.g. colour and shape); and 2) it finds a better trade-off between classifier accuracy and tutoring costs than hand-crafted rule-based policies, including ones with dynamic policies.", "text": "present optimised multi-modal dialogue agent interactive learning visually grounded word meanings human tutor trained real human-human tutoring data. within life-long interactive learning period agent trained using reinforcement learning must able handle natural conversations human users achieve good learning performance minimising human effort learning process. train evaluate system interaction simulated human tutor built burchak corpus human-human dialogue dataset visual learning task. results show that learned policy coherently interact simulated user achieve goal task ﬁnds better trade-off classiﬁer accuracy tutoring costs hand-crafted rule-based policies including ones dynamic policies. introduction intelligent systems/robots brought laboratory physical world must become capable natural everyday conversation human users physical surroundings. among competencies involves ability learn adapt mappings words phrases sentences natural language perceptual aspects external environment widely known grounding problem. know object? suzuli wait sako wakaki? color right shape not. okay burchak burchak sako burchak. cool this? aylana suzili. aylana color? it’s shape. suzili aylana right? yes. agent needs learn ground symbols onto existing perceptual lexical knowledge e.g. silberer lapata thomason kollar matuszek agent child withprior knowledge perceptual categories agent must learn perceptual categories also expressions here concentrate latter scenario system learns identify describe visual attributes interaction human tutors incrementally time. previous work approached grounding problem using variety resources approaches instance either using annotated visual datasets interactions agents real humans feedback however systems ground symbols interaction common important drawbacks order achieve better performance systems require high level human involvement always request feedback human users might affect quality human answers decrease overall user experience lifelong learning task; approaches built/trained based real human-human conversations therefore can’t handle them. natural human dialogue generally messy either machine-machine human-machine dialogue containing natural dialogue phenomena notoriously difﬁcult capture e.g. selfcorrections repetitions restarts pauses ﬁllers interruptions continuations furthermore often exhibit much variation synthetic counterparts order cope ﬁrst problem recent prior work built multimodal dialogue systems investigate effects different dialogue strategies capabilities overall learning performance. results shown that order achieve good tradelearning performance human involvement agent must able take initiative dialogues take account uncertainty predictions well cope natural human conversation learning process. however systems built based hand-crafted synthetic dialogue examples rather real humanhuman dialogues. paper extend work introduce adaptive visual-attribute learning agent trained using reinforcement learning agent trained multi-objective policy capable properly learning novel visual objects/attributes interaction human tutors also efﬁciently minimising human involvement learning process. achieve equivalent/comparable learning performance fully-supervised system less tutoring effort. dialogue control policy trained burchak human-human dialogue dataset consisting conversations human ‘tutor’ human ‘learner’ visual attribute learning task. dataset includes wide range natural increcompare optimised learning agent rule-based agents without adaptive conﬁdence thresholds results show rl-based learning agent outperforms rule-based systems ﬁnding better trade-off learning performance tutoring effort/cost. section review work addressed language grounding problem generally. problem grounding perception received considerable attention computational literature recently. hand work addresses grounding problem implicitly/indirectly category work large literature image video captioning systems learn associate image video descriptions line work uses various forms neural modeling discover association information multiple modalities. often works projecting vector representations different modalities space order retrieve other. importantly models holistic learn symbols speciﬁc tasks without explicit encoding symbolperception link relationship remains implicit indirect. hand models assume much explicit connection symbols perceptions line work representations compositional transparent constituent atomic parts grounded individually perceptual classiﬁers. work paper spirit latter. notated descriptions deﬁnite reference expressions live interaction e.g. latter here clearly appropriate multimodal systems robots expected continuously incrementally learn environment users. multi-modal interactive systems involve grounded language either rule-based e.g. skocaj thomason tellex schlangen systems dialogue control policy hand-crafted therefore systems static cannot adapt less robust; optimised e.g. mohan whitney contrast systems learned data live interaction users; thus adapt behaviour dynamically particular dialogue histories also speciﬁc information another modality ideally interactive systems ought able handle natural spontaneous human dialogue. however work interactive language grounding learn systems synthetic hand-made dialogues simulations lack variation kinds dialogue phenomena occur everyday conversation; thus lead systems robust cannot handle everyday conversation paper change training adaptive learning agent human-human dialogues visual attribute learning task. given above achieve trained adaptive attribute-learning dialogue policy realistic human-human conversations learns optimise trade-off between learning/grounding performance costs form human tutorsin effect form active learning. learning learn visual teraction human tutors tutor learner interactively exchange information visual attributes object see. reinforcement learning policy optimisation learner side tutor side simulated data-driven fashion using human-human dialogue data vision module produces visual attribute predictions using base feature categories i.e. colour space colour attributes ‘bag visual words’ object shapes/class. consists binary classiﬁers logistic regression classiﬁers stochastic gradient descent incrementally learn attribute predictions. visual classiﬁers ground visual attribute words ‘red’ ‘circle’ etc. appear parameters dialogue acts used system. dialogue module implements dialogue system classical architecture composed dialogue management natural language understanding generation components. components interact dialogue representations ask). action representations grounded visual classiﬁers reside vision module. relies adaptive policy learned using policy trained handle natural interactions humans produce coherent dialogues; optimise trade-off accuracy visual classiﬁers cost dialogue tutor. given visual attribute learning task smart agent must learn novel visual objects/attributes accurately possible natural interactions real humans meanwhile attempt minimise human involvement much possible life-long learning process. formulate interactive learning task sub-tasks trained using reinforcement learning hierarchical markov adaptive conﬁdence threshold following previous work also positive conﬁdence threshold threshold determines agent believes predictions. threshold plays essential role achieving trade-off between learning performance tutoring cost since agent’s behaviour e.g. whether seek feedback tutor dependent threshold. form active learning taking place learner asks question attribute isn’t conﬁdent enough already attribute. here learn adaptive strategy aims maximising overall learning performance simultaneously properly adjusting positive conﬁdence threshold range train optimization using library burlap follows detail state space adaptive-threshold initialises -dimensional state space deﬁned uminstance hresholdcur deltaacc uminstance represents many visual objects/images seen hresholdcur represents positive threshold agent currently applying; deltaacc represents seeing instances whether classiﬁer accuracy increases decreases keep constant comparing previous bin. deltaacc conﬁgured three levels action selection actions either increase decrease conﬁdence threshold keep same. reward signal reward function learning tasks given local function rlocal. local reward signal directly proportional agents delta accuracy previous learning step single training episode terminated agent goes instances. natural interaction second sub-task aims learning optimised dialogue strategy allows system achieve learning task natural human-like conversations. state space dialogue agent initialises dimensional state space deﬁned cstate sstate status visual predictions colour shape attributes respectively adaptive conﬁdence threshold described predats represents previous dialogue actions tutor response precontext represents attribute categories talked context history. action selection actions chosen based statistics dialog action frequency occurred burchak corpus including question-asking inform acknowledgment well listening. actions applied either speciﬁc single attribute both. action inform separated sub-actions according whether prediction score greater reward signal reward function learning tasks given global function rglobal dialogue terminated colour shape knowledge either taught human tutors known high conﬁdence scores. dialogue capability listen inform question asking question-answering acknowledgement rejection focus clariﬁcation clariﬁcation-request help-offer help-request checking repetition-request retry-request i.e. applied sarsa algorithm learning multi-mdp learning agent episode deﬁned complete dialogue object. conﬁgured ξ−greedy exploration rate discount factor diet experimental toolkit dialogue collected using incremental variation diet chat-tool developed allows participants communicate shared chat window. supports live ﬁnegrained highly local experimental manipulations ongoing human-human conversation chat-tool designed support elicit record ﬁnegrained level dialogues resemble face-to-face dialogue turns constructed displayed incrementally typed; transient; potentially overlapping; editable i.e. deletion permitted. task learner discover groundings visual attribute words aspects physical world interaction. however since humans already known groundings square task assumed second-language learning scenario visual attribute instead standard english words assigned unknown word made-up language dialogue phenomena chat-tool designed resemble face-to-face dialogue important challenge burchak refers wide range natural incremental dialogue phenomena overlapping selfcorrection repetition ﬁller well continuation hand burchak focuses visual attribute learning task offers list interesting task-oriented dialogue strategies capabilities inform question-asking answering listen well acknowledgement rejection. dialogue action contains huge variations realistic conversation. dialogue actions tagged dataset i.e. trained evaluated optimised learning agents cleaned-up version corpus spelling mistakes emoticons well snippets conversations participant misunderstood task corrected removed. section follow previous work compare trained rl-based learning agent rule-based system best performance previous work. instead using hand-crafted dialogue examples before rl-based system rule-based system trained/developed simulated user trained burchak dialogue data above. learning simple visual attributes hand-made visual object dataset order investigate effects optimised adaptive conﬁdence threshold learning performance build rule-based system three different settings i.e. constant threshold hand-crafted adaptive threshold drops instances hand-crafted adaptive threshold drops instances evaluation metrics compare optimised rule-based learning agents also investigate adaptive threshold affect learning process follows evaluate metrics previous work considering cost tutor accuracy learned meanings i.e. classiﬁers ground colour shape concepts. cost cost measure reﬂects effort needed human tutor interacting system. skocaj point comprehensive teachable system learn autonomously possible rather involving human tutor frequently. several possible costs tutor might incur cinf refers cost tutor providing information single attribute concept cack cost simple conﬁrmation rejection ccrt cost correction single concept associate higher cost correction statements polar questions. penalise learning agent conﬁdently makes false statement thereby incorporating aspect trust metric i.e. differently previous evaluation metrics take account costs parsing producing utterances learning performance mentioned above efﬁcient learner dialogue policy consider classiﬁcation accuracy tutor effort thus deﬁne integrated measure overall performance ratio compare learner’s overall performance across different conditions order train evaluate learning agents build user simulation using generic n-gram framework burchak corpus. user framework takes input sequence recent words dialogue well optional additional conditions outputs next user response multiple levels required e.g. full utterance sequence dialogue actions even sequence single word outputs incremental dialogue. differently existing user simulations framework aims resembling user strategies capabilities realistic conversations also simulating incremental dialogue phenomena e.g. self-repair repetition pauses well ﬁllers. paper created action-based user model predict next user response sequence dialogue actions. simulator produces full utterance following statistics utterance templates predicted action. table shows example interactions learned agent simulated tutor learning task. dialogue agent learned take initiative constantly produces coherent conversations learning process. noted passing vertical axes graphs based averages across folds recall accuracy system tested fold every learning step i.e. every training instances. fig. hand plots accuracy tutoring cost directly. note expected curves terminate place x-axis since different conditions incur different total costs tutor across training instances. gradient curve corresponds increase accuracy unit tutoring cost. gradient line drawn beginning curve fig. constitutes main evaluation measure system’s overall performance condition measure report statistical signiﬁcance results signiﬁcant differences accuracy rl-based policy rule-based policies hand-crafted threshold rl-based policy shows signiﬁcantly less tutoring cost rule-based system constant threshold mean gradient yellow curve actually slightly higher constant-threshold policy blue curve discussed below. discussion accuracy seen fig. rulebased system constant threshold shows fastest increase accuracy ﬁnally reaches around learning process blue curve. systems hand-crafted adaptive threshold incremental decrease shown unexpected trend accuracy across instances orange curve ﬂattens seeing instances grey curve shows good increase beginning later drops instances. thresholds decreased fast agent cannot hear enough feedback tutors improve predictions. contrast this optimised rl-based agent achieves much better accuracy experiment. tutoring cost mentioned above form active learning taking place experiment agent hear feedback tutor conﬁdent enough predictions. also explains slight decrease gradients curves agent exposed training instances subjective conﬁdence predictions increases time thus progressively less need tutoring. detail tutoring cost progresses much slowly system applying hand-crafted adaptive threshold still interactions taking place threshold lower certain value agent might highly conﬁdent predictions. contrast rl-based agent shows faster progress cumulative tutoring cost achieves higher accuracy. overall performance here compare gradients curves optimised learning agent rule-based system constant threshold fig. others incremental decreased threshold cannot achieve acceptable learning performance. agent adaptive threshold achieves slightly better overgradient rule-based system introduced multi-modal learning agent incrementally learn grounded word meanings interaction human tutors time deploys adaptive dialogue policy applied human-human dialogue dataset train evaluate optimised learning agent. evaluated system comparing rule-based system results show that optimised policy learned coherently interact simulated user learn visual attributes object achieves comparable learning performance rule-based systems less tutoring effort needed humans. learning word level learn complete incremental dialogue policy i.e. chooses system output lexical level addition instead acquiring visual concepts objects system recently extended interactively learn real object classes latest system integrates self-organizing incremental neural network deep convolutional neural network learn object classes interaction humans incrementally time. references muhannad al-omari eris chinellato yiannis gatsoulis david hogg anthony cohn. unsupervised grounding textual descriptions object features actions video. principles knowledge representation reasoning proceedings fifteenth international conference cape town south africa april pages harm vries florian strub sarath chandar olivier pietquin hugo larochelle aaron courville. guesswhat? visual object discovery multi-modal dialogue. corr abs/.. simon dobnik robin cooper staffan larsson. type theory records general frameproceedwork modelling spatial language. ings second workshop action perception language healey matthew purver james king jonathan ginzburg greg mills. experimenting clariﬁcation dialogue. proceedings annual meeting cognitive science society. boston massachusetts. meeting association computational linguistics international joint conference natural language processing asian federation natural language processing july beijing china volume long papers. pages cynthia matuszek liefeng luke zettlemoyer dieter fox. learning unscripted deictic gesture language human-robot interactions. proceedings twenty-eighth aaai conference artiﬁcial intelligence july qu´ebec city qu´ebec canada.. pages cynthia matuszek nicholas fitzgerald luke zettlemoyer liefeng dieter fox. joint model language perception grounded attribute learning. proc. international conference machine learning. edinburgh scotland. shiwali mohan aaron mininger james kirk john laird. learning grounded language robots situated interactive instruction. learning interactively human teachers papers aaai fall symposium arlington virginia november iftekhar naim young chol song qiguang liang huang henry kautz jiebo daniel gildea. discriminative unsupervised alignment natural language instructions correnaacl sponding video segments. conference north american chapter association computational linguistics human language technologies denver colorado june pages matthew purver raquel fern´andez matthew frampcascaded lexiton stanley peters. calised classiﬁers second-person reference resproceedings annual sigolution. dial meeting discourse dialogue association computational linguistics london pages http//www.dcs.qmul.ac.uk/ mpurver/papers/purveret-alsigdial-you.pdf. casey kennington david schlangen. simple learning compositional application perceptually grounded word meanings incremental reference resolution. proceedings annual carina silberer mirella lapata. learning grounded meaning representations autoenproceedings annual meetcoders. association computational linguistics yanchao arash eshghi oliver lemon. comparing attribute classiﬁers interactive lanproceedings fourth guage grounding. workshop vision language. association computational linguistics lisbon portugal pages http//aclweb.org/anthology/w-. yanchao arash eshghi oliver lemon. interactively learning visually grounded word meanings human tutor. proceedings workshop vision language hosted annual meeting association computational linguistics vlacl august berlin germany. yanchao arash eshghi oliver lemon. training adaptive dialogue policy interactive learning visually grounded word meanings. proceedings sigdial conference annual meeting special interest group discourse dialogue september angeles usa. pages yanchao arash eshghi gregory mills oliver lemon. proceedings sixth workshop vision language association computational linguistics chapter burchak corpus challenge data interactive learning visually grounded word meanings pages http//aclweb.org/anthology/w-. tong zhang. solving large scale linear prediction problems using stochastic gradient descent algorithms. proceedings twenty-ﬁrst international conference machine learning. page danijel skocaj alen vrecko marko mahnic miroslav jan´ıcek geert-jan kruijff marc hanheide nick hawes jeremy wyatt thomas keller zhou michael zillich matej kristan. integrated system interactive continuous learning categorical knowlj. exp. theor. artif. intell. edge. https//doi.org/./x... danijel skoˇcaj matej kristan aleˇs leonardis. formalization different learning strategies proceedcontinuous learning framework. ings ninth international conference epigenetic robotics; modeling cognitive development robotic systems. lund university cognitive studies pages richard socher andrej karpathy quoc christopher manning andrew grounded compositional semantics ﬁnding transactions describing images sentences. association computational linguistics joshua mason joseph nicholas roy. learning perceptually grounded word meanings unaligned parallel data. machine learning https//doi.org/./s---. stefanie tellex pratiksha thakerll robin deitsl dimitar simeonovl thomas kollar nicholas royl. toward information theoretic human-robot dialog. robotics science systems page jesse thomason jivko sinapov maxwell sevtlik peter stone raymond mooney. learning multi-modal grounded linguistic semantics playing spy. appear proceedings twenty-fifth international joint conference artiﬁcial intelligence ijcai- york city july jesse thomason shiqi zhang raymond mooney peter stone. learning interpret natural language commands human-robot diproceedings twenty-fourth interalog. national joint conference artiﬁcial intelligence ijcai buenos aires argentina july pages david whitney eric rosen james macglashan lawson tellex stefanie l.s. wong. fcmng. reducing errors object-fetching interactions proceedings ieee insocial feedback. ternational conference robotics automation icra june marina sands singapore.", "year": 2017}