{"title": "DeepChess: End-to-End Deep Neural Network for Automatic Learning in  Chess", "tag": ["cs.NE", "cs.LG", "stat.ML"], "abstract": "We present an end-to-end learning method for chess, relying on deep neural networks. Without any a priori knowledge, in particular without any knowledge regarding the rules of chess, a deep neural network is trained using a combination of unsupervised pretraining and supervised training. The unsupervised training extracts high level features from a given position, and the supervised training learns to compare two chess positions and select the more favorable one. The training relies entirely on datasets of several million chess games, and no further domain specific knowledge is incorporated.  The experiments show that the resulting neural network (referred to as DeepChess) is on a par with state-of-the-art chess playing programs, which have been developed through many years of manual feature selection and tuning. DeepChess is the first end-to-end machine learning-based method that results in a grandmaster-level chess playing performance.", "text": "abstract. present end-to-end learning method chess relying deep neural networks. without priori knowledge particular without knowledge regarding rules chess deep neural network trained using combination unsupervised pretraining supervised training. unsupervised training extracts high level features given position supervised training learns compare chess positions select favorable one. training relies entirely datasets several million chess games domain speciﬁc knowledge incorporated. experiments show resulting neural network state-of-the-art chess playing programs developed many years manual feature selection tuning. deepchess ﬁrst end-to-end machine learning-based method results grandmaster-level chess playing performance. computer chess programs based typically manual feature selection tuning evaluation function usually years trial error. computer chess researched ﬁelds within machine learning successful producing grandmaster level players. paper employ deep neural networks learn evaluation function scratch without incorporating rules game using manually extracted features all. instead system trained large dataset chess positions. training done multiple phases. first deep unsupervised neural networks pretraining. train supervised network select preferable position input positions. second network incorporated form alpha-beta search. third training phase used compress network order allow rapid computation. method obtains grandmaster-level chess playing performance state-of-the-art chess programs. best knowledge ﬁrst machine learning-based method capable learning scratch obtains grandmaster-level performance. current advanced chess programs outperforming strongest human players recent machine matches clearly indicate. despite achievements glaring deﬁciency today’s chess programs severe lack learning capability ﬁfty years research area computer games many learning methods employed several games. reinforcement learning successfully applied backgammon checkers although reinforcement learning also applied chess resulting programs exhibit playing strength human master level best substantially lower grandmaster-level state-of-the-art chess programs. experimental results conﬁrm wiering’s formal arguments failure reinforcement learning rather complex games chess. recently combination monte-carlo search deep learning resulted huge improvement game however monte-carlo search applicable chess since much tactical e.g. certain position moves opponent result favorable result refutation suﬃcient render position unfavorable. previous works demonstrated genetic algorithms could applied successfully problem automatic evaluation function tuning features initialized randomly although best knowledge works successful automatic learning methods resulted grandmaster-level performance computer chess involve learning features scratch. rather rely existence manually created evaluation function consists already required features thus used context optimization weights existing features rather feature learning scratch. evaluation function important component chess program. receives chess position input provides score output. score represents good given position example drawish position would score close position white pawns black would score position evaluation function considers typically large number properties addition various piece-related parameters king safety passed pawns doubled pawns piece centrality etc. resulting score linear combination selected features. accurately features associated values capture inherent properties position stronger corresponding chess program becomes. paper interested developing evaluation function scratch i.e. absolutely priori knowledge. result provide evaluation function features including knowledge rules chess. thus training purposes limited observing databases chess games access results games since real objective evaluation function perform relative comparisons positions propose novel training method around concept. model receives positions input learns predict position better. training input pair selected follows position selected random game white eventually game black eventually won. relies safe assumption that average positions taken games white preferable taken games white lost. additionally proposed approach allows creation considerably larger training dataset. example million positions games white million positions approach consists multiple stages. first train deep autoencoder dataset several million chess positions. deep autoencoder functions nonlinear feature extractor. refer component posvec since converts given chess position vector values represent high level features. second phase copies pretrained posvec side side fully connected layers them -value softmax output layer. refer structure deepchess. trained predict positions results win. note similar successful object detection methods found -value output outperform binary output. figure illustrates neural network architecture. dataset employed games dataset ccrl contains chess games white games black games remaining games ended draw. experiments show inclusion games ended draw beneﬁcial games ended win. game randomly extracted positions restriction selected position cannot ﬁrst moves game actual move played selected position capture. capture moves misleading mostly result transient advantage since side likely capture back right away. dataset thus contains positions games white positions games white lost total positions. training posvec ﬁrst trained deep belief network would later serve initial weights supervised training. based stacked autoencoders trained using layer-wise unsupervised training. network consists fully connected layers sizes ––––. initially trained ﬁrst layer autoencoder) ﬁxing weights training weights autoencoder used random subset chess positions training white positions black positions. uses rectiﬁed linear unit i.e. learning rate starts multiplied epoch. regularization used. trained epochs. training deepchess described earlier siamese network core component method. used previously trained posvec initial weights supervised network. placing disjoint copies posvec side side added four fully connected layers size connected posvec components. ﬁrst layers posvec thus serve high level feature extractors last four layers compare features positions determine better. supervised training phase entire network including posvec parts modiﬁed. weights posvec-based feature extraction components i.e. shared weights. trained network epochs. epoch created random input pairs pair consists position selected random positions position selected random positions. pair randomly ordered either since number thus guaranteeing overﬁtting would take place. reason regularization term. activation used layers relu function. learning rate starts multiplied epoch. cross entropy loss used. training validation accuracies obtained respectively. remarkable considering priori knowledge chess including rules games provided. improving inference speed network distillation incorporating trained network chess program evaluating performance ﬁrst address problem network computationally expensive prediction mode running markedly slower typical evaluation function chess program. several previous works demonstrated considerably smaller neural network could trained mimic behavior much complex neural network network compression distilling approaches train smaller network produce output larger network ﬁrst trained smaller four-layer network neurons mimic feature extraction part deepchess consists layers –––. added three layers neurons trained entire network mimic entire deepchess network.. optimization achieved realizing weights concentrated ﬁrst layer posvec components chess pieces given position less weights input layer would activated. thus amount ﬂoating point operations required performed inference much reduced. table summarizes validation results post compression. distilled network comparable full original network. training scratch using smaller network size performance much reduced. chess engines typically alpha-beta search algorithm alpha-beta depth-ﬁrst search method prunes unpromising branches search tree earlier improving search eﬃciency. given position root search tree legal moves side create next layer nodes. time available deeper search tree processed would result better overall playing strength. leaf nodes evaluation function applied. alpha-beta search values stored; represents value current best option side move negative side. position encountered value value would become value search stopped search tree pruned value means opponent would allowed current position reached complex imbalances predictions deepchess show easily learned basic concepts regarding piece values. measured subtle positional features e.g. king safety bishop pair piece mobility passed pawns isolated pawns doubled pawns castling rights etc. features also well understood deepchess. interestingly deepchess learned prefer positions dynamic attacking opportunities even less material. many cases prefers position fewer pawns oﬀers non-material positional advantages. property associated human grandmasters always considered area computer chess programs lacking. scores current evaluation functions state-of-the-art chess programs based linear combination features present deepchess nonlinear evaluator thus higher potential profound understanding chess positions figure shows examples preference deepchess non-materialistic advantages leads favoring positional sacriﬁces played human grandmasters. used falcon chess engine baseline experiments. falcon grandmaster-level chess program successfully participated several world computer chess championships particular second place world computer speed chess championship falcon’s extensive evaluation function consists parameters implementation contains several thousands lines code. despite computational improvements mentioned earlier deepchess numerous implementation improvements result substantial additional computational speedup deepchess still four times slower falcon’s evaluation function. nevertheless incorporate deepchess falcon completely replacing evaluation function program. measure performance deepchess conducted series matches falcon also chess program crafty. crafty successfully participated numerous wcccs direct descendant cray blitz wccc winner frequently used literature standard reference. matches deepchess falcon crafty consisted games time control minutes game side. table provides results. seen deepchess falcon. falcon uses manually tuned evaluation function developed nearly years containing hundred parameters grasp many subtle chess features. without chess knowledge whatsoever deepchess method managed reach level manually tuned evaluation function falcon. results also show deepchess stronger crafty program wcccs manually tuned thirty years. deepchess performs falcon despite fact four times slower. separate experiment allowed deepchess four times time falcon running matches deepchess resoundingly defeated falcon result corresponding performance diﬀerence. shows deepchess actually falcon’s evaluation function considerably superior order utilize full potential enhanced chess understanding critical decrease runtime neural network inference mode. presented ﬁrst successful end-to-end application machine learning computer chess. similarly human chess masters deepchess assign numeral evaluation values diﬀerent positions rather compares diﬀerent positions arise opts promising continuation. observed playing style deepchess note plays aggressively often sacriﬁcing pieces long term positional gains playing style resembles much playing style human grandmasters. computer chess programs long criticized materialistic deepchess demonstrates opposite exhibiting adventurous playing style frequent positional sacriﬁces.", "year": 2017}