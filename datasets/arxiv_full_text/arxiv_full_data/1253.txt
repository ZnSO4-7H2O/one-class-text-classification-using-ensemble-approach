{"title": "Introspective Generative Modeling: Decide Discriminatively", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "We study unsupervised learning by developing introspective generative modeling (IGM) that attains a generator using progressively learned deep convolutional neural networks. The generator is itself a discriminator, capable of introspection: being able to self-evaluate the difference between its generated samples and the given training data. When followed by repeated discriminative learning, desirable properties of modern discriminative classifiers are directly inherited by the generator. IGM learns a cascade of CNN classifiers using a synthesis-by-classification algorithm. In the experiments, we observe encouraging results on a number of applications including texture modeling, artistic style transferring, face modeling, and semi-supervised learning.", "text": "figure ﬁrst shows development pseudonegative samples course training process tree bark texture selected rounds. initial scaffold created reﬁned network later rounds. input tree bark texture synthesized image algorithm shown second row. generative discriminative models traditionally considered distinct complementary other. past connections built combine families presence supervised information large amount data discriminative classiﬁer exhibits superior capability making robust classiﬁcation learning rich informative representations; unsupervised generative models require supervision price relying assumptions often ideal dealing problems real-world complexity. attempts previously made learn generative models directly using discriminative classiﬁers density estimation image modeling also wave recent development generative adversarial networks discriminator helps generator fooled fake samples. discuss detail relations connections study unsupervised learning developing introspective generative modeling attains generator using progressively learned deep convolutional neural networks. generator discriminator capable introspection able self-evaluate difference between generated samples given training data. followed repeated discriminative learning desirable properties modern discriminative classiﬁers directly inherited generator. learns cascade classiﬁers using synthesis-by-classiﬁcation algorithm. experiments observe encouraging results number applications including texture modeling artistic style transferring face modeling semisupervised learning. supervised learning techniques made substantial impact tasks formulated classiﬁcation/regression problem; well-known classiﬁers include boosting random forests convolutional neural networks unsupervised learning task-speciﬁc labeling/feedback provided input data still remains difﬁcult problems machine learning holds bright future since large number tasks little supervision. popular unsupervised learning methods include mixture models principal component analysis spectral clustering topic modeling autoencoders nutshell unsupervised learning techniques mostly guided minimum description length principle best reconstruct data whereas supervised learning methods primarily driven minimizing error metrics best input labeling. unsupervised learning models often generative supervised classiﬁers often discriminative; generative model learning traditionally considered self supervised boosting algorithm proposed train boosting algorithm sequentially adding features weak classiﬁers additionally self-generated negative samples; generative discriminative modeling work generalizes concept generative model successfully modeled learning sequence discriminative classiﬁers self-generated pseudo-negatives. inspired prior work generative modeling development convolutional neural networks develop image modeling algorithm introspective generative modeling simultaneously generator discriminator consisting critical stages training pseudo-negative sampling stage self-generation classiﬁer learning stage self-evaluation model updating. number interesting properties worth highlighting classiﬁer generator special condition architecture needed many existing classiﬁers directly made generators trained properly. end-to-end self-evaluation learning perform end-toend introspective learning self-classify synthesized samples training data followed direct discriminative learning approach target distribution. integrated unsupervised/supervised learning unsupervised supervised learning carried similar pipelines differing absence presence initial negative samples. backpropagation synthesis-by-classiﬁcation algorithm performs efﬁcient training using backpropagation stages sampling stage input images classiﬁcation stage parameters. model-based anysize-image-generation since generative modeling models input image able train images size generate image larger size maintaining coherence entire image. agnosticity various vision applications intrinsic modeling power time generative discriminative adopted many applications; pipeline show number vision tasks experiments including texture modeling artistic style transference face modeling semi-supervised image classiﬁcation paper. supervised classiﬁcation cases algorithm introspective learning family seen introspective generative modeling algorithm connections many existing approaches including minmax entropy work texture modeling hybrid modeling work self-supervised boosting algorithm builds convolutional neural networks particularly inspired lines prior algorithms generative modeling discriminative approach method deepdream code neural artistic style work general pipeline similar boosting algorithm used replaced igm. importantly work motives signiﬁcantly improve time-consuming sampling process efﬁcient process backpropagation next review existing generative image modeling work followed detailed discussions related algorithms recent development generative adversarial networks history generative modeling image nonimage domains extremely rich including general image pattern theory deformable models inducing features wake-sleep minimax entropy theory ﬁeld experts bayesian models deep belief nets pioneering works points promising direction unsupervised generative modeling. however modeling power existing frameworks still somewhat limited computational and/or representational aspects. addition many sufﬁciently explore power discriminative modeling. recent works adopt convolutional neural networks generative modeling either cnns feature extractor create separate paths neural artistic transferring work demonstrated impressive results image transferring texture synthesis tasks focused careful study channels attributed artistic texture patterns instead aiming build generic image modeling framework. self-supervised boosting work sequentially learns weak classiﬁers boosting density estimation modeling power adequately demonstrated. relationship generative discriminative learning framework learns generator sequence boosting classiﬁers using repeatedly self-generated samples called pseudo-negatives approach target distribution. algorithm takes inspiration also observe number limitations overcome uses manually speciﬁed feature types fairly limited today’s standard; sampling process based markov chain monte carlo computational bottleneck; experimental results image modeling classiﬁcation satisfactory. summarize main differences include pling process otherwise slow impractical. alternative algorithm namely igm-single additionally proposed maintain single classiﬁer igm. higher quality results image modeling demonstrated recent development generative adversarial neural networks interesting also highly related igm. summarize differences gan. recent algorithms alongside share similar properties uniﬁed generator/discriminator separate generator discriminator. maintains single model simultaneously generator discriminator. generator therefore self-awareness able self-evaluate difference generated samples w.r.t. training data followed direct classiﬁer training. instead creates convolutional networks generator discriminator. training. internal competition generator discriminator known hard train carries straightforward backpropagation sampling classiﬁer training stage making learning process direct. example textures shown experiments fig. fig. results obtained identical setting without hyper-parameter tuning. modeling. generator mapping features images. directly models underlying statistics image efﬁcient sampling/inference process makes ﬂexible. example able conduct model-based-anysize-generation texture modeling task directly maintaining underlying statistics entire image. speed. performs forward pass reconstruct image generally faster synthesis carried using backpropagation. still practically feasible since takes seconds synthesize image size around seconds synthesize texture image size excluding time load models. model size. since cascade classiﬁers included single model much larger model complexity gan. advantage igm. alternative igm-single model maintains single classiﬁer generative power worse gan. introspective classiﬁer learning work sister paper focusing discriminator side emphasizing classiﬁcation power. focuses generator side studying image construction capability. consists sequence cascading classiﬁers whereas composed single classiﬁer. essentially similar igm-single small difference absence/presence given negative samples. generative modeling aspect icl/igmsingle competitive though. formulation training softmax multi-class classiﬁcation proposed igm. addition focuses single image patch whereas able model/synthesize arbitrary size image. number important image modeling tasks including texture modeling style transferring face modeling semi-supervised learning demonstrated here covered method describe introspective generative modeling algorithm. discuss main formulation ﬁrst bears level similarity however replacement boosting algorithm convolutional neural networks demonstrates signiﬁcant improvement terms modeling computational power. enhanced modeling power comes mainly cnns end-to-end learning automatic feature learning tuning backpropagating network parameters; enhanced computational power also largely cnns natural implementation sampling backpropagating input image. similar igm-single maintains single opposed sequence classiﬁers igm. motivate formulation bayes theory similar gdl. formulation start discussion borrowing notation suppose given training images ..n}. focus patch-based input ﬁrst data sample adopt pseudo-negative concept deﬁned deﬁne class labels indicating negative positive sample. assume positive samples label patterns/targets want study. generative model computes captures underlying generation process class discriminative classiﬁer instead computes bayes rule similar motivation generative model positive samples fully represented generative model negatives discriminative classiﬁer accurately obtained/learned. however seemingly intriguing property chicken-and-egg problem. faithfully learn positive patterns need representative equally difﬁcult more. clarity represent algorithm solution given learning using iterative process starting initial reference distribution negatives e.g. gaussian distribution entire space figure schematic illustration pipeline igm. ﬁgure shows input training samples shown circles. bottom ﬁgure shows pseudo-negative samples drawn learned ﬁnal model. left panel displays pseudo-negative samples drawn time stamp right panel shows classiﬁcation training samples pseudo-negatives time stamp includes pseudo-negative samples self-generated round. indicates number pseudonegatives generated round. carry learning ...t iteratively obtain t−dx. hope gradually learn following iterative process samples drawn become indistinguishable given training samples. samples drawn called pseudo-negatives following deﬁnition next present realization namely additionally igm-single training next present introspective generative modeling algorithm using sequence classiﬁers called igm. given training deﬁned ..n} turned ..n} within discriminative setting. start initial pseudo-negative synthesis-step goal draw fair samples sampling process carried backpropagation need sequence classiqa ..t. timeﬁers using consuming. practice simply perform backpropaqt gation previous st−− taking therefore generating pseudo-negative samples training need large overhead. additional gaussian noise added stochastic gradient observe difference quality samples practice. probably equivalent class probability mass widely distributed extremely large image space. sampling strategies various markov chain monte carlo techniques including gibbs sampling iterated conditional modes adopted often slow. motivated deepdream code neural artistic style work perform stochastic gradient descent backpropagation synthesis. recent works show connection equivalence stochastic gradient descent/ascent markov chain monte carlo sampling conducting experiments alternative sampling schemes using applied earlystopping becomes positive sampling equilibrium long steps. found early-stopping effective efﬁcient viewed contrastive divergence short markov chain simulated. input ..n} initialization obtain initial distribution e.g. gaussian pseudo-negative samples create t=..t classiﬁcation-step train classiﬁer st−− resulting update model synthesis-step sample pseudo-negative samples using varip ational sampling procedure obtain back step convergence algorithm describes learning process. pipeline shown fig. consists synthesis step classiﬁcation step. sequence classiﬁers progressively learned. pseudo-negatives gradually generated classiﬁcation boundary gets tightened approaches target distribution. classiﬁcation-step classiﬁcation-step viewed training normal classiﬁer training ..n}. base classiﬁer. training classiﬁer denote parameters learned high-dimensional vector might consist millions parameters. denotes weights layer combining features carries internal representations. without loss generality assume sigmoid function discriminative probability figure illustration model-based anysize-image-generation strategy. anysize-imagegeneration within allows generate/synthesize image much larger given one. patches extracted training images used training discriminator. however position within training image lost. particular performing synthesis using backpropagation updates pixel values made considering average loss patches overlap given pixel. thus round order consider updates patch centered position image size perform backpropagation patches increase probability shares similar cascade aspect convergence iterative learning process target distribution shown following theorem theorem kl||p− +)||p− gences alternative igm-single denotes score patch size e.g. discriminator round fig. gives illustration round sampling. allows synthesize much larger images able enforce coherence interactions surrounding particular pixel. practice stochasticity efﬁciency synthesis process randomly sampling patches. experiments evaluate igm-single. method adopt discriminator architecture involves input size colorspace four convolutional layers using kernel sizes layers using channels respectively. include batch normalization convolutional layer leaky relu activations leak slope classiﬁcation layer ﬂattens input ﬁnally feeds sigmoid activation. serves discriminator patches extract training image. note genbrieﬂy present igm-single algorithm similar introspective classiﬁer learning algorithm difference without presence input negative samples. pipeline igm-single shown fig. aspect maintain single classiﬁer throughout entire learning process. classiﬁcation step obtain used update according synthesized pseudo-negatives. pseudo-negatives recent rounds chosen mini-batches higher probability earlier rounds order ensure discriminator learns recent mistakes well provide efﬁcient training accumulated negatives grown large later rounds. synthesis stage pseudo-negatives synthesized using previous round’s pseudo-negatives initialization. adam used learning rate stops early average probability patches discriminator likely positive across window previous steps usually order reduce variance. allows average cross decision boundary current iteration discriminator. sampling strategy attain good balance effectiveness efﬁciency. empirically training networks rounds provide good results terms synthesis distillation model’s knowledge. textures synthesized sampling distribution used initially training performing backpropagation synthesis using saved parameters networks round feeding resulting partial synthesis next round. early stopping criterion used outlined training however number patches dialed match number synthesized. patches image synthesizing image since matches average number patches extracted image training. making number patches much larger corresponding ratio used training process shown generate images lower quality diversity. considering results fig. generates images similar quality however usually faithful structure input images. fig. bricks texture synthesized strict grout lines straight ensure bricks rectilinear. similarly fig. forest texture preserves continuity allows variation angle path tree trunks take. diamond texture reﬂective grid-like pattern seen input image allow overlap differently sized diamonds. bottom pebbles resulting synthesis captures size pebbles seen input image well variation color shading. artistic style transfer texture synthesis artistic style make anysize-image-generation architecture adding head network that forward pass network randomly selects number random patches full sized images passes discriminator. allows retain whole space patches within training image rather select subset advance training. texture synthesis texture modeling/rendering long standing problem computer vision graphics interested statistical texture modeling instead texture rendering train similar textures source texture resized used single positive example training negative examples initially sampled normal distribution size adding padding pixels spatial dimension image ensure pixel center equal probability extracted patch. patches extracted randomly across training images discriminator forward pass network batch size images random positives negatives training pseudo-negatives synthesis. round classiﬁer ﬁnetuned using stochastic gradient descent learning rate previous round’s classiﬁer augmentation negative input image istyle stylized version style denotes model learned training style image. include ﬁdelity term synthesis weighted parameter making istyle away input image choose average difference original content image current stylized image step synthesis. examples artistic style transfer shown fig. face modeling figure generated images learned celeba dataset. ﬁrst second third column respectively results dcgan using tensorﬂow implementation igm-single igm. celeba dataset used face modeling experiment consists face images. crop center patches images positive examples. classiﬁcation step stochastic gradient descent learning rate batch size images contains random positives random negatives. synthesis step adam optimizer learning rate stop early pseudo-negatives cross decision boundary. fig. show face examples generated model dcgan model. figure generated images learned svhn dataset. ﬁrst second third column respectively results dcgan using tensorﬂow implementation igm-single igm. svhn dataset consists color images house numbers collected google street view. training consists images extra consists images test images. images size combine training extra positive examples unsupervised learning. following settings face modeling experiments model generate examples shown fig. svhn semi-supervised classiﬁcation perform semi-supervised classiﬁcation experiment following procedure outlined ﬁrst train model svhn training extra unsupervised section then train l-svm learned representations model. features last three convolutional layers concatenated form -dimensional feature vector. example held-out validation taken training used model selection. classiﬁer trained examples taken random remainder training set. test error rate averaged different svms trained random -example training sets. within setting model achieves test error rate dcgan model achieves identical setting fair comparison since result reported achieved training imagenet dataset). conclusion introspective generative modeling points encouraging direction unsupervised image modeling capitalizes power discriminative deep convolutional neural networks. adopted wide range problems computer vision machine learning.", "year": 2017}