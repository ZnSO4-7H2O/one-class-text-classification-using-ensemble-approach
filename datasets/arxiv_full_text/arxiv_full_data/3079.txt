{"title": "Text2Shape: Generating Shapes from Natural Language by Learning Joint  Embeddings", "tag": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "abstract": "We present a method for generating colored 3D shapes from natural language. To this end, we first learn joint embeddings of freeform text descriptions and colored 3D shapes. Our model combines and extends learning by association and metric learning approaches to learn implicit cross-modal connections, and produces a joint representation that captures the many-to-many relations between language and physical properties of 3D shapes such as color and shape. To evaluate our approach, we collect a large dataset of natural language descriptions for physical 3D objects in the ShapeNet dataset. With this learned joint embedding we demonstrate text-to-shape retrieval that outperforms baseline approaches. Using our embeddings with a novel conditional Wasserstein GAN framework, we generate colored 3D shapes from text. Our method is the first to connect natural language text with realistic 3D objects exhibiting rich variations in color, texture, and shape detail. See video at https://youtu.be/zraPvRdl13Q", "text": "abstract. present method generating colored shapes natural language. ﬁrst learn joint embeddings freeform text descriptions colored shapes. model combines extends learning association metric learning approaches learn implicit cross-modal connections produces joint representation captures many-to-many relations language physical properties shapes color shape. evaluate approach collect large dataset natural language descriptions physical objects shapenet dataset. learned joint embedding demonstrate text-to-shape retrieval outperforms baseline approaches. using embeddings novel conditional wasserstein framework generate colored shapes text. method ﬁrst connect natural language text realistic objects exhibiting rich variations color texture shape detail. language allows people communicate thoughts feelings ideas. research artiﬁcial intelligence long sought mimic component human cognition. goal bridge natural language visual modalities. imagine describing round glass coﬀee table four wooden legs having matching colored shape retrieved generated. refer tasks text-to-shape retrieval text-to-shape generation. systems capabilities many applications computational design fabrication augmented reality education. example text-to-shape retrieval systems useful querying shape databases without reliance human annotation individual shapes. likewise text-to-shape generation facilitate design. currently model designers rely expensive modeling software steep learning curves tedious time-consuming manual design. text-to-shape generation system initialize shapes basic attributes deﬁned using natural language descriptions. technology save time money allow inexperienced users design shapes fabrication. fig. leveraging dataset paired natural language descriptions colored shapes method extends learning association metric learning jointly learn text shape embedding clusters similar shapes descriptions establishing implicit semantic connections apply learned embedding tasks text-to-shape retrieval shapes matching description retrieved dataset challenging task text-to-shape generation novel shape generated text. achieve goal need system understands natural language shapes. connect language shapes joint embedding space text shapes. prior work text image embedding image shape embedding prior work text shape embedding best knowledge. moreover prior approaches learning text-image representations rely ﬁnegrained category-level class attribute labels annotations expensive also ill-deﬁned classify objects color material style? ideally would like learn joint embedding text shapes directly natural language descriptions without relying ﬁnegrained category attribute annotations. however connecting natural language shapes challenging simple one-to-one mapping between text shapes given shape many ways describe given natural language description many possible shapes match description. paper ﬁrst present method learning joint text shape representation space directly natural language descriptions shape instances followed text-to-shape generation framework. unlike related work text-to-image synthesis rely ﬁne-grained categorylevel class labels pre-training large datasets. furthermore train text shape encoding components jointly end-to-end fashion associating similar points data within modality modalities this take inspiration recent work learning association establish implicit cross-modal links similar descriptions shape instances combine metric learning scheme strengthens links similar instances modality approach leverages instance-level correspondences text description shape cluster similar descriptions induces attributebased clustering similar shapes. thus obviate need expensive ﬁne-grained category attribute annotations. apply method text-to-shape retrieval text-to-shape generation retrieval task allows evaluate quality jointly learned text-shape embedding baselines prior work. text-toshape generation task challenging task propose. focus colored shape generation descriptions shapes involve color material properties. address task combine joint embedding model novel conditional wasserstein framework providing greater output quality diversity compared conditional formulation. lastly vector embedding arithmetic generator manipulate shape attributes. realistic challenging evaluation collect natural language descriptions chair table shapes shapenet dataset. facilitate controlled evaluation also introduce dataset procedurally generated colored primitives synthetic text captions. experimental results datasets show model outperforms baselines large margin retrieval generation tasks. summary contributions follows create datasets shape color voxelizations corresponding text shapenet objects natural language descriptions procedurally generated geometric primitives synthetic text descriptions. learning representations visual descriptions. reed learn text embeddings capture visual information. work basis several text-to-image synthesis works method applied text-to-image problem utilizes pre-training large image datasets. importantly relies ﬁne-grained category-level labels image expensive collect always well-deﬁned contrast rely ﬁne-grained category attribute labels pre-training. salakhutdinov train deep boltzmann machine model images text tags. sohn introduce generative model multimodal data hallucinating missing data modality minimizing variation information. another class methods learns joint representations using canonical correlation analysis many extensions including deep however point scale well large amounts data text shapes dataset. recent work text-image joint embeddings focuses aspects decoding distributed representations using unsupervised learning unlabeled data. metric learning. metric learning using deep neural networks gained signiﬁcant attention recent years. common methods include using contrastive loss triplet loss n-pair loss extend method song joint representation learning approach. since problem learning joint metric space across diﬀerent modalities framework similar spirit prior cross-modal metric learning formulations compute distances within modality across modalities however smoothed triplet-based similarity loss. generative models generative adversarial networks generative models particularly relevant text-to-shape generation task. recent works shown capability neural networks understand semantics generate realistic images reed explored challenging problem text image synthesis using gans. separately train text embedding gans generate images. recent work improved text-to-image generation stackgan example focuses orthogonal aspect problem fact combined approach.unlike works ﬁne-grained labels making method scalable. voxel generation. common approaches voxel generation using deep learning rely losses voxel-wise cross entropy gans also used generate shape voxelizations noise shape inputs framework builds upon gans performs colored voxel generation freeform text uses wasserstein formulation tulsiani explored related task image colored voxel generation knowledge ﬁrst address text colored voxel generation. address problem learning joint representations freeform text descriptions shapes train evaluate methods task introduce datasets dataset human-designed objects shapenet augmented natural language descriptions controlled procedurally generated dataset geometric primitives base fig. proposed voxel text datasets. left procedurally generated primitives dataset associated generated text descriptions. right voxelizations shapenet models natural language descriptions. word vocabulary maximum number voxels along single dimension number channels voxel shapenet objects natural language descriptions. create realistic dataset real objects natural language descriptions shapenet table chair object categories shapes created human designers accurately represent real objects. choose table chair categories contain many instances ﬁne-grained attribute variations geometry color material. augment shape dataset natural language descriptions provided people amazon mechanical turk crowdsourcing platform produce color voxelizations meshes using hybrid view-based surface sampling method followed downsampling low-pass ﬁlter voxel space. process collecting natural language descriptions algorithm producing color voxelizations overall dataset construction described detail appendix large-scale dataset provides many challenging natural language descriptions paired realistic shapes. primitive shapes. enable systematic quantitative evaluation model create dataset geometric primitives corresponding text descriptions. data generated voxelizing types primitives color variations size variations. color size variations subjected random perturbations generating samples possible primitive conﬁgurations thus creating voxelized shapes. create corresponding text descriptions template-based approach ﬁlls attribute words shape size color several orderings produce sentences large cylinder narrow tall total generate descriptions average descriptions primitive conﬁguration. synthetic text match natural language allow easy benchmark clear mapping attributes primitive shape. fig. overview joint representation learning approach. text shape encoders compute embeddings instances modality make round trips back similar instances modality establishing cross-modal associations metric learning similarities computed within across modalities embeddings belonging class pushed together embeddings diﬀerent classes pushed apart would like joint embedding cluster similar text together similar shapes together keep text descriptions close associated shape instance iii) separate text shapes similar. address generalize learning association approach handle multiple modalities instance-level associations description shape using text-shape-text round trips establish implicit connections separate text shape instances semantically similar enforce properties iii) embedding space jointly optimize association learning objective metric learning combined multimodal association model anchors text associated shape instances allowing latent similarities diﬀerent shapes text emerge. generalize same-modal data association approach haeusser learn cross-modal text-to-shape associations suppose given batch shapes descriptions potentially multiple descriptions shape. shown fig. shape text description passed shape text encoder producing shape embeddings text embeddings representing individual shape text embedding. compute embeddings used structure similar reed text encoder d-cnn shape encoder. rows corresponding matrices. convert probability description associating shape similarly pass softmax layer compute probability associating shape description replacing round-trip probability associating description certain shapes associating shapes description then abbreviate text-shape-text round trip dashed box). given description goal uniform descriptions similar description thus deﬁne roundtrip loss cross-entropy distribution target associate text descriptions possible matching shapes also impose loss probability associating shape description maximize entropy distribution using visit entropy loss uniform distribution shapes. thus cross-modal association loss approach described sec. relies ﬁne-grained category-level classiﬁcation labels text description ﬁne-grained annotations expensive obtain necessarily well-deﬁned shapes shapenet descriptions contain multiple colors materials. thus extend approach work without ﬁne-grained category-level annotations making method scalable practical. assume shape belongs instance-level class containing corresponding descriptions. instance-level labels appropriate association learning approach since explicitly separate descriptions shapes labeled correspond other. thus crossmodal association learning relaxed previous approaches direct supervision cross-modal relationships allowing learn cross-modal associations descriptions shapes labeled correspond moreover extend association learning approach additional round trips shown fig. experiments show greatly improves performance model multimodal problem. addition enforcing loss text-shape-text round trip impose shape-text-shape facilitate learning cross-modal associations impose metric learning losses. serves bootstrapping method improves cross-modal associations signiﬁcantly compared using either association learning metric learning alone. approach cluster similar text descriptions together separate dissimilar text descriptions. extend cross-modal similarities deﬁne cross-modal constraints anchors modality note embeddings restricted unit norm since make optimization diﬃcult avoid degeneracy variation approach used sohn regularize norm embedding vectors exceed certain threshold. apply joint representation learning approach text-to-shape generation using generative adversarial networks. model comprised three main components text encoder generator critic. text encoder maps text latent representations. latent vectors concatenated noise vector passed generator constructs output shapes. lastly critic determines realistic generated outputs look closely match corresponding text descriptions. details architecture appendix gans ideal text-to-shape generation encourage model generate outputs correct properties avoiding per-voxel constraints. crucial description able generate diﬀerent shapes capture speciﬁed attributes. penalizing model generating shapes capture correct attributes match speciﬁc model instance would incorrect. thus conditional plays role text-to-shape framework. formulation based wasserstein improves output diversity avoiding mode collapse issues traditional gans. knowledge present ﬁrst conditional wasserstein gan. rather using traditional conditional approach sample batches matching mismatching text descriptions shapes line reed particular sample matching text-shape pairs mismatching textshape pairs text generator marginal distribution critic evaluates realistic shapes look also well correspond descriptions. thus objective following critic generator pmat pmis matching textshape mismatching text-shape pairs respectively. enforcing gradient penalty rather sampling along straight lines guljarani randomly choose samples real distribution pmat generated fake voxelizations. note refers text embeddings concatenated randomly sampled noise vectors. evaluate learned joint representation retrieval generation experiments. sec. quantitatively evaluate representations primitives dataset text-to-shape retrieval show qualitative results shapenet dataset. sec. compare text-to-shape generation results baselines. lastly visualize diﬀerent dimensions learned embeddings show generation results using vector arithmetic sec. create train/val/test splits random subsets %/%/% primitives shapenet objects datasets. tokenize lemmatize input text using spacy experiments described here present results test split. code data pretrained models published http//textshape.stanford.edu/. would like retrieved shapes closely correspond query sentence. here show results text-to-shape retrieval task. additional experiments text-to-text shape-to-shape shape-to-text retrieval appendix goal experiments verify method produces reasonable embeddings cluster semantically similar descriptions shapes using text-shape instance-level correspondences. primitives dataset constructed shape-color-size conﬁguration single class text describing class others. admits quantitative retrieval evaluation goal retrieve descriptions shapes belonging conﬁguration. shapenet dataset possible description could apply multiple shapes ground truth association shape. thus show quantitative results retrieval task primitives dataset qualitative results shapenet dataset quantitative qualitative shapenet retrieval results comparing method baselines included appendix compare model deep symmetric structured joint embedding reed original formulation learning association round trips also decompose full model following association learning round trips metric learning only combined round trip full combined model multimodal denotes using losses. measure retrieval performance using normalized discounted cumulative gain commonly used information retrieval metric recall rate considers retrieval successful least sample retrievals correct class. table shows full model achieves best performance. ds-sje method requires pre-trained model works well directly optimizes objective. association learning–only approach additional round trips performs signiﬁcantly better largely simplistic nature primitives dataset. found shapenet dataset lba-mm model struggled learn joint embedding space text shapes full model performs best primitives shapenet dataset. fig. shows retrieved shapes generally match query sentence. examples show encoders cluster together similar descriptions similar shapes despite fact retrieved neighbors come diﬀerent instances. learned joint representation used shape synthesis? answer question apply learned embedding novel task text-to-shape generation. compare representation learning wasserstein approach gan-int-cls text-to-image synthesis method uses ds-sje coarse chair/table labels learning embeddings. also compare using joint embeddings conjunction gan-cls abbreviate cgan since variant conditional introduce following metrics quantitative evaluation generated shapes occupancy iou. mean intersection-over-union generated voxels ground truth shape voxels indicating quality occupancy generated shapes regardless color. threshold outputs occupied probability models similar shapes likely higher dissimilar models. realism inception score. train chair/table shape classiﬁer compute inception score quantify realistic outputs look. color earth mover’s distance metric measures well generated colors match ground truth. downsample voxel colors space compute earth mover’s distance ground truth generated hue/saturation distributions using ground distance. occupied voxels used computing color distributions. color/occupancy classiﬁcation accuracy. accuracy whether generated shape class matches ground truth based shape classiﬁer. table shows cgan model trained embedding outperforms gan-int-cls metrics. cwgan model improves metrics except class accuracy. qualitatively fig. shows ganint-cls text-to-image synthesis method struggles generate color occupancy distributions correspond text. largely attributed poor embeddings learned using coarse chair/table labels. cgan achieves comparable conditioning generation results without relying additional class labels still signiﬁcant structural color artifacts. lastly cwgan generates realistic shapes natural color distributions better conditioning text compared baselines. example correctly generate chair padding seat backrest fig. likewise table multiple layers desired. however room improvement table fully supported legs circular table erratic coloring. fig. example text-to-shape generations. cwgan approach correctly conditioned input text generating shapes match described attributes. baseline approach struggles generate plausible shapes. additional results found supplementary material. manipulating shape attributes text. demonstrate method learns embeddings connect natural language shape attributes. fig. shows output tables chairs change reﬂect diﬀerent attributes input descriptions. vary description white instead wooden rectangular instead round outputs change color shape respectively. note enforce consistency outputs; result independently generated. however changing single attribute often results small changes attributes. analysis learned representation activation visualization. visualize representations learned model demonstrate capture shape attributes. using text shape encoders compute embeddings shapenet test objects show individual dimensions representation correlate semantic attributes category color shape. fig. visualizing learned representations. examples visualizes activation speciﬁc dimension darker colors indicating higher values. individual dimensions correlate category shape color dimension sensitive shape category subsequent rows dimensions sensitive physical shape color research direction disentangle representations could enable generating shapes composing attributes. gans evaluated models vector arithmetic show meaningful representation space learned. similarly show vector arithmetic results fig. generator interprets manipulated embeddings produce shapes desired properties. example round expressed subtracting rectangular object round adding existing rectangular shape produces round version shape. moreover also perform arithmetic mixture shape text embeddings. results illustrate learned representation encodes shape attributes structured manner. model implicitly connects descriptions shapes based semantic attributes despite explicit labeling attribute relations shape instances. presented method learning joint embeddings text shapes trained end-to-end using instance-level natural language descriptions shapes. showed learned embeddings enable retrieval text shape modalities outperforming approaches prior work. combined embedding conditional wasserstein formulation task text-to-shape generation. challenging problem approach ﬁrst step. improve quality generated shapes could stronger priors model real-world color distributions leverage bilateral symmetry common physical objects. hope work catalyzes research connecting natural language realistic objects exhibiting rich variations color texture shape detail. acknowledgments. material based upon work supported national science foundation graduate research fellowship program grant opinions ﬁndings conclusions recommendations expressed material author necessarily reﬂect views national science foundation. work supported google intel support technical university munich– institute advanced study funded german excellence initiative european union seventh framework programme grant agreement text encoder architecture. stated main paper architecture. word mapped random trainable vector passed structure outlined table units. layers except last followed relu operator weights regularizer weight shape generation architecture. upsampling fractionally-strided convolutions. layers except last followed relu. last layer followed sigmoid activation function. critic leaky relu activation function leak rate layers except last text embeddings passed -dimension layers concatenated conv output represented concatenation layer table wasserstein critic batch normalization. however batch normalization used non-wasserstein implementations. text-conditional wasserstein gan. text-to-shape generation model illustrated fig. stated main paper using text encoder trained joint representation learning approach text mapped latent space followed concatenation noise. resulting vector passed generator attempts generate plausible shape. shape evaluated critic ﬁnal loss computed. training details. joint representation learning learning association metric learning. association learning sample unique shapes batch matching captions shape. loss embedding norm exceeds threshold every generator iteration. gradient penalty coeﬃcient similar guljarani training baselines used procedure similar update discriminator weights accuracy previous batch note solid resolution voxelizations described appendix represent shape colored voxel grid. training data text description–d voxel shape pairs create paired datasets evaluate method controlled procedurally generated dataset colored geometric primitives real object based shapenet augmented natural language descriptions provided people. arbitrary length vector word indices word index corresponds particular word vocabulary denotes number words description number voxels along largest single dimension number channels voxel grid primitive shape generation. create dataset geometric primitives corresponding text descriptions data generated voxelizing types primitives color variations size variations. color size variations subjected random perturbations generating samples possible primitive conﬁgurations thus creating voxelized shapes. perturbations implemented applying uniformly sampled noise color shape space noise height radius scales shape. sentence templates synthetic dataset. create corresponding text descriptions template-based approach ﬁlls attribute words shape size color several orderings produce sentences large cylinder narrow tall. template patterns generate text variations. example templates {largeness} {tallness} {wideness} {color} {shape} {shape} {largeness} {tallness} {wideness} {color}. variables ﬁlled term applies speciﬁc primitive conﬁguration. total generate descriptions average descriptions primitive conﬁguration. synthetic text match natural language allow easy benchmark clear mapping attributes primitive shape. create realistic dataset real objects natural language descriptions shapenet table chair object categories models created human designers realistically represent real objects. focus object categories explore intra-category variation getting detailed descriptions many object instances. chose table chair categories shapenetcore signiﬁcant variation geometry appearance. fig. user interface collecting natural language descriptions objects crowdsourced workers. worker shown rotating view displayed object asked provide freeform text description appearance object. collecting shape descriptions. collected natural language descriptions people amazon mechanical turk crowdsourcing platform. workers shown animation rendered shapenet object fig. screenshot. experimented using full view object allowed users manipulate camera found much slower users perform task users manipulate view using camera controls decided eﬃcient show pre-rendered rotating view animation. repercussion decision people mentioned fact object rotating descriptions. instructed workers describe appearance object using prompt describe color shape material physical appearance object another person. restriction number words number sentences. many descriptions consisted multiple sentences. understand aspects shape people tend describe sampled text descriptions. based sample descriptions described type object described parts object together color voxelization shapenet models. obtain color voxelizations shapenet mesh models using hybrid surface sampling view-based approach. hybrid approach designed reliably sample surfaces object even occur concavities less likely observed external viewpoints. task computing color voxelizations shapenet models trivial challenging properties mesh representations close coplanar surfaces diﬀerent materials thin structures signiﬁcant variety texture resolution level detail. fig. color voxelization textured chair mesh. left column original mesh slice solid voxelization columns right show unﬁltered ﬁltered versions solid voxelization resolutions low-pass ﬁltering voxel colors downsampling important mitigate aliasing artifacts sampling high frequency patterns chair fabric. perform voxelization resolution downsample lower resolutions pass ﬁlter remove sampling artifacts high frequency color variations textures additionally obtain versions voxelization voxels surfaces interior objects ﬁlled-in represent solid volume. solid voxelization based surface voxelization describe method surface voxelization ﬁrst. surface colored voxelization. obtain surface voxelization ﬁrst render mesh canonical views canonical views orbiting around centroid object. mark surface triangles visible views. perform passes surface point sampling mesh. ﬁrst pass sample surface triangles marked visible whereas second pass sample triangles except triangles assigned material lowest total visibility. pass scheme helps unseen surfaces preventing samples backward facing surfaces usually neutral white gray material. total take million sample points uniformly distributed surface mesh along associated color point. assign higher weight voxels surface normal pointing exterior shape. determining color speciﬁc voxel take samples maximal weight compute color taking median sample space solid colored voxelization. solid color voxelizations obtained ﬁrst performing binary solid voxelization using parity count stabbing methods implemented binvox since internal colors ill-deﬁned choose propagate closest colored voxel uncolored voxel. check quality solid surface voxelizations render resulting voxel grids manually check approximately data. fig. left shows example solid slice interior solid voxelization. pass ﬁltering. sampling colors using method described alone results voxelizations noisy colors shown fig. inaccurate colors aliasing. overcome this low-pass ﬁlter high-resolution prevent color shift element-wise divide ﬁltered voxels pass ﬁltered occupancy mask lastly sample highresolution model desired resolution. fig. shows ﬁltering obtain much smoother voxelizations retaining textures patterns even resolution voxels. experiments resolution solid voxelizations. examples. fig. shows several example shapenet object voxelizations along text description provided crowd worker. shape text descriptions. fig. shows descriptions armchair descriptions succinct text describing detail color pattern parts armchair. descriptions focus different aspects object various terms refer physical attributes. example crescent shaped table fig. ﬁrst column could described t-shaped base connecting legs rather wooden vineshaped decoration base connecting legs. another diﬃcult phenomenon negation. example description blue chair last fig. example color voxelizations variety chair table instances shapenetcore. voxelizations computed resolution downsampled shape example natural language description provided crowdworker. column mentions chair armrests. diversity language used describe object makes challenging dataset. limitations. method voxelization designed handle speciﬁc data properties shapenet meshes. however subject limitations. firstly attempt reproduce transparent surfaces would possible extend approach tracking alpha channel along color assign opacity voxel. extension possible since hybrid surface sampling view-based approach secondly voxel colors capture diﬀuse component account shading illumination. discovered disparity compared pre-rendered mesh animations used collecting natural language descriptions case neutral white light gray colors appeared darker shading. conﬂation ‘white’ ‘gray’ ‘metallic’ natural language descriptions account would either perform light-dependent shading sampled voxel colors render unshaded meshes. finally thin coplanar surfaces diﬀerent colors high frequency detail textures fundamentally challenging capture using ﬁxed resolution voxel sampling scheme. text lowercased tokenized lemmatized using spacy pipeline. since natural language descriptions shapenet many mispellings ﬁrst spell-corrected using languagetool extremely long descriptions tokens discarded frequency representation establishing using remaining terms. shapenet dataset total number unique words dropping frequency words collapsing token left vocabulary size primitives dataset frequency words small vocabulary size table shows overall statistics datasets. note primitives dataset many descriptions shape much smaller language variation structured allow within-modality cross-modality retrieval. within-modality retrieval provide results text-to-text shape-to-shape retrieval query instance retrieve nearest neighbors within query’s modality crossmodality retrieval query modality retrieve other. evaluate text-to-shape shape-to-text retrieval tasks. provide quantitative retrieval results primitives dataset table text-to-text retrieval model able correctly retrieve descriptions corresponding query conﬁguration primitives dataset signiﬁcantly outperforming baselines. moreover association learning alone metric learning alone fail generalize well unseen conﬁgurations test set. however trained jointly signiﬁcant boost performance. lastly original work authors found additional roundtrips boost performance same-modal data. contrary working multimodal data using additional roundtrips model results much higher retrieval performance. similar text-to-text retrieval results model outperforms baselines shape-to-shape text-to-shape retrieval tasks shown table table association learning metric learning alone also underperform ds-sje baseline jointly training methods results best performing model. quantitative shapenet retrieval results shown table since instance-level labels retrieval considered correct retrieved item belongs instance query. words categorize retrieved sentence correct came model query sentence. retrieved sentence oﬀers similar semantic meaning came diﬀerent model retrieval marked incorrect. since numerous descriptions shapes dataset semantically similar labeled absolute numbers entirely capture performance model. however higher quantitative numbers still correlate better performance. report numbers shape-to-shape retrieval since every shape instance-level class. table text-to-text retrieval model outperforms baseline methods alone metric learning alone signiﬁcantly underperform full method moreover utilizing additional round trips brings signiﬁcant improvement compared using round trips performance models still comparable task. moreover full model outperforms baselines text-to-shape retrieval. following subsection give examples retrieval task. given sentence test retrieve nearest sentences. qualitative results model shapenet dataset fig. almost retrieved descriptions come diﬀerent shapes semantically similar. example ﬁrst model learns oval similar circular. second example retrieved descriptions describe chairs last example retrieved descriptions describe glass coﬀee tables. given shape retrieve nearest shapes according learned embedding. show qualitative results shape-to-shape retrieval fig. retrieved neighbors often correspond query style shape. example retrieved neighbors brown armless chair also wooden armless chairs. sofa queried nearest neighbors also sofas. likewise tables retrieved neighbors similar attributes compare model baselines fig. method able perform text-to-text retrieval fairly well performance much worse shape-to-shape retrieval. example chair queried method retrieves tables. similarly ds-sje method perform well either returning chairs share almost similar attributes. however method successfully retrieved chairs look like material color style. provide additional results text-to-shape experiments described main paper. qualitative results shapenet text-to-shape retrieval shown fig. ds-sje method seems return results whenever table caption queried regardless details description. representations learned ds-sje likely capture information attributes. rather capture category information only. method always retrieve shapes correct category method able understand certain details blue glass retrieves shapes indeed match given description. fig. text-to-shape retrieval. shows nearest neighbors text learned embedding match category color shape. compare ds-sje baselines. method return reasonable text-to-shape retrieval results. show generation results fig. fig. general ganint-cls approach struggles properly condition text. example none glass white tables right color. moreover model exhibits mode collapse chairs look tables examples look similar. poor generations primarily quality learned text embeddings also formulation well. representations trained distinguish chair/table categories generator critic hard time learning properly condition input embeddings. cgan method performs better gan-int-cls baseline using joint representation learning approach cgan able properly condition text description generated models usually correct category color. however still mode collapse examples similar looking brown tables examples similar looking chairs. furthermore color distributions look artiﬁcial unsmooth. lastly cwgan produces realistic generations also properly match ground truth terms color category. example example cwgan method produce table white. approaches fail either generating chair generating table wrong color. moreover notice generations cwgan model much higher diversity compared approaches property wasserstein traditional formulation large variations color shape style generated cwgan voxels. results also room improvement. example tables examples rectangular rather square. round table example three legs desk example exactly upside shape. details descriptions hard model capture. thus model able signiﬁcantly outperform baselines still much room improvement future work. lastly provide additional results vector arithmetic text shape embeddings fig. performing simple operations learned representations trained generator produce novel shapes speciﬁc attributes. fig. example text-to-shape generations. cwgan approach correctly conditioned input text generating shapes match described attributes. baseline approach struggles generate plausible shapes. additional results found supplementary material. fig. example text-to-shape generations. cwgan approach correctly conditioned input text generating shapes match described attributes. baseline approach struggles generate plausible shapes. additional results found supplementary material. fig. vector arithmetic joint text-shape embeddings. similar results main paper embeddings admit composition transfer attributes control shape generation.", "year": 2018}