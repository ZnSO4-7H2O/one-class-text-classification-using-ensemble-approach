{"title": "Neural Photo Editing with Introspective Adversarial Networks", "tag": ["cs.LG", "cs.CV", "cs.NE", "stat.ML"], "abstract": "The increasingly photorealistic sample quality of generative image models suggests their feasibility in applications beyond image generation. We present the Neural Photo Editor, an interface that leverages the power of generative neural networks to make large, semantically coherent changes to existing images. To tackle the challenge of achieving accurate reconstructions without loss of feature quality, we introduce the Introspective Adversarial Network, a novel hybridization of the VAE and GAN. Our model efficiently captures long-range dependencies through use of a computational block based on weight-shared dilated convolutions, and improves generalization performance with Orthogonal Regularization, a novel weight regularization method. We validate our contributions on CelebA, SVHN, and CIFAR-100, and produce samples and reconstructions with high visual fidelity.", "text": "increasingly photorealistic sample quality generative image models suggests feasibility applications beyond image generation. present neural photo editor interface leverages power generative neural networks make large semantically coherent changes existing images. tackle challenge achieving accurate reconstructions without loss feature quality introduce introspective adversarial network novel hybridization gan. model efﬁciently captures long-range dependencies computational block based weight-shared dilated convolutions improves generalization performance orthogonal regularization novel weight regularization method. validate contributions celeba svhn cifar- produce samples reconstructions high visual ﬁdelity. editing photos typically involves form manipulating individual pixels achieving desirable results often requires signiﬁcant user expertise. given sufﬁciently powerful image model however user could quickly make large photorealistic changes ease instead interacting model’s controls. recent advances variational autoencoder generative adversarial network shown great promise modeling complex high-dimensional distributions natural images signiﬁcant challenges remain models used general-purpose image editors. vaes probabilistic graphical models learn maximize variational lower bound likelihood data projecting learned latent space reconstructing samples space. gans learn generative model training network \"discriminator\" distinguish real generated data simultaneously training second network \"generator\" transform noise vector samples discriminator cannot distinguish real data. approaches used generate interpolate images operating low-dimensional learned latent space comes beneﬁts drawbacks. vaes stable training dynamics tend produce images discard high-frequency details trained using maximum likelihood. using intermediate activations pre-trained discriminative neural network features comparing reconstructions originals molliﬁes effect requires labels order train discriminative network supervised fashion. contrast gans unstable often oscillatory training dynamics produce images sharp photorealistic features. basic gans lack inference mechanism though techniques train inference network recently developed well hybridization uses vae’s inference network issues arise attempting latent-variable generative model manipulate natural images. first producing acceptable edits requires model able achieve close-to-exact reconstructions inferring latents else model’s output match original image. simultaneously necessitates inference mechanism careful second achieving speciﬁc desired edit requires user able manipulate model’s latent variables interpretable way. typically would require model’s latent space augmented training testing labeled attributes interpolating along latent \"not smiling/smiling\" produces speciﬁc change. fully unsupervised setting however semantically meaningful output features generally controlled entangled latents cannot directly manipulated. paper present neural photo editor interface handles issues enabling user make large coherent changes output unsupervised generative models indirectly manipulating latent vector \"contextual paintbrush.\" applying simple interpolating mask enable exploration existing photos despite reconstruction errors. complementary neural photo editor develop techniques improve common design tradeoffs generative models. model introspective adversarial network hybridization leverages power adversarial objective maintaining vae’s efﬁcient inference mechanism improving upon previous vae/gan hybrids parametric efﬁciency output quality. employ novel convolutional block based dilated convolutions efﬁciently increase network’s receptive ﬁeld orthogonal regularization novel weight regularizer. demonstrate qualitative sampling reconstructing interpolating ability celeba svhn cifar- imagenet quantitatively demonstrate inference capabilities competitive performance semi-supervised svhn classiﬁcation task. quantitative experiments cifar- verify generality dilated convolution blocks orthogonal regularization. present interface shown figure turns coarse user input reﬁned photorealistic image edit indirectly manipulating latent space \"contextual paintbrush.\" idea simple user selects paint brush size color paints output image. instead changing individual pixels interface backpropagates difference local image patch requested color takes gradient descent step latent space minimize difference. step results globally coherent changes semantically meaningful context requested color change. given output image example user image person light skin dark hair widow’s peak painting dark color forehead system automatically hair requested area. similarly user photo person closed-mouth smile user produce toothy grin painting bright white target’s mouth. technique enables exploration samples generated network fails applied directly existing photos relies manipulated image completely controlled latent variables reconstructions usually imperfect. circumvent issue introducing simple masking technique transfers edits reconstruction back original image. original image model’s reconstruction difference modiﬁed reconstruction mask channel-wise mean absolute value smoothed gaussian ﬁlter truncated pointwise mask designed allow changes reconstruction show based magnitude. relaxes accuracy constraints requiring reconstruction feature-aligned rather pixel-perfect modiﬁcations reconstruction applied original image. long reconstruction close enough interpolations smooth plausible system successfully transfer edits. visualization masking technique shown figure method adds minimal computational cost underlying latent space exploration produces convincing changes features including hair color style skin tone facial expression. video interface action available online. complementary neural photo editor introduce introspective adversarial network novel hybridization motivated need image model photorealistic outputs achieves high-quality reconstructions without loss representational power. typically design tradeoff goals related size latent space higher-dimensional latent space tends learn less descriptive features produces higher quality reconstructions. thus seek techniques improve capacity latent space without increasing dimensionality. similar vae/gan decoder network autoencoder generator network instead training separate discriminator network combine encoder discriminator single network. central idea features learned discriminatively trained network tend expressive learned encoder network trained maximum likelihood thus better suited inference. neural photo editor relies high-quality reconstructions inference capacity underlying model critical. accordingly discriminator feature extractor inference subnetwork implemented fully-connected layer ﬁnal convolutional layer discriminator. infer latent values reconstruction sample random values standard normal random image generation using generator network terms weight relative importance loss. λimg leave terms discriminator updated solely using ternary adversarial loss. training step generator produces reconstructions data random samples discriminator observes well reconstructions random samples networks simultaneously updated. compare reconstructions using intermediate activations convolutional layers discriminator mirroring perceptual losses discriminative regularization vae/gan deepsim note feature matching designed operate similar fashion without guidance inference mechanism match latent values particular values using loss complement pixel-wise difference results sharper reconstructions better preserve higher frequency features edges. standard discriminator network trained using implicit label source noting success augmenting discriminator’s objective supervised labels seek additional sources implicit labels hopes achieving similar improvements. ternary loss provides additional source supervision discriminator asking determine sample real generated reconstruction generator’s goal still discriminator assign high \"real\" probability samples reconstructions. thus modify discriminator three output units softmax nonlinearity train minimize categorical cross-entropy term equation indicates discriminator output unit assigned label class. generator trained produce outputs maximize probability label \"real\" assigned discriminator minimizing lgadv posit loss helps maintain balance power early training preventing discriminator learning small subset features distinguish real generated samples reducing range useful features generator learn discriminator. also loss leads higher sample quality perhaps additional source supervision leads discriminator ultimately learning richer feature space. model basic structure dcgan augmented multiscale dilated convolution blocks generator minibatch discrimination discriminator. batch normalization adam networks. code publicly available. propose novel inception-style convolutional block motivated ideas image features naturally occur multiple scales network’s expressivity proportional range functions represent divided total number parameters desire efﬁciently expand network’s receptive ﬁeld. multiscale dilated convolution block applies single ﬁlter multiple dilation factors performs weighted elementwise dilated ﬁlter’s output allowing network simultaneously learn features relevant scales features occur minimal increase parameters. also rapidly expands network’s receptive ﬁeld without requiring increase depth number parameters. dilated convolutions previously successfully applied semantic segmentation similar scheme minus parameter sharing proposed shown figure block parameterized bank ﬁlters applied factors dilation scalars relatively weight output ﬁlter scale. naturally efﬁciently implemented reparameterizing sparsely populated ﬁlterbank displayed figure propose variants standard ﬁlter weights tied base full-rank ﬁlters given sparse layout figure weights tied. selecting standard versus full-rank blocks allows design tradeoff parametric efﬁciency model ﬂexibility. architecture replace hidden layers generator standard blocks using specify blocks base ﬁlter size maximum dilation factor orthogonality desirable quality convnet ﬁlters partially multiplication orthogonal matrix leaves norm original matrix unchanged. property valuable deep recurrent networks repeated matrix multiplication result signals vanishing exploding. note success initializing weights orthogonal matrices posit maintaining orthogonality throughout training also desirable. propose simple weight regularization technique orthogonal regularization encourages weights orthogonal pushing towards nearest orthogonal manifold. augment objective cost architecture builds directly previous vae/gan hybrids difference combination discriminator encoder improve computational parametric efﬁciency well reconstruction accuracy methods bigan provide orthogonal approach inference inference network trained adversarial process. igan neural photo editor turn coarse user input reﬁned outputs generative model methods differ several ways. first focus editing portraits rather objects shoes handbags thus concerned modifying features opposed overall color shape method less well-suited. edit transfer technique follows difference well directly transfer local image changes produced model back onto original image rather estimating mimicking motion color ﬂow. second interface applies user edits step time rather iteratively optimizing output. highlights difference design approaches igan seeks produce outputs best match given user constraints seek allow user guide latent space traversal. finally explicitly tailor model design task hand jointly train inference network test time produce reconstructions single shot. contrast igan trains inference network minimize loss training generator network inference network initial estimate inferred latents iteratively optimized. another related interface reﬁnes simple user input complex textures artistic style transfer related work also circumvents need labeled attributes constructing latent vectors analogy bias-correcting them. qualitatively evaluate celeba svhn cifar- imagenet models implemented theano lasagne samples randomly selected shown figure display visual ﬁdelity typical adversarially trained networks. demonstrates high quality reconstructions previously unseen data shown figure smooth plausible interpolations even drastically different samples. cifar imagenet samples along additional comparisons samples models available appendix. quantitatively demonstrate effectiveness blocks orthogonal regularization cifar- benchmark. using standard data augmentation train -layer densenets epochs annealing learning rate epochs. varying amounts orthogonal regularization modify standard densenet architecture replacing every ﬁlterbank blocks report test error training table addition compare performance using full ﬁlters. noticeable increase performance progressive addition modiﬁcations despite negligible increase number parameters. adding orthogonal regularization improves network’s generalization ability; suspect encourages ﬁlter weights remain close desirable non-zero manifold increasing likelihood available model capacity used preventing magnitude weights overly diminishing. replacing ﬁlters blocks yields additional performance gains; suspect increase expressive power receptive ﬁeld network allowing learn longer-range dependencies ease. also note substituting full-rank blocks -layer densenet improves performance relative increased computational cost coming using larger ﬁlters. evaluating additionally train -layer densenets celeba attribute classiﬁcation task varying amounts orthogonal regularization. plot train validation error training available figure addition orthogonal regularization improves validation error demonstrating utility. editing photos model must produce reconstructions photorealistic featurealigned smooth plausible interpolations outputs. perform ablation study investigate effects proposals employ several metrics evaluate model quality given goals. study progressively modiﬁcations vae/gan baseline train network epochs. reconstruction accuracy pixel-wise distance tend correlate well perceptual similarity. addition pixel-wise distance therefore compare model reconstruction accuracy terms trait reconstruction error. classiﬁcation densenet predict binary attribute vector given image given model’s reconstruction measure percent error. gauging visual quality model’s outputs notoriously difﬁcult inception score recently proposed found correlate positively humanevaluated sample quality. using celeba attribute classiﬁcation network place inception model compare inception score model evaluated random samples. posit metric also indicative interpolation quality high visual quality score large sample population suggests model’s output quality remains high regardless state latent space. results ablation study presented table samples reconstructions conﬁguration available appendix along comparisons fully-trained related models. discriminative experiments progressive addition modiﬁcations results consistent performance improvements across reconstruction metrics inception score. note single largest gains come inclusion blocks suggesting network’s receptive ﬁeld critical aspect network design generative discriminative tasks increased receptive ﬁeld correlating positively reconstruction accuracy sample quality. improvements orthogonal regularization suggest encouraging weights close orthogonal manifold beneﬁcial improving sample reconstruction quality generative neural networks preventing learned weights collapsing undesirable manifold; consistent experience iterating network designs found mode collapse occur less frequently using orthogonal regularization. finally increase sample quality reconstruction accuracy ternary adversarial loss suggests including \"reconstructed\" target discriminator’s objective lead discriminator learning richer feature space. comes along observations training ternary loss observed generator discriminator losses tend balanced training standard binary loss. quantitatively evaluate inference abilities architecture applying semisupervised svhn classiﬁcation task using different procedures. ﬁrst evaluate using procedure training l-svm output layer encoder subnetwork report average test error standard deviation across different svms trained random examples training set. next procedure discriminator outputs distribution object categories additional \"fake\" category total outputs. discriminator trained predict category given labeled data assign \"fake\" label provided data generator assign provided unlabeled real data. modify feature-matching based improved-gan include encoder subnetwork reconstruction losses detailed section include ternary adversarial loss. performance shown table competitive networks evaluated fashions achieving mean classiﬁcation accuracy using svms accuracy using method improved-gan. using svms method tends demonstrate improvement previous methods particularly standard vaes. believe encoder subnetwork based descriptive features therefore better suited discriminating svhn classes. lack improvement using method improved-gan unsurprising architecture change goal discriminator; changes behavior thus indirectly changes generator whose loss slightly modiﬁed feature-matching improved-gan. introduced neural photo editor novel interface exploring learned latent space generative models making speciﬁc semantic changes natural images. interface makes introspective adversarial network hybridization outputs high ﬁdelity samples reconstructions achieves competitive performance semi-supervised classiﬁcation task. makes multiscale dilated convolution blocks orthogonal regularization improvements designed improve model expressivity feature quality convolutional networks. research made possible grants support renishaw edinburgh centre robotics. work presented herein also partially funded european programme beaconing project grant agreement l-c. chen papandreou kokkinos murphy yuille. deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs. arxiv preprint arxiv. goodfellow pouget-abadie jean mehdi bing warde-farley ozair courville bengio. generative adversarial nets. advances neural information processing systems netzer wang coates bissacco a.y. reading digits natural images unsupervised feature learning. nips workshop deep learning unsupervised feature learning volume granada spain russakovsky deng krause satheesh huang karpathy khosla bernstein imagenet large scale visual recognition challenge. international journal computer vision figure samples reconstructions interpolations cifar-. three rows samples bottom three rows reconstructions interpolations. model achieves inception score achieved improved-gan historical averaging. figure samples reconstructions interpolations imagenet. three rows samples bottom three rows reconstructions interpolations. model achieves inception score", "year": 2016}