{"title": "A Visual Embedding for the Unsupervised Extraction of Abstract Semantics", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Vector-space word representations obtained from neural network models have been shown to enable semantic operations based on vector arithmetic. In this paper, we explore the existence of similar information on vector representations of images. For that purpose we define a methodology to obtain large, sparse vector representations of image classes, and generate vectors through the state-of-the-art deep learning architecture GoogLeNet for 20K images obtained from ImageNet. We first evaluate the resultant vector-space semantics through its correlation with WordNet distances, and find vector distances to be strongly correlated with linguistic semantics. We then explore the location of images within the vector space, finding elements close in WordNet to be clustered together, regardless of significant visual variances (e.g. 118 dog types). More surprisingly, we find that the space unsupervisedly separates complex classes without prior knowledge (e.g. living things). Afterwards, we consider vector arithmetics. Although we are unable to obtain meaningful results on this regard, we discuss the various problem we encountered, and how we consider to solve them. Finally, we discuss the impact of our research for cognitive systems, focusing on the role of the architecture being used.", "text": "vector-space word representations obtained neural network models shown enable semantic operations based vector arithmetic. paper explore existence similar information vector representations images. purpose deﬁne methodology obtain large sparse vector representations image classes generate vectors state-of-the-art deep learning architecture googlenet images obtained imagenet. ﬁrst evaluate resultant vector-space semantics correlation wordnet distances vector distances strongly correlated linguistic semantics. explore location images within vector space ﬁnding elements close wordnet clustered together regardless signiﬁcant visual variances surprisingly space unsupervisedly separates complex classes without prior knowledge afterwards consider vector arithmetics. although unable obtain meaningful results regard discuss various problem encountered consider solve them. finally discuss impact research cognitive systems focusing role architecture used. deep learning networks learn representations millions features composing network provides trained deep network exceptionally rich representation language allowing perform detection classiﬁcation remarkable precision. representation language learnt deep networks used straightforwardly tasks like image classiﬁcation. however deep network representations used purposes information coded within feature extracted. vector-space representations. vector-space explored vector arithmetics. approach taken authors syntactic semantic regularities vector representations words. paper extract information neural network models complex domain images. lead work deep networks capable capturing complexity variety information found visual domain. using previously trained network internal features descriptors build vectors features images using trained network. vector-space built analyze semantics contains. results provide insight representations learnt deep network models open applications exploiting deep network representations. word vector representations obtained neural network models found contain syntactic semantic information information extracted arithmetic operations vector-space successfully used tasks machine translation motivation paper explore existence similar information image vector representations could useful generic visual reasoning. image vector representations extracted convolutional neural networks previously explored application image recognition tasks. explored performance features learnt given data recognizing images classes diﬀerent data set. authors found layer network seemed cluster images according high level semantics went further considering utility features image recognition problems ﬁne-grained classiﬁcation attribute selection. works built image vector representations solving image recognition tasks. since layer network optimized discrimination training layer turned eﬀective features available task. however represent abstract visual concepts taught rest layers become useful maximize representativeness instead discriminative power. mid-level layers parameters trained dataset successfully reused recognizing diﬀerent dataset showing relevance learnt models. popular ﬁeld research right within deep learning multimodal systems visual language models integrated. example devise combines skip-gram model trained large corpus trained ilsvrc data. thanks information provided language model devise make reasonable inferences images belonging unknown classes known zero-shot prediction. multimodel system particularly relevant work proposed combining image-sentence embedding long short-term memory. authors show existence regularities perred car. work explore similar regularities without using language model guide purpose build sparse high-dimensional representations image classes trying obtain rich abstractions empower trained labelled images learns visual patterns discriminating labels. deep network millions patterns implemented activation functions within network features. feature within deep network consequently provides signiﬁcant piece visual information description images even maximally relevant discrimination considering feature activation values given image fact looking everything network sees within image learnt training. visual semantics captured neural model thus found features values values represent vector analysis. precision speciﬁcity vector representation bounded quality variety patterns found deep network; networks capable discriminating image classes higher precision provide richer image descriptions. maximize descriptive accuracy detail used googlenet architecture deep ilsvrc visual recognition challenge used pre-trained model available caﬀe deep learning framework trained images imagenet test task discriminating imagenet hierarchy categories. googlenet model composed inception modules. capture output convolution layers modules build vector representation activation values. image trained network diﬀerent layers combined produce million activations expressing presence relevance many diﬀerent visual patterns input image. vector-building process treat composing features independent variables. thus image highdimensional sparse vector representation composed continuous variables. executions described paper performed intel sandybridge-ep -core ram. code used process activation features produce ﬁgures graphs available https//github.com/dariogarcia/tiramisu. experiments images imagenet validation labelled diﬀerent classes including large variety objects animals plants etc. imagenet class mapping diﬀerent wordnet synset concept advantage evaluation process sample images used shown figure obtaining vectors images perform abstraction step build vector representations abstract classes using classes images labelled build image class vector combine speciﬁc image vectors belonging class. result aggregation expect obtain representative values variables class reducing variation found speciﬁc images regarding brightness context scale etc.. number images aggregated class ranges aggregated image figure sample images used experiments obtained imagenet validation set. first images shown labelled class african elephant loxodonta africana second images labelled class acoustic guitar third images labelled ashcan trash garbage wastebin ash-bin ashbin dustbin trash barrel trash bin. class vector size image vector computed arithmetic mean images available class. aggregation process obtain vectors corresponding representations leaf-node categories imagenet hierarchy. alternative aggregation methodologies considered discussed parametrization section. categories imagenet hierarchy correspond diverse entities. simple objects producing weak activations. others complex found rich contexts involving stronger activations. variability magnitude image class vectors aﬀect results similarity metrics since classes less lower activations considered closer classes actually are. second source variability found variable behaviour neurons given location within cnn. typically low-level neurons close input produce frequent stronger activations represent simple patterns easier ﬁnd. hand neurons higher within produce sparse activations specialized role. eliminate impact sources variability perform normalization process image class vector. normalize vector values layer layer guarantees information available visual resolution equally relevant representation image class vector contain amount information. alternative normalization methods including normalization considered discussed parametrization section. image class vector representations built aggregating normalizing activations several images within single vector depicted figure study information contained within resultant vector-space compute image class similarities evaluate consistency information captured proposed embedding space labels represented classes. imagenet labels mapped wordnet concepts thus providing access lexical semantics implemented wordnet. since vector representations supposed capture visual semantics instead signiﬁcant expected. nevertheless wordnet remains source validated knowledge available evaluation. distances among image classes computed wordnet measures typically using hypernym/hyponym lexical taxonomy time compute image class distances vector-space using previously deﬁned methodology. result have every available image class sets similarities respect rest image classes similarities reduced ranking. spearman’s provides measure correlation rankings bounded values close either indicating strong correlation. obtain value every image class comparing lexical visual rankings. considering values image classes obtain distribution correlations indicates level semantic coherency wordnet taxonomy vector-space whole. consider diﬀerent wordnet distances maximize consistency three based path length concepts three corpusbased focused speciﬁcity concept additionally diﬀerent corpus three corpus-based measures brown corpus british national corpus. figure shows distribution correlations vector embedding nine wordnet measures. values mostly found indicating strong correlation ranking elements. results consistent nine wordnet settings; average distributions worse figure histograms spearman’s correlation image class vector similarity computed method nine wordnet similarity measures histogram contains correlation values corresponding correlation every class imagenet dataset. case best case results indicate vector representations contain large amount semantic information also captured wordnet. particularly interesting considering wordnet capture visual semantics color pattern proportion context. several alternative solutions considered vector-building process described methodology section. determine speciﬁc solution appropriate followed evaluation approach previously described. options considered following plied vector whole sub-vector normalizations based layers found vector. considered performance options applied single image vectors aggregation image class vectors aggregations. also considered avoiding normalization step. tested combination parameters evaluating based distribution correlations produced. found best setting arithmetic mean image class normalization layer cosine distance threshold. however imperfect nature evaluation allow deﬁnitely assert setting produces semantically rich vector embedding. instead discuss parameters provided signiﬁcant beneﬁts terms correlation thus recommended future works cause less deﬁnitive eﬀects. aggregation normalization parameters largest impact distribution correlations allowing conﬁdent setting. arithmetic mean clearly outperformed geometric harmonic means normalization layer aggregated image class achieved much higher correlations either whole original image vectors avoiding normalization together. hand distance algorithm particularly activation threshold small impact distribution correlations. parameters choose options seemed maximize correlations diﬀerent choices remain competitive. diﬀerent parameter analyzed layers used build vector representation. previous contributions argue best consider layer activations using image recognition tasks contrary approach methodology uses features layers network goal maximizing representativeness. validate notion certain layers network build embedding space explore correlations wordnet setting. distributions correlations fully comparable measure quality provide formal evaluation previous parameters. however since need provide evidence contrasting previous work regarding layers used decided show mean obtained subset layers. values table taken deﬁnitive evidence. consider using features belonging network features middle features bottom network results indicate correlation achieved middle similar correlation achieved layers. hand correlations achieved considering features bottom layers signiﬁcantly worse still showing correlation. results indicate layers within network contain visual semantics relevant description abstract image classes regardless location. diﬀerences results previous works explained diﬀerences methods goals. previous contributions focused single image representations image recognition tasks. since single images highly variable terms brightness context etc. disperse lower layers representation maybe counterproductive. hand target high-level image class representations much smaller variability thanks aggregation normalization processes analyze semantics captured within deﬁned vector-space perform supervised analysis clusters using wordnet hierarchy ground truth; knowing image classes hyponyms synset explore distribution within embedded space. achieve visual results apply metric multi-dimensional scaling dimensions image classes distance matrix. method builds two-dimensional mapping vector distances respects pairwise original similarities. ﬁrst synsets many hyponyms within imagenet categories wheeled vehicle highlight location image classes belonging sets two-dimensional similarity mapping figure ﬁrst sight sets highlighted images compose deﬁnable clusters. although precision perfect image classes belonging wordnet category clearly assembled together vector-space representation. case dogs relevant wide variety dogs computed visual features common according results visual features common dogs weight vector representation variable features size color proportion. probably caused aggregation normalization process reduces importance within image classes volatile properties. cluster deﬁned wheeled vehicle image classes lower precision dogs probably wheeled vehicles varied dogs nevertheless wheeled vehicle located quadrant graph indicating large reliable features vector representation identifying type image classes. wheeled vehicle located outside middle-left quadrant low-right part figure corresponds snowmobile rather special type wheeled vehicle seems diﬀerent everything. looking figure notice naturally splitting image classes sets. separation consistently sparse area visible ﬁrst sight graph. explain phenomenon explored basic categorization wordnet separating imagenet classes living things deﬁned wordnet living entity rest. painting images belonging living things obtain graph figure graph shows separation found vector-space corresponds simple categorization striking precision unsupervisedly clustering images depending whether depict living things not. mistakes done correspond organisms unique shapes textures things often depicted around living figure scatter plot image class vector similarities built metric multi-dimensional scaling. black circles belong images labelled hyponyms synset domestic canis familiaris dark grey circles belong images labelled hyponyms synset wheeled vehicle. black circles belong images labelled hyponyms synset living thing animate thing. things particular cases rather controversial coral reef living organism according wordnet vectorspace clustered such. encouraged results tried obtain representation vector-space showed separation living organisms rest clarity. purpose tested non-linear mapping distances three dimensions using isomap algorithm features extracted network combined non-linearly obtain class image kind transformation highlight inherent non-linearity vector-space. figure shows evident separation among synsets also complex structure within class images. point assert vector representations capture large amounts high-level semantics. given source deep network provided independent image category labels semantics captured beyond vector space must originate visual features. boundaries semantics captured however hard deﬁne would require state cannot learnt seen images. best notion limits visual semantics provided distinction living things rest. horses salmons eagles lizards mushrooms seem little common visually elements clustered vector-space. structural patterns living things seem therefore particular enough motivate distinction. results open many interesting questions intend address follow-up work. word vector embeddings empower extraction syntactic semantic regularities vector arithmetics regularities explored linguistic context form applications ﬁelds like machine translation image class vector embedding construction process deﬁned methodology section allows consider existence similar regularities within domain images. results evaluation section indicate visual semantics encoded within image class vectors possible operate semantics perform type visual arithmetic reasoning. comparison linguistic context image embedding space build much larger dimensionality data variability. simplify arithmetic process consider simpler relations three operands consider diﬀerent scenarios equations could applied. analyze image classes understood non-overlapped concatenation classes. example could chair plus wheel could produce image classes like oﬃce chair wheelchair. second scenario foresee analyze image classes understood overlapped combination classes. case visual properties mixed classes would need strongly intertwined produce third. example could wolf plus could produce werewolf. exploring image equations described found several limitations prevented obtaining meaningful results. since work process describe limitations here intend solve them hoping researchers beneﬁt experience. ﬁrst problem faced related evaluation image equations since obvious ground truth available. could subjectively propose many diﬀerent equations make visual sense platypus duck beaver turtle shield lizard motorcycle motor bicycle. approach besides hardly scalable since one’s imagination quickly runs easily include human bias implicit consideration non-visual features. nevertheless remains best available evaluation methodology. operator value) make sense visually not. problem approach huge number possible equations computational cost computing all. example using diﬀerent class vectors obtained imagenet dataset compose roughly million diﬀerent substraction operator not). compute single equation needs substract vectors composed million features compute similarity result third vector. computing million therefore problem requiring huge amount computational resources. thus eﬃcient code running parallel high-performance infrastructure must solving problem. another relevant problem caused curse dimensionality. image class vector representations work composed roughly million features. consequently resultant vector space deﬁned million dimensions. high-dimensional space objects highly similar distance measures euclidean distance trouble ﬁnding meaningful diﬀerences. solve issue considering various dimensionality reduction methods well employing distance measures resistant high dimensionality deep learning networks shown appropriate solve speciﬁc component cognitive systems perception. unlike previous models deep networks process huge amounts data ﬁrst learning later identifying abstract patterns characterizing data complex tasks. multiple non-linearities deep learning models solve cognitive problem transforming sub-symbolic data symbolic knowledge; diﬀerence looking seeing. case cnns models mimic animal visual cortex processing images dimensional matrix features. squared sub-parts matrix processed receptive ﬁelds look previously learnt patterns ﬁlters input picture output ﬁlter projected dimensional matrix goal iteratively applying convolution process larger part original input matrix. eventually neurons full input matrix producing data descriptors whole input. current deep architectures include millions ﬁlters distributed among several layers ﬁlters tuned given purpose. design makes cnns humans essence perceiving small visual patterns small visual patches input iteratively aggregating full visual perception obtained. although deep learning apparently solves problem perception deﬁnition large rich representation language models seem limited higher-level purposes related cognition lack symbol operating mechanisms. situation naturally leads solution additional machine learning methods plugged deep learning systems processing representations built achieve high-level cognitive processes. particular architecture follow research representation language learnt obtain speciﬁcation input data empower additional machine learning methods using architecture capable performing high-level cognition concept discovery something cnns cannot ﬁnding clusters entities correspond entities currently impossible overall impact deep learning cognitive systems. however assert least lowest level cognition perception replicated models cnns. combined architecture propose essence behind deep learning success cases deep learning tree search reinforcement learning boardgames video games likely next generation cognitive systems follow architecture well. paper present methodology build vector representations image classes based features originally learnt deep learning network. goal extract visual semantics captured deep network model order make available learning reasoning methods. unlike previous research focus representing abstract classes aggregating normalizing single images belonging concept. consistency methodology allows consider unprecedented amount features diﬀerent elements common semantics variations proportion size color within classes seems dominated essential visual features elements clustered together within embedding space. existence high-level properties supported untaught vector distinction between living organisms non-living things. makes wonder limit learnt visual information straightforward deﬁne visual particularities life. general terms proposed methodology takes large volume pixels translates concepts abstract semantics workﬂow clear implications artiﬁcial cognitive systems tackles problem obtaining symbolic knowledge sub-symbolic data necessary step abstract reasoning real world perception. practice approach extracts high-level knowledge images deep networks making representational power available cognitive purposes. promising architecture cognitive systems. identifying clusters images distinct vector-space ﬁnding distinctive traits classes could used visual learning vector arithmetics could used reasoning artiﬁcial image generation. main follow-up work research goes direction solving problems found applying vector arithmetics exploring deep learning representations outside deep learning. also intend apply work zero-shot prediction task approach would allow tackle completely unsupervised manner. work partially supported joint study agreement ibm/bsc deep learning center agreement spanish government programa severo ochoa spanish ministry science technology tin--p project generalitat catalunya core research evolutional science technology program japan science technology agency", "year": 2015}