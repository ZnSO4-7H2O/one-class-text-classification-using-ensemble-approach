{"title": "Improving Mild Cognitive Impairment Prediction via Reinforcement  Learning and Dialogue Simulation", "tag": ["cs.LG", "cs.CL", "stat.ML"], "abstract": "Mild cognitive impairment (MCI) is a prodromal phase in the progression from normal aging to dementia, especially Alzheimers disease. Even though there is mild cognitive decline in MCI patients, they have normal overall cognition and thus is challenging to distinguish from normal aging. Using transcribed data obtained from recorded conversational interactions between participants and trained interviewers, and applying supervised learning models to these data, a recent clinical trial has shown a promising result in differentiating MCI from normal aging. However, the substantial amount of interactions with medical staff can still incur significant medical care expenses in practice. In this paper, we propose a novel reinforcement learning (RL) framework to train an efficient dialogue agent on existing transcripts from clinical trials. Specifically, the agent is trained to sketch disease-specific lexical probability distribution, and thus to converse in a way that maximizes the diagnosis accuracy and minimizes the number of conversation turns. We evaluate the performance of the proposed reinforcement learning framework on the MCI diagnosis from a real clinical trial. The results show that while using only a few turns of conversation, our framework can significantly outperform state-of-the-art supervised learning approaches.", "text": "introduction progression alzheimer disease consistently heavy area research clinical medicine disease incurable early intervention prodromal phases disease proven delay onset ad-related mental degeneration systemic issues months years consequently much recent clinical research efforts focused detecting early stages mild cognitive impairment prodromal phase progression occurring months years visible mental decline begins successfully detected stage intervention methods confer numerous benefits longevity cognitive physiological health patients brain imaging structural magnetic resonance imaging shown contain prime markers capturing physiologic changes pathological process however identification normal aging particularly challenging fact structural changes brain phase minor hard detect structural even though decline mental status cognitive already begun cases. recently structural connections among brain regions inferred diffusion provided promising predictive performance detection sketching brain networks imaging still remains rather prohibitively expensive difficult scale. moreover high dimensionality brain imaging combined small sample size usually imposes significant challenges learning algorithms leads unstable generalization performance. hand behavior social markers could offer much costeffective option detection recent clinical trial studied differentiating early stage cohort groups using transcripts extensive conversations patients trained interviewers recent preliminary study authors trained supervised learning models lexical distribution conversation showed conversational responses patients take different distribution various conversational topics. success predicting using human dialogue introduced alternative natural language processing approach classically clinically expensive problem. however human interviewers still requires substantial amounts interaction trained staff incur significant expense current form. thus bottleneck questions remain amount conversations needed achieve accurate prediction improve upon baseline performance given limited cohort-specific data? abstract mild cognitive impairment prodromal phase progression normal aging dementia especially alzheimer’s disease even though mild cognitive declines patients normal overall cognition thus challenging distinguish normal aging. using transcribed data obtained recorded conversational interactions participants trained interviewers applying supervised learning models data recent clinical trial shown promising result differentiating normal aging. however substantial amount interactions medical staff still incur significant medical care expenses practice. paper propose novel reinforcement learning framework train efficient dialogue agent existing transcripts clinical trials. specifically agent trained sketch disease-specific lexical probability distribution thus converse maximizes diagnosis accuracy minimizes number conversation turns. evaluate performance proposed framework diagnosis real clinical trial. results show using turns conversation framework significantly outperform state-of-the-art supervised learning approaches. reference format fengyi tang kaixiang ikechukwu uchendu hiroko dodge jiayu zhou. improving mild cognitive impairment prediction reinforcement learning dialogue simulation. proceedings conference london pages. https//doi.org/. /nnnnnnn.nnnnnnn permission make digital hard copies part work personal classroom granted without provided copies made distributed profit commercial advantage copies bear notice full citation first page. copyrights components work owned others must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior specific permission and/or fee. request permissions permissionsacm.org. conference’ london association computing machinery. isbn -x-xxxx-xxxx-x/yy/mm.... https//doi.org/./nnnnnnn.nnnnnnn address aforementioned questions above paper propose novel reinforcement learning framework learns diagnosis agent using limited amount offline human dialogue transcripts. learned diagnosis agent conduct subject-specific conversation humans asking questions based existing conversations efficiently sketch lexical distribution give high-performance prediction. order facilitate using offline transcripts introduce dialogue simulator pipeline generates conversational episodes less noisy out-perform original corpus prediction. dialogue pipeline provides self-contained framework directing dialogue generation diagnostic screening potentially replace need human-expert interviews. rl-agent learns optimal dialogue strategies adaptive unseen users enabling medically-relevant data generated large scale deployed realistic setting. furthermore data generated dialogue simulations used data augmentation perhaps guide medical data collection process future. ultimately greatly decreasing cost data collection amount needed high-level performance introduce clinical direction much cost-effective scalable large-scale diagnostic screening data collection. combination features reinforcement learning framework extend process diagnostic screenings well beyond confines hospitals primary care facilities. related work prediction utterance data. used classical supervised learning framework formulate prediction binary classification problem. interview corpus constructed using participant responses interviewer questions. participant response corpus several interviews preprocessed feature vectors using linguistic inquiry word count dictionary liwc dictionary transforms word given corpus -dimensional feature vector latent dimensions representing grammatical semantic properties word. final -dimensional feature vector constructed corpus aggregation previous liwc vectors. resulting feature representation matrix. best performing classifier benchmark study uses linear support vector machines ℓ-norm regularization resulting performance -fold validation. dialogue systems. dialogue systems provide natural humancomputer interface active research field decades. task-oriented dialogue systems typically designed retrievaltasks users provide queries chat-bot provides appropriate responses based external knowledge base identifying correct answers looking vast amounts documents dialogue systems typically designed pipeline containing components including language understanding unit parses intention semantics input humans dialogue manager manages dialogue state tracking policy learning language generation unit generates response components handcrafted trained individually recent advances deep figure overview proposed methodology. complete conversation participants used build user simulators. simulators used train diagnosis agent conducts minimal turns conversation participants sketches lexical distribution used perform classification. learning allows end-to-end training significantly improves performance capability adapt domains end-to-end systems trained using supervised learning reinforcement learning leveraging user simulator main advantage less training samples needed learn high-degree-of-freedom deep models. work design simulator enable limited amount clinical data available supervised training. note even though dialogue system also tries achieve task nature system radically different existing task-oriented dialogue systems goal efficiently sketch disease specific lexical distribution asking subject-specific questions give classification results. healthcare applications dialogue systems. dialogue systems widely adopted healthcare domain various applications. example chat-bots available assist patient intake process retrieve restaurant accommodation information young adults food allergies perform dialogue analysis generation conversation perform mental health treatment context alzheimer’s disease research designed virtual reality based chat-bot evaluate memory loss using predefined questions answers. discussed applications chat-bots caregiviers alzheimer’s patients providing safety personal assistance entertainment stimulation. recently introduced computer avatar list pre-defined questions neuropsychological tests diagnose dementia. work closely related system utilizes dialogue glean disease-related information. however major issue approach questions obtained mini-mental state examination confirmatory measure used define clinical dementia rather diagnostic tool predict clinical meaningful identify diagnostic markers associated pathological pathways lexical distribution associated cognitive changes purpose diagnostic screening. methodology framework propose paper involves reinforcement learning learn optimal questions participants purposes distinguishing mci. test generate episodes questions prediction rather original corpus. actualize dialogue simulation framework proposed multi-step approach implementation capitalizes vast existing knowledge research. following section present details component dialogue system. figure shows overview components experimental pipeline. overview pipeline proposed framework contains three learning modules user simulator classifier rl-agent. proposed pipeline illustrated figure first user simulator trained unsupervised learning simulates distributed representation user responses given feasible question inputs. next classifier predicts patient label based averaged distributed representation corpus responses. components dialogue manager comprise training environment rl-agent. dialogue manager utilizes user simulator classifier handle state transitions also computes reward based ground-truth labels training classifier prediction. training environment rl-agent able deliver optimal sequences questions training-set users various stages conversations. testing rl-agent produces query inputs test-set user simulators represent unseen users. using queries user simulators generate corresponding distributed representation test-set user responses prediction. following subsections present component pipeline detail demonstrate effectiveness framework improving prediction accuracy reducing conversational turns. construction turn-based dialogue since utterance data collected form conversational transcripts participant must reconstructed turn-based dialogue participant-responses. participant responses unstructured interviewer questions ranged preset question topics illustrated below. interviewer yesterday? participant yesterday morning yesterday busy forgetting went morning. well went albertsons yesterday... interviewer picture? participant picture gosh. looks like uncle lou. never interviewer think picture taken? participant picture probably eighteen seventy something nineteen twenty. looks must total well possible queries interviewers. however purposes study re-compiled question list general questions ubiquitous across conversations. snapshot questions table picture-related tech occupation hobbies family pets confirmation clarification goodbye unspecified comments. comments delexicalised certain topic words <activity> <social topic> order control domain expansion reduce model complexity user simulators. past shown effectiveness delexicalisation controlling domain expansion user simulators without sacrificing contextual meaning sentence queries. additionally also created unspecified comments category included comments deviated general question prompts. comments often result interviewer follow-up specific topics mentioned user. consolidated comments single category distinguish context-specific general questions based corpus. however demarcate type unspecified comment used interviewer. example follow-up comment occupational story tagged <unspecified occupational comment> whereas follow-up comment health concern tagged <unspecified health comment>. role comments serve build rapport improve flow conversation. future studies look generate user-specific grounding statements slots implemented corpus tokenized turn-based responses questions user. unsupervised learning user simulator effectively capture contextual representation user conversation style utilize vector embedding user corpus sentence-level representation given want capture flow conversation response next implement skip-thought embedding shown effectiveness large corporal datasets capturing contextual information sentences given neighboring ones encoding sentences model pretrained bookcorpus dataset contains turn-based conversations various english novels decoder train skip-thought vectors recover original response user portion pipeline. since user individual response styles questions train personalized user-simulator user. user conversation corpus divided question-response turns. dataset example number turns conversation ranged turns. used multilayer perceptron hidden layers output nodes train user simulator. also introduce regularization ℓ-norm penalty constrain model complexity. utilize preset questions interviewer one-hot encoding questions denoted generate observations. here uses classifier predict probabilities classes based current moving-average skip-thought vectors turn predict label current user episode reward calculation. result also used agent part internal state-representation. result used credit assignment generated conversational episode. classifier trained separately training corpus dialogue system phase. action rl-agent chooses actions discrete actions consisting predefined questions question represented vector worth noting differentiate action taken rl-agent questions asked actual interviews respectively. state state representation rl-agent used approximate action-value function. five main components state representation vector skip-thought vector utterance current turn output vector user simulator given action turn moving average skip-thought vectors across utterances current episode first hidden layer weights user-simulator predicted probability current user classes number turns threshold total dimension state vector |wi| turn queries classifier output probability vector composed denotes denotes mci. dimensional vector keeps track classifier's confidence-level prediction based current moving-average skipthought vectors generated turns. keeping track classifier confidence incentivizes rl-agent terminate conversation soon reaches threshold level confidence prediction task. reward since want minimize number dialogue turns designed environment output negative reward every time step unless reach terminal state terminal state reward depends classification using averaged skip-thought vector collected episodes. existing classifier able make correct prediction agent receives positive reward otherwise receives moderately negative reward also input training. given original skip-thought user simulator serves function maps vector output skipthought embedding representation utterance denoted irc. here denotes size question dictionary denotes dimension skip-thought embeddings parameterizes model given user denotes user index denotes turn number. loss function given meansquared error output original skip-thought vector case questions preset state-of-art methods end-to-end recurrent neural network systems deployed train user simulator instead evaluate performance user simulator computed mean squared error outputs simulator original thought vector representation user response turn. reinforcement learning components again denote size skip-thought embeddings denote size question dictionary. formulate dialogue task managers portions dialogue system standard setting agent interacts environment finite number steps. time step agent receives state samples action based current policy environment transitions next state agent receives scalar reward setting rl-agent tries learn optimal policy possible states including ones unseen agent training. this agent learn approximate action-value function maps state-action pairs expected future rewards formally action-value function defined follows discount factor turns. environment environment case consists dialogue manager user simulator classifier. composed reward state generating functions. previous works task manager composed database query manager used generate observations retrieval tasks. case however user simulator classifier equivalent task manager used policy-masking. challenge problem creating environment train agent produce responses best align flow conversations. example agent learn question elaborate that? useful generating wide distribution words user would make sense include first sentence conversation relevant topics introduced. achieve this created policy-modifying function confirmation clarification type questions masked policy turn action history agent include questions social activity tech picture-related hobbies occupation travel entertainment family categories. turn keep track action history vector construct policy-masking vector applied elementwise agent's q-value output. specifically denotes j-th element policy-masking vector represents action values available actions given current state valid action values vector policy masking. achieve effective masking assure elements positive using relu activation function output layer q-network step pre-training q-network described following section. training rl-agent outline training procedure rl-agent. expedite learning process first train rl-agent original corpus training set. user perform initial pass entire corpus using existing action history generate episodes ...at corpus-generated episodes train q-estimator network. initialization procedure motivated previous studies cited effectiveness pre-training successful episodes rl-agent discover large terminal reward signals games delayed rewards minibatch generation transfer weights learning q-network every conversational episodes. testing rl-agent generate actions test user ...ai episodes generated user simulator action prediction. simulated episodes often differ original corpus questions asked agent well skip-thought responses user. experiments evaluation dialogue systems differ widely depending task. previous works typically involve using metrics perplexity averaged reward response measure quality natural language generation phase dialogue system however utility framework comes quality questions chat-bot generates offconversational task propose framework evaluation emphasizes agent’s off-conversation performance. gauge maximum length episodes additionally added linearly increasing penalty passing turn classifier predicts probability either class denote penalty threshold number turns confidence threshold formally reward function defined given policy probability environment transitioning state depends current state internally utilizes user simulator generate skip-thought users. addition state transitions within episodes state-generating function changes users leading different transition probabilities similar states among different users. capture this apply changes training rl-agent multiple users first hidden layer weights user incorporated state representation vector rl-agent distinguish dissimilar users. used user simulator provides means rl-agent learn similar policies similar users dissimilar policies dissimilar users. training user simulator classifier training environment reset users re-initializing user simulator weights correspond user. deep q-networks work action value function needs estimate expected reward based high-dimensional state representations described previous section. order approximate action value given different users complicated internal state changing conversation learn deep q-network parameterized tackle challenging problem. learning procedure conducted optimizing loss function follows denotes parameters target q-network. order learn estimator complex situations ingredients proposed experience replay fixed target q-network. training q-network updated online fashion conducting gradient descent target q-network fixed compute target values updated certain number iterations essential convergence q-network work. also observe experience replay samples minibatch previous experiences update q-network training performance stabilizes consistently. obtain policy mask probability select random action otherwise select maxa execute action observe reward state store transition sample random minibatch terminal utility dialogue system ability improve prediction accuracy baseline techniques number turns needed make accurate prediction. data. data used study obtained randomized controlled behavioral clinical trial ascertain effect unstructured conversation cognitive functions. details study protocol explained clinical study conversational data collected format participant webcam interviews trained interviewers. participant interviewed multiple times course weeks dialogue responses transcribed interview session average conversational episodes participant conversation lasted minutes labels generated using clinical assessment participant's cognitive status medical professionals baselines performance. first compare performance several baseline classifiers prediction task. specific dataset previously achieved benchmark performance score -fold validation using linear ℓ-norm penalty feature engineering linguistic inquiry word count dictionary liwc embeds word -dimensional word vector space dimension representing latent feature english language since various contextual representations words sentences proposed many outperformed classical rule-based contexual embedding techniques distributed representation wordvec allows flexible corpus-dependent latent features created individual words recently skip-thought vectors risen popularity ability embed entire sentences \"thought vectors\" capture contextual meaning syntactic information neighboring sentences. reason compare various here denotes sparse logistic regression classifier denotes random forest classifier denotes support vector machines denotes multi-layer perceptron. feature representation corpus represents distribution word counts. denotes averaged -dimension wordvec embeddings across words appearing corpus user liwc denotes original rulebased embedding used denote averaged -dimension skip-thought vectors across turn-based responses user first four sections table show performance baseline classifiers. using original liwc representation able recover close baseline original paper using classifiers. implementing skipthought embedding used pre-trained skip-thought encoders embed user response across conversational turns. encoder pre-trained bookcorpus dataset large collection novels pertaining numerous literary genres. advantage pre-training dataset bookcorpus contains abundant number turn-based dialogues various character types. conversations capture wide range conversational response styles idiosyncrasies temperaments. seen table best performing baseline model classifier norm using skip-thought embedding features. reason choose classifier portion pipeline. baseline reference also included performance using word count distributions models. evaluate performance rl-agent across stratified shuffle splits. split uses data training testing. compare performance rl-agent manually restricting number questions restricting number turns observe number questions needed recover original baseline performance using classifier. constraint conditions performance rl-agent started surpass baseline performances starting questions able achieve comparable performance using questions. full conversation length turns able achieve improvement upon current previous baselines. comparison mean number conversational turns user original corpus additionally since conversations conducted user adjusted number turns allowed based mean number turns conversation user. reason upper bound constraint questions slightly less full conversation user. figure visualizes relationship performance number questions asked rl-agent. performance improvements additional questions saturate questions. expected highest-yield questions discovered rl-agent asked first test conversations. evaluation user simulators. user simulators serve pivotal role simulating user response training environment previous works user simulators evaluated based accuracy generated user query unseen responses metrics bleu perplexity used phase dialogue generation user query pivotal retrieval-type training systems. case however goal user simulator quite different; rl-agent responsible generating queries output user simulator actually encoded thought-vector user response used state representation downstream prediction purposes. reason evaluate performance user-simulator decoding portion dialogue system rather performance user-simulator generating accurate thought-vector version responses. resulting scores averaged across turns conversation. given user average conversations evaluate performance user simulator leave-one-out fashion user simulator trained conversations except last used evaluation. figure visualizes performance user simulators. mean .±.e- averaged across test performances. top-performing policies. interesting note simulated episodes rl-agent able provide performance boost prediction task. section look qualitatively types questions turns rl-agent comparison original corpus. also compare performance performance using first responses original corpus. again note responses greeting parting queries goodbye counted toward prediction. shown table optimal policy learned framework outperformed original corpus turn constraint. example rl-agent asked questions test users classifier able achieve using simulated response. contrast using first questions original corpus test user produced using first full-length conversation turns original corpus recovers score performance table rank frequently appearing questions effective question appears when start working. context problem question seems generate polarizing responses cohort. also rl-agent included elaboration questions what like <activity> that users expand upon previous responses. clinical perspective also interesting note rl-agent picks questions what yesterday long similar questions used clinically assess immediate recall patients seen occupational questions popular topic asked rl-agent. also case rl-agent follows previous query elaboration question regarding past occupational experiences. interesting note rl-agent transitions picturerelated questions often used clinical interviewers facilitate creative responses participants also observe rl-agent asking questions <unspecified tech comment> when <tech problem> start. frequently asked questions course original dialogue technical difficulties often encountered connection webcam issues interviews unfortunately responses vary greatly times generate verbose responses participants. rl-agent seem able recognize caveat training. approach questions arrive midlatedialogue conversations. overall observe widespread topics portion conversation. polarizing question asked stage what opinion <social topic>? here used delexicalised slots <social topic> reduce model complexity slots substituted wide range social topics political trends recent news. additionally observe rl-agent learns goodbye terminate conversation early numerous cases. mentioned previously designed state function include predicted probability classifier time-step. environment penalizes agent additional turns prediction probability exceeds either class. opting terminate episode rl-agent learns avoid dragging dialogue unnecessarily cases confident prediction. notable question many people think this? actually picture-specific question related provocative pictures. fact confirmed original corpus generated follow-up response users compared picture-related questions when think picture taken? interesting makes that?. ranking question highly rl-agent indirectly prioritizes picture others generating user responses. exemplifies ranking questions used direct future data collection process. approaching conversations notice questions asked agent spread-out among remaining choices. reason rank questions final turns simulated conversations. latter portion note rl-agent utilized elaboration questions what like often activity>. also technology-related questions what opinion using <new tech> included often compared topics occupation social items. indicates tech-related questions high-yield distinguishing responses questions prioritized later conversation rl-agent. discussion conclusion paper introduce framework approaching classically supervised learning problem clinical medicine data often noisy scarce prohibitively expensive obtain. show properly trained framework greatly amount data needed make accurate predictions synthesize relevant data improve performance. achieve framework proposed multi-step approach capitalizes vast existing knowledge human language research. first used state-of-art distributed representation preprocess data. simulation environment reinforcement learning using supervised learning create customized user simulators. lastly utilize trained rl-agent generate questions obtain targeted responses prediction task. careful examination optimal policies discovered agent demonstrates overall framework self-contained directing dialogue generation diagnostic screening potentially replace need trained interviewers. trained rl-agent able discover relevant questions users agent prior experience interaction. also show various clinical insights could deduced observing ranking questions various turn constraints. order framework effectively deployed realistic setting user-simulator could trained online real-time considered. current form usersimulators trained offline scalable larger corpus user volumes. additionally natural language generator phase needed make questions adaptable references charles anderson minwoo daniel elliott. faster reinforcement learning pretraining deep networks predict state dynamics. ijcnn. ieee meysam asgari jeffrey kaye hiroko dodge. predicting mild cognitive impairment spontaneous spoken utterances. alzheimer’s dementia translational research clinical interventions robert chapman mark mapstone john mccrary margaret gardner anton porsteinsson tiffany sandoval maria guillily elizabeth degrush lindsey reilly. predicting conversion mild cognitive impairment alzheimer’s disease using neuropsychological tests multivariate methods. journal clinical experimental neuropsychology bhuwan dhingra lihong xiujun jianfeng yun-nung chen faisal ahmed deng. end-to-end reinforcement learning dialogue agents information access. arxiv preprint arxiv. carol dillon cecilia serrano diego castro patricio perez leguizamón silvina heisecke fernando taragano. behavioral symptoms related cognitive impairment. neuropsychiatric disease treatment hiroko dodge jian nora mattek molly bowman oscar ybarra katherine wild david loewenstein jeffrey kaye. web-enabled conversational interactions method improve cognitive functions results -week randomized controlled trial. alzheimer’s dementia translational research clinical interventions marshal folstein susan folstein paul mchugh. âăĳmini-mental stateâăi̇ practical method grading cognitive state patients clinician. journal psychiatric research serge gauthier barry reisberg michael zaudig ronald petersen karen ritchie karl broich sylvie belleville henry brodaty david bennett howard chertkow mild cognitive impairment. lancet hiroko dodge nora mattek mattie gregor molly bowman adriana seelye oscar ybarra meysam asgari jeffrey kaye. social markers mild cognitive impairment proportion word counts free conversational speech. current alzheimer research yajuan shiqi zhao xinyan xiao yuan yizhong wang qiaoqiao xuan dureader chinese machine reading comprehension dataset real-world applications. arxiv preprint arxiv. heister james brewer sebastian magda blennow linda mcevoy alzheimer’s disease neuroimaging initiative predicting outcome clinically available biomarkers. neurology matthew henderson blaise thomson steve young. robust dialog state tracking using delexicalised recurrent neural networks unsupervised adaptation. slt. ieee ryan kiros yukun ruslan salakhutdinov richard zemel raquel urtasun antonio torralba sanja fidler. skip-thought vectors. advances neural information processing systems. xuijun yun-nung chen lihong jianfeng gao. end-to-end task-completion neural dialogue systems. arxiv preprint arxiv. xiujun zachary lipton bhuwan dhingra lihong jianfeng yun-nung chen. user simulator task-completion dialogues. arxiv preprint arxiv. bing lane. end-to-end trainable neural network model belief tracking task-oriented dialog. arxiv preprint arxiv. tomas mikolov ilya sutskever chen greg corrado jeff dean. distributed representations words phrases compositionality. advances neural information processing systems. volodymyr mnih koray kavukcuoglu david silver andrei rusu joel veness marc bellemare alex graves martin riedmiller andreas fidjeland georg ostrovski human-level control deep reinforcement learning. nature juan manuel fernandez montenegro vasileios argyriou. cognitive evaluation diagnosis alzheimer’s disease based turing test virtual environments. physiology behavior kyo-joong dongkun byungsoo ho-jin choi. chatbot psychiatric counseling mental healthcare service based emotional dialogue analysis sentence generation. mdm. ieee olazaran rubén muñiz reisberg peña-casanova cruz-jentoft serrano navarro garcía rocha frank benefits cognitive-motor intervention mild moderate alzheimer disease. neurology miguel salichs irene encinar esther salichs álvaro castro-gonzález maría malfaz. study scenarios technical requirements social assistive robot alzheimerâăźs disease patients caregivers. international journal social robotics jost schatzmann karl weilhammer matt stuttle steve young. survey statistical user simulation techniques reinforcement-learning dialogue management strategies. knowledge eng. rev. satinder singh diane litman michael kearns marilyn walker. optimizing dialogue management reinforcement learning experiments njfun system. journal artificial intelligence research richard sutton andrew barto. reinforcement learning intro hiroki tanaka hiroyoshi adachi norimichi ukita manabu ikeda hiroaki kazui takashi kudo satoshi nakamura. detecting dementia interactive computer avatars. ieee journal translational engineering health medicine tombaugh nancy mcintyre. mini-mental state examination comprehensive review. ame. geriatrics soc. wang liang zhan paul thompson hiroko dodge jiayu zhou. discriminative fusion multiple brain networks early mild cognitive impairment detection. isbi. ieee tsung-hsien david vandyke nikola mrksic milica gasic lina rojasbarahona pei-hao stefan ultes steve young. network-based endto-end trainable task-oriented dialogue system. arxiv preprint arxiv. liang zhan yashu yalin wang jiayu zhou neda jahanshad jieping paul matthew thompson. boosting brain connectome classification accuracy alzheimer’s disease using higher-order singular value decomposition. frontiers neuroscience", "year": 2018}