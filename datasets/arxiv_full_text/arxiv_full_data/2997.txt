{"title": "Find Your Own Way: Weakly-Supervised Segmentation of Path Proposals for  Urban Autonomy", "tag": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "abstract": "We present a weakly-supervised approach to segmenting proposed drivable paths in images with the goal of autonomous driving in complex urban environments. Using recorded routes from a data collection vehicle, our proposed method generates vast quantities of labelled images containing proposed paths and obstacles without requiring manual annotation, which we then use to train a deep semantic segmentation network. With the trained network we can segment proposed paths and obstacles at run-time using a vehicle equipped with only a monocular camera without relying on explicit modelling of road or lane markings. We evaluate our method on the large-scale KITTI and Oxford RobotCar datasets and demonstrate reliable path proposal and obstacle segmentation in a wide variety of environments under a range of lighting, weather and traffic conditions. We illustrate how the method can generalise to multiple path proposals at intersections and outline plans to incorporate the system into a framework for autonomous urban driving.", "text": "fig. weakly-supervised path proposal segmentation using approach. data collection vehicle equipped camera well odometry obstacle sensors used collect vast quantities data normal driving odometry obstacle data projected training images generate weakly-supervised labels relevant on-road autonomy used train deep semantic segmentation network. runtime vehicle equipped monocular camera perform live segmentation drivable path obstacles using trained network even absence explicit lane markings. generate vast quantities labelled training data without manual annotation spanning wide variety road trafﬁc conﬁgurations number different lighting weather conditions limited time spent driving data collection vehicle. data train offthe-shelf deep semantic segmentation network produce path proposal segmentations using monocular input image. evaluate approach using large-scale autonomous driving datasets kitti dataset collected karlsruhe germany large-scale oxford robotcar dataset consisting recorded driving oxford period year. datasets make additional sensors vehicle trajectory taken driver weaklyabstract— present weakly-supervised approach segmenting proposed drivable paths images goal autonomous driving complex urban environments. using recorded routes data collection vehicle proposed method generates vast quantities labelled images containing proposed paths obstacles without requiring manual annotation train deep semantic segmentation network. trained network segment proposed paths obstacles run-time using vehicle equipped monocular camera without relying explicit modelling road lane markings. evaluate method largescale kitti oxford robotcar datasets demonstrate reliable path proposal obstacle segmentation wide variety environments range lighting weather trafﬁc conditions. illustrate method generalise multiple path proposals intersections outline plans incorporate system framework autonomous urban driving. road scene understanding critical component decision making safe operation autonomous vehicles urban environments. given structured nature onroad driving autonomous vehicles must follow ‘rules road’; crucially driving within designated lanes correct direction negotiating intersections. current commercial systems perform driver assistance on-road autonomy typically depend visual recognition lane markings explicit deﬁnitions lanes trafﬁc rules therefore rely simple road layouts clear markings extend systems beyond multi-lane highways complex urban environments rural undeveloped locations without clear consistent lane markings alternative approach required. paper present weakly-supervised approach segmenting path proposals road vehicle urban environments given single monocular input image. approach capable segmenting proposed path vehicle diverse range road scenes without relying explicit modelling lanes lane markings. deﬁne term path proposal route driver would expected take particular road trafﬁc conﬁguration. present novel method automatically generating labelled images containing path proposals. method leverages behaviour data collection vehicle driver additional sensors mounted vehicle illustrated fig. project video. using approach supervised signal train pixelwise semantic classiﬁer. present segmentation results kitti road object tracking benchmarks investigate performance different lighting weather conditions using oxford dataset. traditional methods camera-based drivable path estimation road vehicles involve preprocessing steps remove shadow exposure artefacts extraction lowlevel road lane features ﬁtting road lane models feature detections temporal fusion road lane hypotheses successive frames effective well-maintained road environments approaches suffer presence occlusions shadows changing lighting conditions unstructured roads areas markings robustness signiﬁcantly increased combining images radar lidar increased sensor cost. recently advances image processing using deep learning impressive results related problem semantic segmentation aims provide per-pixel labels semantically meaningful objects input images deep networks make full image context perform semantic labelling road lane markings hence signiﬁcantly robust previous feature-based methods however automated driving approaches depend large-scale manuallyannotated road scene datasets cityscapes consisting labelled frames respectively) labels time-consuming expensive produce. challenges building large-scale labelled datasets researchers consider virtual environments ground-truth semantic labels rendered parallel synthetic camera images. methods using customised video game engines used produce hundreds thousands synthetic images corresponding ground truth labels virtual environments allow large-scale generation ground-truth semantic labels present problems ﬁrstly rendering pipelines typically optimised speed accurately reﬂect real-world images secondly actions vehicle agents virtual world must pre-programmed resemble realworld trafﬁc scenarios. recent method uses sparse prior information transfer labels real-world images requires sophisticated reconstructions manual annotations. approaches proposed bypassing segmentation entirely learning direct mapping input images vehicle behaviour methods also driver data collection vehicle generate supervised labels network recently demonstrated impressive results real-world fig. sensor extrinsics weakly-supervised labelling. survey vehicle equipped camera obstacle sensor e.g. lidar scanner. extrinsic transform camera lidar found using calibration routine. contact point c{lr} left right wheels ground relative camera frame also measured calibration time. time lidar scanner observes number points p...n obstacles including vehicles road relative pose gctct+ camera time determined using vehicle odometry e.g. using stereo camera. driving tests clear approach generalises scenarios multiple possible drivable paths consider approach instead uses data collection vehicle driver implicitly label proposed paths image still allows planning algorithm choose best path current route. following section outline approach generating weakly-supervised training data proposed path segmentation using video sensor data recorded manually-driven vehicle. sensor conﬁguration addition monocular camera collect input images approach depends following capabilities data collection vehicle vehicle odometry method estimating motion vehicle required. stereo visual odometry although methods using inertial systems wheel odometry would sufﬁce. obstacle sensing method detecting positions impassible objects front vehicle necessary ensure dynamic objects accidentally included drivable label area. lidar scanner though methods dense stereo automotive radar would also suitable. note additional sensing capabilities required collecting training data; resulting network requires monocular input image. fig. illustrates sensor extrinsics vehicle equipped stereo camera lidar sensor. weakly-supervised labelling generate class labels pixels input image make large quantities recorded data data collection vehicle driven human driver variety trafﬁc weather conditions. follow general approach methods learn drive demonstration assume proposed path corresponds chosen driver data collection vehicle scenario. labels generated projecting future path vehicle image object labels detected lidar scanner superimposed proposed path projection project future path vehicle current frame necessary know size vehicle points contact ground trajectory. assume position contact points c{lr} front left right wheels ground relative camera determined part calibration procedure. position contact point c{lr} current camera frame frames found follows perspective projection matrix camera gctct+k chain relative pose transforms formed vehicle odometry frame frame follows gctct+k gctct+×gct+ct+×···×gct+k−ct+k labels formed ﬁlling proposed path pixel quadrilaterals image coordinates corresponding sequential future frames. vertices quadrilateral formed following points camera frame index variable illustration proposed path projection labelling process shown fig. choice frame count depends lookahead distance required path labelling accuracy vehicle odometry system used provide relative frame transforms. practice choose distance beexceeds metres. different camera setups higher viewpoints require greater path distances accumulated odometry error affect far-ﬁeld projections. obstacle projection applications sufﬁcient proposed path labels train semantic segmentation network. however on-road applications presence vehicles dynamic objects naive projection path driven intersect vehicles lane label drivable paths illustrated fig. lead catastrophic results labelled images used plan paths autonomous driving since vehicles trafﬁc labelled traversable network. camera projection matrix extrinsic calibration camera lidar sensor. camera-frame point ctpi take approach inspired stixels label pixels image point obstacle. ensures locations behind detected obstacle labelled non-drivable illustrated fig. obstacle pixel labels take precedence proposed path labels fig. ground contact point obstacle point projection images. time ground contact points c{lr}j corresponding path vehicle frames ahead projected current image pixel labels corresponding drivable paths ﬁlled drawing quadrilaterals left right contact points successive frames time obstacle points current lidar scan projected image pixel labels corresponding obstacles formed extending points image note bottom sections image corresponding vehicle bonnet removed training. images locations labelled neither proposed path obstacle. correspond locations vehicle traversed positive identiﬁcation obstacles made. typically areas correspond road area outside current lane kerbs empty pavements ditches. refer locations unknown area since clear whether vehicle enter spaces; would decision higher-level planning framework discussed section vii. semantic segmentation proposed path obstacle unknown area labels automatically generated large number recorded images used train semantic segmentation network classify images different vehicle equipped monocular camera. make segnet deep convolutional encoder-decoder architecture pixelwise semantic segmentation. although higherperforming network architectures exist segnet provides real-time evaluation consumer gpus making suitable deployment autonomous vehicle. weakly-supervised labelling approach described section generate vast quantities training data limited length time spent driving data collection vehicle. however types routes driven also bias input data on-road driving performed straight line; random subsample training data consist mostly straight-line driving. practice subsample data subsampling based fig. proposed path labels input image applying obstacle labels lidar scanner. without obstacle labels proposed path intersects vehicles lane path driven data collection vehicle case erroneously label sections white drivable route. adding labels obstacles ensures dynamic objects including cyclist pedestrian marked non-drivable. note static obstacles road sign building also labelled obstacles correctly handles occlusions object contours remove erroneous obstacles noise ground-strike. velodyne hdl-e mounted annieway vehicle perform object ﬁltering hence following approach detect obstacles ground plane lidar scan using mlesac treat points plane obstacles illustrated fig. approach effectively identiﬁes obstacles vehicle collide even presence pitching rolling motions. camera-lidar calibration robotcar vehicle determined using method annieway vehicle calibration provided kitti dataset used. kitti model made available city residential road data kitti dataset. oxford model selected diverse range weather conditions traversal route including overcast direct rain night snow; traversal consisted approximately driving. number labelled images used train model shown table examples shown fig. total used images train kitti model images oxford model. datasets built semantic classiﬁer models using standard segnet convolutional encoder-decoder architecture. segnet parameters used datasets modiﬁcations account differences input image resolution. randomly split input data training validation sets performed training epochs selected bestperforming model according validation results. function extracts euler angle transform matrix build histogram average rates randomly sample histogram bins ensure unbiased selection different turning angles. build different models evaluation using kitti dataset using oxford robotcar dataset. datasets collected using different vehicles different sensor setups summarised table vehicles equipped stereo camera systems stereo visual odometry approach compute relative motion estimates required images cameras cropped downscaled resolutions listed table training. oxford robotcar equipped sick ld-mrs lidar scanner performs obstacle merging tracking across scanning planes hardware. points identiﬁed fig. semantic segmentation performed using common encoderdecoder architecture feature representation progressively spatially compressed expanded full resolution perpixel class prediction. fig. obstacle labelling using velodyne data kitti dataset. velodyne scans contain returns road surface well nearby obstacles. ground plane using mlesac retain points plane label pixels using approach section iii-b. ensure accurate labels obstacles retaining drivable surfaces ground. fig. example training images weakly-supervised labels kitti oxford datasets. weakly-supervised approach generates proposed path obstacle labels diverse locations kitti dataset diverse conditions location oxford dataset. manual annotation required generate labels. comparison using kitti road benchmark presented section v-b. trained additional segnet model training images provided egolane estimation evaluation. note ground truth images provided model trained using weakly-supervised approach described above. object detection evaluation using kitti object tracking datasets ensured overlap images selected train weakly-supervised labels images ground truth labels used evaluation. reliable on-road driving semantic segmentation must function multiple environments range lighting weather trafﬁc conditions encountered normal operation. section evaluate performance kitti model oxford model range different test conditions. evaluate oxford model generating ground truth labels four datasets used training consisting images sunny conditions images cloudy conditions images collected night images collected rain total test images. table presents segmentation results three classes four different conditions test datasets listed above column shows mean precision recall intersectionover-union across classes. model provides fig. semantic segmentation frames captured location different conditions. despite signiﬁcant changes appearance between sunny rainy snowy night-time conditions network correctly segments proposed drivable path labels obstacles including cyclists vehicles road barriers. good performance across different conditions mean scores exceeding cases highest performance cloudy weather lowest night reduced image quality low-light conditions. fig. illustrates output network four images location different conditions. despite signiﬁcant changes lighting weather network correctly determines proposed path crossing identiﬁes obstacles result demonstrates weakly-supervised approach used train single network segments proposed paths obstacles across wide range conditions without explicitly modelling environmental changes lighting weather trafﬁc. fig. presents number locations network proposed valid path absence explicit road lane markings instead using context road scene infer correct route. kitti benchmarks demonstrate weakly-supervised labelling approach lead useful performance autonomous driving tasks evaluate different benchmarks kitti vision benchmark suite ego-lane segmentation object detection. however neither benchmarks exact match segmentation results provided network designed different purposes. accordingly present alternative metrics based provided ground truth quantitatively evaluate sysnumber training images used model illustrative fact manually-annotated datasets always time-consuming expensive produce weakly-supervised approach; even manually annotated data also available many tasks approach could used pre-training improve results. object detection kitti benchmark suite contain semantic segmentation benchmark contain object instance bounding boxes object tracking datasets. deﬁnition object kitti benchmark differs signiﬁcantly deﬁnition obstacle part weaklysupervised approach however evaluate object detection performance ensuring every object instance provided kitti object tracking benchmarks also classiﬁed obstacle segmentation approach; hence highest pixel-wise recall score. object instance evaluate number pixels within bounding classiﬁed obstacle using weaklysupervised approach illustrated fig. present three different recall metrics pixel recall includes pixels bounding boxes object class variants instance recall requires certain fraction obstacle-labelled pixels within bounding instance object considered detected present recall results data provided part object tracking datasets table example detection shown fig. combined object classes follows truck tram labels grouped vehicle; pedestrian person sitting cyclist labels grouped person others grouped misc. results show weakly-supervised segmentation approach reliably labelling objects obstacles regardless object class critical avoid planning trajectories intersect vehicles road users. fig. path proposals locations without explicit lane dividers road markings. using context road scene network infers correct proposed path even gravel roads never seen training data tem. note following sections present different evaluation metrics model trained input data interpreted concert; network produces path obstacle labels test image even class evaluation. ego-lane segmentation closest analogue proposed path kitti benchmark suite ego-lane consisting entire drivable surface within lane vehicle currently occupies ego-lane dataset consists training test images manually annotated ground truth labels. trained additional segnet model provided ground truth training images compare model trained weakly-supervised labelled images detailed section iv-b. results models kitti website benchmark shown table fig. illustrates sample network output models. weakly-supervised model outperforms model trained provided ground-truth images increase f-score increase precision exceeding total despite never making manually annotated ground truth images explicit encoding lane markings. although overall performance competitive generated sophisticated network architectures kitti leaderboard result strongly indicates weakly-supervised approach generates segmentations useful real-world path planning. differences fig. example ego-lane segmentation results using kitti road dataset. given input image segnet model trained small number manually-annotated ground truth images performs poorly comparison model trained much larger weakly-supervised dataset generated without manual annotation. fig. example object detection results using obstacle segmentation. given input image network labels areas corresponding proposed path obstacle unknown area ground-truth bounding provided kitti object tracking datasets compute ratio pixels labelled obstacle method object instance consider detected pixels within bounding labelled obstacles. note even failed detections number pixels still labelled obstacle tight obstacle outlines provided method miss portions bounding weakly-supervised labels generated recording data collection trajectory provide proposed path image training time. however intersections locations multiple possible routes test time resulting network frequently labels multiple possible proposed paths image shown fig. important step towards decision-making topological navigation within road network. currently ground truth evaluate route generalisation; present qualitative results illustration plan characterise effect future publication. paper outlined approach weaklysupervised labelling images proposed path segmentation on-road driving using monocular camera. demonstrated leveraging multiple sensors behaviour data collection vehicle driver able generate vast quantities semantically-labelled training data relevant autonomous driving applications; crucially require manual labelling images fig. proposed path segmentation failures. overexposed underexposed images lead incorrect path segmentation; could addressed using high-dynamic-range camera. intersections tight turns clear path segment falls outside ﬁeld view camera; using wider ﬁeld view lens multiple cameras surround conﬁguration would address limitation. order train segmentation network. approach depend speciﬁc road markings explicit modelling lanes propose drivable paths. evaluated approach context ego-lane segmentation obstacle detection using kitti dataset outperforming networks trained manually-annotated training data providing reliable obstacle detections. also demonstrated robustness trained network changes lighting weather trafﬁc conditions using large-scale oxford robotcar dataset successful proposed path segmentation sunny cloudy rainy snowy night-time conditions. plan integrate network planning framework includes previous work topometric localisation across experiences well semantic map-guided approach trafﬁc light detection enable fully autonomous driving complex urban environments. badrinarayanan handa cipolla segnet deep convolutional encoder-decoder architecture robust semantic pixelwise labelling arxiv preprint arxiv. fritsch kuehnl geiger performance measure evaluation benchmark road detection algorithms international ieee conference intelligent transportation systems ´alvarez l´opez baldrich shadow resistant road segmentation mobile monocular system iberian conference pattern recognition image analysis. springer katramados crumpler breckon real-time traversable surface detection colour space fusion temporal analysis international conference computer vision systems. springer mccall trivedi video-based lane estimation tracking driver assistance survey system evaluation ieee transactions intelligent transportation systems vol. yamaguchi watanabe naito ninomiya road region estimation using sequence monocular images pattern recognition icpr international conference ieee labayrade douret laneurit chapuis reliable robust lane detection system based parallel three algorithms driving safety assistance ieice transactions information systems vol. jiang klette vaudrey wang lane model distance transform lane detection tracking international conference computer analysis images patterns. springer lakshmanan hero simultaneous detection lane pavement boundaries using model-based multisensor fusion ieee transactions intelligent transportation systems vol. cordts omran ramos rehfeld enzweiler benenson franke roth schiele cityscapes dataset semantic urban scene understanding proc. ieee conference computer vision pattern recognition sellart materzynska vazquez lopez synthia dataset large collection synthetic images semantic segmentation urban scenes proceedings ieee conference computer vision pattern recognition scharw¨achter enzweiler franke roth stixmantics medium-level model real-time semantic scene understanding european conference computer vision. springer pascoe maddern newman direct visual localisation calibration road vehicles changing city environments proceedings ieee international conference computer vision workshops linegar churchill newman made measure bespoke landmarks -hour all-weather localisation camera ieee international conference robotics automation ieee", "year": 2016}