{"title": "Bucking the Trend: Large-Scale Cost-Focused Active Learning for  Statistical Machine Translation", "tag": ["cs.CL", "cs.LG", "stat.ML", "I.2.7; I.2.6; I.5.1; I.5.4"], "abstract": "We explore how to improve machine translation systems by adding more translation data in situations where we already have substantial resources. The main challenge is how to buck the trend of diminishing returns that is commonly encountered. We present an active learning-style data solicitation algorithm to meet this challenge. We test it, gathering annotations via Amazon Mechanical Turk, and find that we get an order of magnitude increase in performance rates of improvement.", "text": "explore improve machine translation systems adding translation data situations already substantial resources. main challenge buck trend diminishing returns commonly encountered. present active learning-style data solicitation algorithm meet challenge. test gathering annotations amazon mechanical turk order magnitude increase performance rates improvement. figure shows learning curves state statistical machine translation systems urdu-english translation. observe learning curves rise rapidly ﬁrst trend diminishing returns occurs simply curves ﬂatten. paper investigates whether buck trend diminishing returns effectively. active learning applied recently interested starting tiny seed data stopped investigations adding relatively tiny amount data depicted figure contrast interested applying large amount data already exists case many important lanuage pairs. develop algorithm focuses keeping annotation costs low. succeeds soliciting translations parts sentences. show gets savings human annotation time beyond reduction words annotated would indicated factor three speculate why. figure syntax-based hierarchical phrasebased systems’ learning curves urdu-english language pack. x-axis measures number sentence pairs training data. y-axis measures bleu score. note diminishing returns data added. also note relatively early process previous studies terminated. contrast focus main experiments doesn’t even begin much higher performance already achieved period diminishing returns ﬁrmly established. conduct experiments urdu-english translation gathering annotations amazon mechanical turk show indeed buck trend diminishing returns achieving order magnitude increase rate improvement performance. section discusses related work; section discusses preliminary experiments show guiding principles behind algorithm use; section explains method soliciting translation data; section presents main results; section concludes. paper published within proceedings annual meeting association computational linguistics pages uppsala sweden july association computational linguistics active learning shown effective improving systems reducing annotation burdens number tasks current paper highly related previous work falling three main areas large corpora already exist; cost-focused smt. sense work banko brill closely related ours. though focus mainly investigating performance learning methods giant corpora many orders magnitude larger previously used might useful apply acquire data augment large cheaply recognize problem diminishing returns discussed section second area work related previous work cost-conscious. vast majority research focused accurate cost accounting typical assumption annotatable equal annotation cost. early exception ﬁeld work makes point using brackets measure cost syntactic analysis task instead using sentences. another relatively early work ﬁeld along lines work ngai yarowsky measured actual times annotation compare efﬁcacy rule writing versus annotation task basenp chunking. osborne baldridge argued discriminant cost unit cost task head phrase structure grammar parse selection. king design robot tests gene functions. robot chooses experiments conduct using takes monetary costs account selection evaluation. unlike situation costs known beforehand simply cost materials conduct experiments already known robot. hachey showed selectively sampled examples task took longer annotate lower inter-annotator agreement. work related shows examples selected impact cost annotation idea turn around advantage developing data selection algorithm. haertel emphasize measuring costs carefully tagging. develop model based user study estimate time required annotating. kapoor assign costs based message length voicemail classiﬁcation task. contrast show annotation times scale according length words show method achieve speedup annotation time beyond reduction words would indicate. tomanek hahn measure cost tokens task. method solicits labels parts sentences interest reducing annotation effort. along lines method similar respect also solicit annotation parts sentences though prefer measure cost time show time doesn’t track token length smt. haffari haffari sarkar ambati investigate smt. major differences work previous work. intended cases different. deal traditional setting starting extremely small seed data. also standards tiny amount data simulations sentences labeled data models learned relatively translation quality compared state art. hand current paper demonstrate apply situations already large corpora. goal buck trend diminishing returns data build highest-performing systems world keeping annotation costs low. figure section contrasts stop investigations begin studies. major difference measure annotation cost sentences. contrast bring light potential drawbacks practice showing lead different conclusions annotation cost metrics used time money metrics use. report results simulation experiments help illustrate motivate design decisions algorithm present section urdu-english language pack linguistic data consortium contains urdu-english sentence translation pairs amounting million urdu words translated english. experiments paper evaluate genre-balanced split nist urdu-english test set. addition language pack contains urdu-english dictionary consisting entries. experiments dictionary every iteration training. make harder show methods providing substantial gains since dictionary provide higher base performance begin with. however would artiﬁcial ignore dictionary resources exist. experiment translation models hierarchical phrase-based translation syntax augmented translation implemented joshua decoder hererefer systems jhier jsyntax respectively. annotation costs begin cost investigations four simple methods growing training data ranlongest vocabgrowth sendom shortest tence selection. ﬁrst three methods selfexplanatory. vocabgrowth selection modeled best methods previous work based preferring sentences contain phrases occur frequently unlabeled data infrequently so-far labeled data. method selects sentences translation contain n-grams trigger sortedn grams list ﬁrst n-gram isn’t covered labeled training data. selectedsentence find sentence contains trigger. remove selectedsentence unlabeled data labeled training data. occur so-far labeled data. call n-gram covered occurs least so-far labeled data. preference covering frequent n-grams covering infrequent n-grams. method depicted figure figure shows learning curves jhier jsyntax selection random selection. y-axis measures bleu score which fast automatic measuring translation quality shown correlate human judgments perhaps widely used metric community. x-axis measures number sentence translation pairs training data. curves point stopping criterion section met. figure might appear selection better random selection achieving higher-performing systems fewer translations labeled data. however important take care measuring annotation costs figure shows learning curves systems selection methods figure x-axis measures number foreign words training data. difference random selection appears smaller. tions measuring translation annotation cost sentences versus words consider figures show three selection methods figure measures x-axis sentences figure measures words. figure would conclude shortest inferior selection method longest figure would conclude opposite. measuring annotation time cost dollars probably important measures annotation cost. can’t measure simulated experiments time money cost measures section discusses nonsimulated experiments. sentences words track relevant costs predictable known relationships would sufﬁce measure sentences words instead. it’s clear different sentences different annotation time requirements according long complicated sentences annotation cost more. clear words tracks annotation time. section present evidence showing time word vary considerably also show method soliciting annotations reduces time word nearly factor three. prudent evaluate using accurate cost accounting also prudent develop algorithms take costs carefully account. hence reducing annotation time burdens managing uncertainty successful methods developed date uncertainty sampling applied successfully many times intuition clear much learned great uncertainty. however relatively complicated task might case uncertainty approach re-considered. words never occurred training data uncertainty expected high. concerned sentence translated words seen training though uncertainty high word alignments incorrect subsequent learning translation pair severely hampered. tested hypothesis figure shows empirical evidence true. along selection methods’ learning curves charted figure mostnew prefers select sentences largest unseen words them; moderatenew aims prefer sentences moderate unseen words preferring sentences unknown words them. mostnew underperforms could vg’s frequency component mostnew doesn’t have. moderatenew also doesn’t frequency preference likely mostnew winds overwhelming training system word alignments incorrect less learned result. light this algorithm develop section designed avoid word alignment danger. problem automatically detecting stop substantial discussed length literature simulation stop n-grams covered. though simple stopping criterion seems work well seen curve figures stops after words translated jhier’s bleu=. jsyntax’s bleu=. stopping point. ending bleu scores jhier jsyntax respectively. stopping criterion saves annotation actually achieves slightly higher bleu scores data used. note less more phenomenon section describe method soliciting human translations applied successfully improving translation quality real conditions. call method highlighted n-gram method short. solicits translations trigger n-grams entire sentences. provide sentential context highlight trigger n-gram want translated translation highlighted trigger n-gram. asks translations triggers order triggers encountered algorithm figure screenshot interface depicted figure stopping criterion used used last section. stopping criterion becomes true time unlabeled pool foreign text available. motivations soliciting translations parts sentences twofold corresponding possible cases. case translation model learned so-far labeled data able translate non-trigger words sentence correctly. thus asking human translate trigger words avoid wasting human translation effort. snow explored amazon mechanical turk service gathering annotations variety natural language processing tasks recently mturk shown quick cost-effective gather urdu-english translations used mturk service gather annotations. speciﬁcally ﬁrst crawled large articles internet urdu used unlabeled pool gather annotations. applied method section determine post mturk workers translate. gathered n-gram translations paid translation giving total cost usd. also gathered randomly chosen urdu sentence translations control paid sentence translation. prices paid market-driven. chose prices thought reasonable. hindsight given much quicker phrase translations people could greater disparity price. next section even much larger speedup beyond reduction number translated words would give us.) case translation model learned sofar labeled data also able translate non-trigger words correctly. might think would great sentence translated machine potentially learn translation. indeed overarching themes research query examples uncertainty greatest. showed evidence last section case much uncertainty could sense overwhelm machine might better provide training data gradual manner. sentence large accounting translation time mturk returns assignment worktimeinseconds. amount time between worker accepts assignment worker submits completed assignment. value estimate annotation times. figure shows collection versus random collection mturk. x-axis measures number seconds annotation time. note effective. result particularly interesting results time speedup reduction translated words would indicate. average time translate word urdu sentence postings mturk seconds. average time translate word postings mturk seconds. nearly three times faster. figure shows distribution speeds postings versus complete sentence postings. note postings consistently result faster translation speeds sentence postings. hypothesize speedup comes translating full sentence there’s time required examine word translate sense extra signiﬁcant overhead time together synthesize larger sentence translation. factor three speedup evidence overhead signiﬁcant effort compared quickly translating short n-grams sentence. speedup additional beneﬁt approach. it’s imperfect network delays person multitasking pausing accept submit times. nonetheless times ought better estimates taken larger samples. average speed postings seems slower histogram indicates. extremely slow outlier speeds handful postings. almost certainly cases turker working continuously task average speed computed postings might slower actual speed hence true speedup even faster indicated difference average speeds reported. angle around last words data wide short rectangle around newly added translations narrow tall visually appears succeeding bucking trend diminishing returns. conﬁrmed running least-squares linear regression points last words annotated data also points data acquired mturk usd. slope data bleu points urdu word bleu points million urdu words. slope data bleu points word bleu points million words. already order magnitude difference would make difference worth adding data worth leaving aside added time speedup method enjoys. figure distribution translation speeds postings versus complete sentence postings. y-axis measures relative frequency. x-axis measures translation speed seconds word mismatches equally although much important others. another reason it’s intuitive gain bleu points means practice. show concrete example translations show types improvements we’re achieving also examples suggest improvements make selection algorithm future. figure shows prototypical example system working. figure shows example strategy working partially well might. urdu phrase translated turkers gowned veil. however since word aligner aligns word gowned gowned output. prompts number discussion points. first ‘after system’ better translations they’re rewarded bleu scores because references words ‘burqah’ ‘veil’ without ‘gowned’. second hypothesize able improvements overriding automatic alignment software whenever obtain many-to-one one-to-many translation trigger phrases. cases we’d like make sure every word ‘many’ side aligned figure bucking trend performance hng-selected additional data crawl data annotated amazon mechanical turk. y-axis measures bleu. x-axis measures number words annotated. figure shows example before system already translation correct without need additional phrase translation. though before system never seen urdu expression seen urdu words isolation able successfully compose them. area future work before system determine cases automatically avoid asking humans provide translations cases. chine translation. proceedings seventh conference international language resources evaluation valletta malta may. european language resources association michele banko eric brill. scaling large corpora natural language disambiguation. proceedings annual meeting association computational linguistics pages toulouse france july. association computational linguistics. michael bloodgood chris callison-burch. using mechanical turk build machine translation evaluation sets. proceedings workshop creating speech language data amazon’s mechanical turk angeles california june. association computational linguistics. michael bloodgood vijay-shanker. approach reducing annotation costs bionlp. proceedings workshop current trends biomedical natural language processing pages columbus ohio june. association computational linguistics. michael bloodgood vijay-shanker. method stopping active learning based stabilizing predictions need user-adjustable stopping. proceedings thirteenth conference computational natural language learning pages boulder colorado june. association computational linguistics. michael bloodgood vijay-shanker. taking account differences actively passively acquired data case active learning support vector machines imbalproceedings human lananced datasets. guage technologies annual conference north american chapter association computational linguistics pages boulder colorado june. association computational linguistics. chris callison-burch miles osborne philipp koehn. re-evaluating role bleu machine translation research. conference european chapter association computational linguistics trento italy. hachey beatrice alex markus becker. investigating effects selective sampling annotation task. proceedings ninth conference computational natural language learning pages arbor michigan june. association computational linguistics. succeeded bucking trend diminishing returns improving translation quality keeping annotation costs low. future work would like apply ideas domain adaptation also would like test languages increase amount data gather investigate stopping criteria further. also would like investigate increasing efﬁciency selection algorithm addressing issues raised example presented earlier. work supported johns hopkins university human language technology center excellence. opinions ﬁndings conclusions recommendations expressed material authors necessarily reﬂect views sponsor. costs sampling methods active learning annotation. proceedings acl- short papers pages columbus ohio june. association computational linguistics. gholamreza haffari anoop sarkar. active learning multilingual statistical machine transproceedings joint conference lation. annual meeting international joint conference natural language processing afnlp pages suntec singapore august. association computational linguistics. gholamreza haffari maxim anoop sarkar. active learning statistical phrase-based proceedings human machine translation. language technologies annual conference north american chapter association computational linguistics pages boulder colorado june. association computational linguistics. rebecca hwa. sample selection statistical hinrich sch¨utze kehgrammar induction. editors proceedings joint sigdat conference empirical methods natural language processing pages association computational linguistics somerset jersey. ashish kapoor eric horvitz sumit basu. selective supervision guiding supervised learning decision-theoretic active learning. manuela veloso editor ijcai proceedings international joint conference artiﬁcial intelligence hyderabad india january pages ross king kenneth whelan fﬁon jones philip reiser christopher bryant stephen muggleton douglas kell stephen oliver. functional genomic hypothesis generation experimentation robot scientist. nature january. david lewis william gale. sequential algorithm training text classiﬁers. sigir proceedings annual international sigir conference research development information retrieval pages york usa. springer-verlag york inc. zhifei chris callison-burch chris dyer juri ganitkevitch sanjeev khudanpur lane schwartz wren thornton jonathan weese omar zaidan. joshua open source toolkit parsing-based proceedings fourth machine translation. workshop statistical machine translation pages athens greece march. association computational linguistics. francois mairesse milica gasic filip jurcicek simon keizer jorge prombonas blaise thomson steve young. phrase-based statistical language generation using graphical models acproceedings annual tive learning. grace ngai david yarowsky. rule writing annotation cost-efﬁcient resource usage base noun phrase chunking. proceedings annual meeting association computational linguistics. association computational linguistics. miles osborne jason baldridge. ensemblebased active learning parse selection. daniel marcu susan dumais salim roukos editors hlt-naacl main proceedings pages boston massachusetts association computational linguistics. kishore papineni salim roukos todd ward weijing zhu. bleu method automatic proceedings evaluation machine translation. annual meeting association computational linguistics pages philadelphia pennsylvania july. association computational linguistics. manabu sassano. empirical study active learning support vector machines japanese word segmentation. proceedings annual meeting association computational linguistics pages morristown usa. association computational linguistics. greg schohn david cohn. less more active learning support vector machines. proc. international conf. machine learning pages morgan kaufmann francisco rion snow brendan o’connor daniel jurafsky andrew cheap fast good? evaluating non-expert annotations natural language tasks. proceedings conference empirical methods natural language processing pages honolulu hawaii october. association computational linguistics. semisupervised active learning sequence labeling. proceedings joint conference annual meeting international joint conference natural language processing afnlp pages suntec singapore august. association computational linguistics. david vickrey oscar kipersztok daphne koller. active learning approach ﬁnding related proceedings annual meetterms. association computational linguistics uppsala sweden july. association computational linguistics. andreas zollmann ashish venugopal. syntax augmented machine translation chart parsing. proceedings naacl- workshop statistical machine translation york york.", "year": 2014}