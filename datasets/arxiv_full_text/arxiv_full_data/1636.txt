{"title": "Naturalizing a Programming Language via Interactive Learning", "tag": ["cs.CL", "cs.AI", "cs.HC", "cs.LG", "I.2.7; I.2.6; I.2.1"], "abstract": "Our goal is to create a convenient natural language interface for performing well-specified but complex actions such as analyzing data, manipulating text, and querying databases. However, existing natural language interfaces for such tasks are quite primitive compared to the power one wields with a programming language. To bridge this gap, we start with a core programming language and allow users to \"naturalize\" the core language incrementally by defining alternative, more natural syntax and increasingly complex concepts in terms of compositions of simpler ones. In a voxel world, we show that a community of users can simultaneously teach a common system a diverse language and use it to build hundreds of complex voxel structures. Over the course of three days, these users went from using only the core language to using the naturalized language in 85.9\\% of the last 10K utterances.", "text": "monsters initial move forward green monster right front brown ﬂoor girl back door black column ﬁnish door deer initial bird’s view deer head; left back left antler right {right antler} front left deer body; {deer front}; back {deer back}; left {deer back}; front {deer front} guage subject work semantic parsing however capability semantic parsers still quite primitive compared power wields programming language. increasingly limiting potential goal create convenient natural language interface performing wellspeciﬁed complex actions analyzing data manipulating text querying databases. however existing natural language interfaces tasks quite primitive compared power wields programming language. bridge start core programming language allow users naturalize core language incrementally deﬁning alternative natural syntax increasingly complex concepts terms compositions simpler ones. voxel world show community users simultaneously teach common system diverse language build hundreds complex voxel structures. course three days users went using core language using naturalized language last utterances. tasks analyzing plotting data querying databases manipulating text controlling internet things robots people need computers perform well-speciﬁed complex actions. accomplish this route programming language inaccessible tedious even experts syntax uncompromising statements precise. another route convert natural language formal lanpaper propose bridging interactive language learning process call naturalization. learning seed system core programming language always available user. users instruct system perform actions augment language deﬁning utterances e.g. user explicitly tell computer means ‘y’. process users gradually interactively teach system understand language want rather core language forced initially. ﬁrst users learn core language later users make everything already taught. process accommodates users’ preferences computer action space ﬁnal language interpretable computer easier produce human users. compared interactive language learning weak denotational supervision deﬁnitions critical learning complex actions deﬁnitions equate novel utterance sequence utterances system already understands. example left front’ might deﬁned ‘repeat front’ eventually traced back expression ‘repeat select front this’ core language. unlike function deﬁnitions programming languages user writes concrete values rather explicitly declaring arguments. system automatically extracts arguments learns produce correct generalizations. this propose grammar induction algorithm tailored learning deﬁnitions setting. compared standard machine learning demonstrations deﬁnitions provide much powerful learning signal system told directly square’ columns height infer generalize observing many structures different sizes. implemented system called voxelurn command language interface voxel world initially equipped programming language supporting conditionals loops variable scoping etc. recruited users amazon mechanical turk build voxel structures using system. users teach system once learned user used another user. thus community users evolves language becomes efﬁcient time distributed interaction. show user community deﬁned many utterances—short forms alternative syntax also complex concepts ‘add green monster yellow plate system learns users increasingly prefer naturalized language core language last accepted utterances naturalized language. world. world state voxelurn contains voxels voxel relations ‘row’ ‘col’ ‘height’ ‘color’. domainspeciﬁc actions ‘add’ ‘move’ domainspeciﬁc relation ‘direction’. addition state contains selection positions. focus voxelurn think generally world objects equiped relations events calendar cells spreadsheet lines text. language composes actions using usual expressive control primitives ‘if’ ‘foreach’ ‘repeat’ etc. actions usually take sets arguments represented using lambda dependency-based compositional semantics expressions besides standard operations like union intersecperform actions sequentially repeat action times action non-empty action non-empty action item group actions precedence scope selection scope voxels selection table grammar core language includes actions relations sets values grammar rules grouped four categories. bottom domain-general action compositions actions using sets lambda expressions sets domain-speciﬁc relations actions. tion complement lambda leverages tree dependency structure common natural lanrelation ‘color’ ‘has color red’ guage refers voxels color reverse ‘color refers colors voxels number treestructured joins chained without using variables e.g. ‘has color protect core language redeﬁned always precise usable. addition expressivity core language interpolates well natural language. avoid explicit variables using selection serves default argument actions. example ‘select color red; yellow top; remove’ adds yellow voxels removes voxels. tures modular introduce notion scoping. suppose operating palm trees figure user might want ‘select all’ select voxels tree rather voxels scene. general action viewed taking voxels selection producing updated voxels modiﬁed selection default scoping returns constructs alter first ‘{a}’ takes returns thus restoring selection. allows selection temporary variable without affecting rest program. second ‘isolate takes calls returns consists voxels voxels occupy empty locations allows focus selection although scoping explicitly controlled ‘isolate’ unnatural concept non-programmers. therefore choice explicit parser generates three possible scoping interpretations model learns intended based user rule potentially context. goal user build structure voxelurn. wang user provided interactive supervision system selecting list candidates. practical less tens candidates completely infeasible complex action space voxelurn. roughly possible colors containing palm tree figure yields distinct denotations many programs. obtaining structures figure selecting candidates alone would infeasible. work thus uses deﬁnitions addition selecting candidates supervision signal. deﬁnition consists head utterance body sequence utterances system understands. deﬁnitions paraphrasing deﬁning alternative syntax helps naturalize core language second building complex concepts hierarchically. figure ‘add yellow palm tree’ deﬁned sequence steps building palm tree. system understands utterance used body deﬁnitions. example figure shows full deﬁnition tree ‘add palm tree’. unlike function deﬁnitions programming language deﬁnitions specify exact arguments; system learn extract arguments achieve correct generalization. interactive deﬁnition process described figure user types utterance system parses list candidate programs. user selects system executes resulting program. utterance unparsable user rejects candidate programs user asked provide deﬁnition body utterances body understood deﬁned recursively. alternatively user ﬁrst execute sequence commands provide head utterance body type utterances multiple parses; e.g. ‘move forward’ could either modify selection move voxel rather propagating ambiguity head force user commit interpretation selecting particular candidate. note using interactivity control exploding ambiguity. derivation represents process utterance turns program prog. precisely tree node contains corresponding span utterance end) grammar rule rule grammar category list child derivations standard chart parser construct chart. chart cell indexed start indices span construct list partial derivations recursively selecting child derivations subspans applying grammar rule. resulting derivations sorted model score kept. chart denote partial derivations across chart cells. grammar rules starts rules core language grows grammar induction users deﬁnitions rules grammar stored trie based righthand side enable better scalability large number rules. social features properties rules capture unique linguistic styles different users interaction other. author features capture fact users provide better generalizable deﬁnitions tend accepted. friends features cross products author user captures whether rules particular author systematically preferred current user stylistic similarities differences span features include conjunctions category derivation leftmost/rightmost token border span. addition span features include conjunctions category derivation adjacent tokens outside left/right border span. capture weak form context-dependence generally helpful scoping features track community well individual users prefer scoping choices described section global indicators indicators user every time particular scoping choice made parameter estimation. user types utterance system generates list candidate next states. user chooses particular next state list system performs online adagrad update parameters according gradient following loss function here highest coverage substitution ‘add largest substitution available would generalize incorrectly. correct grammar rule substitutes primitive values highest scoring abstractions propose grammar induction procedure optimizes global objective uses learned semantic parsing model choose substitutions. formally partial derivations head whose programs appear derivation body desc descendant derivations goal packing derivations corresponding nonoverlapping spans head. packing maximal derivations added without creating overlap. finding highest scoring packing done using dynamic programming length since start refer span head obtain dynamic program highest scoring maximal packing containing derivation ending exactly position previous systems grammar induction semantic parsing given utterance-program pairs genlex higher-order uniﬁcation algorithms overgenerate rules liberally associate parts parts though rules immediately pruned many spurious rules undoubtedly still kept. interactive setting must keep number candidates small avoid user experience means higher precision rules. fortunately structure deﬁnitions makes grammar induction task easier. rather being given utterance-program pair given deﬁnition consists utterance along body sequence utterances. body fully parsed derivation head likely partially parsed. partial derivations denoted chart. high-level matches—partial derivations chart head also occur full derivation body grammar rule produced substituting nonoverlapping matches categories. example suppose user deﬁnes ﬁrst rule substitutes primitive values respective pre-terminal categories second rule contains compositional categories like actions require care. might expect greedily substituting largest matches match covers largest portion body would work following example shows case largest index longer maximal span order start algorithm generates high precision rule packing deﬁnition. addition highest scoring packing also simple packing includes primitive values unlike simple packing rule induced highest scoring packing always generalize correctly. however rule often generalizes incorrectly down-weighted along score packings. result different rule might induced next time even deﬁnition. extending chart alignment algorithm yields high precision rules fails generalize cases. suppose ‘move deﬁned ‘move top’ ‘up’ parse match anything. would like infer ‘up’ means ‘top’. handle this leverage property deﬁnitions used thus align head body would intuitively expect aligned phrases correspond derivations. assumption transplant derivations chart create matches. constrained usual alignment problem since need consider spans corresponds derivations desc. extended chart algorithm section induce rules. transplanted derivations might form matches allows grammar induction induce generalizable rules. perform extension body consists utterance tend paraphrase. bodies multiple utterances tend concepts alignment impossible. users select candidates parses interactive setting inducing precision rules generate many parses degrade user experience. therefore induce alignment-based rules conservatively—only tokens head aligns body vice versa. setup. ultimate goal create community users build interesting structures voxelurn naturalizing core language. created community using amazon mechanical turk stages. first qualiﬁer tasks worker instructed replicate ﬁxed target exactly ensuring initial users familiar least core language starting point naturalization process. next allowed workers qualiﬁed enter second freebuilding task asked build structure wanted minutes. process designed give users freedom ensuring quality. analogy scheme real system early users make learning investment system learn become easier users. statistics. workers passed qualiﬁer task workers participated ﬁnal freebuilding experiment. built structures. queries consisting distinct token types. these utterances tried accepted deﬁnitions combining body utterances body utterances head average deﬁnitions grammar rules induced compared less core rules. queries parses utterance average naturalization happening? answer according figure plots cummulative percentage utterances core induced unparsable. rule induced utterances getting rejected consider accepted utterances middle figure plots percentage induced rules among accepted utterances entire community well heaviest users. since unparsable utterances cannot accepted accepted core complement accepted induced. conclusion experiment accepted utterances induced—this becomes consider ﬁnal accepted utterances. three modes naturalization outlined table common operations like moving selection people found ‘select left’ verbose shorterned left user preferred right’ instead ‘select bot; select right’ core deﬁned down; right’. deﬁnitions high-level figure learning curves. percentage utterances part core language induced language unparsable system. middle percentage accepted utterances belonging induced language overall heaviest users. bottom expressiveness measured ratio length program length corresponding utterance. concepts tend whole objects parameterized bottom plot figure suggests users deﬁning using higher level concepts since programs become longer relative utterances time. result automatic implicit grammar induction concepts generalize correctly. deﬁnition head tall wide white tower centered here’ arguments match body; ‘black frame’ failed tokenize. short forms left left left left black orangeright left left brown left alternative syntax right down; right select orange select color orange times repeat white left white repeat higher level plate green cube size green monster black frame ﬂower petals deer back music dancer learned parameters. training using regularization obtained features nonzero parameters. user deﬁned many concepts consisting single short token social.author feature user negative weight overall. user compatibility pairs large positive weights others large negative weights. ‘isolate’ scoping choice received positive weights overall many users. highest scoring induced rules correspond ‘add right ‘select left incentives. complex structures show actions voxelurn expressive hierarchical deﬁnitions useful. incentivize behavior created leaderboard ranked structures based recency upvotes course days picked three prize categories released daily. prize categories bridge house animal; tower monster ﬂower; ship dancer castle. incentivize deﬁnitions also track citations. rule used accepted utterance another user rule receives citation. bonuses users according h-index. cited deﬁnitions also displayed leaderboard. qualitative results robust incentives scheme users overﬁt incentives—e.g. around structures work evolution wang differs crucially several ways wang starts scratch relies selecting candidates work starts programming language additionally relies deﬁnitions allowing scale. instead private language user user community work shares language. azaria presents learning instruction agent also advocates learning users. argue developers cananticipate actions users want system cannot understand corresponding natural language even desired action built-in. like azaria starts ad-hoc initial slot-ﬁlling commands natural language basis instructions—our approach starts expressive core designed interpolate natural language. compared previous work work studied interactive learning shared community setting hierarchical deﬁnitions resulting complex concepts. allowing ambiguity ﬂexible syntax reason natural language easier produce—this cannot achieved inform cobol look like natural language. work semantic parsing techniques handle ambiguity semantic parsing semantic representation action space usually designed accommodate natural language considered constant. contrast action space considered constant naturalizing approach language adapts natural accommodating action space. work demonstrates interactive deﬁnitions strong usable form supervision. future wish test ideas domains naturalize real handle paraphrasing implicit arguments. process naturalization data semantic grammar important roles evolution language easier humans produce still parsable computers. kwiatkowski zettlemoyer goldwater steedman. inducing probabilistic grammars logical form higher-order uniﬁcation. empirical methods natural language processing pages tellex kollar dickerson walter banerjee teller roy. understanding natural language commands robotic associanavigation mobile manipulation. tion advancement artiﬁcial intelligence zettlemoyer collins. learning sentences logical form structured classiﬁcation probabilistic categorial grammars. uncertainty artiﬁcial intelligence pages zettlemoyer collins. online learning relaxed grammars parsing logempirical methods natural lanical form. guage processing computational natural language learning pages acknowledgments. thank reviewers panupong pasupat helpful suggestions discussions lambda darpa communicating computers program under prime contract wnf--- career award iis-. artzi zettlemoyer. weakly supervised learning semantic parsers mapping instructions actions. transactions association computational linguistics heck hakkani-tür nikolov. learning concepts conversations spoken international conference dialogue systems. acoustics speech signal processing", "year": 2017}