{"title": "Variational Gaussian Process Auto-Encoder for Ordinal Prediction of  Facial Action Units", "tag": ["stat.ML", "cs.CV"], "abstract": "We address the task of simultaneous feature fusion and modeling of discrete ordinal outputs. We propose a novel Gaussian process(GP) auto-encoder modeling approach. In particular, we introduce GP encoders to project multiple observed features onto a latent space, while GP decoders are responsible for reconstructing the original features. Inference is performed in a novel variational framework, where the recovered latent representations are further constrained by the ordinal output labels. In this way, we seamlessly integrate the ordinal structure in the learned manifold, while attaining robust fusion of the input features. We demonstrate the representation abilities of our model on benchmark datasets from machine learning and affect analysis. We further evaluate the model on the tasks of feature fusion and joint ordinal prediction of facial action units. Our experiments demonstrate the benefits of the proposed approach compared to the state of the art.", "text": "abstract. address task simultaneous feature fusion modeling discrete ordinal outputs. propose novel gaussian process auto-encoder modeling approach. particular introduce encoders project multiple observed features onto latent space decoders responsible reconstructing original features. inference performed novel variational framework recovered latent representations constrained ordinal output labels. seamlessly integrate ordinal structure learned manifold attaining robust fusion input features. demonstrate representation abilities model benchmark datasets machine learning aﬀect analysis. evaluate model tasks feature fusion joint ordinal prediction facial action units. experiments demonstrate beneﬁts proposed approach compared state art. automated analysis facial expressions attracted signiﬁcant attention because practical importance psychology studies human-computer interfaces marketing research entertainment among others objective describe facial expressions means facial action coding system comprehensive anatomically-based system used describe virtually possible facial expressions terms facial muscle movements named action units facs also deﬁnes rules scoring intensity range absent maximal intensity six-point ordinal scale. therefore facs critical high-level interpretation facial expressions. instance high intensity full-blown smiles indicate joy. conversely intensity indicate fake smiles case sarcasm. machine analysis intensities challenging mainly complexity subtlety human facial behavior well individual diﬀerences expressiveness variations head-pose illumination occlusions etc. sources variation typically accounted feature level means geometricappearance-based features capturing geometry texture changes face respectively. furthermore usually appear combination aus. instance criteria intensity scoring changed signiﬁcantly appears maximal intensity since combination changes appearance well timing furthermore co-occurring nonadditive e.g. masks another distinct appearances created thus combining diﬀerent facial features accounting co-occurrences common framework expected result robust accurate estimation target intensity. existing approaches intensity estimation model independently cast classiﬁcation regression task. classiﬁcation seems natural choice handle problem related literature fails account ordinal nature target intensity levels regression-based approaches model intensity levels continuous scale sub-optimal dealing discrete outputs. similarly models attempt multiple intenisty estimation adopt sub-optimal approach deal nature output independent methods. however showed improved performance target task modeling co-occurrences. apart exceptions treat independently none aforementioned approaches addresses task joint output modeling accounting diﬀerent modalities input limitations naturally addressed following recent advances manifold learning particular using framework gaussian processes within framework problem feature fusion transformed learning multiple views continuous-valued predictions handled eﬃciently output. however regression-based models described above models treat ordinal labels continuous values. also limits potential unravel ‘ordinal’ manifold needed facilitate estimation target ordinal intensities. work propose novel manifold-based approach based bayesian latent variable model performs simultaneously feature fusion joint estimation ordinal intensity. speciﬁcally propse variational auto-encoder composed probabilistic recognition model used project observed features onto manifold generative model used reconstruction. this contrast existing work applies deterministic back-mappings allows explicitly model uncertainty projections onto learned manifold. additionally endow proposed vgp-ae ordinal outputs fusion information input features learning joint ordinal output performed simultaneously joint bayesian framework. seamlessly integrate ordinal structure recovered manifold attaining robust fusion target features. best knowledge ﬁrst approach achieves simultaneous feature fusion joint intensity estimation context facial behavior analysis. date existing work automated analysis focuses detection activations problem intensity estimation relatively ﬁeld. research area focuses independent modeling intensities recently joint estimation intensity levels addressed motivated fact intensity annotations diﬃcult obtain levels highly imbalanced. thus imposing structure output terms co-occurrences robust intensity estimation expected. toward direction proposed two-stage learning strategy multi-class support vector machine ﬁrst trained independently. then structure modeling handled dynamic bayesian network captures semantic relationship among au-speciﬁc svms. similar fashion used support vector regressors markov random ﬁeld however two-stage approaches sub-optimal target task regressors/classiﬁers relations learned independently. overcome this proposed learn latent trees encode input features output labels. structure latent variables modeled using tree-like graph. however presence high-dimensional inputs multiple method becomes prohibitively expensive. moreover authors show approach fusion diﬀerent features beneﬁt estimation intensity achieving similar performance individual modalities used. recently proposed sparse learning approach uses notion robust principal component analysis decompose expression facial identity. then joint intensity estimation multiple performed regression model based dictionary learning. however approach deal single modality only. casts joint intensity estimation multi-task learning problem based kernel regression however formulation model mlkr scale high-dimensional features alone using features diﬀerent modalities work presented paper advances current state several aspects proposed vgp-ae eﬃciently perform fusion multiple modalities means shared manifold; automatic feature selection implicitly performed manifold. recovered latent representations used input multiple ordinal regressors concurrently learned joint bayesian framework; allow eﬃciently deal high-dimensional input output variables without signiﬁcantly aﬀecting model’s complexity. fig. proposed vgp-ae. gp-decoder gp-encoder respectively. projection latent variable labels’ ordinal plane facilitated ordinal regression compact representation model. proposed recognition model intermediate variable labels input channel consists i.i.d. samples denotes corresponding facial features. {zi}n common label representation denotes discrete ordinal state c-th output interested simultaneously addressing tasks feature fusion ordinal prediction multiple outputs. purpose propose approach resembles recent work generative models models auto-encoders employed learn compact representations input data. standard auto-encoding setting encoding/decoding functions modeled neural networks. replace functions probabilistic non-parametric mappings significantly reducing number optimized parameters naturally modeling uncertainty mappings. proposed approach regarded b-gplvm fast inference mechanism based non-parametric probabilistic mapping achieve this impose priors models hence obtain well-deﬁned gp-encoder accordance gp-decoder. within setting assume observed features generated random process involving latent variables {xi}n data pairs assumed conditionally independent given latent variables i.e. z|x. random process recovering latent variables distinctive stages latent variable generated general prior distribution projected labels’ ordinal plane obgenerated conditional distribution p|x). served input process described fig. using approach perform classiﬁcation lower-dimensional space however requires access latent space encouraged reﬂect structure output labels. here place priors corresponding hyper-parameters denotes ordinal regression transforms latent variables labels’ ordinal plane {wc}c analysis auto-encoder. ordinal information labels incorporated presented variational framework sec. place priors integrating mapping functions obtain conditionals kernels associated process. note recognition model relevant kernel allows easily combine multiple features individual kernel functions. training recognition model consists maximizing conditional since integral intractable resort approximations. main interest recover bayesian non-parametric solution encoder decoder. ﬁrst need break circular dependence order train simultaneously. gp-decoder. proposed recognition model i.e. variational distribution employed approximate intractable marginal likelihood introducing variational distribution approximation true posterior applying jensen’s inequality obtain lower bound log-marginal likelihood previous section presented recognition model employ learn nonlinear manifold observed inputs. following constrain manifold imposing ordinal structure. attained introducing ordinal variables account ordinal levels aus. notion ordinal regression particular ordinal threshold model imposes monotonically increasing structure discrete output labels continuous manifold. formally non-linear mapping manifold ordinal outputs modeled kernel gp-decoder radial basis function automatic relevance determination eﬀectively estimate dimensionality latent space kernel gp-encoder isotropic observed input. utilize joint optimization scheme stochastic backpropagation re-parameterization trick applied thus obtain monte carlo estimate expectation auto-encoder expectation ordinal classiﬁer computed similar manner. advantage twofold allows eﬃcient computation lower bound even using arbitrary kernel functions provides eﬃcient low-variance estimator gradient extra approximation gradient step requires stochastic gradient descent. adadelta purpose. inference proposed method straightforward test data ﬁrst projected onto manifold using trained gp-encoder. second step apply ordinal classiﬁer obtained latent position. note adopt linear model operates low-dimensional auto-encoder approach inspired neural-network counterparts proposed probabilistic distributions deﬁned input output mapping functions. literature auto-encoders closely related notion ‘back-constraints’. back-constraints introduced deterministic parametric mapping pairs latent variables gplvm observations. mapping facilitates fast inference mechanism enforces structure preservation manifold. mechanism used constrain shared gplvm view multiple views back-constraints recently introduced b-gplvm authors proposed approximate true posterior latent space introducing variational distribution conditioned unobserved inputs. however inputs related observation space considered paper variational posterior latent space constrained using trick parametric deterministic mapping finally authors replaced variational approximation monte carlo expectation-maximization algorithm. samples obtained mapping observed inputs manifold. proposed vgp-ae advances current literature many aspects introduce mapping recognition model. hence model diﬀerent uncertainty levels input allows learn conﬁdent latent representations. non-parametric also allows model complex structures lesser expense thus less prone overﬁtting scales better high-dimensional data. compared probabilistic recognition model facilitates low-dimensional projection observed features variational constraint constitute probabilistic mapping. learn encoders/decoders joint optimization train models alternating scheme. datasets. ﬁrst show qualitative evaluation proposed vgp-ae mnist benchmark dataset images handwritten digits. assess properties auto-endoced manifold. show performance vgp-ae benchmark datasets facial aﬀect disfa challenge). speciﬁcally disfa contains video recordings subjects watching youtube videos. frame coded terms intensity six-point ordinal scale. fera database includes video participants. subjects training subjects features. experiment mnist dataset normalized pixel intensities input resulting feature vector. disfa fera geometric appearance features. speciﬁcally disfa fera datasets come frame-by-frame annotations facial landmarks respectively. removing contour landmarks disfa annotations facial points. register images reference face using aﬃne transform based points. extract local binary patterns histograms bins patches centered around registered point. hence obtain feature vectors commonly used modeling facial aﬀect. evaluation. evaluation measures negative log-predictive density assess generative ability model. task ordinal classiﬁcation report mean squared error intra-class correlation standard measures ordinal data. measures classiﬁer’s consistency regarding relative order classes. measure agreement annotators finally adopt subject-independent setting fera report results subjects development disfa perform -fold cross-validation procedure. models. compare proposed vgp-ae state manifold learning methods perform multi-input multi-output inference. include manifold relevance determination regression model based variational inference variational auto-encoded deep uses recognition model based constrain learning multi-task latent uses mlpbased recognition model maximum likelihood learning approach. also compare variational ordinal regression baseline standard shared covariance function among multi-outputs. also compare single-output ordinal threshold model finally compare state methods joint estimation intensity based mrfs latent trees respectively. single input methods concatenate feature sets. parameters method tuned described corresponding papers. subspace methods used kernel initialized manifold. regression methods used standard rbf. sparse variational methods used inducing points hidden units recognition models vae-dgp mt-lgp. fig. recovering structure rotated mnist. learned kernel matrices manifolds obtained b-gplvm vae-dgp proposed vgp-ae initialized random instance. image depicting digit rotate around results images rotated step goal infer true structure data know priori correspond diagonal-like kernel circular manifold. however challenge arises symmetry digit almost identical opposite degrees results depicted fig. note since deal classiﬁcation task exclude ordinal component vgp-ae. compare learned manifold structure b-gplvm model back-projection latent space single layer vae-dgp backprojections modeled using mlp. fig. learned kernels b-gplvm unable fully unravel dissimilarity ‘inverted’ images resulting also non-smooth kernel discontinuity contrast vae-dgp beneﬁts recognition model manages resolve extent. recovered kernel still suﬀers discontinuity around hand proposed vgp-ae using general recognition model based succeeds accurately discover true underlying manifold also resulting smooth almost ideal kernel. observations supported instances learned manifolds fig. bgplvm learns disconnected manifold ‘jumps’ however vae-dgp proposed vgp-ae recover circular manifold manifold recovered vgp-ae symmetric. fig. convergence analysis proposed method fera. recovered latent space ordinal information reconstructed face shapes sampled diﬀerent regions manifold. estimated average variational capacity points features measured nlpd. average joint intensity estimation. horizontal axis corresponds amount training points evaluated epochs stochastic optimization. siﬁer auto-encoded manifold within joint optimization framework. clearly seen recovered space information labels correctly encoded manifold ordinal structure depicted fig. accurately reconstruct face shapes diﬀerent intensities sampling diﬀerent regions space. fig. shows diﬀerent batch sizes stochastic optimization. small batch size model cannot estimate structure inputs well. hence approximates log-marginal likelihood less accurately. increasing batch size model converges better solution optimization becomes stable since curve becomes smoother iterations. increase batch size considerable eﬀect. fig. evaluate generative part auto-encoder measuring model’s ability reconstruct input features terms nlpd. first clear bayesian training prevents model overﬁtting since nlpd test data follows trend training data. furthermore model reconstruct geometric features better appearance evidenced lower fact lbps higher dimension therefore diﬃcult reconstruct. another reason diﬀerence model learns reconstruct part features enclose relevant information regarding task classiﬁcation. latter supported fig. progress average optimization. beginning model information since latent space initialized randomly. progress model fuses information input features latent space unravels structure data. thus starts rising reaches highest value test data. point model longer beneﬁt appearance features reached plateau. compare proposed approach several methods spontaneous data disfa fera datasets. table summarizes results. first observe methods perform signiﬁcantly better data fera disfa. mainly fact fera contains much balanced hence models learn classiﬁers target task better. furthermore proposed approach performs signiﬁcantly better compared manifold learning methods treat output labels continuous variables. lacks modeling back-projections. results learning less smooth manifold facial expressions affects representation abilities hence predictions. hand vae-dgp learns explicitly mapping observed features fig. demonstration gain/loss feature fusion joint intensity estimation fera. within ﬁrst tuple corresponds proposed vgp-ae second tuple vae-dgp third tuple vgpor latent space deterministic parametric fashion. although strategy proven superior unconstrained learning severely aﬀected cases access noisy high-dimensional features. mt-lgp also models back-mappings. however reports worse results especially disfa. drop performance accounted non-bayesian learning manifold constitutes model prone overﬁtting. regarding sparse ordinal regression instance i.e. vgpor manages learn relatively accurate mappings features labels thus performs close proposed method. however reports worse results since cannot achieve desirable fusion features without learning intermediate latent space. baseline methods i.e. report lower results. attains scores handling ordinal outputs continuous manner ordinal modeling helps report consistently better. finally proposed approach signiﬁcantly outperforms state methods literature intensity estimation i.e. mrf. learns label information generative manner treats extra feature dimensions. although approach beneﬁcial presence noisy features suﬀers learning complicated large tree structures falsely detecting connections features aus. hence performs worse. performs proposed method disfa achieves best average consistently worse fera. inconsistency two-step learning strategy results unraveling graph cannot explain simultaneously diﬀerent features aus. fig. evaluate attained fusion best performing methods fera i.e. proposed vgp-ae vae-dgp vgpor proposed approach manages accurately fuse information input features learned manifold. thus achieves higher compared modalities used individually input features. hand although vgpor reports also high scores beneﬁt presence features cases cannot achieve signiﬁcant increase compared individual inputs. finally vae-dgp consistently attains better performance single feature input. attributed modeling recognition model parametric mlp. latter aﬀects learning manifold especially dealing high-dimensional noisy appearance features. mentioned diﬀerence approach vae-dgp evidenced fig. proposed fusion along novel nonparametric probabilistic recognition model auto-encoder leads less confusion ordinal states across aus. attribute ordinal modeling outputs vgp-ae contrary vae-dgp treats output continuous variables. especially pronounced case subtle examples high intensity levels scarce. presented fully probabilistic auto-encoder mappings govern generative recognition models. proposed variational auto-encoder learned supervised manner ordinal nature labels imposed manifold. allows proposed approach accurately learn structure input data also remain competitive classiﬁcation task. empirically evaluated model task facial feature fusion joint intensity estimation facial action units. proposed model outperforms related methods state approaches target task.", "year": 2016}