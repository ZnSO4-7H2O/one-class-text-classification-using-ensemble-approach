{"title": "Exact Hybrid Covariance Thresholding for Joint Graphical Lasso", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "This paper considers the problem of estimating multiple related Gaussian graphical models from a $p$-dimensional dataset consisting of different classes. Our work is based upon the formulation of this problem as group graphical lasso. This paper proposes a novel hybrid covariance thresholding algorithm that can effectively identify zero entries in the precision matrices and split a large joint graphical lasso problem into small subproblems. Our hybrid covariance thresholding method is superior to existing uniform thresholding methods in that our method can split the precision matrix of each individual class using different partition schemes and thus split group graphical lasso into much smaller subproblems, each of which can be solved very fast. In addition, this paper establishes necessary and sufficient conditions for our hybrid covariance thresholding algorithm. The superior performance of our thresholding method is thoroughly analyzed and illustrated by a few experiments on simulated data and real gene expression data.", "text": "abstract. paper studies precision matrix estimation multiple related gaussian graphical models dataset consisting different classes based upon formulation problem group graphical lasso. particular paper proposes novel hybrid covariance thresholding algorithm effectively identify zero entries precision matrices split large joint graphical lasso problem many small subproblems. hybrid covariance thresholding method superior existing uniform thresholding methods method split precision matrix individual class using different partition schemes thus split group graphical lasso much smaller subproblems solved fast. paper also establishes necessary sufﬁcient conditions hybrid covariance thresholding algorithm. experimental results synthetic real data validate superior performance thresholding method others. graphs widely used describe relationship variables estimating undirected graphical model dataset extensively studied. dataset gaussian distribution problem equivalent estimating precision matrix empirical covariance matrix. many real-world applications precision matrix sparse. problem formulated graphical lasso many algorithms proposed solve take advantage sparsity precision matrix covariance thresholding methods developed detect zero entries matrix split matrix smaller submatrices signiﬁcantly speed process estimating entire precision matrix recently studies jointly estimate multiple related graphical models dataset distinct class labels underlying reason joint estimation graphs classes similar degree increase statistical power estimation accuracy aggregating data different classes. joint graph estimation problem formulated joint graphical lasso makes similarity underlying graphs. addition group graphical lasso used non-convex hierarchical penalty promote similar patterns among multiple graphical models introduced popular group fused graphical lasso; proposed efﬁcient algorithms solve fused graphical lasso. model gene networks proposed node-based penalty promote structure graph. existing algorithms solving joint graphical lasso scale well respect number classes denoted number variables denoted similar covariance thresholding methods graphical lasso couple thresholding methods developed split large joint graphical lasso problem subproblems nevertheless algorithms uniform thresholding decompose precision matrices distinct classes exactly way. such split precision matrices small enough submatrices especially large number classes and/or precision matrices different sparsity patterns. therefore speedup effect covariance thresholding signiﬁcant. contrast above-mentioned uniform covariance thresholding paper presents novel hybrid thresholding approach divide precision matrix individual class smaller submatrices without requiring resultant partition schemes exactly across classes. using method split large joint graphical lasso problem much smaller subproblems. employ popular admm method solve joint graphical lasso based upon hybrid partition scheme. experiments show method solve group graphical lasso much efﬁciently uniform thresholding. hybrid thresholding approach derived based upon group graphical lasso. idea also generalized joint graphical lasso fused graphical lasso. space limit proofs theorems paper presented supplementary material. notation deﬁnition paper script letter like denote partition. denote element. similarly bold letter like denote graph vector matrix. matrix denote entry. denote objects category. denote sample dataset classes data independently identically drawn p-dimension normal distribution denote empirical covariance precision matrices class respectively. optimal mean precision matrices obtained exactly solving joint graphical lasso. binary matrix denote sparsity pattern i.e. partition. partition following conditions satisﬁed element subset union elements equal elements disjoint. given partitions ﬁner denoted every element subset element strictly ﬁner denoted denote matrix describing pairwise relationship elements corresponds elements given partition deﬁne θhkas |hk| |hk| submatrix element suitable graph-based partition. denote variable dataset. graph denote estimated concentration graph graph deﬁnes partition element corresponds connected component matrix divided disjoint submatrices based upon denote i.e. entry equal exists least equal construct partition graph element corresponds connected component obviously holds since subset implies matrix divided disjoint submatrices based upon feasible partition. partition feasible class graph implies obtained merging elements element corresponds union connected components graph divide precision matrix independent submatrices according separately estimate submatrices without losing accuracy. uniformly feasible holds. denote partitions variable holds feasible partition classes graphs. least partitions same non-uniform partition. otherwise class-independent uniform partition abbreviated uniformly feasible holds. obviously ﬁner non-uniform feasible partition classes. based upon deﬁnitions following theorem proved supplementary material. theorem uniformly feasible partition variable feasible graph ﬁnest uniform feasible partition. proof. first element contain edges otherwise since mixing exists least graph contains least edge since union elements implies exist different elements contains edges them contradicts fact contain edges elements feasible graph second hold element element based paragraph split least disjoint subsets contain learn underlying graph structure multiple classes simultaneously penalty functions used promote similar structural patterns among different classes including typical joint graphical lasso formulated following optimization problem covariance thresholding methods identify zero entries precision matrix before directly solving optimization problem like widely used accelerate solving graphical lasso. particular screening method divides variable disjoint groups variables group corresponding entry precision matrix guaranteed using method precision matrix split submatrices corresponding distinct group. achieve best computational efﬁciency shall divide variable small groups possible subject constraint related variables shall group. meanwhile described screening method group graphical lasso. method uses single thresholding criterion classes i.e. employs uniformly feasible partition variable across classes. existing methods described fused graphical lasso node-based learning employ uniform thresholding. uniform thresholding able divide variable ﬁnest feasible partition individual class underlying concentration graphs exactly same. example figure show concentration graphs different classes. graphs differ variables graph split connected components. however mixing graph connected component cannot split further. according theorem uniform feasible partition divide variable disjoint groups without losing accuracy. expected number classes variables increases uniform thresholding perform even worse. fig. illustration uniform thresholding impacted minor structure difference classes. edge matrix concentration graph classes. concentration graph resulting mixing graphs non-uniform thresholding generates non-uniform feasible partition thresholding empirical covariance matrices separately. non-uniform partition variables group class belong different groups another class. figure shows example non-uniform partition. example matrix elements white color non-uniform thresholding. except white color colors indicates group. variables belong group left matrix right matrix. similarly variables belong group right matrix left matrix. fig. illustration non-uniform partition. white color indicates zero entries detected covariance thresholding. entries color white belong group. algorithm covariance thresholding algorithm identify non-uniform feasible partition satisfying condition call algorithm hybrid screening algorithm utilizes class-speciﬁc thresholding global identify non-uniform partition. hybrid screening algorithm terminate rapidly typical linux machine tested synthetic data described section generate uniform feasible partition using global thresholding generate non-uniform feasible partition using class-speciﬁc thresholding partition good using hybrid thresholding algorithm. denote partitions generated hybrid class-speciﬁc global thresholding algorithms respectively. obvious since condition combination global thresholding class-speciﬁc thresholding. figure shows example comparing three screening methods using dataset classes three variables. example class-speciﬁc global thresholding alone cannot divide variable disjoint groups combination fig. comparison three thresholding strategies. dataset contains slightly different classes variables. sample covariance matrices shown ﬁgure. parameters used section describe apply admm solve joint graphical lasso based upon non-uniform feasible partition variable set. according solving admm equivalent minimizing following scaled augmented lagrangian form dual variables. admm algorithm solve iteratively updates three variables alternatively. computational-insensitive step update given requires eigen-decomposition matrices. based upon non-uniform feasible partition updating given equivalent solving total independent sub-problems. independent sub-problem solves following equation solving requires eigen-decomposition small submatrices shall much faster eigen-decomposition original large matrices. based upon non-uniform partition updating given updating given also faster corresponding components plain admm algorithm described since non-uniform thresholding algorithm detect many zero entries admm applied. tested method denoted hadmm synthetic real data compared hadmm control methods gadmm global covariance thresholding algorithm admm; ladmm class-speciﬁc covariance thresholding algorithm +admm. implemented methods tested linux machine intel xeon .ghz. generate dataset classes gaussian distribution ﬁrst randomly generate precision matrices sample data points class. make sure randomly-generated precision matrices positive deﬁnite diagonal entries off-diagonal entry either generate three types datasets follows. evaluate correctness method hadmm compare objective function value generated hadmm admm respect number iterations. methods iterations three types data shown table ﬁrst iterations hadmm admm yield slightly different objective function values. however along iterations passed hadmm admm converge objective function value shown figure supplementary figures experimental result conﬁrms hybrid covariance thresholding algorithm correct. tested several pairs hyper-parameters experiment. please refer supplementary material model selection. note although terms number iterations hadmm admm converge similarly hadmm runs much faster admm iteration hadmm converges much shorter time. previous section shown hadmm converges solution admm. test running times hadmm ladmm gadmm needed considering large amount running time needed ladmm gadmm iterations three methods compare average running time single iteration. tested running time three methods using different parameters three types data. supplementary material model selection. show result figure figure supplementary material respectively. figure shows experimental results type data column experimental results hyper-parameters shown figure hadmm much efﬁcient ladmm gadmm. gadmm performs comparably better ladmm large. running time ladmm increases decreases. also running time three methods increases along number classes. however gadmm sensitive number classes hadmm. moreover hybrid covariance thresholding algorithm yields ﬁner non-uniform feasible partitions precision matrices likely split many smaller submatrices. means potentially easier parallelize hadmm obtain even speedup. also compare three screening algorithms terms estimated computational complexity matrix eigen-decomposition time-consuming subroutine used admm algorithms. given partition variable compufigures non-uniform thresholding algorithm generates partitions much smaller computational complexity usually methods. note ﬁgures y-axis logarithm estimated computational complexity. advantage non-uniform thresholding algorithm even larger shown figure supplemental file. test proposed method real gene expression data. lung cancer data downloaded gene expression omnibus mouse immune dataset described immune dataset consists observations. lung cancer data collected patients lung cancer controls without lung cancer lung cancer dataset consists different classes patient control. treat observations immune dataset lung cancer observations controls three classes compound dataset joint inference task. three classes share common genes dataset features classes. absolute value entries covariance matrix ﬁrst class relatively larger divide entry covariance matrix make three covariance matrices similar magnitude performing joint analysis using unique running time hadmm ladmm gadmm compound dataset different settings shown table resultant gene networks different sparsity shown supplemental file. shown table hadmm always efﬁcient methods different settings. typically small large method much faster ladmm. contrast small large enough method much faster gadmm. what’s more moderate values hadmm still much faster gadmm ladmm. shown resultant networks similar topology structure. reasonable large setting actually networks three classes setting share similar topology structure. what’s more number edges network decrease signiﬁcantly goes shown supplementary material. paper presented non-uniform hybrid covariance thresholding algorithm speed solving group graphical lasso. established necessary sufﬁcient conditions thresholding algorithm. theoretical analysis experimental tests demonstrate effectiveness algorithm. although paper focuses group graphical lasso proposed ideas techniques also extended fused graphical lasso. thresholding algorithm presented paper static sense applied pre-processing step admm applied solve group graphical lasso. extend static thresholding algorithm dynamic version. example identify zero entries precision matrix speciﬁc class based upon intermediate estimation precision matrices classes. shall able obtain ﬁner feasible partitions improve computational efﬁciency. banerjee ghaoui d’aspremont model selection sparse maximum likelihood estimation multivariate gaussian binary data. journal machine learning research boyd parikh peleato eckstein distributed optimization statistical learning alternating direction method multipliers. foundations trends machine learning danaher wang witten d.m. joint graphical lasso inverse covariance estimation across multiple classes. journal royal statistical society series hsieh c.j. dhillon i.s. ravikumar p.k. sustik m.a. sparse inverse covariance matrix estimation using quadratic approximation. advances neural information processing systems. rolfs rajaratnam guillot wong maleki iterative thresholding algorithm sparse inverse covariance estimation. advances neural information processing systems. spira beane j.e. shah steiling schembri gilman dumas y.m. calner sebastiani airway epithelial gene expression diagnostic evaluation smokers suspect lung cancer. nature medicine tseng block-coordinate gradient descent method linearly constrained nonsmooth separable optimization. journal optimization theory applications", "year": 2015}