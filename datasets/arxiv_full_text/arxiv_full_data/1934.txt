{"title": "VSE++: Improving Visual-Semantic Embeddings with Hard Negatives", "tag": ["cs.LG", "cs.CL", "cs.CV"], "abstract": "We present a new technique for learning visual-semantic embeddings for cross-modal retrieval. Inspired by the use of hard negatives in structured prediction, and ranking loss functions used in retrieval, we introduce a simple change to common loss functions used to learn multi-modal embeddings. That, combined with fine-tuning and the use of augmented data, yields significant gains in retrieval performance. We showcase our approach, dubbed VSE++, on the MS-COCO and Flickr30K datasets, using ablation studies and comparisons with existing methods. On MS-COCO our approach outperforms state-of-the-art methods by 8.8% in caption retrieval, and 11.3% in image retrieval (based on R@1).", "text": "fartash faghri david fleet jamie ryan kiros sanja fidler department computer science university toronto canada {faghrifleetrkirosfidler}cs.toronto.edu present technique learning visual-semantic embeddings crossmodal retrieval. inspired hard negatives structured prediction ranking loss functions used retrieval introduce simple change common loss functions used learn multi-modal embeddings. that combined ﬁne-tuning augmented data yields signiﬁcant gains retrieval performance. showcase approach dubbed vse++ ms-coco flickrk datasets using ablation studies comparisons existing methods. ms-coco approach outperforms state-of-the-art methods caption retrieval image retrieval joint embeddings enable wide range tasks image video language understanding. examples include shape-image embeddings shape inference bilingual word embeddings human pose-image embeddings pose inference ﬁne-grained recognition zero-shot learning modality conversion synthesis embeddings entail mappings domains common vector space semantically associated inputs mapped similar locations. embedding space thus represents underlying structure domains locations often direction semantically meaningful. paper focus learning visual-semantic embeddings central tasks imagecaption retrieval generation kiros karpathy fei-fei visual questionanswering malinowski approach visual question-answering example ﬁrst describe image captions nearest caption response question zitnick case image synthesis text approach invert mapping joint visual-semantic embedding image space focus visual-semantic embeddings generic task cross-modal retrieval; i.e. retrieval images given captions captions query image. common information retrieval measure performance i.e. recall fraction queries correct item retrieved closest points query embedding space generally retrieval natural assess quality joint embeddings image language data subsequent tasks problem ranking correct target closer query items corpus unlike learning rank problems max-margin structured prediction chapelle smola formulation model architecture paper closely related kiros learned triplet ranking loss. contrast work advocate novel loss augmented data ﬁne-tuning together produce signiﬁcant increase caption retrieval performance baseline ranking loss well-known benchmark datasets. outperform best reported result ms-coco almost also demonstrate beneﬁt powerful image encoder ﬁne-tuning image encoder ampliﬁed stronger loss finally note formulation complements recent articles propose model architectures similarity functions problem. wang propose embedding network fully replace similarity function used ranking loss. attention mechanism image caption used authors sequentially selectively focus subset words image regions compute similarity. huang authors multi-modal context-modulated attention mechanism compute similarity image caption. proposed loss function triplet sampling could extended applied approaches. image-caption retrieval query caption task retrieve relevant image database. query image retrieves relevant captions. goal maximize recall fraction queries relevant item ranked among items returned. training image-caption pairs. refer positive pairs negative pairs; i.e. relevant caption image caption image deﬁne similarity function should ideally give higher similarity scores positive pairs negatives. caption retrieval query image rank database captions based similarity function; i.e. percentage queries positive caption ranked among captions using likewise image retrieval. follows similarity function deﬁned joint embedding space. approach differs others wang similarity network directly classify image-caption pair matching non-matching. visual-semantic embedding feature-based representation computed image resnet similarly representation caption caption embedding space here denote model parameters used respective mappings obtain initial image caption representations. mappings joint embedding space deﬁned terms linear projections; i.e. model parameters. also ﬁne-tune image encoder would also include training entails minimization empirical loss respect i.e. cumulative loss training data figure illustration typical positive pairs nearest negative samples. assume similarity score negative distance. filled circles show positive pair empty circles negative samples query dashed circles sides drawn radii. notice hardest negative sample closer assuming zero margin higher loss loss compared loss assigns higher loss recent approaches joint visual-semantic embeddings used form triplet ranking loss karpathy fei-fei socher inspired image retrieval chechik prior work employed hinge-based triplet ranking loss margin max. hinge loss comprises symmetric terms queries. ﬁrst taken negative captions given query second negative images given caption term proportional expected loss sets negative samples. closer another joint embedding space negatives pairs margin hinge loss zero. practice computational efﬁciency rather summing possible negatives training common negatives within mini-batch stochastic gradient descent socher karpathy fei-fei course loss functions might consider. approach pairwise hinge loss elements positive pairs encouraged within radius joint embedding space negative pairs closer problematic constrains structure latent space ranking loss entails hyper-parameters difﬁcult set. another possible approach canonical correlation analysis learn thereby trying preserve correlation text images joint embedding eisenschtat wolf comparison measuring performance small correlation-based loss give sufﬁcient inﬂuence embedding negative items local vicinity positive pairs critical inspired common loss functions used structured prediction joachims felzenszwalb focus hard negatives training i.e. negatives closest training query. particularly relevant retrieval since hardest negative determines success failure measured given positive pair hardest negatives given maxj=i maxd=c emphasize hard negatives therefore deﬁne loss like loss comprises terms queries. unlike loss speciﬁed terms hardest negatives hereafter refer loss hinges loss loss function hinges loss. example loss superior multiple negatives relatively small violations combine dominate loss. example fig. positive pair depicted together sets negative samples. fig. exists single negative sample close query. essentially moving hard negative might require signiﬁcant change mapping. however training step pushes hard negative away bring back many small violating negative samples fig. using loss ’new’ negative samples dominate loss model pushed back ﬁrst example fig. create local minima loss problematic loss focuses solely hardest negative. computational efﬁciency instead ﬁnding hardest negatives whole training mini-batch. random sampling mini-batches approximate yields advantages. high probability getting hard negatives harder least entire training set. moreover loss potentially robust label errors training data probability sampling hardest negative entire training somewhat low. appendix analyze probability sampling hard negatives further. ﬁrst perform experiments approach vse++ compare baseline formulation loss referred state-of-the-art approaches. essentially baseline formulation used kiros referred uvs. experiment image encoders simonyan zisserman resnet follows unless speciﬁed otherwise. previous work extract image features directly penultimate fully connected layer. dimensionality image embedding resnet. somewhat detail ﬁrst resize image either single center crop size mean feature vectors crops similar size done klein vendrov refer training center crop training crops also consider using random crops denoted full model extract features single randomly chosen cropped patch opposed pre-computing image features reusing them. note kiros caption embedding normalized image embedding not. normalization vectors means similarity function cosine similarity. vse++ normalize vectors. normalizing image embedding changes importance samples. experiments normalizing image embedding helped baseline better solution. however vse++ signiﬁcantly affected normalization. evaluate method microsoft coco dataset flickrk dataset flickrk standard images training. following karpathy fei-fei images validation images testing. also splits karpathy fei-fei ms-coco. split training contains images validation test images. however also images originally validation ms-coco left split. refer papers training improve accuracy. report results using training sets. image comes captions. results reported either averaging folds test images testing full test images. adam optimizer kingma train models. train models epochs. except ﬁne-tuned models start training learning rate epochs lower learning rate another epochs. ﬁne-tuned models trained table effect data augmentation ﬁne-tuning. copy relevant results vse++ table enable easier comparison. notice applying modiﬁcations exception model reaches vse++ achieves taking model trained epochs ﬁxed image encoder training epochs learning rate margin experiments. mini-batch size experiments. notice since size training different models different actual number iterations epoch vary. evaluation test tackle over-ﬁtting choosing snapshot model performs best validation set. best snapshot selected based recalls validation set. results ms-coco dataset presented table understand effect training algorithmic variations report ablation studies baseline best result vse++ achieved using resnet ﬁne-tuning image encoder improvement caption retrieval improvement image retrieval compared notice using resnet ﬁne-tuning lead improvement using formulation loss function brings signiﬁcant gain comparing vse++ current state-of-the-art ms-coco waynet improvement caption retrieval compared sm-lstm improvement image retrieval. also report results full test ms-coco rows effect training set. compare vse++ incrementally improving training data. comparing models trained improvement image retrieval improvement caption retrieval performance. however train using rc+rv vse++ gains improvement respectively caption retrieval compared vse. shows vse++ better exploit additional data. effect better image encoding. also investigate effect better image encoder models. show effect ﬁne-tuning image encoder. vse++ increases resnet instead best result resnet also ﬁne-tune image encoder becomes increase performance shows improved loss vse++ better guide optimization powerful image encoder used. tables summarizes performance flickrk. obtain improvement caption retrieval improvement image retrieval observed vse++ over-ﬁts trained pre-computed features reason potentially limited size flickrk training set. explained sec. select snapshot model over-ﬁtting occurs based performance validation set. over-ﬁtting occur model trained using training data. results show improvements incurred loss persist across datasets well across models. observed loss take epochs ’warm-up’ training. fig. depicts behavior flickrk dataset using loss starts faster approximately epochs loss surpasses loss. explain this loss depends smaller triplets compared loss. beginning training much model learn. however gradient loss inﬂuenced small triples. such take longer train model loss. explored simple form curriculum learning speed-up training. start training loss epochs switch loss rest training. however perform better training solely loss. practice loss searches hardest negative within mini-batch iteration. explore impact approximation examined performance depends effective sample size searched negatives extreme case negative training hardest negatives entire training set. discussed sec. sampling negative smaller training potentially robust label errors. figure analysis behavior loss flickrk dataset training fig. compares loss loss notice that ﬁrst epochs loss achieves better performance however there-on loss leads much higher recall rates. fig. shows effect negative size performance. fig. shows effect negative sample size loss function. compare caption retrieval performance different negative sizes varied practice negative sizes smaller mini-batch size randomly sample negative mini-batch. cases mini-batch size smaller negative randomly sample mini-batch negative set. observe dataset optimal negative size around interestingly negative sets small slightly vse. understand this note loss still large sample size relatively high probability containing hard negatives. large negative sets model takes longer train ﬁrst epochs. using negative size performance dropped. small size dataset increase probability sampling hardest negative outliers. even though performance drops larger mini-batch sizes still performs better loss. given simplicity approach proposed loss function complement recent approaches sophisticated model architectures similarity functions. demonstrate beneﬁts loss applying another approach joint embeddings called order-embeddings vendrov main difference formulation asymmetric similarity function i.e. again simply replace loss loss. like experimental setting training c+rv. order++ learning schedule margin experiments. however training settings train order. start training learning rate epochs lower learning rate another epochs. like vendrov margin additionally vendrov takes absolute value embeddings computing similarity function replicate order. large multi layered cake candles sticking party decoration containing ﬂowers ﬂags candles. vse++ party decoration containing ﬂowers ﬂags candles. skateboarders doing tricks people watching young skateboarder displaying skills sidewalk near ﬁeld. vse++ young outside skateboarding together. figure examples test images retrieved captions vse++ ﬁnetune. value brackets rank highest ranked ground-truth caption. sample ground-truth captions. table reports results loss replaced loss. replicate results using order formulation slightly better results observe improvement order order++ caption retrieval compared improvement vse++ improvement c+rv training gain even higher improvement here. shows loss potentially improve numerous similar loss functions used retrieval ranking tasks. paper focused learning visual-semantic embeddings cross-modal image-caption retrieval. inspired structured prediction proposed loss based violations incurred relatively hard negatives compared current methods used expected errors vendrov performed experiments ms-coco flickrk datasets showed proposed loss signiﬁcntly improves performance datasets. observed improved loss better guide powerful image encoder resnet also guide better ﬁne-tuning image encoder. modiﬁcations vse++ model achieves state-of-the-art performance ms-coco dataset slightly best recent model flickrk dataset. proposed loss function used train sophisticated models using similar ranking loss training. references aishwarya agrawal jiasen stanislaw antol margaret mitchell lawrence zitnick devi parikh dhruv batra. visual question answering. international journal computer vision yoshua bengio j´erˆome louradour ronan collobert jason weston. curriculum learning. proceedings annual international conference machine learning pedro felzenszwalb ross girshick david mcallester deva ramanan. object detection discriminatively trained part-based models. ieee transactions pattern analysis machine intelligence andrea frome greg corrado shlens samy bengio jeff dean tomas mikolov devise deep visual-semantic embedding model. advances neural information processing systems micah hodosh peter young julia hockenmaier. framing image description ranking task data models evaluation metrics. journal artiﬁcial intelligence research sijin weichen zhang antoni chan. maximum-margin structured learning deep networks human pose estimation. proceedings ieee international conference computer vision tsung-yi michael maire serge belongie james hays pietro perona deva ramanan piotr doll´ar lawrence zitnick. microsoft coco common objects context. eccv springer richard socher andrej karpathy quoc christopher manning andrew grounded compositional semantics ﬁnding describing images sentences. association computational linguistics ioannis tsochantaridis thorsten joachims thomas hofmann yasemin altun. large margin methods structured interdependent output variables. journal machine learning research peter young alice micah hodosh julia hockenmaier. image descriptions visual denotations similarity metrics semantic inference event descriptions. association computational linguistics yukun ryan kiros rich zemel ruslan salakhutdinov raquel urtasun antonio torralba sanja fidler. aligning books movies towards story-like visual explanations watching movies reading books. iccv lawrence zitnick aishwarya agrawal stanislaw antol margaret mitchell dhruv batra devi parikh. measuring machine intelligence visual question answering. arxiv preprint arxiv. richard socher daniel christopher manning. bilingual word embeddings phrase-based machine translation. proceedings conference empirical methods natural language processing probability sampling hardest negative denote training image-caption pairs {cn} denote captions. suppose draw samples mini-batch permutation refer rankings captions according similarity function {cm}. assume permutations uncorrelated. given query image interested probability getting captions percentile mini-batch. assuming samples probability simply probability sample mini-batch percentile. probability tends zero exponentially fast goes hence large enough mini-batch size probability close sample negative captions mini-batch harder training set. probability percentile tends zero much slowly. probability goes relatively large mini-batch size. analysis shows strong signals randomly sampling mini-batches potentially robust outliers negative captions better describe image compared ground-truth caption.", "year": 2017}