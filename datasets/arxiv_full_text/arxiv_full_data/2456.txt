{"title": "Policy Gradient for Coherent Risk Measures", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "Several authors have recently developed risk-sensitive policy gradient methods that augment the standard expected cost minimization problem with a measure of variability in cost. These studies have focused on specific risk-measures, such as the variance or conditional value at risk (CVaR). In this work, we extend the policy gradient method to the whole class of coherent risk measures, which is widely accepted in finance and operations research, among other fields. We consider both static and time-consistent dynamic risk measures. For static risk measures, our approach is in the spirit of policy gradient algorithms and combines a standard sampling approach with convex programming. For dynamic risk measures, our approach is actor-critic style and involves explicit approximation of value function. Most importantly, our contribution presents a unified approach to risk-sensitive reinforcement learning that generalizes and extends previous results.", "text": "several authors recently developed risk-sensitive policy gradient methods augment standard expected cost minimization problem measure variability cost. studies focused speciﬁc risk-measures variance conditional value risk work extend policy gradient method whole class coherent risk measures widely accepted ﬁnance operations research among ﬁelds. consider static time-consistent dynamic risk measures. static risk measures approach spirit policy gradient algorithms combines standard sampling approach convex programming. dynamic risk measures approach actor-critic style involves explicit approximation value function. importantly contribution presents uniﬁed approach risk-sensitive reinforcement learning generalizes extends previous results. risk-sensitive optimization considers problems objective involves risk measure random cost contrast typical expected cost objective. problems important decision-maker wishes manage variability cost addition expected outcome standard various applications ﬁnance operations research. reinforcement learning risk-sensitive objectives gained popularity means regularize variability total cost/reward markov decision process many risk objectives investigated literature applied celebrated markowitz mean-variance model value-at-risk conditional value risk view taken paper preference risk measure another problem-dependent depends factors cost distribution sensitivity rare events ease estimation data computational tractability optimization problem. however highly inﬂuential paper artzner identiﬁed natural properties desirable risk measure satisfy. risk measures satisfy properties termed coherent obtained widespread acceptance ﬁnancial applications among others. focus coherent measures risk work. sequential decision problems mdps another desirable property risk measure time consistency. time-consistent risk measure satisﬁes dynamic programming style property strategy risk-optimal n-stage problem component policy t-th work present policy gradient algorithms coherent risk objective. approach applies whole class coherent risk measures thereby generalizing unifying previous approaches focused individual risk measures. consider static coherent risk total discounted return time-consistent dynamic markov coherent risk. main contribution formulating risk-sensitive policy-gradient coherent-risk framework. speciﬁcally provide related work risk-sensitive optimization speciﬁc risk functions studied recently several authors. studied exponential utility functions studied meanvariance models studied cvar static setting studied dynamic coherent risk systems linear dynamics. paper presents general method whole class coherent risk measures limited speciﬁc choice within class particular system dynamics. reference showed dynamic coherent risk objective essentially robust mdp. planning large scale mdps considered using approximation value function. many problems approximation policy space suitable sampling-based rl-style approach suitable approximations policy value function scales-up large continuous mdps. however make technique part method. optimization coherent risk measures thoroughly investigated ruszczynski shapiro stochastic programming case policy parameters affect distribution stochastic system reward function thus approach suitable problems. case mdps dynamic risk proposed dynamic programming approach. approach scale-up large mdps curse dimensionality. motivation risk-sensitive policy gradient methods refer reader preliminaries consider probability space outcomes σ-algebra representing events interested parameterized tunable parameter following suppress notation θ-dependent quantities. ease technical exposition paper restrict attention ﬁnite probability spaces i.e. ﬁnite number elements. results extended lp-normed spaces without loss generality details omitted brevity. denote space random variables deﬁned probability space paper random variable interpreted cost i.e. smaller realization better. denote point-wise partial order i.e. denote pθξz ξ-weighted expectation tuple state action spaces; bounded deterministic state-dependent cost; transition probability distribution; discount factor; initial state. actions chosen according θ-parameterized stationary markov policy denote trajectory length drawn following policy mdp. coherent risk measures risk measure function maps uncertain outcome extended real line intuitively condition ensure rationality single-period risk assessments ensures diversifying investment reduce risk; guarantees asset higher cost every possible scenario indeed riskier; also known ‘cash invariance’ means deterministic part investment portfolio contribute risk; intuition behind doubling position asset doubles risk. refer reader detailed motivation coherent risk. following representation theorem shows important property coherent risk measures fundamental gradient-based approach. theorem risk measure coherent exists convex bounded closed that result essentially states coherent risk measure expectation w.r.t. worst-case density function chosen adversarially suitable test density functions referred risk envelope. moreover means coherent risk measure uniquely represented risk envelope. thus sequel shall interchangeably refer coherent risk-measures either explicit functional representation corresponding risk-envelope. paper assume risk envelop given canonical convex programming formulation satisﬁes following conditions. assumption given policy parameter risk envelope coherent risk measure written constraint afﬁne function constraint convex function exists strictly feasible point denote sets equality inequality constraints respectively. furthermore given twice differentiable exists results easily extended random costs state-action dependent costs random initial states. dynamic markov risk study optimal policy stationary markov necessarily case static risk. results extended history-dependent policies stationary markov policies state space augmented accumulated cost. latter shown sufﬁcient optimizing cvar risk assumption implies risk envelope known explicit form. theorem case ﬁnite probability space coherent risk convex compact set. justiﬁes afﬁne assumption convex assumption moreover additional assumption smoothness constraints holds many popular coherent risk measures cvar mean-semi-deviation spectral risk measures risk measures deﬁned take account temporal structure random variable might have associated return trajectory case mdps. sense risk measures called static. dynamic risk measures hand explicitly take account temporal nature stochastic outcome. primary motivation considering measures issue time consistency usually deﬁned follows certain outcome considered less risky states world stage also considered less risky stage example shows importance time consistency evaluation risk dynamic setting. illustrates multi-period decision-making optimizing static measure lead time-inconsistent behavior. similar paradoxical results could obtained risk metrics; refer readers insights. markov coherent risk measures. markov risk measures introduced useful class dynamic time-consistent risk measures particularly important study risk mdps. -length horizon markov coherent risk measure static coherent risk measure satisﬁes assumption trajectory drawn policy important note static coherent risk a)µθ. limt→∞ well-deﬁned since cost bounded. also deﬁne assume markov risk measure i.e. evaluation static coherent risk measure allowed depend whole past. problem formulation paper interested solving risk-sensitive optimization problems. given random variable static coherent risk measure deﬁned section static risk problem given example setting correspond cumulative discounted cost trajectory induced policy parameterized dynamic markov coherent risk measure deﬁned dynamic risk problem given except limited cases reason hope neither tractable problems since dependence risk measure complex non-convex. work towards modest goal search locally optimal thus main problem trying solve paper calculate gradients srp’s drp’s objective functions interested non-trivial cases gradients cannot calculated analytically. static case would correspond non-trivial dependence dynamic risk also consider cases state space large tractable computation. approach dealing difﬁcult cases sampling. assume static case obtain i.i.d. samples random variable dynamic case assume state action obtain i.i.d. samples next state show sampling indeed used cases devise suitable estimators gradients. ﬁnally solve problems gradient estimate plugged standard stochastic gradient descent algorithm learning locally optimal solution structure dynamic risk think gradient estimator help estimate gradient ∇θρ∞. indeed follow idea begin estimating gradient static risk case. gradient formula static risk section consider static coherent risk measure propose sampling-based estimators ∇θρ. make following assumption policy parametrization standard policy gradient literature assumption likelihood ratio well-deﬁned bounded moreover approach implicitly assumes given easily calculated. also standard requirement policy gradient algorithms satisﬁed various applications queueing systems inventory management ﬁnancial engineering convexity strict feasibility assumption implies non-empty saddle points next theorem presents formula gradient ∇θρ. shall subsequently show formula particularly convenient devising sampling based estimators ∇θρ. theorem assumptions hold. saddle point proof theorem given supplementary material involves application envelope theorem standard ‘likelihood-ratio’ trick. demonstrate utility theorem several examples show generalizes previously known results also enables deriving useful gradient formulas. example cvar cvar level random variable denoted ρcvar popular coherent risk measure deﬁned formula recently proved case continuous distributions explicit calculation conditional expectation several additional smoothness assumptions. show holds regardless assumptions discrete case well. proof also considerably simpler. example mean-semideviation semi-deviation random variable deﬁned semi-deviation captures variation cost mean appealing alternative standard deviation distinguish variability upside downside deviations. mean-semideviation risk measure deﬁned ρmsd coherent risk measure following result proposition assumption proposition used devise sampling based estimator ∇θρmsd replacing expectations sample averages. algorithm along proof proposition supplementary material. section provide numerical illustration optimization mean-semideviation objective. general gradient estimation algorithm previous examples obtained gradient formula analytically calculating lagrangian saddle point plugging formula theorem consider general coherent risk which contrast cvar mean-semideviation cases lagrangian saddle-point known analytically. assume know structure risk-envelope given show case estimated using sample average approximation formula theorem assume given i.i.d. samples pθ;n i{ωi denote corresponding empirical distribution. also sample risk envelope deﬁned according replaced pθ;n consider following version optimization note deﬁnes convex optimization problem variables constraints. following assume solution computed efﬁciently using standard convex programming tools interior point methods denote solution denote corresponding multipliers obtained conλ programming algorithm propose following estimator gradient-based theorem thus gradient estimation algorithm two-step procedure involving sampling convex programming. following show conditions ∇θ;n consistent estimator ∇θρ. proof reported supplementary material. proposition assumptions hold. suppose exists compact cξ×cλ that lagrangian saddle points non-empty bounded. functions ﬁnite-valued continuous large enough non-empty w.p. assume that pθ;n converges w.p. point limn→∞ limn→∞ ∇θ;n w.p. assumptions proposition large rather mild. note implied slater condition assumption satisfying need risk well-deﬁned every empirical distribution natural requirement. since pθ;n always converges uniformly essentially requires smoothness constraints. remark particular summarize section seen exploiting special structure coherent risk measures theorem envelope-theorem style result theorem able derive sampling-based likelihood-ratio style algorithms estimating policy gradient coherent static risk measures. gradient estimation algorithms developed static risk measures used sub-routine subsequent treatment dynamic risk measures. section derive formula gradient markov coherent dynamic risk measure ∇θρ∞. approach based combining static gradient formula theorem dynamic-programming decomposition risk-sensitive value-function policy deﬁned slight abuse notation denotes markovcoherent dynamic risk initial state shown structure markov dynamic risk value function unique solution risk-sensitive bellman equation expectation taken next state transition. note deﬁnition thus ∇θρ∞ ∇θvθ. develop formula ∇θvθ; formula extends well-known policy gradient theorem developed expected return markov-coherent dynamic risk measures. make standard assumption analogous assumption static case. assumption likelihood ratio well-deﬁned bounded state denote saddle point corresponding state replacing replacing next theorem presents formula ∇θvθ; proof supplementary material. theorem assumptions theorem used develop actor-critic style sampling-based algorithm solving problem composed interleaved procedures critic given policy calculate risk-sensitive value function actor using critic’s theorem estimate ∇θρ∞ update space limitation restricts specifying full details actor-critic algorithm analysis. following highlight ideas results. full details refer reader full paper version provided supplementary material. critic main challenge calculating value function state space large dynamic programming cannot applied ‘curse dimensionality’. overcome this exploit fact equivalent value function robust modify recent algorithm estimate using function approximation. figure numerical illustration selection assets. probability density asset return. plots probability selecting asset training iterations policies respectively. iteration samples used gradient estimation. therefore propose two-phase sampling procedure estimate ﬁrst critic’s estimate derive -weighted transitions. state trajectory sample several next states estimate convergence analysis actor-critic algorithm gradient error incurred function approximation reported supplementary material. numerical illustration section illustrate approach numerical example. purpose illustration emphasize importance ﬂexibility designing risk criteria selecting appropriate risk-measure suits user’s risk preference problem-speciﬁc properties. consider trading agent invest three assets returns ﬁrst assets normally distributed return third asset pareto distribution mean return variance inﬁnite; heavy-tailed distributions widely used ﬁnancial modeling agent selects action randomly probability policy parameter. trained three different policies policy risk-neutral i.e. maxθ trained using standard policy gradient policy risk-averse mean-semideviation objective maxθ trained using algorithm section policy also risk-averse mean-standardalgorithm policies figure shows probability selecting asset training iterations. although highest mean return risk-averse policy chooses since lower downside expected. however heavy upper-tail policy opted choose instead. counter-intuitive rational investor avert high returns. fact case stochastically dominates presented algorithms estimating gradient static dynamic coherent risk measures using policy gradient style formulas combine sampling convex programming. thereby approach extends risk-sensitive whole class coherent risk measures generalizes several recent studies focused speciﬁc risk measures. technical side important future direction improve convergence rate gradient estimates using importance sampling methods. especially important risk criteria sensitive rare events cvar conceptual point view coherent-risk framework explored work provides decision maker ﬂexibility designing risk preference. numerical example shows ﬂexibility important selecting appropriate problem-speciﬁc risk measures managing cost variability. however believe approach much potential that. protect types uncertainties. representation duality coherent-risk naturally relates risk model uncertainty. similar connection made model-uncertainty mdps dynamic markov coherent risk. believe carefully shaping risk-criterion decision maker able take uncertainty account broad sense. designing principled procedure risk-shaping trivial beyond scope paper. however believe much potential risk shaping handling model misspeciﬁcation dynamic decision making.", "year": 2015}