{"title": "Factored Value Iteration Converges", "tag": ["cs.AI", "cs.LG"], "abstract": "In this paper we propose a novel algorithm, factored value iteration (FVI), for the approximate solution of factored Markov decision processes (fMDPs). The traditional approximate value iteration algorithm is modified in two ways. For one, the least-squares projection operator is modified so that it does not increase max-norm, and thus preserves convergence. The other modification is that we uniformly sample polynomially many samples from the (exponentially large) state space. This way, the complexity of our algorithm becomes polynomial in the size of the fMDP description length. We prove that the algorithm is convergent. We also derive an upper bound on the difference between our approximate solution and the optimal one, and also on the error introduced by sampling. We analyze various projection operators with respect to their computation complexity and their convergence when combined with approximate value iteration.", "text": "abstract. paper propose novel algorithm factored value iteration approximate solution factored markov decision processes traditional approximate value iteration algorithm modiﬁed ways. least-squares projection operator modiﬁed increase max-norm thus preserves convergence. modiﬁcation uniformly sample polynomially many samples state space. complexity algorithm becomes polynomial size fmdp description length. prove algorithm convergent. also derive upper bound diﬀerence approximate solution optimal also error introduced sampling. analyze various projection operators respect computation complexity convergence combined approximate value iteration. markov decision processes extremely useful formalizing solving sequential decision problems wide repertoire algorithms choose unfortunately mdps subject ‘curse dimensionality’ problem state variables size grows exponentially even though many practical problems polynomial-size descriptions. factored mdps rescue explosion oﬀer compact representation fmdp framework assumes dependencies factored several easy-to-handle components. mdps known parameters three basic solution methods value iteration policy iteration linear programming bertsekas tsitsiklis excellent overview). methods linear programming generally considered less eﬀective others. comes surprise eﬀective fmdps algorithms best knowledge linear programming another. furthermore classic value iteration algorithm known divergent function approximation used includes case fmdps too. paper propose variant approximate value iteration algorithm solving fmdps. algorithm direct extension traditional value iteration algorithm. furthermore avoids computationally expensive manipulations like linear programming construction decision trees. prove algorithm always converges ﬁxed point requires polynomial time reach ﬁxed accuracy. bound distance optimal solution also given. approximation. also give suﬃcient condition convergence approximate value iteration list several examples interest. section extend results previous section fmdps review related works section conclusions drawn section markov decision processes. characterized sixtuple ﬁnite states; ﬁnite possible actions; reward function agent reward agent choosing action state transition function probability agent arrives state given started upon executing action starting state agent; ﬁnally discount rate future rewards. policy agent mapping tells probability agent chooses action state policy agent parameters determine stochastic process experienced agent instantiation known easy optimal policy provided history modify transition probability distribution time instant value functions satisfy famous bellman equations later shall generalize concept state system. state system vector state variables fmdp description. reason already boldface vector notation preliminary description. exact value iteration. consider value iteration mdps uses bellman equations iterative assignment starts arbitrary value function iteration performs update sake better readability shall introduce vector notation. suppose states integers i.e. clearly value functions equivalent n-dimensional vectors reals indexed states. vector corresponding denoted value state similarly deﬁne n-dimensional column vector entries notations written matrix entries compactly well known max-norm contraction contraction factor consequently banach’s ﬁxed point theorem exact value iteration converges unique solution initial vector solution satisﬁes bellman equations furthermore required precision γv−v∗∞. iteration costs computation vt−v∗∞ steps. approximate value iteration. section shall review approximate value iteration linear function approximation ordinary mdps. results section hold general perform operations eﬀectively compact representations method directly applied domain factorized markovian decision problems underlining importance following considerations. suppose wish express value functions linear combination basis functions matrix entries denote weight vector basis functions step substitute right hand side cannot left hand side assignment general r.h.s. contained image space examples projections convergent divergent. section examine certain possibilities choosing projection arbitrary vector g-projection. linear operators represented matrix form shall denote least-squares projection. least-squares ﬁtting used almost exclusively projecting value functions term usually used sense least-squares projection. case chosen minimizes least-squares error corresponds linear projection moore-penrose pseudoinverse well known however method diverge. example divergence e.g. book bertsekas tsitsiklis reason simple matrix non-expansion l-norm lemma requires l∞-norm projection hold general case. l-norm projection also requires solution linear program interestingly projection operator non-expansion non-linear required solution linear program quadratic program step value iteration clearly cumbersome. hand linear also known incompatible shall focus operators avi-compatible linear. normalized linear mapping. arbitrary matrix deﬁne normalization matrix dimensions entries obtained dividing element corresponding corresponding column sums equal therefore maximal sense absolute value element increased resulting matrix probabilistic linear mapping. elements nonnegative row-sums equal assumes probabilistic interpretation. interpretation detailed appendix normalized least-squares projection. among linear operators guarantees best least-squares error therefore expect normalization plays similar role among avi-compatible linear projections. unless noted otherwise projection subsequently. according lemma error bound proportional projection error therefore represented space basis functions small error algorithm gets close optimum. furthermore lemma used check posteriori good basis functions are. improve basis functions iteratively. similar arguments brought guestrin association lp-based solution algorithm. mdps attractive solution time polynomial number states. consider however sequential decision problem variables. general need exponentially large state space model mdp. number states exponential size description task. factored markov decision processes avoid trap compact task representation. naive tabular representation transition probabilities would require exponentially large space however next-step value state variable often depends variables full transition probability obtained product several simpler factors. formal description introduce several notations function local-scope function deﬁned subspace state space index set. local-scope function extended trivially whole state space small local-scope functions represented eﬃciently take n|z| diﬀerent values. functions usually represented either tables dynamic bayesian networks. maximum size appearing local scopes bounded constant description length fmdp polynomial number variables value functions. optimal value function nm-dimensional vector. represent eﬃciently rewrite local-scope functions small domains. unfortunately general case factored form exists desired number basis functions domain local-scope basis function looking value function form quality approximation depends factors choice basis functions approximation algorithm. basis functions usually selected experiment designer general guidelines automate process. given basis functions apply number algorithms determine weights give short overview methods section here concentrate value iteration. exploiting factored structure value iteration. fmdps substitute factored form transition probabilities rewards factored approximation value function formula yields entries composed local-scope functions individual elements computed eﬃciently. means time required computation exponential sizes function scopes polynomial number variables making approach attractive. unfortunately matrices still exponentially large exponentially many equations overcome problem sampling show below. hand select suﬃciently large subset remaining system equations still over-determined. necessary size selected subset determined later small possible solution reduced equation system remain close original solution high probability. sake simplicity assume projection operator linear matrix sub-matrices corresponding performed eﬀectively matrices polynomial size. show solution sampled data close true solution high probability. theorem unique solution fmdp solution corresponding equation sampled matrices proof theorem found appendix derivation closely related work drineas colleagues although inﬁnity-norm instead l-norm. important diﬀerence exploit factored structure gaining exponentially better bound. resulting factored value iteration algorithm summarized table exact solution factored mdps infeasible. idea representing large using factored model ﬁrst proposed koller parr similar ideas appear already works boutilier dearden goldszmidt recently framework extended fmdps hybrid continuous-discrete variables factored partially observable mdps furthermore framework also applied structured mdps alternative representations e.g. relational mdps ﬁrst-order mdps algorithms solving factored mdps. major branches algorithms solving fmdps ﬁrst approximates value functions decision trees makes linear programming. decision trees provide represent agent’s policy compactly. koller parr boutilier present algorithms evaluate improve policies according policy iteration scheme. unfortunately size policies grow exponentially even decision tree representation program variables constraints here weights free parameters chosen freely following sense optimum solution independent choice provided greater approximate linear programming approach approximate value function linear combination basis functions resulting approximate variables constraints markov decision processes ﬁrst formulated tasks schweitzer seidmann approximate form farias guestrin show maximum local-scope functions computed rephrasing task non-serial dynamic programming task eliminating variables one. therefore transformed equivalent compact linear program. gain exponential necessarily cases according guestrin shown dechter exponential induced width cost network undirected graph deﬁned variables edge appear together original functions complexity algorithm course dependent variable elimination order problem structure. computing optimal elimination order np-hard problem elimination orders yielding induced tree width exist problems. furthermore approximate task solution longer independent optimal choice values known. approximate lp-based solution algorithm also guestrin dolgov durfee apply primal-dual approximation technique linear program report improved results several problems. approximate policy iteration algorithm also uses approximate reformulation based policy-evaluation bellman equation policy-evaluation equations however linear contain maximum operator need second costly transformation step. hand algorithm needs explicit decision tree representation policy. liberatore shown size decision tree representation grow exponentially. applications. applications fmdp algorithms mostly restricted artiﬁcial test problems like problem boutilier various versions sysadmin task york driving task guestrin koller gearhart kanodia show lp-based solution algorithm also capable solving practical tasks consider realtime strategy game freecraft. several scenarios modelled fmdps solved successfully. furthermore solution generalizes larger tasks similar structure. unknown environment. algorithms discussed assume parameters fmdp known basis functions given. case factorization structure fmdp known actual transition probabilities rewards apply factored versions r-max attempts exist obtain basis functions structure fmdp automatically. patrascu select basis functions greedily approximated bellman error solution minimized. poupart apply greedy selection selection criteria diﬀerent decision tree constructed partition state space several regions basis functions added region. approximate value function piecewise linear region. metric splitting related quality solution. sampling. sampling techniques widely used state space immensely large. lagoudakis parr sampling without theoretical analysis performance validity approach veriﬁed empirically. farias give thorough overview constraint sampling techniques used investigate least-squares solution overdetermined linear system prove suﬃcient keep polynomially many samples reach error high probability. introduce non-uniform sampling distribution variance approximation error minimized. however calculation probabilities requires complete sweep equations. paper proposed algorithm factored value iteration approximate solution factored markov decision processes. classical approximate value iteration algorithm modiﬁed ways. firstly least-squares projection operator substituted operator increase maxnorm thus preserves convergence. secondly polynomially many samples sampled uniformly state space. complexity algorithm becomes polynomial size fmdp description length. prove algorithm convergent give bound diﬀerence solution optimal one. also analyzed various projection operators respect computation complexity convergence combined approximate value iteration. knowledge ﬁrst algorithm provably converges polynomial time avoids linear programming. authors grateful zolt´an szab´o calling attention articles drineas research supported ‘new emergent world models individual evolutionary social learning’ grant opinions errors manuscript author’s responsibility necessarily reﬂect project members. projections various norms. wish know whether minw implies various values speciﬁcally interested cases fig. indicates implication hold case give rigorous proof claims. consider example values easy calculation shows hl∞∞ i.e. cases. shall prove following lemma lemma minw proof. multiple solutions minimization task consider vector minimum l-norm. l-sphere center radius figure projections various norms. vector projected onto image space i.e. subspace deﬁned consider smallest sphere around touches subspace radius sphere distance subspace tangent point projection point holds. shaded region indicates region v∞}. ensure convergence projected vector must fall shaded region. suppose indirectly without loss generality assume coordinate largest absolute value positive. therefore denote coordinate vector small enough cross polytope suﬃciently small ﬁrst statements trivial. third statement note vertex cross polytope consider cone whose vertex edges edges joining easy vector pointing origo contained cone |zi| consequently small enough vector contained image space vector chosen smallest l-norm image space inequality cannot sharp i.e. however strict inequality contradicts assumption thus completing proof. shall introduce auxiliary exact value iteration identical approximate value iteration original k-element state space states state considered discrete observation true state system action space discount factor identical corresponding items arbitrary element selected initial state. order obtain transition probabilities consider observing observing next time step observation infer hidden state system; state agent makes action transfers state according original mdp; that infer probability observation given hidden state consequently transition probability deﬁned total probability paths proof sampling theorem first prove useful lemma approximating product large matrices. rm×n rn×k suppose sample columns uniformly random also select corresponding rows constant scaling factor compensating dimension decrease sampled matrices. following lemma similar lemma estimate inﬁnity-norm instead l-norm. lemma rm×n rn×k integer uniformly random least sample size satisﬁes proof. variable assignment domain consider rows correspond variable assignment compatible i.e. identical components arbitrary individual product term apply previous lemma. note row/column samples product independence required within single matrix pairs. summing right-hand sides gives statement lemma. i.e. respect value function hw∗. help rewrite linear expression πhw∗. furthermore componentwise operator express eﬀect downsampled value function applying previous lemma times probability greater probability greater constants depending polynomially norm component local-scope functions independent informally theorem tells required number samples grows quadratically desired accuracy logarithmically required certainty furthermore dependence number variables slightly worse quadratic. means even number equations exponentially large i.e. select polynomially large random subset equations high probability solution change much.", "year": 2008}