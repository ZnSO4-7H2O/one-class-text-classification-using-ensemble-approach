{"title": "Blind Image Denoising via Dependent Dirichlet Process Tree", "tag": ["cs.CV", "stat.ML"], "abstract": "Most existing image denoising approaches assumed the noise to be homogeneous white Gaussian distributed with known intensity. However, in real noisy images, the noise models are usually unknown beforehand and can be much more complex. This paper addresses this problem and proposes a novel blind image denoising algorithm to recover the clean image from noisy one with the unknown noise model. To model the empirical noise of an image, our method introduces the mixture of Gaussian distribution, which is flexible enough to approximate different continuous distributions. The problem of blind image denoising is reformulated as a learning problem. The procedure is to first build a two-layer structural model for noisy patches and consider the clean ones as latent variable. To control the complexity of the noisy patch model, this work proposes a novel Bayesian nonparametric prior called \"Dependent Dirichlet Process Tree\" to build the model. Then, this study derives a variational inference algorithm to estimate model parameters and recover clean patches. We apply our method on synthesis and real noisy images with different noise models. Comparing with previous approaches, ours achieves better performance. The experimental results indicate the efficiency of the proposed algorithm to cope with practical image denoising tasks.", "text": "existing image denoising approaches assumed noise homogeneous white gaussian distributed known intensity. however real noisy images noise models usually unknown beforehand much complex. paper addresses problem proposes novel blind image denoising algorithm recover clean image noisy unknown noise model. model empirical noise image method introduces mixture gaussian distribution ﬂexible enough approximate diﬀerent continuous distributions. problem blind image denoising reformulated learning problem. procedure ﬁrst build two-layer structural model noisy patches consider clean ones latent variable. control complexity noisy patch model work proposes novel bayesian nonparametric prior called dependent dirichlet process tree build model. then study derives variational inference algorithm estimate model parameters recover clean patches. apply method synthesis real noisy images diﬀerent noise models. comparing previous approaches achieves better performance. experimental results indicate eﬃciency proposed algorithm cope practical image denoising tasks. image denoising fundamental problem studied decades area computer vision image processing previous approaches developed assumption noise follows homogeneous white gaussian distribution ﬁxed known standard deviation however noise models real images much complex rather one-parameter homogeneous white gaussian noise. stated tsin real images noise introduced multiple diﬀerent sources noise types neither gaussian homogeneous especially series band capture device setting well image acquiring environment unknown result statistics noise signal frequency scale spatial dependent. thus practical image denoising algorithms must ﬂexible enough eﬃciently cope complex noise even noise model provided. problem deﬁned blind image denoising. portilla proposed generalized version bls-gsm denoising method method relaxed assumption noise homogeneous white gaussian distributed adopting zeromean correlated gaussian model estimate noise wavelet subband. proposed segmentation-based algorithm jpeg image blind denoising cope intensity-dependent noise. method ﬁrst segmented input image small piecewise areas; introduced so-called noise level function model relation gray level pixel noise level. gaussian conditional random ﬁeld constructed denoising. recently lebrun introduced approach called multiscale noise clinic state-of-the-art performance. adaption nl-bayes similar method introduced zero-mean correlated gaussian noise model group algorithms made good eﬀorts investigating relation signal noise. however common assumption rely noise certain group patches pixels within image homogeneous gaussian distributed patches share certain features similar patches transform domain feature domain methods proposed diﬀerent schemes group patches pixels diﬀerent domains noisy image. noise eliminated conjunction thorough noise estimation method group followed adapted denoising method. methods achieved good performance researchers also suggested noise models still inﬂexible noise real images empirical image noise complex cope real noisy images following issues must considered well noise model existing algorithms still ﬂexible enough model dependency noise signal real noisy images. fig. shows example denoising result photo david hilbert algorithm eliminate complete noise loss generality noise model. instead investigating complex relation noise diﬀerent image features directly model empirical noise image multi-modal non-gaussian distribution ﬂexible enough cover wide varieties image noise models. natural selection distributions mixture gaussian distribution universal approximator continuous distributions also fundamental multi-modal model heterogeneous data recover clean image formulate blind image denoising learning problem estimate noisy patch model complex noise treat clean image patches latent variables estimate model learned. motivated facts clean natural image patches well modeled mixture gaussian distribution local subspaces introduce low-rank gaussian mixture model modeling underlying clean image patches. two-layer structural mixture model observed noisy patches derived accordingly. infer free parameters within model study introduces bayesian nonparametric techniques model construction. propose novel nonparametric prior called dependent dirichlet process tree prior structural mixture model. derive novel nonparametric structural mixture model approximated full posterior distribution model variational inference. fig. shows example denoising result method comparing proposed approach eﬃciently eliminate complex noise real images well-preserve detailed features. formulate blind image denoising framework ﬁrst build model noisy patches treat clean ones latent variables; second estimate parameters model well latent variables recover clean patches. conduct extensive experiments synthetic real noisy images method. experimental results show proposed noise model eﬃcient empirical noise real-world images proposed method cope empirical image denoising tasks real noisy images best performance. remainder paper organized follows sec. introduces background dirichlet process used build nonparametric model blind image denoising. sec. introduces novel framework blind image denoising. sec. derives elegant nonparametric prior sec. applies build bayesian nonparametric model blind image denoising. sec. presents derivation posterior inference algorithms learn clean patches noisy observations. sec. conducts extensive experiments method compared related works. sec. provides discussion study future work. figure three components tree-structured dependent mixture model. layer denotes mixture model consist certain components represented nodes. bottom layer component parameterized higher layer component parameterized children node bottom layer shares e.g. component potentially inﬁnite dimensional almost sure discrete even non-atomic generate discrete distributions continuous parameter spaces widely used prior mixture models linear superposition component distributions basic form dirichlet process mixture model given representation data considered drawn distribution parameter parameters drawn distribution ﬁnite suitable dimension number components mixture model learned represent data well parameters mixture. dirichlet process mixture foundation large number bayesian nonparametric models rely mixture representation data. even though abstract constructed several methods convenience inference. next review work inﬁnite-dimensional distribution. chinese restaurant process simple constructive representation imagine chinese restaurant inﬁnite many tables. customers arrive choose table according following random process considered proportion broken remainder unit-length stick size proportional random draws beta. weight component length inﬁnite pieces stick tends zero exponentially. nice feature procedure construction independent signiﬁcant advantage representation mean-ﬁeld variational inference. goal develop bayesian nonparametric method blind image denoising. formulate denoising problem learning procedure. constructed model noisy patches treated clean patch. generate procedure naturally split parts clean patch ﬁrst drawn clean patch model latent variable drawn noise model. identify signiﬁcant features clean natural image patches model clean patches. first investigated clean natural image patches eﬃciently modeled mog. attribute also used image processing algorithms second real-world high dimensional signals always well-modeled certain low-rank representation since natural signals rarely full rank following features propose mixture low-rank gaussian distribution components clean patch modeling. clean patches associated within component assumed subspace. parameters associated low-rank include -dimensional probability vector component weights unknown blind image denoising. patches sharing subspace model noise associated components. idea reasonable universal approximator continuous distribution similar noise modeling strategy also found model interpret procedure generating noisy patch follows ﬁrst clean patch generated subspace parameter that drawn component associated subspace parameter φtk. thus considered essentially tree-structured dependent mixture model. layer observed noisy patches divided groups. second layer group mixture components sharing i.e. latent clean patches noisy ones group drawn subspace. section propose statistical model procedure noisy patch model. clean patches considered latent variables. long above-mentioned hierarchies explored parameters latent variables well estimated. finally clean image recovered accordingly. building model adopt bayesian nonparametric methodology inference complexities layers build elegant dependent dirichlet process called dependent dirichlet process tree problem. ddpt eﬃciently capture dependency relation parameters tree-structure. then apply ddpt noisy patch modeling problem blind image denoising. used build nonparametric models rely mixtures represent distribution data. however process cannot capture structure among components. mixture model hierarchical dependency tree among mixture components layers component lowest-layer mixture model lies along path hierarchy. illustrating example shown fig. also explain here. here build ddpt prior structured multi-layer representation mixture model capture dependency relationship. dependent dirichlet process tree layers deﬁned imaging following scenario. suppose cities along travel route. ﬁrst city chinese figure representation chinese restaurant tourism process. layer corresponds city boxes chinese restaurants city. circle inﬁnite tables restaurant. tourist choose table restaurant parameter table dish ordered. restaurant inﬁnite number tables rest inﬁnite number chinese restaurants. table restaurants city card name another restaurant next city along travel-line recommendation. thus restaurants cities organized l-layer tree inﬁnite branches. tourist arrives ﬁrst city begins travel along route. plans chinese restaurant cities. enters chinese restaurant ﬁrst city selects table according sec. then follows recommendation table goes restaurant identiﬁed table next city selects table according crp. trip tourist visited exactly restaurants constitutes path restaurant ﬁrst city. name process chinese restaurant tourism process construct ddpt illustrating example shown fig. tourists ﬁnish travel schedule l-level tree potentially inﬁnite branches built collection tourists’ paths. ddpt used prior model hierarchies dependent mixture model discussed before. instance consider whose components gaussian distributed. component parameterized mean vector covariance matrix respectively. here deﬁne dependent follows layer represents mixture gaussian components mmog component share mean vector. second layer formed gaussian components mog. ddpt also represented stick-breaking construction. root stick’s length ﬁrst layer stick broken stick-breaking process sec. parameter i.e. length segment stick-breaking applied stick segments ﬁrst layer e.g. layer stick figure dirichlet process stick-breaking procedure linear partitioning. two-layer ddpt stick breaking process. stick unit length partitioned stick segments stick-breaking process. stick segment unit length extra stick-breaking process performed. proposed ddpt model capture dependency among mixture components area bayesian nonparametrics. hierarchical introduced sharing mechanism allow sharing mixture components multiple dirichlet process mixture models. nested chinese restaurant process tree-structured extension hierarchical clustering hierarchies built nested similar ours. dependency parameters among components modeled combination models allow sharing mixture components explicitly. diﬀerent sub-trees. approach modeling dependencies among mixture components designed mixture mog. proposes diﬀerent base distributions mog. base distributions generated higher-layer approaches achieve excellent performance consideration. problems address focus building hierarchies clustering diﬀerent ours resulting distinction ddpt previous approaches. apply proposed ddpt blind image denoising model noisy patches recover underlying clean patches. two-layer structural mixture model built follows. patches represented groups layer represent subspaces group represented mixture component group parameterized φkt. long parameters estimated clean patch model noise model recovered. then recover clean patch projecting noisy onto clean patch model. mixture parameter drawn second layer group base distribution concentration parameter noisy patches drawn model stick-breaking construction follows propose low-rank underlying clean patch modeling. speciﬁcally clean patch assumed follow samples drawn gaussian component local subspace. model low-rank property gaussian component enforcing covariance matrix low-rank positive semideﬁnite matrix. d-dimensional zero-mean gaussian distribution identity covariance matrix. similar decomposition method also seen area dimensional reduction decomposition model low-rank feature intuitive method enforce matrix low-rank since rank rank. nice attribute favored model samples drawn model also low-rank representable. given samples decomposed random variable whose rank rank rank) rank rank rank gaussian component respectively dimension utk. following setting introduce conjugate prior gaussian distribution base distribution following generative process approach assume clean patches several subspaces noise associated subspace distributed mog’s eﬃciency approximating continuous density. thus marginal noise distribution approach convex combination several mogs remains mog. following results mean noise zero. marginal mean noise subspace zero accordingly. previous approaches noise assumed dependent signal. here show noise model approaches interpreted certain constraints well conﬁrms using noise modeling reasonable. noise wavelet subband gaussian distribution. thus marginal noise model essentially constraint noise subband drawn single gaussian component. liu’s approach assume noise model density-dependent gaussian distribution also essentially. lebrun’s approach assume noise patch well nearby patches feature domain gaussian distributed. marginal noise distribution noisy image well. contrast noise model general. without assumption dependency relation signal noise algorithm estimates empirical noise model noisy patches directly. speciﬁcally ﬁrst layer mixture divides noisy patches groups respect structure underlying clean patches. within group noisy patch considered addition independent signals rank clean patch noise. clean patch well recovered bayesian approaches. section propose variational approach approximate posterior distributions latent variables parameters model image denoising. given observable data bayesian posterior distributions latent parameters represented target posterior distribution second constant respect thus ﬁnding target posterior distribution equivalent minimizing objective function respect estimation low-rank groups parameters involved representation low-rank groups at}t prior distributions derive posterior distributions }∪{µt at}t figure performance algorithm images bsds left right clean image noisy image white gaussian noise result k-svd sure-guided nl-bayes approach. zoom examine details. recovery method also interpreted novel variational bayesian wiener filtering utilized recover signals contaminated unknown noise. utilized generalize denoising algorithm based wiener ﬁltering blind image denoising including section extensively evaluate approach comparing number state-of-the-art algorithms. experimental results show method handle niosy images large variety noise models real applications superior performance compared previous works. throughout work parameter follows patch size extract patches input image algorithm conventional patch based denoising algorithms ddpt top-level concentration parameters second-level concentration parameter hyper-parameters simple settings approach performs stably well following experiments. initialize parameters model follows. ﬁrst perform k-means++ algorithm divide patches groups initialize mean group. number components group initialize getting average component. perform singular value decomposition initialize projection patch subspace within component. group calculate residual patch projection perform k-means++ result initialization scheme parameter initialization experiments robust diﬀerent noisy images. method used handle noisy images diﬀerent noise models. ﬁrst test performance method images contaminated homogeneous white gaussian noise general assumption noise traditional non-blind denoising algorithms. here compare method several stateof-the-art non-blind denoising algorithms designed homogeneous white gaussian noise k-svd sure-guided nl-bayes test algorithms synthesis noisy http//www.cs.technion.ac.il/~elad/software/ http//www.ipol.im/pub/art/// http//www.cs.tut.fi/~foi/gcf-bmd/index.htmlref_software http//www.ipol.im/pub/art/// images produced adding homogeneous white gaussian noise diﬀerent deviation images benchmark datasets clean images bsds competitive algorithms non-blind provide true noise intensity noisy image input algorithms. blind approach algorithm inference noise intensity automatically. evaluate performance algorithm introduce measurements peak signal-to-noise ratio structural similarity index used measure similarity denoised image clean one. larger value either psnr ssim indicates performance better. table. illustrates numerical performance algorithms synthesis images contaminated noise intensity observed that measurements algorithm achieves competitive performance compared state-of-the-art algorithms especially images contaminated large noise intensities fig. shows denoising results images bsds noise intensity visualization. modeling clean patches algorithm eﬃciently eliminate noise reserving detailed features especially noise intensity large. speciﬁcally method reserve patterns grass image tree others tend smooth features. practical image denoising underlying noise model real noisy images diﬀerent homogeneous white gaussian noise blind denoising algorithm capability handle images contaminated diﬀerent noise. section propose experiments synthesis data show approach handle images contaminated diﬀerent types noise even noise model provided. noisy images produced adding following types zero-mean noise clean images bsds left down right down. four parts contaminated heterogeneous gaussian noise laplace noise white gaussian noise uniform noise respectively resulting position dependent noise. apply methods noisy images contaminated types noise comparison state-of-the-art blind image denoising approach also claimed able handle heterogeneous non-gaussian noise multiscale noise clinic blind image denoising approach code online available). multiscale approach free parameter e.g. number scales researchers claimed handle images range fair comparison noisy image multiscale approach number scales select best denoising result. method parameters ﬁxed introduced before. table illustrates numerical performance algorithms. observed method better multiscale respect psnr ssim signiﬁcant margin types noise diﬀerent parameters. fig. shows example denoising results image tid. observed multiscale approach tends smooth detailed features moreover noise eliminated completely noise heterogeneous formed image intensity bounded value noisy figure comparison contaminated homogeneous white gaussian noise psnr multiscale heterogeneous noise psnr multiscale laplace noise psnr multiscale uniform noise psnr multiscale combined noise psnr multiscale part fig. caused less generality noise model comparison ﬂexibility approach well eliminate noise features well preserved. shows approach general enough handle noisy images contaminated diﬀerent noise model. show eﬃciency approach real-world problems demonstrate performance method handling real noisy images comparison method algorithm applied images various noise models. ﬁrst test method using pictures taken cameras remarkable noise. fig. taken nikon apply algorithms seen better eliminate noise without introducing artifacts. fig. shows performance another example noisy images ‘bear’ ‘postcard’ whose noise relatively normal. observed that comparing result better eliminate noise preserve features. speciﬁcally features marked green boxes smoothed multiscale approach well reserved ours. meanwhile within blue noise well handled multiscale approach well eliminated ours. apply algorithms recovery scanned photographs screen-shots movies. noise images generally large grain altered processing including scanning jpeg encoding. fig. show several examples results obtained algorithms kind noise. observed eliminate kind noise eﬃciently. shows noise model better handle large even structural noise real images. comparison also eliminate noise completely. fig. shows obtained results another photographs david hilbert morris downloaded wikipedia proﬁles. approach achieves better performance images. contrast eliminate noise completely. phenomena appears denoising results images well. shows eﬃciency algorithm handling real noisy images even noise complex. proposed learning-based approach automatically recover clean image observed noisy one. noise model unknown modeled mog. clean patches assumed several local subspaces. built two-layer structural mixture model noisy patches treat clean ones latent variables. build model proposed dependent dirichlet process tree prior novel nonparametric prior introduces mechanism parameters sharing among mixtures. variational inference algorithm proposed accordingly estimate model clean patches latent variables. extensive experiments conducted test performance approach images contaminated diﬀerent noise. method achieved best performance among competitive algorithms preserving detailed features eliminating noise diﬀerent models. features make method modeled complex image ﬁrst time image noise modeling. idea used generate previous non-blind image denoising approaches develop blind image denoising algorithms images unknown noise. developed ddpt model prior noisy patch model. prior introduces mechanisms parameter sharing among mixture components. though focused blind image denoising paper proposed model utilized diﬀerent applications e.g. ﬁtting topic models discovering taxonomies images", "year": 2016}