{"title": "Mental Sampling in Multimodal Representations", "tag": ["cs.LG", "cs.AI"], "abstract": "Both resources in the natural environment and concepts in a semantic space are distributed \"patchily\", with large gaps in between the patches. To describe people's internal and external foraging behavior, various random walk models have been proposed. In particular, internal foraging has been modeled as sampling: in order to gather relevant information for making a decision, people draw samples from a mental representation using random-walk algorithms such as Markov chain Monte Carlo (MCMC). However, two common empirical observations argue against simple sampling algorithms such as MCMC. First, the spatial structure is often best described by a L\\'evy flight distribution: the probability of the distance between two successive locations follows a power-law on the distances. Second, the temporal structure of the sampling that humans and other animals produce have long-range, slowly decaying serial correlations characterized as $1/f$-like fluctuations. We propose that mental sampling is not done by simple MCMC, but is instead adapted to multimodal representations and is implemented by Metropolis-coupled Markov chain Monte Carlo (MC$^3$), one of the first algorithms developed for sampling from multimodal distributions. MC$^3$ involves running multiple Markov chains in parallel but with target distributions of different temperatures, and it swaps the states of the chains whenever a better location is found. Heated chains more readily traverse valleys in the probability landscape to propose moves to far-away peaks, while the colder chains make the local steps that explore the current peak or patch. We show that MC$^3$ generates distances between successive samples that follow a L\\'evy flight distribution and $1/f$-like serial correlations, providing a single mechanistic account of these two puzzling empirical phenomena.", "text": "resources natural environment concepts semantic space distributed patchily large gaps patches. describe people’s internal external foraging behavior various random walk models proposed. particular internal foraging modeled sampling order gather relevant information making decision people draw samples mental representation using random-walk algorithms markov chain monte carlo however common empirical observations argue simple sampling algorithms mcmc. first spatial structure often best described lévy ﬂight distribution probability distance successive locations follows power-law distances. second temporal structure sampling humans animals produce long-range slowly decaying serial correlations characterized /f-like ﬂuctuations. propose mental sampling done simple mcmc instead adapted multimodal representations implemented metropolis-coupled markov chain monte carlo ﬁrst algorithms developed sampling multimodal distributions. involves running multiple markov chains parallel target distributions different temperatures swaps states chains whenever better location found. heated chains readily traverse valleys probability landscape propose moves far-away peaks colder chains make local steps explore current peak patch. show generates distances successive samples follow lévy ﬂight distribution /f-like serial correlations providing single mechanistic account puzzling empirical phenomena. many complex domains vision motor control language categorization common-sense reasoning human behavior consistent predictions bayesian models bayes’ theorem prescribes simple normative method combine prior beliefs information make inferences world. however sheer number hypotheses must considered complex domains makes exact bayesian inference intractable. instead must individuals performing kind approximate inference sampling perform approximation bayesian models complex problems makes many difﬁcult computations easy instead integrating vast hypothesis spaces samples hypotheses drawn posterior distribution. computational cost samplebased approximations scales number samples rather dimensionality hypothesis space though using small numbers samples result particular biases inference. interestingly biases inference introduced using small number samples match biases observed human behavior. example probability matching anchoring effects many reasoning fallacies explained way. however consensus exact nature algorithm used sample human mental representations. previous work posited people either direct sampling markov chain monte carlo sample posterior distribution hypotheses paper demonstrate algorithms cannot explain empirical effects found wide variety tasks. particular algorithms produce distances samples follow lévy ﬂight distribution separately produce autocorrelations follow scaling. sampling algorithm match empirical effects note mental representations shown patchy high probability regions separated large regions probability. compare ﬁrst algorithms developed sampling multimodal distributions metropolis-coupled mcmc demonstrates produces empirical phenomena. previously lévy ﬂight distributions scaling explained separately result efﬁcient search signal self-organizing behavior respectively provide ﬁrst account explain phenomena result purposeful mental activity. real world resources rarely distributed uniformly environment. food water critical nature resources often occur spatially isolated patches large gaps between. therefore humans animals’ foraging behaviors adapt patchy environments. fact foraging behaviors observed display lévy ﬂight class random walk whose step lengths follow heavy-tailed power-law distribution lévy ﬂight distribution probability executing jump length given values correspond normalizable probability distributions. examples mobility patterns following lévy ﬂight recorded albatrosses marine predators monkeys humans lévy ﬂights advantageous patchy environments resources sparsely randomly distributed probability returning previously visited target site smaller standard random walk. patchy environment lévy ﬂights visit target sites random walk interestingly proven foraging optimal exponent regardless dimensionality space target sites sparse visited number times forager detect remember target site close vicinity remarkably mental representations concepts also patchy distance mental samples also follows lévy ﬂight distribution. example semantic ﬂuency tasks retrieved animals tend form clusters task also found produce lévy ﬂight distributions inter-response intervals considered measure distance samples making reasonable assumption linear relationship mental distance. there various ways make link distance samples. assume takes longer transition sample away mental space. second assume generating sample takes ﬁxed amount time unreported samples generated reported sample sampler travelled unreported samples generated; unreported samples plausible task participants given credit animal name report. besides spatial structure distance successive locations following power-law distribution number studies reported temporal structure many cognitive activities contains long-range slowly decaying serial correlations. correlations tend follow scaling frequency spectral power considered scaling. power spectra derived submitting time series fourier analysis. noise also known pink ﬂicker noise varies predictability intermediately white noise brown noise note lévy ﬂights random walks produce noise noise instead. /f-like temporal ﬂuctuations human cognition ﬁrst reported time estimation spatial interval estimation tasks participants asked repeatedly estimate pre-determined time interval second spatial interval inch subsequent studies shown scaling laws response times mental rotation lexical decision serial visual search parallel visual search well time switch different percepts looking bistable stimulus given sampling described lévy ﬂight spatially autocorrelations investigate sampling algorithms capture spatial temporal structure human cognition. time interval estimation spatial interval estimation mental rotation lexical decision serial search parallel search memory retrieval task natural scene perception main ﬁndings power spectra slopes power spectra slope power spectra slope power spectra slope power spectra slope power spectra slope power-law exponents movement trajectories follow noise lévy ﬂight consider three possible sampling algorithms might employed human cognition direct sampling random walk metropolis metropolis-coupled mcmc deﬁne independently drawing samples accord posterior probability distribution. efﬁcient algorithm sampling three possible implement human cognition often requires calculating intractable normalizing constants scale exponentially dimensionality hypothesis space used explain biases human cognition probability matching mcmc algorithms bypass problem normalizing constant simulating markov chain transitions states according ratio probability hypotheses deﬁne classical metropolis-hastings mcmc algorithm thought random walker exploring probability landscape hypotheses preferentially climbing peaks posterior probability distribution however limited number samples unlikely reach modes probability distribution separated large regions probability. leads biased approximations posterior distribution random walks used model clustered responses memory retrieval particular used model multistable perception anchoring effect various reasoning biases third algorithm also known parallel tempering replica-exchange mcmc ﬁrst algorithms successfully tackle problem multimodality involves running markov chains parallel different temperature general temperature interest target distribution unchanged. purpose heated chains traverse valleys probability landscape propose moves far-away peaks colder chains make local steps explore current probability peak patch. decides whether swap states randomly chosen chains every iteration particular swapping chain accepted rejected according metropolis rule; hence name metropolis-coupled mcmc coupling induces dependence among chains chain longer markovian. stationary π/ti samples cold chain approximate posterior distribution pseudocode presented below. note reduces number parallel chains section evaluate whether empirical effects lévy ﬂights autocorrelations produced direct sampling random walk metropolis metropolis-coupled mcmc algorithms. simulated patchy environment nmode gaussian mixtures means uniformly generated dimensions covariance matrix ﬁxed identity matrix mixtures. method produce patchy environment multimodal probability landscape ﬁrst positions algorithm found panel figure empirical ﬂight distances obtained calculating euclidean distance consecutive positions sampler. positions cold chain used. power-law distributions produce straight lines log-log plot. therefore power-law exponents ﬁtted linear regression window-averaged log-binned ﬂight distance data used non-overlapping windows evenly split x-axis cell means represented yellow ﬁlled dots bottom panel figure fitting cell means provides lower-variance method estimating slope ﬁtting log-binned data directly. figure shows reproduce distributional property ﬂight distance lévy ﬂight estimated power-law exponent produced values outside range lévy ﬂight. figure searching behavior simulated patchy environment component gaussian mixture. trajectory ﬁrst positions log-log plot ﬂight distance best-ﬁtted lines used estimate levy ﬂight exponent based cell means using non-overlapping windows log-binned data plots algorithm. gaussian proposal distribution identity covariance matrix. plots algorithm parallel chains cold chain shown here. gaussian proposal distributions chains identity covariance matrix. algorithms ﬁrst samples used. investigated impact spatial sparsity estimated power-law exponents. simulation number gaussian mixture used range varied. spatial sparsity computed mean distance gaussian modes. small moderate spatial sparsity found positive relationship spatial sparsity estimated power-law exponents range produced power-law exponents range reported human mental foraging studies failed three algorithms spatial sparsity great single mode explored large jumps made. also checked whether really suitable explore patchy mental representations rwm. simulated patchy environment used identical gaussian mixtures identity covariance matrix optimal sampling algorithm visit mode equally often hence produce uniform distribution visit frequencies modes. effectiveness exploring representation examined computing kullback-leibler divergence uniform distribution modes relative frequency often algorithm visited mode discrete uniform distribution nmode number identical gaussian mixtures empirical frequency visited modes time samples assigned closest mode determining empirical frequencies. faster divergence algorithm reaches zero effective algorithm exploring underlying environment algorithm serves benchmark algorithms. shown figure quickly catches lags behind exploring patchy environment. figure estimated power-law exponents ﬂight distance distributions three sampling algorithms manipulating spatial sparsity gaussian mixture environment. spatial sparsity measurement deﬁned mean distance modes. three algorithms used settings figure dashed lines show range human data. divergence mode visiting true distribution three sampling algorithms. underlying patchy environments three algorithms. simulated lévy ﬂight proposal distribution. darker colors represent higher spatial sparsities. dashed lines show range human data. course seem simply using wrong proposal distribution rwm. instead using gaussian proposal distribution lévy ﬂight proposal distribution straightforwardly produce lévy ﬂights posterior distribution uniform entire space however patchy environment lévy ﬂight proposal distribution typically produce lévy ﬂight distribution distances samples estimated power-law exponents range human data also seen figure different spatial sparsities. reason long jumps proposal distribution unlikely successful long jumps often propose states regions nearly zero posterior probability. typical interval estimation task requests participants repeatedly produce estimation target interval many repeated trials instance participants ﬁrst given example target interval repeated judgments without feedback trials. time series produced human subjects showed noise exponent close however log-log plot human data typically observed ﬂatten highest frequencies effect explained result processes fractional brownian motion combined white noise highest frequencies figure shows example time series ﬁrst samples generated used simple gaussian target distribution simulation distribution responses produced participants indistinguishable gaussian note initiated mode gaussian distribution burn-in period simulation. results show produces noise whereas produces white noise closest brown noise tends generate brown noise because every proposed sample accepted algorithm reduces ﬁrst-order autoregressive process shown simulation figure gaussian width becomes much greater width gaussian proposal distribution produces brown noise. figure sampling unimodal gaussian power spectra traceplot sample distribution bottom. best-ﬁtted lines power spectra estimated based block-averaged periodograms plots algorithm. plots algorithm parallel chains cold chain shown here. result similar using parallel chains restrict swapping neighboring chains only. algorithms here ﬁrst samples used. contrast tendency produce noise acceptance rate high. shown three processes widely distributed autoregressive coefﬁcients produces approximation noise higher-temperature chains thought roughly similar processes lower autoregressive coefﬁcients explain asymptotic behavior noise. also interesting single process able produce slope lower frequencies well ﬂattening slope higher frequencies ascribed different processes reason produces result appears chains similar temperatures states similar posterior probability repeatedly swap back forth produce high frequency oscillations coldest chain. lévy ﬂights advantageous patchy world observed many foraging task humans animals. random walk gaussian steps produce occasional long-distance jump lévy ﬂight does. however swapping scheme parallel chains enables produce lévy-like scaling ﬂight distance distribution. additionally figure estimated slopes power spectra related ratio gaussian width proposal step size. ratio acceptance rate proposed sample low; opposite case high ratio. asymptotic behaviors noise brown noise white noise. produces long-range slowly-decaying temporal correlations scaling. long-range dependence rules sampling algorithm draws independent samples posterior distribution since sample sequence would serial correlation also rules current sample solely depends previous sample. results suggest algorithms people sample mental representations complex like instead adapted sampling multimodal distributions. however people adapted multimodal distributions behavior appears temporal pattern even actually sampling unimodal distribution. gilden’s experiments overall distribution estimated intervals multimodal instead indistinguishable gaussian distribution assuming posterior distribution hypothesis space also unimodal somewhat inefﬁcient rather simple mcmc. potentially brain hardwired particular algorithms slow adapt unimodal representations difﬁcult know distribution unimodal rather single mode patchy space. previous explanations scale-free phenomenon human cognitions self-organized criticality argue noise generated interactions many simple processes produce hallmarks complexity explanations assume mixture scaled processes like noise attention noise ability perform cognitive tasks approaches argue noise general property cognition empirical effects. explanation scale-free process mechanistic assuming reﬂect cognitive need gather vital resources multimodal world. autocorrelations make samplers less effective sampling simple distributions need tolerated multimodal world order sample isolated modes. course claim sampling algorithm able produce noise lévy ﬂights. possible algorithms deal better multimodality mcmc running multiple non-random walk markov chains parallel hamiltonian monte carlo could produce similar results. future work explore algorithms match human data.", "year": 2017}