{"title": "Face Deidentification with Generative Deep Neural Networks", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Face deidentification is an active topic amongst privacy and security researchers. Early deidentification methods relying on image blurring or pixelization were replaced in recent years with techniques based on formal anonymity models that provide privacy guaranties and at the same time aim at retaining certain characteristics of the data even after deidentification. The latter aspect is particularly important, as it allows to exploit the deidentified data in applications for which identity information is irrelevant. In this work we present a novel face deidentification pipeline, which ensures anonymity by synthesizing artificial surrogate faces using generative neural networks (GNNs). The generated faces are used to deidentify subjects in images or video, while preserving non-identity-related aspects of the data and consequently enabling data utilization. Since generative networks are very adaptive and can utilize a diverse set of parameters (pertaining to the appearance of the generated output in terms of facial expressions, gender, race, etc.), they represent a natural choice for the problem of face deidentification. To demonstrate the feasibility of our approach, we perform experiments using automated recognition tools and human annotators. Our results show that the recognition performance on deidentified images is close to chance, suggesting that the deidentification process based on GNNs is highly effective.", "text": "faculty computer information science university ljubljana veˇcna ljubljana slovenia department computer engineering istanbul technical university maslak istanbul turkey faculty electrical engineering university ljubljana trˇzaˇska cesta ljubljana slovenia *blaz.medenfri.uni-lj.si abstract face deidentiﬁcation active topic amongst privacy security researchers. early deidentiﬁcation methods relying image blurring pixelization replaced recent years techniques based formal anonymity models provide privacy guaranties time retaining certain characteristics data even deidentiﬁcation. latter aspect particularly important allows exploit deidentiﬁed data applications identity information irrelevant. work present novel face deidentiﬁcation pipeline ensures anonymity synthesizing artiﬁcial surrogate faces using generative neural networks generated faces used deidentify subjects images video preserving non-identity-related aspects data consequently enabling data utilization. since generative networks adaptive utilize diverse parameters represent natural choice problem face deidentiﬁcation. demonstrate feasibility approach perform experiments using automated recognition tools human annotators. results show recognition performance deidentiﬁed images close chance suggesting deidentiﬁcation process based gnns highly effective. last decades extensive amount video data recorded stored. since access exploitation data difﬁcult monitor alone prevent appropriate measures need taken ensure data misused privacy people adequately protected. popular approach towards privacy protection image video data deidentiﬁcation. ribari´c deﬁne deidentiﬁcation process concealing removing personal identiﬁers source content order prevent disclosure data unauthorized purposes. video data example translate blurring pixelation facial areas represent early deidentiﬁcation examples. naive methods typically useful preventing humans recognizing subjects videos less successful automated recognition techniques repeating deidentiﬁcation process test data still enables automated recognition i.e. parrot attack thus successful deidentiﬁcation images videos advanced techniques needed. another shortcoming naive deidentiﬁcation techniques fact information contained data typically removed even information related identity. raises question data utility. deidentiﬁed data useful purposes require identity information example rely gender information information needs preserved even deidentiﬁcation. recent deidentiﬁcation approaches therefore focus ways removing identity information images videos still retaining non-identity related information paper follow recent trends present deidentiﬁcation approach exploiting generative neural networks represent contemporary generative models capable synthesizing photo-realistic artiﬁcial images object based supplied high-level information. similarly existing deidentiﬁcation techniques replace original faces input data surrogates generated small number identities. however instead synthesizing surrogate faces pixel averaging prior work combine identities generate artiﬁcial surrogates deidentiﬁcation. ﬂexibility also allows parameterize generation process respect various appearancerelated characteristics synthesize faces different appearances property ensures deidentiﬁcation approach able conceal identity individuals also preserve utility data. demonstrate feasibility proposed deidentiﬁcation pipeline extensive experiments chokepoint dataset experimental results show gnns viable solution problem face deidentiﬁcation able generate realistic visually convincing deidentiﬁcation results. furthermore deidentiﬁed faces offer suitable level privacy protection evidenced experiments number contemporary recognition models well humans. summary make following contributions introduce face deidentiﬁcation pipeline exploits gnns produce artiﬁcial surrogate faces deidentiﬁcation offers level ﬂexibility generation process available existing deidentiﬁcation approaches. present qualitative evaluation proposed pipeline challenging data captured real surveillance scenario discuss advantages limitations deidentiﬁcation approach. demonstrate efﬁcacy proposed pipeline comprehensive quantitative experiments several state-of-the-art recognition techniques literature human annotators. existing approaches deidentiﬁcation often implement formal privacy protection models k-anonymity l-diversity t-closeness among these k-anonymity models likely received attention area face deidentiﬁcation resulted socalled k-same family algorithms algorithms operate closed static facial images substitute image average closest identities computed closed images. several images replaced average face data anonymity certain level guaranteed. number k-same variants presented literature including original k-same algorithm k-same-select ksame-model name few. majority techniques implemented using active appearance models another example deidentiﬁcation technique using aams recently presented jourabloo here authors combine facial-attribute face-veriﬁcation classiﬁers joint objective function. optimizing objective function optimal weights estimated deidentiﬁed original image many common attributes possible time classiﬁed different subjects. q-far deidentiﬁcation approach also based follow k-same principle proposed samarˇzija ribari´c combines face deidentiﬁcation pose estimation. authors cover different facial orientations ﬁtting multiple aams achieve anonymity replacing original faces surrogates sufﬁciently initial identities. zhang present method controllable face deidentiﬁcation demonstrate high degree control different attributes deidentiﬁed faces similar approach able alter retain speciﬁc aspects target appearance. another example related aam-based techniques recently proposed here authors propose k-diff-furthest algorithm related k-anonymity model k-same family techniques differs ability track individuals deidentiﬁed video since deidentiﬁed faces distinguishable properties. experimental evaluation performed authors shows algorithm capable maintaining diversity deidentiﬁed faces keeps distinguishable original faces. however approach deal data utility aspect e.g. expression preservation. different aam-based deidentiﬁcation approaches brki´c propose deidentiﬁcation method based style-transfer. authors describe pipeline enables altering appearance faces videos artistic style replacement performed input data thus making automatic recognition difﬁcult. another interesting deidentiﬁcation approach presented chriskos which contrary deidentiﬁcation methods hinders recognition automatic recognition algorithms human observers. authors utilize projections hyperspheres order defeat classiﬁers preserving enough visual information enable human viewers correctly identify individuals. block-diagram deidentiﬁcation pipeline presented fig. procedure starts face detection step takes image video frame input locates candidate facial regions input data deidentiﬁcation. detected region feature vector computed using state-of-the-art deep face recognition network i.e. network matched ﬁxed gallery subjects. based matching procedure k-closest identities gallery data selected generative network synthesize artiﬁcial face visual characteristics selected identities. finally artiﬁcially generated face blended input image conceal original identity. fig. block diagram deidentiﬁcation pipeline. procedure uses generative neural network generate synthetic faces used deidentiﬁcation. generated face combination identities gallery data closest input face. appealing characteristic deidentiﬁcation pipeline ﬂexibility able synthesize high-resolution realistic-looking faces various appearances. here generation process governed small number appearance-related parameters control visual characteristics synthesized faces pose skin color gender identity facial expression alike. thus setup able generate artiﬁcial faces predeﬁned identities facial expressions gender forth alter time. instance goal preserve facial expressions faces could automatically recognize facial expressions input image recognition result input gnn. network would generate synthetic image predeﬁned expression. similar procedure could used retain alter visual characteristic input faces contribute towards preservation data utility main goals contemporary deidentiﬁcation technology. even though approach similar nature k-same family algorithms implement k-anonymity protection model important differences invalidate k-anonymity model assumptions. example technique operate subject-speciﬁc images limited closed scenarios. thus anonymity guarantees associated k-same family algorithms apply approach extensive experimental validation demonstrate feasibility developed deidentiﬁcation pipeline. deidentiﬁcation procedure starts standard face detection step using off-the-shelf viola-jones face detector opencv detector process input image video frame returns bounding boxes detected faces. detected region processed separately sequential manner -dimensional feature vector extracted region using pre-trained -layer face network step output last fullyconnected layer face network considered feature vector. computed feature vector matched gallery feature vectors using cosine similarity. matching procedure feature vector extracted region input image gallery feature vectors results ordered list similarity scores. based list identify similar identities gallery feed generative network surrogate-face generation. idea generating synthetic surrogate face based closest identities similar essence established family k-same family algorithms except fact ﬁnal face case entirely generated gnn. generate gallery deidentiﬁcation approach process images radboud faces database network ofﬂine extraction step store templates identities rafdb dataset so-called feature database featdb fig. pipeline. feature vectors correspond ﬁnite facial identities used generating faces deidentiﬁcation. generative part used deidentiﬁcation pipeline comprises powerful recently introduced dosovitskiy generating images objects different viewpoint angles various basic transformations. architecture later extended another application involving face generation michael flynn. work approach gnns train network deidentiﬁcation. already suggested previous section want network able generate surrogate faces identities mixtures identities contained feature database deidentiﬁcation pipeline. thus rafdb training. fully trained network able generate artiﬁcial faces accordance supplied identities also line appearance-related parameters exposed training stage. generation process described follows output generative network stands identity-related parameter vector encodes information k-closest identities returned matching procedure denotes parameter vector guides generation process affects speciﬁc characteristics visual appearance generated output. equation vector general relate appearance characteristic appropriately annotated training data. since rafdb annotated respect different facial expressions train network generate faces different identities well facial expressions. however number appearance-related parameters exposed network limited general deﬁned labels available training data. generative network consists fully-connected deconvolutional layers described detail deconvolution layer includes upscaling layer followed convolution fig. sample outputs generative network identity mixing identities using displayed left right respectively. increasing number identities generated faces converge towards average appearance still realistic without ghosting effects. ﬁrst label images refers generated facial expression second identity identities used generation process. layer. stabilization error training achieved adding batch normalization layers leaky-rectiﬁer-unit-activation functions deconvolution layers. loss training procedure calculated pixel-wise mean square difference ground truth image artiﬁcially generated image. training performed images rafdb dataset desktop intel core utilizing titanx takes around hours. current training dataset network able interpolate different identities well different facial expressions. combining identities generate averaged faces almost without ghosting effect shown fig. using appearance-related parameter vector also preserve utility input data e.g. form facial expressions retained altered regards original input. sample faces generated shown fig. here ﬁrst block images shows artiﬁcial images generated based single identity second block shows images computed based identities last block shows sample faces generated four identities note generated faces closer average appearance number identities increases still appear realistic feature ghosting effects. last step deidentiﬁcation pipeline face replacement generated surrogate face blended input image. face replacement step starts facial-landmark estimation using approach landmarks detected both generated face detected original input face. using sets landmarks estimate perspective transformation aligns landmarks artiﬁcially generated face landmarks original face using ransac. generated face image warped using transformation order adjust synthetic content landmarks original image. correction fig. illustration replacement procedure gaussian mask artiﬁcially generated face image modiﬁed gaussian mask geometrically corrected synthetic face without background sample frame deidentiﬁed frame. following geometric corrections apply second post-processing procedure discards background generated faces. step simple skin-color segmentation performed using upper lower boundaries color-space deﬁne skin intensities i.e. lower= upper=. pixels values within deﬁned range retained rest discarded. erosion dilation used remove possible isolated regions belong facial area. step make sure background around generated facial area removed facial region without gray-colored background seen fig. swapped deidentiﬁcation. stand dimensions generated image denote image coordinates. online generated kernel serves weight mask blending original generated image pixels. kernel warped using homography transformation order ensure best possible face alignment suitable level naturalness ﬁnal output. replacement procedure illustrated fig. here ﬁrst image shows gaussian weight mask second image shows initial output generative network third image shows gaussian mask modiﬁed result geometric correction segmentation step fourth image presents adjusted last images depict original deidentiﬁed frame test dataset. section present experimental results aimed demonstrating merits deidentiﬁcation pipeline. ﬁrst discuss experimental dataset performance metrics present qualitative well quantitative results. evaluate performance deidentiﬁcation approach chokepoint dataset contains video footage captured typical surveillance scenario. people videos recorded walking portal array cameras placed. chokepoint videos exhibit variations across illumination conditions pose image sharpness alike well suited studying performance deidentiﬁcation technology. chokepoint dataset contains video sequences total frames. videos feature subjects walking ﬁrst portal subjects walking second portal. experiments partitioned video sequences distinct subsets. ﬁrst subset contained sequences people mostly frontal poses second subset contained remaining sequences people less frontal poses i.e. proﬁle frames. refer former subset original latter proﬁle hereon. video sequences original subset subjected deidentiﬁcation approach stored experimental evaluation. measure efﬁcacy developed deidentiﬁcation pipeline conduct four types veriﬁcation experiments -fold cross-validation protocol. fold perform legitimate illegitimate veriﬁcation attempts. different types veriﬁcation experiments brieﬂy outlined below original original experiment sample image pairs legitimate veriﬁcation attempts image pairs illegitimate veriﬁcation attempts experimental fold video sequences original subset. goal experiment establish baseline performance recognition techniques considered experiments. since video frames sampled videos experiment biased towards higher performances since appearance variability frames limited. original proﬁle experiment construct image pairs legitimate illegitimate veriﬁcation attempts fold images taken original proﬁle subsets. here ﬁrst image pair always sampled original subset second always sampled proﬁle subset. subsets contain distinct video sequences experiment better reﬂects baseline performance recognition techniques considered experiments. deidentiﬁed original experiment equivalent original original experiment difference ﬁrst image image pair replaced deidentiﬁed version. thus experiment meant measure efﬁcacy performance proposed deidentiﬁcation procedure. veriﬁcation attempts cross-validation folds experiment direct correspondence original original experiment therefore clearly demonstrate effect deidentiﬁcation veriﬁcation performance. deidentiﬁed proﬁle last experiment follows approach original proﬁle experiment replaces video frames original subset deidentiﬁed version. goal experiment demonstrate feasibility deidentiﬁcation approach. report performance standard performance metrics graphs. speciﬁcally present receiver operating characteristic curves plot value veriﬁcation rate false acceptance rate different values decision threshold report number scalar performance metrics experiments i.e. equal error rate operating point curve -ver equal veriﬁcation rate area curve fig. qualitative examples deidentiﬁed frames. shows example frames video sequence chokepoint dataset corresponding deidentiﬁcation results note generative network able generate realistic renderings faces deidentiﬁcation. ﬁrst demonstrate efﬁcacy deidentiﬁcation approach qualitative examples fig. here shows frames video sequence chokepoint dataset corresponding deidentiﬁcation result. image pair left image represents original frame right image deidentiﬁed counterpart. part deidenﬁed faces generated generative network appear natural realistic. case substituted identities generated similar identities characteristic deidentiﬁcation approach ﬂexibility generative network offers producing synthetic face images deidentiﬁcation. generation process parameterized respect desired target appearance synthetic face makes possible generate faces different characteristics important trying retain non-identity-related information deidentiﬁed data. video conferencing applications example want protect privacy conference participants hiding identity still preserve information facial expressions convey conversation. customer-proﬁling applications focus typically demographics customers identity. deidentiﬁcation approach able conceal identity people image data retain certain aspects facial appearance. characteristic demonstrated fig. here ﬁrst column shows sample frames video sequence chokepont dataset second third fourth ﬁfth column show three different deidentiﬁcation results rendered happy angry surprised neutral facial expression respectively. show results different facial expressions deidentiﬁcation pipeline general able generate variations synthetic faces accordance appearance-related label training data. thus data used training contains images annotated respect facial expressions able generate faces different facial expressions data contains labels gender synthesize faces belonging males females forth. number different appearance variations approach cover limited number available labels. fig. deidentiﬁed frames rendered different facial expressions. images ﬁrst column represent original frames video sequences chokepoint dataset. second third fourth ﬁfth columns show deidentiﬁed frames rendered happy angry surprised neutral expression respectively. seen deidentiﬁcation approach highly ﬂexible able retain alter speciﬁc aspects deidentiﬁed faces. fig. show examples visually less pleasing deidentiﬁcation results. image artifacts visible consequence different scene conditions ascribed replacement procedure. artifacts could alleviated elaborate face-replacement approach exploiting example poisson blending color-proﬁle matching. however would affect speed pipeline currently runs around frames second processing sequence subject present time around frames second executing sequence involving multiple subjects simultaneously present scene. framerates achieved desktop intel core ram. another cause image artifacts extreme facial poses people exit scene result visible misalignment superimposed faces original facial areas. among main limitations deidentiﬁcation approach persistence identity deidentiﬁed data. dealing video footage deidentiﬁcation procedure ideally produce result frames given video sequence. words facial area given subject replaced artiﬁcially generated face target identity entire duration video. however changes facial appearance matching module occasionally returns inconsistent results causes changes target identity deidentiﬁed frames. effect demonstrated ﬁrst fig. identity change observed last image pair variations scene’s illumination despite fact subject deidentiﬁed. nevertheless target identity deidentiﬁcation determined state-of-the-art face recognition model procedure able assign consistent target identity time test videos considered experiments. fig. qualitative examples problematic deidentiﬁcation results. upper shows identity switch last frame change scenes illumination. lower shows difﬁculties presence multiple people occlude faces background. misalignment original surrogate faces also visible second image pair lower happens extreme viewing angles people exit scene. quality efﬁcacy deidentiﬁcation techniques typically measured reidentiﬁcation experiments goal evaluate risk successfully identifying person deidentiﬁed data. risk commonly assessed automatic manual recognition experiments. outlined section perform number veriﬁcation experiments -fold cross validation protocol towards risk assessment consider three state-of-the-art automatic recognition approaches literature. speciﬁcally open-source implementation -layer face network hereon -layer implementation squeezenet network trained around million images squeezenet hereon iii) algorithm openbr openbr hereon. networks output last fully connected layer network feature vector compute similarity score image pair cosine angle corresponding feature vectors. openbr default matching option. also conduct manual recognition experiments using similar -fold cross-validation protocol automatic techniques limit extend comparisons automatic experiments. thus comparisons performed fold resulting total veriﬁcation attempts experimental run. veriﬁcation experiment evaluated human evaluator i.e. four evaluators covered four veriﬁcation experiments. produce similarity scores needed generating performance metrics curves manually assign similarity score ﬁve-point scale comparison accordance methodology proposed similar existing works face deidentiﬁcation approach tries conceal identity people replacing detected facial areas synthetically generated surrogate faces. however identity cues also extracted contextual information directly related facial appearance. example facial outline hair-style even clothing represent context feed facial area recognition technique directly detected face detector. thus facial area also contains contextual information shape head hair style alike. comparison images context illustrated last column table without context trim bounding returned face detector side facial areas used recognition experiments therefore cropped tighter contain little contextual information. sample comparison images used experiments shown last column table numerical results experiments presented table note ver- values reported manual experiments insufﬁcient number manually graded image comparisons. expected results contextual information signiﬁcantly better without contextual information experiments nondeidentiﬁed images used. veriﬁcation attempts conducted deidentiﬁed images contextual information still contributes higher performance experiments differences images without context smaller. also evidenced curves experiments fig. best performing automatic technique network able ensure recognition performance well random deidentiﬁed-vs-original experiment deidentiﬁed-vs-proﬁle experiment context available. contextual information present performance drops experiments respectively. observations suggest contextual information important exploited contemporary recognition techniques boost performance. thus care needs taken appropriately conceal modify remove contextual information data well. another interesting observation made plots fig. drop performance manual experiments. unaltered images human performance close perfect experiments. however deidentiﬁcation human performance drops random contextual information present slightly better chance contextual information available. fig. curves veriﬁcation experiments. curves left show results experiments images contextual information curves right show results obtained without contextual information. upper shows experiments unaltered deidentiﬁed images original subset lower shows experiments unaltered deidentiﬁed images proﬁle subset. results show approach effective. performance. blue plots show results unaltered images plots show results deidentiﬁed images. needs noted even cases performance deidentiﬁcation exactly random still signiﬁcantly lower obtained unaltered images tested techniques. highest median value experiment deidentiﬁcation achieved network contextual information available. however value signiﬁcantly random limited applications requiring reliable face recognition. last experiment compare deidentiﬁcation approach existing deidentiﬁcation techniques literature. speciﬁcally report results naive methods i.e. blurring pixelation unlike techniques k-same family applied video data using experimental protocol used previous experiments. results comparison generated best performing recognition approach table i.e. network presented table seen naive methods result worse recognition performance approach therefore appear ensure better anonymity. however fig. values experimental folds presented form plots assessed techniques well human experiments. blue plots show results unaltered images plots show experiments deidentiﬁed images. left plots present results contextual information right plots present results without context. note deidentiﬁcation result close indicated random performance. right side table show qualitative deidentiﬁcation examples closed images xmvts dataset note closed required k-same family techniques applicable. accordance k-anonymity scheme replace clusters images surrogate face generated results deidentiﬁcation approach visually convincing feature ghosting effects images generated original k-same approach approach also possible retain certain aspects original data necessarily true blurred pixelated images shown second third image respectively. table deidentiﬁcation performance network. left part table shows comparison existing deidentiﬁcation techniques proposed approach experiments chokepoint dataset. right part table presents qualitative comparison approach competing techniques literature closed images. paper presented novel approach face deidentiﬁcation using generative neural networks. proposed approach evaluated chokepoint dataset highly encouraging results. evaluation suggests generative networks viable tool face deidentiﬁcation high degree anonymity ensured swapping original faces artiﬁcially generated surrogate faces. furthermore experiments show ﬂexibility generative network possible control appearance generated surrogate faces thus retain speciﬁc aspects input images contributing signiﬁcantly utility deidentiﬁed faces. deidentiﬁcation results visibly convincing additional improvements possible. part future work plan including additional generator parameters capitalize utility deidentiﬁed faces. possible improvements include better blending procedure would improve overall naturalness deidentiﬁed faces remove artifacts. also consider incorporating tracking scheme would improve applicability approach video data. research supported parts arrs research programme metrology biometric systems arrs research programme computer vision tubitak project marie curie integration grant within framework programme croatian hrrz project deppss de-identiﬁcation privacy protection surveillance systems cost action de-identiﬁcation privacy protection multimedia content. wong chen sanderson lovell b.c. ’patch-based probabilistic image quality assessment face selection improved video-based face recognition’ cvprw fawcett introduction analysis’. peer emerˇsiˇc bule ˇzganec-gros ˇstruc ’strategies exploiting independent cloud implementations biometric experts multibiometric scenarios’. messer kittler sadeghi marcel marcel bengio cardinaux sanderson czyz vandendorpe srisuk petrou kurutach kadyrov paredes kepenekci f.b. akar g.b. deravi mavity ’face veriﬁcation competition xmvts database’. avbpa", "year": 2017}