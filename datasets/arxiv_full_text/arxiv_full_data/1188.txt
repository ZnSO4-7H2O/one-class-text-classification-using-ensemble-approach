{"title": "Occlusion Edge Detection in RGB-D Frames using Deep Convolutional  Networks", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Occlusion edges in images which correspond to range discontinuity in the scene from the point of view of the observer are an important prerequisite for many vision and mobile robot tasks. Although they can be extracted from range data however extracting them from images and videos would be extremely beneficial. We trained a deep convolutional neural network (CNN) to identify occlusion edges in images and videos with both RGB-D and RGB inputs. The use of CNN avoids hand-crafting of features for automatically isolating occlusion edges and distinguishing them from appearance edges. Other than quantitative occlusion edge detection results, qualitative results are provided to demonstrate the trade-off between high resolution analysis and frame-level computation time which is critical for real-time robotics applications.", "text": "abstract—occlusion edges images correspond range discontinuity scene point view observer important prerequisite many vision mobile robot tasks. although occlusion edges extracted range data extracting images videos challenging would extremely beneﬁcial variety robotics based applications. trained deep convolutional neural network identify occlusion edges images videos rgb-d inputs. avoids hand-crafting features automatically isolating occlusion edges distinguishing appearance edges. quantitative occlusion edge detection results qualitative results provided demonstrate trade-off high resolution analysis frame-level computation time critical real-time robotics applications. occlusion edge detection fundamental capability computer vision systems evident number applications signiﬁcant attention received occlusion edges useful wide array tasks including object recognition feature selection grasping obstacle avoidance navigating path-planning localization mapping stereo-vision optic ﬂow. addition numerous applications concept occlusions edges supported human visual perception research referred ﬁgure/ground determination. occlusion boundaries established depth order regions become possible aids navigation simultaneous localization mapping path planning. occlusion edges help image feature selection rejecting features generated regions span occlusion edge. dependent viewpoint position removing variant feature saves processing increases recognition accuracy many object recognition problems shape object better recognition rather appearance easily dramatically altered e.g. painted objects camouﬂage people wearing different clothes. however shape determination approach state-of-the-art sift based object recognition algorithms. furthermore knowledge occlusion edges helps stereo vision optic algorithms robotics geometric edges objects demarcate spatial extents helping grasping manipulation well maneuvering world without collision therefore knowledge occlusion edges essential. context paper evaluates efﬁcacy deep learning tools task occlusion edge detection. recently class techniques emerged performing machine learning tool various tasks object recognition speech recognition denoising hashing data fusion deep neural networks pre-trained using deep belief networks perform quite well data types deep convolutional neural networks shown suited images. better performance primarily attributed preservation local structures opposed dbn-dnn occlusion edge detection task logically conceived step process identifying edges image followed distinguishing occlusion appearance edges. therefore deep neural networks particularly interesting problems extract hierarchical features data visualization intermediate optimized ﬁlters show edge type features common. also noted approach eliminates need complicated hand-crafting features commonly done many current approaches. availability gpus recent advancements algorithmic/implementation side large cnns learnt without signiﬁcant overﬁtting high volume data complex problems fact model size optimized iteratively certain problem. often however memory implementing becomes bottle-neck. paper main contributions formulation occlusion edge detection problem classiﬁcation center-pixels image patch rgb-d channels performance evaluation various input information namely rgb-d single time frame single time frame fusion patch predictions generate framewide occlusion edges. study uses publicly available benchmark rgb-d data captured moving camera indoor environment computer vision group technische universitt mnchen optimized hardware-accelerated implementation done nvidia gpu. paper organized seven sections including introduction. problem formulation along data description provided section section provides details architecture training parameters testing post-processing discussed section various experiments corresponding quantitative results provided section qualitative observations articulated section finally paper summarized concluded future research directions section vii. general difﬁcult deﬁne edge pixels rigorously. image edges manifest along paths high contrast four main reasons texture change i.e. abrupt change surface color lighting change i.e. sharp shadows range discontinuity i.e. abrupt change distance observer surface normal change e.g. intersection planes. important appreciate distinction causes image edges. texture change illumination edges observed sensors. therefore remaining geometric edge types range discontinuities abrupt surface normal changes. surface normal changes pose invariant however edges range discontinuities vary observer position. surface normal range discontinuities illustrated last image fig. cylinder sides fig. examples range discontinuities. position edges varies space position observer shifts whereas cylinder edge position consistent regardless observer position. mapping following characteristics desired extracted edge voxels rotation translation helpful terms constraining pose. therefore study focus identifying third fourth type edges. traditional approaches detect geometric edges data include keypoint detector based extension harris corner operator point cloud library detector operates local normals points. related approach selecting interest points meshes introduced principle study similar recent work indoor scene segmentation however study focuses occlusion edges isolated using cnns also reasonable performance achieved without using depth channel rgbdata. mentioned earlier paper uses benchmark rgb-d data computer vision group technische universitt mnchen data contains depth images microsoft kinect sensor recorded full frame rate sensor resolution moving camera indoor environment. occlusion edge detection problem formulated classiﬁcation problem procedure generating training data provided following subsection. edge label pixel i.e. ground truth automatically determined using depth channel data. label generation procedure illustrated fig. left right three plates ﬁgure shows example frame corresponding channel data classiﬁcation frame generated using simple thresholding depth data. gray white colors black color seen classiﬁcation frame. signiﬁes depth measurements presence absorbing surface larger maximum distance allowed sensor surface. rgb-d data collected using camera motion along certain trajectory indoor environment. trajectory divided disjoint training testing sections trained model tested using previously unseen data. frames rgb-d data size. order create training examples convolutional neural network patches extracted large frames training section. training label patch determined pixels located center illustrated fig. majority pixels center patch contains occlusion edges patch labeled occlusion patch. hand center pixels contain appearance edges edge corresponding patch labeled occlusion patch. patches considerable number unlabeled pixels pre-ﬁltered used training. convolutional neural network used paper illustrated fig. three pairs convolution-pooling layers followed softmax output layer section articulates details layers well various hyper-parameters used model learning. description layers described section ii-a patches used data study. depending experiment different number channels used input data. example channels used single frame rgb-d data channels used frame. detailed description various experiments provided section layer size parameters correspond rgb-d experiment channels. ﬁrst convolutional layer uses ﬁlters size stride pixel padding pixels edges. conﬁgured rectiﬁed linear units train several times faster equivalents tanh connections two-fold subsampling pooling layer follows convolutional layer generates input data second convolutional layer. layer uses ﬁlters size stride pixel padding pixels edges. second pooling layer speciﬁcation ﬁrst used generate input size third convolutional layer uses ﬁlters size stride padding strategies before. third pooling layer also conﬁguration fig. example depth classiﬁcation frames training data generation procedure. classiﬁcation frame gray signiﬁes edge occlusion edges white black unreliable data. leads softmax output layer labels corresponding occlusion occlusion classes. hyper-parameters described trained using stochastic gradient descent mini-batch size examples. although biases convolutional layer neurons initialized constant values zero weights neurons initialized zero-mean gaussian distributions standard deviations ﬁrst second third convolutional layer. interestingly network performed better comparatively larger initialization weight standard deviation output layer. learning rate momentum used convolutional layers training epochs respectively. finally l-regularizers used convolutional layers well weight dropout used model training study. training nvidia kepler series gpus flops/watt efﬁcient used drive real-time image processing capabilities. kepler series consists maximum streaming execution units -bit memory controllers. unit single-precision cuda cores core comprises fully pipelined ﬂoating-point integer arithmetic logic units. gpus consist cores on-board device memory deep learning applications targeted gpus previously implementations compute memory bound. stacking channels rgbd experiments result vector respectively suitable single instruction multiple datapath architecture gpus. time training batch size caches memory utilization gpu’s memory high. also results experiments successfully single instead partitioning different layers multiple gpus. performance testing done quantitative qualitative manner various input information explained section quantitative results classiﬁcation errors computed based model’s ability predict label center pixels test patch collected frame captured testing section camera motion. qualitative observations visualization made using post-processing scheme illustrated fig. scheme classiﬁcation conﬁdence patch center pixels collected softmax posterior distribution extrapolated across patch using gaussian distribution full width half maximum gaussian kernels overlapping patches fused mixture model generate smooth occlusion edges testing frame. rgb-d frame ﬁrst experiments used single temporal frames rgb-d data task seem rather straight forward depth information directly available channels input data. however majority edges current frames appearance edges channels clearly provide information. therefore task model detect edges automatic feature extraction distinguishing occlusion edges appearance edges. frame second experiments used single temporal frames data goal investigate discriminative features exist extracted channels order classify patches occlusion occlusion edges. ideally without temporal information channels carry occlusion information. however occlusion information remain certain features shadows. therefore objective investigate features recognized detect occlusion edges. numerical results provided cases. training training patches extracted large image frames used. testing patches used provide quantitative performance data. figure shows training testing error plots various epochs speciﬁcally training error graph clearly demonstrates training process saturate. relu connections used cnn. provided table cases false alarm performance signiﬁcantly better compared missed detection performance. numerically overall error percentage close false alarm rate majority test example patches contain occlusion edges. finally expected detection performance input inferior rgb-d input. however false alarm rates quite comparable. overall interesting observe performance degradation large input data changes depth channel removed. section presents qualitative results order understand efﬁcacy deep learning tools occlusion edge detection robotics applications whole. figures show performances rgb-d input stride fig. post-processing testing phase involves collecting overlapping patches constant stride large frames; prediction conﬁdence patch center pixel label converted gaussian kernel full width half maximum gaussian labels fused mixture model generate smooth occlusion edges testing frame. expected occlusion edge generation better lower value stride information available pixel case. noted marked regions ﬁgures false detection occlusion edges reduces lower value stride. trade-off lies computational speed. lower value stride frame processing time increases linearly increase number test patches. therefore trade-off chosen properly realtime robotics applications. figures show performances input stride testing frame similar observations made case well. heat maps also demonstrate decrease detection conﬁdence case compared rgb-d input. pixel classiﬁcation problem image patch extracted larger frame. apart rgb-d inputs experiments performed investigate performance degradation associated dropping depth channel. noted although missed detection rate increases slightly without depth data false alarm performance degrade signiﬁcantly. testing post-processing scheme developed visualize testing performance. tradehigh resolution patch analysis frame-level computation time discussed critical real-time robotics applications. rgb-d frames ends spectrum input data information content. therefore investigations currently pursued multiple time-frames input order extract structure motion. apart task research directions design motion planning using decisions cnns analysis computation speed accuracy trade-off real-time operation. fig. occlusion detection performance test frame rgb-d input stride heat description fig. circled region shows inferior performance compared stride fig. occlusion detection performance test frame input stride heat description fig. circled region shows example mistaking appearance edges occlusion edges sargin bertelli manjunath rose probabilistic occlusion boundary detection spatio-temporal lattices computer vision ieee international conference ieee wagemans elder kubovy palmer peterson singh heydt century gestalt psychology visual perception perceptual grouping ﬁgure–ground organization. psychological bulletin vol. sundberg brox maire arbel´aez malik occlusion boundary detection ﬁgure/ground assignment optical computer vision pattern recognition ieee conference smith drummond cipolla layered motion segmentation depth ordering tracking edges pattern analysis machine intelligence ieee transactions vol. mozos ballesta reinoso comparative belhumeur mumford bayesian treatment stereo correspondence problem using half-occluded regions computer vision pattern recognition proceedings cvpr’. ieee computer society conference bengio olivier expressive power deep architectures algorithmic learning theory. springer berlin/heidelberg krizhevsky sutskever hinton imagenet classiﬁcation hinton deng dahl mohamed jaitly senior vanhoucke nguyen sainath kingsbury deep neural networks acoustic modeling speech recognition ieee signal processing magazine vol.", "year": 2014}