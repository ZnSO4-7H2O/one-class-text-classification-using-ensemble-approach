{"title": "From One Point to A Manifold: Knowledge Graph Embedding For Precise Link  Prediction", "tag": ["cs.AI", "cs.LG"], "abstract": "Knowledge graph embedding aims at offering a numerical knowledge representation paradigm by transforming the entities and relations into continuous vector space. However, existing methods could not characterize the knowledge graph in a fine degree to make a precise prediction. There are two reasons: being an ill-posed algebraic system and applying an overstrict geometric form. As precise prediction is critical, we propose an manifold-based embedding principle (\\textbf{ManifoldE}) which could be treated as a well-posed algebraic system that expands the position of golden triples from one point in current models to a manifold in ours. Extensive experiments show that the proposed models achieve substantial improvements against the state-of-the-art baselines especially for the precise prediction task, and yet maintain high efficiency.", "text": "despite success previous methods none previous studies addressed issue precise link prediction ﬁnds exact entity given another entity relation. speciﬁc query fact existing methods would extract candidate entities contain correct answers mechanism ensure correct answers rank ahead candidate list. generally speaking precise link prediction would improve feasibility knowledge completion effectiveness knowledge reasoning performance many knowledge-related tasks. taking knowledge completion example want know birth place martin r.r. expect exact answer u.s. candidates make sense. first algebraic perspective fact following treated equation translation-based principle embedding could treated solution equation group. current embedding methods number equations free variables called ill-posed algebraic problem deﬁned speciﬁcally indicates equations dimension embedding vector denotes dimension. therefore equations number facts number variables number entities relations respectively. case triples much entities relations number variables much less number equations typically illposed algebraic system. mathematically ill-posed algebraic system would commonly make solutions imprecise unstable. paper propose address issue replacing translation-based principle manifold-based principle manifold function. manifold-based principle model make nearly well-posed algebraic system taking number equations free parameters knowledge graph embedding aims offering numerical knowledge representation paradigm transforming entities relations continuous vector space. however existing methods could characterize knowledge graph degree make precise link prediction. reasons issue ill-posed algebraic system adopting overstrict geometric form. precise link prediction critical knowledge graph embedding propose manifold-based embedding principle could treated well-posed algebraic system expands point-wise modeling current models manifold-wise modeling. extensive experiments show proposed models achieve substantial improvements state-of-the-art baselines particularly precise prediction task maintain high efﬁciency. related poster slides datasets codes published http//www. ibookman.net/conference.html. introduction knowledge critical artiﬁcial intelligence embedded representation knowledge offers efﬁcient basis computing symbolic knowledge facts. speciﬁcally knowledge graph embedding projects entities relations continuous high-dimension vector space optimizing well-deﬁned objective functions. variety methods proposed task including transe ptranse fact knowledge graph usually represented triple indicate head entity relation tail entity respectively. goal knowledge graph embedding obtain vectorial representations triples i.e. well-deﬁned objective functions. branch embedding methods translation-based methods transe ptranse treat triple relation-speciﬁc translation head entity tail entity formally figure visualization comparison transe manifolde manifolde manifold collapses solid circle dimension reduction. data selected wordnet freebase. blue crosses mean correctly matched entities crosses indicate unmatched ones. upper block corresponds transe near center plausible triple clear true false triples near golden position chaotically distributed. block manifolde triples inside solid circle matched outside unmatched. relatively less errors manifolde transe. second geometric perspective position golden facts existing methods almost point strict relations insufﬁcient complex relations many-to-many relations. example entity american revolution exist many triples many tail entities compete point would major loss objective function. previous work transh transr address problem projecting entities relations relation-speciﬁc subspaces. however subspace golden position also point over-strict geometric form still existing. seen fig. translation-based geometric principle involves much noise. however manifolde alleviates issue expanding position golden triples point manifold high-dimensional sphere. mean manifolde avoids much noise distinguish true facts possible false ones improves precision knowledge embedding fig. shows. summarize contributions two-fold addressed issue precise link prediction uncover reasons ill-posed algebraic system over-strict geometric form. best knowledge ﬁrst time propose manifoldaddress issue formally. based principle alleviate issue design model manifolde achieves remarkable improvements state-of-the-art baselines experiments particularly precise link prediction. besides methods also efﬁcient. related work translation-based methods pioneering work knowledge graph embedding transe opens line translation-based methods. transe treats triple relation-speciﬁc translation head entity tail entity score function form following principle number models proposed. instance transh adopts projection transformation transr applies rotation transformation mrhtr mrt. similar work also includes transd transm approaches take consideration extra information relation-type paths different conﬁdence levels semantic smoothness embedding space probabilistic embedding method modeling uncertainty knowledge base. notably translation-based models demonstrate state-of-the-art performance. methods unstructured model simpliﬁed version transe ignores relation information score function reduced structured embedding model transforms entity space head-speciﬁc tail-speciﬁc matrices score function deﬁned ||mhrh mtrt||. semantic matching energy model enhance considering correlations between entities relations different matrix operators follows weight matrices hadamard product bias vectors. single layer model applies neural network knowledge graph embedding score function deﬁned latent facrelation-speciﬁc weight matrices. model makes second-order correlations between entities quadratic form score function hwrt. neural tensor network model deﬁnes expressive score function combine gw··rt relation-speciﬁc linear layer tanh function rd×d×k -way tensor. besides rescal collective matrix factorization model also common method knowledge graph embedding instead adopting translation-based principle apply manifold-based principle speciﬁc triple head entity relation given tail entities high-dimensional manifold. intuitively score function designed measuring distance triple away manifold relation-speciﬁc manifold parameter. manifold function entity relation real number ﬁeld. sphere. sphere typical manifold. setting tail entities speciﬁc fact supposed high-dimensional sphere center radius formally stated below straight-forward extension translation-based models zero. geometric perspective manifold collapses point applying translation-based principle. reproducing kernel hilbert space usually provides expressive approach represent manifolds motivates apply manifold-based principle kernels. point kernels involved sphere hilbert space figure visualization embedding manifold-based models. corresponds sphere setting tail entities supposed sphere. clock dial matched facts spheres. corresponds hyperplane setting clock dial hyperplanes making embedding precise. mapping original space hilbert space induced kernel commonly could linear kernel gaussian kernel polynomial kernel obviously applying linear kernel function reduced original sphere manifold. hyperplane. shown fig. could manifolds intersected loss embedding. spheres would intersect strict conditions hyperplanes would intersect normal vectors parallel. motivated fact apply hyperplane enhance model below rhead rtail speciﬁc relation embeddings. geometric perspective given head entity relation tail entities hyperplane whose direction rhead bias corresponds practical cases since vectors rhead rhead likely parallel would chance loss function minimized margin hinge loss. false triples sampled bernoulli sampling method introduced initialize embedding vectors similar methods used deep neural network stochastic gradient descent applied solve problem. theory computation complexity relative transe bounded small constant small constant caused manifoldbased operations kernelization. commonly transe efﬁcient among translation-based methods manifolde could comparable transe efﬁciency hence faster translation-based methods. experiments experiments conducted four public benchmark datasets subsets wordnet freebase statistics datasets listed tab.. experiments conducted tasks link prediction triple classiﬁcation. demonstrate proposed model performs manifold-based principle present visualization comparison translation-based manifold-based models section finally conduct error analysis understand beneﬁt limits models. link prediction reasoning focus knowledge computation. verify reasoning performance embedding link prediction task conducted. task aims predict missing entities. alternative entities relation given embedding methods infer missing entity. speciﬁcally task predict given predict given benchmark datasets task. notably many tasks could motivated enlarging number precisely predicted tail entities head relation apply absolute operators rhead||t rtail| instance one|w| dimensional case |h+rhead||t+rtail| absolute operator would double solution number meaning tail entities rather could matched precisely head relation. reason absolute operator would promote ﬂexibility embedding. algebraic perspective ill-posed equation system posses equations free variables always leads undesired properties instability reason translation-based principle performs well precise link prediction. alleviate issue manifold-based methods model embedding within nearly well-posed algebraic framework since principle indicates equation fact triple. taking example sphere could conclude equation embedding system would algebraically stable condition easy achieve enlarging embedding dimension suitable degree. theory larger embedding dimension provides solutions embedding equations makes embedding ﬂexible. suitable condition satisﬁed stable algebraic solution would lead embedding characterization therefore precise link prediction would promoted. geometric perspective translation-based principle allocates position golden triple. extend point whole manifold high dimensional sphere. instance tail entities relation could sphere applies center radius. obversely would suitable manifold setting point setting. evaluation protocol. adopt protocol used previous studies. firstly testing triple corrupt replacing tail every entity knowledge graph. secondly calculate probabilistic score corrupted triple score function ranking scores descending order obtain rank original triple. evaluation metric proportion testing triple whose rank larger hits applied common reasoning ability hits concerns precise embedding performance. called setting. ﬁlter corrupted triples exist training validation test datasets thefilter setting. corrupted triple exists knowledge graph ranking ahead original triple also acceptable. eliminate case filter setting preferred. settings higher hitsn means better performance. note report results setting hits small make sense. notably actually baseline setting times average running time results. implementation. datasets same directly reproduce experimental results several baselines literature hits. hits request results authors ptranse kge. acknowledge authors yankai shizhu attempted several settings validation dataset best conﬁguration. bern. sampling strategy optimal conﬁgurations manifolde follows. sphere linear kernel polynomial kernel fbk. hyperplane learning rate embedding dimension margin linear kernel linear kernel fbk. experimental environment common memory windows note symbols introduced methods. notably train model convergence rounds previous version. version adopt trick train model rounds. algebraic perspective it’s reasonable measure algebraic ill-posed degree radio translation-based principle number equations number free variables larger radio means ill-posed. since manifold-based principle alleviates issue manifolde would make promotion relatively comparable baselines larger radio. metric hits radio transe achieves manifolde achieves leading relative improvement radio transe achieves manifolde achieves leading relative improvement comparison illustrates manifold-based methods could stabilize algebraic property embedding system means precise embedding could approached much better. geometric perspective traditional models attempt express matched entities position leads unsatisfactory performance complex relations. meanwhile manifold-based model could perform much better complex relations discussed. metric hits simple relation improves relatively manifolde transe complex relations improve relatively respectively. comparison demonstrates manifold-based method extends golden position point manifold could better characterize true facts especially complex relations. triple classiﬁcation order present discriminative capability method true false facts triple classiﬁcation conducted. classical task knowledge base embedding aims predicting whether given triple correct not. benchmark datasets task. note evaluation classiﬁcation needs negative samples datasets already built negative triples. evaluation protocol. decision process simple follows triple threshold positive; otherwise negative. thresholds {σr} determined validation dataset. task sometriple binary classiﬁcation. implementation. methods datasets directly re-use results different methods literature. attempted several settings validation dataset best conﬁguration. optimal conﬁgurations manifolde follows bern sampling. sphere linear kernel gaussian kernel hyperplane learning rate embedding dimension margin linear kernel polynomial kernel speciﬁcally relation type complex improves transe manifolde relation gender extreme relation improves comparison shows manifold-based methods could handle complex relations better. fig. shows translation-based principle involves much noise near center supposed true facts. attribute issues precise link prediction issue introduced previously however manifold-based principle alleviates issue enhance precise knowledge embedding could seen visualization results. error analysis analyze errors link prediction randomly sample testing triples could rank positions manifolde three categories errors summarized. notably call predicted rank triple golden rank triple. rank triple corcontained knowledge rect thus ranking golden acgraph ceptable. category caused incompleteness dataset. example reﬂexive semantics general expression professional knowledge related concepts rank triple related concept exactly correct. category caused relatively simple manifolds applied manifolde. example puzzled place membership similar mentions similar concepts possible knowledge could exploit complex manifolds enhance discriminative ability. conclusions paper study precise link prediction problem reveal reasons problem ill-posed algebraic system over-restricted geometric form. alleviate issues propose novel manifoldbased principle corresponding manifolde models inspired principle. algebraic perspective manifolde nearly well-posed equation system geometric perspective expands point-wise modeling translation-based principle manifold-wise modeling. extensive experiments show method achieves substantial improvements stateof-the-art baselines. colin evans praveen paritosh sturge jamie taylor. freebase collaboratively created graph database structuring proceedings human knowledge. sigmod international conference management data pages antoine bordes jason weston ronan collobert yoshua bengio learning structured proceedings embeddings knowledge bases. twenty-ﬁfth aaai conference artiﬁcial intelligence antoine bordes xavier glorot jason weston yoshua bengio. joint learning words meaning representations open-text semantic parsing. international conference artiﬁcial intelligence statistics pages antoine bordes nicolas usunier oksana alberto garcia-duran translating embeddings modeling yakhnenko. multi-relational data. advances neural information processing systems pages miao qiang zhou emily chang thomas fang zheng. transition-based knowledge graph proembedding relational mapping properties. ceedings paciﬁc asia conference language information computation pages xavier glorot yoshua bengio. understanding difﬁculty training deep feedforward neural networks. international conference artiﬁcial intelligence statistics pages quan wang wang lihong wang guo. semantically smooth knowledge graph embedding. proceedings shizhu kang guoliang zhao. learning represent knowledge graphs gaussian embedding. proceedings international conference information knowledge management pages raphael hoffmann congle zhang xiao ling luke zettlemoyer daniel weld. knowledge-based weak supervision information exproceedings traction overlapping relations. annual meeting association computational linguistics human language technologies-volume pages association computational linguistics rodolphe jenatton nicolas roux antoine bordes guillaume obozinski. latent factor model highly multi-relational data. advances neural information processing systems pages yankai zhiyuan maosong sun. modeling relation paths representation learning knowledge bases. proceedings conference empirical methods natural language processing association computational linguistics yankai zhiyuan maosong yang xuan zhu. learning entity relation embeddings knowledge graph completion. proceedings twenty-ninth aaai conference artiﬁcial intelligence maximilian nickel volker tresp hans-peter kriegel. three-way model collective proceedings learning multi-relational data. international conference machine learning pages maximilian nickel volker tresp hans-peter kriegel. factorizing yago scalable machine learning linked data. proceedings international conference world wide pages richard socher danqi chen christopher manning andrew reasoning neural adtensor networks knowledge base completion. vances neural information processing systems pages ilya sutskever joshua tenenbaum ruslan salakhutdinov. modelling relational data using bayesian clustered tensor factorization. advances neural information processing systems pages zhen wang jianwen zhang jianlin feng zheng chen. knowledge graph embedding translating hyperplanes. proceedings twentyeighth aaai conference artiﬁcial intelligence pages", "year": 2015}