{"title": "Decoupled Learning for Factorial Marked Temporal Point Processes", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "This paper introduces the factorial marked temporal point process model and presents efficient learning methods. In conventional (multi-dimensional) marked temporal point process models, event is often encoded by a single discrete variable i.e. a marker. In this paper, we describe the factorial marked point processes whereby time-stamped event is factored into multiple markers. Accordingly the size of the infectivity matrix modeling the effect between pairwise markers is in power order w.r.t. the number of the discrete marker space. We propose a decoupled learning method with two learning procedures: i) directly solving the model based on two techniques: Alternating Direction Method of Multipliers and Fast Iterative Shrinkage-Thresholding Algorithm; ii) involving a reformulation that transforms the original problem into a Logistic Regression model for more efficient learning. Moreover, a sparse group regularizer is added to identify the key profile features and event labels. Empirical results on real world datasets demonstrate the efficiency of our decoupled and reformulated method. The source code is available online.", "text": "factorial marked temporal point process mentioned marked point process represented single mark single discrete variable many application scenarios event carry multiple markers. instance movement carries label position label company treated orthogonal markers different values. though cases ubiquitous real world factorial marked point processes drawn little attention literature existing literatures mostly work single marker inspired factorial hidden markov models introduce factorial marked temporal point process event represented multiple markers propose decoupling method learn process. intensity function problem statement core concept point process intensity function represents expected instantaneous rate events time conditioned history. basic intensity function constant time used homogeneous poisson process. another popular form used denotes event history marker-vs.marker infectivity kernel capturing temporal dependency event paper interested describing factorial marked point process event marker prediction task using history event information individual level proﬁle event taker. focus next-event label estimation distributed markers. particular empirical study focuses individual level next prediction involving position company linkedin users duration prediction current department transition prediction next department patients mimic-ii database abstract—this paper introduces factorial marked temporal point process model presents efﬁcient learning methods. conventional marked temporal point process models event often encoded single discrete variable i.e. marker. paper describe factorial marked point processes whereby time-stamped event factored multiple markers. accordingly size infectivity matrix modeling effect pairwise markers power order w.r.t. number discrete marker space. propose decoupled learning method learning procedures directly solving model based techniques alternating direction method multipliers fast iterative shrinkage-thresholding algorithm; involving reformulation transforms original problem logistic regression model efﬁcient learning. moreover sparse group regularizer added identify proﬁle features event labels. empirical results real world datasets demonstrate efﬁciency decoupled reformulated method. source code available online. index terms—factorial temporal point process decoupled learning alternating direction method multipliers fast iterative shrinkage-thresholding algorithm events ubiquitous across different domains applications. e-commerce events refer transactions associated users items. health informatics event sequence series treatment time patient. predictive maintenance events carry important data failure occurs type. examples effectively modeling predicting dynamic behavior vital importance practical usefulness. marked temporal point process point process useful tool modeling event sequence arbitrary timestamp associated event. event point process carry extra information called marker. marker typically refers event type lies discrete label space i.e. ﬁnite category school computational science engineering college computing georgia institute technology atlanta georgia east china normal university shanghai china. e-mail zhacc.gatech.edu general concept found marked point pattern point process carries extra information called mark random variable several random variables geometrical shape information. paper focus discrete labels marks. marked point process also termed multi-dimensional point process dimension refers discrete mark value. learning temporal point process point process powerful tool modeling event sequence timestamp continuous time space. early work dates back hawkes processes shows appropriateness selfexciting mutual-exciting process like earthquake aftershock learning fulﬁlled maximum likelihood estimation directly computing gradient hessian matrix w.r.t. log-likelihood function recently modernized machine learning approaches devise efﬁcient algorithms learning parameters speciﬁed point process. nonparametric expectation-maximization algorithm proposed multiscale hawkes processes using majorization-minimization framework shows superior efﬁciency robustness compared sampling based estimation methods. extends technique handle multi-dimensional hawkes process adding low-rank sparsity regularization term maximum likelihood estimation based loss function. factorial model though almost works mentioned involve infectivity matrix model parameters learning none considers factorial temporal point process case i.e. event type factored multiple markers leads explosion infectivity matrix size. idea factorizing events states multiple variables employed hidden markov models using variational methods solve data mining task like capturing statistical structure little literature found utility point process. best knowledge ﬁrst work factorial marked point process learning event marker prediction. note timestamp prediction approximated predicting predeﬁned time interval time duration marker done paper. sparse regularization point process sparse regularization well-established technique traditional classiﬁcation regression models regularizer group lasso sparse group regularizer etc. recent point process models also found applications like regularization used ensure sparsity social infectivity matrix nuclear norm low-rank network structure group lasso feature selection. propose sparse group regularizer encourages nonzero elements focusing columns obeying intuition features labels play major role event dynamics. little work literature group sparse regularizer point process learning. contributions main contributions paper introduce concept factorial marked point process event marker prediction propose decoupled learning algorithm simplify factorial model decoupling marker mutual relation modeling. method outperforms general marked point process real-world datasets. present multi-label logistic regression perspective devise reformulation towards class point process discriminative learning problems. eases learning processes using on-the-shelf solver. factorial point process refers processes event factorized multiple markers. except movement prediction department prediction mentioned introduction many application cases described factorial point process haven’t explored yet. instance weather forecast containing temperature humidity precipitation wind seen factorial point process markers marker discrete continuous values. obviously factors affect other e.g. humidity today inﬂuenced precipitation temperature recent days. conventional marked point process could model factors using single marker without considering infectivity factors. factorial point process multiple markers event essential. learning factorial point process challenging. taking movement prediction markers company position example predict probability user n-th need learn -dimension tensor representing impact history companies {ci}n− impact history positions {pi}n− respectively. point process means need learn intensity functions including simple case considers infectivity different sequences i.e. also consider impact another user movement user choice would compute -dimension tensor measure complete infectivity extra intensities ways simplify factorial point process learning e.g. treat combination multiple factors marker conventional marked point process model lead explosion size infectivity matrix. paper explore simple decoupling solution decouple factorial point process separate models different markers respectively. shown fig. instance markers decouple original infectivity matrix smaller introducing tensor variable acc. present decoupled model details following section. generally discuss situation event factorized markers given event sequence event marker intensity function conventional marked point process model marker deﬁned time-invariant features sequence taker extracted proﬁle like self-introduction linkedin users patients’ diagnose mimic-ii database corresponding coefﬁcients. marked point process model marker contains multiple label dimensions major bottleneck mz)× measure directional effect generally size infectivity matrix however objective function tailored particular task hand instead taking care handling posterior probability whole event sequence interested predicting next event mark information. enable discriminative learning paradigm boost next event prediction accuracy recent work suggests focus loss function learning. decoupled point process model dependency between different markers measured inter-inﬂuence parameters i.e. dependency process marker marker process measured parameter azyi ayzi independent fashion. spirit simplify probability independence assumption marker marker involves many parameters learning natural idea introducing sparsity reduce complexity. incorporating group sparsity overall sparsity sparse group regularizer regularization combination regularization group lasso encourages nonzero elements concentrated columns whole matrix rest part assumed zeros. regularization encourages whole matrix sparse. behind rationale proﬁle features event marker values main contributor point process. means mitigate challenge learning parameter large sequences relatively short propose decoupled factorial point process model linearly decouple intensity func tion interdependent point processes z-th marker written binary indicators connecting inﬂuence one’s former marker markers note vector azzi r×mz parameter intra-inﬂuence within marker {zi} azyi r×my inter-inﬂuence vectors illustrated fig. using notation fact function predeﬁned embodiments chosen table time being specify functions focus solving learning problem general setting. fig. example decoupling perspective factorial event sequence learning. event sequence represented three-marker label space decouple model treats sequence overlay three sequences whose marker space respectively whole marker space’s dimension linear directed dash arrows events sketch effect previous events future events within three sequences also across three sequences. particular attentions shall paid model method designated predict next event’s marker continuous occurrence timestamp enable next event time prediction discretize time interval several levels illustrated hand accurate timestamp rather discretized version used learning point process model makes sure model capture ﬁne-grained time information. following scheme admm propose fista based method line search soft-shrinkage operators solve subproblems admm. whole algorithm summarized alg. reformulated decoupled learning factorial marked point process learning softmax sample classiﬁers. z-th classiﬁer takes classify markers ˆmz. following experiments show reformulated learning method fact optimizes loss function alg.. predict given history next event markers ˆmz|z computing predictions given ˆmz∈mz important note though model technically issues discrete output inherently classiﬁcation model practice future events’ timestamp predicted approximated discrete duration done experiments. regard treat future timestamp marker. verify potential proposed model apply linkedin-career dataset crawled de-identiﬁed linkedin predict user’s next company next position duration current job; dataset extracted public medical database mimic-ii predict patient’s transition next department duration stay current department. experiments conducted ubuntu .lts .ghz× ram. convenience replicating experiments crawled deidentiﬁed linkedin-career dataset code available github. based intensity function loss function show reformulate learning decoupled point process multi-class logistic regression task. obvious merit reformulation reuse on-the-shelf solvers e.g. http//www.yelab.net/software/slep/ little parameter tuning. contrast algorithm presented linkedin including selfintroduction technical skills working experience de-identiﬁcation preprocess. collect samples industry because staff turnover rate high makes easier collect suitable samples; industry familiar authors domain knowledge help better curate data. extract proﬁle features users’ self-introduction technical skills users’ history company position working experience. exclude samples zero movement so-called linkedin-career benchmark involving users companies kinds positions kinds durations. dataset extent representative industry. companies large corporations like google facebook microsoft medium-sized enterprise like adobe hulu vmware. positions technical positions like engineer senior engineer tech lead management positions like manager director ceo. durations discretize duration stay position company temporary short-term mediumterm long-term. goal predict user’s next company companies next position positions duration stay current company position durations. dataset contains patients mimicii database including patients’ diagnose treatment record transition different departments duration stay departments. goal predict patient’s next department departments including coronary care unit anesthesia care unit fetal cardiac surgery recovery unit medical trauma surgical neonatal general ward predict patient’s duration stay kinds duration including temporary short-term longterm proﬁle features extracted patients’ diagnose treatment record many peer methods evaluated follows intensity function choices framework tested four point process embodiments namely mutually-corrected processes hawkes process iii) self-correcting process modulated poisson process characters brieﬂy compared table note experiments models learned reformulated algorithm described alg. table comparison admm solver reformulated solver prediction accuracy percentage joint prediction accuracy accpt time cost average iteration count random initialization trials. time iteration number average result. moreover explore effect discretizing time interval making duration prediction also experiment rmtpp proposed instead predicting discrete label duration gives continuous prediction result. prediction performance metrics prediction accuracy evaluate performance model four variants accpt denote prediction accuracy state state state joint respectively. evaluate performance discrete duration prediction compared rmtpp computed. compute prediction predicted discrete duration substituted intermediate time point discrete intervals e.g. years temporary stay years short-term stay years longterm stay. compute prediction predicted continuous duration rmtpp discretized using criterion proposed model. linkedin-career data compute precision curve top-k position company duration predictions shown fig. metrics widely used recommender system. fact model predicting next company next position duration given career history used recommending companies posts predicted time period solver admm solver make fair comparison solver admm solver i.e. alg. share initial parameter initialized uniform distribution sampling running time iteration count average -fold cross validation. table compares solver admm solver regarding accuracy time cost dataset linkedin-career icu. prediction accuracy similar admm solver costive converges slowly shown fig.. also shown alg. involves hyperparameters tune tuned best performance. comparison reformulated table accuracy comparison different intensity functions linkedin-career numbers bold denote best second-best accuracy speciﬁed metric dataset. learning point process based models reformulated solver discussed main paper. long sequence denotes transitions. non-point process based lrnp present performance prediction target. comparing running time table solver better scalability admm solver. admm solver general algorithm convex optimization sparse group regularization solver works special design objectives reformulated logistic regression loss. many algorithmic optimizations logistic regression used solver like efﬁcient projection slep table decoupled marked point process model much better performance rnn. next-event prediction task relatively short sequences like dataset linkedin-career typical sequence classiﬁcation task. need make prediction every step sequence rather make prediction whole sequence. means end-to-end sequence classiﬁcation model needs deal sequences considerably variable length including large number sequences length table comparison future event duration prediction rmtpp decoupled linkedin dataset. note rmtpp model predicts continuous timestamp value future events. patients’ demand transition next department decrease move department department transition prediction; probability future events inﬂuenced history events according table i.e. one’s transition possibility related his/her history career experience patient’s future department transition procedure related his/her history treatment. inﬂuence sequence length explore performance behavior experiment short-sequences long-sequences respectively linkedin-career. results table show decoupled algorithm advantage long-sequence prediction suggesting decoupled make better history information. inﬂuence sparsity verify effect sparse group regularization compare accuracy decoupled model different regularization settings including without sparse regularization group lasso group sparsity sparse group regularization regularization group lasso overall sparsity group sparsity. shown table sparse group regularizer outperforms. also explore feature selection functionality investigating magnitudes elements matrix element measures inﬂuence proﬁle feature marker label small values indicate corresponding features markers little inﬂuence label. example linkedin-career dataset numerical values coefﬁcient column vector corresponding marker engineer nonzero showing working experience engineer important industry. marker director elements corresponding coefﬁcient column vector zero except rows positions ounder suggesting ascending career path general. verify effect discretizing time interval making duration prediction decoupled-mcp rmtpp also compared table though little tricky discrete wrong prediction leads smaller continuous wrong prediction e.g. ground truth medium-term duration years misclassiﬁed longterm duration years de-mcp rmtpp gives continuous prediction value years de-mcp relatively also absolutely small. shows discretization time interval extent rational. iii) infectivity matrix decoupling coupling table table also compare performance decoupled model coupled model simpliﬁed model marker considered. boils singledimension case method termed uni-com unipos uni-dur dataset linkedin-career uni-duration uni-transition respectively. uni-cpt involves model uses output uni-c uni-p uni-t combine together joint prediction. shows decoupled model consistently achieves best performance perhaps attributed reduction model complexity given relatively limited training data. comparing accuracies table dataset linkedincareer table dataset improvement accuracy decoupled model compared coupled model single-dimension model remarkable linkedin-career icu. reason linkedin-career coupled state space decoupled decoupled linkedincareer dataset larger coupled state space icu. decoupled smaller state spaces improvement linkedin-career notable icu. choice intensity function many popular intensity forms listed table according table table mutually-correcting process consistently shows superior performance intensity function embodiments. veriﬁes simple assumptions intensity tends decrease moment event happens i.e. desire suppressed fulﬁlled prediction study problem factorial point process learning event carry multiple markers whereby relevant concept found factorial hidden markov models learning algorithms presented ﬁrst directly based regularized discriminative prediction objective function employs admm fista techniques optimization; second simple solver based reformulation objective function. experimental results real-world datasets collaborate effectiveness approach. work partially supported national natural science foundation china national research development program china nsfc-zhejiang joint fund integration industrialization informatization xiao yang modeling intensity function point process recurrent neural networks aaai ghahramani jordan factorial hidden markov models advances neural information processing systems hawkes spectra self-exciting mutually exciting goldberger amaral glass hausdorff ivanov mark mietus moody c.-k. peng stanley physiobank physiotoolkit physionet components research resource complex physiologic signals circulation vol. trivedi upadhyay gomez-rodriguez song recurrent marked temporal point processes embedding event history vector proceedings sigkdd international conference knowledge discovery data mining. weichang received b.s. degree electronic engineering huazhong university science technology china currently pursuing ph.d. degree department electronic engineering shanghai jiao tong university shanghai china. current research interests include data mining especially medical information mining disease modeling based event sequence learning. junchi currently associate professor shanghai jiao tong university. that senior research staff member principal scientist visual computing research started career since april obtained ph.d. department electronic engineering shanghai jiao tong university china. received china doctoral dissertation nomination award china computer federation doctoral dissertation award. research interests machine learning visual computing. serves associate editor ieee access executive board china multimedia chapter. xiaokang yang received degree xiamen university xiamen china degree chinese academy sciences ph.d. degree shanghai jiao tong university currently distinguished professor school electronic information electrical engineering shanghai jiao tong university shanghai china. research interests include visual signal processing communication media analysis retrieval pattern recognition. serves associate editor ieee transactions multimedia associate editor ieee signal processing letters. hongyuan professor school computational science engineering college computing georgia institute technology east china normal university. earned degree scientiﬁc computing stanford university since working information retrieval machine learning applications numerical methods. recipient leslie prize institute mathematics applications outstanding paper awards international conference advances neural information processing systems best student paper award sigir international conference information retrieval associate editor ieee transactions knowledge data engineering.", "year": 2018}