{"title": "Being Negative but Constructively: Lessons Learnt from Creating Better  Visual Question Answering Datasets", "tag": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "abstract": "Visual question answering (QA) has attracted a lot of attention lately, seen essentially as a form of (visual) Turing test that artificial intelligence should strive to achieve. In this paper, we study a crucial component of this task: how can we design good datasets for the task? We focus on the design of multiple-choice based datasets where the learner has to select the right answer from a set of candidate ones including the target (i.e. the correct one) and the decoys (i.e. the incorrect ones). Through careful analysis of the results attained by state-of-the-art learning models and human annotators on existing datasets, we show the design of the decoy answers has a significant impact on how and what the learning models learn from the datasets. In particular, the resulting learner can ignore the visual information, the question, or the both while still doing well on the task. Inspired by this, we propose automatic procedures to remedy such design deficiencies. We apply the procedures to re-construct decoy answers for two popular visual QA datasets as well as to create a new visual QA dataset from the Visual Genome project, resulting in the largest dataset for this task. Extensive empirical studies show that the design deficiencies have been alleviated in the remedied datasets and the performance on them is likely a more faithful indicator of the difference among learning models. The datasets are released and publicly available via http://www.teds.usc.edu/website_vqa/.", "text": "visual question answering attracted attention lately seen essentially form turing test artiﬁcial intelligence strive achieve. paper study crucial component task design good datasets task? focus design multiple-choice based datasets learner select right answer candidate ones including target decoys careful analysis results attained state-of-the-art learning models human annotators existing datasets show design decoy answers signiﬁcant impact learning models learn datasets. particular resulting learner ignore visual information question still well task. inspired this propose automatic procedures remedy design deﬁciencies. apply procedures re-construct decoy answers popular visual datasets well create visual dataset visual genome project resulting largest dataset task. extensive empirical studies show design deﬁciencies alleviated remedied datasets performance likely faithful indicator difference among learning models. datasets released publicly available http//www.teds.usc.edu/website_vqa/. recently multimodal information processing tasks image captioning visual question answering gained attention. number signiﬁcant advances learning algorithms made along development nearly dozens datasets active research domain. among datasets popular ones include mscoco visual genome several others. overarching objective learning machine needs beyond understanding different modalities information separately learn correlate order perform well tasks. evaluate progress complex ai-like tasks however challenging topic. tasks involving language generation developing automatic evaluation metric open problem remedied. original dataset correct answer train easily selected machine often used correct answer decoy answers. procedures create alternative decoys correct answer decoys highly likely examining either image question alone. cases machines make mistakes unless consider information together. thus alternative decoys suggested procedures better designed gauge well learning algorithm understand information equally well. paper study design high-quality multiple choices visual task. task machine presented image question list candidate answers. goal select correct answer consistent understanding image question candidate answers. multiple-choice based tests designing presented negative answers refer decoys important deciding questions ask. experience exploiting elimination strategy question easy none three answers could right remaining must correct clever strategy taking exams shortcuts prevent studying faithfully different learning algorithms comprehend meanings images languages noted machines achieve high accuracies selecting correct answer without visual input question clearly learning algorithms overﬁt incidental statistics datasets. instance decoy answers rarely used correct answers machine rule decoy answer binary classiﬁer determines whether answers correct answers note classiﬁer need examine image needs memorizes list correct answers training dataset. fig. example sec. detailed analysis. focus minimizing impacts exploiting shortcuts. suggest principles creating decoy answers. light amount human efforts curating existing datasets visual task propose procedures revise datasets decoy answers better designed. contrast earlier works procedures fully automatic incur additional human annotator efforts. apply procedures revise visualw additionally create multiple-choice based dataset recently released visual genome dataset resulting largest multiple-choice dataset visual task million image-question-candidate answers triplets. conduct extensive empirical human studies demonstrate effectiveness procedures creating high-quality datasets visual task. particular show machines need three information perform well missing information induces large drop performance. furthermore show humans dominate machines task. however given revised datasets likely reﬂecting true human machine understanding multimodal information expect advances learning algorithms likely focus task instead overﬁtting idiosyncrasies datasets. rest paper organized follows. sect. describe related work. sect. analyze discuss design deﬁciencies existing datasets. sect. describe automatic procedures remedying deﬁciencies. sect. conduct experiments analysis. conclude paper sect. provide recent overviews status visual task. dozens datasets task. real-world images based synthetic ones. usually image multiple questions corresponding answers generated. achieved either human annotators automatic procedure uses captions question templates detailed annotations objects. concentrate datasets visualw visual genome images mscoco besides pairs questions correct answers visualw visual madlibs provide decoy answers pair task evaluated multiple-choice selection accuracy. decoy answers focus work. decoys consist human-generated plausible answers well high-frequency random answers datasets. visualw decoys human-generated plausible ones. note that humans generate decoys looking questions correct answers images. thus decoys might unrelated corresponding images. learning algorithm potentially examine image alone able identify correct answer. visual madlibs questions generated limited question templates detailed annotations images. thus similarly learning model examine image alone deduce correct answer. propose automatic procedures revise visualw decoy generation carefully orchestrated prevent learning algorithms exploiting shortcuts datasets overﬁtting incident statistics. particular design goal learning machine needs understand components image-question-answers triplet order make right choice ignoring either components result drastic degradation performance. work inspired experiments observe machines without looking images questions still perform well visual task. others also reported similar issues though multiple-choice setting. work extends providing detailed analysis well automatic procedures remedy design deﬁciencies. section examine detail dataset visualw popular choice visual task. demonstrate deﬁciencies designing decoy questions impact performance learning algorithms. multiple-choice visual datasets training test example triplet consists image question candidate answer contains target decoys denoted triplet thus d··· dk}}. denote either target decoy. investigate well learning algorithm perform supplied different modalities information. concentrate hidden-layer model proposed achieved state-of-the-art results dataset visualw. model computes scoring function given triplet penultimate layer resnet- visual features represent average wordvec embeddings text features represent form joint feature concatenate features together. candidate highest score prediction selected model output. standard training validation test splits visualw contains examples respectively. question candidate answers. parameters learned minimizing binary logistic loss predicting whether candidate target triplet. details sect. supplementary material. first candidate answers used train learning model model performs signiﬁcantly better random guessing humans humans deem answers equally likely without looking image question note case information contains nothing. thus model learns speciﬁc statistics candidate answers dataset exploits those. adding information image machine improves signiﬁcantly gets close performance information used weaker correlation question answers improves modestly. expected. visualw dataset decoys generated human annotators plausible answers questions without shown images thus many decoy answers visual groundings. instance question what animal running? elicits equally likely answers tiger lion image running park immediately rule fig. similar examples. thus performance implies many triplets solved object attribute concept detection image without understanding questions. indeed case also humans humans achieve considering note difference machine human likely difference understanding visual information. note human improves signiﬁcantly i+q+a added machine marginally. difference attributed difference understanding question correlating answers two. since image corresponds multiple questions multiple objects solely relying image work well principle. difference clearly indicates visual model language component weak model cannot fully exploit information making smaller relative improvement humans improved relatively explained above decoy answers drawn plausible answers question irrespective whether visually grounded not. also discovered targets infrequently used decoys. speciﬁcally among training samples unique correct answers used times correct answers question. however among decoys correct answer appears times average chance level times disparity exists test samples too. consequently following rule computing answer’s likelihood correct perform well. essentially measures unbiased used target decoys. indeed attains accuracy test data better random ingguess close learning model using answers information good rules designing decoys based analysis summarize following guidance rules design decoys question unresolvable decoys need equally plausible question. otherwise machines rely correlation question candidate answers tell target decoys even without images. note principle followed datasets. neutrality. decoys answers equally likely used correct answers. image unresolvable decoys need plausible image. appear image exist questions decoys treated targets image. otherwise visual resolved objects attributes concepts detection images even without questions. ideally decoy triplet meet three principles. neutrality comparably easier achieve reusing terms whole targets decoys. contrary decoy hardly meet simultaneously. however long decoys triplet meet neutrality meet others meet triplet whole still achieves three principles machine ignoring either images questions likely perform poorly. section describe approaches remedying design deﬁciencies existing datasets visual task. introduce automatic procedures create decoy answers prevent learning models exploiting incident statistics datasets. main ideas procedures operate dataset already contains image-question-target triplets i.e. assume decoys already. instance used procedures create multiplechoice dataset visual genome dataset decoy. assume image dataset coupled multiple pairs case nearly existing datasets. given triplet create sets decoy answers qou-decoys. search among triplets similar questions targets triplets collected decoys targets similar questions likely plausible question qou-decoys likely follow rules neutrality question unresolvable compute average wordvec represent question similarity measure similarity questions. resolving ambiguous decoys potential drawback automatically selected decoys semantically similar ambiguous rephrased terms target utilize ﬁltering steps alleviate first perform string matching decoy target deleting decoys contain covered target secondly utilize wordnet hierarchy wu-palmer score eliminate semantically similar decoys. score measures similar word senses based depth word senses taxonomy least common subsumer. compute similarity strings according scores similar manner score used evaluation visual performance. eliminate decoys higher wup-based similarity target. nltk toolkit compute similarity. supplementary material details. details qou-decoys sort keep triplet similar triplets entire dataset according question similarity. triplet compute wupbased similarity potential decoy target successively accept similarity decoys. also perform check among selected decoys ensure similar other. iou-decoys potential decoys sorted randomly. wup-based similarity threshold applied remove ambiguous decoys. several authors noticed design deﬁciencies existing databases proposed ﬁxes dataset used procedure generate iou-decoys. empirically show iou-decoys signiﬁcantly remedy design deﬁciencies decoys datasets. several previous efforts generated decoys similar spirit qou-decoys. automatically decoys similar questions captions based question templates annotated objects tri-grams glove embeddings paragraph vectors linguistic surface similarity respectively. later different tasks visual considers removing semantically ambiguous decoys like ours. humans create decoys given questions targets. shown previously decoys fail rule neutrality. real dataset uses images mscoco training/validation/testing splits construct triplets. totally triplets generated images. question candidate answers general decoys human-generated randomly sampled randomly sampled frequent-occurring targets. test indicate targets studies focus training validation sets. visual genome dataset uses images mscoco contains triplets. decoys provided. human annotators asked write diverse pairs questions answers freely image respect regions average image coupled question-answer pairs. divide dataset non-overlapping %/%/% training/validation creating decoys create qou-decoys iou-decoys every triplet dataset following steps sect. cases cannot decoys include random ones original decoys visualw; randomly include frequently-occurring targets. visual models utilize models mentioned sect. experiments. denote mlp-a mlp-qa mlp-ia mlp-iqa models using i+q+a multimodal information respectively. hidden-layer neurons. -layer resnet compute visual features -dimensional. resnet pre-trained imagenet wordvec feature questions answers -dimensional pre-trained google news. parameters models learned minimizing binary logistic loss predicting whether candidate answer target corresponding triplet. stochastic gradient descent mini-batch size momentum stepped learning rate policy optimization. tune number iterations step size using validation set. details supplementary material. evaluation metric visualw compute accuracy picking target multiple choices. follow protocol comparing picked answer human-generated targets. accuracy computed based number exactly matched targets decoy sets compare dataset thus derive several variants orig original sets decoys datasets orig replaced ones selected qou-decoys generating procedure orig replaced ones selected iou-decoys generating procedure +iou orig replaced ones combining combining orig iou. user studies automatic decoy generation lead ambiguous decoys mentioned sect. thus conduct user study amazon mechanic turk test humans’ performance datasets remedied automatic procedures. select dataset triplets. triplet answered three workers total workers involved. report average human performance compare learning models’. supplementary material details. effectiveness decoys better decoys force learning models integrate pieces information images questions answers make correct selection multiple-choices. particular prevent learning algorithms exploiting shortcuts partial information sufﬁcient performing well visual task. table clearly indicates goals achieved. orig decoys relatively small gain mlp-ia mlp-iqa suggests question information ignored attain good performance. however iou-decoys require questions help resolve gain substantial likewise qou-decoys including images information improves mlp-qa substantially mlp-iqa’s note orig decoys gain smaller expected mlp-ia matches better qou-decoys iou-decoys mlp-qa around. thus natural combine decoys. particularly appealing mlp-iqa improves noticeably models learned partial information combined +qou-decoys furthermore using answer information attains chance-level accuracy. dataset observations hold though lesser degree. columns observe substantial gains complementary information added model improvements much visible observed original decoy sets. combining table notice improvements mlp-qa mlp-iqa tend lower facing iou-decoys. also expected difﬁcult decoys simultaneously answers tend target answers. nonetheless deem future direction explore. differences across datasets contrasting visualw notice visualw tends bigger improvements general. fact many questions targets valid decoy target vice versa. decoys already captured orig adding decoy answers make noticeable improvement. supplementary material however show remove questions/answers pairs degree improvements increases substantially. mlp-iqa trained qavg decoys. model initializes models visualw datasets. report accuracies ﬁne-tuning together best results learned solely datasets respectively. shown table ﬁne-tuning improves performance datasets. particular result original visualw attains state-of-the-art previously best performance dataset reported model pre-trained ﬁne-tuned visualw. present fig. examples image-question-target triplets together iou-decoys qou-decoys target. predictions corresponding mlp-iqa also included. ignoring information images questions makes extremely challenging answer triplet correctly even humans. ﬁltering steps sect. fail observed example. wup-based similarity relies wordnet hierarchy. semantically similar words like lady woman similarity much lower dog. issue alleviated considering alternative semantic measures wordvec used searching similar questions. question ambiguous answer. bottom example fig. candidates seem valid target. another representative case asked background image. images contain mountains distance terms valid. perform detailed analysis existing datasets multiple-choice visual found design decoys inadvertently provide shortcuts machines exploit perform well task. describe several principles constructing good decoys propose automatic procedures remedy existing datasets. also created dataset applying procedures visual genome resulting largest multiple-choice dataset task million image-question-candidate answers triplets. conduct extensive empirical studies demonstrate effectiveness methods creating better visual datasets. remedied datasets visual genome based dataset released available http//www.teds.usc.edu/website_vqa/.", "year": 2017}