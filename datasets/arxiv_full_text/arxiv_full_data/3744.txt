{"title": "A Discipline of Evolutionary Programming", "tag": ["cs.NE", "cs.AI", "cs.CC", "cs.DS", "cs.LG", "cs.MA", "I.2,E.1,F.1"], "abstract": "Genetic fitness optimization using small populations or small population updates across generations generally suffers from randomly diverging evolutions. We propose a notion of highly probable fitness optimization through feasible evolutionary computing runs on small size populations. Based on rapidly mixing Markov chains, the approach pertains to most types of evolutionary genetic algorithms, genetic programming and the like. We establish that for systems having associated rapidly mixing Markov chains and appropriate stationary distributions the new method finds optimal programs (individuals) with probability almost 1. To make the method useful would require a structured design methodology where the development of the program and the guarantee of the rapidly mixing property go hand in hand. We analyze a simple example to show that the method is implementable. More significant examples require theoretical advances, for example with respect to the Metropolis filter.", "text": "genetic ﬁtness optimization using small populations small population updates across generations generally suﬀers randomly diverging evolutions. propose notion highly probable ﬁtness optimization feasible evolutionary computing runs small size populations. based rapidly mixing markov chains approach pertains types evolutionary genetic algorithms genetic programming like. establish systems associated rapidly mixing markov chains appropriate stationary distributions method ﬁnds optimal programs probability almost make method useful would require structured design methodology development program guarantee rapidly mixing property hand hand. analyze simple example show method implementable. signiﬁcant examples require theoretical advances example respect metropolis ﬁlter. performance analysis genetic computing using unbounded exponential population sizes population updates across generations directly applicable real practical problems always deal bounded population size preliminary version published proc. int’nl workshop algorithmic learning theory lecture notes artiﬁcial intelligence vol. springer-verlag heidelberg partially supported european union neurocolt esprit working group project aladdin contract number author’s aﬃlliations university amsterdam. evolutionary development population. establish fast feasible speed convergence distribution populations obtain monte carlo sampling optimal type individual high probability. method propose clearly used wide range genetic computing models includes genetic algorithms strings genetic programming trees forth. application method problems another matter; examples solving trivial problems don’t example solving diﬃcult problem. main question future research supply application. structure paper follows. section explain ﬁnite markov chain model genetic processes. states chain correspond ﬁnite populations. transition probability states induced selection reproduction ﬁtness rules since evolution generation generation random process using ﬁnite populations diﬀerent evolutions diverge. case consider evolutions probability density distributions. idea view processes corresponding inﬁnite populations completely transformed generation. view approximation large populations large updates generations average possible evolutions ﬁnite population. evolutions considered several authors convenient vehicle analyze genetic processes completely deterministic. section show even view deterministic evolution average evolution average behave diﬀerent every particular real evolution. crucial point particular evolution strays average. analyze relation population size population update size. mild conditions guarantee ergodicity markov chain converges stationary distribution states stationary distribution sample populations. total stationary probability concentrated populations containing individual best ﬁtness large enough process ﬁnds individual high probability. approach workable must small enough populations convergence stationary distribution fast. convergence stationarity fast enough rapidly mixing markov chains. chains recently basis spectacular randomized approximation algorithms combinatorial counting statistical physics combinatorial optimization certain quadratic dynamic processes related genetics inﬁnite populations section introduces general genetic computing. eﬃciency technique applications depends crucially rate convergence markov chain. since number states typically large chain reach equilibrium particular evolution explored tiny fraction state theory genetic computing important demonstrate formal method genetic ﬁtness optimization together rigorous analysis demonstrating strategy guaranteed work high probability rather intuitive heuristic arguments. application genetic computing sampling stationary distribution proposed process uses large number short runs opposed long run. show method meaningful demonstrate problem section fact trivially successful abundance optimal solutions. really signiﬁcant examples currently much harder— already beyond scope exploration. along development structured methodology genetic system resulting markov chain rapidly mixing moreover types suﬃciently high ﬁtness obtained suﬃciently high probability ﬁnal stationary state distribution. mind design methodology develop genetic system satisfying requirements speciﬁcations problem statement. trees whatever—our discussion general precise objects don’t matter. even types grow practically speaking still upper bound genetic system tries solve optimization problem following sense. individual graded terms well solves problem genetic system supposed solve expressed function maps grading example real interval ﬁtness type then normalized ﬁtness individual applied perspective several researchers observed earlier pays restart population evolution takes unpromising direction example also koza l.j. eshelman algorithms speciﬁcally restart automatically many others. thoughts ﬁtness proportional selection selection individuals population according probability related product frequency occurrence ﬁtness. population definition sequence random variables outcomes ﬁnite state space ﬁnite state time-homogeneous markov chain every ordered pair states quantity called transition probability state state independent markov chain associated transition matrix deﬁned ij=. matrix non-negative stochastic sums unity. elements. elements constitute linear list intervals marked selected elements—exlusive selected elements—represents elements types result follows directly.) associated transition matrix general closed form expression transition probabilities simple ga’s derived asymptotics steady state distributions population size increases determined. observed mentioned closed form expression allows expression ‘expected waiting time global optimum encountered ﬁrst time’ ‘expected waiting time ﬁrst optimum within error tolerance global optimum’ ‘variance measures run’ analysis provided. instead initial experimental work reported. interested quantitative estimates expressions. example consider process generation next population current population consists sampling individuals removing individuals producing population ′′s{w small population size sample size cause evolutionary trajectories drift apart. without loss generality illustrated simpliﬁed setting ignoring ﬁtness selection. deterministic evolution sort average evolutions underlying populations problems. given distribution density local transition matrix transformation deﬁned probability density evolution particular nice properties demonstrated hold population evolutions. particular probability density evolution converges. distribution called equilibrium distribution simple ﬁtness selection general quadratic dynamical systems without ﬁtness selection following convergence property derived. certain inﬁnite evolutionary models equivalent transformation probability densities evolution develops deterministically according equation practice things diﬀerent. namely single evolution probability density diﬀerent every evolution represented population. populations small population updates across successive generations small dealing random process chance selections cause great divergence evolution populations. practice evolutionary computing always case. would like quantify this. primarily considering probability densities neither explores explicit quantitative manner divergence trajectories individual runs based population sizes. rather focus issue population size grows divergence possible trajectories gets progressively smaller. limit inﬁnite populations generations converge expected trajectory smaller populations. clearly trajectories small envelope around expected trajectory expected trajectory good predictor happens individual run. moreover expected trajectory corresponds trajectory equation system analyzed analysis transformation tells expect individual bounded population however expected trajectory completely diﬀerent individual trajectories; individual trajectories bounded populations diverge wildly expected trajectory predict anything happens individual run. analysis like deal individual genetic algorithm rather sequence expectations individual runs system. expectation anything actually happens. this consider dictatorial coin gives ﬁrst outcome fair odds. however afterwards always gives outcome. either produces equal probabilities. expectation obtaining trial however actual fact trial either probability probability outcome terms formalism initially express dictatorial coin terms evolutionary processes analyze happens continue markov chain termonology. example formulate dictatorial coin example evolutionary format equation transformation given figure evolution probability densities transformation next uniform probability replacement draw elements current population. subsequently execute cross-over according matrix. resulting individuals form next generation. entry gives transition probability going state denote probability state steps since markov chain ergodic pointwise limit limt→∞ exists stationary distribution. satisfy population probability population population probability population stay population next generation probability small almost surely. therefore evolution quickly settle either henceforth remain long time. assume ﬁnite population probability density drawing individual selection phase. assume furthermore selection phase draw sample cardinality larger better approximate resulting frequencies. quantitatively works follows. next probability distribution deﬁned equation frequency distribution obtain basis outcome drawing examples. considerations dependence problematic. convenient replace every gives probability exceed value pair probability exceed value pair upper bounded r/eα′. hence probability exceed value pair least conclude every absolute error estimate population associated density distribution obtain probability distribution associated probability density population resulting eliminating pair individuals adding pair individuals example start population size containing diﬀerent types types positive probability selected produce next generation. tions therefore distributions ˆp′. every population obtained probability generations. single deterministic evolution generations probability distributions reference shows probability distribution inﬁnite quadratic crosssystem stays duration evolution generations appropriate sense close population size initially drawn randomly inﬁnite population. upshot considerations limited size populations population updates variation evolutions great. practice always deal limited size populations individuals. question arises overcome problem individual evolution become trapped undesirable niche—as example —for example niche consisting populations non-optimal individuals. answer need randomize evolutions. inspecting populations random sample evolutions want almost surely individual best ﬁtness. latter easy inspected evolutions large covers almost populations. infeasible general. look easy tricks point example m.o. rabin others observed power randomization deterministic algorithms solve problems probability almost repeated independent runs algorithm provided single probability error appropriately less direct application probability boosting evolutionary computing follows. random variable deﬁned ﬁrst-case optimal solution randomized algorithm like observation useful must show case interest expected running time ﬁrst-case hitting time optimal solution polynomial problem dimension. fact suﬃces case respect subset computations appropriate positive probability like equation follow exposition given ergodic markov chain consider problem sampling elements state space assumed large according stationary distribution desired distribution realized picking arbitrary initial state simulating transitions markov chain according probabilities assume computed locally required. number simulated steps increases distribution random variable approach rate approach stationarity expressed following time-dependent measure largest relative distance state maximized possible states parameter allows specify relevant portions state space. case omit subscript write instead |λi| transient behavior chain hence rate convergence governed magnitude eigenvalues reversible case second characterization implies eigenvalues symmetric matrix d/qd−/ real. leads following clean formulation dependence negative eigenvalues? able apply lemma without oscillations require eigenvalues positive. turns simple modiﬁcation chain negative eigenvalues turns chain positive eigenvalues without definition given family ergodic markov chains parametrized strings given alphabet. denote r.p.d. entire state space steps deﬁne function positive reals natural numbers question arises whether approach rapidly mixing markov chains generalized reversible chains non-reversible chains. aﬃrmatively settled another treatment later given short discussion celebrated result jerrum sinclair shows rapidly mixing markov chains obtain randomized algorithm approximates value permanent matrix within ratio probability markov chain renaissance employ rapidly mixing markov chains obtain fully polynomial randomized approximation schemes hard problems computer science applications generate uniform stationary distribution approximation obtained monte carlo sampling states determining proportion successful states. application genetic computing proceed diﬀerently high probability sample states containing best individual illustrate idea example section chain evolutionary process converges concentrate suﬃcient amount probability populations containing maximally individuals populations containing individuals enable compute required solutions. populations containing least solution best ﬁtness stationary probability population ensure feasibility algorithm customarily require polynomial problem parameter. rapid mixing property satisﬁed evolutionary system satisfy structural properties. properties least principle always taken care implementing evolutionary system choosing selection rules cross-over operator mutation rules appropriately. requirements covered section question probability concentration property subtle clear generally even principle. many cases satisﬁed obtain approximately globally optimal solution. structural discipline evolutionary programming need develop methodology given problem speciﬁcation guides construct evolutionary system associated markov chain satisﬁes following requirements property required matrices irreducible nonnegative entries. since matrices consider stochastic entries transition probabilities case easy satisfy ‘suitable’ condition property since deal ergodic matrices required ergodicity property always satisﬁed case. ergodicity immediate positive mutation probability transforming pair types hence proper choice genetic system leading suitable transition probabilities inducing rapidly mixing markov chain satisfy property construction evolutionary system. perhaps less easy whether feasible satisfy property particular case indeed without knowing optimal individual priori. however discussed similar approach approximating hard combinatorial optimization problems worked ﬁne. paradigm. running program longer polynomial number generations signiﬁcantly change closeness state distribution stationary distribution markov chain. guarantee state containing optimal individual probability inversely polynomial problem parameter. however polynomially repeating procedure implies monte carlo sampling almost surely discovers individual optimal ﬁtness. transition population next generation follows. avoid problems periodicity self-loop probability state note also dispenses problem negative eigenvalues. consequently probability state changes using crossover mutation probability stays same. probability selecting string population selection phase select individuals according probabilities probability perform crossover mutation crossover operator interchanges single corresponding selects single position uniform probability subsequently mutate oﬀspring ﬂipping single uniform probability chosen positions ﬁrst prove rapid mixing showing following system rapidly mixing system initial state binary l-vector. step uniformly random select position current l-vector ﬁfty-ﬁfty probability produce next l-vector. markov chain states binary l-vectors. proof system almost uniform generator using singleton populations suﬃces arbitrary starting singleton population. terms ga’s single-bit mutation. example involves single-bit mutation single-bit cross-over selection. reader advised cosmetic change make example look like ‘realistic’ example essentially example lemma this consider vectors successive generations lemma o)). probability least l-vector every l-vector probability changed generations proof. fraction least runs steps population elements element selected frequency least selection indexes individuals mated produce next generation. possible sequences outcomes. hence maximal kolmogorov complexity given moreover since binary descriptions length fraction least /tth part sequences consider binary string consisting blocks length log√l block encoding types. denote number occurrences following vector successive generations consider time selected. times ﬁfty-ﬁfty probability either nothing done vector incurs position selected uniformly random cross-over followed position selected uniformly random mutation. viewpoint individual vector mutation operations alone simply emulates trajectory singleton l-vector lemma length given equation extra random ﬂips cross-over increase length emulation. l-vector. every every l-vector initial population turns exactly steps probability least therefore generates steps every particular population individuals probability individual. however want stationary distribution populations heavily concentrate probability populations containing optimal nearoptimal individuals even populations scarce. example ﬁtness function extend populations maxω∈p{f want generate random element distribution concentrated optimum solutions. similar generating random distribution θ/α) small positive number. then large probability random maximize general method modify random walk converges arbitrary prescribed probability distribution metropolis ﬁlter let’s explain generated current population follows. first select random position string resulting ﬂipping next generation {ω′}; otherwise next population {ω′} probability next population probability clearly modiﬁed random walk markov chain stationary distribution example number optimal individual sampled stationary distribution high probability. unfortunately general known estimate mixing time metropolis-ﬁltered random walk. positive side compute volume n-space using method show ﬁltered walk mixes essentially fast corresponding unﬁltered walk. similar approach combinatorial optimization using markov chain monte carlo method sense metropolis process-type markov chain stationary distribution concentrates high probability optimal solutions surveyed give polynomial time metropolis process approximate maximum matching arbitrary graphs high probability. precisely arbitrary graph vertices algorithm ﬁnds matching accuracy parameter assumed constant—the running time actually exponential however successes scarce. current status references metropolis algorithms suggested theoretical possibility constructing genetic processes provably optimize objective function high probability polynomial time. given simple example that however succeeds abundance optimal solutions. altogether seems diﬃcult time even construct example genetic process rapidly mixing also nonuniform stationary distribution heavily concentrates probability populations containing optimal individuals case populations scarce. example would give evidence power proposed method.", "year": 1999}