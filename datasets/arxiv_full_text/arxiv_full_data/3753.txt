{"title": "Tuning Modular Networks with Weighted Losses for Hand-Eye Coordination", "tag": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY"], "abstract": "This paper introduces an end-to-end fine-tuning method to improve hand-eye coordination in modular deep visuo-motor policies (modular networks) where each module is trained independently. Benefiting from weighted losses, the fine-tuning method significantly improves the performance of the policies for a robotic planar reaching task.", "text": "figure technique improve hand-eye coordination better performance transferring deep visuo-motor policies planar reaching task simulated real environments figure modular neural network used predict q-values given pixel inputs. composed perception control modules. perception module consists three convolutional layers layer extracts physically relevant information single image. control module predicts action q-values given action maximum q-value executed. architecture similar additional end-to-end ﬁne-tuning process using weighted perception task losses. note values normalized interval error robot’s current target position i.e. time step possible actions chosen change robot conﬁguration joint increasing decreasing constant amount leaving unchanged. agent required learn reach using raw-pixel visual inputs monocular camera accompanying rewards network architecture training method additional end-to-end ﬁne-tuning using weighted losses shown fig. perception network ﬁrst trained estimate scene conﬁguration raw-pixel image using quadratic loss function paper introduces end-to-end ﬁne-tuning method improve hand-eye coordination modular deep visuomotor policies module trained independently. beneﬁting weighted losses ﬁne-tuning method signiﬁcantly improves performance policies robotic planar reaching task. recent work demonstrated robotic tasks based directly real image data using deep learning example robotic grasping however methods require largescale real-world datasets expensive slow acquire limit general applicability approach. reduce cost real dataset collection used simulation learn robotic planar reaching skills using deepmind showed impressive results simulation exhibited brittleness transferred real robot camera introducing bottleneck separate perception control modules independent training skills learned simulation easily adapted real scenarios using real-world images however still performance drop compared control module network ideal perception. reduce performance drop propose ﬁne-tuning combined network improve hand-eye coordination. preliminary studies show naive ﬁne-tuning using qlearning give desired result tackle problem introduce novel end-to-end ﬁne-tuning method using weighted losses work signiﬁcantly improved performance combined network. consider planar reaching task deﬁned controlling robot operational space end-effector position moves position target vertical plane reaching controller adjusts robot conﬁguration minimize australian centre robotic vision queensland university technology brisbane australia. fangyi.zhanghdr.qut.edu.au †this research conducted australian research council centre excellence robotic vision additional computational resources services provided research support group qut. results summarized fig. table dmed median third quartile error distance pixels input image also listed. fine-tuned achieved much better performance initial. ﬁne-tuned performance even close control module controls using ground-truth sensing inputs. also evaluations real-world trials baxter achieved similar results. experimental results show feasibility proposed ﬁne-tuning approach. improved hand-eye coordination modular deep visuo-motor policies possible ﬁne-tuning weighted losses. adaptation real scenarios still kept presenting real samples compute perception loss. levine sampedro krizhevsky quillen. learning hand-eye coordination robotic grasping deep learning international symposium experilarge-scale data collection. mental robotics zhang leitner milford upcroft corke. towards vision-based deep reinforcement learning robotic motion australasian conference robotics automation control. separate training perception control individually end-to-end ﬁne-tuning conducted combined network using weighted task perception losses. control network updated using perception network updated using weighted loss pseudo-loss reﬂects loss bottleneck balancing weight. backpropagation algorithm infer βδlp δlbn gradients resulted δlbn gradients resulting respectively evaluated feasibility proposed approach using metrics euclidean distance error average accumulated reward simulated trials. comparison evaluated three networks initial fine-tuned initial combined network without end-to-end ﬁnetuning labelled selected perception control modules best performance individually. fine-tuned obtained ﬁne-tuning initial using proposed approach. works baseline indicating performance upper-limit. ﬁne-tuning used learning rate mini-batch size task perception losses respectively exploration possibility k-gps. parameters empirically selected. make sure perception module remembers skills simulated real scenarios real samples also used obtain δlp. similar samples mini-batch real scenarios i.e. weight updating step extra real samples used addition simulated samples mini-batch δlq.", "year": 2017}