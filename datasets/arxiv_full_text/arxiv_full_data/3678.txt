{"title": "Visualization of Tradeoff in Evaluation: from Precision-Recall & PN to  LIFT, ROC & BIRD", "tag": ["cs.LG", "cs.AI", "cs.IR", "stat.ME", "stat.ML"], "abstract": "Evaluation often aims to reduce the correctness or error characteristics of a system down to a single number, but that always involves trade-offs. Another way of dealing with this is to quote two numbers, such as Recall and Precision, or Sensitivity and Specificity. But it can also be useful to see more than this, and a graphical approach can explore sensitivity to cost, prevalence, bias, noise, parameters and hyper-parameters.  Moreover, most techniques are implicitly based on two balanced classes, and our ability to visualize graphically is intrinsically two dimensional, but we often want to visualize in a multiclass context. We review the dichotomous approaches relating to Precision, Recall, and ROC as well as the related LIFT chart, exploring how they handle unbalanced and multiclass data, and deriving new probabilistic and information theoretic variants of LIFT that help deal with the issues associated with the handling of multiple and unbalanced classes.", "text": "david m.w. powers beijing university technology china flinders university australia technical report kit-- computer science engineering mathematics flinders university basically approaches often correct look often wrong doesn’t really matter this. ignore classes consider marks right wrong simple accuracy error rate usually expressed probability percent correct like marks exam. classifiers often work minimizing error tend think terms good rather bad. therefore focus goodness measures every complementary error measure. approach simplistic several ways. particular problems harder others classes easy predict others indeed situations rare significant costly deserve weight others. problem evaluation machine learning become topical recently series aaai icml workshops well considerable interest graphical visualization methods assist intuitive understanding tradeoffs avoid relying single number however techniques still tend make assumption dealing two-class problem even work seek extend multi-class problem tends reducing graphical representation single number simple average area curve across dichotomous classifiers volume surface multidimensional generalization area curve meaningful interpretation terms probability correctly ranking pair instances variants spread weight possible operating points classifier even though deploy specific case classification requires choosing single operating point. characterized components certainty component related classification optimal operating point consistency component related fall conditions change paper review case classes interest like class relevant documents yes/no questions. consider impact prevalence cost particular classes complementary question bias classifier. addition consider desirability predicting right number instances label impact imbalances errors/noise data implicit relationship cost. concentrate lift visualizations review various advantages disadvantages including derivative measures proposed improve them. finally move multiclass case primary focus difficult issues present proposed modifications address problems produce clear meaningful multiclass visualizations rather single point failure arises information reduced single number irrespective relative accuracy kappa takes. dichotomous case basic measures used evaluation usually based dichotomous distinction right wrong relevant irrelevant positive negative. assume supervised learning paradigm distinguishing positives negatives based dataset containing examples both corresponding dataset evaluating hand-designed hand-tuned system. strictly speaking always least classes classified sometimes focus single class terms evaluation learning rand accuracy hand takes account accuracy classes definable directly contingency table terms weighted averages single class accuracy precision single class recall termed positive terms true positives positive prevalence negative bias prevalence relative frequency empirical probability class bias relative frequency sample probability prediction. table explains standard systematic notation based contingency table showing predicted labels horizontally real labels vertically left hand table shows probabilities. thus left four coloured cells horizontal vertical margins correspond respectively prevalences biases towards corresponding class. right hand table shows counts dependent sample size four coloured cells size test horizontal vertical margins. recall precision also alternate names systematic notation true positive rate true positive accuracy completeness present equations recall precision define f-measure using either harmonic mean recall precision equivalently expressing true positives relative assumed common distribution represented arithmetical mean also show rand accuracy calculated forms contingency table. however easy accuracy prevalence-weighted average recall inverse recall conversely also bias-weighted average precision inverse precision formally recall important measure whole families names inverse complementary forms fields better known sensitivity addition important graphical tradeoff methods based recall family including lift precision-recall graphs. however graphs always biased although often advocated providing clearer detail highly skewed applications like information retrieval skewprev rn/rp skewbias pn/pp systematic naming system table noted true positive rate rate true positives correctly predicted positive similarly true negative rate rate true negatives correctly predicted negative. rates interpreted proportions positives negatives correctly identified equivalently probability positives resp. negatives correctly rates relating errors including particular false positive rate rate true negatives turn falsely positive predictions false negative rate rate true positives turn negatives. recall also known specificity ignored information retrieval close number predictions much smaller number irrelevant documents much scope optimization. case intelligent systems general. fallout characterizing contamination positive predictions proportion negative examples reflection this fpr. well-known receiver operating characteristics closely related chart directly plots without normalizing probabilities dividing number positives negatives. linear scalings won’t change appearance autoscaled graph… given don’t constrain axes scale graphs look identical need change values label axes with. however caution angles lines drawn graph change axes drawn equal scale. particular positive diagonal joining special significance negative diagonal joining also interest break-­‐even case break-even case arises bias prevalence viz. hence recall precision. means made right number predictions class whereas poorly biased system tend overpredict class underpredict another. thus useful heuristic false positives false negatives regarded equal weight cost encompass similar variance noise. clearly perfect score number real positives predicted positives must match classifiers tend achieve tradeoff. recall chance case chance case arises informed prediction made pure guessing. case expect positive predictions turning rate positive instances negative instances chance line thus tpr=fpr positive diagonal origin curve isobars parallel chance line represent classifiers equal levels informedness guessing. tpr–fpr invrec represents distance chance line formally probability informed prediction specific system. context analysis independently shown skew independent measure weighted relative accuracy average across parameterizations represented curve gini total area curve closely related mann-whitney statistic corresponding area curve. psychology formula emerged pair regression coefficients model well directional strengths association measured human subjects geometric mean corresponds matthews correlation equivalent maximizing perpendicular distance left chance line thus finding nearest tangential isocost line perfect point maximizes informedness. informedness related cost assumption positives negatives equal cost total breakeven assumes positives negatives equal cost informedness quantity also known gambling trading edge given standard bookmaker odds expected winnings given bookmaker cost formula correspond multiclass informedness. value measured terms odds winning balancing expected number wins losses giving equal cost total. informedness also known education multiclass formula used ensure fair marking multiple choice exams independent number choices odds guessing wrong questions possibilities weights right wrong answers accordingly also sometimes useful look information flow direction markedness prec invprec often predicting variable actually marked real class/situation. noted earlier geometric mean informedness markedness matthews correlation. also discuss application bookmaker accounting costing frameworks particular information theoretic costing giving formula expected information gain costing general leading different ideal operating point. break-even case recall precision f-measure informedness markedness correlation kappa informedness markedness indeed shown also representable kapparenormalizations recall precision subtracting component chance. area kappa proposed alternative originally using cohen kappa cohen fleiss kappa known probabilistic interpretations deviate strongly informedness bias varies prevalence. like bookmaker informedness also defined multiple classes rather dichotomous case considered far. consistent kappa bookmaker informedness form seen fig. area bookmaker operating characteristics curve equates gini/. cases reached optimal number positive predictions said negative predictions data becomes unbalanced insert errors smaller class less bigger class shift operating point right left leading increase decrease setting bias towards predicting class. similarly noise imbalance e.g. label noise model introduces error class lead slower discovery class increase operating bias. case happens multiclass case. classes always going imbalances rest evaluation. balanced case look well common evaluation measures interpretable across different classifiers datasets including diagnosis prediction different demographic environmental conditions. chance-correct chance-corrected correct expected accuracy chance measures consider accuracy single class biased high trying predict whether student guess question right wrong achieve accuracy predicting always wrong. course accuracy prediction lower students informed. kappa view informedness ‘always wrong’ prediction outcomes k-way exam correctly give hand variant kappa based naïve expectation chance always-wrong guessing distinguishes different kappa measures model expectation informedness arguably appropriate absence costings contradicting default balancing cost negatives cost positives consider case take account cost ratios. balancing cost individual positives negatives balancing cost positives negatives difference marginal distributions. thus case optimizing accuracy optimizing kappa gives result optimizing informedness. nonetheless specific cost allocation lead different optimum even balanced conversely misoptimization occur balanced data reflect natural prevalences environment system deployed. kappa variants calculating auk. illustrated fig. different choices give different curves coincide balanced case give rise different values different bias-prevalence tradeoffs move balance bookmaker informedness well known gini weighting loss cost relative probabilities winning losing roch curves real life type error cost another. many applications missed positive errors could lead loss life massive costs false alarm errors give scare small cost. assumption false positive costs false negative implicit common evaluation measures well complementary error distance measures equating cost getting positives wrong getting negatives wrong done default informedness individual costs inversely proportional prevalence viz. cp∝/rp cn∝/rn. thus chance line gradient given tpr/fpr zero-cost line group costing sense. graph tp/fp rp/rn. lines origin rewritten terms individual costs attributed tp/fp cn/cp tp*cp tn*cn changing costs roc-implied defaults changes gradient equal cost lines. also known isocost contours general straight parallel lines charts charts precision-recall charts called roch rocch charts basically connect pareto-optimal points straight line segment. points optimal sense assumed skew computational intelligence points pareto front said dominate points front clearly points segment equally good cost prevalence skew corresponding gradient. conversely points hull inside surrounded area can’t optimum cost prevalence variant. addition point segment achievable interpolation systems correspond endpoints example randomly choose system probability inverse distance target point. however caution given roch chart displaying test data fusion based test data guarantee interpolating points hull better independent data zigs zags noise. cost allows deeper understanding areas defined them particular roch averaged measures components good operating point selected based current costs prevalences robust changes costs prevalences. regard components representing certainty consistency distributional variants main controversies trade-off graphs appropriateness distribution implied choice variable x-axis recall=tpr=sensitivity assumed y-axis lift charts. already looked variant auc. whereas plots chance corrected measure rather recall y-axis fallout=fpr=-specificity plots kappa directly interpretable advocated above tpr–fpr h-­‐curve hand notes averaging distribution dependent classifier rather distribution classes real world. considers uniform distribution doesn’t reflect natural bias towards particular prevalence cost class proposes beta distribution model cost associated class. general form like f-measure provides opportunity weight positive negative components rather based harmonic mean related geometric mean =/). consider equally weighted form effectively averaged note inverse relationship prevalence cp∝/rp cn∝/rn giving equivalence show interestingly different chance correct measures analysed shown different normalizations determinant different ways averaging prevalences and/or biases thus tpr*gm tpr/gm |c|/gm measure longer clear diagonal representing chance isocost lines representing equal cost. introduced average chance-correct kappa measure specifically rejecting distributional assumptions hand similarly proponents reject distribution assumptions hand unnatural show consistency slightly different assumptions impose guessed cost distribution like hand’s h-measure/h-auc since hand’s approach makes complex distributional assumptions find arbitrary much intended plotted used calculating illustrate h-curve here. discussed earlier limited value classifier evaluation mixes consistency classifier informedness. lift chart another kind chart similar lift essentially plotted different variable x-axis rather lift emerged independently data mining depicting returns mail relative number mailed also illustrated fig. actually sensible worthy broader effectively plots recall number positive labels accepted. situation similar information retrieval decision many search results display view although also determine threshold. lift thus theoretically attractive avoids dependency outcomes system count proportion positives predicted corresponds credibility threshold classifier predictions curves lift charts used shape credibility distance measure empirical probability distribution adjust threshold vary parameter count positives. independence concerns noted averaging distribution errors following theorems demonstrate need concern. turns optimizations lift bift equivalent. proof insight. dichotomous case single decision determines whether think positive whether think negative. similarly tpr+fnr tnr+fpr dual graph simply reflection auroc auroc'. area chance line subtracted auboc auboc' gini/. formal proof. result discovered simplification bookmaker cost formula. proof insight. every example included reduce threshold adds segment bift chart incrementing area also increments either chart dual boc' chart. considering normalization chart x-axes equation n*aubift rn*auboc rp*auboc'. result follows formal proof. result discovered straightforward simplification integral. pn/receiver operating characteristics /bookmaker operating characteristics graphs show blue equal informedness isobars thin class-color break-even lines. areas curve auk=gini represent respectively probability positive ranked higher negative half probability informed decision made averaged threshold. lift shows recall bias class-color break-even lines vertical chance line becomes class-color curveset main diagonal area curves represents average informedness gini components bookmaker. precision-recall graphs recall precision showing blue-gray arithmetic mean isobars red-brown break-even line. reciprocal precision-recall harmonic mean isobars information domain geometric mean isobars. shapes similar scaling near linear small errors data multi-classifier fusion facial emotion recognition cohn-kanade dataset true rate results shown anger disgust fear happiness sadness surprise based -fold cross validation showing numbers images real class. iii. multiclass case measures classes measures defined either intrinsically based evaluation single class presented context dichotomous two-class problem precision inverse precision give accuracy. extends multiclass case too. recall different classes weighted associated prevalences precision different classes weighted associated biases giving accuracy. similarly accuracy multiple datasets weighted associated proportions multiclass accuracy macro-average recall precision f-measure calculated harmonic mean. ‘winnings’ must averaged proportion time made price averaged bias system. result thus equivalent bookmaker informedness multiclass case markedness must similarly averaged weighted prevalence correlation calculated geometric mean visualizations classes figure illustrated dichotomous measures tradeoffs using example -class problem emotion recognition smooth detailed result fusion multiple base classifiers. precision-recall graph noteworthy compared lift charts break-even lines coincide classes precision=recall. different slope lines indicate different weightings precision recall equivalently different bias/prevalence ratios. since distributions come dataset choice bias>prevalence class necessarily entails setting bias<prevalence another isoskew lines diverge. deviations skew implied prevalences equivalent skews implied different explicit cost choices turn optimize different bias skews. particular case interest relative difference bias classifiers classifier bias corresponding class prevalence. skew ratio looking isoskew lines describes relative drift classifier away true prevalence. basis multiclass visualizations variant lift plots bookmaker informedness directly individual class bift rather displaying implicitly difference recall inverse recall curves shown fig. bift illustrated data fig. lift bift charts arguably clearer spread convergent isoskew lines parallel thus spread graphed function around optimum. avoids clutter lack clarity near peak roc. spreads divergent around optimum specifically exploring tradeoff bias versus prevalence particular interested chance-correct assessment rather biased measures explore additional transformations retain advantage lift address striking difference observe compare chart unifies bias=prevalence isoskew line; allows high resolution view around optimum. bift chance-corrected variant lift based bookmaker informedness plotting tpr-fpr recall-fallout recall inverse recall rather recall fallout separately fig. note drift right isoskew lines lack precision bprd plots bookmaker probability tpr-fpr informed decision versus relative drift. note drift right isoskew meridian blip right confused classes. bird plots bookmaker information log-log versus scale relative drift. note optimum bookmaker probability information corresponds minimum information loss. note smoothing means stpr= sfpr= permitted occur infinite information loss. noise error cuts corner shifts optimum left break-even point birdhead emphasises selection members preponderant classes. pareto optimization problem visualization evaluation measure multiple classes degrees freedom explore amplifying difficulty pareto optimization problem increases beyond basically variety mechanisms optimize individual class dichotomy pareto-optimization replaces expectation finding overall optimum directly idea factoring dominated solution space cannot possibly contain optimum. leaving last class suffer whatever fate left fact happened measures visualizations based recall precision well negatives handled indirectly taken account all. clearly difficult plot accuracy informedness multiple parameters varied setting optimum thresholds becomes significant optimization problem right. indeed fusion problem substantial problem classifiers need combine multiple classifiers together solve multiclass problems pairwise classifiers fuse). precisely problem addressing want visualization help second-guess classifier beyond simple voting bias heuristics explore better combinations parameters different conditions bias prevalence isoskew line chart shows consistent system based heuristic charts don’t different slopes problem unbalanced different classes different prevalences example used fig. lift chart better… parallel appropriate rescaling make break-even isoskew lines coincide. scaling require simply compensates directly relative drift figure shows bift modification lift showing informedness δp'=tpr-fpr recall inverserecall area curve corresponds area curves lift chart analogous display class figure next shows bprd also based bookmaker informedness compensates relative drift chart corresponds number positive predictions made match number positive classes plotting gain according bookmaker odds versus relative drift multiplier. bookmaker estimating probability informed decision thus recall=precision corresponds vertical line given rd=%. another currency cost-basis consider pricing basis shannon information rather traditional probabilistic bookmaker odds. close inspection graph show noisy near optimum apparent optima class break-even line. optima graph relate arithmetic mean recall precision taking reciprocals axes optimizes harmonic mean doesn’t change effect lower prevalence classes. seeing fairly arbitrary noise effects increment find apparent true positive amongst false positives. important size boundary region corner miss optimum achieved sharply prevalent class graph zooms useful reciprocal transforms implicit unbounded fg-measures. move bumps curves. however indicated chance-correct informedness markedness equivalents giving correlation. corresponds linear isometrics scale version graph arithmetic mean harmonic mean become complementary log+log log. small variations probabilities near small effects -log interested minimizing cost maximizing gain information conveyed prediction bookmaker odds -log. however problems this given informedness even negative therefore cost using information loss good predictability versus poor predictability giving analogous information theoretic form bookmaker setting prices differently. also chance information exploited negative information utilized positive information misused -log. however problem either and/or origin curve also technically problem fmeasure means recall precision harmonic mean undefined case also represents exclude cases curves generally convenient laplace smoothing ensure stay non-zero consequence defining finite best case smoothed based laplace smoothing term added counts generalize smoothed relative density similarly. thus introduce smoothed definition bookmaker information appropriately shaped bird graph information-theoretic graph shows significant variation desired optimum hiding much noise visible graphs fig. limiting bias defined smoothing assumption thus -log spreads left wing ‘feathers’ prevalences balanced. given enough data mitigate effect smoothing balanced prevalences across classes maximum relative drift logk expected upper limit x-axis. general upper bound reflects skew predict negatives positives. extreme cases seen lower prevalence classes thus different coloured feathers right wing tip. birdhead spreads errors without smoothing first error infinite information smoothing represents significant jump still enough optimum left balance meridian bookmaker information costing rather right bookmaker probability costing. conclusions graphs single point representing best achievable point classifier interpretable independent prevalences individual classes operating points reflect bias prevalence higher skew towards positives easier achieve high precision high bias towards positive predictions automatically achieve high recall pushing operating points towards point irrespective performance underlying classifier. example always guessing positive achieves recall precision automatically prevalence even though guessing. guessing tends turn proportion correct labels incorrect labels chance line makes axis guessing scores rotating graph graph making diagonal axis additional advantage expanding best achievable point entire axis line graph. thus instead competitive solutions bunching together corners spread allowing better discrimination tuning around optimum. however x-axis still represents error rate major criticism derivatives lift bift replace error rate positive prediction rate bias something control without supervision. bird graph desirable property parallel vertical isoskew lines moving left right central y-axis fig. successive meridians indicate loss additional information relative optimal bias implied prevalence. class occurs others must average occur less according bias prevalence model. want assign equal cost class bird default would shift split isoskew lines would appropriate normalize relative drift scale taking account cost prevalence instead. wrong. class difficult identify another undertrained subject measurement error label noise bias prevalence model suboptimal. problems detected bird graph. range shown represents order magnitude discrepancy bias prevalence. separate ‘optima’ independent curves consistent predictions class moreover scales emphasize many bits information loss move away settings implied prevalence and/or cost structure dataset/application. convenient lift bift charts percentages along x-axis interpretable reference actual known prevalences. probability-scale bprd normalization shows differences relative prevalence unifies left sides subtend triangular curves leads spreading range overprediction right portion curves according prevalence classes. bird extension without systematic spread allowing significant differences seen clearly prevalence variation conveniently spreading parallel layers left central parts showing linear extension right side. example consistent inflection meridian changing concave concave down. note derivatives -log linear part left wing right extrema relation centre part curve birdhead expected dominated normally distributed noise error selecting positive negative distribution don’t simply sum. composite result provide visual solution takes single number derived multiple binary graphs combines blindly single number. furthermore individual curves bias gives equal weight positive negative case rather equal weight individual class. weighting bias towards class shown optimal derivation multiclass case bookmaker informedness generalization dichotomous case weighting systems shown suboptimal. similarly caution emphasized regarding misleading measures rather informedness precision recall graph well known simply plot recall precision based equation however graphs less well known introduce variants. summarize details perspective draw them. relatively easy draw plots using matlab slightly tricky draw excel fig. fig. generated. explain excel offer downloadable spreadsheets illustrate. assumed spreadsheet example true class prediction value possible label used determine value predicted. tricky part excel limited number standard functions available e.g. taking ranks finding argmax calculating counts various conditions. uniform works across versions exploit array formula capability allows formulae work whole arrays cells including performing arithmetic operations cells summing array indicate array formula necessary control-shift-enter rather enter entering formula. turn boolean relation result count adding using multiply achieve ‘logical and’ second condition technique count number items threshold output classifier subject desired constraint true false effectively class show formulae used define values axis curve member family lift graphs presented classes don’t talk positives versus negatives such becomes class label note upper case lower case represent label legibly without tiny subscripts legend. represents bias skew versus prevalence base logarithm represents entropy associated -logp information entropy associated event probability smoothed sfrx s+|>θx –ve| s+|–ve| uses count s+|bool| s+|bool| laplace smoothing baeza-yates ribeiro-neto modern information retrieval addison wesley. schölkopf r.c. williamson a.j. smola shawe-taylor john platt support vector p.a. flach hernandez-orallo ferri coherent interpretation measure aggregated classification performance international conference machine learning m.j.a. berry linoff data mining techniques marketing sales customer support", "year": 2015}