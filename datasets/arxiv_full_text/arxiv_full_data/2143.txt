{"title": "Ancestral Causal Inference", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Constraint-based causal discovery from limited data is a notoriously difficult challenge due to the many borderline independence test decisions. Several approaches to improve the reliability of the predictions by exploiting redundancy in the independence information have been proposed recently. Though promising, existing approaches can still be greatly improved in terms of accuracy and scalability. We present a novel method that reduces the combinatorial explosion of the search space by using a more coarse-grained representation of causal information, drastically reducing computation time. Additionally, we propose a method to score causal predictions based on their confidence. Crucially, our implementation also allows one to easily combine observational and interventional data and to incorporate various types of available background knowledge. We prove soundness and asymptotic consistency of our method and demonstrate that it can outperform the state-of-the-art on synthetic data, achieving a speedup of several orders of magnitude. We illustrate its practical feasibility by applying it on a challenging protein data set.", "text": "constraint-based causal discovery limited data notoriously difﬁcult challenge many borderline independence test decisions. several approaches improve reliability predictions exploiting redundancy independence information proposed recently. though promising existing approaches still greatly improved terms accuracy scalability. present novel method reduces combinatorial explosion search space using coarse-grained representation causal information drastically reducing computation time. additionally propose method score causal predictions based conﬁdence. crucially implementation also allows easily combine observational interventional data incorporate various types available background knowledge. prove soundness asymptotic consistency method demonstrate outperform state-ofthe-art synthetic data achieving speedup several orders magnitude. illustrate practical feasibility applying challenging protein data set. discovering causal relations data foundation scientiﬁc method. traditionally cause-effect relations recovered experimental data variable interest perturbed seminal work like do-calculus pc/fci algorithms demonstrate that certain assumptions already possible obtain substantial causal information using observational data. recently several proposals combining observational experimental data discover causal relations. causal discovery methods usually divided categories constraint-based score-based methods. score-based methods typically evaluate models using penalized likelihood score constraint-based methods statistical independences express constraints possible causal models. advantages constraint-based score-based methods ability handle latent confounders selection bias naturally need parametric modeling assumptions. additionally constraint-based methods expressed logic allow easy integration background knowledge trivial even simple cases approaches based logic major disadvantages traditional constraint-based methods vulnerability errors statistical independence test results quite common real-world applications ranking estimation conﬁdence causal predictions. several approaches address ﬁrst issue improve reliability constraint-based methods exploiting redundancy independence information idea assign weights input statements reﬂect reliability reasoning scheme takes weights account. several weighting schemes deﬁned simple ways attach weights single independence statements complicated schemes obtain weights combinations independence statements unfortunately approaches sacriﬁce either accuracy using greedy method scalability formulating discrete optimization problem super-exponentially large search space additionally conﬁdence estimation issue addressed limited cases propose ancestral causal inference logic-based method provides comparable accuracy best state-of-the-art constraint-based methods causal systems latent variables without feedback improves scalability using coarse-grained representation causal information. instead representing possible direct causal relations represent reason ancestral relations developing specialised ancestral reasoning rules. representation though still super-exponentially large drastically reduces computation time. moreover turns convenient real-world applications distinction direct causal relations ancestral relations always clear necessary. given estimated ancestral relations estimation reﬁned direct causal relations constraining standard methods smaller search space necessary. furthermore propose method score predictions according conﬁdence. conﬁdence score thought approximation marginal probability ancestral relation. scoring predictions enables rank according reliability allowing higher accuracy. important practical applications reliability predictions constraint-based methods major impediment wide-spread use. prove soundness asymptotic consistency mild conditions statistical tests scoring method. show outperforms standard methods like bootstrapped cfci terms accuracy achieves speedup several orders magnitude synthetic dataset. illustrate practical feasibility applying challenging protein data addressed score-based methods observe successfully recovers faithfulness violations. context showcase ﬂexibility logic-based approaches introducing weighted ancestral relation constraints obtain combination observational interventional data show substantially increase reliability predictions. finally provide open-source version algorithms evaluation framework easily extended http//github.com/caus-am/aci. preliminaries assume data generating process modeled causal directed acyclic graph contain latent variables. simplicity also assume selection bias. finally assume causal markov assumption causal faithfulness assumption hold. words conditional independences observational distribution correspond one-to-one d-separations causal dag. throughout paper represent variables uppercase letters sets variables denoted boldface. proofs provided supplementary material. directed edge causal represents direct causal relation cause effect intuitively framework indicates manipulating produce change manipulating effect detailed discussion found sequence directed edges directed path. exists directed path ancestor otherwise ancestor variables write underlying causal induces unique true ancestral structure represents transitive closure direct causal relations projected observed variables. disjoint sets denote conditional independence given conditional dependence call cardinality order conditional dependence relation. following deﬁne minimal conditional independence square brackets indicate needed dependence hold context note negation minimal conditional independence minimal conditional dependence. minimal conditional dependences closely related ancestral relations pointed lemma disjoint variables related work conﬂict resolution earliest algorithms deal conﬂicting inputs constraint-based causal discovery conservative adds redundant checks algorithm allow detect inconsistencies inputs makes predictions rely ambiguous inputs. idea applied yielding conservative bccd uses bayesian conﬁdence estimates process information decreasing order reliability discarding contradictory inputs arise. combine algorithm combines output several overlapping observational experimental datasets single causal model ﬁrst pooling recalibrating independence test p-values adding constraint incrementally order reliability instance. constraint makes problem unsatisﬁable discarded. approach inspired method presented hyttinen eberhardt järvisalo causal discovery formulated constrained discrete minimization problem. given list weighted independence statements searches optimal causal graph minimizes weights independence statements violated according order test whether causal graph induces certain independence method creates encoding d-connection graphs. d-connection graphs graphs obtained causal graph series operations encoding d-connection graphs complex structure encoding possible d-connection graphs sequence operations generated given causal graph. approach shown correct errors inputs computationally demanding huge search space. propose ancestral causal inference causal discovery method accurately reconstructs ancestral structures also presence latent variables statistical errors. builds rather optimizing encoding dags optimizes much simpler ancestral structures. variables number possible ancestral structures number partial orders grows n/+o number dags computed well-known super-exponential recurrence formula number admgs dag| although still super-exponential number ancestral structures grows asymptotically much slower number dags even admgs. example variables ancestral structures already admgs lower bound number encoding dags d-connection graphs used hej. rules rules explicitly encode marginalization conditioning operations d-connection graphs cannot easily adapted work directly ancestral relations. instead encodes ancestral reasoning rules novel causal reasoning rules lemma disjoint variables optimization loss function formulate causal discovery optimization problem loss function optimized possible causal structures. intuitively loss function sums weights inputs violated candidate causal structure. given list weighted input statements input statement associated weight deﬁne loss function weights input statements satisﬁed given possible structure denotes possible causal structures. causal discovery formulated discrete optimization problem means input satisﬁed structure according rules general formulation includes differ types possible structures rules represents possible causal graphs operations d-connection graphs. represent ancestral structures rules rules constrained optimization constrained optimization problem implemented using variety methods. given complexity rules formulation expressive logical language supports optimization e.g. answer programming convenient. widely used declarative programming language based stable model semantics successfully applied several np-hard problems. state-of-the-art solver clingo provide encoding supplementary material. weighting schemes supports types input statements conditional independences ancestral relations. statements assigned weight reﬂects conﬁdence. propose simple approaches desirable properties making asymptotically consistent mild assumptions assigning much smaller weight independences dependences approaches frequentist approach appropriate frequentist statistical test indepengiven observational interventional data intervention single known target simple obtain weighted ancestral statement two-sample test tests whether distribution changes respect observational distribution intervening approach conveniently applies various types interventions perfect interventions soft interventions mechanism changes activity interventions two-sample test also implemented independence test tests independence indicator variable value observational samples samples interventional distribution intervened upon. constrained minimization produce several optimal solutions underlying structure identiﬁable inputs. address issue propose loss function score conﬁdence feature soundness completeness scoring method sound oracle inputs theorem sound causal reasoning rules. feature conﬁdence score sound oracle inputs inﬁnite weights. here soundness means identiﬁable inputs identiﬁable inputs otherwise features consider example ancestral relations variables conjecture rules order--complete i.e. allow deduce ancestral relations identiﬁable oracle conditional independences order observational data. higher-order inputs additional rules derived. however primary interest work improving computation time accuracy willing sacriﬁce completeness. detailed study completeness properties left future work. null hypothesis independence/nonancestral relation alternative hypothesis dependence/ancestral relation. note need choose sample-size dependent threshold suitable rate. kalisch bühlmann show done partial correlation tests assumption distribution multivariate gaussian. bayesian weighting scheme assume hold mild technical conditions ﬁnite-dimensional exponential family models. cases probability type type error converge addition corresponding weight converge theorem sound causal reasoning rules. feature conﬁdence score asymptotically consistent assumption here asymptotically consistent means conﬁdence score probability identiﬁably true probability identiﬁably false probability otherwise. figure execution time comparison synthetic data frequentist test synthetic models average execution time different combinations number variables max. order detailed plot execution times section report evaluations synthetically generated data application real dataset. crucially causal discovery precision often important recall. many realworld applications discovering high-conﬁdence causal relations useful ﬁnding every possible causal relation reﬂected recently proposed algorithms e.g. compared methods compare predictions acyclic causally insufﬁcient version used combination scoring method also evaluate standard methods anytime anytime cfci implemented pcalg package anytime versions allow independence test results certain order. obtain ancestral relations output using theorem cfci rank predictions predict type relation ancestral non-ancestral unknown scoring predictions also compare bootstrapped versions anytime anytime cfci. perform bootstrap repeating following procedure times sample randomly half data perform independence tests anytime fci. output pags extract ancestral predictions average them. refer methods bafci. fair comparison independence tests thresholds methods. synthetic data simulate data using simulator experimental condition generate randomly linear acyclic models latent variables gaussian noise sample data points. perform independence tests order weight dependence statements using weighting schemes described section frequentist weights tests based partial correlations fisher’s z-transform obtain approximate p-values signiﬁcance level bayesian weights bayesian test conditional independence presented implemented prior probability independence. figure show average execution times single core .ghz different combinations figure show execution times sorting execution times ascending order. variables almost orders magnitude faster difference grows exponentially increases. variables complete four ﬁrst simulated models timeout reference execution time bootstrapped anytime cfci. figure show accuracy predictions precision-recall curves ancestral nonancestral relations different settings. figure results computed using frequentist weights evaluations scoring method methods possible independence test results case anytime versions cfci equivalent standard versions cfci. since overall results similar report results bayesian weights supplementary material. ﬁrst figure show setting variables. performances coincide performing signiﬁcantly better nonancestral predictions ancestral figure accuracy synthetic data prediction tasks using frequentist test left column shows precision-recall curve ancestral predictions middle column shows zoomed-in version interval right column shows nonancestral predictions. predictions remarkable independence test results order contrast uses independence test results orders. interestingly discrete optimization algorithms seem beneﬁt much higher order independence tests thus omit plots instead bootstrapping traditional methods oblivious dependence weights seems produce surprisingly good results. nevertheless outperform bootstrapped cfci suggesting methods achieve nontrivial error-correction. second figure show setting variables. setting slow. addition previous plot plot accuracy oracle background knowledge descendants variable setting simulates effect using interventional data performance improves signiﬁcantly especially ancestral preditions. performance cfci limited fact cannot take advantage background knowledge except complicated postprocessing application real data consider challenging task reconstructing signalling network cytometry data different experimental conditions. consider experimental condition observational setting seven others interventional settings. details evaluations reported supplementary material. contrast likelihoodbased approaches like approach need model interventions quantitatively. need know intervention targets intervention types matter. another advantage approach takes account possible latent variables. t-test test intervention variable whether distribution changes respect observational condition. p-values tests order obtain weighted ancestral relations used input example adding changes distribution signiﬁcantly respect observational baseline weighted ancestral relation mekraf. addition partial correlations order obtain weighted independences used input. score ancestral relations ordered pair variables. main results illustrated figure compare bootstrapped anytime cfci figure results cytometry dataset. matrix represents ancestral relations represents cause column effect. colors encode conﬁdence levels green positive black unknown negative. intensity color represents degree conﬁdence. example identiﬁes cause high conﬁdence. different inputs. output boostrapped anytime similar report supplementary material. algorithms like independences observational data input therefore miss strongest signal weighted ancestral relations obtained comparing interventional observational data. supplementary material compare also methods interestingly show there results similar best acyclic model reconstructed score-based method constraint-based methods computationally unfeasible setting combine assumes perfect interventions notably algorithms correctly recover faithfulness violations take account weight input statements contrast methods start reconstructing skeleton like would decide nonadjacent unable recover erroneous decision. illustrates another advantage approach. shown ancestral structures well-suited causal discovery. offer natural incorporate background causal knowledge e.g. experimental data allow huge computational advantage existing representations error-correcting algorithms needed ancestral structures mapped ﬁner-grained representation direct causal relations sketch supplementary material. furthermore conﬁdence estimates causal predictions extremely helpful practice signiﬁcantly boost reliability output. although standard methods like bootstrapping already provide reasonable estimates methods take account conﬁdence inputs presented here lead improvements reliability causal relations inferred data. strangely enough neither optimization methods seems improve much higher order independence test results. conjecture happen loss function essentially assumes test results independent another finding take account loss function improve achievable accuracy extension straightforward. supported netherlands organization scientiﬁc research also supported dutch programme commit/ datasemantics project. supported grant eu-fp grant agreement also thank soﬁa triantaﬁllou feedback especially pointing correct read ancestral relations pag. strengthened version rule note additional assumptions made redundant actually used proof. completeness give proof here. directed path paths blocked directed path must contain node hence contradiction exists path noncollider every collider ancestor exists collider ancestor collider closest ancestor note path d-connected given contradiction). symmetry also suppose exists path noncollider collider ancestor noncollider note subpath must d-connected given least outgoing edge follow edge along reaching either ﬁrst collider. collider reached follow directed path hence directed path i.e. addition must noncollider subpath assume must paths noncollider collider ancestor node closest also path collider ancestor noncollider path must blocked given would noncollider path would need order block however must also noncollider hence cannot therefore must collider path cannot ancestor show ancestor collider would ancestor contradiction. hence must outgoing arrow pointing towards encounter collider following directed edges contradiction collider hence would ancestor hence ancestor therefore soundness theorem sound causal reasoning rules. feature conﬁdence score sound oracle inputs inﬁnite weights i.e. identiﬁable inputs identiﬁable inputs otherwise proof. assume data generating process described causal contain additional latent variables distributions faithful dag. theorem follows directly soundness rules soundness logical reasoning. asymptotic consistency scoring method theorem sound causal reasoning rules. feature conﬁdence score asymptotically consistent assumption main paper i.e. proof. number statistical tests ﬁxed probability error test results converges asymptotically. loss function structures correspond properties true causal converges probability whereas loss function structures compatible properties true causal converges probability. figures show performance higher order independence test results main paper cfci gives best predictions methods. figure report accuracy results frequentist test setting figure main paper. performances really improve higher order actually seem deteriorate. figure report accuracy results synthetic data also bayesian test described main paper prior probability independence using bayesian test change overall conclusions overlap order perform better bootstrapped fci. provide details results real-world dataset brieﬂy described main paper cytometry data data consists simultaneous measurements expression levels biochemical agents individual cells human immune system different experimental conditions. table reagents used various experimental conditions corresponding intervention types targets. intervention types targets based biological background knowledge. upper table describes no-icam batch conditions commonly used literature. lower table describes additional icam batch conditions also here. batch conditions experimenters added α-cd α-cd activate signaling network conditions. remaining conditions α-cd α-cd added consider absence stimuli global intervention relative observational baseline batch consider observational dataset interventional datasets different activators inhibitors added cells described table note datasets last conditions settings. information intervention types paper ignore fact last interventional datasets batch also global intervention. ignoring global intervention allows compute weighted ancestral relations since consider variable changes distribution respect observational condition effect main target intervention line previous work also consider main target intervention based consensus network even though considered targets intervention. future work plan extend order address task learning intervention targets data done score-based approach. main paper provide results commonly used no-icam batch experimental conditions. report additional results batch. moreover provide results causal discovery icam batch quite consistent no-icam batch. finally compare methods applied dataset especially score-based approach shows surprisingly similar results although uses different method. figure results cytometry dataset no-icam batch. represents possible inputs weighted independences order observational dataset weighted ancestral relations recovered comparing interventional datasets observational data. bottom rows matrix represents ancestral relations estimated using different inputs different methods represents cause columns effects. colors encodes conﬁdence levels green positive black unknown negative. intensity color represents degree conﬁdence. figure provide additional results no-icam batch. ﬁrst show possible inputs weighted independences observational data weighted ancestral relations comparing interventional datasets observational data. speciﬁcally consider inputs independences order color encodes weight independence. example heatmap shows strongly dependent. weighted ancestral relations figure plot matrix represents cause columns effects. described main paper t-test test intervention variable whether distribution changes respect observational condition. biological knowledge summarised table deﬁne intervention target considered putative cause. p-values tests threshold obtain weights ancestral relations similarly proposed main figure show results icam setting. results similar results no-icam batch showing predicted ancestral relations robust. particular clear also icam batch weighted ancestral relations strong signal methods exploit distinct advantage methods cannot general settings appear various faithfulness violations. example well-known causes observational data variables independent. nevertheless data intervention leads change expected. interesting note approach correctly recover faithfulness violation takes account weight input statements contrast methods start reconstructing skeleton figure comparison ancestral relations predicted score-based method using no-icam batch. depicted ancestral relations obtained transitive closure direct causal relations reported results ancestral relations. black edges ancestral relations found methods blue edges identiﬁed grey edges present transitive closure result also compare results other mostly score-based approaches. amongst results report direct causal relations no-icam batch inferred score-based method assuming acyclicity. order compare fairly ancestral relations found ﬁrst perform transitive closure direct causal relations results ancestral relations. take predicted ancestral relations compare figure black edges majority represent ancestral relations found methods. blue edges found grey edges found interestingly results quite similar despite different approaches. particular allows confounders constraint-based method assumes causal sufﬁciency score-based. table summarizes existing work cytometry dataset. originally part material updated adding also results transitive closure table updated table causal relationships biochemical agents cytometry data according different causal discovery methods. consensus network according denoted reconstructed network provide versions edges acyclic case reported original paper transitive closure consists edges. provide fair comparison also pick ancestral predictions aci. edge raf→mek mek→raf mek→erk mek→akt mek→jnk plcg→pip plcg→pip plcg→pkc pip→plcg pip→pip pip→pkc pip→plcg pip→pip pip→akt akt→erk akt→jnk erk→akt erk→pka pka→raf pka→mek pka→erk pka→akt pka→pkc pka→p pka→jnk pkc→raf pkc→mek pkc→plcg pkc→pip pkc→pip pkc→erk pkc→akt pkc→pka pkc→p pkc→jnk p→jnk p→pkc jnk→pkc jnk→p ancestral structure seen transitive closure directed edges acyclic directed mixed graph several strategies reconstruct direct causal relations ancestral structure particular combination scoring method. sketch possible strategy leave in-depth investigation future work. possible strategy ﬁrst recover ancestral structure scoring method oracle input constraints algorithm. speciﬁcally weighted output obtained input list similarly scoring algorithm score direct causal relations standard algorithm possible admgs additional constraints reduce search space ones speciﬁc ancestral structure average asymptotically reduction n/+o variables. refer two-step approach restricted side effect assigning inﬁnite scores original ancestral predictions instead originally estimated scores estimated direct causal predictions scores also inﬁnite ﬂattening ranking. preliminary evaluation issue reusing original ancestral scores also inﬁnite direct predictions scores. another option scores causal relations soft constraints although time writing still unclear whether would lead speedup previously mentioned version. compared accuracy execution times standard restricted simulated data. figure shows curves predicting presence absence direct causal relations methods. table list execution times recovering direct causal relations. additionally list execution times second step approach restricted highlight improvement execution time resulting restrictions. preliminary investigation simulated data restricted much faster standard predicting direct causal relations sacriﬁces little accuracy last column table show execution times standard used score ancestral relations. interestingly predicting direct causal relations faster predicting ancestral relations hej. still variables algorithm takes seconds models ﬁrst simulated models. another possible strategy ﬁrst reconstructs ancestral relations conditional dependences using procedure similar loci recovering direct causal relations. subtleties conversion pags direct causal relations leave based strategies well better analysis conversion ancestral relations direct causal relations future work. answer programming widely used declarative programming language based stable model semantics logical programming. thorough introduction found syntax resembles prolog computational model based principles faster solvers propositional logic applied several np-hard problems including learning bayesian networks admgs search problems reduced computing stable models optionally scored. state-of-the-art solver clingo provide complete encoding using clingo syntax table encode sets natural correspondence binary numbers boolean formulas encode set-theoretic operations. since support real numbers scale weights factor round nearest integer. define extension causes sets existscauses means exists caused causes ismember existscauses node ismember existscauses causes ismember node node ismember", "year": 2016}