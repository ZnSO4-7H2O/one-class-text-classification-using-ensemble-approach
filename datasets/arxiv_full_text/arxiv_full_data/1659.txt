{"title": "Training an adaptive dialogue policy for interactive learning of  visually grounded word meanings", "tag": ["cs.CL", "cs.AI", "cs.LG", "cs.RO"], "abstract": "We present a multi-modal dialogue system for interactive learning of perceptually grounded word meanings from a human tutor. The system integrates an incremental, semantic parsing/generation framework - Dynamic Syntax and Type Theory with Records (DS-TTR) - with a set of visual classifiers that are learned throughout the interaction and which ground the meaning representations that it produces. We use this system in interaction with a simulated human tutor to study the effects of different dialogue policies and capabilities on the accuracy of learned meanings, learning rates, and efforts/costs to the tutor. We show that the overall performance of the learning agent is affected by (1) who takes initiative in the dialogues; (2) the ability to express/use their confidence level about visual attributes; and (3) the ability to process elliptical and incrementally constructed dialogue turns. Ultimately, we train an adaptive dialogue policy which optimises the trade-off between classifier accuracy and tutoring costs.", "text": "goal build interactive systems learn grounded word meanings relating perceptions real-world objects diﬀerent previous work e.g. learn groundings descriptions without interaction recent work using deep learning methods systems rely training data high quantity possibility online error correction. furthermore unsuitable robots multimodal systems need continuously incrementally learn environment encounter objects haven’t seen training data. limitations likely alleviated systems learn concepts needed situated dialogue humans. interaction human tutor also enables systems take initiative seek particular information need lack e.g. asking questions highest information gain fig. example robot could questions learn colour square\" request presented red\" things improve performance concept furthermore systems could allow meaning negotiation present multi-modal dialogue system interactive learning perceptually grounded word meanings human tutor. system integrates incremental semantic parsing/generation framework dynamic syntax type theory records visual classiﬁers learned throughinteraction ground meaning representations produces. system interaction simulated human tutor study effects diﬀerent dialogue policies capabilities accuracy learned meanings learning rates eﬀorts/costs tutor. show overall performance learning agent aﬀected takes initiative dialogues; ability express/use conﬁdence level visual attributes; ability process elliptical incrementally constructed dialogue turns. ultimately train adaptive dialogue policy optimises trade-oﬀ classiﬁer accuracy tutoring costs. identifying classifying talking objects events surrounding environment capabilities intelligent goal-driven systems interact agents external world recently surge interest signiﬁcant progress made variety related tasks including generation natural language descriptions images identifying images based descriptions visual classiﬁers learned interaction provide perceptual grounding basic semantic atoms semantic representations produced parser system interaction simulated human tutor test hypotheses accuracy learned meanings learning rates overall cost/eﬀort human tutor aﬀected diﬀerent dialogue policies capabilities takes initiative dialogues; agent’s ability utilise level uncertainty object’s attributes; ability process elliptical well incrementally constructed dialogue turns. results show diﬀerences along dimensions signiﬁcant impact accuracy grounded word meanings learned processing eﬀort required tutors. section present overview vision language processing systems well multi-modal systems learn associate them. compare along main dimensions visual classiﬁcation methods oﬄine online kinds representation learned/used. online oﬄine learning. number implemented systems shown good performance classiﬁcation well nl-description novel physical objects attributes either using oﬄine methods incremental learning process system’s parameters updated training example presented system interactive learning task presented here latter appropriate system expected learn interactions human tutor period time. shen hasegawa propose soinn-svm model re-trains linear classiﬁers data points clustered together examples seen far. clustering done incrementally system needs keep examples memory. kristian leonardis hand propose okde model continuously learns categorical knowledge visual attributes probability distributions categories however learning scratch unrealistic predeﬁne concept groups systems need learn that e.g. colour grounded speciﬁc sub-space object’s features. visual classiﬁers therefore assume category groupings here instead learn individual binary classiﬁers visual attribute distributional logical representations. learning ground natural language perception fundamental problems artiﬁcial intelligence. main strands work address problem learn distributional representations using deep learning methods often works projecting vector representations diﬀerent modalities space order able retrieve attempt ground symbolic logical forms obtained semantic parsing classiﬁers various entities types/events/relations segment image video. perhaps advantage latter former method strictly compositional i.e. contribution meaning individual word semantic atom whole representation clear whereas hard distributional models. noted work also uses latter methodology though dialogue rather sentence semantics care about. similar work probably kennington schlangen learn mapping individual words rather logical atoms low-level visual features directly. system compositional grammar further groundings learned pairings object references images rather dialogue. sets approach apart others domain-general incremental semantic grammar principled mechanisms parsing generation; given model dialogue representations constructed jointly interactively tutor system course several turns perception nl-semantics modelled single logical formalism eﬀectively induce ontology atomic types combined arbitrarily complex ways generation complex descriptions arbitrarily complex visual scenes compare grammar therefore logical structure grounded meanings). developed system support attribute-based object learning process natural incremental spoken dialogue interaction. architecture system shown fig. system main modules vision module visual feature extraction classiﬁcation learning; dialogue system module using dsttr. describe components individually explain interact. attribute-based classiﬁers used point neither multi-label classiﬁcation models ‘zero-shot’ learning models show acceptable performance attribute-based learning tasks. here instead logistic regression classiﬁers stochastic gradient descent incrementally learn attribute predictions. seen images predicting binary label vectors. build visual feature representations learn classiﬁers particular attributes explained following subsections. visual feature representation contrast previous work reduce feature noise learning process simplify method feature extraction consisting base feature categories i.e. colour space colour attributes ‘bag visual words’ object shapes/class. colour descriptors consisting colour space values extracted pixel quantized matrix. descriptors inside bounding binned individual histograms. meanwhile visual words built phow descriptors using visual dictionary visual words calculated using blocks -pixel step size quantized k-means centres. feature extractor vision module presents -dimensional feature vector single training/test instance stacking quantized features shown figure dynamic syntax word-by-word incremental semantic parser/generator based around dynamic syntax grammar framework especially suited fragmentary highly contextual nature dialogue. dialogue modelled interactive incremental construction contextual semantic representations contextual representations aﬀorded ﬁne-grained semantic content jointly negotiated/agreed upon interlocutors result processing questions answers clariﬁcation requests corrections acceptances etc. cannot detail lack space proceed introduce type theory records formalism contextual/semantic representations couched also within perception modelled here. semantics dialogue modelling particularly wellsuited problem allows information various modalities including vision language represented within single semantic framework dobnik model semantics spatial language perceptual classiﬁcation). logical forms speciﬁed record types sequences ﬁelds form containing label type witnessed records type record sequence labelvalue pairs type case type fields manifest i.e. given singleton type e.g. type member; here write using syntactic sugar fields also dependent ﬁelds preceding record type standard subtype relation deﬁned record types ﬁelds contains figure subtypes subtyping relation allows semantic information incrementally speciﬁed i.e. record types indeﬁnitely extended information/constraints. here feature since allows system fig. shows various parts system interact. point time system access ontology types attributes encoded record types whose individual atomic symbols ‘red’ ‘square’ grounded classiﬁers trained far. given individuated objects scene encoded record system utilise existing ontology output record type maximally characterises scene dynamic syntax operates representations provide direct interface between perceptual classiﬁcation semantic processing dialogue representation acts non-linguistic context dialogue resolution e.g. deﬁnite reference indexicals also logical database system generate utterances answer questions objects fig. illustrates semantics answer question retrieved visual context uniﬁcation conversely concept learning ds-ttr parser incrementally produces record types representing meaning jointly established tutor system far. domain ultimately type judgements i.e. scene/image/object judged particular type e.g. fig. individuated object square. jointly negotiated type judgements provide training instances classiﬁers. general training instances form image/scene segment record type. decomposed constituent atomic types noted introduction interactive systems learn continuously long humans need incrementally; quickly possible; little eﬀort/cost human tutor possible. addition learning takes place dialogue dialogue needs human-like/natural possible. general several diﬀerent dialogue capabilities policies concept-learning agent might adopt lead diﬀerent outcomes accuracy learned concepts/meanings learning rates cost tutor trade-oﬀs these. goal paper therefore experimental study eﬀect diﬀerent dialogue policies capabilities overall performance learning agent which describe measure capturing trade-oﬀ accuracy learned meanings cost tutoring. design. dialogue system outlined carry main experiment factorial design i.e. three factors levels. together factors determine learner’s dialogue behaviour initiative determines takes initiative dialogues. tutor takes initiative s/he drives conversation forward asking questions learner making statement attributes object. hand learner initiative makes statements asks uncertainty questions initiates topics etc. determines whether learner takes account dialogue behaviour subjective conﬁdence attributes presented object. conﬁdence probability assigned attribute classiﬁers object positive instance attribute conﬁdence threshold used here. agent question conﬁdent answer hedge answer tutor question conﬁdent e.g. this? errm maybe square?\". agent always takes know attributes given object behaves according assumption. context-dependency determines whether learner process context-dependent expressions short answers incrementally constructed turns e.g. this? square\" tutor simulation policy experiment large-scale hand-crafted interactive tutoring simulator simulates behaviour human tutor. tutor policy kept constant across conditions. policy always truthful helpful omniscient complete access labels object; always acts context dialogue dictates answers question asked conﬁrms rejects learner describes object; always corrects learner describes object erroneously. dependent measures describe dependent measures experiment i.e. classiﬁer accuracy/score tutoring cost overall performance measure combines former measures. conﬁdence threshold determine agent takes conﬁdent attribute prediction conﬁdence-score thresholds. consists values base threshold positive threshold experiment involves hundreds dialogues running experiment real human tutors proven costly juncture though plan full evaluation system future. trusts prediction not. conﬁdence score classiﬁer positive base thresholds learner conﬁdent knowledge check tutor e.g. red?. however conﬁdence score classiﬁer positive threshold learner conﬁdent enough knowledge bother verifying tutor. lead less eﬀort needed tutor learner becomes conﬁdent knowledge. however since learning agent high conﬁdence prediction assistance tutor positive threshold would reduce chances allow tutor correct learner’s mistakes. therefore tested diﬀerent ﬁxed values conﬁdence threshold determined ﬁxed base threshold positive threshold deemed appropriate values interactive learning process i.e. values preserved good classiﬁer accuracy requiring much eﬀort tutor section adaptive policy learned adjusts agent’s conﬁdence threshold dynamically time. evaluation metrics test diﬀerent dialogue capabilities strategies aﬀect learning process consider cost tutor accuracy learned meanings i.e. classiﬁers ground colour shape concepts. cost cost measure reﬂects eﬀort needed human tutor interacting system. skocaj point comprehensive teachable system learn autonomously possible rather involving human tutor frequently. several possible costs tutor might incur table refers cost tutor providing information single attribute concept cack cost simple conﬁrmation rejection ccrt cost correction single concept associate higher cost correction statements polar questions. penalise learning agent conﬁdently makes false statement thereby incorporating aspect trust metric ﬁnally parsing well production costs tutor taken account single word costs parsed tutor generated exact values based intuition kept constant across experimental conditions therefore confound results reported below. learning performance mentioned above eﬃcient learner dialogue policy consider classiﬁcation accuracy tutor eﬀort thus deﬁne integrated measure overall performance ratio compare learner’s overall performance across diﬀerent conditions dataset dataset used comprised images single simple handmade objects white background nine attributes considered dataset colours shapes relative balance number instances attribute. ing. training instance system interacts simulated tutor. dialogue object ends either shape colour object discussed agreed upon learner requests presented next image deﬁne learning step comprised dialogues. learning step system tested using test process repeated times i.e. rounds/folds time diﬀerent random split thus resulting data-points cost accuracy every learning step. values reported below including plots fig. correspond averages across folds. experiment presented above learning agent’s positive conﬁdence threshold held constant however since conﬁdence threshold becomes reliable agent exposed training instances hypothesised threshold changes dynamically time lead better trade-oﬀ classiﬁcation accuracy cost tutor i.e. better overall performance ratio example lower positive thresholds appropriate later stages training agent already performing well attribute classiﬁers reliable. leads diﬀerent dialogue behaviours learner takes diﬀerent decisions encounters training examples. test hypothesis trained evaluated adaptive policy adjusts learning agent’s conﬁdence threshold interacts tutor optimization used markov decision process model reinforcement learning where state space determined varia reviewer points handle uncertainty principled possibly better results using pomdps. another reviewer points policy learned adapting conﬁdence threshold conditions point addressing limitations work progress feed classiﬁer’s outputted conﬁdence level continuous feature full dialogue control. ables number training instances seen agent’s current conﬁdence threshold actions either increase decrease conﬁdence threshold keep same; local reward signal directly proportional agent’s overall performance ratio previous learning step sarsa algorithm chosen learning episode deﬁned complete training instances. fig. shows example interactions learner tutor experimental conditions. note system able deal utterance continuations +uc+cd short answers l+uc+cd polar answers system interacts time tutor training instances. ninth curve +cd) shows learning agent dynamic conﬁdence threshold using policy trained using reinforcement learning latter compared dark blue curve noted passing vertical axes graphs based averages across folds recall accuracy system tested fold every learning step i.e. every training instances. fig. hand plots accuracy tutoring cost directly. note expected curves terminate place x-axis since diﬀerent conditions incur diﬀerent total costs tutor across training instances. gradient curve corresponds increase accuracy unit tutoring cost. gradient line drawn beginning curve fig. constitutes main between-subjects analysis variance shows signiﬁcant main eﬀects initiative uncertainty context-dependency system’s overperformance. also signiﬁcant initiative×uncertainty interaction constant also signiﬁcant main eﬀect conﬁdence threshold type measure mean gradient adaptive curve actually slightly lower constant-threshold counter-part blue curve discussed below. tutoring cost seen fig. cumulative cost tutor progresses slowly learner initiative takes conﬁdence account behaviour grey blue curves. form active learning taking place learner asks question attribute isn’t conﬁdent enough already attribute. also explains slight decrease gradients curves agent exposed training instances subjective conﬁdence predictions increases time thus progressively less need tutoring. accuracy hand l+uc curves fig. show slowest increase accuracy ﬂatten agent’s conﬁdence score beginning unreliable agent seen training instances many cases doesn’t query tutor interaction whatsoever informative examples doesn’t exposed contrast this l+uc+cd curve achieves much better accuracy. comparing gradients curves fig. shows overall performance agent gradient measure signiﬁcantly better others l+uc conditions however agent adaptive threshold +cd) achieves slightly lower overall gradient constant threshold counter-part achieves much higher accuracy overall much faster ﬁrst units cost therefore conclude adaptive policy desirable. finally signiﬁcant main eﬀect contextdependency overall performance explained fact conditions agent able process context-dependent incrementally constructed turns leading less repetition shorter dialogues therefore better overall performance. presented multi-modal dialogue system learns grounded word meanings human tutor incrementally time employs dynamic dialogue policy system integrates semantic grammar dialogue logical theory types visual classiﬁers semantic representations grounded. used implemented system study eﬀect diﬀerent dialogue policies capabilities overall performance learning agent combined measure accuracy cost. results show order maximise performance agent needs take initiative dialogues take account changing conﬁdence predictions able process natural human-like dialogue. ongoing work uses reinforcement learning learn complete incremental dialogue policies i.e. choose system output lexical level deal uncertainty system takes classiﬁers’ outputted conﬁdence levels directly features continuous space mdp. simon dobnik robin cooper staﬀan larsson. modelling language action perception type theory records. proceedings international workshop constraint solving language processing pages julian hough matthew purver ruth kempson eleni gregoromichelaki. conversational interactions capturing dialogue dynamics. larsson borin editors quantiﬁcation conversation festschrift robin cooper occasion birthday volume tributes pages college publications london. eshghi howes gregoromichelaki hough purver. feedback conversation incremental semanth intertic update. national conference computational semantics london association computational linguisitics. endres derek hoiem david forsyth. describing objects attributes. proceedings ieee computer society conference computer vision pattern recognition julian hough matthew probabilistic type theory inpurver. proceedings cremental dialogue processing. eacl workshop type theory natural language semantics pages gothenburg sweden april. association computational linguistics. andrej karpathy fei-fei deep visual-semantic alignments generating image descriptions. ieee conference computer vision pattern recognition cvpr boston june pages casey kennington david schlangen. simple learning compositional application perceptually grounded word meanings incremental reference resolution. proceedings conference association computational linguistics association computational linguistics. christoph lampert hannes nickisch stefan harmeling. attributebased classiﬁcation zero-shot visual object categorization. ieee trans. pattern anal. mach. intell. cynthia matuszek liefeng luke zettlemoyer dieter fox. learning unscripted deictic gesture language human-robot interactions. proceedings twenty-eighth aaai conference artiﬁcial intelligence july québec city québec canada. pages tong zhang. solving large scale linear prediction problems using stochastic gradient proceedings twentydescent algorithms. ﬁrst international conference machine learning page acm. danijel skocaj matej kristan alen vrecko marko mahnic miroslav janícek geertjan kruijﬀ marc hanheide nick hawes thomas keller michael zillich zhou. system interactive learning dialogue tutor. ieee/rsj international conference intelligent robots systems iros francisco september pages danijel skoˇcaj matej kristan aleš leonardis. formalization diﬀerent learning strategies continuous learning frameproceedings ninth international work. conference epigenetic robotics; modeling cognitive development robotic systems pages lund university cognitive studies. richard socher milind ganjoo christopher manning andrew zero-shot learning cross-modal transfer. advances neural information processing systems annual conference neural information processing systems pages lake tahoe nevada usa. richard socher andrej karpathy quoc christopher manning andrew grounded compositional semantics ﬁnding describing images sentences. transactions association computational linguistics stefanie tellex pratiksha thaker joshua mason joseph nicholas roy. learning perceptually grounded word meanings unaligned parallel data. machine learning yanchao arash eshghi oliver lemon. comparing attribute classiﬁers proceedings interactive language grounding. fourth workshop vision language pages lisbon portugal september. association computational linguistics. yanchao oliver lemon arash eshghi. interactive learning dialogue multimodal language grounding. semdial proceedings workshop semantics pragmatics dialogue gothenburg sweden august pages", "year": 2017}