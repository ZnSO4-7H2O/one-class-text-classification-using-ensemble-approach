{"title": "A Study on the Global Convergence Time Complexity of Estimation of  Distribution Algorithms", "tag": ["cs.AI", "cs.NE"], "abstract": "The Estimation of Distribution Algorithm is a new class of population based search methods in that a probabilistic model of individuals is estimated based on the high quality individuals and used to generate the new individuals. In this paper we compute 1) some upper bounds on the number of iterations required for global convergence of EDA 2) the exact number of iterations needed for EDA to converge to global optima.", "text": "abstract. estimation distribution algorithm class population based search methods probabilistic model individuals estimated based high quality individuals used generate individuals. paper compute upper bounds number iterations required global convergence exact number iterations needed converge global optima. enetic algorithms class optimization algorithm motivated theory natural selection genetic recombination. tries find better solution selection recombination promising solution. works well wide verities problem domains. poor behaviors genetic algorithms problems designed operators crossover mutation guarantee building block hypothesis preserved development type algorithms. search techniques preserve building blocks emergence class algorithm called probabilistic model building genetic algorithm also known estimation distribution algorithm principle concept technique prevent disruption partial solutions contained individual giving high probability presented child individual. achieved building probabilistic model represent correlation variables individual build model generate next population. edas classified three classes based interdependencies variables individuals instances edas algorithm include population-based incremental learning univariate marginal distribution algorithm learning automata-based estimation distribution algorithm compact genetic algorithm dependencies model mutual information maximization input clustering combining optimizer mutual information trees bivariate dependencies model factorized distribution algorithm bayesian evolutionary algorithm multiple dependencies model name few. researchers studied working mechanism edas. mühlenbein gonzález höhfeld rudolph studied behavior umda pbil. mühlenbein mahnig discussed convergence separable additively decomposable functions. zhang mühlenbein proved edas infinite population size globally converge. despite fact working mechanisms edas studied time complexity speed convergence edas algorithm known. paper propose results number iterations needed edas converge globally population size infinite. approach proposed sections. first upper bounds number iterations required global convergence calculated second section exact number iterations needed converge global optima calculated. rest paper organized follows. section briefly presents algorithm modeling uses infinite population size. section demonstrate theorems time complexity edas. conclusion given final section. solving optimization problem described below. -initialization generate initial population individuals. -selection choose individuals population form parent population using selection schema truncation tournament proportional selection schema. -updating perform updating operations individuals parent population iteration generate individuals form population time e.g. ξ=ξs. e{f| ξ}=fmax stop else step condition step algorithm every individual population optimal solution globally converged. underlying probability distribution functions individuals respectively. famous glivenko-canteli theorem empirical probability density functions induced individuals converge respectively sizes tend infinity. therefore thought population parent population iteration infinite population describe selection schemes used paper. truncation selection schema truncation selection ranks individuals population according fitness selects best ones parents truncation selection threshold best individuals selected become parents next generation. population size infinite modeled two-tournament selection schema two-tournament selection model individuals chosen current population best individual selected parent. selection must repeated times generate parents population size infinite schema modeled ratio number individuals population belong size sequence {d); n=…} generated random sequence general. individuals population members population size tends infinity according glivenko-canteli theorem computed follows define global convergence stopping time τ=min{n|e{f|ξ}=fmax} every e{f|ξ}=fmax according definition first time globally converges. infinite finite. manner define min{n|d)=}. following state lemmas show relationship lemma global convergence stopping time edaτ equal min{n|d)=}. proof. prove lemma contradiction. first assume τ<τ′ definition i.e. exists least doesn’t belong <fmax) p)=b>. thus lemma indicates lemma remark state stopping time {d); n=…}. stopping time {e{f| ξ};n=…} stopping time {d); n=…} reason rest paper study time complexity rather time complexity {e{f| ξ};n=…}. using notations lemmas algorithm described follows. initialization <p<). selection generate according selection schema. termination condition )/))))+ iterations. obvious important parameter stopping time truncation selection schema. lower values impose lower upper bound stopping time higher values exert higher upper bound stopping time eda. section strong results convergence derived. stated {d); n=…} random sequence general population size tends infinity sequence becomes deterministic sequence. words knowing compute exact value properties derive strong results convergence eda. results exact number iterations needed converge global optima reported paper summarized following theorems. paper presented results global convergence computation time algorithms. following quantities computed upper bounds number iterations required global convergence exact number iterations needed converge global optima.", "year": 2006}