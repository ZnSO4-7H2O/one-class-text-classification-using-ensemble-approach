{"title": "Predicting Deep Zero-Shot Convolutional Neural Networks using Textual  Descriptions", "tag": ["cs.LG", "cs.CV", "cs.NE"], "abstract": "One of the main challenges in Zero-Shot Learning of visual categories is gathering semantic attributes to accompany images. Recent work has shown that learning from textual descriptions, such as Wikipedia articles, avoids the problem of having to explicitly define these attributes. We present a new model that can classify unseen categories from their textual description. Specifically, we use text features to predict the output weights of both the convolutional and the fully connected layers in a deep convolutional neural network (CNN). We take advantage of the architecture of CNNs and learn features at different layers, rather than just learning an embedding space for both modalities, as is common with existing approaches. The proposed model also allows us to automatically generate a list of pseudo- attributes for each visual category consisting of words from Wikipedia articles. We train our models end-to-end us- ing the Caltech-UCSD bird and flower datasets and evaluate both ROC and Precision-Recall curves. Our empirical results show that the proposed model significantly outperforms previous methods.", "text": "figure deep multi-modal neural network. ﬁrst modality corresponds tf-idf features taken text corpus corresponding class e.g. wikipedia article particular object. passed multi-layer perceptron produces linear output nodes second modality takes image feeds convolutional neural network last layer passed linear projection produce image features score class produced sense text pipeline though producing classiﬁer weights image pipeline. concept zero-shot learning introduced literature improve scalability traditional object recognition systems. ability classify images unseen class transferred semantically visually similar classes already learned visual classiﬁer. popular approach exploit shared knowledge classes form attributes stripes four legs main challenges zero-shot learning visual categories gathering semantic attributes accompany images. recent work shown learning textual descriptions wikipedia articles avoids problem explicitly deﬁne attributes. present model classify unseen categories textual description. speciﬁcally text features predict output weights convolutional fully connected layers deep convolutional neural network take advantage architecture cnns learn features different layers rather learning embedding space modalities common existing approaches. proposed model also allows automatically generate list pseudoattributes visual category consisting words wikipedia articles. train models end-to-end using caltech-ucsd bird ﬂower datasets evaluate precision-recall curves. empirical results show proposed model signiﬁcantly outperforms previous methods. recent success deep learning approaches object recognition supported collection large datasets millions images thousands labels although datasets continue grow larger acquiring broader categories time consuming expensive collect. furthermore collecting detailed ﬁne-grained annotations attribute object part labels even difﬁcult datasets size. hand massive amount textual data available online. online encyclopedias english wikipedia currently contain articles represent rich knowledge base diverse topics. ideally would exploit rich source information roundness. typically much smaller perceptual attributes number objects thus training classiﬁers typically much easier task. work pre-deﬁnes attribute typically depending dataset used somewhat limits applicability methods larger scale. work build ideas introduce novel zero-shot learning model predicts visual classes using text corpus particular encyclopedia corpus. encyclopedia articles explicit categorization human knowledge. article contains rich implicit annotation object category. example wikipedia entry cardinal gives detailed description bird’s distinctive visual features colors shape beak. explicit knowledge sharing encyclopedia articles also apparent inter-references. model aims generate image classiﬁers directly encyclopedia articles classes training images. overcomes difﬁculty hand-crafted attributes lack ﬁne-grained annotation. instead using simple word embeddings short image captions model operates directly natural language corpus image pixels. ﬁrst contribution novel framework predicting output weights classiﬁer fully connected convolutional layers convolutional neural network introduce convolutional classiﬁer operates directly intermediate feature maps cnn. convolutional classiﬁer convolves feature ﬁlter predicted text description. classiﬁcation score generated global pooling convolution. also empirically explore combining features different layers cnns effects classiﬁcation performance. evaluate common objective functions used zero-shot learning rank-based retrieval tasks. quantitatively compare performance different objective functions using roc-auc mean average-precision classiﬁcation accuracy. show different cost functions outperform different evaluation metrics. evaluated caltech-ucsd bird dataset oxford ﬂower dataset proposed model signiﬁcantly outperforms previous state-of-the-art zero-shot learning approach addition testing performance model seen classes comparable state-ofthe-art ﬁne-grained classiﬁer using additional annotations. domain adaptation concerns problem distinct datasets known source target domains respectively. typical supervised setting given source training target training goal transfer information source domain target domain order produce better predictor training target domain alone. unlike zero-shot learning class labels domain adaptation assumed known advance ﬁxed. substantial work computer vision deal domain adaption. address problem mentioned access source target data available training time. extended unsupervised setting target labels available training time. target data available however labels still given consistent across domains. authors explicitly account inter-dataset biases able train model invariant these. considered uniﬁed formulation domain adaptation multi-task learning combine different domains using dot-product operator. image text embeddings projections space pixels space text space nearest neighbours semantically related. semantic label embedding image label embeddings jointly trained semantic information shared modalities. example image tiger could embedded space near label tiger label tiger would near label lion. accomplished ranking objective using linear projections image features bag-of-words attribute features. label features produced unsupervised skip-gram model trained wikipedia articles image features produced trained imagenet allows model semantic relationships labels order predict labels appear training set. removes ﬁnal classiﬁcation layer retains uses uncertainty classiﬁer produce ﬁnal embedding convex combination label embeddings. uses unsupervised label embeddings together outlier detector determine whether given image corresponds known label label. allows standard classiﬁer label known. semantic relationship labels. rather assume labels composed attributes attempt learn semantic relationship attributes images. labels constructed combining different sets attributes. setup previously considered attributes manually annotated. training attributes predicted along image label test time. explores relative attributes captures images relate along different attributes. problem formulation inspired attempt derive embedding features label directly natural language descriptions rather attribute annotations. difference architecture deep neural networks jointly embed image text features rather using probabilistic regression domain adaptation. overall goal model learn image classiﬁer natural language descriptions. training model takes text features representing particular class images class. test time previously unseen textual description associated images presented. model needs classify images unseen visual classes images trained classes. ﬁrst introduce general framework predict linear classiﬁer weights extend concept convolutional classiﬁers. given image feature vectors associated class labels training dtrain l)}n distinct class labels available training. test time given additional number previously unseen classes ltest ...c test images xtest associated unseen classes dtest predicting linear classiﬁer weight vector particular class hard deal unseen classes using standard formulation. assume provided additional text feature vector associated class instead learning static weight vector text feature used predict classiﬁer weights words deﬁne function where mapping transforms text special features visual image feature space. case choosing linear transformation formulation similar work mapping represented non-linear regression model parameterized neural network. given mapping text features class extended one-vs-all linear classiﬁer previously unseen classes. predicting output weights neural nets drawbacks direct mapping typically high dimensional makes difﬁcult estimate large number parameters example linear transformation setup number parameters proportional problems considered paper implies millions parameters need estimated thousand data points. addition parameters highly correlated makes gradient based optimization methods converge slowly. instead introduce second mapping parameterized multi-layer neural network transforms visual image features lower dimensional space dimensionality predicted weight vector drastically reduced using formulation binary classiﬁer written transformed image feature output neural network. similar predicted using text features therefore formulation equivalent binary classiﬁcation neural network whose output weights predicted text features. using neural networks perform non-linear dimensionality reduction text visual features. special case linear transformations equivalent rank matrix factorization visualization model shown figure predicting convolutional classiﬁer convolutional neural networks currently accurate models object recognition tasks contrast traditional hand-engineered features cnns build deep hierarchical multi-layer feature representation image pixels. common boost performance vision system using features fully connected layer although image features obtained fully connected layer mapping functions transform text features weights neural networks parameterized matrix goal learning adjust model accurately classify images based textual description. consider training containing textual descriptions class images. next examine following objective functions training model. binary cross entropy image feature text feature indicator used encode whether image corresponds class represented text using encoding. binary cross entropy intuitive objective function predicted binary classiﬁer sigmoid function equation image evaluated classes training becomes computationaly expensive number classes grows. instead monte carlo minibatch scheme approximate summation images classes namely draw mini-batch images compute cost summing images minibatch. also image labels minibatch only. computational cost minibatch scheme instead hinge loss considered hinge loss objective. hinge loss objective functions popular among retrieval ranking tasks multi-modal data. fact predicting output layer weights neural network formulated ranking task text descriptions visual images. although formulation similar focus work classiﬁcation rather information retrieval. indicator represent cnns useful generic vision pipelines little spatial local information retained them. feature maps lower convolutional layers hand contain local features arranged spatially coherent grid. addition weights convolution layer locally connected shared across feature map. number trainable weights fewer fully connected layers. therefore appealing predict convolutional ﬁlters using text features relatively small number parameters. denote extracted activations convolutional layer feature maps rm×w×h representing feature denoting width height feature map. unlike previous approaches directly formulate convolutional classiﬁer using feature maps convolutional layers. first perform non-linear dimensionality reduction reduce number feature maps sec. reduction mapping rm×w×h rk×w×h reduced feature deﬁned given text features particular class corresponding predicted convolutional rk×s×s weights size predicted ﬁlter. similarly fully connected parameterized multi-layer neural netmodel work. formulate convolutional classiﬁer follows global pooling function rw×h denotes convolution typically used convolutional layers. convolving predicted weights feature maps encourage model learn informative location feature detectors based textual descriptions. global pooling operation aggregates local features whole image produces score. depending type pooling operation noisy-or average pooling pooling convolutional classiﬁer different sensitivities local features. experimental results found average pooling works well general pooling suffers over-ﬁtting. also take advantage architecture using features extracted intermediate convolutional layers ﬁnal fully connected layer. given convolutional feature fully connected feature propagating image write experiments image features extracted running layer model pre-trained imagenet without ﬁne-tuning. speciﬁcally create image features fully connected classiﬁer used activations last fully connected dimension hidden layer convolutional features generated using feature maps conv layers. addition images preprocessed similar being net. particular image resized shortest dimension stays pixels. center patch cropped resized image. various components models parameterized relu neural nets different sizes. transformation function textual features parameterized two-hidden layer fully-connected neural network whose architecture p--k dimensionality text feature vectors size predicted weight vector fully connected layer. image features layer visual mapping architecture intermediate convlayer features rm×w×h intermediate conv layer ﬁrst transformed ﬁlters size conv layer ﬁnal rk×w×h convolved ﬁlters predicted unit hidden layer adam used optimize proposed models minibatches images. found work well proposed models. potentially difference magnitude sparse gradient text features dense gradients convolutional layers. problem avoided using adaptive step sizes. model implementation based open-source package torch training time fully connected model hours titan whereas joint fc+conv model takes hours train. caltech ucsd bird -category caltech ucsd bird dataset widely used competitive ﬁne-grained classiﬁcation benchmarks. evaluated method cub- cub- versions bird dataset. instead using semantic parts attributes common approaches used images wikipedia articles train models. wikipedia article associated bird class articles total. average number words articles around wikipedia article transformed -dimensional term frequency-inverse document frequency feature vector. noticed here margin typically hinge loss objective encourages classiﬁer score higher correct text description lower classes. similarly sec. minibatch method adapted train hinge loss objective function efﬁciently. euclidean distance loss function previously used ﬁxed pre-learnt word embedding. cost function obtained classiﬁer formulation expanding euclidean distance minimizing hinge loss additional negative norm equivalent minimizing euclidean distance. hinge loss prevents inﬁnite penalty negative examples jointly learning embedding class text descriptions images. section empirically evaluate proposed models various objective functions. model corresponds sec. text features used predict fully-connected output weights image classiﬁer. conv model convolutional classiﬁer sec. predicts convolutional ﬁlters feature maps. joint model denoted c+conv. evaluate predicted zeroshot binary classiﬁer test images unseen seen classes. evaluation zero-shot learning performance varies widely throughout literature. report model performance using common metrics roc-auc commonly used metrics binary classiﬁcation. compute receiver operating characteristic curve predicted binary classiﬁer evaluate area curve. pr-auc pointed dataset number positive negative samples imbalanced precision-recall curve shown better metric compared roc. pr-auc computed trapezoidal integral area curve. prauc also called average precision top-k classiﬁcation accuracy although models viewed binary classiﬁers class multi-class classiﬁcation accuracy computed evaluating given test image text descriptions classes sorting ﬁnal prediction score ˆyc. table roc-auc pr-auc performance compared methods. performance shown zero-shot unseen classes test data seen training classes. class averaged mean aucs also included. roc-auc pr-auc report best numbers obtained among models trained different objective functions. cub- contains images different bird species. around images class. follow protocol using random split classes unseen rest classes seen. among seen classes allocate images testing images training. around training images testing. -fold cross-validation used evaluate performance. order compare previously published results ﬁrst evaluated model using image text features since image features spatial information predicting fully connected weights. visual features ﬁrst two-hidden layer neural hidden units ﬁrst second layers. used processed text features predict dimensional fully connected classiﬁer weights hidden layer neural net. baseline domain adaptation method also evaluated using features layer. oxford flower- dataset contains classes total images. ﬂowers chosen common ﬂower species united kingdom. class contains around images. used text corpus experimental setup similar ﬂower classes used training classes used unseen testing. similar cub- dataset compared method previously published results using visual text features. results caltech ucsd bird oxford flower datasets shown table dramatically improve upon state-of-the-art zero-shot learning. demonstrates deep approach capable producing highly discriminative feature vectors based solely natural language descriptions. predicting convolutional ﬁlters hybrid approach improves model performance. cub- updated version number images increased bird classes version number training cases doubled class. used experimental setup wikipedia articles version. studied model performance across different objective functions sec. evaluation shown table models trained binary cross entropy good balance roc-auc pr-auc classiﬁcation accuracy. models trained hinge loss constantly outperform others pr-auc figure word sensitivities unseen classes using model cub-. dashed lines correspond test-set prauc class. tf-idf entries independently words reduce pr-auc shown chart. approximately speaking words considered important attributes classes. wikipedia article class projected onto feature vector nearest image neighbors test-set shown. within-class nearest neighbors consider images class overall nearest neighbors considers test-set images. metric. however hinge loss models perform well top-k classiﬁcation accuracy zero-shot classes compared loss functions. euclidean distance model seems perform well unseen classes achieving much lower accuracy seen classes. shows best overall performance across three metrics. convolutional classiﬁer joint fc+conv model operate feature maps extracted cnns. recent work shown using features convolutional layers beneﬁcial using ﬁnal fully connected layer features cnn. evaluate performance convolutional classiﬁer using features different intermediate convolutional layers report results table features conv layer discriminative lower conv layers. proposed model learns discriminate unseen classes text descriptions additional information. contrast traditional zero-shot learning pipelines often involve list hand-engineered attributes. assume text descriptions images given model. goal generate list attributes particular class based text description. figure left panel shows sensitivity three unseen classes cub- test using model. word appears articles corresponding tf-idf entry measure change prauc. multiply ratio norms tf-idf vectors deletion ensure network sees total input magnitude. words result largest decrease pr-auc deemed important words unseen class. cases type bird tanager important feature. cases physically descriptive words purplish important. cases nondescriptive words variable found important perhaps rarity corpus. collection sensitive words thought pseudo-attributes class. figure right panel show ability text features describe visual features. three unseen classes text pipeline model produce weights search test images whose features highest product weights. restrict images within unseen class test image highly correlated textual description. allow images span entire classes resulting images show birds similar physical characteristics birds unseen classes. implies text descriptions informative physical characteristics model able produce semantically meaningful joint embedding. examples neighborhood queries found supplementary material. multi-class recognition performance zero-shot classes e.g. around top- accuracy cubird still lower attribute-based methods. possible take advantage discovered attribute list sec. reﬁne classiﬁcation performance. namely infer attribute list class learn second stage attribute classiﬁcation model. leave future work. introduced ﬂexible zero-shot learning model learns predict unseen image classes encyclopedia articles. used deep neural network text image pixels joint embedding space. interpreted using natural language description produce classiﬁer weights object recognition network. utilized structure cnns incorporates intermediate convolutional feature maps feature vector last fully-connected layer. showed method signiﬁcantly outperforms previous zero-shot methods roc-auc metric substantially improves upon current state-of-the-art cubird oxford flower datasets using images text articles. found network able learn pseudo-attributes articles describe different classes text embeddings captured useful semantic information images.", "year": 2015}