{"title": "Conditional Image Synthesis With Auxiliary Classifier GANs", "tag": ["stat.ML", "cs.CV"], "abstract": "Synthesizing high resolution photorealistic images has been a long-standing challenge in machine learning. In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in 128x128 resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, 128x128 samples are more than twice as discriminable as artificially resized 32x32 samples. In addition, 84.7% of the classes have samples exhibiting diversity comparable to real ImageNet data.", "text": "paper introduce methods improved training generative adversarial networks image synthesis. construct variant gans employing label conditioning results resolution image samples exhibiting global coherence. expand previous work image quality assessment provide analyses assessing discriminability diversity samples class-conditional image synthesis models. analyses demonstrate high resolution samples provide class information present resolution samples. across imagenet classes samples twice discriminable artiﬁcially resized samples. addition classes samples exhibiting diversity comparable real imagenet data. characterizing structure natural images rich research endeavor. natural images obey intrinsic invariances exhibit multi-scale statistical structures historically difﬁcult quantify recent advances machine learning offer opportunity substantially improve quality image models. improved image models advance stateof-the-art image denoising compression in-painting super-resolution better models natural images also improve performance semi-supervised learning tasks reinforcement learning problems several promising approaches building image synthesis models. variational autoencoders maximize variational lower bound log-likelihood training data vaes straightforward train introduce potentially restrictive assumptions approximate posterior distribution autoregressive models dispense latent variables directly model conditional distribution pixels models produce convincing samples costly sample provide latent representation. invertible density estimators transform latent variables directly using series parameterized functions constrained invertible technique allows exact log-likelihood computation exact inference invertibility constraint restrictive. generative adversarial networks offer distinct promising approach focuses game-theoretic formulation training image synthesis model recent work shown gans produce convincing image samples datasets variability resolution however gans struggle generate globally coherent high resolution samples particularly datasets high variability. moreover theoretical understanding gans on-going research topic work demonstrate adding structure latent space along specialized cost function results higher quality samples. exhibit pixel samples classes imagenet dataset increased global coherence importantly demonstrate quantitatively high resolution samples naive resizings resolution samples. particular downsampling samples leads decrease visual discriminability. also introduce metric assessing variability across image samples employ metric demonstrate synthesized images exhibit diversity comparable training data large fraction imagenet classes. detail work ﬁrst figure resolution samples classes taken ac-gan trained imagenet dataset. note classes shown selected highlight success model representative. samples imagenet classes linked later text. generative adversarial network consists neural networks trained opposition another. generator takes input random noise vector outputs image discriminator receives input either training image synthesized image generator outputs probability distribution possible image sources. discriminator trained maximize log-likelihood assigns correct source basic framework augmented using side information. strategy supply generator discriminator class labels order produce class conditional samples class conditional synthesis signiﬁcantly improve quality generated samples richer side information image captions bounding localizations improve sample quality instead feeding side information discriminator task discriminator reconstructing side information. done modifying discriminator contain auxiliary decoder network outputs class label training data subset latent variables samples generated forcing model perform additional tasks known improve performance original task addition auxiliary decoder could leverage pre-trained discriminators improving synthesized images motivated considerations introduce model combines strategies leveraging side information. model proposed class conditional auxiliary decoder tasked reconstructing class labels. propose variant architecture call auxiliary classiﬁer acgan every generated sample corresponding class label addition noise uses generate images discriminator gives probability distribution sources probability distribution class labels logd. objective function parts likelihood correct source log-likelihood correct class structurally model tremendously different existing models. however modiﬁcation standard formulation produces excellent results appears stabilize training. moreover consider acgan model part technical contributions work along proposed methods measuring extent model makes given output resolution methods measuring perceptual variability samples model thorough experimental analyis generative model images creates samples imagenet classes. early experiments demonstrated increasing number classes trained holding model ﬁxed decreased quality model outputs. structure ac-gan model permits separating large datasets subsets class training generator discriminator subset. imagenet experiments conducted using ensemble ac-gans trained class split. train several ac-gan models imagenet data broadly speaking architecture generator series ‘deconvolution’ layers transform noise class image train variants model architecture generating images spatial resolutions. discriminator deep convolutional neural network leaky relu nonlinearity mentioned earlier reducing variability introduced classes imagenet signiﬁcantly improves quality training. train ac-gan models images classes mini-batches size evaluating quality image synthesis models challenging variety probabilistic criteria lack perceptually meaningful image similarity metric. nonetheless later sections attempt measure quality ac-gan building several ad-hoc measures image sample discriminability diversity. hope work might provide quantitative measures used training subsequent development image synthesis models. building class-conditional image synthesis model necessitates measuring extent synthesized images appear belong intended class. particular would like know high resolution sample naive resizing resolution sample. consider simple experiment pretend exists model synthesizes images. trivially increase resolution synthesized images performing bilinear interpolation. would yield higher resolution images images would blurry versions resolution images discriminable. hence goal image synthesis model simply produce high resolution images produce high resolution images discriminable resolution images. measure discriminability feed synthesized images pre-trained inception network report fraction samples inception network assigned correct label. calculate accuracy measure series real synthesized images spatial resolution artiﬁcially decreased bilinear interpolation note spatial resolution decreased accuracy decreases indicating resulting images contain less class information summarized ﬁnding across imagenet classes imagenet training data reso could also inception score method several advantages accuracy ﬁgures easier interpret exponentiated kl-divergences; accuracy assessed individual classes; accuracy measures whether class-conditional model generated samples intended class. compute inception accuracy modiﬁed version inception-v supplied https//github.com/openai/improved-gan/. figure generating high resolution images improves discriminability. training data synthesized images zebra class resized lower spatial resolution subsequently artiﬁcially resized original resolution inception accuracy shown corresponding images. bottom left summary accuracies across varying spatial resolutions training data image samples models. error measures standard deviation across subsets images. dashed lines highlight accuracy output spatial resolution model. training data achieves accuracies resolutions respectively. bottom right comparison accuracy scores spatial resolutions point represents imagenet class. classes line equality. green corresponds zebra class. also artiﬁcially resized images sanity check demonstrate simply increasing number pixels increase discriminability. goal analysis show synthesizing higher resolution images leads increased discriminability. model achieves accuracy versus samples resized samples resized words downsizing outputs ac-gan decreases visual discriminability respectively. furthermore imagenet classes higher accuracy performed analysis ac-gan trained spatial resolution. model achieved less discriminability ac-gan model. accuracies model plateau spatial resolution consistent previous results. finally resolution model achieves less discriminability spatial resolution model. best knowledge work ﬁrst attempts measure extent image synthesis model ‘making given output resolution’ fact ﬁrst work consider issue all. consider important contribution proposing model synthesizes images imagenet classes. note proposed method applied image synthesis model measure ‘sample quality’ constructed. fact method applied type synthesis model long easily computable notion sample quality method ‘reducing resolution’. particular expect similar procecure carried audio synthesis. image synthesis model interesting outputs image. indeed well-known failure mode gans generator collapse output single prototype maximally fools discriminator class-conditional model images interesting outputs image class. inception accuracy measure whether model collapsed. model simply memorized example imagenet class would well metric. thus seek complementary metric explicitly evaluate intra-class perceptual diversity samples generated ac-gan. several methods exist quantitatively evaluating image similarity attempting predict human perceptual similarity judgements. successful multiscale structural similarity ms-ssim multi-scale variant well-characterized perceptual similarity metric attempts discount aspects image important human perception ms-ssim values range higher ms-ssim values correspond perceptually similar images. proxy image diversity measure msssim scores randomly chosen pairs images within given class. samples classes higher diversity result lower mean ms-ssim scores samples classes lower diversity higher mean ms-ssim scores training images imagenet training data contain variety mean ms-ssim scores across classes indicating variability image diversity imagenet classes note highest mean ms-ssim score training data. calculate mean ms-ssim score imagenet classes generated ac-gan model. track value training identify whether generator collapsed also employ metric compare diversity training images samples model training completed. figure plots mean ms-ssim values image samples training data broken class. blue line line equality. classes mean sample ms-ssim scores maximum ms-ssim training data. words classes sample variability exceeds least variable class imagenet training data. used measuring quality image compression algorithms using reference ‘original image’. instead potentially unrelated images. believe acceptable following reasons first visual inspection seems indicate metric makes sense pairs higher ms-ssim seem similar pairs lower ms-ssim. second restrict comparisons images synthesized using class label. restricts ms-ssim situations similar typically used third metric ‘saturated’ use-case. scores around would concerned applicability msssim. finally fact training data achieves variability metric evidence metric working intended. second point ms-ssim metric intended proxy entropy generator distribution pixel space measure perceptual diversity outputs. entropy generator output distribution hard compute pairwise ms-ssim scores would good proxy. even easy compute argue would still useful separate measure perceptual diversity. consider generator entropy sensitive trivial changes contrast well changes semantic content outputs. many applications don’t care contribution entropy useful consider measures attempt ignore changes image consider ‘perceptually meaningless’ hence msssim. presented quantitative metrics demonstrating ac-gan samples diverse discriminable examine metrics interact. figure shows joint distribution inception accuracies figure comparison mean ms-ssim scores pairs images within given class imagenet training data samples horizontal line marks maximum ms-ssim value across imagenet classes. point individual class. mean score across training data samples respectively. mean standard deviation scores across training data samples respectively. scores line arise classes training largely succeeded. ms-ssim scores across classes. inception accuracy ms-ssim anti-correlated fact classes diversity contain inception accuracies conversely classes high diversity inception accuracies exceed comparison inception-v model achieves accuracy average across classes fraction classes ac-gan samples reach level accuracy. indicates opportunity future image synthesis models. results suggest gans drop modes likely produce quality images. stands contrast popular hypothesis gans achieve high sample quality expense variability. hope ﬁndings help structure investigation reasons differing sample quality gans image synthesis models. previous quantitative results image synthesis models trained imagenet reported terms loglikelihood log-likelihood coarse potentially inaccurate measure sample quality instead compare previous state-of-the-art results cifar- using lower spatial resolution following procedure tend decreasing mean ms-ssim scores. classes generator ‘collapses’ increasing mean ms-ssim scores. compute inception score samples ac-gan resolution split groups random. also compute inception score extra samples split groups random. select best model based ﬁrst score report second score. performing grid search across hyperparameter conﬁgurations able achieve score compared state moreover accomplish without employing techniques introduced work provides additional evidence ac-gans effective even without beneﬁt class splitting. figure qualitative comparison samples ac-gan samples model possibility must investigated acgan overﬁt training data. ﬁrst check network memorize training data identify nearest neighbors image samples training data measured distance pixel space nearest neighbors training data resemble corresponding samples. provides evidence ac-gan merely memorizing training data. figure inception accuracy ms-ssim imagenet classes data point represents mean msssim value samples class. figure line marks maximum ms-ssim value across imagenet classes. samples ac-gan models achieve variability expense discriminability. ac-gan ﬁxed altering class label corresponds generating samples ‘style’ across multiple classes figure shows samples bird classes. elements although class changes column elements global structure preserved indicating ac-gan represent certain types ‘compositionality’. figure samples generated imagenet dataset. samples generated model randomly chosen samples generated ac-gan. ac-gan samples possess global coherence absent samples earlier model. sophisticated method understanding degree overﬁtting model explore model’s latent space interpolation. overﬁt model might observe discrete transitions interpolated images regions latent space correspond meaningful images figure highlights interpolations latent space several image samples. notably generator learned certain combinations dimensions correspond semantically meaningful features discrete transitions ‘holes’ latent space. second method exploring latent space acgan exploit structure model. acgan factorizes representation class information class-independent latent representation sampling figure latent space interpolations selected imagenet classes. left-most right-columns show three pairs image samples pair distinct class. intermediate columns highlight linear interpolations latent space three pairs images. class-independent information contains global structure synthesized image. column distinct bird class corresponds ﬁxed latent code class conditional image synthesis affords opportunity divide dataset based image label. ﬁnal model divide imagenet classes across acgan models. section describe experiments highlight beneﬁt cutting diversity classes training ac-gan. employed ordering labels divided contiguous groups ordering seen following section display samples classes. aspects split merit discussion number classes split intra-split diversity. training ﬁxed model classes harms model’s ability produce compelling samples performance larger splits improved giving model parameters. however using small split sufﬁcient achieve good performance. unable train converge reliably even split size raises question whether easier train model diverse classes similar classes unable conclusive evidence selection classes split signiﬁcantly affects sample quality. figure mean pairwise ms-ssim values imagenet classes plotted number imagenet classes used during training. everything except number classes trained using values report msssim values ﬁrst classes keep scores comparable. ms-ssim quickly goes class count increases. scores computed using random restarts class count using number training steps model. since observed generators recover collapse phase ﬁxed number training steps seems justiﬁed case. tivity class count well-supported experimentally. note that since failure case occurs class count increased ‘generator collapse’ seems plausible general methods addressing ‘generator collapse’ could also address sensitivity. work introduced ac-gan architecture demonstrated ac-gans generate globally coherent imagenet samples. provided quantitative metric image discriminability function spatial resolution. using metric demonstrated samples discriminable model generates lower resolution images performs naive resize operation. also analyzed diversity samples respect training data provided evidence image samples majority classes comparable diversity imagenet data. several directions exist building upon work. much work needs done improve visual discriminability resolution model. although synthesized image classes exhibit high inception accuracies average inception accuracy model still real training data immediate opportunity addressing augment discriminator pre-trained model perform additional supervised tasks improving reliability training ongoing research topic. imagenet classes exhibited diversity comparable real training data. training stability vastly aided dividing imagenet classes across ac-gan models. building single model could generate samples classes would important step forward. image synthesis models provide unique opportunity performing semi-supervised learning models build rich prior natural image statistics leveraged classiﬁers improve predictions datasets labels exist. ac-gan model perform semi-supervised learning ignoring component loss arising class labels label unavailable given training image. interestingly prior work suggests achieving good sample quality might independent success semi-supervised learning references ball´e johannes laparra valero simoncelli eero density modeling images using generalized normalization transformation. corr abs/. http//arxiv.org/abs/.. denton emily chintala soumith szlam arthur fergus robert. deep generative image models using laplacian pyramid adversarial networks. corr abs/. http//arxiv.org/ abs/.. kingma diederik rezende danilo jimenez mohamed shakir welling max. semi-supervised learning deep generative models. corr abs/. http//arxiv.org/abs/. ledig theis huszar caballero aitken tejani totz wang photorealistic single image super-resolution using generative adversarial network. arxiv e-prints september kede qingbo wang zhou duanmu zhengfang yong hongwei hongliang zhang lei. group competition methodology compare objective image quality models. ieee conference computer vision pattern recognition june maas andrew hannun awni andrew. rectiﬁer nonlinearities improve neural network acoustic models. proceedings international conference machine learning nguyen dosovitskiy alexey yosinski jason brox thomas clune jeff. synthesizing preferred inputs neurons neural networks deep generator networks. corr abs/. http//arxiv.org/abs/.. radford alec metz luke chintala soumith. unsupervised representation learning deep concorr volutional generative adversarial networks. abs/. http//arxiv.org/ abs/.. ramsundar bharath kearnes steven riley patrick webster dale konerding david pande vijay. masprosively multitask networks drug discovery. ceedings international conference machine learning reed scott akata zeynep xinchen logeswaran lajanugen schiele bernt honglak. generproceedative adversarial text-to-image synthesis. ings international conference machine learning johnston nick hwang sung minnen david shor joel covell michele. full resolution image compression recurrent neural networks. corr abs/. http//arxiv.org/abs/.. oord a¨aron kalchbrenner vinyals oriol espeholt lasse graves alex kavukcuoglu koray. conditional image generation pixelcnn decoders. corr abs/. http //arxiv.org/abs/.. wang zhou bovik alan sheikh hamid simoncelli eero image quality assessment error visibility structural similarity. ieee transactions image processing wang zhou simoncelli eero bovik alan multiscale structural similarity image quality assessment. signals systems computers conference record thirty-seventh asilomar conference volume ieee russakovsky olga deng krause jonathan satheesh sanjeev sean huang zhiheng karpathy andrej khosla aditya bernstein michael berg alexander fei-fei imagenet large scale visual recognition challenge. international journal computer vision ./s---y. szegedy christian yangqing sermanet pierre reed scott anguelov dragomir erhan dumitru vanhoucke vincent rabinovich ancorr drew. abs/. http//arxiv.org/ abs/.. szegedy christian vanhoucke vincent ioffe sergey shlens jonathon wojna zbigniew. rethinking inception architecture computer vision. corr abs/. http//arxiv.org/ abs/.. transposed convolution transposed convolution transposed convolution transposed convolution input convolution convolution convolution convolution convolution convolution table imagenet hyperparameters. soft-sigmoid refers operation output units apply softmax activation units sigmoid activation remaining unit. also activation noise discriminator suggested transposed convolution transposed convolution transposed convolution input convolution convolution convolution convolution convolution convolution table cifar- hyperparameters. list given hyperparameter means performed grid search using values list. hyperparameters single ac-gan trained whole cifar- dataset. ac-gan trained split samples groups could give sense variance inception score. best knowledge identical analysis performed", "year": 2016}