{"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "text": "dataset bias remains signiﬁcant barrier towards solving real world computer vision tasks. though deep convolutional networks proven competitive approach image classiﬁcation question remains models solved dataset bias problem? general training ﬁne-tuning state-ofthe-art deep model domain requires signiﬁcant amount data many applications simply available. transfer models directly domains without adaptation historically poor recognition performance. paper pose following question single image dataset much larger previously explored adaptation comprehensive enough learn general deep models effectively applied image domains? words deep cnns trained large amounts labeled data susceptible dataset bias previous methods shown show generic supervised deep model trained large dataset reduces remove dataset bias. furthermore propose several methods adaptation deep models able operate little labeled domain speciﬁc data. experiments show adaptation deep models benchmark visual domain adaptation datasets provide signiﬁcant performance boost. supervised deep convolutional neural networks trained large-scale classiﬁcation tasks shown learn impressive mid-level structures obtain high levels performance contemporary classiﬁcation challenges models generally assume extensive training using labeled data testing limited data domain. practice however images would like classify often produced different imaging conditions drawn different distribution leading domain shift. scaling models domains remains open challenge. deep cnns require large amounts training data learn good mid-level convolutional models ﬁnal fully-connected classiﬁer stages. continuing expansion web-based datasets like imagenet promises produce labeled data almost desired category large-scale supervised datasets include images category across domains practical interest. earlier deep learning efforts addressed challenge learning layers unsupervised fashion using unlabeled data discover salient mid-level structures approaches unfortunately image datasets inherently biased theoretical practical results shown supervised methods’ test error increases proportion difference test training input distribution. many visual domain adaptation methods forth compensate dataset bias limited shallow models. evaluation image category classiﬁcation across visually distinct domains focused ofﬁce dataset contains image categories domains recently showed using deep mid-level features learned imagenet instead conventional bag-of-words features effectively removed bias domain adaptation settings ofﬁce dataset however limited experiments small-scale source domains found ofﬁce evaluated subset relevant layers. almost none previous domain adaptation studies used imagenet source domain utilized full parameters deep trained source data. recent work rodner attempted adapt imagenet dataset take advantage deep convolutional features. paper question deep models still suffer dataset bias trained layers truly large scale source dataset? here provide ﬁrst evaluation domain adaptation deep learned representations natural setting imagenet used source data target category. million labeled images available imagenet -way classiﬁcation dataset train model evaluate generalization ofﬁce dataset. constitutes three orders magnitude increase source data compared several thousand images available largest domain ofﬁce. easier adapt imagenet previous smaller source domains dataset bias remains major issue. fine-tuning parameters small amount labeled target data turns unsurprisingly problematic. instead propose simple intuitive adaptation method train ﬁnal domain-adapted classiﬁcation layer using various layers pre-trained network features without ﬁne-tuning parameters. provide comprehensive evaluation existing methods classiﬁer adaptation applied fully connected layers network including last task-speciﬁc classiﬁcation layer. adapting imagenet ofﬁce turns possible achieve target domain performance source domain performance using single labeled example target category. examine setting labeled examples target domain setting labeled target examples also describe practical solutions choosing various adaptation methods based experimental constraints limited computation time. task consider adapting large source domain target domain labeled examples. typical approach domain adaptation transfer learning deep architectures take representation learned back-propagation large dataset transfer representation smaller dataset ﬁne-tuning i.e. backpropagation lower learning rate however ﬁne-tuning requires ample amount labeled target data expected work well consider sparse label condition one-shot learning scenario evaluate below labeled example category target domain. fact experiments setting ﬁne-tuning actually reduces performance. speciﬁcally imagenet→webcam task reported section using ﬁnal output layer predictor target domain received accuracy using ﬁnal output layer tuning produced degraded accuracy separate method recently proposed deep adaptation called deep learning domain adaptation interpolating domains method learns multiple unsupervised deep models directly source target combined datasets uses representation general unsupervised deep convolutional models unable achieve performance supervised deep cnns. however training supervised deep model requires sufﬁcient labeled data. insight extensive labeled data available source domain exploited using supervised model without requiring signiﬁcant amount labeled target data. therefore propose using supervised deep source model supervised unsupervised adaptation algorithms applied models learned target data directly. hybrid approach utilize strong representation available supervised deep model trained large source dataset requiring enough target labeled data train shallow model fewer parameters. speciﬁcally consider training convolutional neural network source domain using network extract features target data used train auxiliary shallow learner. extracting features deep source model follow setup donahue extracts visual feature decaf imagenet-trained architecture propose general framework selectively adapting parameters convolutional neural network whose representation classiﬁer weights trained large-scale source domain imagenet. framework adds ﬁnal domain-adaptive classiﬁcation layer takes activations existing network’s layers input features. note network cannot effectively ﬁne-tuned without access labeled target data. adapted layer linear classiﬁer combines source target training data using adaptation method. demonstrate generality framework select representative popular linear classiﬁer adaptation approaches empirically evaluate section separate discussion supervised unsupervised adaptation settings. denote features extracted source domain features extracted target domain similarly denote source domain image classiﬁer target domain image classiﬁer many unsupervised adaptation techniques seek minimize distance subspaces represent source target domains. denote subspaces respectively. geodesic flow kernel method unsupervised domain adaptation approach seeks embeddings source target points minimize domain shift. inputs method lower-dimensional embeddings source target domains method constructs geodesic along manifold subspaces finally transformation using closed-form solution classiﬁcation subspace alignment method also begins low-dimensional embeddings source target domains respectively. seeks minimize transformation matrix objective analytical solution objective given trained source data transformed target data late fusion perhaps simplest supervised adaptation method independently train source target classiﬁer combine scores create ﬁnal scoring function. call approach late fusion. explored many simple adaptation approach. linear interpolation score particular example equal convex combination source target classiﬁer scores vadapt αvt. method requires setting hyperparameter determines weights source target classiﬁers. late fusion major advantages easy implement source classiﬁer uses precomputed make adaptation fast. case linear interpolation combination rule however method potentially suffer sensitive hyperparameter. show hyperparameter analysis section daum´e simple feature replication method proposed domain adaptation method augments feature vectors source component target component shared component. source data point augmented target data point augmented finally trained augmented source target data—a relatively expensive procedure given potentially large size source domain tripled augmented feature dimensionality. classiﬁer adaptation method projective model transfer proposed variant adaptive svm. takes input classiﬁer pre-trained source domain. pmtsvm learns target domain classiﬁer adding extra term usual objective target source hyperplanes. hinge denotes hinge loss data matrix label vector classiﬁer hyperplane hyperparameter which increases enforces transfer source classiﬁer. mmdt max-margin domain transforms method jointly optimizes svm-like objective feature transformation matrix mapping target points source feature space classiﬁer parameters source feature space. particular mmdt minimizes following loss function hinge deﬁned pmt) ofﬁce dataset collection images three distinct domains amazon dslr webcam. categories dataset consist objects commonly encountered ofﬁce settings keyboards cabinets laptops. categories overlap categories present -category imagenet classiﬁcation task. thus experiments limit classes. experiments using amazon source domain follow standard training protocol dataset using source examples category total images. overlapping categories backpack bike helmet bottle desk lamp desktop computer cabinet keyboard laptop computer mobile phone mouse printer projector ring binder ruler speaker trash can. imagenet largest available dataset image category labels. categories’ worth data train network categories overlap ofﬁce labeled source classiﬁer data. experiments fully trained deep model described section extracting feature representations three different layers cnn. train source classiﬁer using features source domains adapt target domain. source domains consider either amazon domain corresponding -category imagenet subset category many examples. focus webcam domain target domain amazon-to-webcam shown challenging shift combination exempliﬁes shift online images realworld images taken typical ofﬁce/home environments. note that regardless source domain chosen learn classiﬁer imagenet data categories used train network. method evaluated across random train/test splits report averages standard errors setting. random train/test split choose example training examples testing therefore test split examples. unsupervised adaptation methods operate transductive setting target subspaces learned unlabeled test data. support vector machine trained source data. support vector machine trained target data. support vector machine trained source target data. account large discrepancy number training data points source target domains weighted data points constraints source target domains effectively contribute equally optimization problem. speciﬁcally source data point receives weight target data point receives weight denote number data points source target respectively. first value used c-svm classiﬁer methods without validation data able tune parameter properly choose leave default value. since methods report require setting parameter feel relative comparisons methods sound even absolute numbers could improved setting daum´e mmdt look source target data simultaneously weighting scheme source target svm. late fusion linear interpolation combination rule reported across hyperparameter settings figure help understand performance varies trade emphasis learned classiﬁers source target domains. again validation data tune parameter report tables performance averaged across parameter settings. plot indicates usually best parameter setting could learned available data. choose corresponds allowing large amount transfer source classiﬁer target classiﬁer. source-only classiﬁer stronger target-only classiﬁer unsupervised methods evaluated variety subspace dimensionalities figure shows overall method performance vary signiﬁcantly dimensionality choice. table amazon→webcam adaptation experiment. show multiclass accuracy target domain test supervised unsupervised adaptation experiments across fully connected layer features labeled target example). best performing unsupervised adaptation algorithms shown blue best performing supervised adaptation algorithms shown red. completeness begin evaluating amazon source domain. preliminary results setting reported extend comparison presenting results adaptation algorithms complete evaluation hyperparameter settings. table presents multiclass accuracies algorithm using either layer deep network corresponds output fully connected layers. trained using amazon data achieves in-domain accuracy using decaf feature in-domain accuracy using decaf feature. numbers signiﬁcantly higher performance classiﬁer webcam test data indicating even decaf features still domain shift amazon webcam datasets. next consider unsupervised adaptation setting labeled examples available target dataset. scenario apply state-of-the-art unsupervised adaptation methods methods make subspace dimensionality hyperparameter. show results using -dimensional subspace leave discussion setting parameter section shift adaptation algorithms increase performance using layer feature offer additional improvement using layer feature. ﬁnally assume single example category available target domain. bottom rows table show supervised adaptation algorithms able provide signiﬁcant improvement regardless feature space chosen even one-shot scenario. experiment noticed using second fully connected layer stronger overall feature general. next address main questions paper still domain shift using large source dataset imagenet? begin answer question follow experimental paradigm previous experiment imagenet source dataset. results shown table again ﬁrst verify source achieves higher performance tested indomain data webcam data. indeed overlapping labels source produces accuracy imagenet data using decaf features accuracy using table imagenet→webcam adaptation experiment. comparison unsupervised supervised adaptation algorithms imagenet webcam domain shift. results computed using outputs fully connected layers features. best supervised adaptation performance indicated best unsupervised adaptation performance highlighted blue. table imagenet→webcam amazon→webcam adaptation experiments using decaf label activations trained full imagenet data. again compare multiclass accuracy various unsupervised supervised adaptation methods. best performing unsupervised adaptation algorithm shown blue best performing supervised adaptation algorithms shown red. note using imagenet source domain overall performance algorithms improves. addition unsupervised adaptation approaches effective smaller source domain experiment. decaf differs decaf features constitutes activations corresponding labels imagenet classiﬁcation task. proposed activations softmax unit compute label probabilities. instead experiment using decaf activations directly feature representation akin training another classiﬁer using output -way classiﬁer. imagenet results uniformly better decaf decaf decaf likely fact decaf explicitly trained imagenet data effectively discriminate imagenet categories. effectively classify images source domain able better adapt source domain target domain. however negligible difference performance amazon performance actually decreasing respect decaf certain adaptation methods. believe ﬁnal activation vector speciﬁc -way imagenet task decaf provides general representation better suited amazon domain. this turn results improved adaptation. general however difference various decaf representations amazon source small enough insigniﬁcant. adaptation experiments show that despite large size even imagenet large enough cover domains traditional domain adaptation methods long increasing performance mitigating effects shift. depending characteristics problem hand results suggest different methods suitable. labels exist target domain unsupervised adaptation algorithms easy fast compute adaptation time still achieve increased performance sourcemethods. scenario experimented subspace alignment based methods require setting parameter indicates dimensionality input subspaces. figure shows effect changing subspace dimensionality overall method performance. general noticed methods particularly sensitive parameter long dimensionality remains larger number categories label set. threshold subspace less likely capture important discriminative information needed classiﬁcation. case large source dataset limited number labeled target examples preferable compute source classiﬁer parameters advance examine source parameters target data adaptation time. examples kinds methods late fusion pmt. methods unaffected number data points source domain adaptation time thus applied quickly. experiments found properly tuned late fusion classiﬁer linear interpolation fastest effective approach. figure shows performance linear interpolation late fusion vary hyperparameter although method sensitive found source domains basic strategy setting around provides close approximation optimal performance. setting interpreted trusting target classiﬁer source much completely discount information available source classiﬁer. table report performance linear interpolation averaged across hyper parameter settings well performance linear interpolation best possible setting experiment denoted oracle performance. computational constraints labels target domain best-performing method seems frustratingly easy approach originally proposed daum´e applied deep models finally found feature representation signiﬁcant impact adaptation performance. results show imagenet source performs best decaf representation whereas amazon source performs best decaf representation. this combined intuition seems indicate adaptation source domains imagenet intermediate representation decaf powerful adaptation whereas imagenet classiﬁcation works best full representation trained paper presented ﬁrst evaluation domain adaptation large-scale source dataset deep features. demonstrated that although using imagenet source domain generalizes figure evaluation hyperparameters domain adaptation methods. analysis combination hyperparameter late fusion linear interpolation. analysis subspace dimensionality unsupervised adaptation algorithms experimental results show deep adaptation methods long mitigating effects domain shift. based results also provided practical recommendations choosing feature representation adaptation method accounting constraints runtime accuracy. number interesting directions take given results. first notice though decaf strongest feature learning classiﬁer imagenet data decaf actually better feature amazon source domain webcam target domain. could lead hybrid approach uses different feature representations various domains produces combined adapted model. another interesting direction explored integrate adaption algorithms deep models explicitly even allow feedback stages. current deep models although allow information ﬁnal classiﬁer representation learning architecture. feel next step separate task speciﬁc adaptable layer simply learn ﬁnal layer instead learns separate equivalent ﬁnal layer regularized ﬁnal layer learned source dataset. future work natural extension result shown paper pre-trained deep representations large source domains effectively adapted target domains using shallow linear adaptation methods cases target data limited approach best mitigate dataset bias.", "year": 2013}