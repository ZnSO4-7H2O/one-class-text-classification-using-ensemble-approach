{"title": "Budgeted Experiment Design for Causal Structure Learning", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "We study the problem of causal structure learning when the experimenter is limited to perform at most $k$ non-adaptive experiments of size $1$. We formulate the problem of finding the best intervention target set as an optimization problem, which aims to maximize the average number of edges whose directions are resolved. We prove that the objective function is submodular and a greedy algorithm is a $(1-\\frac{1}{e})$-approximation algorithm for the problem. We further present an accelerated variant of the greedy algorithm, which can lead to orders of magnitude performance speedup. We validate our proposed approach on synthetic and real graphs. The results show that compared to the purely observational setting, our algorithm orients majority of the edges through only a small number of interventions.", "text": "second question received less attention. address second question herein. speciﬁcally consider setup experiments containing exactly intervention. reason consider single-intervention experiments many applications experiments biology performing simultaneous interventions multiple variables feasible. majority work ﬁeld causality separates design algorithms dealing statistical concerns. reason statistical tests required often well-studied statistics. many seminal works ﬁeld causal inference almost entire books decouple statistical algorithmic considerations. focus algorithm design side problem formulate optimization problem. propose approximation algorithm allows experimenter take high advantage limited budget experiments. contributions. interventional inference algorithm ﬁrst observational test algorithm performed variables. test learns skeleton well orientation edges causal graph. based result initial stage complete experiments designed non-adaptive manner. advantage non-adaptive approach complete experiments enables experimenter perform interventional experiments parallel. formal description problem interest provided problem description section. present problem ﬁnding best intervention target optimization problem aims maximize average number edges whose directions resolved. prove objective function monotonically increasing submodular. implies general greedy algorithm -approximation algorithm. since computing objective function intractable given present unbiased estimation function. additionally propose fast estimator close study problem causal structure learning experimenter limited perform non-adaptive experiments size formulate problem ﬁnding best intervention target optimization problem aims maximize average number edges whose directions resolved. prove objective function submodular greedy algorithm -approximation algorithm problem. present accelerated variant greedy algorithm lead orders magnitude performance speedup. validate proposed approach synthetic real graphs. results show compared purely observational setting algorithm orients majority edges small number interventions. problem learning causal relations among variables interest many scientiﬁc domains causal structures commonly represented directed acyclic graphs vertices random variables directed edge variable indicates variable direct cause order uncover causal relations among variables experimenter restricted work observational data variables running conditional independence based algorithms usually left causal relations unresolved. hand sufﬁcient experiments involving interventions identify underlying causal graph completely. interventional inference algorithm consists experiments. experiment experimenter intervenes subset variables collects data intervened system. setting natural questions arise smallest required number experiments performance unbiased estimator improved algorithm section implement accelerated variant general greedy algorithm lazy evaluations originally proposed minoux algoirthm lead orders magnitude performance speedup using synthetic real data experiments section show proposed approach recovers signiﬁcant portion edges number interventions many graphs interest. generic algorithms purely observational setting greedy equivalence search algorithm purely observational approaches reconstruct causal graph markov equivalence class hence direction edges remain unresolved. albeit stronger assumptions full structure learning using merely observational data feasible growing body research learning causal structures using interventional data speciﬁcally hauser b¨uhlmann extended notion markov equivalence interventional case proposed interventional generalization algorithm. note performing intervention could viewed optimally designing change environment. case data comes different unknown changes environment studied. regarding ﬁrst question discussed earlier considered complete graph underlying causal structure obtain worst case bounds number required experiments under assumption causal sufﬁciency. work cases experiments containing bounded unbounded number interventions studied. shown problem designing proper experiments causal inference connected problem ﬁnding separating system graph. hence connection authors derived fundamental bounds number required experiments fully learning graph. adaptive algorithms experiment design proposed algorithms minimize number experiments worst case proposed. algorithms adaptive polynomial complexity size experiments large half order graph practical many real-life applications. authors present information-theoretic lower bounds number required experiments deterministic randomized adaptive approaches. also proposed adaptive algorithm allowed learn chordal graphs completely. authors considered costs intervening variable derived experiment design algorithm minimum total cost reconstructs whole structure. also considered case number experiments limited. however experiment setup allowed include intervening arbitrary number variables. budgeted experiment design problem similar inﬂuence maximization problem. goal latter vertices given network speciﬁed inﬂuence model expected number vertices inﬂuenced seeds maximized. authors showed selecting inﬂuential vertices np-hard provided ﬁrst provable approximation guarantees efﬁcient algorithms based submodularity objective function. many improvements besides interpretative differences important distinction problems maximum inﬂuence problem goal spread inﬂuence vertices graph budgeted experiment design problem goal pick initial vertices leads discovering orientation many edges possible. optimal solution problems given graph quite different deﬁnition mixed graph consists vertices undirected edges directed edges directed graph consists vertex directed edges directed graph ﬁnite graph directed cycles. called causal vertices represent random variables directed edge indicates variable direct cause variable model assume restrictions underlying causal dag. consider structural equation model variables collection equations denotes parents jointly independent noise variables. furthermore assume faithfulness assumption probability distribution causal sufﬁciency deﬁnition causal dags markov equivalent every distribution compatible graphs also compatible other. graphs partitioned mutually exclusive exhaustive markov equivalence classes equivalence classes induced markov equivalence relation graph union dags markov equivalence class graph union mixed graphs skeleton mixed graph skeleton contains directed edge direction edge either former later speciﬁed members set. rest edges union remain undirected. focus single-intervention experiments setup experiments therefore exper iment form simplify notation donate intervention targets moreover shown observing result null experiment orientation edge exists hand experiments orientation cannot learned. experiment intervened called zero information experiment prevents zero information experiments. formally focus following problem experimenter allowed perform experiments size portion graph could reconstructed average? formalize problem statement follows. given directed edges underlying deﬁne edges belong direction learned applying meek rules starting directed edges i.e. edges whose direction learned result information mentioned earlier intervening variables learn orientation edges intersecting members denoting edges intervening variables results learning direction edges edges whose direction learned result intervening applying meek rules g∗)| consider dags markov equivalence class since know ground truth deﬁne average number edges whose direction learned result intervention target problem hard solve reasons first ﬁnding optimum requires combinatorial search. second even given computing requires considering dags markov equivalence class worst case complete graph requires super-exponential computation time. using purely observational data learn causal structure markov equivalence. could done performing complete conditional independence based algorithm deﬁne follows. deﬁnition complete conditional independence-based algorithm includes ﬁrst ﬁnding skeleton vstructures graph performing conditional independence tests given observational data then applying meek rules. algorithm leads learning markov equivalence class ground truth dag. performing ground truth denote directed edges revealed procedure undirected edges interventions enable differentiate among different causal structures within markov equivalence class. notion ideal intervention intervention variable inﬂuence variables target variable removed randomized forcing values independent distribution intervention changes joint distribution variables system direct indirect cause. denote intervention interventional inference algorithm consists experiments ...ek} experiment contains interventions i.e. inference algorithm adaptive experiments performed sequentially information obtained previous experiments used design next passive experiments designed beforehand. approach take algorithm ﬁrst perform algorithm learn skeleton direction edges design experiments passive manner budget constraint. approach gives experimenter ability perform experiments parallel without need wait result experiment choose next one. example study gene regulatory networks cases cells same experiments performed different cells simultaneously. seminal work nemhauser showed submodular monotonically increasing function |ˆi|= found greedy algorithm satisﬁes maxi|i|=k greedy algorithm -approximation algorithm. result proposed approach. show function monotonically increasing submodular hence greedy algorithm -approximation algorithm maximization problem lemma function monotonically increasing i.e. sets proof. first show given directed graph function monotonically increasing function proposed method intervening elements ﬁrst discover orientation edges applying meek rules possibly learn orientation extra edges. implies therefore using information direction edges. hence step applying meek rules soundness order-independence meek algorithm recover direction extra edges i.e. turn implies finally relation gi∈g desired result immedisimilarly gi)| gi)|. since seen proof lemma gi). gi)|≥ therefore gi)∩r gi)| implies together fact function monotonically increasing function shows submodular function finally gi∈g since nonmentioned problem description section another issue regarding solving optimization problem computational intractability calculating given intervention target propose running monte-carlo simulations intervention model sufﬁcient number times obtain accurate estimation pseudo-code baseline estimator presented subroutine subroutine ﬁrst orient edges possible directions independently according bernoulli distribution obtain directed graph keep dags markov equivalence class multiset check whether markov equivalence class sufﬁces check v-structures note multiset repetition allowed operator pseudo-code indicates multiset addition. finally calculate estimated value instead theorem obtained subroutine unbiased estimate i.e. experiments showed cases generated graphs subroutine markov equivalence class therefore propose efﬁcient estimator pseudocode proposed estimator presented subroutine subroutine given mixed graph generate dags markov equivalence class follows consider subsets size random uniformly random order subset orient undirected edges among independently according bernoulli distribution. resulting orientation induced subgraph became directed cycle v-structure redo orienting. keep checking subsets size induced subgraph directed none prove claim directed cycle size itself claim trivial. suppose cycle size relabel vertices since graph chordal chord hence triangle vertices vi+} direction vi+} directed cycle size otherwise directed cycle vertices. relabeling vertices repeating reasoning concludes claim. components undirected subgraph chordal therefore claim insure generated directed graph sufﬁces make sure directed cycles length checks proposed procedure. checking generated markov equivalence class sufﬁces check v-structures check proposed procedure. resulted generated multiset finally calculate estimated value instead next consider required cardinality obtain desired accuracy estimation chernoff bound purpose. general greedy algorithm presented algorithm deﬁning marginal gain variable previous chosen algorithm iteratively adds variable largest marginal gain intervention target runs budget. either estimators used calculating estimation marginal gains. theorem exists probability larger algorithm )-approximation algorithm probability larger submodularity function exploited implement accelerated variant general greedy algorithm lazy evaluations originally proposed minoux round general greedy algorithm check marginal gain remaining vertices note consequence submodularity function function monotonically decreasing. main idea improved greedy algorithm take advantage property avoid checking variables round algorithm. idea follows suppose vertices i-th round algorithm obtained marginal gains round calculate monotonic decreasing property conclude hence need calculate detailed description improved greedy algorithm given algorithm idea formalized follows deﬁne proﬁt parameter variable initialize value also variables deﬁne update updv false beginning every round algorithm switched true update value marginal gain vertex round algorithm pick vertex largest proﬁt update proﬁt value marginal gain updv true. process repeated vertex largest proﬁt already updated i.e. update true. vertex round. example round vertex highest proﬁt updating proﬁt correctness improved algorithm follows directly submodularity theorem holds algorithm well. algorithm lead orders magnitude performance speedup synthetic graphs subsection evaluate performance proposed improved greedy algorithm synthetically generated chordal graphs. randomly chosen partial elimination ordering vertices generate underlying chordal graphs graph pick random ordering vertices. starting vertex highest order connect vertices lower order probability inversely proportional order then connect parents directed edges directed edge oriented parent lower order parent higher order. order make sure generated graph connected vertex connected vertices lower order pick uniformly random parent evaluate performance proposed algorithm underlying graph consider ratio number edges whose directions discovered merely result interventions number edges whose directions resolved observational data. note speciﬁc graph generating approach orientation none edges learned observational data. perfect elimination ordering vertices undirected chordal graph induced neighborhood subgraph formed vi−} clique. generated instances chordal dags order experiments improved greedy algorithm utilized subroutine used estimating figure depicts discovered edge ratio respect budget seen ﬁgure three interventions sufﬁces discover direction edges whose direction unknown prior performing interventions. investigate effect order graph performance proposed algorithm evaluated discovered edge ratio budget graphs order figure furthermore compare performance proposed algorithm optimal solution generated instances chordal dags order performed brute force search optimal solution budget discovered edge ratio proposed algorithm optimal solution respectively. real graphs evaluated performance proposed algorithm gene regulatory networks collection biological regulators interact other. transcription factors main players activate genes. interactions transcription factors regulated genes species genome presented directed graph. graph links drawn whenever transcription factor regulates gene’s expression. moreover vertices functions i.e. transcription factor regulated gene. considered grns dream silico network challenge conducted networks challenge extracted known biological interaction networks. since know true causal structures grns obtain give input proposed algorithm. figure depicts discovered edge ratio networks extracted grns e-coli yeast bacteria budget order network seen discovered edge ratio least grns. studied problem experiment design causal inference limited number experiments available. model experiment consists intervening single vertex makes results taking advantage ﬁnite budget interventions makes model suitable applications intervening several variables simultaneously feasible. also model experiments designed merely based result initial purely observational test enables experimenter perform interventional tests parallel. addressed following question much causal structure learned limited number experiments available? formulated problem ﬁnding best intervention target optimization problem aims maximize average number edges whose directions discovered. showed objective function monotonically increasing submodular. consequently greedy algorithm approximation algorithm problem. moreover proposed estimation methods order compute objective function given intervention targets. presented accelerated variant greedy algorithm lead orders magnitude performance speedup. examined proposed improved greedy algorithm synthetic well real graphs. results show signiﬁcant portion causal graphs learned number interventions. suppose figure depicts graph optimal solution inﬂuence maximization problem different optimal solution budgeted experiment design problems. clearly inﬂuencing vertex leads inﬂuencing vertices graph hence vertex solution inﬂuence maximization problem. intervening leads discovering orientation edges intervening leads discovering orientation edges. orientation learned ﬁrst iteration applying meek rules g∗)∪ then learned orientation meek rules rule oriented s.t. g∗)∪a) rule oriented s.t. rule oriented s.t. skeleton skeleton skeleton condition rule satisﬁed intervening well implies g∗)) contradiction. therefore sufﬁces show case belongs exactly g∗)∪ g∗)∪ belongs happen. sufﬁces show exist intervention target i.e. exist intervention target structure depicted figure subgraph applying orientations learned implies respectively hence respectively. therefore either case subgraph. therefore hence learned applying meek rules. consider rules following learned orientation rule structures figure subgraph applying orientations learned g∗). case structure using rule subgraph induced vertices also learn case structure using rule also learn therefore cannot learn direction hence subgraph. learned orientation rule structures figure subgraph applying orientations learned g∗). case structures using rule subgraph induced vertices also learn case structure using rule subgraph induced vertices also learn therefore cannot learn direction hence subgraph. learned orientation rule structures figure subgraph applying orientations learned g∗). case structures using rule subgraph induced vertices also learn case structure using rule subgraph induced vertices also learn using rule subgraph induced vertices also learn case structures using rule subgraph induced vertices also learn therefore cannot learn direction hence subgraph. also learn hence subgraph. case structure direction edge also known. direction edge using rule subgraph induced vertices also learn otherwise using rule subgraph induced vertices also learn therefore also mentioned earlier therefore learned orientation applying meek rules. triangle induced vertices learned orientation edge seen structures lead learning orientation least edges triangle. following show structure form lead learning orientation making subgraph either. suppose learned structure form depicted figure using rule subgraph induced vertices also learn therefore edge too. also using rule triangle induced vertices orientation edges therefore order subgraph need structure depicted figure subgraph. seen figure structure similar complete skeleton contains triangle vertices learned orientation claim procedure always repeats i.e. step skeleton contains triangle induced vertices learned orientation prove claim induction. already proved base induction above. step induction suppose hypothesis true vertex form structure form adjacent otherwise using rule subgraph induced vertices also learn moreover using rule triangle induced vertices direction also using rule subgraph induced vertices also learn therefore edge too. showed subgraph subgraph subgraph structure figure subgraph chain required subgraphs continue. therefore since order graph ﬁnite exist step since cannot vertex possible required subgraphs hence conclude subgraph. hauser b¨uhlmann characterization greedy learning interventional markov equivalence classes directed acyclic graphs. journal machine learning research kempe kleinberg tardos maximizing spread proceedings inﬂuence social network. ninth sigkdd international conference knowledge discovery data mining acm. kocaoglu dimakis vishwanath cost-optimal learning causal graphs. arxiv preprint arxiv.. koller friedman probabilistic graphical models principles techniques. press. leskovec krause guestrin faloutsos vanbriesen glance cost-effective outbreak detection networks. proceedings sigkdd international conference knowledge discovery data mining acm. marbach schaffter mattiussi floreano generating realistic silico gene networks performance assessment reverse engineering methods. journal computational biology meek graphical models selecting meinshausen hauser mooij peters versteeg b¨uhlmann methods causal inference gene perturbation experiments validation. proceedings national academy sciences", "year": 2017}