{"title": "Estimating 3D Trajectories from 2D Projections via Disjunctive Factored  Four-Way Conditional Restricted Boltzmann Machines", "tag": ["cs.CV", "cs.AI"], "abstract": "Estimation, recognition, and near-future prediction of 3D trajectories based on their two dimensional projections available from one camera source is an exceptionally difficult problem due to uncertainty in the trajectories and environment, high dimensionality of the specific trajectory states, lack of enough labeled data and so on. In this article, we propose a solution to solve this problem based on a novel deep learning model dubbed Disjunctive Factored Four-Way Conditional Restricted Boltzmann Machine (DFFW-CRBM). Our method improves state-of-the-art deep learning techniques for high dimensional time-series modeling by introducing a novel tensor factorization capable of driving forth order Boltzmann machines to considerably lower energy levels, at no computational costs. DFFW-CRBMs are capable of accurately estimating, recognizing, and performing near-future prediction of three-dimensional trajectories from their 2D projections while requiring limited amount of labeled data. We evaluate our method on both simulated and real-world data, showing its effectiveness in predicting and classifying complex ball trajectories and human activities.", "text": "estimation recognition near-future prediction trajectories based dimensional projections available camera source exceptionally difﬁcult problem uncertainty trajectories environment high dimensionality speciﬁc trajectory states lack enough labeled data article propose solution solve problem based novel deep learning model dubbed disjunctive factored four-way conditional restricted boltzmann machine method improves state-of-the-art deep learning techniques high dimensional time-series modeling introducing novel tensor factorization capable driving forth order boltzmann machines considerably lower energy levels computational costs. dffw-crbms capable accurately estimating recognizing performing near-future prediction three-dimensional trajectories projections requiring limited amount labeled data. evaluate method simulated real-world data showing effectiveness predicting classifying complex ball trajectories human activities. estimating predicting trajectories three-dimensional spaces based twodimensional projections available camera source open problem wide-ranging applicability including entertainment medicine biology physics etc. unfortunately solving problem exceptionally difﬁcult variety challenges variability states trajectories partial occlusions self articulation layering objects scene loss information resulting observing trajectories planar image projections. variety techniques considered variants problem incorporating additional sensors e.g. cameras radars provide data geometric solvers allowing accurate estimation prediction. though compelling success methods arrives increased costs computational complexities problem above however framed time-series estimation prediction numerous machine learning algorithms applied. emerging trend machine learning computer vision pattern recognition deep learning successfully applied variety ﬁelds e.g. multi-class classiﬁcation collaborative ﬁltering image quality assessment reinforcement learning transfer learning information retrieval depth estimation face recognition activity recognition related work temporal-based deep learners e.g. brieﬂy review next. extending standard restricted boltzmann machines temporal rbms consider succession rbms time frame allowing perform accurate prediction estimation time-series. complexity naive extensions require high computational effort acquiring acceptable behavior. conditional rbms remedy problem proposing alternative extension rbms here architecture consists separate visible layers representing history current values hidden layer latent correlation discovery. though successful crbms capable modeling time series data relatively smooth variations similarly state-of-the-art neural network architectures time series e.g. recurrent neural networks learn within model different types time-series. thus model different types non-linear time variations within model authors extend crbms allowing three-way weight tensor connection among different layers. computational complexity reduced adapting factored version weight tensor leads construction exhibiting accurate modeling prediction results variety experiments including human motion styles however methods fail perform classiﬁcation regression uniﬁed framework. recently factored four-way conditional restricted boltzmann machines proposed extend fcrbms incorporating label layer four-way weight tensor connection among layers modulate weights capturing subtle temporal differences. construction allowed ffw-crbms perform both i.e. classiﬁcation real-valued predictions within model outperform state-of-the-art specialized methods classiﬁcation prediction contributions paper ﬁrst propose ffw-crbms estimate trajectories projections time also capable classify trajectories. though successful discovered ffw-crbms require substantial amount labeled data achieving acceptable performance predicting three-dimensional trajectories two-dimensional projections. ffw-crbms require three-dimensional labeled information accurate predictions typically available secondly paper remedy problems proposing extension ffw-crbms dubbed disjunctive ffw-crbms extension reﬁnes factoring four-way weight tensor connecting machine layers settings labeled data scarce. adopting factorization specializes ffw-crbms ensures lower energy levels yields sufﬁciency reduced training dataset dffw-crbms reach similar classiﬁcation performance state-of-the-art methods least double performance real-valued predictions. importantly accuracy improvements come computational beled data simultaneously classifying predicting three-dimensional trajectories based two-dimensional projections accurately estimating three-dimensional postures arbitrary number time-steps future. extensively tested dffw-crbms both simulated real-world data show capable outperforming state-of-the-art methods real-valued predictions classiﬁcations. ﬁrst experiments evaluate performance predicting classifying simulated three-dimensional ball trajectories thrown different initial spins. given successes second experiments predict classify high-dimensional human poses activities using real-world data showing dffwcrbms acquire double accuracy results reduced labeled data sizes. section provides relevant background knowledge essential remainder paper. firstly restricted boltzmann machines basis proposed method surveyed. secondly contrastive divergence training algorithm deep learning methods presented. section concludes brief description deep-learning based models time series prediction classiﬁcation. restricted boltzmann machines energy-based models unsupervised learning. generative model distribution training data prediction models employ stochastic nodes layers making less vulnerable local minima further stochastic neural conﬁgurations rbms possess excellent generalization density estimation capabilities formally consists visible hidden binary layers connected undirected bipartite graph. exactly visible layer collects visible units represents real-data hidden layer representing hidden units increases learning capability enlarging class distributions represented arbitrary complexity. number neurons visible hidden layers respectively. denotes weight connection visible hidden unit denote state visible hidden unit respectively. matrix weights layers given rnh×nv. energy function rbms given where represent biases visible hidden layers respectively. joint probability visible hidden conﬁguration written exp) marginal distribution used determine probability data point represented rbms parameters trained maximizing likelihood function typically following gradient energy function. unfortunately rbms maximum likelihood estimation applied directly intractability problems. problems circumvented using contrastive divergence train rbm. learning follows gradient where distribution markov chain running steps symbolizes kullback-leibler divergence update rules free parameters rbm’s energy function equation differentiated respect parameters. thus weight updates done follows hjvin total number input instances superscript shows input instance. superscript indicates states obtained steps gibbs sampling markov chain starts original data distribution practice learning performed using step gibbs sampling carried four sub-steps initialize visible units infer hidden units infer visible units update weights biases. conditional restricted boltzmann machines extension rbms used model time series data example human activities. undirected model binary hidden variables connected real-valued visible ones. time step hidden visible nodes receive connection visible variables last time-steps. history real-world values time collected real-valued history vector nv<t taylor hinton introduced factored condition restricted boltzmann machine permits modeling different styles time series within model introduction multiplicative three-way interactions preset style label reduce computational complexity model factored third order tensors layer products matrices. formally fcrbm deﬁnes joint probability distribution visible hidden neurons. joint distribution conditioned past observations model parameters preset style label interested readers referred comprehensive discussion crbms fcrbms. limitations exhibited fcrbms e.g. impossibility performing classiﬁcation without extensions proposed four-way conditional restricted boltzmann machines performing prediction classiﬁcation uniﬁed framework fw-crbms introduced additional layer four-way multiplicative weight tensor interaction neurons. please note that later four-way models proposed perform classiﬁcation prediction fw-crbms extended fcrbms include label layer fourth order weight tensor connection wijko rnv×nh×nv<t×nl nv<t represent number neurons present hidden history label layers respectively. number factors indices visible layer neurons hidden layer neurons history layer neurons labeled layer neurons respectively. symbolize bidirectional symmetric weights visible hidden label layers factors respectively figure high level depiction ffw-crbm showing four layer conﬁguration factored weight tensor connection among them. gaussian nodes shown history visible layers represent real-valued inputs sigmoidal nodes hidden label layers demonstrate binary values. wv<t represents directed weights history layer factors. case three-way models standard unsuccessful training also four-way models need predicting output layers thus proposed sequential variant named sequential markov chain contrastive divergence suitable tuning free parameters fw-crbms. ffw-crbms shown good generalization time series latent feature learning capabilities compared state-of-the-art techniques including limited support vector machines crbms fcrbms reasons believe ffw-crbms serve basis predicting three-dimensional trajectories two-dimensional projections. unfortunately ffw-crbms readily applicable problem require substantial amount labeled data successful tuning. paper extend ffw-crbms disjunctive ffw-crbms proposing novel factoring process essential predicting classifying trajectories projections. model detailed next reduces sample complexities current methods allows lower energy levels compared ffw-crbms leading improved performance. section details disjunctive factored four conditional restricted boltzmann machines shown figure similarly ffw-crbms model consists four layers represent visible history hidden label units. contrary factoring adopted ffw-crbms however model incorporates factoring layers. ﬁrst i.e. ﬁgure responsible specializing machine real-valued predictions wv<t second specializes machine classiﬁcation corresponding weight tensor collections. specialization responsible reducing sample complexities needed dffw-crbms successful parameter tuning demonstrated section computational complexity dffw-crbm remains here denotes total number factors weight tensor collection specializing dffw-crbms regression total number factors responsible classiﬁcation. represent indices visible layer neurons hidden layer neurons history layer neurons labeled layer neurons respectively. furthermore represent bidirectional symmetric weight connections visible hidden layers factors wv<t denote directed weights label history layers factors. similarly represent bidirectional symmetric weights label hidden layers factors wv<t denote directed weights visible history layers factors. finally groups four weight matrices noted belong factorized tensor specialization regression classiﬁcation respectively. inference dffw-crbm corresponds determining values activation probabilities units. shown figure units within layer share connections. allows parallel probability computation units labelled within layer. overall input hidden represents update iteration momentum denotes learning rate weight decay. detailed discussion choice parameters provided hinton therein update rules attained deriving energy functional respect free parameters dffw-crbms eight free parameters corresponding connections factors layers inferred. presented below. intuitively update equations aims minimizing reconstruction error moreover update equations include three main terms representing connections factored weights corresponding layer machine figure instance connections hidden history label layers sufﬁce updating represents markov chain step running total steps starting original data distribution denotes expectation input data represents model’s expectation. algorithm presents high-level description sequential markov chain contrastive divergence adapted train dffw-crbms. shows main steps needed training machines. firstly visible layer inferred ﬁxing history label layers. second step label layer reconstructed ﬁxing history present layers. updating weights involves implementation rules derived previous section. procedures repeated pre-speciﬁed number epochs epoch reconstruction error decreasing reach minimum energy function guaranteeing minimized divergence original data distribution given model. section extensively tests performance dffw-crbms simulated well real-world datasets. major goal experiments assess capability dffw-crbm predict three-dimensional trajectories twodimensional projection given small amounts labeled data secondary objective goal classify trajectories different spins activities real-valued prediction setting compared method state-of-the-art ffwcrbms fcrbms classiﬁcation method’s performance tested ffw-crbms support vector machines radial basis functions evaluation metrics assess models’ performance variety standard metrics used. classiﬁcation used accuracy percentages estimation tasks used normalized root mean square error estimating distance prediction ground truth pearson correlation coefﬁcient reﬂecting correlations predictions ground truth p-value arrive statistically signiﬁcant predictions. generated different ball trajectories thrown different spins using bullet physics library. simulated dataset targeted three objectives using small amounts labeled training data. first estimated ball coordinates based projections time-step second aimed predicting near-future ball coordinates recursively giving limited sequence coordinates starting point. third classiﬁed various ball spins based coordinates. used four trajectory classes corresponding four different ball spin types. class trajectories containing approximately time-steps sampled. assess performance dffw-crbm performed -fold cross validation reported mean standard deviation results. precisely class trajectories used labeled trajectory train models used testing. deep learner setting visible layers models neurons three denoting ball center coordinates projection time label layer consisted neurons history layers included table classiﬁcation present step estimation multi-step prediction balls trajectories experiment. results cross-validated presented mean standard deviation show method capable outperforming state-of-the-art techniques evaluation metrics. neurons corresponding last history frames. frame incorporates coordinates center ball projected dimensional space. number hidden neurons number factors discussed next paragraph subsection learning rate momentum chosen. weight decay factors number markov chain steps training phase also gibbs sampling testing phase weights initialized finally data normalized mean unit variance explained models trained epochs. importance disjunctive factoring optimal number hidden neurons factors performed exhaustive search varying number hidden neurons number factors gain insights behavioral differences ffw-crbms dffw-crbms even energy equation dffw-crbm extra tensor figure illustrate scale heat-map averaged energy levels. computed using equation ffw-crbm equation dffw-crbm models trained epochs. though models acquire lowest energy levels conﬁguration starting hidden neurons number factors larger analyzing results signiﬁes importance disjunctive factoring introduced paper. namely dffw-crbms always acquire lower energy levels compared ffw-crbms it’s specialized tensor factoring. moreover averaging energy levels aforementioned ﬁgure found average energy level dffw-crbm approximately three times smaller ffw-crbm thus anticipating accurate performance results showed next. figures compare capabilities dffw-crbms estimating different trajectories balls picked random ffw-crbms showing method capable achieving closely correlated transitions real trajectory. interestingly dffw-crbms handle discontinuities less abruptly compared ffw-crbms. cross-validation results showing performance models ball trajectories summarized table terms classiﬁcation svm-rbf ffw-crbm figure estimation different balls trajectories counterparts dffw-crbm ffw-crbm showing method outperforms state-of-the-art techniques requiring less data. dffw-crbm perform almost similarly slightly advantage dffwcrbm. case coordinates estimation projection time-step dffw-crbm clearly outperforms state-of-the-art methods nrmse almost twice smaller fcrbms ffw-crbms. besides that case mean value correlation coefﬁcient dffw-crbm double ffwcrbm fcrbm powerless multi-step prediction near-future point coordinates dffw-crbm even signiﬁcant improvement. worth highlighting scenario average value step prediction almost perfectly steps predicted future mean value still positive larger methods. ﬁnal experiments tested change accuracy classiﬁcation number data points used. summarized bar-graph figure showing method slightly outperforms state-of-the-art techniques cases. given successes next evaluate performance method real-world data representing variety human activities. experiments targeted main objectives third secondary one. ﬁrst corresponded estimating three-dimensional joint coordinates two-dimensional projections well predicting coordinates near future third involved classifying activities based two-dimensional joint coordinates. please note third experiment exceptionally hard loss three-dimensional information making different activities similar. figure estimation trajectory center ball projection using ffw-crbm dffw-crbm ﬁgure presents trajectory space bottom ﬁgure presents coordinates trajectory plot. actors million human poses corresponding images. further actors database accurately reports human skeleton joint positions space together projections acquired frames seconds used seven actors subject subject subject subject subject subject subject accompanied corresponding joint activities purchasing smoking phoning sitting-down eating walking-together greeting sitting posing discussing directing walking waiting avoid computational overhead also reduced temporal resolution data leading total training testing instances. instances split different subjects joints projections time label layer consisted neurons history layers included neurons corresponding history frames incorporating joint coordinates. size hidden layer neurons number factors explained next paragraph. furthermore learning rate used guarantee bounded reconstruction errors. number markov chain steps training phase gibbs sampling testing phase weights initialized particularities momentum weight decay also data normalized mean unit standard deviation. importance disjunctive factoring similarly previous experiment simulated balls trajectories searched optimal number hidden neurons factors performing exhaustive search varying number hidden neurons factors respectively. figure depicts scale averaged energy levels ffw-crbm dffw-crbm trained epochs. before balls experiment energy levels models affected number factors number hidden neurons. even scrutinizing unnormalized energy levels fact energy levels dffw-crbm always much lower energy levels ffw-crbm reﬂects importance disjunctive factoring. quantifying averaging energy levels model observe dffw-crbm average approximately three times less energy ffw-crbm results tables show dffw-crbms capable achieving better performance state-of-the-art techniques classiﬁcation prediction even using small amount training data. results provide proofof-concept fact ddfw-crbms capable accurately predicting trajectories projections using data training testing. activity recognition goal experiments classify activities based projections. please note task substantially difﬁcult solve loss information exhibited performed projection. namely activities different space might resemble high similarities projections leading classiﬁcation accuracies. table reports accuracy performance dffw-crbms state-of-the-art methods including svms ffw-crbms. averaging results subjects observe three models perform comparable. worth mentioning classiﬁcation accuracy random choice scenario would models performs approximately times better. also performed experiments classify activities input data points prove correctness presented methods show dffw-crbms capable achieving state-of-the-art classiﬁcation results. here used data train models remaining test. clear figure models increase performance amount training data increases reaching around accuracy data used training. estimating skeleton coordinates projections task estimate joint coordinates counterpart using training data. results depicted table show dffw-crbms achieves better performance ffw-crbms fcrbm. though ffw-crbms perform comparatively worth noting p-values signify fact dffw-crbms drastically outperform ffw-crbms sense predictions correlated ground truth property essential accurate reliable predictions. figure average classiﬁcation accuracies mean standard deviation human activities experiments subjects data training testing models come person amount training data increased. perform multi-step predictions skeleton joints based projections. starting initial state model executed autonomously recursively feeding-back outputs perform next-step predictions. deﬁnitely performance expected degrade since prediction errors accumulate time. table showing performance models step predictions validate phenomenon since metrics show decrease models’ performance time. table however also signify dffw-crbms outperform ffw-crbms multi-step predictions achieving average nrmse compared nrmse ffw-crbms. results summarized figure showing minimum maximum performance results models. experiments clearly dffw-crbm best performer both prediction errors correlations. motivation second human activities experiments goal determine extend dffw-crbms generalize across different human subjects activities. main motivation reality subject-speciﬁc data scarce data available different users domains abundant. results reported table figure show dffw-crbms capable generalizing beyond speciﬁc subjects ability learning latent features shared among variety tasks. experiments here data subjects used train models predictions unseen subject performed. procedure repeated cross-validate results. further emulate real-world settings data used training. testing however data testing subjects used increasing tasks’ difﬁculty. three goals previous experiments targeted. crbms achieve comparable results ffw-crbms accuracy outperforming svms. clearly classiﬁcation results resemble higher accuracies compared table reasons attributed back availability similar domain data subjects signifying latent feature similarities automatically learn dffw-crbms. estimation skeleton coordinates projections again dffw-crbms achieve better performance ffw-crbms present step estimation skeleton joints projections outperform fcrbm. worth highlighting dffw-crbms capable attaining high average prediction correlation ground-truth almost prediction skeleton trajectories finally figure shows dffw-crbms capable surpassing ffw-crbms multistep predictions unseen subjects achieving prediction errors high ground paper proposed disjunctive factored four-way conditional restricted boltzmann machines novel machine learning techniques used estimating trajectories projections using limited amounts labeled data. tensor factoring introduced dffw-crbms machines capable achieving substantially lower energy levels state-of-the-art techniques leading accurate predictions classiﬁcation results. furthermore dffw-crbms capable performing classiﬁcation accurate near-future predictions simultaneously uniﬁed framework. table classiﬁcation present step estimation multi-step prediction human activities experiments training testing done different persons. results cross-validated presented mean standard deviation. empirical evaluation showed methods capable outperforming state-ofthe-art machine learning algorithms classiﬁcation regression. precisely dffw-crbm capable achieving substantially lower energy levels ffw-crbm. leads least double accuracies real-valued predictions acquiring similar classiﬁcation performance increased computational complexity costs.", "year": 2016}