{"title": "Conditional Similarity Networks", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "What makes images similar? To measure the similarity between images, they are typically embedded in a feature-vector space, in which their distance preserve the relative dissimilarity. However, when learning such similarity embeddings the simplifying assumption is commonly made that images are only compared to one unique measure of similarity. A main reason for this is that contradicting notions of similarities cannot be captured in a single space. To address this shortcoming, we propose Conditional Similarity Networks (CSNs) that learn embeddings differentiated into semantically distinct subspaces that capture the different notions of similarities. CSNs jointly learn a disentangled embedding where features for different similarities are encoded in separate dimensions as well as masks that select and reweight relevant dimensions to induce a subspace that encodes a specific similarity notion. We show that our approach learns interpretable image representations with visually relevant semantic subspaces. Further, when evaluating on triplet questions from multiple similarity notions our model even outperforms the accuracy obtained by training individual specialized networks for each notion separately.", "text": "makes images similar? measure similarity images typically embedded featurevector space distance preserve relative dissimilarity. however learning similarity embeddings simplifying assumption commonly made images compared unique measure similarity. main reason contradicting notions similarities cannot captured single space. address shortcoming propose conditional similarity networks learn embeddings differentiated semantically distinct subspaces capture different notions similarities. csns jointly learn disentangled embedding features different similarities encoded separate dimensions well masks select reweight relevant dimensions induce subspace encodes speciﬁc similarity notion. show approach learns interpretable image representations visually relevant semantic subspaces. further evaluating triplet questions multiple similarity notions model even outperforms accuracy obtained training individual specialized networks notion separately. understanding visual similarities images problem computer vision. measure similarity images embedded feature-vector space distances preserve relative dissimilarity. commonly convolutional neural networks trained transform images respective feature-vectors. refer similarity networks. learning networks pairwise triplet similarity constraints simplifying assumption commonly made objects compared according unique measure similarity. however objects various attributes compared according multitude semantic aspects. figure example illustrating objects compared according multiple notions similarity. here demonstrate three intuitive concepts challenging combine machine vision algorithm embed objects feature space distances preserve relative dissimilarity shoes category; objects similar terms color; sneakers t-shirts stylistically closer. illustrative example consider comparison coloured geometric shapes task toddlers regularly exposed beneﬁts concept learning. consider triangle circle similar terms color triangle blue triangle. however triangles similar another terms shape triangle circle. optimal embedding minimize distances between perceptually similar objects. example also practical example figure creates situation objects semantically repelled drawn time. standard triplet embedding ignores sources similarity canjointly satisfy competing semantic aspects. thus successful embedding necessarily needs take visual concept account objects compared address issue learn separate triplet networks aspect similarity. however idea wasteful terms parameters needed redundancy parameters well associated need training data. figure proposed conditional similarity network consists three components first learned convolutional neural network feature extractor learns disentangled embedding i.e. different dimensions encode features speciﬁc notions similarity. second condition encodes according visual concept images compared. third learned masking operation that given condition selects relevant embedding dimensions induce subspace encodes queried visual concept. work introduce conditional similarity networks joint architecture learn nonlinear embeddings gracefully deals multiple notions similarity within shared embedding using shared feature extractor. different aspects similarity incorporated assigning responsibility weights embedding dimension respect aspect similarity. achieved masking operation leading separate semantic subspaces. figure provides overview proposed framework. images passed convolutional network projected nonlinear embedding different dimensions encode features speciﬁc notions similarity. subsequent masks indicate dimensions embedding responsible separate aspects similarity. compare objects according various notions similarity selecting appropriate masked subspace. proposed approach convolutional network learns disentangled embedding well masks learn select relevant dimensions trained jointly. experiments evaluate quality learned embeddings ability embed unseen triplets. demonstrate csns clearly outperform single triplet networks even sets specialist triplet networks parameters available network trained towards single similarity notion. show csns make representation interpretable encoding different similarities separate dimensions. contributions formulating conditional similarity networks approach allows learn nonlinear embeddings incorporate multiple aspects similarity within shared embedding using shared feature extractor demonstrating proposed approach outperforms standard triplet networks even sets specialist triplet networks variety hard predictive visual tasks similarity based learning emerged broad ﬁeld interest modern computer vision used many contexts. disconnected input image triplet based similarity embeddings learned using crowdkernels further tamuz introduce probabilistic treatment triplets learn adaptive crowd kernel. similar work generalized multipleviews clustering settings amid ukkonen well maaten hinton combination triplet embeddings input kernels presented wilber work include joint feature embedding learning. early approach connect input features embeddings learn image similarity functions ranking foundational line work combining similarities neural network models learn visual features similarities revolves around siamese networks pairwise distances learn embeddings discriminatively. contrast pairwise comparisons triplets advantage ﬂexibility capturing variety higher-order similarity constraints rather binary similar/dissimilar statement pairs. neural networks learn visual features triplet based similarities used wang schroff face veriﬁcation ﬁne-grained visual categorization. insight works semantics captured triplet embeddings natural represent complex class-structures dealing problems highdimensional categorization greatly boost ability models share information classes. disentangling representations major topic recent machine learning literature example tackled using boltzmann machines reed chen propose information theoretical factorizations improve unsupervised adversarial networks. within stream research work closest karaletsos representation learning introduces joint generative model inputs triplets learn factorized latent space. however focus work generative aspect disentangling representations proof concept applications low-dimensional data. work introduces convolutional embedding architecture forgoes generative pathway favor exploring applications embed high-dimensional image data. thus demonstrate generative interpretation required reap beneﬁts conditional similarity networks demonstrate particular common computer vision tasks. theme work goal modeling separate similarity measures within system factorizing latent spaces. note relation goals variety approaches used representation learning. multi-view learning used shape inference shown generically good learn factorized latent spaces. multiple kernel learning employs information encoded different kernels provide predictions using synthesized complex feature space also used similarity-based learning mcfee lanckriet multi-task learning approaches used information disparate sources using differing assumptions combined beneﬁcially ﬁnal prediction task. indeed gating mechanism interpreted architectural novelty neural networks multi-task triplet learning. similar work multiliniear networks also strive factorize representations differ ignore weak additional information. interesting link also exists multiple similarity learning category speciﬁc similarities used approximate ﬁne-grained global embedding. global factorized embeddings thought approach capture similar information shared space directly feature learning. also discuss notion attention work employing gates attend mentioned subspaces inferred embeddings focusing particular visual tasks. term confused spatial attention used draw model bears similarity insofar shows ability gate focus model relevant dimensions beneﬁcial semantics quantitative performance model. figure masking operation selects relevant embedding dimensions given condition index. masking seen soft gating function attend particular concept. goal learn nonlinear feature embedding image feature space pair images euclidean distance reﬂects semantic dis-similarity. particular strive distance images semantically similar objects small distance images semantically different objects large. relationship hold independent imaging conditions. consider embedding observed images coordinates feature space here clariﬁes embedding function composition arbitrarily nonlinear function linear projection rd×b denotes dimensions embedding stands dimensions output nonlinear function general denote parameters function denoting ﬁlters weights. given unknown conditional similarity function oracle crowd compare images according condition condition deﬁned certain notion similarity according images compared. figure gives example notions according images fashion products compared. condition serves switch attented visual concepts effectively gate different similarity functions using image reference oracle apply decide whether similar conditioned oracle returns ordering distances call triplet triplet deﬁned indices {reference image distant image closer image} e.g. larger feature space spanned model given function learn nonlinear embedding consistent observed triplets deﬁne loss function triplets model similarity structure images. triplet loss commonly used euclidean distance representations images scalar margin helps prevent trivial solutions. generic triplet loss capable capturing structure induced multiple notions similarities. able model conditional similarities introduce masks embedding rd×nc number possible notions similarities. deﬁne parameters dimension denoting rectiﬁed linear unit max{ such denote selection c-th mask column dimension mask plays role element-wise gating function selecting relevant dimensions embedding required attend particular concept. role masking operation visually sketched figure masked distance function images given appearing small technical change inclusion masking mechanism triplet-loss highly non-trivial effect. mask induces subspace relevant embedding dimensions effectively attending relevant dimensions visual concept queried. loss function above translates modulated cost phasing euclidean distances between irrelevant feature-dimensions preserving loss-structure relevant ones. given triplet deﬁned indices observed images corresponding condition-index ﬁnal triplet loss function given figure visualization embeddings learned subspaces character feature space. subspaces obtained attending different subsets dimensions image representations. subspace left groups images character type right according font style. clear visual representation discretize space grid pick image cell random. without terms optimization scheme choose inﬂate embeddings create space data points instead learning appropriate parameters encode semantic structure. deﬁne loss-function lcsn training csns putting together deﬁned loss functions. given images triplet constraints associated condition well parameters masks embedding function loss deﬁned font style character type. particular contains different characters fonts ﬁrst second zapposk shoe dataset collected grauman. dataset contains images individual richly annotated shoes size pixels each resize images exhibit multiple complex variations. particular looking four different characteristics type shoes suggested gender shoes height shoes’ heels closing mechanism shoes also shoes’ brand information perform ﬁnegrained classiﬁcation test. supervise evaluate triplet networks sample triplet constraints annotations datasets. font dataset sample triplets characters type font different. zappos dataset sample triplets analogous three categorical attributes. heel heights numerical measurements triplet pick shoes similar height different height. first split images three parts training validation test set. then sample triplets within set. attribute collect train validation test triplets. initial model experiments convnet pre-trained imagenet. model variants ﬁne-tuned triplets differ trained. compare four different approaches schematically illustrated figure standard triplet network common approach learn triplet constrains single convolutional network embedding layer receives supervision triplet loss deﬁned equation such aims learn available triplets jointly come single measure similarity. task speciﬁc triplet networks second compare separate triplet network experts trained single notion similarity. overcomes simplifying assumption comparisons come single measure similarity. however comes cost signiﬁcantly parameters. best model achievable currently available methods. conditional similarity networks ﬁxed disjoint masks compare variants conditional similarity networks. extend standard triplet network masking operation embedding vector supervise network loss deﬁned equation ﬁrst variant learns convolutional ﬁlters embedding. figure visualization embeddings subspaces learned csn. spaces clearly organized according closure mechanism shoes category shoes. shows csns successfully separate subspaces. paper nonlinear embedding function deﬁned convolutional neural network. masked learning procedure masks learn select speciﬁc dimensions embedding associated given notion similarity. time learns encode visual features different dimensions embedding encode features associated speciﬁc semantic notions similarity. then test time image mapped embedding looking different dimensions image’s representation reason different semantic notions similarity. call feature space spanned function property disentangled preserves separation similarity notions test time. perform experiments different datasets. first illustrative purposes dataset fonts collected bernhardsson. dataset contains million images single characters gray scale size pixels each. dataset exhibits variations according pre-deﬁned masks allocate embedding dimensions task. learning masks initialize using normal distribution mean variance. following relu results initial mask values induce random subspaces similarity measure. observe different random subspaces perform better setup subspaces start values. masks initialized disjoint analogous predeﬁned masks perform similar random masks able learn shared features. visually explore learned embeddings regarding consistency according respective similarity notions. stress semantic representations taking place within shared space produced network. representations disentangled dimension encodes feature speciﬁc notion similarity. allows simple masking operation look speciﬁc semantic subspace. figure shows embeddings subspaces fonts dataset project dimensions using t-sne learned features successfully disentangled dimensions selected ﬁrst mask describe character type selected second mask font style figures show embeddings four subspaces learned zapposk dataset. figure shows subspace encoding features closure mechanism shoes. figure shows subspace attending type shoes. embedding clearly separates different types shoes boots slippers highlighted areas reveal interesting details. example highlighted region upper right side shows nearby images type completely different according aspects. means selected feature dimensions successfully focus type aspect encode notions. figure shows subspace suggested gender shoes. subspace separates shoes female male buyers well shoes adult youth buyers. learned submanifold occupies rotated square axes deﬁned gender age. finally figure shows continuous embedding heel heights subtle visual feature. feature csns fact learn separated semantic subspaces embeddings using masking mechanism. visualize masks common model choices figure show traditional triplet loss dimension equally taken account triplet. further show pre-deﬁned masks used factorize embedding fully disjoint figure show four different model variants used experiments example three objects compared according contradictory notions similarity green red. standard triplet network treats triplets equally nc-many triplet network experts specialized green respectively masks pre-set disjoint embedding dimension encodes feature speciﬁc notion similarity learned masks learned select features relevant respective notion similarity. masks pre-deﬁned disjoint different notions similarity. ensures learned embedding fully disentangled dimension must encode features describe speciﬁc notion similarity. conditional similarity networks learned masks second variant learns convolutional ﬁlters embedding mask parameters together. allows model learn unique features subspaces well features shared across tasks. variant additional beneﬁt learned masks provide interesting insight different similarity notions related. train different convolutional networks datasets. font dataset variant architecture layers convolutions fully connected layers train scratch. zappos dataset ﬁne-tune layer deep residual network pre-trained imagenet remove downsampling module adjust smaller image size. train networks mini-batch size optimize using adam experiments embedding dimension weights embedding losses minibatch sample triplets uniformly condition equal proportions. train model epochs perform early stopping evaluate snapshot highest validation performance test set. figure visualization subspaces according suggested gender shoes height shoes’ heel. result shows csns learn categorical well continuous characteristics time. features. lastly show learned mask. interestingly masks sparse accordance embeddings presented previous section conﬁrming concepts low-dimensional. further although many additional dimensions available model learned share features across concepts. demonstrates csns learn required number dimensions relevance determination reducing need picking right embedding dimensionality. evaluate quality learned embeddings different model variants test well generalize unseen triplets. particular perform triplet prediction testset hold-out triplets zapposk dataset. ﬁrst train model ﬁxed triplets triplets sourced four different notions similarity. convergence evaluate triplet associated query testset whether distance smaller according concept/query since binary task random guessing would perform error rate error rates different models shown table standard triplet networks fail capture ﬁne-grained similarity reach error rate task speciﬁc triplet networks greatly improves that achieving error rate shows simply learning single space cannot capture multiple similarity notions. however comes cost figure visualization masks left standard triplet networks dimension equally taken account triplet. center conditional similarity network allows focus subset embedding answer triplet question. here mask focuses fourth. right learned masks evident model learns switch different dimensions question. further small subset shared across tasks. times model parameters. conditional similarity networks ﬁxed disjoint masks achieve error rate clearly outperforming single triplet network well specialist networks parameters available learning. means factorizing embedding space separate semantic subspaces csns successfully capture multiple similarity notions without requiring substantially parameters. moreover csns beneﬁt learning concepts jointly within model utilizing shared structure concepts keeping subspaces separated. csns learned masks achieve error rate improving performance even further. indicates beneﬁts allowing model determine relevant dimensions share features across concepts. table triplet prediction results evaluate many triplets test satisﬁed learned embeddings. triplets come four different similarity notions. proposed conditional similarity network clearly outperforms standard triplet networks treat triplet came similarity notion. moreover csns even outperform sets specialist triplet networks parameters available training network speciﬁcally trained towards similarity notion. csns learned masks provide best performance. further evaluate impact number unique triplets available training performance. compare models trained thousand triplets concept. figure shows triplet networks generally improve available triplets. further csns ﬁxed masks consistently outperform specialized triplet networks. lastly csns learned masks results shown table residual network trained imagenet leads good initial visual features general classiﬁcation tasks. starting pretrained model observe standard triplet learning approach decreases quality visual features csns retain information. triplet prediction experiment section standard triplet networks perform well naturally limited fact contradicting notions cannot satisﬁed single space. classiﬁcation result documents problem reaches even deeper. contradicting gradients stop embedding layer instead expose entire network inconsistent learning signals hurt underlying convolutional features. work propose conditional similarity networks learn nonlinear embeddings incorporate multiple aspect similarity within shared embedding. learned embeddings disentangled embedding dimension encodes semantic features speciﬁc aspect similarity. allows compare objects according various notions selecting appropriate subspace using element-wise mask. demonstrate csns clearly outperform single triplet networks even sets specialist triplet networks parameters available network trained towards similarity notion. further instead black-box predictor csns qualitatively highly interpretable evidenced exhibition semantic submanifolds learn. moreover provide feature-exploration mechanism learned masks surfaces structure private shared features different similarity aspects. lastly empirically naively training triplet network triplets generated different similarity notions limit ability correctly embed triplets also hurts underlying convolutional features thus generalization performance. proposed csns simple implement easy train end-to-end alternative resolve problems. would like thank gunnar r¨atsch baoguang insightful feedback. work supported part connected experiences laboratory google focused research award cloud credits research facebook equipment donation. figure triplet prediction performance respect number unique training triplets available. csns ﬁxed masks consistently outperform specialized triplet networks. csns learned masks generally require triplets since need learn embedding well masks. however enough triplets available provide best performance. evaluate different learning approaches affect visual features networks. compare standard triplet networks csns. initialized imagenet pre-trained residual network ﬁne-tuned using triplets respective losses described section evaluate features learned approaches subsequently performing brand classiﬁcation zappos dataset. particular keep convolutional ﬁlters ﬁxed replace last embedding layer networks hidden softmax classiﬁcation layer. select brands zappos dataset examples train standard multi-class classiﬁcation approach using brands classes. noteworthy triplets used ﬁnetuning contain brand information. table using off-task classiﬁcation evaluate standard triplet networks csns affect convolutional features imagenet-pretrained network based naively training standard triplet network triplets different similarity notions hurts underlying convolutional features. reed sohn zhang lee. learning disentangle factors variation manifold interaction. proceedings international conference machine learning pages", "year": 2016}