{"title": "Learning Typographic Style", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Typography is a ubiquitous art form that affects our understanding, perception, and trust in what we read. Thousands of different font-faces have been created with enormous variations in the characters. In this paper, we learn the style of a font by analyzing a small subset of only four letters. From these four letters, we learn two tasks. The first is a discrimination task: given the four letters and a new candidate letter, does the new letter belong to the same font? Second, given the four basis letters, can we generate all of the other letters with the same characteristics as those in the basis set? We use deep neural networks to address both tasks, quantitatively and qualitatively measure the results in a variety of novel manners, and present a thorough investigation of the weaknesses and strengths of the approach.", "text": "abstract. typography ubiquitous form aﬀects understanding perception trust read. thousands diﬀerent font-faces created enormous variations characters. paper learn style font analyzing small subset four letters. four letters learn tasks. ﬁrst discrimination task given four letters candidate letter letter belong font? second given four basis letters generate letters characteristics basis set? deep neural networks address tasks quantitatively qualitatively measure results variety novel manners present thorough investigation weaknesses strengths approach. history fonts typography vast originating back least ﬁfteenth century germany creation movable type press johannes gutenberg ﬁrst font blackletter. based handwriting style time used print ﬁrst books centuries later numerous studies consistently shown large impact fonts readability text also comprehensibility trustability written despite prevalence standard fonts used throughout academic literature innumerable creative stylized unique fonts available. many created individual designers hobbies particular applications logos movies print advertisements. small sample fonts used study shown figure seminal work tenenbaum freeman towards separating style content applied letter generation. motivation goals similar theirs hope learner exploit structure samples related content extract representations necessary modeling style. endgoal perform tasks synthesis analysis styles never encountered. contrast attempt explicitly model style content separately; rather training learning model reproduce style content style implicitly distinguished. also extend work four directions. first demonstrate small subset characters required eﬀectively learn discriminative generative models representing typographic style; instead alpha-numeric characters used previously. second letters learn individual-letter combined-letter models capable generating remaining letters. third broaden results thousands unseen fonts encompassing expansive styles seen previously. finally present novel methods quantitatively analyzing generated results applicable image-creation task. fonts particularly well suited examination style provide diversity along many axes shape size stroke weight slant texture serif details within constrained environment stylistic elements readily distinguished content. additionally unlike many image generation tasks task enormous beneﬁt readily available groundtruth data thereby allowing quantitative measurement performance. recently growing attention devoted style terms fonts perceptual shape similarity architecture rigid objects computer graphics cursive text photographs artwork music primary goal paper succinctly stated follows given small letters particular font generate remaining letters style? address question need ensure enough information small basis ascertain style. subject next section. addressing question whether basis-letters contain enough information extract style immediately work towards identifying sources potential diﬃculties overarching goal generating characters i.e. generative process enough information extract basis letters successfully complete task? further networks created vital component validating ﬁnal generated results discriminative task follows given four basis letters e.g. basq font-a another letter train classiﬁer correctly identify whether generated font-a’s style? figure next describe data pre-processed neural networks used address task. fig. positive negative samples classiﬁcation task. left group ﬁfth letter member font. right ﬁfth letter not. note cases right easy. however challenging requiring slant subtle edge weights analyzed respectively. fonts used study true-type-font format allows scaling. stylistic variations present data ratio widths heights diﬀerent font faces vary dramatically. size characters generated point setting; ensures font style speciﬁes large little stylistic decision preserved training example largest letter within basq comprised basis throughout study. chosen contained diverse edges angles curves rearranged/analyzed reveal hints composing many remaining letters. training approximately examples created randomly chosen unique fonts. training composed positive examples negative examples generating examples character variation disjoint testing font families present training created exactly manner. training testing negative examples chosen randomly pairing diﬀerent font-families. building successes deep neural networks image recognition tasks recent summary imagenet) explore variety neural network architectures task. numerous experiments conducted discover eﬀective network architectures use. architectures tried performing seven selected. though full description experiments beyond scope paper general principles found provided help guide future studies. individual ’towers’ characters review column/tower architectures). single image easier capture relative sizes characters. multiple images individualized character transformations created potentially cleaner derivatives. numerous experiments results consistently favored using individual towers terms training time ﬁnal accuracy. figure network depth contrast trend increasing network depth deeper nets lead improved performance. unlike general object detection tasks deep neural networks able exploit property images thoughts compositional hierarchies deep hierarchies present task. study sets convolution layers used fully connected layers prior ﬁnal output additional depth increase performance. create negative examples fonts font-family i.e. times-romanbold times-roman never used negative example. hierarchy fonts apriori known font families estimated simple lexicographic analysis font names. importantly noted preclude fonts appear visually nearly indistinguishable used negative examples. fig. left middle tower-based network architectures. left layers within towers fully connected. middle layers within towers convolutions. right fully connected treated character inputs single image ﬁgure also shows three diﬀerent fonts used training networks. relu logistic? variety activation functions attempted including exclusively logistic activations throughout network activations except ﬁnal logistic-output unit rest activations throughnetwork worked best relu. though performance diﬀerence consistent across trials relu units trained faster. convolutions fully connected layers convolution layers frequently employed purposes achieving translation invariance free parameter reduction especially used conjunction pooling layers. task translation invariance crucial general object detection tasks object interest centered. further task worked well across number network sizes free-parameter ranges. networks employed convolutions well used fully connected layers exclusively performed equally well. mentioned previous section architectures experimented task. gradient descent momentum used train networks domain-speciﬁc prenormalization weights necessary. architectures seven chosen based tower architecture performance discrimination task measured independent test -basis letters drawn fonts used training. results consistent across wide variety free parameters; seven networks classiﬁed networks. leftmost column examples character correctly recognized belonging font shown. second column correctly recognized negative examples given. note letter ground-truth used input network; provided show actual letter font. second column note similarity correctly discerned letters ground-truth. particular column distinguishing marks proposed real ’h’; recognized member font based solely weight strokes. fig. font not? binary classiﬁcation results. columns show examples character taken diﬀerent font basis corresponding actual letter basis also given. sixth character ground-truth used training/testing; shown comparison. third column shows false-negatives. several mistakes readily explained rows non-alphabetic fonts rows explicitly designed diverse characters e.g. creating ’ransom note’ like artistic eﬀects. also shown finally last column false-positives shown diﬀerent fonts mistakenly recognized same. three types errors seen. fonts extremely thin strokes failure rate increases. factors under-representation training less information pixel maps make correct discriminations. second before non-alphabetic fonts appear. third source mistakes many fonts characters appear similar match basis font’s style worth emphasizing font design process algorithmic one; artist/designer create fonts much little variation desired. multiple acceptable variations character. despite similar performance networks enough variation outputs exists ensemble examples networks correct. network mistaken mistaken mistaken. therefore using simple majority voting scheme seven networks employed ensemble yields accuracy. ensemble used throughout remainder paper. previous section determined suﬃcient information -basis letters correctly determine whether ﬁfth letter member font. section attempt construct networks generate characters. experiments broadly divided approaches single multiple-letter generation. ﬁrst approach network trained generate single letter. multiple-letter generation networks letters generated simultaneously network. though single letter networks conceptually simpler training network generate multiple letters simultaneously allow hidden units share useful representations features i.e. serif style line width angles etc. form transfer learning strong basis multi-task learning previous section experiments numerous network architectures conducted. architectures varied number layers units connectivity patterns. ﬁnal architecture used shown figure discrimination task described previous section single output node. allowed large penultimate hidden layers since number connections ﬁnal output remained small. contrast image generation tasks number output nodes number hidden unit penultimate layer connects small patch output layer. various patch sizes tried; patches sizes ﬁnally employed. unlike convolution de-convolution networks connection weights shared. sharing necessary since translation invariance needed generated image; letter generated center output. similar architectures used superresolution image deconvolution often weight sharing letter chosen ﬁrst test case since many fonts constituent building blocks present basis letters previous experiments network trained unique fonts loss pixel-space using sgd+momentum. numerous experiments without batch normalization conducted consistent diﬀerence ﬁnal error observed. results fonts test shown figure fig. results shown generation. results judged external human evaluator. actual font characters shown right. deemed acceptable replacements original. unfortunately simply measuring pixel-wise diﬀerence actual target letter correlate well subjective evaluations performance. real-world image generation tasks aesthetic judgment vital. asked human rater ascertain quality result along axis shape generally correct serif appropriately captured acceptable replacement actual letter? last metric hardest measure perhaps relevant. outcome overall positive caveats noted figure section explore task generating upper-case letters simultaneously. unlike single-letter generation process described previous section hidden units network share extracted features. particularly useful character generation process many letters common components figure fig. single multi-letter generation. left networks show individual letter creation right network generates letters simultaneously thereby allowing hidden units share extracted information. tower/column architectures employed transform basis letters generative network also auto-encodes basis letters best single-letter-generation networks best multi-letter-generation networks error repeatedly reduced using multiletter generation networks. qualitatively however characters generated networks appeared similar. nonetheless small error improvement coupled ease deployment multi-letter-generation network used going forward. large results shown figure subjectively evaluating results would error prone yield inconsistent results given diﬃculty evaluating individual consistency large subjective evaluation conducted independent user experience researcher volunteer aﬃliated project. given paper copy input letters generated letters actual letter. asked evaluate along dimensions listed above. additionally control also given examples included real ’r’s order minimize bias. paid experiment. fig. output multi-letter-generation networks postprocessing. examples shown. good results. bottom results letters smudged. non-alphabet/picture fonts shown. previous section results font generation network measured network’s error subsequently external human evaluator. here present alternate methods based using discriminative networks developed section discriminative networks used determine whether input character font basis characters. recall employing voting-ensemble networks accuracy attained. here test generative network font results passed discriminative network ensemble along original basq-basis letters consequently output used determine whether generated letter font basis letters. novel variants method using pairs generator/discriminator networks independently proposed based architectures generative-adversarial models entirely separate fonts. thus limited fonts basis-set. next examination reverse question asked above. generate letters before question generated letters used basis original letters recognized font? table column synthetic basis original test. generation portion remains same test revised previous experiments compared generated characters original font. gives measure closely generated characters resemble original font. ﬁnal experiment consistent generated letters other. given basis letters generated font generated letters font classiﬁed same? table column synthetic basis synthetic test. looking table column original basis synthetic test seen generated fonts appear similar original fonts based. interesting question arises then second test synthetic basis original test lower recognition rate? answer lies fact font designer introduce non-systematic variations visual interest adhere strict stylistic cues present letters. obvious cases ’ransom note fonts’ character intentionally representative characters. themed fonts introduce objects trees animals vehicles design reﬂect artist’s individual creativity. example fonts replace empty spaces letter mini-airplanes letter etc. generated fonts capture shapes synthesize consistent characters reuse many elements. likely original font’s glyphs appear outside cohesive generated networks. third column synthetic basis synthetic test shows characters generated extremely consistent other. normally would considered good attribute; however viewed terms baseline raises important question. generated fonts homogeneous original fonts? reason mentioned above potentially troubling reason generated characters much alike? characters regressed mean? ﬁnal test examine possibility explicitly using network generated fonts. first basis letters randomly selected generated font. second randomly select another generated font character candidate test character. randomly paired samples created. unlike previous tests accuracy measured many matches found accuracy measured many nonmatches detected. explicitly tests whether generated fonts look similar other. running test discriminative network ensemble yields diﬀerent-font detection rate baseline repeat experiment pairs generated original fonts. yields correct diﬀerent-font detection rate close results indicate generated fonts regressed mean terms recognizable serifs style remain distinguishable original fonts. diﬀerence performance column table likely variability introduced smaller artistic variances inserted designers described paragraph above. beyond straightforward explorations varying number selection basis letters also generating lower-case letters many conceptually interesting avenues future work. first alternative approach using generator networks discriminative-networks propagate derivatives back inputs modify input pixels maximize similarity hidden states speciﬁed values. recently proposed create natural images well dream like images deep dreams second made concerted eﬀort simplest networks possible. extensive empirical search space networks learning algorithms conducted straightforward approach addressing task. recent preprints describe concurrent explorations similar related problems much complex architectures yield comparably promising results. extending work architectures easily done; example evaluation mechanisms used study akin generative adversarial nets synthetic-vs.-real distinguisher network font generator trained outperform other. study provides strong easily implemented baseline architectures learning approaches compared. third trained networks used novel manners beyond synthesizing characters existing fonts. possible take attributes multiple fonts combine them? example basis composed characters font-a characters font-b resulting characters combination two? preliminary evidence suggests possible; though perhaps examples font necessary artistically innovative combinations produced. fig. novel combinations fonts. results ﬁrst shows input letters characters generated onta second ontb. characters font used input resulting characters shown. example note weight ﬁrst font combined size second font. bottom example note hollow look ﬁrst font combined weight shapes second font. fourth taken image based approach font generation. alternate speculative direction non-image based approach recurrent networks long-short-term-memory lstms used generate characters directly truetype language? task network’s inputs would include basis letters. similar programmatic learning lstms compose simple programs sequences music recently attempted possible generate results directly encodings produce another orthogonal result complement study. feasibility approach open future research. paper presented learning method analyze typographic style based small letters employ learned models distinguish fonts produce characters style. results quite promising fully capturing artistic visual intent beginning. many overall shapes weights angles serifs successfully modeled.", "year": 2016}