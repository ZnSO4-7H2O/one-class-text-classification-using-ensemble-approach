{"title": "Fairness-aware machine learning: a perspective", "tag": ["cs.AI", "cs.CY", "cs.LG", "stat.ML"], "abstract": "Algorithms learned from data are increasingly used for deciding many aspects in our life: from movies we see, to prices we pay, or medicine we get. Yet there is growing evidence that decision making by inappropriately trained algorithms may unintentionally discriminate people. For example, in automated matching of candidate CVs with job descriptions, algorithms may capture and propagate ethnicity related biases. Several repairs for selected algorithms have already been proposed, but the underlying mechanisms how such discrimination happens from the computational perspective are not yet scientifically understood. We need to develop theoretical understanding how algorithms may become discriminatory, and establish fundamental machine learning principles for prevention. We need to analyze machine learning process as a whole to systematically explain the roots of discrimination occurrence, which will allow to devise global machine learning optimization criteria for guaranteed prevention, as opposed to pushing empirical constraints into existing algorithms case-by-case. As a result, the state-of-the-art will advance from heuristic repairing, to proactive and theoretically supported prevention. This is needed not only because law requires to protect vulnerable people. Penetration of big data initiatives will only increase, and computer science needs to provide solid explanations and accountability to the public, before public concerns lead to unnecessarily restrictive regulations against machine learning.", "text": "movies prices medicine get. growing evidence decision making inappropriately trained algorithms unintentionally discriminate people. example automated matching candidate descriptions algorithms capture propagate ethnicity related biases. several repairs selected algorithms already proposed underlying mechanisms discrimination happens computational perspective scientiﬁcally understood. need develop theoretical understanding algorithms become discriminatory establish fundamental machine learning principles prevention. need analyze machine learning process whole systematically explain roots discrimination occurrence allow devise global machine learning optimization criteria guaranteed prevention opposed pushing empirical constraints existing algorithms case-by-case. result state-ofthe-art advance heuristic repairing proactive theoretically supported prevention. needed requires protect vulnerable people. penetration data initiatives increase computer science needs provide solid explanations accountability public public concerns lead unnecessarily restrictive regulations machine learning. position paper largely based starting grant proposal wrote summer slightly updated summer manuscript cover related work came submitted proposal. sharing compressed version research content including personal details descriptions collaborators risk management budget such. proposal interview round funded. papers came last year ﬁeld advancing rapidly think perspectives outlined still date worth sharing. recent years media social research pointed plenty anecdotal evidence decision making algorithms unintentionally discriminate people news articles raising concerns increasingly appear major global press including times wall street journal guardian. weeks editorial nature focused accountability data algorithms. attention public media gathering evidence emerging research discipline discrimination-aware machine learning data mining focuses providing treatment. existing treatment addresses selected algorithms clear tackle systematically. discrimination refers adversary treatment people based belonging group rather individual merits. example automated matching candidate descriptions propagate ethnicity related biases. data encodes human biases blindly applied machine learning picks propagates possibly even exaggerates biases importantly discrimination ∗indre.zliobaitehelsinki.ﬁ http//www.nytimes.com////upshot/when-algorithms-discriminate.html http//www.wsj.com/articles/computers-are-showing-their-biases-and-tech-firms-are-concerned- http//www.theguardian.com/commentisfree//apr//algorithms-are-like-invisible-judges-that-decide-our-fates algorithms occur even training data objective well sampled human decision makers occasionally make biased decisions inappropriately trained models would discriminate continuously systematically long term reaching eﬀects large population. discrimination many grounds many areas life forbidden national international legislation. instance finland came force january substantially expanding scope protection. applies nearly public private activities protecting discrimination based ethnicity nationality language religion belief opinion health disability sexual orientation personal characteristics. currently preparing nondiscrimination directive expanding scope protection. scope protection expanding worldwide currently clear address potential discrimination algorithms. example president oﬃce urges expand technical expertise preventing disparate impact data analytics weeks editorial nature highlights research need ways audit bias without revealing algorithms develop computational techniques better address correct discrimination training data sets algorithms scope impact machine learning technologies decisions informed data society continues grow essential develop scientiﬁc expertise controlling potential discrimination algorithms. requires protect vulnerable people. computer scientists accountable algorithm performance need able provide scientiﬁc explanations guarantees happening algorithms used decision support public concerns lack trust leads unnecessarily restrictive regulatory actions machine learning. computational mechanisms discrimination algorithms happens happen scientiﬁcally well understood. fundamental insights needed developing systematic theoretically supported prevention. number approaches already proposed suggesting repair algorithms preprocessing training datasets adding regularizer model postprocessing trained models model outputs however generic issues current approaches. firstly consensus assess fairness algorithms dozens measures sometimes contradictory exist. typically solutions come constraints optimize measures performance. without unifying theory hard argue extent current approaches work generalize. secondly solution typically tailored speciﬁc combination machine learning setting discrimination situation hardly generalize algorithms types variables grounds discrimination. proposing tailored repairs combination algorithm task setting discrimination occurrence works short merely treating symptoms instead curing disease. long need develop fundamental scientiﬁc understanding ensuring transparency accountability using machine learning society. within goal guaranteeing fairness algorithms issues. research objective develop theoretical understanding algorithms become discriminatory prevent computational means. rather trying case-by-case approach characterize computational process whole relation potential unfairness would make possible uncover roots problem systematically prevent algorithms becoming discriminatory. hypothesis based position paper follow investigation data-driven algorithms become discriminatory biased unrepresentative training data used combination global optimization criteria focus maximizing overall performance taking account remaining inaccuracies distribute. expectation addressing issues ensure fairness algorithms also make overall performance algorithms better. currently enforcing fairness considered burden accurate performance. believe addressing core problem lead win-win situation since guaranteeing fairness would seen duty provide clear beneﬁts everybody involved. research intersection computer science social sciences main focus machine learning. interaction social sciences helps deﬁne fair resource allocation diagnosing; computer science responsible analysis machine learning processes computing methodologies performance guarantees; interaction helps prescribe non-discrimination requirements computationally guarantee prevention. figure depicts setting solid lines show cross-disciplinary interactions dashed lines show would become possible. aims machine learning research provide computational means account potential discrimination. intend judge behavior fair reveal concrete cases discrimination. machine learning research perspective essential grounds areas potential discrimination expertise collaborators social science essential establishing general principles diagnosing preventing. discrimination-aware machine learning data mining emerging discipline studying potential discrimination algorithms transparency accountability using algorithms decision support. discipline builds upon machine learning data mining algorithm design statistical science discrimination testing well sociology deﬁning fairness. goal develop algorithmic techniques would obey fairness regulations prescribed law. focus main challenges formulate fairness constraints mathematically make models obey them. interdisciplinary survey overviews techniques used legal review presents legal background. attention public media gathering evidence focus emerging research community providing treatment. mechanisms discrimination algorithms happens circumstances happens happen well understood. existing research follows directions discrimination discovery discrimination prevention. discovery aims ﬁnding discriminatory patterns data using data mining machine learning methods builds upon extensive research statistics discrimination evidence addressing challenges increasing volumes complexity data ways possible unfairness. statistics focusing hypotheses testing decision data provide essential solutions correctly compare groups people. prevention orthogonal issue focusing machine learning processes becoming increasingly urgent omnipresent data initiatives. discrimination prevention develops methods sanitizing algorithms adjusting machine learning process outputs would obey selected fairness constraints. several attempts algorithms made preprocessing training however generic issues current approaches. firstly consensus measure fairness algorithms therefore hard argue extent proposed ﬁxes work generalize. secondly solution typically tailored speciﬁc setting situation hard generalize algorithms types variables grounds discrimination. proposing tailored repairs combination like coping symptoms instead curing disease. propose instead repairing algorithm algorithm variants settings characterize computational process whole relation potential unfairness. achieved analyzing interactions data characteristics learning task settings relation protected variables learning techniques assumptions. identifying assumption violations critical theoretically quantifying eﬀects violations taking account special status protected variables formalized collaboration social science promise technical contributions computer science solving cross-disciplinary problem main goal also better understanding implications imperfect data machine learning general. main technical research challenge derive expectations guarantees performance terms thoroughly deﬁned fairness measures. approach would lead theory potential discrimination occurrence machine learning backed expectations unfairness accompanied principles prevention. become possible anticipate unfairness prevent systematically even initial models built opposed repairing models discrimination discovered. research objective develop theoretical understanding algorithms become discriminatory establish fundamental machine learning principles prevention. machine learning research aiming pointing particular discrimination cases judging behavior right wrong. goal develop technological knowledge. reached solving following research tasks solving enables systematic diagnosing develops theory understanding phenomenon develops mechanisms making models fair fairness constraints satisﬁed models become better. already obtained preliminary results concrete action plan. uncertainty roadmap proceed clear. also makes good starting point student. investigate hypotheses outlined position paper potentially generate hypotheses. plan minimum work existing hypotheses provide theoretical evidence those already make major contribution. optimization criteria depend theoretical understanding gained anticipate beyond current understanding enforcing fairness cost accuracy. redesigning machine learning optimization criteria hope demonstrate enforcing fairness also leads accurate models. even succeed maximum devising global optimization criteria guarantee fairness minimize costs accuracy notable contribution addition contributions main research output methodological framework translating types task settings base models modeling assumptions data characteristics distinct schemes discrimination occurrence backed theoretical expectations discrimination accompanied principles prevention. given foundations computer scientists develop algorithmic techniques prevention experts investigate reﬂect technical ﬁndings non-discrimination laws sociologists develop analysis tools general public guarantees non-discrimination. working hypothesis algorithms become discriminatory speciﬁc violations assumptions upon learning methods usually based combination optimization criteria used learning. speciﬁcally discrimination occur training data incorrect incomplete badly sampled discrimination algorithms occur even unfairness training data. typical machine learning objective maximize global performance controlling remaining inaccuracies distribute across groups individuals. hypothesis prevention rather forcing non-discrimination constraints algorithm algorithm generic robust optimization criteria maybe sacriﬁcing overall accuracy minimizing large one-directional errors within subgroups. objective scientiﬁcally justify performance criteria fairness decision making algorithms. literally dozens discrimination measures used diﬀering input variables statistical tests comparison functions measuring share people discriminated magnitude discrimination counting decisions data inferring models inspecting parameters taking taking account factors explaining diﬀerence people. measures direct discrimination indirect discrimination sometimes mixed together. ﬁeld emerging researchers exploratory phase come measures deﬁnitions. lack scientiﬁc arguments using other clear researchers after. recent analysis suggests instead searching discrimination decision data trying remove need consider makes algorithms discriminatory. example consider automated matching service algorithm used decide gets invited interview. algorithm ranks using text input decision makers decide many top-ranked candidates invite. rank list nationality candidates appear nationality candidates algorithm maximally biased favor however suppose enough capacity candidates invited interview decision data shows discrimination. algorithm still biased maximum discriminate next application round. researchers using measures built upon indirect discrimination statistics insights suggest conceptually diﬀerent approach look ranking mechanism algorithm. start deﬁning mathematical model fairness consulting social scientists experts net-neutrality describe discrimination mechanisms equations larger scope). analytically experimentally evaluate existing measures select principle capture aspects fairness model including accounting explanatory variables recent investigation suggests curve alike measures could suitable. similar measures episodically used alternative measuring discrimination regression context suﬀers computational complexity working large datasets workarounds e.g. rank approximations. perhaps building upon recent studies curves cost space help establish ﬁnal arguments. solving task enable characterize performance algorithms terms discrimination. able measure discrimination scientiﬁc conﬁdence measuring after proceed core research analyze circumstances algorithms inferred data become discriminatory extent. several hypotheses preliminary evidence outlined position paper namely discrimination happens training data incorrect incomplete feature space instance space also consider evolving data analyze in-depth scenarios synthetic real benchmark datasets full range task settings classiﬁcation regression binary numeric categorical protected ground multiple protected grounds categorical numerical explanatory variables. synthetic data control magnitude biases degree data incompleteness tune hypotheses seek theoretical explanations similar spirit similarly example missing value analysis streaming data explanations called simpson’s paradox omitted variable bias based causality theory since currently thorough explanations lacking explanatory theories novel make fundamental contributions. also revisit open question keeping keeping protected characteristic model. clearly demonstrated removing protected characteristic solve discrimination problem lawyers strictly removing anyway pilot investigation suggests model training process stay able quantify portion observed inequality justiﬁable eliminated. final models decision making course seems initial machine learning study systematically provide scientiﬁc arguments provide direct implications policy making. current tendency forbid collecting sensitive data likely unless allowed algorithm developers would able guarantee non-discrimination. recent pilot study linear regression demonstrates happen. present example theoretical explanation appendix. intended exemplify principle kind research done. following analysis methodology auditing algorithms developed rq.. include diagnostics framework procedural check-list model development rq.-rq.. solving equip theoretical understanding discrimination algorithms happens form fundamentals discrimination-aware machine learning. make possible diagnose existing algorithms judge intended machine learning procedures updating existing developing machine learning techniques would inherently prevent discrimination also guarantee discrimination prevention. building tackle come novel optimization criteria machine learning used decision support. standard machine learning optimizes overall performance accuracy. discrimination-aware machine learning variants tested non-discrimination constraints models regularized using constraints works particular scenario particular test particular constraints realistic consider possible constraints possible protected grounds data vary time well. anticipating solution tricky since depend ﬁndings remotely related attempt guarantee non-discrimination chosen measure success. scientiﬁc intuition optimization criteria robust minimize large deviations errors across subgroups instance space approach would cluster inputs optimize accuracy cluster instead observation time controlling direction deviations. also expect something similar developed regression missing data could work parameter controls tradeoﬀ ideal accuracy robustness. case cannot come criterion based solely accuracy non-discrimination constraints including protected variable. commonly accepted accuracy decrease many covenants. testing data discriminatory observed testing accuracy ﬂawed. ultimate goal rethinking optimization criteria demonstrate enforcing non-discrimination also leads better models. successful change researchers think machine learning process provide sound scientiﬁc arguments beyond requires adopt non-discriminatory algorithms practice discrimination-aware machine learning data mining emerging discipline researchers exploring possibilities solutions keep revealing challenges research scratched surface far. situation outlined research tasks anticipating systematic approach problem unifying theory good potential scientiﬁc breakthroughs. highest potential scientiﬁc breakthroughs perhaps make rethink overall performance optimization criteria building machine learning intended used decision support.", "year": 2017}