{"title": "HDLTex: Hierarchical Deep Learning for Text Classification", "tag": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "abstract": "The continually increasing number of documents produced each year necessitates ever improving information processing methods for searching, retrieving, and organizing text. Central to these information processing methods is document classification, which has become an important application for supervised learning. Recently the performance of these traditional classifiers has degraded as the number of documents has increased. This is because along with this growth in the number of documents has come an increase in the number of categories. This paper approaches this problem differently from current document classification methods that view the problem as multi-class classification. Instead we perform hierarchical classification using an approach we call Hierarchical Deep Learning for Text classification (HDLTex). HDLTex employs stacks of deep learning architectures to provide specialized understanding at each level of the document hierarchy.", "text": "abstract—increasingly large document collections require improved information processing methods searching retrieving organizing text. central information processing methods document classiﬁcation become important application supervised learning. recently performance traditional supervised classiﬁers degraded number documents increased. along growth number documents come increase number categories. paper approaches problem differently current document classiﬁcation methods view problem multi-class classiﬁcation. instead perform hierarchical classiﬁcation using approach call hierarchical deep learning text classiﬁcation hdltex employs provide specialized understanding level document hierarchy. although many existing approaches document classiﬁcation quickly identify overall area document rapidly organize documents correct subﬁelds areas specialization. further combination top-level ﬁelds sub-ﬁelds presents current document classiﬁcation approaches combinatorially increasing number class labels cannot handle. paper presents approach hierarchical document classiﬁcation call hierarchical deep learning text classiﬁcation hdltex combines deep learning architectures allow overall specialized learning level document hierarchy. paper reports experiments hdltex exhibits improved accuracy traditional document classiﬁcation methods. year scientiﬁc researchers produce massive number documents. active scholarly peerreviewed english-language journals published million articles evidence rate growth journals publications accelerating volume documents made automatic organization classiﬁcation essential element advancement basic applied research. much recent work automatic document classiﬁcation involved supervised learning techniques classiﬁcation trees na¨ıve bayes support vector machines neural nets ensemble methods. classiﬁcation trees na¨ıve bayes approaches provide good interpretability tend less accurate methods. however automatic classiﬁcation become increasingly challenging last several years growth corpus sizes number ﬁelds sub-ﬁelds. areas research little known years become areas high growth interest. growth sub-ﬁelds occurred across range disciplines including biology material science health sciences growth sub-ﬁelds means important label document specialized area also organize document classiﬁcation necessary organize documents retrieval analysis curation annotation. researchers studied developed variety methods document classiﬁcation. work information retrieval community focused search engine fundamentals indexing dictionaries considered core technologies ﬁeld considerable work built foundational methods provide improvements feedback query reformulation recent work employed methods data mining machine learning. among accurate techniques support vector machine svms kernel functions separating hyperplanes high-dimensional spaces. kernel methods used information retrieval include string kernels spectrum kernel mismatch kernel widely used sequence data. related methods difﬁcult interpret. reason many information retrieval systems decision trees na¨ıve bayes methods. methods easier understand such support query vapnik chervonenkis introduced boser introduced nonlinear version address complex classiﬁcation problems idea nonlinear generating kernel shown equation followed equations multi-class text classiﬁcation using string kernels within svms successful many research projects original solves binary classiﬁcation problem; however since document classiﬁcation often involves several classes binary requires extension. general multi-class solves following optimization indicates number classes slack variables learning parameter. solve msvm construct decision function classes approach msvm binary compare pairwise classiﬁcation labels number labels classes. another technique msvm one-versus-all classes labels versus labels. stacking support vector machines stacking svms another baseline method comparison hdltex. stacking provides ensemble individual classiﬁers generally produces accurate results single-svm models na¨ıve bayes simple supervised learning technique often used information retrieval speed interpretability suppose number documents document label number labels. na¨ıve bayes calculates paper uses newer methods machine learning document classiﬁcation taken deep learning. deep learning efﬁcient version neural networks perform unsupervised supervised semi-supervised learning deep learning extensively used image processing many recent studies applied deep learning domains text data mining. basic architecture neural network fully connected network nonlinear processing nodes organized layers. ﬁrst layer input layer ﬁnal layer output layer layers hidden. paper refer fully connected networks deep neural networks convolutional neural networks modeled architecture visual cortex neurons fully connected spatially distinct cnns provide excellent results generalizing classiﬁcation objects images recent work used cnns text mining research closely related work paper zhang used cnns text classiﬁcation character-level features provided fully connected dnn. regardless application cnns require large training sets. another fundamental deep learning architecture used paper recurrent neural network rnns connect output layer back input. architecture particularly important learning time-dependent structures include words characters text deep learning hierarchical classiﬁcation paper although speciﬁc architectures comparative analyses application document classiﬁcation new. salakhutdinov used deep learning hierarchically categorize images. level images labeled animals vehicles. next level classiﬁes kind animal vehicle. paper describes deep learning approaches create hierarchical document classiﬁcation approach. deep learning methods promise providing greater accuracy related methods. deep learning methods also provide ﬂexible architectures used produce hierarchical classiﬁcations. hierarchical classiﬁcation methods produce highly accurate also enables greater understanding resulting classiﬁcation showing document sits within ﬁeld area study. paper compares ﬁfteen methods performing docmethods baselines ument classiﬁcation. since used traditional non-hierarchical document classiﬁcation. baseline methods three widely used document classiﬁcation term-weighted support vector machines multi-word support vector machines na¨ıve bayes classiﬁcation three newer deep learning methods form basis implementation approach hierarchical document fig. hdltex hierarchical deep learning text classiﬁcation. deep neural network approach text classiﬁcation. left ﬁgure depicts parent-level model right ﬁgure depicts child-level models deﬁned input documents parent level. documents enter hierarchical models features extracted text. employed different feature extraction approaches deep learning architectures built. used text vector-space models using dimensions described glove vector-space model mathematical mapping word space deﬁned used count-based term frequency–inverse document frequency feature extraction. approach uses counts n-grams sequences words example text paper introduced technique composed following ngrams methods used paper extend concepts deep learning neural networks hierarchical document classiﬁcation problem. deep learning neural networks provide efﬁcient computational models using combinations nonlinear processing elements organized layers. organization simple elements allows total network generalize research described here used several different deep learning techniques combinations techniques create hierarchical document classiﬁers. following subsections provide overview three deep learning architectures used deep neural networks recurrent neural networks convolutional neural networks architecture layer receives input previous layer outputs next layer. layers fully connected. input layer consists text features output layer node classiﬁcation label node binary classiﬁcation. architecture baseline dnn. additional details architecture found fig. hdltex hierarchical deep learning text classiﬁcation. structure recurrent neural networks text classiﬁcation. left ﬁgure parent level text leaning model. right ﬁgure depicts child-level learning models deﬁned input documents parent levels. paper extends baseline architecture allow hierarchical classiﬁcation. figure shows architecture. ﬁrst level classiﬁcation baseline dnn. second level classiﬁcation hierarchy consists trained domain output ﬁrst hierarchical level. second level connected output ﬁrst level. example output ﬁrst model labeled computer science next hierarchical level trained computer science documents. ﬁrst hierarchical level trained documents next level document hierarchy trained documents speciﬁed domain. second deep learning neural network architecture rnn. output layer nodes reenter input layer. approach advantages text processing general formulation given equation state time refers input step equation wrec recurrent matrix weight input weights bias element-wise function. modiﬁed basic architecture hierarchical classiﬁcation. figure shows extended architecture. several problems arise rnns error gradient descent algorithm back-propagated network deal problems long short-term memory special type preserves long-term dependencies effective compared basic rnn. figure shows basic cell lstm model. although lstm chain-like structure similar lstm uses multiple gates regulate amount information allowed node state. step-by-step explanation lstm cell gates provided below description bias vector weight matrix input memory cell time indices refer input cell memory forget output gates respectively. figure shows structure gates graphical representation. biased later words inﬂuential earlier ones. overcome bias convolutional neural network models include max-pooling layer determine discriminative phrases text gated recurrent unit gating mechanism rnns introduced simpliﬁed variant lstm architecture differences follows grus contain gates possess internal memory second non-linearity applied ﬁnal deep learning approach developed hierarchical document classiﬁcation convolutional neural network although originally built image processing discussed section cnns also effectively used text classiﬁcation basic convolutional layer connects small subset inputs usually size similarly next convolutional layer connects subset preceding layer. convolution layers called feature maps stacked provide multiple ﬁlters input. reduce computational complexity cnns pooling reduce size output stack layers next network. different pooling techniques used reduce outputs preserving important features common pooling method max-pooling maximum element selected pooling window. order feed pooled output stacked featured maps next layer maps ﬂattened column. ﬁnal layers typically fully connected. general back-propagation step weights adjusted also feature detector ﬁlters. potential problem cnns used text number channels size feature space. might large text images less problem primary contribution research hierarchical classiﬁcation documents. traditional multi-class classiﬁcation technique work well limited number classes performance drops increasing number classes present hierarchically organized documents. hierarchical deep learning model solve problem creating architectures specialize deep learning approaches level document hierarchy structure hierarchical deep learning text architecture deep learning model follows hidden layers cells hidden layer. lstm used implementation cells hidden layers. filter sizes max-pool layer sizes pooling contains hidden layers. contain speciﬁc topics belonging respectively. train test baseline methods described section hierarchical document classiﬁcation methods described section collected data meta-data published papers available science automate collection used selenium choromedriver chrome browser. extract data site used beautiful soup speciﬁcally extracted abstract domain keywords published papers. text abstract input classiﬁcation domain name provides label level hierarchy. keywords provide descriptors next level classiﬁcation hierarchy. table shows statistics collection. example medical sciences top-level domain classiﬁcations sub-classiﬁcations within domain. also articles documents within domain health sciences data set. divided data three parts shown table data full data documents data sets subsets full data number training testing documents shown well number labels classes levels. dataset seven level- classes sub-classes. data three higher-level classes four sub-classes last high-level class three subclasses. removed special characters three data sets training testing. equations learning parameter learning rate objective cost function. history updates deﬁned update parameters uses momentum term rescaled gradient shown equation approach optimization perform bias correction problem sparse gradient. equations ﬁrst second moments respectively. estimated approach handle non-stationarity objective function rmsprop adam also overcome sparse gradient issue drawback rmsprop document collection labels shown table target value levels computer science electrical engineering psychology mechanical engineering civil engineering medical science biochemistry} children levels labels following results obtained using combination central processing units graphical processing units processing done xeon cores memory cards vidia quadro vidia esla implemented approaches python using compute uniﬁed device architecture parallel computing platform table shows results experiments. baseline tests compare three conventional document classiﬁcation approaches stacking three deep learning approaches tests outperforms others three data sets. performs secondbest three data sets. term weighting third ﬁrst sets multi-word approach third place third data set. third data smallest three fewest labels differences among three best performers large. results show overall performance improvement general document classiﬁcation obtainable deep learning approaches compared traditional methods. overall na¨ıve bayes much worse methods throughtests. tests classifying documents within hierarchy hdltex approaches stacked deep learning architectures clearly provide superior performance. data best accuracy obtained combination ﬁrst level classiﬁcation second level. gives accuracies ﬁrst level second level overall. signiﬁcantly better others except combination dnn. data best scores achieved level time level closest scores obtained levels respectively. document classiﬁcation important problem address given growing size scientiﬁc literature document sets. documents organized hierarchically multi-class approaches difﬁcult apply using traditional supervised learning methods. paper introduces approach hierarchical document classiﬁcation hdltex combines multiple deep learning approaches produce hierarchical classiﬁcations. testing data documents obtained science shows combinations higher level lower level produced accuracies consistently higher obtainable conventional approaches using na¨ıve bayes svm. results show deep learning methods provide improvements document classiﬁcation provide ﬂexibility classify documents within hierarchy. hence provide extensions current methods document classiﬁcation consider multi-class problem. methods described improved multiple ways. additional training testing hierarchically structured document data sets continue identify architectures work best problems. also possible extend hierarchy levels capture complexity hierarchical classiﬁcation. example keywords treated ordered hierarchy continues multiple levels. hdltex also applied unlabeled documents found news media outlets. french brown n.-h. classiﬁcation approach boolean query reformulation jasis vol. kowsari yammahi bari vichr alsaby berkovich construction fuzzyﬁnd dictionary using golay coding transformation searching applications international journal advanced computer science applications vol. s.-b. k.-s. h.-c. myaeng some effective techniques naive bayes text classiﬁcation ieee transactions knowledge data engineering vol. linh than dang effective interpretable method document classiﬁcation knowledge information systems vol. oquab bottou laptev sivic learning transferring mid-level image representations using convolutional neural networks proceedings ieee conference computer vision pattern recognition huang learned-miller learning hierarchical representations face veriﬁcation convolutional deep belief networks computer vision pattern recognition ieee conference weston watkins multi-class support vector machines technical report csd-tr-- department computer science royal holloway university london tech. rep. keˇselj peng cercone thomas n-gram-based author proﬁles authorship attribution proceedings conference paciﬁc association computational linguistics pacling vol. merri¨enboer gulcehre bahdanau bougares schwenk bengio learning phrase representations using encoder-decoder statistical machine translation arxiv preprint arxiv. abadi agarwal barham brevdo chen citro corrado davis dean devin tensorﬂow large-scale machine learning heterogeneous distributed systems arxiv preprint arxiv.", "year": 2017}