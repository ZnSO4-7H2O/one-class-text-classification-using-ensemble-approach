{"title": "Oracle performance for visual captioning", "tag": ["cs.CV", "cs.CL", "stat.ML"], "abstract": "The task of associating images and videos with a natural language description has attracted a great amount of attention recently. Rapid progress has been made in terms of both developing novel algorithms and releasing new datasets. Indeed, the state-of-the-art results on some of the standard datasets have been pushed into the regime where it has become more and more difficult to make significant improvements. Instead of proposing new models, this work investigates the possibility of empirically establishing performance upper bounds on various visual captioning datasets without extra data labelling effort or human evaluation. In particular, it is assumed that visual captioning is decomposed into two steps: from visual inputs to visual concepts, and from visual concepts to natural language descriptions. One would be able to obtain an upper bound when assuming the first step is perfect and only requiring training a conditional language model for the second step. We demonstrate the construction of such bounds on MS-COCO, YouTube2Text and LSMDC (a combination of M-VAD and MPII-MD). Surprisingly, despite of the imperfect process we used for visual concept extraction in the first step and the simplicity of the language model for the second step, we show that current state-of-the-art models fall short when being compared with the learned upper bounds. Furthermore, with such a bound, we quantify several important factors concerning image and video captioning: the number of visual concepts captured by different models, the trade-off between the amount of visual elements captured and their accuracy, and the intrinsic difficulty and blessing of different datasets.", "text": "li.yaoumontreal.ca nicolas ballas nicolas.ballasumontreal.ca kyunghyun kyunghyun.chonyu.edu john smith jsmithus.ibm.com yoshua bengio yoshua.bengioumontreal.ca task associating images videos natural language description attracted great amount attention recently. state-of-the-art results standard datasets pushed regime become difﬁcult make signiﬁcant improvements. instead proposing models work investigates performances oracle obtain. order disentangle contribution visual model language model oracle assumes highquality visual concept extractor available focuses language part. demonstrate construction oracles ms-coco youtubetext lsmdc surprisingly despite simplicity model training procedure show current state-of-the-art models fall short compared learned oracle. furthermore suggests inability current models capturing important visual concepts captioning tasks. standard datasets publicly available coco flickr image captioning youtubetext mvad mpi-md video captioning ﬁeld progressing astonishing speed. instance state-of-theart results coco image captioning improved rapidly bleu similarly benchmark youtubetext repeatedly pushed bleu score obtaining encouraging results captioning approaches involve large networks usually leveraging convolution network visual part recurrent network language side. therefore results model certain complexity contribution different component clear. instead proposing better models main objective work develop method offers deeper insight strength weakness popular visual captioning copyright document resides authors. distributed unchanged freely print electronic forms. models. particular propose trainable oracle disentangles contribution visual model language model. obtain oracle follow assumption image video captioning task solved steps consider model refers usually high dimensional visual inputs representations image video refers caption usually sentence natural language description. order work well needs form higher level visual concept either explicitly implicitly based ﬁrst step denoted followed language model transforms visual concept legitimate sentence denoted referes atoms visually perceivable assumption suggests alternative build oracle. particular assume ﬁrst step close perfect sense visual concept observed almost accuracy. train best language model conditioned hints produce captions. using proposed oracle compare current state-of-the-art models helps quantify capacity visual modeling major weakness apart strong language modeling. addition applied different datasets oracle offers insight intrinsic difﬁculty blessing them general guideline designing algorithms developing models. finally also relax assumption investigate case visual concept realistically predicted accuracy demonstrate quantity-accuracy trade-off solving visual captioning tasks. visual captioning problem image captioning attracted great amount attention lately. early work focused constructing linguistic templates syntactic trees based concept visual inputs another popular approach based caption retrieval embedding space devlin kiros recently language models conditioned visual inputs widely studied work fang maximum entropy language model used donahue karpathy fei-fei vinyals recurrent neural network based models built generate natural language descriptions. work devlin advocates combine types language models. furthermore cider proposed alternative evaluation metric image captioning shown advantageous compared bleu meteor. improve performance bengio suggests simple sampling algorithm training winning recipes msr-coco captioning challenge suggests extra semantic information guide language generation process. similarly video captioning made substantial progress recently. early models barbu kojima rohrbach tend focus constrained domains limited appearance activities objects videos. also rely heavily hand-crafted video features followed template-based shallow statistical machine translation approaches produce captions. borrowing success image captioning recent models donahue rohrbach venugopalan recently ballas adopted general encoder-decoder approach end-to-end parameter tuning. videos input speciﬁc variant encoding neural networks form higher level visual summary followed caption decoder recurrent neural networks. training type models possible availability three relatively large scale datasets collected youtube guadarrama constructed based descriptive video service movies torabi rohrbach latter recently combined ofﬁcial dataset large scale movie description challenge capturing higher-level visual concept idea using intermediate visual concept guide caption generation discussed context image captioning rohrbach video captioning. work trained classiﬁers predeﬁned visual concepts extracted captions using heuristics linguistics natural language processing. work resembles sense also extract similar constituents captions. purpose study however different. assuming perfect classiﬁers visual atoms able establish performance upper bounds particular dataset. note simple bound suggested rohrbach meteor measured training captions particular test caption. largest score picked upper bound. comparison approach constructs series oracles trained generate captions given different number visual hints. therefore bounds clear indication models’ ability capturing concept within images videos performing caption generation instead suggested rohrbach performs caption retrieval. construction oracle inspired observation denotes caption containing sequence words length denotes visual inputs image video. denotes visual concepts call atoms. explicitly factorized captioning model parts call conditional language model given atoms call conditional atom model given visual inputs. establish oracle assume atom model given amounts treat dirac delta function assigns probability mass observed atom words therefore fully observed task image video captioning reduces task language modeling conditioned atoms. arguably much easier task compared direct modeling therefore well-trained model could treated performance oracle information contained directly inﬂuences difﬁculty modeling instance atoms available reduces unconditional language modeling could considered lower bound increasing amount information carries modeling becomes straightforward. oracle parameterization given atoms summarize visual concept appearing visual inputs section describes detailed parameterization model denoting overall parameters. particular adopt commonly used encoderdecoder framework model conditional based following simple factorization recurrent neural networks natural choices outputs identiﬁed sequences. borrow recent success variant rnns called long-short term memory networks ﬁrst introduced hochreiter schmidhuber formulated following denotes word embedding matrix apposed atom embedding matrix parameters lstm. lstm’s state probability next word sequence softmax parameters overall training criterion oracle atoms construction conﬁguration associated different distribution therefore different oracle model. deﬁne conﬁguration orderless collection unique atoms. size items different other. considering particular problem image video captioning atoms deﬁned words captions related actions entities attributes entities reason using three particular choices language components atoms arbitrary decision. reasonable consider three types among visually perceivable ones human describes visual content natural language. verify conducting human evaluation procedure identify visual atoms show dominant majority indeed match human visual perception detailed section able capture important concepts considered crucial getting superior performance. therefore comparing performance existing models oracle reveals ability capturing atoms visual inputs unknown. formulation section generic relying assumption two-step visual captioning process independent parameterization section practice however needs take account several contributing factors oracle. firstly atoms visual concepts deﬁned -gram words -gram phrases arguably mixture n-gram representations potential capture complicated correlations among visual concepts. simplicity work uses -gram representations detailed section secondly procedure used extract atoms needs reliable extracting mainly visual concepts leaving non-visual concepts. ensure this procedure used work veriﬁed human evaluation detailed thirdly modeling capacity conditional language direct inﬂuence obtained oracle. section shown example many possible parameterizations. lastly oracle sensitive training procedure hyper-parameters therefore important keep mind proposed oracle conditions factors quite surprisingly however simplest procedure parameterization show experimental section oracle serves purpose reasonably well. demonstrate procedure learning oracle three standard visual captioning datasets. coco commonly used benchmark dataset image captioning. consists training validation images. image accompanied captions sentence. follow split used subset images used validation another subset images used testing. youtubetext commonly used benchmark dataset video captioning. consists video clips accompanied multiple captions. overall video caption pairs. following split clips training validation testing. another video captioning datasets recently introduced torabi rohrbach compared youtubetext much larger number video clips associated captions. recently merge together large scale movie description challenge therefore name particular dataset lsmdc. visual concepts images videos summarized atoms provided caption language model. split three categories actions entities attributes. identify three classes utilize stanford natural language parser automatically extract them. caption parsed apply simple heuristics based tags produced parser ignoring phrase sentence level tags words tagged nnps prp} entity atoms. words tagged vbz} action atoms. words tagged jjs} attribute atoms. atoms identiﬁed lemmatized nltk lemmatizer unify original dictionary format figure illustrates results. extracted atoms coco youtubetext lsmdc. gives entities actions attributes coco entities actions attributes youtubetext entities actions attributes lsmdc. note although total number atoms categories large atom frequency varies. addition language parser guarantee perfect tags. therefore atoms used training oracle sort according frequency make sure frequent ones ﬁrst also give priority atoms larger coverage detailed section below. conducted simple human evaluation conﬁrm extracted atoms indeed predominantly visual. might impractical evaluate extracted atoms three datasets focus frequent atoms. evaluation intends match last column table current state-of-the-art models equivalent capacity capturing perfectly less atoms three categories. subjects asked cast vote independently. ﬁnal decision atom visual made majority vote. table shows ratio atoms ﬂagged visual procedure. http//goo.gl/lsvpr complete list tags https//goo.gl/fuzdd http//www.nltk.org/ available https//goo.gl/tvtfj details available https//goo.gl/tvtfj table human evaluation proportion atoms voted visual. clear extracted atoms three categories contain dominant amount visual elements hence verifying procedure described section another observation entities actions tend visual attributes according human perception. form captions used vocabulary size coco youtubetext lsmdc respectively. three datasets models trained training different conﬁguration atom embedding size word embedding size lstm state memory size. avoid overﬁtting also experimented weight decay dropout regularize models different size. particular experimented random hyper-parameter search bergstra bengio range similarly performed random search weight decay coefﬁcient range whether dropout. optimization performed minibatch size adadelta automatically adjust per-parameter learning rate. model selection done standard validation early stopping patience report results test splits. comparing oracle performance existing models compare current state-ofthe-art models’ performance established oracles figure table shows comparison three different datasets. figure could easily associate particular performance equivalent number atoms perfectly captured across atom categories illustrated table oracle included bold. somehow surprising state-of-the-art models performance equivalent capturing small amount all. experiment highlights shortcoming state-of-art visual models. improving them could close performance currently oracles. quantify diminishing return number atoms increases would expect oracle improved accordingly. however clear speed improvement. words gain performance proportional number atoms given generating captions atom frequencies language modeling. figure quantiﬁes effect. oracle three datasets shows signiﬁcant gain beginning diminishes quickly atoms used. figure also highlights difference among actions entities attributes generating captions. three datasets tested entities played much important roles figure learned oracle coco youtubetext lsmdc number atoms varied x-axis oracles computed y-axis testsets. ﬁrst shows oracles bleu meteor atoms three categories. second shows oracles atoms selected individually category. cider used coco youtubetext test example associated multiple ground truth captions argued lsmdc meteor used argued rohrbach although visual atoms dominant three atom categories shown section increase number non-visual atoms included living free relatively difﬁcult associated particular part visual inputs. excluding non-visual atoms conditional language model tighten oracle bound less hints provided major difﬁculty lies labor hand-separating visual atoms non-visual ones best knowledge difﬁcult automate heuristics. atom accuracy versus atom quantity assumed atoms given words prediction accuracy atoms reality would hardly expect perfect atom classiﬁer. naturally trade-off number atoms would like capture prediction accuracy figure quantiﬁes trade-off coco lsmdc. also indicates upper limit performance given different level atom prediction accuracy. particular replaced portion randomly selected replaced randomly picked atoms appearing case corresponds shown figure larger ratio worse assumed atom prediction value shown legend figure according ﬁgure order improve caption generation score would options either keeping number atoms ﬁxed improving atom prediction accuracy table measure semantic capacity current state-of-the-art models. using figure could easily reported metric number visual atoms captured. establishes equivalence model proposed oracle model’s semantic capacity. learned oracle denoted bold. keeping accuracy increasing number included atoms. state-of-art visual model already model around atoms hyphotesize could gain improving atoms accuracy rather increase number atom detected models. figure learned oracles different atom precision atom quantity coco lsmdc number atoms varied x-axis oracles computed y-axis testsets. cider used coco meteor lsmdc. shows could increase score either improving p|v) ﬁxed increase also shows maximal error bearable different score. intrinsic difﬁculties particular datasets figure also reveals intrinsic properties dataset. general bounds youtubetext much higher coco lsmdc lowest. instance ﬁrst column ﬁgure taking atoms respectively blue- around coco youtubetext less lsmdc. little visual information condition upon strong language model required makes dramatic difference across three datasets. therefore oracle compared across different datasets offer objective measure difﬁculties using captioning task. work formulates oracle performance visual captioning. oracle constructed assumption decomposing visual captioning consecutive steps. assumed perfection ﬁrst step visual atoms recognized followed second step language models conditioned visual atoms trained maximize probability given captions. empirical construction requires automatic atom parsing training conditional language models without extra labeling costly human evaluation. oracle enables gain insight several important factors accounting success failure current state-of-the-art models. reveals model independent properties different datasets. furthermore relax assumption prefect atom prediction. sheds light trade-off atom accuracy atom coverage providing guidance future research direction. importantly experimental results suggest efforts required step visual inputs converted visual concepts despite effectiveness shown experiments empirical oracle constructed simplest atom extraction procedure model parameterization mind makes construction sense conservative oracle. authors would like acknowledge support following agencies research funding computing support t.j. watson research nserc calcul québec compute canada canada research chairs cifar. would also like thank developers theano developing powerful tool scientiﬁc computing.", "year": 2015}