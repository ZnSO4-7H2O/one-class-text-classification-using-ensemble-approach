{"title": "Unsupervised Diverse Colorization via Generative Adversarial Networks", "tag": ["cs.CV", "cs.AI"], "abstract": "Colorization of grayscale images has been a hot topic in computer vision. Previous research mainly focuses on producing a colored image to match the original one. However, since many colors share the same gray value, an input grayscale image could be diversely colored while maintaining its reality. In this paper, we design a novel solution for unsupervised diverse colorization. Specifically, we leverage conditional generative adversarial networks to model the distribution of real-world item colors, in which we develop a fully convolutional generator with multi-layer noise to enhance diversity, with multi-layer condition concatenation to maintain reality, and with stride 1 to keep spatial information. With such a novel network architecture, the model yields highly competitive performance on the open LSUN bedroom dataset. The Turing test of 80 humans further indicates our generated color schemes are highly convincible.", "text": "abstract. colorization grayscale images topic computer vision. previous research mainly focuses producing color image recover original supervised learning fashion. however since many colors share gray value input grayscale image could diversely colorized maintaining reality. paper design novel solution unsupervised diverse colorization. speciﬁcally leverage conditional generative adversarial networks model distribution real-world item colors develop fully convolutional generator multi-layer noise enhance diversity multi-layer condition concatenation maintain reality stride keep spatial information. novel network architecture model yields highly competitive performance open lsun bedroom dataset. turing test humans indicates generated color schemes highly convincible. image colorization assigns color pixel target grayscale image. early colorization methods require users provide considerable scribbles grayscale image apparently time-consuming requires expertise. later research provides automatic colorization methods. colorization algorithms diﬀer ways model correspondence grayscale color. given input grayscale image non-parametric methods ﬁrst deﬁne color reference images used source data. then following image analogies framework color transferred onto input image analogous regions reference image parametric methods hand learn prediction functions large datasets color images training stage posing colorization problem either regression continuous color space classiﬁcation quantized color values supervised learning fashion. whichever seeking reference images learning color prediction model methods share common goal i.e. provide color image closer original one. know many colors share gray value. purely grayscale image cannot tell color clothes girl wearing color bedroom wall methods produce deterministic paper avoid sepia-toned colorization conditional generative adversarial networks generate diverse colorizations single grayscale image maintaining reality. originally proposed generate vivid images random noise. composed adversarial parts generative model captures data distribution discriminative model estimates probability whether image real generated generator part tries input noise data distribution closer ground truth data distribution discriminator part tries distinguish generated fake data comes adversarial situation. careful designation generative discriminative parts generator eventually produce results forming distribution close ground truth distribution controlling input noise various results good reality. thus conditional much suitable framework handle diverse colorization cnns. meanwhile discriminator needs signal whether training instance real generated directly provided without human annotation training phase task unsupervised learning fashion. aspect model designation unlike many conditional gans using convolution layers encoder deconvolution layers decoder build fully convolutional generator convolutional layer splinted concatenate layer continuously render conditional grayscale information. additionally maintain spatial information convolution stride avoid downsizing data. also concatenate noise channels ﬁrst half convolutional layers generator attain diversity color image generation process. generator would capture color distribution alter colorization result changing input noise. thus longer need train additional independent model color scheme like goal alters producing original colors producing realistic diverse colors conduct questionnaire surveys turing test instead calculating root mean squared error comparing original image measure colorization result. feedback subjects indicates model successfully produces high-reality color images yielding positive feedback rate ground truth images furthermore perform signiﬁcance t-test compare percentages human judges real color images test instance resulting p-value indicates signiﬁcant diﬀerence generated color images real ones. share repeatable experiment code research. problem colorization proposed last century research diverse colorization paid much attention decade. used additionally trained model handle diverse colorization scene image particularly dawn. posed colorization problem classiﬁcation task class re-balancing training time increase colorfulness result. work dimensional embedding color ﬁelds using variational auto-encoder learned. constructed loss terms decoder avoid blurry outputs take account uneven distribution pixel colors ﬁnally developed conditional model multi-modal distribution gray-level image color ﬁeld embeddings. compared work solution uses conditional generative adversarial networks achieve unsupervised diverse colorization generic little domain knowledge images. generative adversarial networks attained much attention unsupervised learning research recent years. conditional gans widely used various computer vision scenarios. used text generate images applying adversarial networks. provided general-purpose imageto-image translation model handles tasks like label scene aerial night edges photo also grayscale color. works share similar goal conditional structure diﬀers previous work several architectural choices mainly generator. unlike generators employ encoder-like front part consisting multiple convolution layers decoder-like part consisting multiple deconvolution layers generator uses convolution layers architecture downsize data shape applying convolution stride pooling operation. additionally multi-layer noise generate diverse colorization using multi-layer conditional information keep generated image highly realistic. fig. illustration conditional gan. generator given conditional information together noise produces generated color channels. discriminator trained real color image generated color image goal distinguish real images fake ones. nets trained adversarially. distinguished real images adversarially trained discriminator trained detecting fake images produced generator. training procedure illustrated figure without generator could still learn mapping would produce deterministic outputs. suitable diverse colorization tasks deterministic neural networks. convolution deconvolution convolution deconvolution layers basic components image generators. convolution layers mainly used exact conditional features. additionally many researches superposition multiple convolution layers stride downsize data shape works data encoder. deconvolution layers used upsize data shape decoder data representation many researches share encoder-decoder structure choose convolution layers generator firstly convolution layers well capable feature extraction transmission. meanwhile convolution stride prevent data shape downsizing thus important spatial information kept along data till ﬁnal generation layer. researches also takes spatial information consideraadding skip connections encoder-decoder structure tends extract global features generate images overall information suitable global shape transformation tasks. image colorization need detailed spatial local guidance make sure item boundaries accurately separated diﬀerent color parts generated channels. alone modiﬁcation straightforward easy implement. structural diﬀerence u-net convolution model figure color image represented diﬀerent forms. common representation form splits color pixel green blue three channels. computer vision tasks representation generality. kinds representations also included like colorization tasks grayscale image conditional information thus straightforward representation channel called luminance channel represents exactly grayscale information. using representation predict channels concatenate grayscale channel give full color image. additionally image representation result channels predicted thus keep grayscale generated color image consistent original grayscale image need additional multi-layer noise authors mentioned noise ignorance training generator. handle problem provide noise form dropout applied several layers generator training test time. also noticed problem. traditional gans conditional gans receive noise information start layer continuous data transformation network noise information attenuated lot. overcome problem make colorization results diversiﬁed concatenate noise channel onto ﬁrst half generator layers conduct experimental comparison one-layer noise multi-layer noise representations results shown section fig. detailed structure conditional gan. generator cubic part represents convolution-batchnorm-relu structure. connections represent modiﬁcations traditional conditional gans. bottom discriminator multi-layer conditional information conditional gans usually conditional information ﬁrst layer layer shape previous generators changes along convolution deconvolution layers. consistent layer shape generator apply concatenation conditional grayscale information throughout whole generator layers provide sustained conditional supervision. though u-net skip structure also help posterior layers receive conditional information model modiﬁcation still straightforward convenient. wasserstein recent work wasserstein acquired much attention. authors used wasserstein distance help getting problems original gans like mode collapse gradient vanishing provide measurable loss indicate progress training. also implementing wasserstein modiﬁcation model results better model. make comparison results wasserstein section various kinds color image datasets choose open lsun bedroom dataset conduct experiment. lsun large color image dataset generated iteratively human labeling automatic deep neural classiﬁcation. contains around million labeled images scene categories object categories. among choose indoor scene bedroom enough samples unlike outdoor scenes trees almost always green always blue items indoor scenes like bedroom various colors shown figure exactly need fully explore capability conditional model. experiments bedroom images randomly picked grayscale image model epoch. focus results boxes representation suﬀers structural miss additional trade-oﬀ loss loss. take enlarged image right figure example wall left split unnaturally white orange colors results setting acquire smooth transitions. moreover model using representation shall predict color channels representation predicts channels given grayscale channel ﬁxed conditional information makes model training much stable. fig. comparison diﬀerent color space representation. training testing representation. bottom training representation loss. focus results boxes representation results lack item continuity additional trade-oﬀ loss loss. single-layer condition setting multi-layer condition setting epoch. results multi-layer condition model makes generator structural information thus results multi-layer condition model stable single-layer conditional model suﬀers colorization derivation like images boxes figure wasserstein three groups colorization results grayscale images using wasserstein shown figure result wasserstein produce comparable results ﬁrst column wasserstein shows still failed results fig. comparison single-layer multi-layer noise model results. left results single-layer noise model. right results multi-layer noise model. apparently multilayer noise possesses generator higher diversity. wasserstein like last column even note wasserstein results come training twice number epochs results. mainly training lsun bedroom dataset quite large discriminator overﬁt easily prevents gradient vanishing problem. also large dataset discriminator needs quite times optimization convergence mention wasserstein shall momentum based optimization strategies like adam non-linear parameter value clipping wasserstein needs much longer training produce comparable results model. since wasserstain helps improve stability training price much longer training time achieved results good reality wassserstein structure. variety image colorization results conditional gans provided figure apparently fully convolutional generator multi-layer noise multi-layer condition concatenation produces various kinds colorization schemes maintaining good reality. almost color parts kept within correct components without deviation. fig. comparison single-layer multi-layer condition model result. results single-layer condition model suﬀer colorization derivation bottom results multi-layer condition model smooth transition. measurements. others additional classiﬁers predict colorized image detected still correctly classiﬁed. goal generate diverse colorization schemes cannot take distance measurements exist reasonable colorizations diverge original color image. note previous work image colorization provide quantiﬁed measurements. therefore like previous researches provide questionnaire surveys turing test measure colorization results. total participants questions. question display color images ground truth image others generated colorizations grayscale image ground truth poor reality. ground truth image among reference case participants think real. arrange images randomly avoid position bias participants. feedback participants indicates generated color images convincible rate ground truth images furthermore signiﬁcance ttest ground truth generated images percentages humans rating real image question. p-value indicating generated results signiﬁcant diﬀerence ground truth images. also calculate credibility rank within group ground truth image four corresponding generated images. image gets higher rank higher percentage participants mark real. average credibility rank ground truth images means fig. comparison results wasserstein gan. line consists leftmost ground truth color image three results three results wasserstein gan. rightmost images failed results wasserstein gan. paper proposed novel solution automatically generate diverse colorization schemes grayscale image maintaining reality exploiting conditional generative adversarial networks solved sepia-toned problem models also enhanced colorization diversity. introduced novel generator architecture consists fully convolutional non-stride structure multi-layer noise enhance diversity multi-layer condition concatenation maintain reality. structure model successfully generated diversiﬁed high-quality color images input grayscale image. performed questionnaire survey turing test evaluate colorization result. feedback participants indicates generated colorization results highly convincible. future work investigated methods generate color images conditional given corresponding grayscale images provides model maximum freedom generate kinds colors also additional constraints generator guide colorization procedure. conditions include limited speciﬁed item color blue white wall etc.; global color scheme warm tone cool tone etc. note given constraints generative adversarial networks shall still produce various vivid colorizations. fig. example results conditional lsun bedroom data. groups images consists leftmost ground truth color image diﬀerent colorizations generated conditional gans given grayscale version ground truth image. clearly novel structure generator produces various colorization schemes maintaining good reality.", "year": 2017}