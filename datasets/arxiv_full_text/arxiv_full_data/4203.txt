{"title": "An All-in-One Network for Dehazing and Beyond", "tag": ["cs.CV", "cs.AI"], "abstract": "This paper proposes an image dehazing model built with a convolutional neural network (CNN), called All-in-One Dehazing Network (AOD-Net). It is designed based on a re-formulated atmospheric scattering model. Instead of estimating the transmission matrix and the atmospheric light separately as most previous models did, AOD-Net directly generates the clean image through a light-weight CNN. Such a novel end-to-end design makes it easy to embed AOD-Net into other deep models, e.g., Faster R-CNN, for improving high-level task performance on hazy images. Experimental results on both synthesized and natural hazy image datasets demonstrate our superior performance than the state-of-the-art in terms of PSNR, SSIM and the subjective visual quality. Furthermore, when concatenating AOD-Net with Faster R-CNN and training the joint pipeline from end to end, we witness a large improvement of the object detection performance on hazy images.", "text": "effective dark channel prior reliably calculate transmission matrix followed series works enforced boundary constraint contextual regularization sharper restored images. accelerated method automatic recovery atmospheric light presented developed color attenuation prior created linear model scene depth hazy image learned model parameters supervised way. illustrate method jointly estimate scene depth recover clear latent image foggy video sequence. proposed algorithm based non-local prior based assumption color cluster clear image becomes haze-line space. methods hinge physical model various sophisticated image statistics assumptions. however since estimation physical parameters single image often inaccurate dehazing performance methods appears always satisfactory. lately convolutional neural networks witnessed prevailing success computer vision tasks introduced image dehazing well. dehazenet proposed trainable model estimate transmission matrix hazey image. exploited multi-scale ﬁrst generated coarse-scale transmission matrix later reﬁned absence end-to-end dehazing deep learning approaches image restoration enhancement fully embraced end-to-end modeling training model directly regress clean image corrupted image. examples include image denoising deblurring super resolution comparison end-to-end deep model dehazing directly regresses clean image hazy one. might appear weird ﬁrst glance needs realize haze essentially brings non-uniform signal-dependent noise scene attenuation surface caused haze correlated physical distance surface camera different image degradation models assume signal-independent noise case signals parameterized degradation process. hence restoration models could easily modeled static mapping function. directly applicable dehazing degradation process varies signals restoration model input-adaptive well. existing methods share belief order recover clean scene haze estimate accurate medium transmission atmospheric light calculated separately empirical rules abstract—this paper proposes image dehazing model built convolutional neural network called all-in-one dehazing network designed based reformulated atmospheric scattering model. instead estimating transmission matrix atmospheric light separately previous models aod-net directly generates clean image light-weight cnn. novel endto-end design makes easy embed aod-net deep models e.g. faster r-cnn improving high-level task performance hazy images. experimental results synthesized natural hazy image datasets demonstrate superior performance state-of-the-art terms psnr ssim subjective visual quality. furthermore concatenating aod-net faster r-cnn training joint pipeline witness large improvement object detection performance hazy images. existence haze presence aerosols dust mist fumes adds complicated noise images captured cameras. dramatically degrades visibility outdoor images contrasts reduced surface colors become faint. moreover hazy image effectiveness many subsequent high-level computer vision tasks jeopardy object detection recognition. dehazing algorithms thus widely considered challenging instance image restoration enhancement. similar problems like image denoising super-resolution earlier dehazing work assumed availability multiple images scene. however haze removal single image gained dominant popularity since practical realistic settings paper focused problem single image dehazing. prior knowledge exploited dehazing hazy image generation follows well-received physical model apart estimating global atmospheric light magnitude achieve haze removal recognized recovery transmission matrix. proposed physically-grounded method estimating albedo scene. discovered boyi feng wuhan national laboratory optoelectronics huazhong university science technology wuhan china. email boyilicsgmail.com dfenghust.edu.cn. fig. psnr ssim comparisons aod-net several state-of-art methods dehazing synthetic images middlebury stereo database results certify aod-net presents faithful reconstructions clean images. fig. visual quality comparison aod-net several state-of-the-art methods natural hazy image. please amplify ﬁgures view detail differences bounded regions. clean image recovered based physical model. albeit intuitive procedure directly measure minimize reconstruction distortions. errors separate steps estimating transmission matrix atmospheric light accumulate potentially amplify other. result traditional separate pipeline gives rise sub-optimal image restoration quality. missing link high-level vision tasks currently dehazing models rely sets evaluation criteria syntehtic hazy images groundtruth clean images known psnr ssim typically computed measure restoration ﬁdelity; real natural hazy images unknown groundtruth available comparison dehazing results subjective visual quality. however unlike image denoising super resolution results whose suppression effects visual artifacts visible visual differences state-ofthe-art dehazing models typically manifest global illumination tone often subtle tell. general image restoration enhancement known part low-level vision tasks usually thought preprocessing step mid-level high-level vision tasks. known performance high-level computer vision tasks object detection recognition deteriorate presence various degradations largely affected quality image restoration enhancement. however best knowledge exploration correlate dehazing algorithms results high-level vision task performance. ﬁrst propose end-to-end trainable dehazing model directly produces clean image hazy image rather relying separate intermediate parameter estimation step. aod-net designed based re-formulated atmospheric scattering model thus preserving physical ground existing works however built different belief physical model could formulated more end-to-end fashion parameters estimated uniﬁed model. ﬁrst quantitatively study dehazing quality could affect subsequent high-level vision task serves objective criterion comparing dehazing results. moreover aod-net seamlessly embedded deep models constitute pipeline performs high-level tasks hazy images implicit dehazing process. thanks unique all-in-one design pipeline jointly tuned improving performance further infeasible replacing aod-net deep hehazing alternatives aod-net trained synthetic hazy images tested synthetic real natural images. experiments demonstrate superiority aod-net several state-of-the-art methods terms psnr ssim also visual quality lightweight efﬁcient model aod-net costs second process image single gpu. concatenated faster r-cnn aod-net notably outperforms dehazing models improving object detection performance hazy images performance margin boosted even jointly tune pipeline aod-net faster r-cnn end. paper extended previous conference version notable improvement current paper lies section present in-depth discussion evaluating enhancing dehazing object detection introduce joint training part abundant details analysis. also provide detailed thorough analysis architecture aod-net besides included extensive comparison results. section proposed aod-net explained. ﬁrst introduce transformed atmospheric scattering model based aod-net designed. architecture aod-net described detail. existing works follows identical threestep procedure estimating transmission matrix hazy image using sophisticated deep models; estimating using empirical methods; estimating clean image procedure leads sub-optimal solution directly minimize image reconstruction errors. separate estimation cause accumulated even ampliﬁed errors combining together calculate integrated variable constant bias default value since dependent build input-adaptive deep model whose parameters change input hazy images minimizes reconstruction error output groundtruth clean image. proposed aod-net consists modules illustrated figure k-estimation module estimates input followed clean image generation module utilizes input-adaptive parameters estimate k-estimation module critical component aod-net responsible estimating depth relative haze level. depicted figure convolutional layers form multi-scale features fusing varied size ﬁlters. parallel convolutions varying ﬁlter sizes used second layer. concatenated coarse-scale network features intermediate layer ﬁne-scale network. inspired them concat layer aod-net concatenates features layers conv conv. similarly concat concatenates conv conv; concat concatenates conv conv conv conv. multiscale design captures features different scales intermediate connections also compensate information loss convolutions. notably convolutional layer aod-net uses three ﬁlters. result aod-net much light-weight compared existing deep methods e.g. following k-estimation module clean image generation module consists element-wise multiplication layer several element-wise addition layers order generate recovered image calculating end-to-end deep network minimizing reconstruction errors observed figure baseline found overestimate cause overexposure visual effects. aod-net clearly produces realistic lighting conditions structural details since enables mutually reﬁne joint estimation other. inaccurate estimate hyperparameters also compromised compensated all-in-one formulation. create synthesized hazy images using groundtruth images depth meta-data indoor depth database different atmospheric lights choosing channel uniformly select database take images training non-overlapping testset also take full-size synthetic images middlebury stereo database testset besides test natural hazy images evaluate model generalization. training process weights initialized using gaussian random variables. utilize relu neuron found effective brelu neuron proposed speciﬁc setting. momentum decay parameter respectively. batch size images learning rate adopt simple mean square error loss function pleased boosts psnr also ssim well visual quality. aod-net model takes around training epochs converge usually performs sufﬁciently well epochs. paper trained model epochs. also found helpful clip gradient constrain norm within technique popular stabilizing recurrent network training compared proposed model several state-of-theart dehazing methods fast visibility restoration dark-channel prior boundary constrained context regularization automatic atmospheric light fig. visual results dehazing synthetic images. left right columns hazy images dehazenet results mscnn results aod-net results groundtruth images. please amplify ﬁgure view detail differences bounded regions. recovery color attenuation prior non-local image dehazing dehazenet mscnn among previous experiments quantitative results restoration quality reported absence haze-free ground-truth testing real hazy images. synthesized hazy images accompanied ground-truth images enabling compare dehazing results terms psnr ssim. tables iii-b display average psnr ssim results testsets respectively. since aod-net optimized loss surprising higher psnr performance others. appealing observation aod-net gains even greater ssim advantages competitors even though ssim directly referred optimization criterion. ssim measures beyond pixel-wise errors well-known faithfully reﬂect human perception become curious part aod-net consistent improvement achieved. following investigation image testset decomposed mean image residual image. former constructed pixel locations taking mean value easily justiﬁed images equals mean images added residual images. mean image roughly corresponds global illumination related residual concerns local structural variations contrasts etc. observe aod-net produces similar residual competitive methods dehazenet cap. however mses mean parts aodnet results drastically lower dehazenet shown table iii. implied that aod-net could capable correctly recover thanks joint parameter estimation scheme end-to-end reconstruction loss. since human eyes certainly sensitive large changes global illumination local distortion wonder visual results aodnet also evidently better results often look unrealistically bright. advantage also manifests illumination term computing ssim partially interprets strong ssim results. major source ssim gains seems contrast term. examples randomly select images test mean contrast values aod-net results testsetb signiﬁcantly higher bccr mscnn dehazenet synthetic images figure shows dehazing results synthetic images testset observe aod-net results generally possess sharper contours richer colors visually faithful ground-truth. well outdoor images. evaluate stateof-art methods natural image examples signiﬁcantly challenging dehaze general outdoor images found authors challenges dominance highly cluttered objects textures illumination variations. revealed figure suffers overly-enhanced visual artifacts. bccr mscnn produce unrealistic color tones several images bccr results second bccr mscnn results fourth dehazenet aod-net competitive visual results among plausible details. closer look still observe sometimes blurs image textures dehazenet darkens regions. aod-net recovers richer saturated colors suppressing artifacts. white objects mscnn creates opposite artifact over-enhancement head region comparison. aod-net manages remove haze without introducing fake color tones distorted object contours. little hurt haze-free images although trained hazy images aod-net veriﬁed possess highly desirable property causes little negative impacts input image haze-free. endorses robustness effectiveness k-estimation module. figure shows results challenging clean images colorlines. image anti-halation aod-net another image enhancement task called image anti-halation without re-training. halation spreading light beyond proper boundaries forming undesirable effect bright areas photos. related dehazing following different physical models anti-halation results aodnet decent figure examples. white scenery natural images white scenes object always major obstacle haze removal. many effective priors fail white objects since objects similar color atmospheric light transmission value close zero. dehazenet mscnn rely carefully-chosen ﬁltering operations post-processing improve robustness white objects inevitably sacriﬁce visual details. although aod-net explicitly consider handling white scenes end-to-end optimization scheme seems contribute stronger robustness here. figure displays hazy images white scenes dehazing results various methods. easy notice intolerable artifacts results especially region ﬁrst row. problem alleviated persists dehazenet mscnn results aod-net almost artifactfree. moreover seems blur textural details section speciﬁcally analyze usefulness inter-layer concatenations k-estimation module combine multi-scale features varied size ﬁlters. conjecture despite empirical ﬁnding current concatenation facilitates smooth feature transition low-level higher-level consistently feeding several consecutive lower layers immediate next layer. comparison purposes designed baseline conv conv conv conv conv involves inter-layer concatenation. testset average psnr ssim testset average psnr ssim results generally inferior aod-net especially ssim values suffer signiﬁcant drops. light-weight structure aod-net leads faster dehazing. select images testset models machine core cpu.ghz memory) without acceleration. per-image average running time models shown table despite slower matlab implementations fair compare dehazenet ours. results illustrate promising efﬁciency aod-net costing time dehazenet image. high-level computer vision tasks object detection recognition concern visual semantics received tremendous attentions however performance algorithms largely jeopardized various degradations practical applications. conventional approach resorts separate image restoration step feeding target task. recently validates joint optimization restoration recognition steps would signiﬁcantly boost performance traditional twostage approach. however previous works mainly examined effects remedies common degradations noise blur resolution image classiﬁcation tasks only. best knowledge similar work quantitatively study existence haze would affect high-level vision tasks alleviate impact using joint optimization methods. study problem object detection presence haze example high-level vision tasks interact dehazing. choose faster r-cnn model strong baseline test synthetic natural hazy images. concatenate aod-net model faster r-cnn model jointly optimized uniﬁed pipeline. general conclusions drawn experiments haze turns heavier object detection becomes less reliable. haze conditions jointly tuned model constantly improves detection surpassing naive faster r-cnn non-joint approaches. create three synthetic sets pascal dataset heavy haze medium haze light haze depth maps predicted method described split nonoverlapped training test set. first compare schemes without network ﬁne-tuning naive fasterrcnn directly input hazy image using model pretrained clean pascal-voc dehazenet faster r-cnn ﬁrst dehazing using dehazenet faster rcnn; mscnn faster r-cnn ﬁrst dehazing using mscnn faster r-cnn; faster r-cnn ﬁrst dehazing using faster r-cnn; aodnet faster r-cnn aod-net concatenated faster rcnn without joint tuning. calculate mean average precision three test sets shown ﬁrst three rows table clean pascal-voc test heavy haze degrades nearly ﬁrst dehazing using various dehazing methods detection improves lot. among them dcp+faster r-cnn performs best improvement heavy haze. without joint tuning aod-net+faster rcnn performs comparable mscnn+faster r-cnn appears worse dcp+faster r-cnn. pipeline aodnet+faster r-cnn jointly optimized improved object detection performance hazy images. tune aod-net+faster r-cnn three hazy training sets separately call tuned version jaod-faster rcnn. learning rate ﬁrst iterations next iterations momentum weight decay result joint tuning increases heavy haze case shows major strength end-to-end optimization value unique design. comparison also re-train faster r-cnn hazy data sets comparison. learning rate ﬁne-tuning pre-trained faster r-cnn retraining adapted hazy dataset retrained faster r-cnn increases heavy haze still consistently worse jaod-faster r-cnn. furthermore since practically desirable obtain uniﬁed model works arbitrary haze levels generate training includes various haze levels randomly sampled re-tune evaluate jaod-faster r-cnn retrained faster r-cnn training whose results compared last table although perform slightly inferior dedicated counterparts trained applied speciﬁc haze level perform consistently well three haze levels jaod-faster r-cnn outperforms retrained faster rcnn. figure plots comparisons every iterations jaod-faster r-cnn retrained faster r-cnn schemes various haze conditions. fig. object detection results natural hazy images conﬁdence threshold displayed dehazed results dehazing performed; visualize output tuned aod-net part dehazed image.). ﬁne-tuned faster r-cnn jaod-faster r-cnn select model trained synthetic light haze. compared naive faster-rcnn; dehazenet faster rcnn; mscnn faster r-cnn; aod-net faster rcnn; fine-tuned faster r-cnn. jaod-faster r-cnn. observe haze cause missing detections inaccurate localizations unconﬁdent category recognitions faster r-cnn. aod-net faster r-cnn already shows visible advantages naive faster-rcnn performance dramatically improved jaod-faster r-cnn results surpasses alternatives visibly. note aod-net faster r-cnn beneﬁts joint optimization two-folds aod-net jointly estimates parameters entire pipeline jointly tunes low-level high-level jaod-faster r-cnn arguably best performer shown above question arise naturally result fact aod-faster r-cnn uses parameters faster r-cnn? section show adding extra layers parameters without task-speciﬁc design dehazing necessarily improve performance object detection haze. fig. training process every iterations four training datasets. training heavy haze. training medium haze. training light haze. training multiple haze levels. designed baseline named auto-faster r-cnn replaces aod-net part jaod-faster r-cnn plain convolutional auto-encoder. auto-encoder exactly amount parameters aod-net consisting convolutional layers structure resembling k-estimation module. pre-train auto-encoder dehazing task using training protocol dataset aod-net concatenate faster r-cnn end-to-end tuning. observed table performance auto-faster r-cnn aod-faster rcnn shows even worse fine-tuned faster r-cnn. recall veriﬁed directly adding extra layers faster r-cnn necessarily improve performance object detection general clean images. conclusion consistent counterpart hazy case. besides noted although jaod-faster rcnn appends aod-net faster r-cnn complexity increased much thanks light-weight design aod-net. per-image average running time faster r-cnn jaod-faster rcnn using nvidia geforce titan gpu. paper proposes aod-net all-in-one pipeline directly reconstructs haze-free images end-to-end cnn. compare aod-net variety state-of-the-art methods synthetic natural haze images using objective subjective criteria. extensive experimental results conﬁrm superiority robustness efﬁciency aod-net. moreover also present ﬁrst-ofits-kind study aod-net boost object detection recognition performance natural hazy images joint pipeline optimization. observed jointly tuned model constantly improves detection presence haze surpassing naive faster r-cnn non-joint approaches. still mentioned above dehazing technique highly correlated depth estimation images room improving performance aod-net incorporating depth prior knowledge elaborate depth estimation module. cheng wang zhang yang huang. robust emotion recognition quality rate video deep learning approach. proceedings conference affective computing intelligent interaction sulami glatzer fattal werman. automatic recovery atmospheric light hazy images. computational photography ieee international conference pages ieee tang yang wang. investigating haze-relevant features learning framework image dehazing. proceedings ieee conference computer vision pattern recognition pages j.-p. tarel hautiere caraffa cord halmaoui gruyer. vision enhancement homogeneous heterogeneous fog. ieee intelligent transportation systems magazine wang chang yang huang. studying resolution recognition using deep networks. proceedings ieee conference computer vision pattern recognition pages wang yang wang chang yang huang. self-tuned deep super resolution. proceedings ieee conference computer vision pattern recognition workshops pages zhang yang zhang nasrabadi huang. close loop joint blind image restoration recognition computer vision ieee sparse representation prior. international conference pages ieee shelhamer donahue karayev long girshick guadarrama darrell. caffe convolutional architecture fast feature embedding. proceedings international conference multimedia pages kopf neubert chen cohen cohen-or deussen uyttendaele lischinski. deep photo model-based phoacm transactions graphics tograph enhancement viewing. volume page zhiying zhou l.-f. cheong. simultaneous video defogging stereo reconstruction. proceedings ieee conference computer vision pattern recognition pages shen reid. learning depth single monocular images using deep convolutional neural ﬁelds. ieee transactions pattern analysis machine intelligence mccartney. optics atmosphere scattering molecules meng wang duan xiang pan. efﬁcient image dehazing boundary constraint contextual regularization. proceedings ieee international conference computer vision pages girshick sun. faster r-cnn towards realtime object detection region proposal networks. cortes lawrence sugiyama garnett editors advances neural information processing systems pages curran associates inc. scharstein szeliski. high-accuracy stereo depth maps using computer vision pattern recognition structured light. proceedings. ieee computer society conference volume pages i–i. ieee schechner narasimhan nayar. instant dehazing images using polarization. computer vision pattern recognition cvpr proceedings ieee computer society conference volume pages i–i. ieee", "year": 2017}