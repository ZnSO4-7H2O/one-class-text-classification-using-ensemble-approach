{"title": "Contextual RNN-GANs for Abstract Reasoning Diagram Generation", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Understanding, predicting, and generating object motions and transformations is a core problem in artificial intelligence. Modeling sequences of evolving images may provide better representations and models of motion and may ultimately be used for forecasting, simulation, or video generation. Diagrammatic Abstract Reasoning is an avenue in which diagrams evolve in complex patterns and one needs to infer the underlying pattern sequence and generate the next image in the sequence. For this, we develop a novel Contextual Generative Adversarial Network based on Recurrent Neural Networks (Context-RNN-GANs), where both the generator and the discriminator modules are based on contextual history (modeled as RNNs) and the adversarial discriminator guides the generator to produce realistic images for the particular time step in the image sequence. We evaluate the Context-RNN-GAN model (and its variants) on a novel dataset of Diagrammatic Abstract Reasoning, where it performs competitively with 10th-grade human performance but there is still scope for interesting improvements as compared to college-grade human performance. We also evaluate our model on a standard video next-frame prediction task, achieving improved performance over comparable state-of-the-art.", "text": "fig. shows example problem dat-dar dataset highlights intricacies reasoning involved inferring correct answer different pattern components sides corners changing different multiple ways making interesting challenge correctly generate next image sequence. accurate generation models developed reasoning task used general applications forecasting simulation generation. models also useful generation real-world images videos recent research direction computer vision deep learning direction present application best models task next frame generation moving mnist videos. sequential generation model temporally recurrent version generative adversarial networks name context-rnn-gans context refers sequential history especially well-suited sequential image-based reasoning tasks. model generator tries generate correct next image based previous sequence images. adversarial discriminator explanation ground truth dashed line ﬁrst goes left right sides also changes single double hence ground truth double dashed lines sides. corners number slanted lines increase every images hence ground truth four slant lines corners. context-rnn-gan ‘context’ refers adversary receiving previous images generator also rnn. name distinguishes simpler rnngan model adversary contextual generator rnn. understanding predicting generating object motions transformations core problem artiﬁcial intelligence. modeling sequences evolving images provide better representations models motion ultimately used forecasting simulation video generation. diagrammatic abstract reasoning avenue diagrams evolve complex patterns needs infer underlying pattern sequence generate next image sequence. this develop novel contextual generative adversarial network based recurrent neural networks generator discriminator modules based contextual history adversarial discriminator guides generator produce realistic images particular time step image sequence. evaluate context-rnn-gan model novel dataset diagrammatic abstract reasoning performs competitively th-grade human performance still scope interesting improvements compared college-grade human performance. also evaluate model standard video next-frame prediction task achieving improved performance comparable state-of-the-art. recent success machine learning neural networks atari sparked renewed interest artiﬁcial intelligence models perform well tasks even humans challenging. important task category abstract reasoning measures one’s lateral thinking skills ﬂuid intelligence i.e. ability quickly identify patterns logical rules trends data integrate information apply solve problems. speciﬁcally address problem diagrammatic abstract reasoning subset differential aptitude tests introduced judge psychometric proﬁciency. featured intelligence assessment systems since validated showed proﬁciency dat-dars predictors engineering training. task involves generation future diagram based sequential evolution component patterns given problem sequence. also gets previous timesteps’ images context current timestep’s image discriminator uses images preceding current timestep contextual information better distinguish whether generator produced realistic images particular timestep sequence also develop novel image representations using unsupervised siamese network modeling joint representation adjacent timesteps. helps bring much information temporal evolution across consecutive time steps. modeling problem using unsupervised setting training sequential image language model large quantities sequences help method generalize better unseen test sequences. empirically perform quantitative evaluation dat-dar dataset ﬁrst generating successor image test sequence measuring similarity between generated image candidate answer images multiple-choice setting intelligence quotient dataset. report accuracy percentage correct hits. compare several baselines model variants feature representations context-rnngan model siamese features performs best. also compared human performance promisingly ﬁnal model competitive th-grade high school students still scope interesting improvements compared advanced engineering college students. also demonstrate context-rnn-gan model successfully model video next-frame generation moving mnist dataset achieve improved performance comparable state-of-the-art. novel temporally contextual rnn-based adversarial generation model adversary access full context previous preceding images context deciding real fake sample timestep. introduced tests measure success individual adapting speciﬁc situation speciﬁc condition. visual problems intelligence tests among earliest continuously researched problems looked terms propositional logic beginning recently recently also signiﬁcant interest building systems compete humans variety tasks geometry-based problems physics-based problems repetition symmetry detection visual question answering verbal reasoning analogy task closely relates problem raven’s progressive matrices. there problems constrained; squares matrix missing sequential pattern evolves along columns rows. addressed using propositional logic based framework theorem prover based approach however focus novel task involves unrestricted pattern movements bigger datasets rely representability terms propositional logic. task also closely related task next frame prediction videos involves predicting next frame based previous frames. however change across consecutive real-world video frames extremely small compared evolving shapes changing spatial dynamics diagrammatic reasoning task. hence poses several challenges different task video next-frame generation modeling optical ﬂows plays major role producing better-looking next frames. related work video prediction direction include language modeling based approaches convolution-based lstms adversarial cnns context encoders data-conditioned gans lastly generative adversarial networks also extended spatial recurrence attention structure whereas speciﬁcally focus temporal recurrence constraints frames video rnns. gans also used high resolution image generation image manipulation text-to-image synthesis generates videos single image using gans discriminator judges entire video rather individual frames conditioned previous frames. convolutionallstms similar gru-rnn baseline ﬁnal context-rnn-gan model adversarial loss gives better results. predict multiscale videos using cnns provide ﬁxed number previous frames context discriminator helpful modeling short sequences. generate long-term future frames action dependent games transition frames mostly smooth similar consecutive frames unlike task involves discontinuous movements evolving diagrammatic pattern. context-rnn-gan context-rnn-gan model uses sequential structure diagrammatic abstract reasoning problem framework i.e. generate next image sequence previous context images. basic principle underlying model original model discriminator generator play following minimax game pdata data’s distribution generator’s distribution vector parameters generator discriminator’s distribution vector parameters discriminator. discriminator tries distinguish inputs sampled real data generator’s distribution labeling respectively. hand generator tries fool discriminator getting generated image also labeled discriminator. model trained well discriminator cannot discriminate images generated generator images actual data distribution sampled. next case importantly also sequential context generator discriminator model capture temporal sequence-of-images nature task described detail next. generator want generator generate output image given previous images sequential order generated image close possible correct next timestep’s image sequence xt+. therefore choose generator sequential model generates sequentially next image trying fool discriminator believing actually follow preceding input note generator model lstm-based gru-based vanilla rnns; choose grus based empirical evaluation. figure context-rnn-gan model generator discriminator rnns. generates image every timestep receives preceding images context decide whether current image output real generated particular timestep. input images. given image real data distribution unlike traditional model’s discriminator). this inject context discriminator including preceding images along generator’s generated image provides context discriminator decide whether generator’s image actually follows previous images. model context choose discriminator sequence model well namely gru-rnn. sequence model essentially sequenceto-label encoding model receives context images preceding timesteps generator’s image last timestep ﬁnal hidden state mapped sigmoid predicting whether actual fake image timestep. training discriminator particular timestep correct image timestep generated image output generator train discriminator classiﬁed therefore loss function train minimizing loss implies tries generated image adjust close real image following judged current state discriminator. minimizing loss lead instability training because generator generate images able fool discriminator manifold might quite different wants model correctly. hence similar train model combination loss loss deﬁned rnn-gan rnn-gan model simpliﬁed version contextrnn-gan model discriminator simply multilayer perceptron gets generated images current timestep previous context image. objective discriminator classify whether image provided image dataset’s distribution generated generator. i.e. discriminator replaced finally simplest model regular models sequence images trying predict features image given features previous images sequence. tried loss functions. feed-forward baseline feed-forward network baseline simply fullyconnected multi-layered perceptron layers trained using ﬁrst images x..xt− predict ﬁfth image testing last images x..xt used predict features answer image xt+. section discuss various image embedding methods used create input features sequence models context-rnn-gan discussed above. pixels ﬁrst baseline images resized dimension pixel values used features row-wise stacking pixel values. features generated model resized visualize generation. histogram oriented gradients features obtained concatenating histograms occurrences gradient orientation cells images hence capturing features corresponding various edge types proving good feature detector. autoencoder shown effectiveness autoencoders reducing dimensionality data. hence used unsupervised autoencoder hidden units bottleneck layer trained images dataset. activations bottleneck layer used feature representations images. pretrained used features penultimate layers overfeat network image localization task ilsvrc pre-trained imagenet dataset shown useful tasks sketch recognition architecture consists stages layers. stage consists convolutions rectiﬁed linear units optionally max-pooling layers. extracted output layer output fully connected layer seventh stage ﬁnal classiﬁcation. fine-tuned alexnet model ﬁne-tuned alexnet pretrained imagenet challenge labels annotated dat-dar dataset’s images dividing image four quadrants four feature types counted quadrant image labels multioutput-multiclass classiﬁcation. counting features done using diagram parser used model used euclidean loss produced outputs. shallow trained end-to-end shallow three convolutional layers followed relu dropout fully connected layer. trained solely images’ labels described above. resultant features penultimate layer used. learning rate kernel size similar used siamese initial timesteps regular sequential models lstms face difﬁculty generating next image sequence lack sufﬁcient context resolve this propose learn joint embedding adjacent images features sequential models. this created siamese network uses pair shallow cnns followed fully connected layer cnns. cnns parameters shared help distance images feature plane. siamese network tries minimize distance similar images maximize distance dissimilar images using contrastive loss siamese network trained initializing shared cnns parameters shallow cnn. ﬁne-tuned image dataset contrastive loss uses every pair temporally adjacent images problem similar examples uses pairs images different problems dissimilar examples. activations fully connected layers network features models. dataset collected data several test books online resources collected training problems annotated test problems used transforms rotation mirror reﬂections across axes increase data eight times leading total problem sequences train containing sequence diagrams. test problem consists ﬁgures input sequence question answer choices i.e. multiple-choice setup allow easier quantitative evaluation. proposed models trained ﬁgures question part i.e. training consisting images used whereas correct answer ﬁgure used training. models validated using ﬁrst answer ﬁgure tested remaining unseen answer ﬁgure test/validation questions. training details best hyperparameters context-rnn-gan layers hidden units generator single layer hidden units discriminator. best hyperparameters rnn-gan model layers hidden units generator mulilayered perceptron ﬁnal models context-rnn-gan rnn-gan models λadv dat-dar task next-frame prediction task similar based empirical evidence experiments. best hyperparameters regular hidden layer hidden units based loss functions; adding layers hidden units help. best hyperparameters feedforward baseline layers hidden units based loss functions adding layers hidden units didn’t help. models dropout applied hidden layer. models trained using adam optimizer evaluation metrics visualizations generated images importantly also perform quantitative evaluation matching generated image embedding embeddings candidate answer images returning closest matching image. accuracy determined number correct choices made model respect total test size. human performance test proﬁciency humans dat-dar dataset conducted experiments sets individuals. problems divided sets problems given much time required complete questions. also ﬁrst given example problem explanation answer. advanced college students senior students computer science department premier university took part ﬁrst experiment. th-grade high school students students grade reputed high school took part second experiment. seen table diagrammatic abstract reasoning task quite challenging even humans best performance strong undergraduate college students roughly th-grade students achieving accuracy. figure visualizations image generation. four problems ﬁrst images question sequence second-last column ground-truth last column model generation. various feature representation methods table ﬁrst show baseline results regular trained different features. shallow siamese features perform best here. next best feature settings novel context-rnn-gan model shown table primary context-rnn-gan model combined novel siamese features obtains best results even competitive performance th-grade human performance. however still scope interesting model feature improvements compared collegenext-frame generation moving-mnist videos also tested context-rnn-gan model popular moving-mnist task introduced show results compared methods well convolution-based lstm model fair comparison report results ae-convlstm model model optical ﬂow. shown table perform better comparable state-of-the-art multiple metrics qualitiative generation visualization also present quantitative evaluation visualizations images generated model moving-mnist tasks. show cases generated image corresponds closely correct answer image. example task model able correctly infer generate next-sequence diagrams changing arrow directions number type lines different corners sides multiple shapes interacting different ways etc. similarly mnist task model able correctly generate digits moving different amounts directions. presented novel context-rnn-gan model generate images sequential reasoning scenarios task diagrammatic abstract reasoning. combined useful feature representations siamese cnns model performs competitively th-grade humans still scope interesting improvements compared college-level human performance making novel challenging task generation community. sequential model also general enough useful tasks next frame generations video similarly important tasks forecasting simulation. thank reviewers devi parikh dhruv batra kundan kumar aravind srinivas deepak pathak shubham tulsiani greg shakhnarovich shubham tulsiani helpful feedback.", "year": 2016}