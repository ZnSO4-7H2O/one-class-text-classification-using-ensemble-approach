{"title": "Towards Adaptive Training of Agent-based Sparring Partners for Fighter  Pilots", "tag": ["stat.ML", "cs.AI", "cs.LG", "cs.RO"], "abstract": "A key requirement for the current generation of artificial decision-makers is that they should adapt well to changes in unexpected situations. This paper addresses the situation in which an AI for aerial dog fighting, with tunable parameters that govern its behavior, must optimize behavior with respect to an objective function that is evaluated and learned through simulations. Bayesian optimization with a Gaussian Process surrogate is used as the method for investigating the objective function. One key benefit is that during optimization, the Gaussian Process learns a global estimate of the true objective function, with predicted outcomes and a statistical measure of confidence in areas that haven't been investigated yet. Having a model of the objective function is important for being able to understand possible outcomes in the decision space; for example this is crucial for training and providing feedback to human pilots. However, standard Bayesian optimization does not perform consistently or provide an accurate Gaussian Process surrogate function for highly volatile objective functions. We treat these problems by introducing a novel sampling technique called Hybrid Repeat/Multi-point Sampling. This technique gives the AI ability to learn optimum behaviors in a highly uncertain environment. More importantly, it not only improves the reliability of the optimization, but also creates a better model of the entire objective surface. With this improved model the agent is equipped to more accurately/efficiently predict performance in unexplored scenarios.", "text": "requirement current generation artiﬁcial decision-makers adapt well changes unexpected situations. paper addresses situation aerial ﬁghting tunable parameters govern behavior must optimize behavior respect objective function evaluated learned simulations. bayesian optimization gaussian process surrogate used method investigating objective function. beneﬁt optimization gaussian process learns global estimate true objective function predicted outcomes statistical measure conﬁdence areas haven’t investigated yet. model objective function important able understand possible outcomes decision space; example crucial training providing feedback human pilots. however standard bayesian optimization perform consistently provide accurate gaussian process surrogate function highly volatile objective functions. treat problems introducing novel sampling technique called hybrid repeat/multi-point sampling. technique gives ability learn optimum behaviors highly uncertain environment. importantly improves reliability optimization also creates better model entire objective surface. improved model agent equipped accurately/eﬃciently predict performance unexplored scenarios. rapid advancement capabilities artiﬁcial intelligence research area potential completely revolutionize u.s. armed forces train battlespace dominance. becomes sophisticated many opportunities insert domain training environments. basis agents stand humans live-virtual-constructive simulations. humans participating training exercises environments need challenged appropriate level relative skills. red-force agents assess skill-level human participants adapt accordingly needed. agents like could serve worthy credible sparring partners indistinguishable experienced humans. speciﬁcally work investigate agent tunable parameters govern overall behavior adapted optimize objective function engagement outcomes. beyond optimizing outcome metric also important agent realistic representation entire objective function enable adapt behavior appropriately dynamic uncertain environments. ∗graduate researcher computer science university colorado boulder aiaa student member †assistant professor aerospace engineering sciences university colorado boulder aiaa member ‡director orbit logic incorporated greenbelt aiaa professional member §sr. software engineer orbit logic incorporated greenbelt ¶division technical advisor force research laboratory warﬁghter readiness research division wright patterson simulating engagement costly. beyond ﬁnancial expense operating simulation environment contributions cost also include involvement skilled personnel limited availability wall-clock duration simulation itself. engagement metrics need optimized cannot described analytically sampled running simulations. sampled generally nonlinear noisy. consequently many traditional optimization methods applicable. besides identifying optimum performance agent also obtain model overall objective function. allow agent adaptive notion outcomes might arise modifying behavior parameters without exhaustively search high-dimensional parameter space. addition model also used generate useful estimate expected performance adversaries wide range scenarios using small number test evaluations. bayesian optimization using gaussian process surrogate functions well-suited addressing points gpbo uses gaussian process surrogate function approximate true objective function. surrogate function includes estimated value objective function location solution space well conﬁdence estimated value. optimization algorithm makes surrogate function intelligently search solution space optimum based number sampled function evaluations i.e. using ‘explore/exploit’ strategies locate minimum quickly possible using sparse function evaluations build surrogate model. show standard application gpbo methods well suited address points application. demonstrate novel approach implementing gpbo called hybrid repeat/multi-point sampling addresses issue. setting gpbo hrms able identify minimum reliably standard gpbo also yields useful surrogate representation objective surface. finally using total function evaluations traditional gpbo. remainder paper previous work occurred ﬁeld discussed formal deﬁnition problem given including details regarding application gpbo aerial ﬁghting. section reviews previous work area gives theoretical background gpbo. formal deﬁnition adaptive agent problem ‘learning engine’ framework used train decision-making given section iii. finally section show simulated experiments implementation gpbo hrms useful optimizing highly volatile metrics application well diﬀerent parameters. furthermore hrms outperforms traditional sampling techniques thus yielding valuable insights ﬁghter performance global surrogate function model. simulations air-to-air combat training studied extensively. paper mcmanus goodrich discuss integration system separate simulators included interface pilots participate. moore discussed method measure pilot performance validated simulated combat scenarios. order evaluate pilot performance metrics must calculated. traditionally performance grades issued ﬂight instructors evolved less subjective repeatable. many metrics well accepted community. contemporary development newer metrics expert evaluations still utilized validation. paper kelly reviews summarizes much work. speciﬁcally mentions metrics include relative aircraft position throttle speedbrake manipulation overall engagement outcomes name few. producing meaningful metrics operate time-series summary data engagements still active ﬁeld research. experiments utilized metrics mentioned literature above. paper focus ‘cumulative time kill’ metric total time eliminate enemy. current body work involves optimization aircraft engagement focused mainly optimal strategies teams. mulgund concerned large-scale combat tactics able demonstrate promising results area. addressed problem optimizing cooperative multiple target attack using genetic algorithms also applying gonsalves burge investigated mission plans could optimized. optimization focused strategic level whereas work focused modifying behaviors pilots. recently work ernest design function real time combat also interpretable. work utilized genetic optimization group fuzzy inference systems together produce control actions given input data. system able produce ‘ﬁne-grained’ control actions single groups ﬁghters. also speciﬁcation fiss control outputs interpretable humans. work fairly similar seeks optimal solution combat scenario modifying ﬁghter behaviors also interpretable. solution diﬀers design entire work operates tunable behaviors. also approach tries minimize number simulations needed optimum build model solution space time; model used later adapt decisions. autonomous agents simulation scenarios used extensively video game industry non-player character autonomous agent interacts human players. majority agents used video gaming industry using year technology highly scripted. cole used order tune game agents ﬁrst person shooter games. liaw used genetic algorithms order evolve game agents work team. othman discuss simulations evolve agent tactical purposes. work addresses optimization behaviors take account cost running experiments constructing model true objective function allow robust given extremely volatile objective metric. finally bayesian optimization emerged critical tool tuning hyperparameters various areas machine learning also applied several ﬁelds modeling user preferences reinforcement learning. well suited optimizing objective functions expensive evaluate unknown. often fewest function evaluations compared competing methods. properties make ideal optimizing behavioral parameters pilot. however already mentioned demonstrated later standard application gpbo able perform well objective functions highly volatile surrogate representation true objective function desired. goal optimization minimize nonlinear function maps rd). here typically subset euclidean space known search space search identify element known fairly easy evaluate. many applications often case. speciﬁcally knowledge might noisy function evaluations. goal bayesian optimization minimize unknown noisy objective function costly evaluate also learning time. named bayesian inference concept probability theory applied optimization process. initial belief potential objective functions called prior updated subsequent observations evidence p|y). mathematically leads application bayes’ rule p|y)p quantity p|y) also known likelihood. finally updated probability given observed also known function known forrester function standard objective function testing optimization methods. iteration begins seed data initial surrogate function. surrogate function represented blue line shaded conﬁdence bounds. acquisition function directs data sampled. data acquired inference along updated process continues. case iteration minimum located represents true objective function fairly well. surrogate function gaussian processes deﬁned probability distribution functions values evaluated arbitrary points jointly gaussian distribution. used bayesian optimization gaussian process serve ‘surrogate’ function estimate true objective function. referred bayesian optimization gaussian process surrogate main components gaussian process shown equation mean function covariance function theory could function assume zero paper simplify notation. kernel commonly used machine learning applications property able change smoothness using parameter parameter means resulting function diﬀerentiable once. quantity ‘length scale’ parameter. matrix rn×n elements covariance pairs training outputs test outputs respectively written here rp×n making rp×p. equation shows expression conditional distribution given test points training data mean variance distribution calculated analytically using equations acquisition function evaluation experiment. typically operates surrogate function quantify possibility ﬁnding optimum objective function location. acquisition function indicates optimum likely found according current information objective function. bayesian optimization selects optimum acquisition function next point evaluated. paper three acquisition functions evaluated expected improvement upper conﬁdence bound thompson sampling acquisition functions themselves many local optima require global optimization methods identify optimum. therefore necessary global optimization algorithms. recall reason makes sense true objective function assumed ‘expensive’ evaluate. expense acceptable/desirable forego using gpbo standard global optimization method. words global optimization acquisition function small cost true objective function expensive enough. work makes direct optimization algorithm utilizes lipschitz continuity property bound function values local rectangles search accordingly. direct also commonly used gpbo discussion topic found work shahriari makes unique explicitly uses current observed optimum objective function along predicted quantify optimum might located. name suggests values literally translate statistically expected improvement current estimated optimum sampling given location. acquisition function inspired regret multi-armed bandit problems. goal bound regret sequential optimization process regret deﬁned diﬀerence actual strategy ideal strategy. deﬁned parameters hyperparameter. simply takes mean prediction multiple standard deviation every adds themb. possible drawback function requires hyperparameter exist principled ways select often avoided practice tuning problem fact proven consistently better methods require hyperparameters. experience selecting works optimization hasn’t diﬃcult. thompson sampling works diﬀerently either ucb. name suggests involves sampling functions directly gaussian process function obtained optimum found objective function evaluated point. exploration exploitation inherently part stochastic nature. another nice property thompson sampling naturally lends parallelized search optimum. large numbers tend identify locations better chance ﬁnding optimum objective function. known limitation diﬃculty performing high dimensional applications. also found case -on- aerial combat application dimensionalities decision making summary aforementioned acquisition functions beneﬁts drawbacks investigated shahriari single best acquisition function every situation evaluate application. apply technique experimentally attempt identify best simulated aerial combat scenario. given functions deﬁned above procedure algorithm followed. termination criteria could number iterations something sophisticated. practice performance bayesian optimization depends greatly selection tuning surrogate function. discuss section paper demonstrate ﬁrst application gpbo training decision-makers continuous behavioral parameters. show gpbo used making adaptive uncertain environments volatile outcomes. demonstrate standard application gpbo methods well suited addressing highly volatile objective functions like found aerial ﬁghting application. methods also lack ability model overall surrogate function used decision making performance analysis. introduce hrms novel sampling approach addresses stated shortcomings standard gpbo. experiments show that simulated aerial combat scenario method ﬁnds optimum objective value reliably/repeatably standard gpbo also yields accurate surrogate representation true objective surface. problem deﬁned combat scenario autonomous blue force agents. agents behavioral parameters given parameter vectors xxxr xxxb respectively. goal optimize objective function must evaluated using high-ﬁdelity combat simulation. work xxxr constant optimization changing xxxb. remainder paper uses following xbxbxb {intspeed launch} application evaluating objective function time consuming. figure illustration objective function based variations diﬀerent inputs. apparent function nonlinear noisy discontinuous. consequently specialized class optimization needed reduce number evaluations needed optimum. review detail setup simulation gpbo applied. figure one-dimensional examples objective function {blueintspeed bluelaunch}. ﬁgures empirically produced holding xxxrxxxrxxxr parameters constant well xxxb parameters except listed running many experiments location. dark blue line represents mean shaded area times standard deviation. figure depicts process optimum parameter xxxb found. bottom portion ﬁgure shows high-level learning loop ﬁgure represents simulation environment. agent parameters chosen ﬁrst simulation using parameters agent. eﬀort leveraged pilot agent logic developed orbit logic previous eﬀorts; however overall approach agnostic agent logic itself agent tunable behavior parameters could substituted. simulation completed engagement metrics calculated delivered gpbo algorithm evaluation. bayesian optimization algorithm associates recent engagement metrics behavior parameters selects parameters goal ﬁnding optimum parameters. designed engagement scenario included signiﬁcant opportunity collection relevant metrics drive validate gpbo learning process. includes single blue force ﬁghter penetrating adversary’s defended engagement zone. primary objective engage air-to-air combat agent assigned nominal ﬂight plan includes multiple way-points that ﬂown over provide mission ‘scoring points’. way-points arranged ensure ﬁghters periodically encounter illustrated ﬁgure instigating employment air-to-air combat logic. figure diagram depicting engagement space. blue players begin rinit binit respectively. ﬂight path carries way-points indicated dashed lines. ﬂight engage criteria decision logic met. theoretically attractive na¨ıve application gpbo typically yield satisfactory results. fact learning hyperparameters surrogate model involves non-convex optimization fact objective functions noisy. furthermore without initial data guide learning model learning process converge incorrect results early stages gpbo process. hence careful design implementation practices needed ensure reliable subtle critical point order gpbo work suﬃciently accurate needed order approximate true objective function. speciﬁcally necessary approximates actual attributes objective function. therefore necessary provide ‘seed’ data bootstrap good seed sample input space random sampling. however ensure suﬃcient coverage space na¨ıve uniform random sampling insuﬃcient samples correlated drawn proximity other. instead type stratiﬁed random sampling called latin hypercube sampling used. method ensures uniform sampling input space. number seed points must also selected given random sampling method. main factors would aﬀect many samples needed homogeneity objective function smoothness function. unfortunately objective function unknown limits ability optimally select number seed points. important work desire ensure gpbo choose good experiment location optimization process begins. sampling done appropriately gpbo algorithm begin investigating local optimum able escape. best knowledge using form quasi random sampling heuristically selected amount seed data currently state-of-the-art. common seed points dimensionality problem. section suggest that depending properties objective function necessary diﬀerent heuristic simple multiple dimensionality. true kernel hyperparameters known priori extremely important able learn accurate reliable possible. hyperparameters parameters govern covariance function behaves data used kernel hyperparameters trained best data. several approaches learning hyperparameters. maximum likelihood estimate cross-validation maximum posteriori three widely used methods investigated. methods yields point estimate ‘true’ hyperparameters used kernel. learning engine implementation estimate used. method found stable tolerant diﬀerent objective functions simulation settings. crossvalidation sensitive tended over-ﬁt training datac. undesirable hyperparameters selected poorly gpbo begin searching wrong places. despite still conditions presenting stability diﬃculties. future eﬀorts investigate monte-carlo methods distributions hyperparameters instead explicitly choosing best estimate. standard gpbo approach. second multiple sampling evaluated multiple diﬀerent locations simultaneously. finally propose method called repeat sampling identical except objective function evaluated repeatedly intuitive reason introducing repeat sampling obtain informative statistical sample objective function every iteration. necessary because gpbo work properly surrogate function needs ‘suﬃciently accurate’ representation true objective function. helps information regarding noise true objective function useful surrogate function guiding gpbo. concept repeat sampling also commonly used experimental design known experiment eplication. besides gaining statistical information replication frequently used experiment setup expensive; would deﬁnitely consideration training human pilots. multi-point sampling several methods used generally methods attempt forecast points might interest future evaluations. three diﬀerent methods investigated paper. ﬁrst known q-ei. similar instead optimizing xbxbxb function optimized multiple xxxb points time. method notoriously expensive evaluate dimensionality increases calculation function expensive. expensive monte-carlo simulations known faster cases. alternative approximate method introduced computing points quickly. method used simulations. next method called gp-ucb-pe uses function pure exploration technique perform parallel search optimum. gp-ucb-pe algorithm simple premise greedily select ﬁrst points using acquisition function. done ﬁrst selecting maximum function identical non-batch approach. next taking advantage fact covariance predictions updated without knowing re-calculated assuming proposed known select resulting maximum process repeated points selected. finally simple extension basic used select points. instead drawing single function selecting optimum functions drawn optimum found experiments corresponding locations optimum. known diﬃculty highdimensions curse dimensionality. drawing random functions high-dimensional space easy because order suﬃcient resolution must randomly sample entire input space repeat sampling critical problems extremely noisy volatile objective functions allows converge noisy objective function intuitively understood recognizing algorithm works kernel updated iteration. single sample evaluated iteration kernel update could responding noise acquisition function could direct next experiment wrong place. instead kernel provided ‘statistical sample’ function update less likely respond outlying observations. hybrid repeat/multi-point sampling strategies especially valuable objective function less expensive evaluate simulation experiments parallel without signiﬁcantly increasing overall cost optimization. following means batch samples selected. likewise samples taken location. note special case rs=ms=. finally refer combined sampling strategies using hybrid repeat/multi-point sampling hrms experimentally evaluated section goal identify varying aﬀects gpbo. given decision agent optimization problem perform experiments investigate performance diﬀerent acquisition functions aerial combat simulations. importantly wish investigate eﬀect varying optimization results. speciﬁcally three common acquisition functions evaluated expected improvement upper conﬁdence bound thompson sampling also evaluate corresponding batch sampling forms q-ei gp-ucb-pe multiple draws diﬀerent levels used gpml toolbox used representation hyperparameter inference. orbit logic developed discoverable data interfaces usable blue force agent parameters initiate simulation runs recover metrics conclusion each. relevant experiment parameters shown table table acronym stands automatic relevance determination. involves modifying kernel input scaling. particularly useful dealing mixed engineering units inputs ‘relevant’ contributing output others. hyperparameters estimated using map. requires prior probabilities placed hyperparameter. prior beliefs hyperparameters known hyperpriors. finally using laplace inference used approximate method ﬁnding maximum posterior distribution. figure shows estimated locations optimum well optimum acquisition function. estimates grow tighter together closer ground truth become greater conﬁgurations marked colored rectangles highlight methods using solely underperform method combines greater ﬁnding similar functions well. ﬁgure conclude hrms conﬁgurations yield repeatable optimization results neither alone clearly better. figure scatter plots values diﬀerent rs/ms conﬁgurations. results running gpbo approximately function evaluations. horizontal line ground truth value. detailed investigation results large optimization tends terminate early ill-conditioned covariance matrix. occurred ‘too big’ locations returned many nearly identical objective function values locations. subsequent covariance matrix became linearly dependent conditioning problems inference. suggests clearly trade-oﬀ beneﬁts unstable revisit point conclusion section. important note given ﬁxed time optimization total number function evaluations cases exceed strategy. mainly overhead calculating illustrated figure signiﬁcantly exceeds total function evaluations figure plot showing total amount optimization iterations corresponding number function evaluations running conﬁguration hours. note that exception total number function evaluations mixed rs/ms conﬁgurations generally doesn’t exceed gpbo figure depicts examples ﬁnal obtained time limited optimization three diﬀerent hrms conﬁgurations. left column ‘ground truth model obtained training several thousands samples input space. insight rs/ms strategy yielded better represents ground truth. ﬁndings indicate hrms improves repeatability optimization overall ﬁdelity surrogate representation objective function. applies ﬁxed computation time number function evaluations. phenomena linked i.e. optimization repeatable surrogate representation accurate. returning high level goal research training behavioral parameters optimize combat objective capability adaptive. figure demonstrates gpbo useful application. shows using hrms results repeatable identiﬁcation optimum behaviors simulated combat. figure shows combined rs/ms strategy yields accurate surrogate representation true objective function. surrogate model gives insights expected value changes entire behavioral space. seem large areas lower intspeed moderate launch good blue. conversely appears higher intspeed conﬁgurations don’t yield good results. looking simulation recording helps gather insight why. figure shows outcomes diﬀerent simulations. scenario lower launch intspeed values good results scenario higher intspeed yields poor results blue agent figure table ﬁgures illustrating eﬀect combined rs/ms sampling using acquisition function. bottom left right ﬁrst column truth surface obtained high density sampling ﬁtting data. following columns show example results optimization runs using indicated values ﬁnal columns represents optimization solution hours several interesting insights drawn surrogate identiﬁed rs/ms surrogate functions identiﬁed lesser extent rs/ms oﬀer less reliable insight true function. capability gives ability identify optimum behavior also better capability adapt able predict outcomes location behavioral space. case able select behavioral parameters blue pilot order optimize ttk. beyond optimizing shown possible construct useful surrogate model optimization process. gpbo hrms sampling used order achieve goals using hrms together gpbo necessary characteristics simulated combat problem objective function extremely volatile desirable learn optimum action model objective function well. gpbo provides perform optimization expensive objective functions. ability make predictions value objective function locations investigated. using hrms improve ability. such ﬁnal optimization results improved valuable insights true objective function modeled. better global model true objective better able adapt order achieve desired outcomes. using gpbo hrms several advantages application. demonstrated algorithm able identify optimum extremely nonlinear noisy objective functions. importantly evaluation objective function speciﬁcally chosen yield beneﬁt given data kept number combat simulations possible. course used simulated engagements ai’s applying methodology simulations human participants required really address higher-level goals research. would also interesting decision-making could model objective function able select behaviors noisy environment able tutor human suggesting behaviors likely yield successful results. left image shows simulation start identical scenarios. images column show point blue agent launches mid-ranged missile. images column show scenarios blue loses lock red. however column blue lower intercept speed able regain lock bottom blue able maneuver order regain lock time without lock missile longer guided it’s target. extended simultaneously train multiple blue force agents train team behaviors well. also addition statistical behavior recognition components exploitation ability gpbo parallelizable simulations fundamental learning approach could also quite naturally applied extremely rapid online learning adaptation well learning humans loop. respect theory gpbo hrms sampling work needed investigate autonomous methods values calculated attempt guarantee best possible performance. existing literature regarding experiment replication helpful regard. also importance adaptively adjust problems possibly ‘too big’ ill-conditioned covariances introduced mentioned above. particular concern heteroskedastic objective function words objective function statistical properties noise varies input space. couple theoretical challenges still present investigated future work. ﬁrst hyperparameters remain sensitive even improvements using instead using fully bayesian learning might promising. however approach involves several drawbacks requiring mcmc sampling. second challenge curse dimensionality ever present. methods gp-ucb-pe calculated transfer well higher dimensions instead would useful utilize output direct optimization algorithm indicate important locations sample objective function located high dimensional space sample densely there. also method using random embeddings introduced enable bayesian optimization useful problems much higher dimensionality remains evaluated setting.", "year": 2016}