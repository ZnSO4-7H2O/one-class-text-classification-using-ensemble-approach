{"title": "Semantic3D.net: A new Large-scale Point Cloud Classification Benchmark", "tag": ["cs.CV", "cs.LG", "cs.NE", "cs.RO"], "abstract": "This paper presents a new 3D point cloud classification benchmark data set with over four billion manually labelled points, meant as input for data-hungry (deep) learning methods. We also discuss first submissions to the benchmark that use deep convolutional neural networks (CNNs) as a work horse, which already show remarkable performance improvements over state-of-the-art. CNNs have become the de-facto standard for many tasks in computer vision and machine learning like semantic segmentation or object detection in images, but have no yet led to a true breakthrough for 3D point cloud labelling tasks due to lack of training data. With the massive data set presented in this paper, we aim at closing this data gap to help unleash the full potential of deep learning methods for 3D labelling tasks. Our semantic3D.net data set consists of dense point clouds acquired with static terrestrial laser scanners. It contains 8 semantic classes and covers a wide range of urban outdoor scenes: churches, streets, railroad tracks, squares, villages, soccer fields and castles. We describe our labelling interface and show that our data set provides more dense and complete point clouds with much higher overall number of labelled points compared to those already available to the research community. We further provide baseline method descriptions and comparison between methods submitted to our online system. We hope semantic3D.net will pave the way for deep learning methods in 3D point cloud labelling to learn richer, more general 3D representations, and first submissions after only a few months indicate that this might indeed be the case.", "text": "paper presents point cloud classiﬁcation benchmark data four billion manually labelled points meant input data-hungry learning methods. also discuss ﬁrst submissions benchmark deep convolutional neural networks work horse already show remarkable performance improvements state-of-the-art. cnns become de-facto standard many tasks computer vision machine learning like semantic segmentation object detection images true breakthrough point cloud labelling tasks lack training data. massive data presented paper closing data help unleash full potential deep learning methods labelling tasks. semanticd.net data consists dense point clouds acquired static terrestrial laser scanners. contains semantic classes covers wide range urban outdoor scenes churches streets railroad tracks squares villages soccer ﬁelds castles. describe labelling interface show data provides dense complete point clouds much higher overall number labelled points compared already available research community. provide baseline method descriptions comparison methods submitted online system. hope semanticd.net pave deep learning methods point cloud labelling learn richer general representations ﬁrst submissions months indicate might indeed case. deep learning made spectacular comeback since seminal paper revives earlier work especially deep convolutional neural networks quickly become core technique whole range learning-based image analysis tasks. large majority state-of-the-art methods computer vision machine learning include cnns essential components. success image-interpretation tasks mainly easily parallelisable network architectures facilitate training millions images single availability huge public benchmark data sets like imagenet pascal images rgb-d data. cnns great success story image interpretation less point cloud interpretation. makes supervised learning hard point clouds sheer size millions points data irregular gridaligned places sparse structure strongly varying point density recording nowadays straight-forward main bottleneck generate enough manually labeled training data needed contemporary machine learning learn good models generalize well across unseen scenes. additional dimension number classiﬁer parameters larger space speciﬁc effects like occlusion variations point density lead many different patterns identical output classes. aggravates training good general classiﬁers generally need training data contrast images fairly easy annotate even note large number points semanticd.net scale number pixels rgb-d benchmark aims order accelerate development powerful algorithms point cloud processing provide hitherto largest collection laser scans pointlevel semantic ground truth annotation. total consists points class labels classes. data split training test sets approximately equal size. scans challenging size points scan also high measurement resolution long measurement range leading extreme density note that besides laser scanner point clouds also efﬁcient classify point clouds generated pipelines directly instead going individual images merge results changes large occlusions. convenient benchmark test provide freely available data also automated online submission system well public results submitted methods. benchmark also includes baselines following standard paradigm eigenvalue-based feature extraction multiple scales followed classiﬁcation random forest basic deep learning approach. moreover ﬁrst submissions made benchmark also brieﬂy discuss. benchmarking efforts long tradition geospatial data community particularly isprs. recent efforts include example isprs-eurosdr benchmark high density aerial image matching aims evaluating dense matching methods oblique aerial images isprs benchmark test urban object detection reconstruction contains several different challenges like semantic segmentation aerial images object reconstruction computer vision large-scale benchmark data sets millions images become standard learning-based image interpretation tasks. variety datasets introduced many tailored speciﬁc task serving basis annual challenges several consecutive years datasets boosting research image classiﬁcation object detection heavily rely images downloaded internet. web-based imagery major driver benchmarks expensive dedicated photography campaigns accomplished dataset generation. enables scaling benchmarks hundreds millions images although often weakly annotated considerable amount label noise taken account. additionally assume internet images constitute general collection images less bias towards particular sensors scenes countries objects etc. allows training richer models generalize well. ﬁrst successful attempts object detection images large scale tinyimages million small images milestone still widely used dataset semantic image segmentation famous pascal dataset challenge used training testing many well-known state-of-the-art algorithms today like another recent dataset mscoco contains images annotations allow object segmentation object recognition context image captioning. popular benchmarks computer vision today imagenet dataset made convolutional neural networks popular computer vision contains images organized according wordnet hierarchy words grouped sets cognitive synonyms. introduction popular low-cost gaming device microsoft kinect gave rise several large rgb-d image databases. popular examples depth dataset rgb-d provide labeled rgb-d images object segmentation scene understanding. compared laser scanners low-cost structured-light rgb-d sensors much shorter measurement ranges lower resolutions work poorly outdoors interference infrared spectrum sunlight projected sensor pattern. best knowledge publicly available dataset laser scans scale aforementioned vision benchmarks exists today. thus many recent convolutional neural networks designed voxel grids resort artiﬁcially generated data models modelnet rather small synthetic dataset. consequence recent ensemble methods reach performance modelnet clearly indicates model overﬁt limited data. existing laser scan datasets mostly acquired mobile mapping devices robots like kaist small publicly available. publicly availabe laser scan datasets include oakland dataset sydney urban objects data paris-rue-madame database data iqmulus terramobilita contest common lidar data mobile mapping provides much lower point density typical static scan like ours. also relatively small supervised learning algorithms easily overﬁt. majority today’s available point cloud datasets comes without thorough transparent evaluation publicly available internet continuously updated lists submissions benchmark. semanticd.net benchmark presented paper closing gap. provides largest labeled point cloud data approximately four billion hand-labeled points comes sound evaluation continuously updates submissions. ﬁrst dataset allows full-ﬂedged deep learning real laser scans high-quality manually assigned labels point. given points want infer individual class label point. provide three baseline methods meant represent typical categories approaches recently used task. many state-of-the-art laser scanners also acquire color values even entire color images scanned scene. color images additional object evidence help classiﬁcation. ﬁrst naive baseline classiﬁes color images without using depth information establish link vast literature semantic image segmentation. modern methods deep convolutional neural networks workhorse. encoder-decoder architectures like segnet able infer labels entire image once. deep architectures also combined conditional random fields baseline method section covers image-based semantic segmentation. figure projection ground truth images. bottom results classiﬁcation image baseline. white unlabeled pixels black pixels corresponding point gray buildings orange made ground green natural ground yellow vegetation blue high vegetation purple hard scape pink cars directly. recent implementation standard classiﬁcation pipeline i.e. extract hand-crafted features neighbourhoods feed discriminative learning algorithm. typical features encode surface properties based covariance tensor point’s neighborhood randomized histograms additionally height distributions encoded using cylindrical neighborhoods second baseline method represents category. iii) baseline rather obvious extension apply deep learning also point clouds mostly using voxel grids obtain regular neighbourhood structure. work efﬁciently large point neighborhoods clouds strongly varying density recent work uses adaptive neighbourhood data structures like octrees sparse voxel grids third baseline method section basic straight-forward implementation voxel-grid cnns. convert color values scans separate images cube mapping ground truth labels also projected point clouds image space point labeling task turns pure semantic image segmentation problem images chose associate hierarchical ﬁelds method semantic segmentation proven deliver good performance variety tasks available original implementation. method works follows four different types features texton sift local quantized ternary patters self-similarity features extracted densely image pixel. feature category separately clustered distinct patterns using standard k-means clustering corresponds typical bag-of-words representation. pixel image feature vector concatenation bag-of-word histograms ﬁxed rectangles varying sizes. rectangles randomly placed extended neighbourhood around pixel. multi-class boosting classiﬁer discriminative weak features found explained local smoothing without loosing sharp object boundaries smooth inside superpixels favor class transitions boundaries. superpixels extracted mean-shift sets coarse-to-ﬁne parameters described class likelihoods overlapping superpixels predicted using feature vector consisting bag-of-words representation superpixel. pixel-based superpixelbased classiﬁers additional smoothness priors pixels superpixels combined probabilistic fashion conditional random ﬁeld framework proposed probable solution associative hierarchical optimization problem found using move making graph-cut based algorithm appropriate graph construction higher-order potentials second baseline inspired infers class label directly point cloud using multiscale features discriminative learning. again access original implementation. method uses efﬁcient approximation multi-scale neighbourhoods point cloud sub-sampled multi-resolution pyramid constant small number neighbours level captures multi-scale information. multi-scale pyramid generated voxel-grid ﬁltering uniform spacing. feautre extracted level extension decribed uses different combinations eigenvalues eigenvectors covariance pointneighborhood different geometric surface properties. furthermore height features based vertical cylindrical neighbourhoods added emphasize special role gravity direction note make color values scanner intensities. always available point clouds empirically found improve results method. classiﬁer random forest optimal parameters found grid search fold cross-validation. please refer details. work least amount parameters layer hence reduce risk overﬁtting computational cost. separate network paths different resolutions vgg-like architecture design baseline point cloud classiﬁcation task following recent voxnet shapenet encoding ideas. pipeline illustrated fig. instead generating global voxel-grid prior processing create voxel cubes scan point. different resolutions voxel size ranges encode empty voxel cells ﬁlled ones input thus encoded multidimensional tensor cube entries scan point. scales handled separately vgg-like network path includes convolutional pooling relu layers. separate network paths ﬁnally concatenated single representation passed fully-connected layers. output second fully-connected layer dimensional vector contains class scores classes benchmark challenge. scores transformed class conditional probabilities soft-max function. describing network architecture detail introduce following notation stands convolutional layers ﬁlters input channels output channels zero-padding size border stride size stands fully-connected layers. stands relu non-linearity stands volumetric pooling receptive ﬁeld applied stride size dimension stands dropout probability stands soft-max layer. this strategy automatically centers voxel-cube scan point. note alternative approach global voxel grid several scan points could fall grid cell dense scan parts. would require scan point selection grid cell computationally costly results down-sampling. training deploy standard multi-class cross-entropy loss. deep learning non-convex efﬁciently optimized stochastic gradient descent produces classiﬁers state-of-the-art prediction performance. algorithm uses randomly sampled mini-batches several hundred points batch iteratively update parameters cnn. popular adadelta algorithm optimization extension stochastic gradient decent mini batch size training samples batch sampled randomly balanced training batches sample training data large representative point cloud million points standard pre-processing step cnns data augmentation enlarge training avoid overﬁtting. here augment training random rotation around z-axis every batches. experiments turned additional training data improve performance. indicates case rather deal underﬁtting i.e. model lacks capacity fully capture evidence available training data. thus refrain possible augmentations like randomly missing points adding noise. network implemented uses torch framework deep learning. code documentation baseline publicly available https//github.com/nsavinov/semanticdnet. published terrestrial laser scans consist total billion points contain urban rural scenes like farms town halls sport ﬁelds castle market squares. intentionally selected various different natural man-made scenes prevent over-ﬁtting classiﬁers. published scenes captured central europe describe typical european architecture shown figure surveying-grade laser scanners used recording scenes. colorization performed post processing step deploying high resolution cubemap generated camera images. general static laser scans high resolution able measure long distances little noise. especially compared point clouds derived structure-from-motion pipelines kinect-like structured light sensors laser scanners deliver superior data quality. scanner positions data recording selected usually done ﬁeld little scan overlap needed registration scenes recorded minimum time. free choice scanning position implies prior assumption based point density class distributions made. publish laser scans scene small overlap. relative position laser scans location estimated targets. following classes within benchmark challenge cover made terrain mostly pavement; natural terrain mostly grass; high vegetation trees large bushes; vegetation ﬂowers small bushes smaller buildings churches city halls stations tenements etc.; remaining hard scape clutter class instance garden walls fountains banks etc.; scanning artifacts artifacts caused dynamically moving objects recording static scan; cars trucks. classes illdeﬁned instance scanning artifacts could also cars trucks hard differentiate large small bushes. classes helpful numerous applications. please note applications class scanning artifacts gets ﬁltered heuristic rule sets. within benchmark want deploy machine learning techniques instead thus perform heuristic pre-processing. view large data sets important reasons typically real world scan data sets large. hence methods impact real problems able process large amount data. large data sets especially important developing methods modern inference techniques capable representation learning. small datasets good results leave strong doubts possible overﬁtting; unsatisfactory results hand hard interpret guidelines research mistakes short-comings contrast common strategies data labelling ﬁrst compute over-segmentation followed segment-labeling manually assign point class label individually. although strategy labor-intensive avoids inheriting errors segmentation approach importantly classiﬁers learn hand-crafted rules segmentation algorithms trained data. general difﬁcult label point cloud hand images. main problem hard select point monitor millions points without clear neighbourhood/surface structure. tested different strategies annotation follow iterative ﬁltering strategy manually select couple points simple model data remove model outliers repeat steps inliers belong class. procedure possible select large buildings couple seconds. small part point clouds labeled approach student assistants zurich. annotation user rotates point cloud ﬁxes view draws closed polygon splits point cloud parts part usually contains points background discarded. procedure repeated times remaining points belong class. points separated different layers corresponding classes interest. procedure works well existing software packages outsourced largest difference samples test training sets occurs class building. however seem affect performance submissions far. difﬁcult classes scanning artefacts cars training test samples large variation possible object shapes. scanning artefacts probably hardest class shape artefacts mostly depends movement objects scanning process. note that following discussions industry professionals class hard scape designed clutter class contains sorts man-made objects except houses cars ground. order intuition quality manually acquired labels also checked label agreement among human annotators. provides indicative measure much different annotators agree labeling data viewed internal check manual labeling precision. roughly estimate label agreement different human annotators areas different scans scene overlap. cannot rule completely overlapping areas might labeled person viewed indicative measure. recall overlaps adjacent scans precisely established artiﬁcial markers scene. even scan alignments would perfect without error exact point-to-point correspondences exist scans scan points acquired different locations never exactly fall onto spot. thus resort nearest neighbor search point correspondences. moreover scan points corresponding point adjacent scan. threshold distance used ignore points correspondence exists. point correspondences estblished possible transfer ground truth labels cloud compute confusion matrix. note deﬁnition correspondence symmetric point correspondences cloud cloud equal correspondences cloud cloud pair calculate intersection-over-union values indicate maximum label disagreement correspondences found moving objects course hence ignored category scanning artefacts evaluation figure semanticd.net benchmark provides large high quality terrestrial laser scans billion manually annotated points standardized evaluation framework. data published recently submissions optimistic change future. first submissions already show ﬁnally cnns beginning outperform conventional approaches example covariance baseline large laser scans. goal submissions benchmark yield better comparisons insights strengths weaknesses different classiﬁcation approaches point cloud processing hopefully contribute guide research efforts longer term. hope benchmark meets needs research community becomes central resource development efﬁcient accurate methods classiﬁcation space. follow pascal challenge’s choice main segmentation evaluation measure intersection union averaged classes. assume classes indexed integers overall number classes. confusion matrix chosen classiﬁcation method entry number samples ground-truth class predicted class evaluation measure class deﬁned auxiliary measures provide confusion matrix finally participant asked specify time took classify test well hardware used experiments. measure important understanding suitable method real-world scenarios usually billions points required processed. computational demanding methods provide reduced challenge consisting subset published test data. results baseline methods well submissions shown table full challenge table reduced challenge. three published baseline methods covariance based method performs better baseline color based method. computational cost could deep learning baseline deepnet reduced data set. expect network higher capacity perform much better. results full challenge methods deepsegnet harrisnet already beat covariance baseline signiﬁcant margin respective percent points. indicates deep learning seems also point clouds enough data available training. ﬁrst sign benchmark already starts work generates progress. class distributions test training rather similar shown figure interestingly class samples man-made terrain because convenience operators ﬁeld tend place scanner paved ground. recall also quadratic decrease point density distance scanner many samples close scanner. compensates different class frequencies opposed example overall accuracy balance different class frequencies giving higher inﬂuence large classes. table semanticd benchmark results full data covariance baseline tmlc-ms image baseline tml-pc ﬁrst submissions harrisnet deepsegnet. categories man-made terrain natural terrain high vegetation vegetation buildings hard scape scanning artefacts cars. scanning artefacts ignored classiﬁcation present image data. table semanticd benchmark results reduced data covariance baseline tmlc-msr image baseline tmlpcr baseline deepnet. tmlc-msr method tmlc-ms goes tmlc-pcr tmlcpc. cases indicates classiﬁers reduced dataset. categories man-made terrain natural terrain high vegetation vegetation buildings hard scape scanning artefacts cars. scanning artefacts ignored classiﬁcation present image data. blomley weinmann leitloff jutzi shape distribution features point cloud analysis-a geometric histogram approach multiple scales. isprs annals photogrammetry remote sensing spatial information sciences. boykov kolmogorov experimental comparison min-cut/max-flow algorithms energy minimization vision. transactions pattern analysis machine intelligence. cavegn haala nebiker rothermel tutzauer benchmarking high density image matching oblique airborne imagery. int. arch. photogramm. remote sens. spatial inf. sci. vol. chen l.-c. papandreou kokkinos murphy yuille deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs. arxiv preprint arxiv.. demantk´e mallet david vallet dimensionality based scale selection lidar point clouds. international archives photogrammetry remote sensing spatial information sciences. hackel wegner schindler fast semantic segmentation point clouds strongly varying point density. isprs annals photogrammetry remote sensing spatial information sciences vol. iii- maturana scherer voxnet convolutional neural network real-time object recognition. intelligent robots systems ieee/rsj international conference ieee monnier vallet soheilian trees detection laser point clouds acquired dense urban areas mobile mapping system. isprs annals photogrammetry remote sensing spatial information sciences. riemenschneider b´odis-szomor´u weissenberg gool learning classify multi-view semantic segmentation. european conference computer vision springer rottensteiner sohn gerke wegner isprs test project urban classiﬁcation building reconstruction. technical report isprs working group scene analysis. russakovsky deng krause satheesh huang karpathy khosla bernstein berg fei-fei imagenet large scale visual recognition challenge. international journal computer vision serna marcotegui goulette deschaud j.-e. paris-rue-madame database mobile laser scanner dataset benchmarking urban detection segmentation classiﬁcation methods. international conference pattern recognition applications methods icpram shotton winn rother criminisi textonboost joint appearance shape context modeling multiclass object recognition segmentation. european conference computer vision. torralba fergus freeman million tiny images large data nonparametric object scene recognition. ieee transactions pattern analysis machine intelligence weinmann jutzi mallet feature relevance assessment semantic interpretation point cloud data. isprs annals photogrammetry remote sensing spatial information sciences. munoz bagnell vandapel hebert contextual classiﬁcation functional max-margin markov networks. computer vision pattern recognition cvpr ieee conference ieee zhuang wang contextual classiﬁcation laser points conditional random ﬁelds urban environments. intelligent robots systems ieee/rsj international conference ieee", "year": 2017}