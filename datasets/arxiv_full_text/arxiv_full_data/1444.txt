{"title": "KSU KDD: Word Sense Induction by Clustering in Topic Space", "tag": ["cs.CL", "cs.AI", "stat.AP", "stat.ML", "68T05"], "abstract": "We describe our language-independent unsupervised word sense induction system. This system only uses topic features to cluster different word senses in their global context topic space. Using unlabeled data, this system trains a latent Dirichlet allocation (LDA) topic model then uses it to infer the topics distribution of the test instances. By clustering these topics distributions in their topic space we cluster them into different senses. Our hypothesis is that closeness in topic space reflects similarity between different word senses. This system participated in SemEval-2 word sense induction and disambiguation task and achieved the second highest V-measure score among all other systems.", "text": "context closeness topic distributions topic space indication similarity senses. motivation behind building system observation context polysemous word helps determining sense degree. word sense induction system create topic model given corpus infer topic distribution documents containing ambiguous words. probabilistic model collection discrete data graphically represented shown figure three level hierarchical bayesian model. model corpus consists documents multinomial distribution topics turn multinomial distributions words. generate document using probabilistic model distribution topics generated using dirichlet prior parameter then words document topic drawn multinomial distribution parameter then word drawn topic’s distribution words describe language-independent unsupervised word sense induction system. system uses topic features cluster diﬀerent word senses global context topic space. using unlabeled data system trains latent dirichlet allocation topic model uses infer topics distribution test instances. clustering topics distributions topic space cluster diﬀerent senses. hypothesis closeness topic space reﬂects similarity diﬀerent word senses. system participated semeval- word sense induction disambiguation task achieved second highest v-measure score among systems. ambiguity meaning inherent natural language deliverer words tries minimize size vocabulary uses. therefore sizable portion vocabulary polysemous intended meaning words encoded context. knowledge acquisition bottleneck problem scarcity training data unsupervised corpus based approaches could favored supervised ones word sense disambiguation tasks. similar eﬀorts area include work latent dirichlet allocation topic models extract global context topic feature along baseline features. another technique uses clustering based approach wordnet external resource disambiguation without relying training data disambiguate polysemous word text document document topic distribution represent context. document topic distribution probabilistic distribution document topics. assumption that given word senses topic distribution language-independent totally unsupervised computationally cheap system compare performance systems participating semeval- task expect degradation precision simple approach granularity senses becomes ﬁner; degrading sensitivity mapping topics space senses space. note simple approach fail multiple senses word appear document; since senses represented topic distribution document clustered cluster. system language-independent system. used topic model knowledge training testing corpus language. unlike systems doesn’t make part speech features language dependent require annotated training data. features used topics distribution bag-of-words containing ambiguous word. first target polysemous word train mallet parallel topic model implementation training instances word. trained topic model infer topics distribution test instances word. k-topics topic model topics distribution represented point k-dimensional topic space. points clustered diﬀerent clusters representing word sense. used mallet’s k-means clustering algorithm cosine similarity measure distance different topic distributions topic space. v-measure used unsupervised evaluation. harmonic mean homogeneity completeness. homogeneity measure degree formed cluster consists data points belong single gold standard class deﬁned below. system described earlier tested semeval- task data participated task semeval- sense induction process cases. running main experiments wanted number topics used topic model could aﬀect performance system. tested system semeval- data using diﬀerent values shown table found v-measure f-score values increase increasing dimensions added topic space diﬀerent senses k-dimensional space unfold. trend stops next evaluated performance system semeval- task data. since training data provided task used unannotated version test instances create topic model. target word trained topic model given test instances. used generated model’s inferencer topics distribution them. distributions clustered topic space using k-means algorithm cosine similarity measure used evaluate distances distributions. results experiment shown table system took part main semeval task unsupervised evaluation system second highest v-measure value words. break obtained v-measure f-scores shown table analyze performance system examined clustering target noun word promotion diﬀerent senses system. compared classes word answer provided task organizers. objective comparison k-means clustering algorithm equal number classes. even though number formed clusters aﬀects performance system assume number senses known analysis. focus ability algorithm cluster similar senses together. graphical comparison given figure target noun word promotion instances four senses. lower four rectangles figure represent four diﬀerent classes upper four rectangles represent four clusters created system. three four pending topic words classiﬁed either belonging cluster cluster cluster cluster topic model unable detect extract topic words encourage sense word. finally lack enough training instances sense promotional issue newspaper clustering topics distributions global context polysemous words topic space induce sense cheap require annotated data language-independent. even though clustering produced system fully conform senses given classes seen analyzed example given earlier clustering carried diﬀerent senses. case sense captured topic model instead cues instances context used cluster accordingly. induced clustering noise though. simple approach used cheap sense induction languages tagger created yet. system second highest v-measure score semeval- task achieves good trade-oﬀ between performance cost.", "year": 2013}