{"title": "A-NICE-MC: Adversarial Training for MCMC", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Existing Markov Chain Monte Carlo (MCMC) methods are either based on general-purpose and domain-agnostic schemes which can lead to slow convergence, or hand-crafting of problem-specific proposals by an expert. We propose A-NICE-MC, a novel method to train flexible parametric Markov chain kernels to produce samples with desired properties. First, we propose an efficient likelihood-free adversarial training method to train a Markov chain and mimic a given data distribution. Then, we leverage flexible volume preserving flows to obtain parametric kernels for MCMC. Using a bootstrap approach, we show how to train efficient Markov chains to sample from a prescribed posterior distribution by iteratively improving the quality of both the model and the samples. A-NICE-MC provides the first framework to automatically design efficient domain-specific MCMC proposals. Empirical results demonstrate that A-NICE-MC combines the strong guarantees of MCMC with the expressiveness of deep neural networks, and is able to significantly outperform competing methods such as Hamiltonian Monte Carlo.", "text": "existing markov chain monte carlo methods either based generalpurpose domain-agnostic schemes lead slow convergence problem-speciﬁc proposals hand-crafted expert. paper propose anice-mc novel method automatically design efﬁcient markov chain kernels tailored speciﬁc domain. first propose efﬁcient likelihood-free adversarial training method train markov chain mimic given data distribution. then leverage ﬂexible volume preserving ﬂows obtain parametric kernels mcmc. using bootstrap approach show train efﬁcient markov chains sample prescribed posterior distribution iteratively improving quality model samples. empirical results demonstrate a-nice-mc combines strong guarantees mcmc expressiveness deep neural networks able signiﬁcantly outperform competing methods hamiltonian monte carlo. variational inference monte carlo methods approaches deal complex probability distributions machine learning. former approximates intractable distribution solving variational optimization problem minimize divergence measure respect tractable family. latter approximates complex distribution using small number typical states obtained sampling ancestrally proposal distribution iteratively using suitable markov chain recent progress deep learning vastly advanced ﬁeld variational inference. notable examples include black-box variational inference variational autoencoders enabled variational methods beneﬁt expressive power deep neural networks adversarial training allowed training families implicit generative models efﬁcient ancestral sampling. mcmc methods hand beneﬁted much recent advancements. unlike variational approaches mcmc methods iterative nature naturally lend expressive function approximators even evaluating existing mcmc technique often challenging natural performance metrics intractable compute deﬁning objective improve performance mcmc easily optimized practice large parameter space difﬁcult problem address limitations introduce a-nice-mc method training ﬂexible mcmc kernels e.g. parameterized using neural networks. given kernel view resulting markov chain implicit generative model i.e. sampling efﬁcient evaluating likelihood intractable. propose adversarial training effective likelihoodfree method training markov chain match target distribution. first show used learning setting directly approximate data distribution. approach train markov chain sample efﬁciently model prescribed analytic expression classic case mcmc techniques. leverage ﬂexible volume preserving models bootstrap technique automatically design powerful domain-speciﬁc proposals combine guarantees mcmc expressiveness neural networks. finally propose method decreases autocorrelation increases effective sample size chain training proceeds. demonstrate trained operators able signiﬁcantly outperform traditional ones hamiltonian monte carlo various domains. time-homogeneous stochastic transition kernel parametrized initial distribution particular assume deﬁned implicit generative model auxiliary random variable deterministic denote distribution markov chain transformation irreducible positive recurrent unique stationary distribution assume case parameters target distribution data distribution posterior think stochastic generative model used efﬁciently produce samples certain characteristics allowing efﬁcient monte carlo estimates. consider settings specifying target distribution. ﬁrst learning setting analytic expression access typical samples {si}m second case analytic expression possibly normalization constant access samples. cases discussed sections respectively. assuming stationary distribution exists value typically intractable compute. time also intractable since involves integration marginal distribution possible paths however directly obtain samples close large enough aligns well idea generative adversarial networks likelihood free method requires samples model. generative adversarial network framework training deep generative models using player minimax game. generator network generates samples transforming noise variable discriminator network trained distinguish fake samples generator real samples given data distribution formally deﬁnes following objective setting could assume empirical distribution samples choose state markov chain steps good approximation large enough. however optimization difﬁcult know reasonable advance gradient updates expensive backpropagation entire chain. intuitively ﬁrst condition encourages markov chain converge towards relatively short runs second condition enforces ﬁxed point transition operator. instead simulating chain convergence especially time-consuming initial markov chain takes many steps generator would steps average. empirically observe better training times uniformly sampling respectively iteration hyperparameters experiments. experiment distribution images digits faces experiments parametrize autoencoding structure auxiliary variable directly added latent code network serving source randomness hyperparameter sampling inexpensive evaluating probabilities according generally intractable would require integration starting distribution factored gaussian distribution mean standard deviation mean standard deviation training set. include details ares based dcgan architecture appendix models trained gradient penalty objective wasserstein gans visualize samples generated trained markov chain figures shows consecutive samples chain figure clear related terms high-level properties digit identity model learns move modes dataset instead generating single sample ancestrally. drastically different iterative generative models trained maximum likelihood generative stochastic networks infusion training train specifying particular target xt+. fact maximize discriminator score model choose generate near different mode. investigate frequency various modes stationary distribution consider class-to-class transition probabilities mnist. step transition operator starting real samples class labels classify generated samples cnn. thus able quantify transition matrix labels figure results show class probabilities fairly uniform range although seems mgan objective encourages rapid transitions different modes always case. particular shown figure adding residual connections highway connections existing model signiﬁcantly increase time needed transition modes. suggests time needed transition modes affected architecture choose architecture introduces information bottleneck forces model forget higher chance occur another mode; hand model shortcut connections tends generate close increase autocorrelation hinder performance samples used monte carlo estimates. consider setting target distribution speciﬁed analytic expression known energy function normalization constant equation might intractable compute. form common bayesian statistics computational physics graphics compared setting section additional challenges ideas markov chain monte carlo literature satisfy ﬁrst condition guarantee θ}∞t= asymptotically converge speciﬁcally require transition operator satisfy detailed balance condition condition satisﬁed using metropolis-hastings sample ﬁrst obtained proposal distribution gθ|x) accepted following probability therefore resulting transition kernel expressed tθ|x) gθ|x)aθ|x) shown stationary idea optimize good proposal gθ|x). directly equation attempt optimize mgan objective unfortunately differentiable setting similar policy gradient optimization reinforcement learning. principle score function gradient estimators could used case; experiments however approach leads extremely acceptance rates. initialization ratio gθ)/gθ|x) extremely leads acceptance rates trajectories informative training. might possible optimize directly using sophisticated techniques literature introduce alternative approach based volume preserving dynamics. gain intuition method introduce hamiltonian monte carlo volume preserving models widely applicable mcmc method introduces auxiliary velocity variable gθ|x). proposal ﬁrst draws obtains simulating dynamics corresponding hamiltonian acceptance computed using distribution acceptance probability v)/p since v)/gθ safely discard transition since independent. return case proposal parametrized neural network; could satisfy equation could signiﬁcantly improve acceptance rate compared reinforce setting. fortunately design proposal using volume preserving model case volume preserving model determinant jacobian one. models constructed using additive coupling layers ﬁrst partition input parts deﬁne mapping expressive function neural network. stacking multiple coupling layers model becomes highly expressive. moreover forward transformation backward transformation easily derived. family models called non-linear independent components estimation crucial components. introduction auxiliary variable prevents random walk behavior; symmetric proposal equation allows step consider particular simulate hamiltonian dynamics twice starting always return auxiliary variables easily integrated neural network proposals. however hard obtain symmetric behavior. proposal deterministic hold condition difﬁcult achieve therefore introduce proposal satisﬁes equation preventing random walk practice resampling every step. figure sampling process a-nice-mc. step proposal executes high probability regions guide towards tend reject high probability regions operations reasonable probability accepted. given nice proposal acceptance step guarantees stationary distribution ratio v)/p still lead acceptance rates unless carefully chosen. intuitively would like train proposal produce samples likely although proposal non-differentiable w.r.t. require score function gradient estimators train fact bijection samples high probability regions training train reach target distribution pdp. mgan objective equation minimize distance distribution generated prior distribution mgan objective objective measures divergence distributions parameter balance factors; experiments divergence transition operator includes trained nice proposal followed metropolis-hastings step call resulting markov chain adversarial nice monte carlo sampling process illustrated figure intuitively lies high probability region propose state another high probability region. low-probability probability region would move closer target opposite. however step bias process towards high probability regions thereby suppressing randomwalk behavior. main remaining challenge direct access samples order train according adversarial objective equation whereas case section dataset samples data distribution. order retrieve samples train model bootstrap process quality samples used adversarial training increase time. obtain initial samples running slow mixing operator stationary distribution starting arbitrary initial distribution samples train model obtain samples trained transition operator tθi; repeating process obtain samples better quality turn lead better model. important metric evaluating mcmc algorithms effective sample size measures number effective samples obtain running chain. samples mcmc methods i.i.d. higher would like samples independent possible case training nice proposal objective equation lead high autocorrelation even though acceptance rate reasonably high. coupling layer contains residual connections input output; shown section models tend learn identity mapping empirically high autocorrelation. propose pairwise discriminator reduce autocorrelation improve ess. instead scoring sample time discriminator scores samples time. real data draw independent samples bootstrapped samples; fake data draw either drawn data distribution samples running chain steps sample running chain steps similar samples drawn original mgan objective. optimal solution would match distributions target distribution. moreover correlated discriminator able distinguish real fake pairs model forced generate samples little autocorrelation. details included appendix pairwise discriminator conceptually similar minibatch discrimination layer difference provide correlated samples fake data provides independent samples might similar. demonstrate effectiveness pairwise discriminator show example image domain figure model shortcut connections trained without pairwise discrimination clear variety samples pairwise discriminator signiﬁcantly reduces autocorrelation. code reproducing experiments available https//github.com/ermongroup/a-nice-mc. demonstrate effectiveness a-nice-mc ﬁrst compare performance several synthetic energy functions ring ring densities illustrated figure ring single connected component high-probability regions performs well; ring selected demonstrate cases fails move across modes using gradient information. a-nice-mc performs well cases. hyperparameters experiments particular consider three coupling layers update respectively. ensure could affect updates table performance mcmc samplers measured effective sample size higher better averaged runs different initializations. appendix formulation appendix benchmark running time methods. figure mean absolute error estimating statistics ring w.r.t. simulation length. averaged chains. density plots methods. initial distribution gaussian centered origin overestimates densities rings towards center. ring report distance sample origin indicates mixing across different rings. four scenarios performed well ring; cases modes distant other little gradient information move modes. hand a-nice-mc able freely move modes since nice proposal parametrized ﬂexible neural network. ring example demonstrate results. assume initial distribution optimize maximum likelihood. methods resulting particles estimate shown figures fails large true estimated statistics. also explains lower ring table another reasonable measurement consider gelman’s diagnostic evaluates performance across multiple sampled chains. evaluate rings domain using chains samples burn-in steps sample. gives value whereas a-nice-mc gives value suggest even chains succeed estimating distribution reasonably well. training increase ess? show figure cases increases training iterations bootstrap rounds also indicates using pairwise discriminator effective reducing autocorrelation. admittedly training introduces additional computational cost could utilize obtain samples initially initial cost amortized thanks improved ess. example ring domain reach approximately seconds sample trained a-nice-mc catch less seconds. next demonstrate effectiveness a-nice-mc bayesian logistic regression posterior single mode higher dimensional space making strong candidate task. however order achieve high samplers typically many leap frog steps require gradients every step inefﬁcient computationally expensive. a-nice-mc requires running obtain proposal much cheaper computationally. consider three datasets german heart australian evaluate lowest across covariates obtain samples burn-in samples. leap frog steps tune step size best possible. a-nice-mc hyperparameters experiments although outperforms a-nice-mc terms nice proposal less expensive compute proposal almost order magnitude leads higher second best knowledge paper presents ﬁrst likelihood-free method train parametric mcmc operator good mixing properties. resulting markov chains used target empirical analytic distributions. showed using novel training objective leverage ﬂexible neural networks volume preserving models obtain domain-speciﬁc transition kernels. kernels signiﬁcantly outperform traditional ones based elegant simple general-purpose analytic formulas. hope ideas allow bridge mcmc neural network function approximators similarly black-box techniques context variational inference combining guarantees mcmc expressiveness neural networks unlocks potential perform fast accurate inference high-dimensional domains bayesian neural networks. would likely require gather initial samples methods variational inference since chances untrained proposals stumble upon energy regions diminished curse dimensionality. therefore would interesting whether could bypass bootstrap process directly train leveraging properties models. another promising future direction investigate proposals rapidly adapt changes data. case infer latent variable particular data point variational autoencoders. believe possible utilize meta-learning algorithms data-dependent parametrized proposals. research funded intel corporation grants authors would like thank daniel lévy discussions nice proposal proof yingzhen suggestions training procedure aditya grover suggestions implementation. goodfellow pouget-abadie mirza warde-farley ozair courville bengio generative adversarial nets advances neural information processing systems freitas højen-sørensen jordan russell variational mcmc proceedings seventeenth conference uncertainty artiﬁcial intelligence morgan kaufmann publishers inc. jakob marschner manifold exploration markov chain monte carlo technique rendering scenes difﬁcult specular transport transactions graphics vol. abadi agarwal barham brevdo chen citro corrado davis dean devin tensorﬂow large-scale machine learning heterogeneous distributed systems arxiv preprint arxiv. assume target distribution markov chain monte carlo sampler produces correlated samples {xi}n suppose estimating mean sampling; assume increasing number samples reduce variance estimate. proposition consider sequence ergodic markov chains state space deﬁne probability distribution time step stationary distribution n-th markov chain n-th chain. following conditions hold ﬁrst inequality uses fact pdtv< second inequality true assumption third inequality uses fact logρ logρ ρt−b δ/\u0001. hence sequence {πn}∞n= converges total variation. moreover convergence total variation distance equivalent convergence jensen-shannon divergence gans attempt minimize motivates gans achieve conditions proposition suggests optimization criterion look satisﬁes conditions proposition translates equation indicator function ﬁrst equality deﬁnition second equality true since volume preserving third equality reparametrization conditions last equality uses deﬁnition volume preserving determinant jacobian code available https//github.com/ermongroup/markov-chain-gan. denote fully connected layer neurons. ‘convd denote convolutional layer ﬁlters size stride ‘deconvd denote transposed convolutional layer ﬁlters size stride following model generate figure bottom ﬁgure figure residual connection input second layer decoder outputs ﬁrst layers decoder encoder highway connection input image output decoder since runtime results depends type machine language low-level optimizations make fair comparison a-nice-mc tensorflow code written executed tensorflow optimization computation graphs tensorflow wall-clock time seem exactly linear cases even force program thread cpu. wall-clock time affected aspects batch size number steps. wall-clock time relatively linear respect number steps exactly linear respect batch size. given ﬁxed number steps wall-clock time constant batch size lower threshold increases approximately linearly. perform speed benchmarking methods select batch size value around threshold order prevent signiﬁcant under-estimates efﬁciency. found graph much optimized batch size determined execution. therefore perform benchmarks optimized graph specify batch size prior running graph. energy functions batch size bayesian logistic regression batch size experiments hyperparameters a-nice-mc hmc. sample chain burn-in steps evaluate samples next steps. leapfrog steps step size a-nice-mc consider three coupling layers updates respectively. motivation behind particular architecture ensure could affect updates coupling layer select function one-layer neurons. discriminator three layer neurons each. similar settings section gradient penalty method train model. bootstrapping ﬁrst collect samples running nice proposal untrained every iterations replace half samples samples latest trained model. models trained adam iterations batch size learning rate tuned step size parameter achieve best possible dataset german heart australian a-nice-mc consider three coupling layers updates respectively; dimensions experiments. one-layer neurons bottom coupling layer two-layer neurons middle layer. discriminator three layer neurons each. training bootstrapping strategy appendix models trained adam iterations batch size learning rate following ﬁgure illustrates architecture details a-nice-mc experiments. batch normalization since slows execution network provide much improvement.", "year": 2017}