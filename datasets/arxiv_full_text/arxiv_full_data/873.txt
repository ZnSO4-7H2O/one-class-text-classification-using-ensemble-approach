{"title": "AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction  in Structure-based Drug Discovery", "tag": ["cs.LG", "cs.NE", "q-bio.BM", "stat.ML"], "abstract": "Deep convolutional neural networks comprise a subclass of deep neural networks (DNN) with a constrained architecture that leverages the spatial and temporal structure of the domain they model. Convolutional networks achieve the best predictive performance in areas such as speech and image recognition by hierarchically composing simple local features into complex models. Although DNNs have been used in drug discovery for QSAR and ligand-based bioactivity predictions, none of these models have benefited from this powerful convolutional architecture. This paper introduces AtomNet, the first structure-based, deep convolutional neural network designed to predict the bioactivity of small molecules for drug discovery applications. We demonstrate how to apply the convolutional concepts of feature locality and hierarchical composition to the modeling of bioactivity and chemical interactions. In further contrast to existing DNN techniques, we show that AtomNet's application of local convolutional filters to structural target information successfully predicts new active molecules for targets with no previously known modulators. Finally, we show that AtomNet outperforms previous docking approaches on a diverse set of benchmarks by a large margin, achieving an AUC greater than 0.9 on 57.8% of the targets in the DUDE benchmark.", "text": "deep convolutional neural networks comprise subclass deep neural networks constrained architecture leverages spatial temporal structure domain model. convolutional networks achieve best predictive performance areas speech image recognition hierarchically composing simple local features complex models. although dnns used drug discovery qsar ligand-based bioactivity predictions none models beneﬁted powerful convolutional architecture. paper introduces atomnet ﬁrst structure-based deep convolutional neural network designed predict bioactivity small molecules drug discovery applications. demonstrate apply convolutional concepts feature locality hierarchical composition modeling bioactivity chemical interactions. contrast existing techniques show atomnet’s application local convolutional ﬁlters structural target information successfully predicts active molecules targets previously known modulators. finally show atomnet outperforms previous docking approaches diverse benchmarks large margin achieving greater targets dude benchmark. fundamentally biological systems operate physical interaction molecules. ability determine molecular binding occurs therefore critical discovery medicines furthering understanding biology. unfortunately despite thirty years computational efforts computer tools remain inaccurate routine binding prediction physical experiments remain state binding determination. ability accurately predict molecular binding would reduce time-to-discovery treatments help eliminate toxic molecules early development guide medicinal chemistry efforts paper introduce predictive architecture atomnet help address challenges. atomnet novel regards atomnet ﬁrst deep convolutional neural network molecular binding afﬁnity prediction. also ﬁrst deep learning system incorporates structural information target make predictions. deep convolutional neural networks currently best performing predictive models speech vision dcnn class deep neural network constrains model architecture leverage spatial temporal structure domain. example low-level image feature edge described within small spatially-proximate patch pixels. feature detector share evidence across entire receptive ﬁeld tying weights detector neurons recognition edge depend found within image reduction number model parameters reduces overﬁtting improves discovery generalizable features. local low-level features hierarchically composed network larger complex features insight biochemical interactions similarly local modeled similarlyconstrained machine learning architectures. chemical groups deﬁned spatial arrangement bonding multiple atoms space atoms proximate other. chemical groups interact e.g. hydrogen bonding π-bond stacking strength repulsion attraction vary type distance angle predominantly local effects complex bioactivity features described considering neighboring groups strengthen attenuate given interaction even cases distant atoms rarely affect other enforced locality dcnn appropriate. additionally edge detectors dcnns images applicability detector e.g. hydrogen bonding π-bond stacking invariant across receptive ﬁeld. local biochemical interaction detectors hierarchically composed intricate features describing complex nonlinear phenomenon molecular binding. addition introducing dcnn architecture biochemical feature discovery atomnet ﬁrst deep neural network structure-based binding afﬁnity prediction. recently deep neural networks shown out-perform random forests svms qsar ligand-based virtual screening introduced dahl best performing architecture merck molecular activity kaggle challenge multi-task deep neural network multi-task architecture trains single neural network multiple output neurons predict activity input molecule different assay. because molecules often tested multiple assays mt-dnn architecture combine training evidence among similar prediction tasks work followed untherhiner ramsundar demonstrated mt-dnn technique scales large biochemical databases pubchem bioassays chembl ligand-based techniques including mt-dnn come several limitations. first restricted targets substantial amounts prior data already available such cannot make predictions novel targets. practice creates paradoxical dynamic predictive models offer help precisely targets least require dependence known active ligands also makes difﬁcult show network right right reasons; artifacts training data analogue bias make difﬁcult properly assess accuracy generalizability second existing deep neural networks ligand-based models take molecular ﬁngerprints ecfp input. input encoding limits discovery features compositions pre-speciﬁed molecular structures deﬁned ﬁngerprinting process eliminates ability discover arbitrary features. third model blind target model cannot elucidate potential interactions left unfulﬁlled molecule. limits guidance could provided medicinal chemists optimization molecule. address limitations atomnet combines information ligand information structure target. approach requires locations atom binding site target access information enables model discover arbitrary molecular features. features describe favorable unfavorable interactions ligands targets shown section applied targets binders known model. demonstrate application atomnet model three realistic challenging benchmarks directory useful decoys enhanced benchmark internal dude-like benchmark; benchmark experimentally-veriﬁed inactive molecules. benchmarks provide different complimentary assessment performance; advantages summarized here described detail below. standard benchmark dude permits direct comparisons structure-based binding afﬁnity prediction systems. unfortunately dude speciﬁes test without specifying separate training set; constructing dude-like benchmark ensure overlap training test molecules. finally correctly classifying experimentally-veriﬁed active inactive molecules challenging test structurally similar molecules different labels cases excluded benchmarks using property-matched decoys dissimilarity requirement order presume decoys inactive. dude dude well-known benchmark structure-based virtual screening methods shoichet ucsf methodology dude benchmark fully described mysinger brieﬂy benchmark constructed ﬁrst gathering diverse sets active molecules target proteins. analogue bias mitigated removing similar actives; similar actives eliminated ﬁrst clustering actives based scaffold similarity selecting exemplar actives cluster. then active molecule paired property matched decoys selected similar known actives respect -dimensional physico-chemical descriptors being topologically dissimilar based ﬁngerprints enforcement topological dissimilarity supports assumption decoys likely inactives because chemically different know active. benchmark consists targets actives active. randomly selected targets test designated remaining targets training set. afﬁnity units measured lower target conﬁdence greater equal target annotated binding site scpdb database resolution ligands passed pains ﬁlers promiscuity rules following mysinger ﬁrst grouped target afﬁnities uniprot gene name preﬁx removed targets less active ligands. ﬁltering process yielded actives targets. second active paired selected zinc database similarly mysinger third partitioned data training validation testing sets ﬁrst clustering active ligands target based bemis-murcko scaffolds choosing ligands least apart cluster exemplars. clusters less exemplars discarded. fourth deﬁned test randomly selecting targets corresponding actives decoys. last training partitioned clusters -fold cross validation sets. ﬁnal dataset consists actives decoys targets. experimentally veriﬁed inactives limitation benchmarks based exclude decoys similar active molecules. design decision justify assumption selected decoys likely inactive even without experimental validation. enforced dissimilarity actives decoys means benchmarks lack challenging cases actives inactive molecules highly similar include challenging cases substituting decoys molecules experimentally validated inactives. constructed benchmark similar chembl- replaced inactive molecules. deﬁned molecule inactive measured activity higher ended actives inactives targets partitioned -fold cross-validation sets bemis-murcko clusters. network topology consists input layer followed multiple d-convolutional fullyconnected layers topped logistic-cost layer assigns probabilities active inactive classes. units hidden layers implemented relu activation function input representation input layer receives vectorized versions grids placed co-complexes target proteins small-molecules sampled within target’s binding site. first deﬁne binding site using ﬂooding algorithm seeded bound ligand annotated scpdb database second shift coordinate co-complexes cartesian system originated center-of-mass binding site. third sample multiple poses within binding site cavity. fourth crop geometric data within appropriate bounding box. study used cube centered origin. fifth translate input data ﬁxed-size grid spacing. grid cell holds value represents presence basic structural features location. basic structural features vary simple enumeration atom types complex protein-ligand descriptors splif sift apif last unfold grid ﬂoating point vector. network architecture convolutional layers implemented support parameters ﬁlter size stride padding similar fashion implementation krizhevsky used network architecture input layer described above followed four convolutional layers fully-connected layers hidden units each topped logistic-regression cost layer activity classes. model training training model done using stochastic gradient descent adadelta adaptive learning method backpropagation algorithm mini-batches examples gradient step. attempt made optimize meta-parameters except limitation ﬁtting model memory. training time week nvidia-k gpus. baseline method comparison used smina fork autodock vina baseline evaluation. smina implements improved empirical scoring function minimization routines predecessor freely available gplv license. area receiver operating characteristic logauc report results three benchmarks. indicates classiﬁcation performance measuring area curve true-positive rate versus false-positive rate. value means perfect separation whereas value implies random separation. logauc measurement similar emphasizes early enrichment performance putting weight beginning curve cases correctly classiﬁed rank-ordered list contribute score later ones. here used logarithmic base means weight ﬁrst ranked results equal weight next nonlinearity logauc value makes hard interpret subtract area log-scaled random curve logauc adjusted-logauc hence positive adjustedlogauc values imply better random performance whereas negative ones imply worse random performance. brevity adjusted-logauc logauc interchangeably rest manuscript. table figures summarize results across three different benchmarks. four evaluation data sets atomnet achieves order-of-magnitude improvement smina level accuracy useful drug discovery. tables summarize logauc results respect different performance thresholds. full dude atomnet achieves exceeds targets smina achieves single target approximately benchmark. atomnet achieves better targets smina achieves targets restrict evaluation held-out target subset dude atomnet exceeds targets targets respectively. smina achieves accuracy target targets respectively. atomnet achieves mean median held-out compared achieved smina reducing available mean error expected performance atomnet drops slightly held-out examples whereas smina’s performance not. chembl--pmd dataset atomnet achieves better held-out targets smina achieves zero targets. reduce standard accuracy better atomnet succeeds targets smina succeeds target third benchmark uses inactives instead property-matched decoys seems challenging two. atomnet predicts better targets smina succeeds zero. meeting exceeding atomnet succeeds targets smina succeeds although atomnet smina perform worse previous benchmarks atomnet still signiﬁcantly outperforms smina respect overall early enrichment performances. benchmark uses inactives includes challenging classiﬁcation cases structurally similar molecules different labels cases excluded benchmarks using decoys must structurally dissimilar order presume labelled inactive. additionally atomnet shows good early enrichment performance indicated highly positive logauc values. atomnet outperforms smina respect early enrichment achieving mean logauc compared smina dude- benchmark. visualizing curves illustrate difference logauc measurements respect early enrichment. example figure value target imply mediocre performance. however early enrichment indicated logauc target suggest many actives concentrated rankordered results. similarly target value log-scale plot suggest actives concentrated rank-order list logauc table comparisons atomnet smina dude chembl--pmd chembl-inactives benchmarks. dude- refers held-out targets whereas dude- refers full dataset. filter visualization convolutional layers consist multiple different ﬁlters learn identify speciﬁc locally-related features repeatedly applying ﬁlters across receptive ﬁeld. dealing images visualize ﬁlters verify model capable learning relevant features. example krizhevsky demonstrated ﬁlters ﬁrst convolutional layer model could detect lines edges color gradients. case however easily visualize ﬁlters because ﬁlters -dimensional input channels discrete. example close values result similar colors carbon closer nitrogen oxygen. similar values imply similar functionalities. table number targets atomnet smina exceed given thresholds. example chembl- atomnet achieves better targets chembl- contains targets dude- contains targets dude- contains targets chembl- inactives contains targets. table number targets atomnet smina exceed given adjusted-logauc thresholds. example chembl- atomnet achieves adjusted-logauc better targets chembl- contains targets dude contains targets dude- contains targets chembl- inactives contains targets. overcome limitations take indirect approach. instead directly visualizing ﬁlters order understand specialization apply ﬁlters input data examine location maximally ﬁre. using technique able ﬁlters chemical functions. example figure illustrate locations particular ﬁlter ﬁrst convolutional layer ﬁres. visual inspection locations ﬁlter active reveals ﬁlter specializes sulfonyl/sulfonamide detector. demonstrates ability model learn complex chemical features simpler ones. case ﬁlter inferred meaningful spatial arrangement input atom types without chemical prior knowledge. comparison structure-based methods paper present novel application deep convolutional neural networks bioactivity predictions rather reporting headto-head comparisons structure-based methods. order results context used popular program smina baseline point reference. smina practical advantages fast free active development suitable analyzing large benchmarks timely cost-efﬁcient manner. nevertheless using published work provide broader context comparing atomnet commercial docking algorithms reported literature. common benchmark dude which like smina publicly available widely used. therefore present following comparisons previously described results gabel evaluated surﬂex-dock representative targets dude. median surﬂex-dock compared achieved atomnet. coleman evaluated dock. fully automated manner whole dude benchmark. achieved mean logauc compared logauc allen reported mean dude targets using dock. compared presented atomnet ﬁrst structure-based deep convolutional neural network designed predict bioactivity small molecules drug discovery applications. locally-constrained deep convolutional architecture allows system model complex non-linear phenomenon molecular binding hierarchically composing proximate basic chemical features intricate ones. incorporating structural target information atomnet predict active molecules even targets previously known modulators. atomnet shows outstanding results widely used structure-based benchmark achieving greater targets dude benchmark surpassing previous docking methods.", "year": 2015}