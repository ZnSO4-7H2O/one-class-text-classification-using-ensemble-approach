{"title": "Use of Ensembles of Fourier Spectra in Capturing Recurrent Concepts in  Data Streams", "tag": ["cs.AI", "cs.LG"], "abstract": "In this research, we apply ensembles of Fourier encoded spectra to capture and mine recurring concepts in a data stream environment. Previous research showed that compact versions of Decision Trees can be obtained by applying the Discrete Fourier Transform to accurately capture recurrent concepts in a data stream. However, in highly volatile environments where new concepts emerge often, the approach of encoding each concept in a separate spectrum is no longer viable due to memory overload and thus in this research we present an ensemble approach that addresses this problem. Our empirical results on real world data and synthetic data exhibiting varying degrees of recurrence reveal that the ensemble approach outperforms the single spectrum approach in terms of classification accuracy, memory and execution time.", "text": "research apply ensembles fourier encoded spectra capture mine recurring concepts data stream environment. previous research showed compact versions decision trees obtained applying discrete fourier transform accurately capture recurrent concepts data stream. however highly volatile environments concepts emerge often approach encoding concept separate spectrum longer viable memory overload thus research present ensemble approach addresses problem. empirical results real world data synthetic data exhibiting varying degrees recurrence reveal ensemble approach outperforms single spectrum approach terms classiﬁcation accuracy memory execution time. many real world applications patterns concepts recur time. machine learning applications model capture recognize concept re-occurrence gain signiﬁcant efﬁciency accuracy advantages systems simply re-learn concepts time re-occur. applications include safety time critical requirements need concept re-use support decision making becomes even compelling. auto-pilot systems sense environmental changes take appropriate action avoid disasters smoothly. environmental conditions change appropriate actions must taken shortest possible time interest safety. thus example situation involves occurrence sudden pressure area coupled high winds would require appropriate action keep aircraft steady trajectory. machine learning system coupled ﬂight simulator learn concepts form classiﬁers store repository timely re-use aircraft live ﬂying missions. live ﬂying mode autopilot system quickly re-use stored classiﬁers situations re-occur. additionally live ﬂying mode potentially hazardous situations experienced real world setting abundance applications exhibit recurring behavior stock sales applications timely decision making results improved productivity. research setting data stream environment seek capture concepts occur store highly compressed form repository re-use concepts classiﬁcation need arises future. number challenges need overcome. firstly compression scheme captures concepts using minimal storage required high volatile high dimensional environment. memory overhead prime concern number concepts grow continuously time given unbounded nature data streams. secondly real-world environments concepts rarely ever occur exactly original form mechanism needed recognize partial re-occurrence concepts. thirdly concept encoding scheme needs efﬁcient order support high speed data stream environments. order meet challenges extend work proposed number ways. concepts initially captured using decision trees discrete fourier transform applied encode spectra yielding compressed versions original decision trees. firstly instead encoding concept using fourier spectrum ensemble approach aggregate individual spectra single uniﬁed spectrum. advantages ﬁrst reduction memory overhead. memory reduced fourier coefﬁcients common different spectra combined single coefﬁcient thus eliminating redundancy. second advantage arises ensemble concepts manifest combination previously occurring concepts already present ensemble higher likelihood recognized resulting better accuracy stability large segments data stream. vast literature concept drift detection exists small body work exists exploitation recurrent concepts. methods exist fall broad categories. firstly methods store past concepts models meta-learning mechanism best match concept drift triggered secondly methods store past concepts ensemble classiﬁers. method proposed research belongs second category ensembles remember past concepts. algorithm called reddla presented algorithm designed handle recurring concepts unlabeled data instances. issues explicit domain required concept recurrence interval. issue high memory overhead. future rate change. whenever difference observed estimated rates change threshold classiﬁer best represents current concept stored repository. experimentation stagger data showed proposed approach outperformed flora method classiﬁcation accuracy re-emergence previous concepts stream. ramamurthy bhatnagar ensemble approach based classiﬁers global ensemble classiﬁers built dynamically collection classiﬁers none existing individual classiﬁers able meet minimum accuracy threshold based user deﬁned acceptance factor. whenever ensemble accuracy falls accuracy threshold updated classiﬁer trained current chunk data. another ensemble based approach katakis proposed mapping function applied data stream instances form conceptual vectors grouped together clusters. classiﬁer incrementally built cluster ensemble formed based classiﬁers. experimentation usenet data showed ensemble approach produced better accuracy simple incremental version naive bayes classiﬁer. gomes used layer approach ﬁrst layer consisting classiﬁers trained current concept second layer contains classiﬁers created past concepts. concept drift detector ﬂags warning state triggered incoming data instances buffered prepare classiﬁer. number instances warning window threshold classiﬁer layer used instead re-using classiﬁers layer major issue method validity assumption explicit contextual information available data stream. gama kosina also proposed layered system designed delayed labelling similar respects gomes approach. approach gama kosina pair base classiﬁer ﬁrst layer referee second layer. referees learn regions feature space corresponding base classiﬁer predicts accurately thus able express level conﬁdence base classiﬁer respect newly generated concept. base classiﬁer receives highest conﬁdence score selected provided user deﬁned ratio parameter; classiﬁer learnt. just-in-time classiﬁers solution proposed allipi deal recurrent concepts. concept change detection carried classiﬁcation accuracy well observing distribution input instances. drawback model designed abrupt drifts weak handling gradual changes. recently sakthithasan pears used discrete fourier transform encode decision trees highly compressed form future use. showed encoding effective improving classiﬁcation accuracy memory usage processing time general. maintains pool fourier spectra decision tree forest parallel. decision tree forest dominates model none existing fourier spectra matches current concept otherwise classiﬁcation done best performing fourier spectrum. discrete fourier transform vast area application diverse domains time series analysis signal processing image processing turns park kargupta show effective terms classiﬁcation applied decision tree model. kargupta working domain distributed data mining showed fourier spectrum fully captures decision tree algebraic form meaning fourier representation preserves classiﬁcation power original decision tree. kargupta showed fourier spectrum given decision tree approximated computing small number order coefﬁcients thus reducing storage overhead. suitable thresholding scheme place fourier spectrum consisting order coefﬁcients thus ideal mechanism capturing past concepts. furthermore classiﬁcation unlabeled data instances done directly fourier domain well known inverse deﬁned expression used recover classiﬁcation value thus avoiding need expensive reconstruction decision tree fourier spectrum. inverse fourier transform given instance transformed binary vector symbolic mapping actual attribute value mapped value classiﬁed using inverse function equation suppose instance classiﬁcation value calculated follows modiﬁcation continuous basis. pool maintains collection fourier spectra encoded hoeffding trees best classiﬁcation accuracy across forest particular concept drift point. hoeffding tree fourier spectrum equipped instance drift detector. research seqdrift drift detector default option. fourier spectrum represented individually fourier concept tree work aggregate spectra maintain pool ensemble spectra known ensemble pool aggregation process carried different ways. algorithm aggregates reference similarity based accuracy whereas aggregates based structural similarity. describe process algorithm discuss generated special case. algorithm input energy threshold accuracy threshold input structural similarity threshold output best performing classiﬁer suits current concept randomly selected hoeffding tree model forest read instance data stream step hoeffding tree rooted attribute created. step tree randomly chosen best performing classiﬁer next empty pool created step incoming instance routed trees forest pool concept drift signal triggered drift detector instance attached best classiﬁer ﬁrst concept drift point best performing tree transformed fourier spectrum energy thresholding method assumption best tree highest accuracy helps locate conceot changes precisely trees tree captures concepts greater detail others thus highest accuracy. thereafter stored repository reuse whenever concept recurs. spectra stored repository ﬁxed nature intention capture past concepts. best performing classiﬁer identiﬁed shown step subsequent drift point best classiﬁer pool classiﬁer applied classify data instances best classiﬁer emerges subsequent drift point. otherwise best classiﬁer forest tests made prior applying reduce redundancy pool. firstly check whether difference accuracy best hoeffding tree forest best performing fourier spectrum pool greater user deﬁned threshold test succeeds applied produce furthermore second test made ensure fourier representation already pool test also passed algorithm aggregation called integrate selected existing fourier spectrum plant separate fourier spectrum pool algorithm aggregation searches spectrum greatest structural similarity currently generated spectrum step evaluates degree disagreement classiﬁcation decisions data instance degree disagreement existing ensemble pool easily updated incrementally algorithm using single counter variable ensemble removes steps algorithm aggregation. alternative aggregating structurally similar spectra used accuracy measure deﬁnes similarity. similarity based accuracy leads aggregating similar performing fourier spectra together. thus test hypothesis aggregation spectra based structural similarity produces better performing trees based accuracy. sakthihasan showed classiﬁcation accuracy sensitive spectral energy given total squares coefﬁcients); higher energy greater classiﬁcation accuracy general. thresholding spectral energy thus effective method obtaining compact spectrum retaining classiﬁcation power inherent decision tree counterpart. solution described iterate order spectrum compute ratio energy orders respectively. thresholding implemented order ratio less small tolerance value drawback simple solution guarantee cumulative energy order contains proportion total energy. fortunately solution exists problem. theorem proves equals thus total energy computed efﬁciently without enumerate single coefﬁcients. proof case prove result exactly combination exists discuss extension case combination present. withloss generality illustrate proof wild card characters occur beginning vector occur position simple reordering operation used without affecting validity proof. suppose cardinality attributes reordering next optimization applied optimize fourier basis function calculation equation especially wildcard characters present path vector hoeffding tree. proof case prove result exactly combination exists discuss extension case combination present. withloss generality illustrate proof wild card characters occur beginning vector occur position simple reordering operation used without affecting validity proof. suppose cardinality attributes reordering dimensionality dataset. order realize full beneﬁts ensemble learning fourier domain aggregate individual spectra represent different concepts manifest different points stream. denotes ensemble spectrum produced individual spectra produced different points stream; classiﬁcation accuracy corresponding spectrum partitions zero coefﬁcients spectrum park used ensemble learning fourier spectra setting different ours. considered distributed system node producing spectrum aggregation taking place central node. setting data stream environment spectra advance still principle distributive nature linear weighted expressed hence expression implementing ensemble learning essential difference. direct application using entire attributes comprising data would inefﬁcient. exponential number coefﬁcients respect number attributes could cause bottleneck high dimensional environments. practical solution populate spectrum using attributes present given tree. major advantage approach smaller computational overhead fourier transform effort directly proportional size attribute used. initial spectrum extended full length spectrum containing attributes absent given tree using simple transformation scheme. deﬁne attribute decision tree subset attributes deﬁne splits tree. suppose integrating spectra trees attribute sets respectively. apply obtain using attributes attribute attributes similarly generate using attributes deﬁned order integrate need account differences attribute sets this take expand spectrum incorporating attributes expansion deﬁned single operation schema instance spectrum expand spectrum adding attribute index positions coefﬁcient value expansion remain classiﬁcation value added index positions remains unchanged. position integrate spectra produced localized attributes. essentially means efﬁcient method implementing ensemble learning using expression main focus study assess effectiveness ensemble approach vis-a-vis respect classiﬁcation accuracy memory consumption processing speed tolerance noise. also assessed sensitivity ep’s accuracy signiﬁcant factors pool size impact drift detector. experimentation done following parameter values experimented rotating hyperplane data generator commonly used drift detection recurrent concept mining. dataset generated within data stream tool injected concept recurrence stream known points could evaluate capabilities recognize exploit recurrences. dataset different concepts generated spanned instances occurred total times different points stream. order challenge concept recognition process added noise inverting class labels randomly selected instances. flight data dataset generated nasa’s fltz ﬂight simulator designed simulate ﬂight conditions experienced commercial ﬂights. consists separate ﬁles containing data single ﬂight four scenarios take climb cruise landing. data recorded every second data instance produced. velocity feature chosen class feature needs adjusted order maintain aircraft stability various maneuvers take landing. velocity discretized binary outcomes down depending directional change moving average window size data instances. previous research fourier spectrum revealed accuracy memory advantages meta learning approaches employed gama kosina storing past concepts repository details advantages fourier approach experimentation reader referred focus comparative study ensemble approach versus single spectrum approach. mind designed three types experiments. accuracy critical performance measure many practical applications. dynamic nature data streams classiﬁcation accuracy current concept taken performance measure. figure presents accuracy values algorithms equal-sized sub-divisions stream. also present overall mean standard deviations accuracy taken across entire stream dataset. shows individual accuracies across segments overall accuracy across entire stream consistent other. metact uses referee based strategy found worst performing algorithm datasets. contrast outperforms algorithms general followed fct. results show clearly based methods superior dynamic data stream environment. exploit aggregation fourier spectra hence challenged memory constrained environment number models stored reuse limited. figure depicts performance environment memory severely limited. introduces large burden re-learn concepts change. resilient small pool sizes given concept recurs approximated linear combination spectra embedded ensemble waveform arbitrary shape approximated large enough sine functions signal processing. examining model usage statistics times higher model re-use flight dataset. corresponding value dataset. provides empirical support claim aggregation-based model signiﬁcant advantage reducing degree relearning. rotating hyperplane known recurrence points advantage counterparts explicit. display stream segment third round concept occurrences spanning concepts. intervals represent second recurrence concept figure shows outperforms concepts; metact concepts; cbdt concepts. next aspect memory constrained environment memory consumption assessed following section. memory consumption inﬂuenced degree generalizability given algorithm. greater degree generalizability promotes higher re-use reduces number spectra need stored repository achieve given level classiﬁcation accuracy. context interesting compare consumption contrasting model re-use characteristics. table presents average memory consumption pool entirety dataset. mentioned section algorithms table components forest repository pool. memory consumed forest distinguishing factor marginal difference algorithms thus focus repository pool. without exception consumed least memory compared algorithms. expected structurally examines instance vectors aggregates similar vectors together. hand structural similarity guaranteed structurally different spectra producing similar accuracy could chosen candidates aggregated thus resulting larger spectra. table provides evidence support premise memory consumed higher lower fct. average datasets achieved reduction memory consumption relation fct; corresponding ﬁgure electricity represents signiﬁcant beneﬁt applying aggregation fourier space. processing speed dependent variety factors maintaining classifying relatively larger number fourier spectra compared aggregation generalize models thus reducing re-learning need application ﬁnally computational overheads aggregation. therefore section assesses trade single aggregated fourier approaches terms processing speed. table shows fastest time. even though potential faster simple aggregation strategy suffers inappropriate aggregations introduce instability thus triggering drift points counterpart. hand efﬁciently structural similarity comparison incrementally updating simple counters remembers number disagreements classiﬁcation current winner tree every fourier spectra pool. hand although aggregation strategy requires computational effort effort compensated stability triggers fewer false drift alarms either fct. therefore experiment demonstrates expensive operation aggregation applied appropriately yield direct processing speed advantage period time. algorithms work well noise-free environments fail noisy environments lack ability generalize data removing minor variations often correspond noise. application mentioned earlier extracts signiﬁcant coefﬁcients ignoring minor coefﬁcients capture noise inherent data. shown application provides robustness noisy environment opposed non-dft based approach metact. therefore experiment aimed testing whether aggregation added advantage non-aggregation based method fct. figure shows percentage accuracy decrease noise levels relative accuracy original flight dataset. clear decrease accuracy higher noise level. interesting higher tolerance noise compared fct. intervals noise found lesser decrease counterpart. similarly noise level fraction tied performance intervals. again metrics tracked superior performance explained terms power generalize making robust effects noise next examine sensitivity parameters signiﬁcantly affect performance. superiority algorithms study conﬁned algorithm. please refer sensitivity analysis fct’s parameters. experiment contrasted classiﬁcation accuracy different ends pool size scale namely context flight dataset four concepts pool size represents extremely limiting memory environment size represents situation memory plentiful. figure shows accuracy values intervals. interestingly pool size highest accuracy intervals. gain accuracy compared pool sizes respectively. signiﬁcant outcome research. even extreme memory challenged environment achieves best accuracy setting much higher memory capacity. implication ensemble accuracy increases greater diversity resonates research conducted illustrates strength aggregation applied algorithm. memory becomes available pool size fct’s accuracy converges counterpart expected. higher memory setting accommodate spectra pool tailored speciﬁc concepts. drift detector incorrectly triggers change points leads partial learning concept developed classiﬁers stored pool. introduces ﬂuctuations accuracy turn trigger change detections causing even ﬂuctuations cyclic problem. hand drift detector fails detect changes classiﬁers updated timely fashion thus leading poor performance. situation arise drift detector signiﬁcantly high detection delay signaling changes. adwin seqdrift drift detectors shown contrasting properties. seqdrift lower false positive rate adwin similar sensitivity adwin. therefore comparative study largely governed false positive detections. figure reveals seqdrift helped reduce frequency sudden accuracy drops seen adwin latter signaling false changes concepts. segment shown figure gain accuracy using seqdrift entire data set. research proposed novel approach capturing exploiting recurring concepts data streams. optimized derivation fourier spectrum employing mechanisms energy thresholding speeding computation fourier basis functions. research revealed ensemble approach outperformed single spectrum approach thus method choice high speed dynamic environments generate large amounts concepts progression stream. environments would challenged terms memory capacity would forced ﬂush portions repository sooner thus losing ability exploit concept recurrences turn leading loss accuracy. however shown experimentation care needs taken spectra combined naive approach simply combining similarly performing spectra terms accuracy worse maintaining single spectra. showed structural similarity scheme outperformed approaches broad criteria including accuracy robustness noise over-ﬁtting memory consumption processing speed. terms future work promising directions. believe possible reduce computational effort involved deriving spectrum keeping lowest order coefﬁcient leaf node decision tree together residual coefﬁcient captures contribution coefﬁcients node. secondly concept drift point parallelize computation spectrum thread processing incoming instances another thread parallel environment spark framework.", "year": 2015}