{"title": "A Large Dataset to Train Convolutional Networks for Disparity, Optical  Flow, and Scene Flow Estimation", "tag": ["cs.CV", "cs.LG", "stat.ML", "I.2.6; I.2.10; I.4.8"], "abstract": "Recent work has shown that optical flow estimation can be formulated as a supervised learning task and can be successfully solved with convolutional networks. Training of the so-called FlowNet was enabled by a large synthetically generated dataset. The present paper extends the concept of optical flow estimation via convolutional networks to disparity and scene flow estimation. To this end, we propose three synthetic stereo video datasets with sufficient realism, variation, and size to successfully train large networks. Our datasets are the first large-scale datasets to enable training and evaluating scene flow methods. Besides the datasets, we present a convolutional network for real-time disparity estimation that provides state-of-the-art results. By combining a flow and disparity estimation network and training it jointly, we demonstrate the first scene flow estimation with a convolutional network.", "text": "recent work shown optical estimation formulated supervised learning task successfully solved convolutional networks. training so-called flownet enabled large synthetically generated dataset. present paper extends concept optical estimation convolutional networks disparity scene estimation. propose three synthetic stereo video datasets sufﬁcient realism variation size successfully train large networks. datasets ﬁrst large-scale datasets enable training evaluating scene methods. besides datasets present convolutional network real-time disparity estimation provides state-of-the-art results. combining disparity estimation network training jointly demonstrate ﬁrst scene estimation convolutional network. estimating scene means providing depth motion vectors visible points stereo video. royal league task comes reconstruction motion estimation provides important basis numerous higher-level challenges advanced driver assistance autonomous systems. research last decades focused subtasks namely disparity estimation optical estimation considerable success. full scene problem explored extent. partial scene simply assembled subtask results expected joint estimation components would advantageous availability data become even important convolutional networks. dosovitskiy showed optical estimation posed supervised learning problem solved large network. training network created simple synthetic dataset ﬂying chairs proved sufﬁcient predict accurate optical general videos. results suggest also disparities scene estimated convolutional network ideally jointly efﬁciently real-time. missing implement idea large dataset sufﬁcient realism variability train network evaluate performance. table comparison available datasets collection offers annotated data greater data variety existing choice. data fully contiguous dense accurate ground truth. paper present collection three datasets made using customized version open source creation suite blender. effort similar spirit sintel benchmark contrast sintel dataset large enough facilitate training convolutional networks provides ground truth scene ﬂow. particular includes stereo color images ground truth bidirectional disparity bidirectional optical disparity change motion boundaries object segmentation. moreover full camera calibration point positions available i.e. dataset also covers rgbd data. cannot exploit full potential dataset single paper already demonstrate various usage examples conjunction convolutional network training. train network disparity estimation yields competitive performance also previous benchmarks especially among methods real-time. finally also present network scene estimation provide ﬁrst quantitative numbers full scene sufﬁciently sized test set. datasets. ﬁrst signiﬁcant efforts create standard datasets middlebury datasets stereo disparity estimation optical estimation stereo dataset consists real scenes optical dataset mixture real scenes rendered scenes. datasets small today’s terms. especially small test sets heavy manual overﬁtting. advantage stereo dataset availability relevant real scenes especially latest high-resolution version sintel entirely synthetic dataset derived short open source animated movie. provides dense ground truth optical ﬂow. since recently beta testing version disparities available training. training frames sintel dataset largest dataset currently available. contains sufﬁciently realistic scenes including natural image degradations motion blur. authors much effort correctness ground truth frames pixels. makes dataset reliable test comparison methods. however training convolutional networks dataset still small. kitti dataset produced extended contains stereo videos road scenes calibrated pair cameras mounted car. ground truth optical disparity obtained laser scanner combined egomotion data car. dataset contains real data acquisition method restricts ground truth static parts scene. moreover laser provides sparse data certain distance height. recent version models cars ﬁtted point clouds obtain denser labeling include also moving objects. however ground truth areas still approximation. dosovitskiy trained convolutional networks optical estimation synthetic dataset moving chair images superimposed natural background images. dataset large limited single-view optical ﬂow. contain motions publicly available. latest sintel dataset kitti dataset used estimate scene restrictions. occluded areas ground truth scene available. kitti interesting component scene namely motion points missing approximated ﬁtted models cars. comprehensive overview important comparable datasets features given table convolutional networks. convolutional networks proven successful variety recognition tasks image classiﬁcation recent applications convolutional networks include also depth estimaflownet dosovitskiy related work. uses encoder-decoder architecture additional crosslinks contracting expanding network parts encoder computes abstract features receptive ﬁelds increasing size decoder reestablishes original resolution expanding upconvolutional architecture adapt approach disparity estimation. disparity estimation method ˇzbontar uses siamese network computing matching distances image patches. actually estimate disparity authors perform cross-based cost aggregation semi-global matching contrast work ˇzbontar end-to-end training convolutional network disparity estimation task corresponding consequences computational efﬁciency elegance. scene ﬂow. hundreds papers disparity estimation optical estimation scene ﬂow. none uses learning approach. scene estimation popularized ﬁrst time work vedula analyzed different possible problem settings. later works dominated variational methods. huguet devernay formulated scene estimation joint variational approach. wedel followed variational framework decoupled disparity estimation larger efﬁciency accuracy. vogel combined task scene estimation superpixel segmentation using piecewise rigid model regularization. quiroga extended regularizer smooth ﬁeld rigid motion. like wedel decoupled disparity estimation replaced depth values rgbd videos. optical projection world’s motion onto image plane. commonly scene considered underlying motion ﬁeld computed stereo videos rgbd videos. assume successive time frames stereo pair yielding four scene provides images quantities computed case known camera intrinsics extrinsics. cameraindependent deﬁnition scene obtained separate components optical disparity disparfigure given stereo images times arrows indicate disparity relations them. components commonly used estimate scene ﬂow. datasets provide relations including blue arrows. given disparities disparity change almost redundant. thus kitti scene benchmark optical disparities evaluated. case scene reconstructed surface points visible left right frame. especially context convolutional networks particularly interesting estimate also depth motion partially occluded areas. moreover reconstruction motions disparities sensitive noise small error optical lead large error motion vector. created synthetic dataset suite consists three subsets provides complete ground truth scene forward backward direction. used open source creation suite blender animate large number objects complex motions render results tens thousands frames. modiﬁed pipeline blender’s internal render engine produce besides stereo images three additional data passes frame view. provide positions visible surface points well future past positions. pixelwise difference between data passes given camera view results image motion vectors complete scene ground truth seen camera. note information complete even occluded regions since render engine always full knowledge scene points. non-opaque materials notably windows rendered fully transparent avoid consistency problems data. pixel pixel motion vector coplanar imaging plane optical ﬂow. depth directly retrieved pixel’s position converted disparity using known conﬁguration virtual stereo rig. compute disparity change depth component motion vector. example results shown fig. addition rendered object segmentation masks pixel’s value corresponds unique index object. objects consist multiple subparts separate material make render additional segmentation masks pixel encodes material’s index. recently available beta version sintel also includes data. similar sintel dataset also provide motion boundaries highlight pixels least moving objects following holds difference motion frames least pixels boundary segment covers area least pixels. thresholds chosen match results sintel’s segmentation. frames views provide full camera intrinsics extrinsics matrices. used structure motion tasks require camera tracking. rendered image data using virtual focal length wide simulated sensor. driving dataset added wide-angle version using focal length visually closer existing kitti datasets. like sintel dataset datasets also include disclean pass shows coltinct versions every image textures scene lighting image degradations ﬁnal pass additionally includes postprocessing effects simulated depth-of-ﬁeld blur motion blur sunlight glare gamma curve manipulation. main part data collection consists everyday objects ﬂying along randomized trajectories. generated stereo frames ground truth data. instead focusing particular task enforcing strict naturalism rely randomness large pool rendering assets generate orders magnitude data existing option without running risk repetition saturation. data generation fast fully automatic yields dense accurate ground truth figure example scenes flyingthingsd dataset. optical images disparity images disparity change images. best viewed color screen high resolution base scene large textured ground plane. generated static background objects shapes randomly chosen cuboids cylinders. object randomly scaled rotated textured placed ground plane. populate scene downloaded detailed models stanford’s shapenet database. assembled training models testing size also model categories split disjointly. sampled random objects object collection randomly textured every material every object. shapenet object translated rotated along smooth trajectory modeled camera object randomized displacements. camera animated too. prove applicability synthetic datasets scene estimation train convolutional networks. general follow architecture flownet network consists contractive part expanding part long-range links between them. contracting part contains convolutional layers occasional strides resulting total downsampling factor allows network estimate large displacements. expanding part network gradually nonlinearly upsamples feature maps taking account also features contractive part. done series up-convolutional convolutional layers. note data bottleneck network information also pass longrange connections contracting expanding layers. illustration overall architecture refer ﬁgures dosovitskiy disparity estimation propose basic architecture dispnet described table found additional convolutions expanding part yield smoother disparity maps flownet architecture; figure also tested architecture makes explicit correlation layer call dispnetcorr. network images processed separately layer conv resulting features correlated horizontally. consider maximum displacement pixels corresponds pixels input image. compared correlation dosovitskiy correlation computationally much cheaper allows cover larger displacements ﬁner sampling flownet used stride correlation. train joint network scene estimation combining ﬁne-tuning pretrained networks disparity ﬂow. illustrated figure implementation flownet predict left right image dispnets predict disparities ﬁne-tune large combined network estimate disparity additionally disparity change. training. networks trained end-to-end given images input ground truth output. employ custom version caffe make adam optimizer kingma learning rate used divided every iterations starting iteration depth networks direct connections contracting expanding layers lower layers mixed gradients losses active. found using loss weight schedule beneﬁcial start training loss weight assigned lowest resolution loss loss weight figure example frames version kitti benchmark suite driving dataset. show many static moving cars various realistic viewpoints thin objects complex shadows textured ground challenging specular reﬂections. second part dataset made open source blender assets animated short monkaa. regard resembles sintel dataset. monkaa contains nonrigid softly articulated motion well visually challenging fur. beyond that visual similarities sintel; monkaa movie strive amount naturalism. selected number suitable movie scenes additionally created entirely scenes using parts pieces monkaa. increase amount data rendered selfmade scenes multiple versions random incremental changes camera’s translation rotation keyframes. driving scene mostly naturalistic dynamic street scene viewpoint driving made resemble kitti datasets. uses models pool flyingthingsd dataset additionally employs highly detailed tree models warehouse simple street lights. fig. show selected frames driving lookalike frames kitti name conv conv conva convb conva convb conva convb conva convb pr+loss upconv iconv pr+loss upconv iconv pr+loss upconv iconv pr+loss upconv iconv pr+loss upconv iconv pr+loss table speciﬁcation dispnet architecture. contracting part consists convolutions conv convb. expanding part upconvolutions convolutions loss layers alternating. features earlier layers concatenated higher layer features. predicted disparity image output losses training progressively increase weights losses higher resolution deactivate resolution losses. enables network ﬁrst learn coarse representation proceed ﬁner resolutions withlosses constraining intermediate features. data augmentation. despite large training chose perform data augmentation introduce diversity training data almost extra cost. perform spatial transformations chromatic transformations transformation input images. figure interleaving weights flownet dispnets sceneflownet. every layer ﬁlter masks created taking weights network setting weights networks zero respectively outputs network concatenated yield network three times number inputs outputs disparity introducing rotation vertical shift would break epipolar constraint. horizontal shifts would lead negative disparities shifting inﬁnity towards camera. evaluation existing methods. evaluated several existing disparity optical estimation methods dataset. namely disparity evaluate state-of-the-art method ˇzbontar lecun popular semi-global matching approach block matching implementation opencv. results shown together dispnets table endpoint error error measure cases exception kitti test d-all error measure reported kitti evaluation server. percentage pixels estimation error larger larger ground truth disparity pixel. table endpoint errors evaluation sceneflownet presented datasets. driving dataset contains largest disparities ﬂows disparity changes resulting large errors. flyingthingsd dataset contains large ﬂows monkaa contains smaller ﬂows larger disparities. amount data processed training scene network training relatively slow converged yet. expect results improve allow network train longer. quantitative evaluation datasets shown table introduced synthetic dataset containing stereo image pairs ground truth disparity optical scene ﬂow. motivation create sufﬁciently large dataset suitable train convolutional networks estimate quantities dataset also serve evaluation methods. particularly interesting scene lack datasets ground truth. demonstrated dataset indeed used successfully train large convolutional networks network trained disparity estimation state runs times faster. ﬁrst approach training network scene estimation using standard network architecture also shows promising results. convinced dataset help boost deep learning research challenging vision tasks stereo scene estimation.", "year": 2015}