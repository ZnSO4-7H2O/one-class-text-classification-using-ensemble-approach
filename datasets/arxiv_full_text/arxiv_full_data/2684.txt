{"title": "Learning Disentangled Representations with Semi-Supervised Deep  Generative Models", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Variational autoencoders (VAEs) learn representations of data by jointly training a probabilistic encoder and decoder network. Typically these models encode all features of the data into a single variable. Here we are interested in learning disentangled representations that encode distinct aspects of the data into separate variables. We propose to learn such representations using model architectures that generalise from standard VAEs, employing a general graphical model structure in the encoder and decoder. This allows us to train partially-specified models that make relatively strong assumptions about a subset of interpretable variables and rely on the flexibility of neural networks to learn representations for the remaining variables. We further define a general objective for semi-supervised learning in this model class, which can be approximated using an importance sampling procedure. We evaluate our framework's ability to learn disentangled representations, both by qualitative exploration of its generative capacity, and quantitative evaluation of its discriminative ability on a variety of models and datasets.", "text": "variational autoencoders learn representations data jointly training probabilistic encoder decoder network. typically models encode features data single variable. interested learning disentangled representations encode distinct aspects data separate variables. propose learn representations using model architectures generalise standard vaes employing general graphical model structure encoder decoder. allows train partially-speciﬁed models make relatively strong assumptions subset interpretable variables rely ﬂexibility neural networks learn representations remaining variables. deﬁne general objective semi-supervised learning model class approximated using importance sampling procedure. evaluate framework’s ability learn disentangled representations qualitative exploration generative capacity quantitative evaluation discriminative ability variety models datasets. learning representations data fundamental challenges machine learning artiﬁcial intelligence. characteristics learned representations depend intended use. purposes solving single task primary characteristic required suitability task. however learning separate representations every task involves large amount wasteful repetitive effort. representation factorisable structure consistent semantics associated different parts likely generalise task. probabilistic generative models provide general framework learning representations model speciﬁed joint probability distribution data latent random variables representation found considering posterior latent variables given speciﬁc data. learned representation inferred values latent variables depends data also generative model choice latent variables relationships latent variables data. extremes approaches constructing generative models. fully-speciﬁed probabilistic graphical models practitioner decides latent variables present joint distribution relationships them functional form conditional distributions deﬁne model. deep generative models impose assumptions structure model instead employing neural networks ﬂexible function approximators used train conditional distribution data rather specify hand. tradeoffs clear. explicitly constructed graphical model structure form joint distribution ensures latent variables particular semantics yielding disentangled representation. unfortunately deﬁning good probabilistic model hard complex perceptual domains vision extensive feature engineering siddharth necessary deﬁne suitable likelihood function. deep generative models completely sidestep difﬁculties feature engineering. although address learning representations enable better reconstruct data representations always exhibit consistent meaning along axes variation produce entangled representations. approaches considerable merit particularly faced absence side information data often situations aspects variation data desired characterised. bridging challenging. enforce disentangled representation hold different axes variation ﬁxed training johnson combine neural likelihood conjugate exponential family model latent variables. class models efﬁcient marginalisation latent variables performed learning projection onto conjugate exponential family encoder. propose general class partiallyspeciﬁed graphical models probabilistic graphical models modeller needs specify exact relationship subset random variables model. factors left undeﬁned model deﬁnition learned parametrised ﬂexible neural networks. provides ability situate oneself particular point spectrum specifying precisely axes variations information would like extract learning disentangled representations them leaving rest learned entangled manner. subclass partially-speciﬁed models particularly common obtain supervision data subset variables. practice often variation data easy explain therefore annotate whereas variation less clear. example consider mnist dataset handwritten digits images vary terms content style visible right-hand side fig. explicit digit latent variable captures meaningful consistent axis variation independent style; using partially-speciﬁed graphical model means deﬁne digit variable even leaving unspeciﬁed semantics different styles process rendering digit image. fully unsupervised learning procedure generally guarantee inference model classes fact recover digits. however given small amount labelled examples task becomes signiﬁcantly easier. beyond ability encode variation along particular axes also want interpret data different ways. example considering images people’s faces might wish capture person’s identity context lighting conditions faces another. paper introduce recipe learning inference partially-speciﬁed models ﬂexible framework learns disentangled representations data using graphical model structures encode constraints interpret data. present framework context variational autoencoders developing generalised formulation semi-supervised learning dgms enables framework automatically employ correct factorisation objective given choice model latents taken observed. respect work extends previous efforts introduce supervision variational autoencoders introduce variational objective applicable general class models allowing consider graphical-model structures arbitrary dependencies latents continuous-domain latents dynamically changing dependencies. provide characterisation compile partially-supervised generative models stochastic computation graphs suitable end-to-end training. approach allows also amortise inference simultaneously learning network performs approximate inference representations time learn unknown factors model itself. demonstrate efﬁcacy framework variety tasks involving classiﬁcation regression predictive synthesis including ability encode latents variable dimensionality. figure semi-supervised learning structured variational autoencoders illustrated mnist digits. top-left generative model. bottom-left recognition model. middle stochastic computation graph showing expansion node corresponding sub-graph. generative-model dependencies shown blue recognition-model dependencies shown orange. section detailed explanation. right learned representation. vaes class deep generative models simultaneously train probabilistic encoder decoder elements data xn}. central analogy encoding considered latent variable casting decoder conditional probability density parameters distribution output deterministic neural network parameters takes input. placing weak prior decoder deﬁnes posterior joint distribution pθp. inference vaes performed using variational method approximates posterior distribution using encoder whose parameters output network referred inference network recognition network. generative inference networks denoted solid dashed lines respectively graphical model trained jointly performing stochastic gradient ascent evidence lower bound typically ﬁrst term eqφ] approximated monte carlo estimate remaining terms expressed divergence −klp) computed analytically encoder model prior gaussian. paper consider models generative model approximate posterior arbitrary conditional dependency structures involving random variables deﬁned number different distribution types. interested deﬁning architectures subset variables interpretable. variables assume supervision labels available fraction data. additionally retain variables inference performed fully unsupervised manner. keeping central goal deﬁning learning partially-speciﬁed models. running example mnist corresponds classiﬁcation label whereas captures implicit features type handwriting style. class models general models work kingma consider three model designs speciﬁc conditional dependence structure. also require conjugate exponential family model work johnson perform semi-supervised learning class models need deﬁne objective suitable general dependency graphs deﬁne method constructing stochastic computation graph incorporates conditional dependence structure generative model recognition model objective. model’s joint distribution factorises unsupervised supervised collections terms dsup shown graphical model. standard variational bound joint evidence observed data also factorises shown factor corresponding unsupervised part graphical model exactly focus supervised term expanded below incorporating additional weighted component kingma note formulation introduces constant controls relative strength supervised term. joint distribution model implicitly weights terms situations relative sizes dsup vastly different control relative weights terms help ameliorate discrepancies. deﬁnition implicitly assumes evaluate conditional probability considered kingma factorisation qφqφ. derive estimator lsup generalises models arbitrary conditional dependence structure. purposes exposition moment consider case qφqφ. factorisation generating samples requires inference means longer compute simple monte carlo estimator sampling unconditioned distribution moreover also cannot evaluate density order address difﬁculties re-express supervised terms objective note estimator applies conditional dependence structure. suppose deﬁne encoder factorisation qφqφqφ. propose importance weights estimator deﬁned whose objective recover taking weights constants also deﬁne objective analogous used importance-weighted autoencoders compute logarithm monte carlo estimate rather monte carlo estimate logarithm. objective takes form derived moving sums logarithms applying substitution wms/qφ /qφ. construction stochastic computation graph perform gradient ascent objective graphical models onto stochastic computation graph stochastic node forms sub-graph. figure shows expansion simple mnist digits model discrete variable represents underlying digit latent variable interest partial supervision data. unobserved gaussian-distributed variable captures remainder latent information. includes features hand-writing style stroke thickness. generative model assume factorisation pθpp independent prior. recognition model conditional dependency structure disentangle digit label handwriting style generative recognition model jointly form stochastic computation graph containing sub-graph stochastic variable. correspond fully supervised partially supervised unsupervised variables. example graph contains three types subgraphs corresponding three possibilities supervision gradient estimation fully supervised variable compute likelihood generative model neural parameters returns parameters normal distribution unobserved variable compute prior probability conditional probability usual reparametrisation used sample ﬁrst sampling using usual reparametrisation trick partially observed variable also compute probabilities discrete discrete). value treated observed available sampled otherwise. particular example sample using gumbel-softmax relaxation discrete distribution. example fig. illustrates general framework deﬁning vaes arbitrary dependency structures. begin deﬁning node random variable. node specify distribution type parameter function determines probability generative model depends variables network. function constant fully deterministic neural network whose parameters learned data. unsupervised semi-supervised variable must additionally specify function returns parameter values recognition model along sampling procedure. given speciﬁcation computation graph compute importance sampling estimate simply running network forward repeatedly obtain samples unobserved variables. calculate importance weight joint probability semi-supervised variable labels available. estimate optimised respect variables train autoencoder. figure visual analogies mnist data partially supervised labels infer style variable vary label exploration style space label held ﬁxed style varied. visual analogies svhn data partially supervised labels fully supervised. evaluate framework along number different axes pertaining ability learn disentangled representations provision partial graphical-model structures latents weak supervision. particular evaluate ability function classiﬁer/regressor particular latents given dataset learn generative model manner preserves semantics latents respect data generated perform tasks ﬂexible manner variety different models data. experiments choose architecture parameters considered standard type size respective datasets. images concerned employ convolutional architectures employ standard recurrence multi-mnist case. learning used adam learning rate momentumcorrection terms default values. mini batch sizes varied depending dataset used sizes labelled subset dsup. above including details precise parameter values source code including pytorchbased library specifying arbitrary graphical models framework available https//github.com/probtorch/probtorch. begin experiment involving simple dependency structure fact kingma validate performance importance-sampled objective special case recognition network generative models factorise indicated fig. giving importance weights constant model tested it’s ability classify digits perform conditional generation mnist google street-view house numbers datasets. fig. shows generative recognition models digit label denoted partially speciﬁed style factor denoted assumed unobserved variable. figure illustrate conditional generation capabilities learned model show effect ﬁrst transforming given input disentangled latent space style latent variable ﬁxed manipulating digit generative model generate data expected visual characteristics. note results obtained partial supervision labelled data points case mnist labelled data points case svhn. style latent variable taken diagonal-covariance gaussian dimensions respectively. figure shows svhn full supervision. figure illustrates alternate mode conditional generation style latent taken gaussian varied digit held ﬁxed. next evaluate model’s ability effectively learn classiﬁer partial supervision. compute classiﬁcation error label-prediction task datasets results reported table fig. note minor points difference setup method compare always models directly data pre-processing pre-learning data. thus mnist compare figure right classiﬁcation error rates different labelled-set sizes multiple runs supervision rate svhn compare multi-stage process model uses single stage. left classiﬁcation error different labelled sizes supervision rates mnist svhn here scaling classiﬁcation objective held ﬁxed note sparsely labelled data modicum over-representation helps improve generalisation better performance test set. conversely much over-representation leads overﬁtting. model baseline same. however svhn baseline method report errors model; two-stage model involves separate feature-extraction step data learning semi-supervised classiﬁer. results indicate model objective indeed perform setup considered kingma serving basic validation framework. note however perspective achieving lowest possible classiﬁcation error could adopt number alternate factorisations innovations neural-network architectures supervision rate discussed section formulate objective provide handle relative weight supervised unsupervised terms. given unsupervised size supervised size scaling term relative weight γm/. figure shows exploration relative weight parameter mnist svhn datasets different supervised sizes line graph measures classiﬁcation error given starting i.e. line kingma ./ρ. labelled data sparse over-representing labelled examples training help generalisation improving performance test data. experiments part choosing factor provides good results. however expected over-ﬁtting occurs increased beyond certain point. next move complex domain involving generative models faces. here yale dataset processed jampani results fig. seen graphical models experiment fig. dependency structures employed complex comparison previous experiment. interested showing model learn disentangled representations identity lighting evaluate it’s performance tasks classiﬁcation person identity regression lighting direction. note generative model assumes special structure simply specify model latent variables independent prior. previous work assumed generative model latent variables identity lighting shading reﬂectance following relationship pixel data. here wish demonstrate generative model still learns correct relationship latent variables virtue structure recognition model given supervision. note recognition model lighting latent variable continuous domain partially supervise. further encode identity categorical random variable instead constructing pixel-wise surface-normal customary. formulation allows address task predicting identity directly instead applying surrogate evaluation methods figure presents qualitative quantitative evaluation framework jointly learn structured recognition model generative model parameters. figure left exploring generative capacity supervised model manipulating identity lighting given ﬁxed value latent variables. right classiﬁcation regression error rates identity lighting latent variables fully-supervised semi-supervised classiﬁcation direct -out-of- choice whereas comparison error nearest-neighbour loss based inferred reﬂectance. regression loss angular distance. finally conduct experiment extends complexity prior models even further. particularly explore capacity framework handle models stochastic dimensionality number latent variables determined random variable models composed smaller models. conduct experiment domain multi-mnist. apposite choice satisﬁes requirements image varying number individual digits essentially dictates model must learn count image composed exemplars mnist data employ mnist model within multi-mnist model. model structure assume generative recognition networks shown fig. extend models mnist experiment composing stochastic sequence generator loop length random variable. loop iteration generative model iteratively samples digit style uses generate digit image manner earlier mnist example. additionally afﬁne tranformation also sampled digit iteration transform digit images common combined canvas represents ﬁnal generated image using spatial transformer network recognition model predict number digits pixels image. loop iteration deﬁne bernoulli-distributed digit image supervision available compute probability binary cross-entropy manner likelihood term mnist model. supervision available deterministically mean distribution. seen akin providing bounding-boxes around constituent digits supervision labelled data must taken account learning afﬁne transformations decompose multi-mnist image constituent mnist-like images. model design similar used draw recurrent vaes absence canonical multi-mnist dataset created mnist dataset manipulating scale positioning standard digits combined canvas evenly balanced across counts digits. conducted experiments within domain. ﬁrst experiment seek measure well stochastic sequence generator learns count heed paid disentangling latent representations underlying digits. figure left example input multi-mnist images reconstructions. top-right decomposition multi-mnist images constituent mnist digits. bottom-right count accuracy different supervised sizes given dataset size here generative model presumes availability individual mnist-digit images generating combinations sampled afﬁne transformations. second experiment extend model also incorporate pre-trained mnist model previous section allows generative model sample mnist-digit images also able predict underlying digits. also demonstrates leverage compositionality models complex model known simpler model substructure simpler model learned weights dropped directly. count accuracy errors across different supervised sizes reconstructions random inputs decomposition given inputs constituent individual digits shown fig. reconstructions image decompositions shown correspond nested-model conﬁguration. observe able reliably infer counts digits given images able simultaneously reconstruct inputs well constituent parts. paper introduce framework learning disentangled representations data using partially-speciﬁed graphical model structures semi-supervised learning schemes domain variational autoencoders accomplished deﬁning hybrid generative models incorporate structured graphical models unstructured random variables latent space. demonstrate ﬂexibility approach applying variety different tasks visual domain evaluate efﬁcacy learning disentangled representations semisupervised manner showing strong performance. partially-speciﬁed models yield recognition networks make predictions interpretable disentangled space constrained structure provided graphical model weak supervision. framework implemented pytorch library enabling construction stochastic computation graphs encode requisite structure computation. provides another direction explore future extension stochastic computation graph framework probabilistic programming probabilistic programs beyond presented framework permit expressive models incorporating recursive structures higher-order functions. combination frameworks neural networks recently studied ritchie indicating promising avenue exploration. work supported epsrc grant erc--adg -helios epsrc grant seebibyte ep/m/ epsrc/muri grant ep/n/. supported alan turing institute epsrc grant ep/n/. supported darpa ppaml u.s. afrl cooperative agreement fa---. additionally supported intel darpa cooperative agreement fa---.", "year": 2017}