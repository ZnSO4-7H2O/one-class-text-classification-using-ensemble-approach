{"title": "Message Passing Multi-Agent GANs", "tag": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "abstract": "Communicating and sharing intelligence among agents is an important facet of achieving Artificial General Intelligence. As a first step towards this challenge, we introduce a novel framework for image generation: Message Passing Multi-Agent Generative Adversarial Networks (MPM GANs). While GANs have recently been shown to be very effective for image generation and other tasks, these networks have been limited to mostly single generator-discriminator networks. We show that we can obtain multi-agent GANs that communicate through message passing to achieve better image generation. The objectives of the individual agents in this framework are two fold: a co-operation objective and a competing objective. The co-operation objective ensures that the message sharing mechanism guides the other generator to generate better than itself while the competing objective encourages each generator to generate better than its counterpart. We analyze and visualize the messages that these GANs share among themselves in various scenarios. We quantitatively show that the message sharing formulation serves as a regularizer for the adversarial training. Qualitatively, we show that the different generators capture different traits of the underlying data distribution.", "text": "communicating sharing intelligence among agents important facet achieving artiﬁcial general intelligence. ﬁrst step towards challenge introduce novel framework image generation message passing multi-agent generative adversarial networks gans recently shown effective image generation tasks networks limited mostly single generator-discriminator networks. show obtain multi-agent gans communicate message passing achieve better image generation. objectives individual agents framework fold co-operation objective competing objective. co-operation objective ensures message sharing mechanism guides generator generate better competing objective encourages generator generate better counterpart. analyze visualize messages gans share among various scenarios. quantitatively show message sharing formulation serves regularizer adversarial training. qualitatively show different generators capture different traits underlying data distribution. unsupervised learning emerged important facets machine learning research. advent generative adversarial networks become possible harness large amounts unlabeled data form generative model make extremely plausible images target superhuman intelligence create networks learn large quantities data also interact among order learn even compete other. work obtain ﬁrst approaches towards engaging multiple agents towards learning deep unsupervised representations. note recently multiple agents explored sukhbaatar foerster employ deep reinforcement based formulation order achieve shared utility. generative adversarial networks recently seen applications image inpainting interactive image generation brushstrokes image super resolution abstract reasoning diagram generation gans augmented several ways extract structure representations notably chen tuzel dumoulin multi-agent generator based framework elegance applicable applications demonstrate application task unsupervised image generation. work bears close resemblance work adversarial neural cryptography cryptographic system automatically learned based varying objectives three agents alice eve. conceding competing objectives based ideas. multi-agent systems message passing ﬁrst employed foerster model harnessing messages received generator based similar ideas. lazaridou introduced message passing model different agents forcibly made co-operate introduction bottleneck clustering image features show messages images category usually same. work presents ﬁrst forays subject traditional deep unsupervised learning setting rather deep reinforcement setting reward structure discrete training becomes slightly difﬁcult. work present setting multigenerator based generative adversarial networks competing objective function promotes generators compete among apart trying maximally fool discriminator. also analyze conceding objective tries promote generator better itself. also introduce message passing model order make generators aware generations generator targeting hence learn generate better images. message passing model fact emerged bottleneck added order make message generator actually learn meaningful representations messages. hence demonstrate performance message passing model presence three bottlenecks. ﬁrst generators passed samples different noise distributions namely provided samples normal passed samples uniform. message passing model also analyzed objectives introduced competing objective conceding objective understand message generations networks produce situations. models yielded interesting results seen fig. fig. without explicit formulation generators generating images much facial detail generator generating images overall content even obscure objects last image fig. woman wearing eyes covered depicted. interesting observation fig. message interpolation results generators showed process artist takes artistic creation. summary main contributions paper presenting novel framework multi-agent gans comprises multiple generators. introducing objective promotes competition among generators another unsupervised learning generative models made immense progress within remarkably short time notably pioneered major directions variational autoencoders generative adversarial networks efforts made uniﬁcation methods using adversarial autoencoders since variational autoencoder based models based maximum likelihood based objective hence modes remain unexplored. generative adversarial networks received tremendous interest recent times especially radford able show several interesting interpolation based generations even arithmetic properties exists latent space. several applications video generation image manipulation object generation gans underlying generative model. several variants training objective also proposed order stabilize training salimans arjovsky bottou several objective functions proposed minimize divergence different jensen shannon divergence proposed goodfellow instance nowozin experiment various different divergences show improved results. conditional gans technical approach closely related conditional gans mirza osindero generate images based class speciﬁc information reed condition generation text ghosh condition generation previous inputs chen learn special representations latent variables interpretable conditional based model. durugkar also looked upon multi-agent gans model based multiple discriminators rather multiple generators based ensemble based principles rather message passing based objective. tuzel learn joint distribution images coupling pair gans i.e. jointly training pair generator-discriminator initial layers generators shared weights similarly last layers discriminators shared weights. message passing models co-operating agents belief propagation based message passing major learning algorithms employed principal training procedure probabilistic graphical models. paradigm co-operating agents looked upon game theory foerster sukhbaatar introduce formulations co-operating agents message passing model common communication channel respectively. lazaridou recently introduced framework networks work co-operatively introduce bottleneck forces networks pass messages even interpretable humans. competing agents although generative adversarial networks goodfellow modeled adversarial game agents advent competing objective even competing generators generators start venturing slightly different modes underlying noise space exploring greater modes data. work incorporates competition deep ensembles passing gradient best network. abadi andersen formulated neural cryptography based framework adversary alice work co-operatively order hide sensitive information eve. introduction multiple generators another objectives helps understand dynamics system. also introduce version message passing generative adversarial networks several variations pass messages order make generations better. message passing model augmented several bottlenecks encourage generators pass meaningful messages. competing objective competing objective introduced based principle generators also compete better scores generations discriminator. minimization objective function generator conceding objective principle behind introduction objective generators guide order better scores generations discriminator. model similar structure competing objective crucial difference function used. here minimization objective function generator ez∼pz)) d))] message passing message passing model based upon principle messages passed generators make generators explore different subspaces image manifold also provide better training discriminator regularization introducing different types images discriminator. message passing model generator generates images conditioned upon message receives generator noise sampled noise distribution. generators generated respective images common message generator shared parameters takes image input generates message message generated generator’s image passed generator message next iteration. also experimented individual message generators generator common message generator works better messages transferred generators meaningful messages produced network gauge generations generators. minimization objective function generator composed noise obtained distribution message passed message initialized distribution noise. message generator created message generator previous iteration. similarly minimization objective function generator conditioned message passing model generated image passed message generator creates output. output along generator’s input encoded using multilayer perceptron called encoder create message. message conditioned generation input generator encoder create much better messages knows factors generation. objective minimized generator message passing model oblivious input generator received order generate images hence doesn’t give good generations hand conditioned message generation gives much better generations messages also conditioned input output generators. consider three different bottlenecks order force messages meaningful different noise distributions noise generators sampled different distributions. principle behind introduction bottleneck generators would able master modes kinds noise distributions additionally messages forced different mirroring trivial noise distribution initially started with. concretely ormal used training pair generators. conceding objective order generators co-operate pass meaningful messages make better provide model generators’ objective function tries make generator’s generations better scores discriminator passes messages accordingly. objective function minimized generator competing objective order effects competing objective message passing model whether rogue messages passed order better scores generations discriminator provide model message passing gans compete along passing messages. structure message passing condition. objective function minimized generator model architecture details generator discriminator’s architecture unaltered radford change introduction message generator almost identical architecture discriminator modiﬁcation changing number ﬁlters message dimension ﬁnal output. extensive experimentation different dimensions used message best results produced dimension message experiments done classiﬁcation representation image obtained passing real images discriminator employed radford used alongside novel feature representation enabled formulation message generator. interesting aspect message generator never real images generated images generators still feature representation used still gives interesting results. dataset used classiﬁcation examples street view house numbers dataset goodfellow used radford also salimans evaluation techniques. ablation studies performed identify beneﬁts discriminator representation message representation individually well. clustering celebrity dataset used partition faces based type hair categories bald black brown blond gray. images belonging partitions passed message generator representations images message generator. representations reduced dimensions using t-sne represented using different colors. somewhat meaningful clusters start emerging exercise. visualization introduction message passing mechanism visualization done varying messages noise order interpret manifold learnt pair generators. interesting insight emerged interpolation messages showed major content image interpolation noise produced texture changes image. phenomenon would elucidated results analysis section further. classiﬁcation results svhn shown table models’ discriminator representation improved results discriminator representation dcgan radford thus showing proposed models provide regularization training procedure discriminator. non-trivial accuracy obtained message representation never real images interesting phenomena improvement accuracy message alongside discriminator features shows message representation learns complementary features helps overall classiﬁcation task. conceding objective performs better competing objective absence message passing lags behind competing objective message passing introduced well. message passing doesn’t perform well compared conditioned message passing respect experiment performed generators getting noise different noise distributions hence rest message passing experiments conducted conditioned message generator based architecture. clustering described experimental section clustering performed messages visualized using t-sne space. evident clustering results emerge clusters messages based disjoint division hair style. evident fig. messages bald hair style totally separates rest black brown subjective similar message space clusters black hair emerge totally pure. gray hair also separates quite clearly rest. figure noise interpolation competing objective. generations obtained noise interpolation generator move wearing spectacles smiling lady without spectacles. generations seem realistic. generator able capture facial details even direction lightning. figure noise interpolation competing objective. shows generations like animated characters. generator able capture dominating features texture images. noise interpolation done generations cartoon character human version. figure noise interpolation conceding objective. conceding objective generations spike hairs normal hairs black spectacles. also face shifts changes smile. figure noise interpolation conceding objective. generated personalities changing mood smile sadness shock. interpolation noise also changing orientation straight tilted. different noise distribution evident table case different noise distribution condition performs better consider conditioned message passing next bottlenecks figure noise interpolation competing objective conditioned message. generator able learn minute details face later getting artistic able generate angel like image varied color schemes. figure noise interpolation competing objective conditioned message. it’s easy learning detailed features. interpolation done noise ﬁgure goes loose hair tied hair without making strong changes. figure message interpolation competing objective conditioned message. made interpolating messages generator shows ﬁgure changing smiling woman smiling man. direction face pointing also changes. figure message interpolation competing objective conditioned message. shows hasn’t learnt detailed features. generations longer hair shorter ones changes lightning. figure noise interpolation conceding objective conditioned message. change noise lighting condition changing. visible change appearance face. figure noise interpolation conceding objective conditioned message. modeling cartoon ﬁgure band forehead. interpolation noise band changing hair. figure message interpolation conceding objective conditioned message. seems artist adds attributes face beginning left eye. also facial details prominent images. figure message interpolation conceding objective conditioned message. shows generations going young person dense hairs person sparse hairs. direction person looking also changes. presented several novel architectures objectives aimed training multi-agent gans along bottlenecks generators receiving noise different noise distributions competing generators compete other conceding generators tries encourage generator perform better itself. evident experiments models learn meaningful representations. introduction architecture regularizes training discriminator evident improved results discriminator. representations obtained message generator quite valuable evident high accuracy obtained representation even shown real images. goodfellow pouget-abadie mirza warde-farley ozair courville bengio generative adversarial nets. advances neural information processing systems pages ledig theis husz´ar caballero aitken tejani totz wang photo-realistic single image super-resolution using generative adversarial network. arxiv preprint arxiv..", "year": 2016}