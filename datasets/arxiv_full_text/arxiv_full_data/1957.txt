{"title": "Inverse Graphics with Probabilistic CAD Models", "tag": ["cs.CV", "cs.AI", "stat.ML"], "abstract": "Recently, multiple formulations of vision problems as probabilistic inversions of generative models based on computer graphics have been proposed. However, applications to 3D perception from natural images have focused on low-dimensional latent scenes, due to challenges in both modeling and inference. Accounting for the enormous variability in 3D object shape and 2D appearance via realistic generative models seems intractable, as does inverting even simple versions of the many-to-many computations that link 3D scenes to 2D images. This paper proposes and evaluates an approach that addresses key aspects of both these challenges. We show that it is possible to solve challenging, real-world 3D vision problems by approximate inference in generative models for images based on rendering the outputs of probabilistic CAD (PCAD) programs. Our PCAD object geometry priors generate deformable 3D meshes corresponding to plausible objects and apply affine transformations to place them in a scene. Image likelihoods are based on similarity in a feature space based on standard mid-level image representations from the vision literature. Our inference algorithm integrates single-site and locally blocked Metropolis-Hastings proposals, Hamiltonian Monte Carlo and discriminative data-driven proposals learned from training data generated from our models. We apply this approach to 3D human pose estimation and object shape reconstruction from single images, achieving quantitative and qualitative performance improvements over state-of-the-art baselines.", "text": "recently multiple formulations vision problems probabilistic inversions generative models based computer graphics proposed. however applications perception natural images focused low-dimensional latent scenes challenges modeling inference. accounting enormous variability object shape appearance realistic generative models seems intractable inverting even simple versions many-tomany computations link scenes images. paper proposes evaluates approach addresses aspects challenges. show possible solve challenging real-world vision problems approximate inference generative models images based rendering outputs probabilistic programs. pcad object geometry priors generate deformable meshes corresponding plausible objects apply afﬁne transformations place scene. image likelihoods based similarity feature space based standard mid-level image representations vision literature. inference algorithm integrates single-site locally blocked metropolis-hastings proposals hamiltonian monte carlo discriminative datadriven proposals learned training data generated models. apply approach human pose estimation object shape reconstruction single images achieving quantitative qualitative performance improvements state-of-the-art baselines. formulations vision problems probabilistic inversions generative models based computer graphics long history recently attracted renewed attention however applications object perception single natural images seemed intractable. generative models natural images instead either focused problems considered low-dimensional latent scenes comprised simple shapes made heavy temporal continuity modeling side accounting enormous variability object shape appearance realistic generative models seem wildly intractable. failure inverse graphics approach primarily lack generic graphics engine computational intractability inversion problem. also proved difﬁcult navigate tension model ﬂexibility inference tractability. consider permissive models generic priors meshes exacerbate intractability inference sometimes lead unrealistic percepts. hand identifying high likelihood inputs rendering engine seem challenging enough without additionally accounting highly structured scene prior. figure probabilistic framework stochastic scene generator deﬁnes distribution mesh afﬁne latent variables. generic rendering engine common express probabilistic programs changing scene priors random samples drawn generic object model scene prior consists gaussian process afﬁne transformations. random samples drawn human model scene priors deﬁned armature mesh smooth deformations afﬁne transformations. probabilistic models scene priors viewed stochastic scene generator samples generated rendered approximate renderer form mid-level representation compared data likelihood function paper proposes evaluates approach aims address challenges. show possible solve challenging real-world vision problems approximate inference generative image models deformable meshes. approach uses scene representations build tools computer-aided design nonparametric bayesian statistics specify priors object geometry using probabilistic programs within generic rendering engine environment stochastic procedures sample meshes component priors apply afﬁne transformations place scene. image likelihoods based similarity feature space based standard mid-level image representations vision literature best knowledge system ﬁrst real-world formulation deﬁne rich generative models rigid deformable programs interpret real images. apply approach human pose estimation object shape reconstruction single images achieving quantitative performance exceeds state-of-the-art baselines. mesh based parametrization model consists large mixed discrete continuous latent variables. this coupled complex many-to-many nature graphics mapping makes computation inverse mapping extremely difﬁcult inference problem. inference algorithm integrates single-site locally blocked metropolis-hastings proposals hamiltonian monte carlo discriminative proposals learned training data generated models. show discriminative proposals aids inference pipeline terms speed accuracy allowing successfully leverage strengths discriminative methods generative modeling. probabilistic deformable programs deﬁne generative models shapes combining three major components ﬁrst proposed stochastic scene generator distribution meshes scene elements afﬁne transformations. scene generator factorized several scene elements figure quantitative results object parsing quantitative comparison reconstruction method sirfs method beats baseline considerable margin without using pre-segmented objects. moreover quantitative errors attributed minor misalignment model lack segmented object given baseline. illustration inference trajectory typical escaping many local minimas. images depict z-buffer rendered mesh. image closer prior image prior starts latents favoring complicated objects quickly converges posterior inference progresses. approximate renderer projects mesh mid-level representation stochastic comparison. approximate renderer complex simulator denoted function projection generated scene denotes additional control variables rendering engine. contributions formulate image interpretation inverting simulator observations. blender widely used open source graphics environment exposes numerous interfaces model render manipulate complex scenes. paper take idea inverse graphics literally abstracting simulator function driving putting rich priors scene elements order abstract away extreme pixel variability real world images transform images contour maps recent structured random forest model approximate renderer outputs mid-level representation conditioned resulting image hypothesis space simple appearances variability preserving geometric details. stochastic comparator likelihood function case likelihood free inference distance function experiments contour based representation data rendered image stochastic comparator deﬁned probabilistic variant chamfer distance. traditionally chamfer distance uses distance transform output smooth cost function observation image ﬁxed sized template. ﬁrst step transform rendering data computing distance transform computes value closest point contour every location image. nonsymmetric chamfer distance template since typically many outliers robust variations. likelihood function expressed follows demonstrate framework challenging real world parsing problems parsing generic artifact objects inferring pose humans single images. ﬂexibility rich priors expressivity generic graphics simulator allows handle extreme shape variability problem domains relative ease. generative models denote afﬁne transformations entire object latent matrix denoted matrix afﬁne matrix drawn uniform distribution range translation variables range scale range rotation three axes independently. lathing casting useful representation express models main inspiration approach modeling generic artifacts. given object boundaries space popular algorithm graphics lathe object taking cross section points deﬁning medial axis cross section sweeping cross section across medial axis continuously perturbing respect space extremely large variability shapes. introduce generative model consisting gaussian processes ﬂexible non-parametric prior object proﬁles lathing intermediate output graphics simulator mesh approximating whole part object rendered image camera re-projection. height object sampled uniform distribution. objects consist several sub-parts. without loss generality simplicity study objects up-to subparts circular cross-section. sample along medial axis object using beta distribution resulting independent spanning proportions. since smoothness proﬁle objects priori unknown need hyper-parameter inference bandwidths covariance kernel gps. resulting points passed graphics simulator lathing based mesh generation results generation inference reconstructing objects amounts calculating posterior show typical samples prior example inference trajectory figure generative model formalized follows naturally deﬁne compositional model parts parameterized inﬁnite mixture experts hierarchical mixture model learn shapes human bodies. however outside scope current paper left future work. order demonstrate deformable programs designed compositional mesh human body parts vertex groups mesh approximate bones joints. popular algorithm graphics generate armature resulting mesh deﬁne priors armature control points. figure qualitative results object parsing comparison sirfs every color image ground truth model shown black border color image. super impose depth buffer obtained methods original color images. consist results obtained sirfs blue depicts results obtained model roughly viewpoint. blue models rendered different viewpoints results obtained collecting posterior samples model given corresponding color images. illustrated method gives dramatically better qualitative results challenging task suggesting strong object prior beneﬁcial problem visual reconstruction. armature tree root node centered around center mesh. underlying armature tree used medial axis deform mesh local part-wise fashion. joint/bone armature afﬁne matrix scale {ut}t∈xyz rotation {nt}t∈xyz location {ut}t∈xyz latent variables.the armature re-ﬂipped marked mesh depicted figure whenever random choices inference change propagated root node pre-deﬁned stopping node smoothly evolve mesh. order assess coverage model show samples drawn prior figure illustrative inference. inference inverting graphics simulators intractable therefore resort using markov chain monte-carlo approximate inference. inference model especially hard following reasons highly coupled variables discrete continuous variables many local minimas clutter occlusion noisy observations. approximate inference possible inverting graphics simulator propose following mixture proposal kernels local random proposal single site metropolis hastings moves continuous variables gibbs moves discrete variables. proposal kernel block proposal afﬁne latent variables rotation matrix almost always coupled latent variables parameterizing mesh. denote latents belonging afﬁne transformation {sl}l non-afﬁne latents. order allow afﬁne latent groups following blocked proposal discriminative proposal despite asymptotic convergence inference often gets suck local minimas occlusion clutter noisy observations. often times escape local figure quantitative results human pose estimation illustration inference independent runs given test image. even without making assumptions afﬁne transformations human body scale location inference converges reliably posterior. resulting mesh projected super-imposed onto test image show localization accuracy. quantitatively evaluate performance dataset collected various sources labelme images signiﬁcant occlusion person sitting category internet. model signiﬁcantly outperforms current state human pose detector minima sampler could make precise changes large number latent variables time. follow strategy similar learn data-driven proposals sample prior annotated training data given k-nearest {sk}k qdata αdatakde accepting rejecting following ratio collected small dataset objects internet demonstrate superior results current state model single object reconstruction compared baseline model require pre-segmented objects joint inference afﬁne transformations mesh elements. evaluating reconstruction challenge single images. asked experts manually generate images blender evaluated approaches calculating z-mae score n-mse described figure model much lower z-mae n-mse score sirfs without utilizing pre-segmented objects. moreover error approach attributed slight misalignment parse model respect ground truth importantly demonstrated figure approach dramatically better qualitative results compared sirfs. figure shows typical trajectory inference prior posterior challenging real world image. future work hope naturally extend model handle arbitrary cross figure qualitative results pose estimation comparison pose detector ﬁrst column every results contain test image followed contour image. results shown stick ﬁgures original image. results model rendered black background. method consistently outperforms baseline. many model’s failure cases errors localizing hands primarily noisy resolution contour map. future better bottom-up features give ﬁner contours mid-level representations texture descriptors interesting avenues improving results. collected small dataset humans performing variety poses sources labelme images signiﬁcant occlusion person sitting category internet demonstrate superior results comparison current state-of-the-art deformable parts model pose estimation project pose obtained model key-points comparison baseline. shown figure outperform baseline signiﬁcant margin. shown figure images people sitting heavy occlusion hard discriminative model right mainly missing observation signal making strong case model based approach like seems give reasonable parses. model’s failure cases shown figure inferring position; typically noisy quality contour maps around area small size. subsequent section utilize strengths bottom-up pipeline learn better strategy probabilistic inference. inference human pose estimation also explore discriminatively trained predictors sample generators inversion pipeline. sample large number samples prior pose estimated rendered images using feed-forward figure discriminative proposal learning following procedure highlighted section generate large number samples prior pose detector resulting rendered images treat bounding outputs features. given color image calculate features using pose detector retrieve k-nearest neighbors data generated given neighbors kernel density estimator latent variables learned proposal. sample parsed result proposal learning. samples drawn given color image semantically close posterior. inference ﬁne-tunes solution better proposal kernels algorithm. shown log-l plot independent chains without learned proposal. inference learned proposal consistently outperforms baseline terms speed accuracy. pose detection pipeline. inference pose model real test image k-nearest neighbors sampled dataset space pose parameters local density estimator generate discriminatively trained proposal. intuitively feed-forward pathways rapidly initializes latent variables reasonable state leaving tuning inference pipeline. effect conﬁrmed figure independent markov chains without discriminative proposals. results consistently favors runs discriminative learning terms accuracy speed. shown possible solve challenging real-world vision problems approximately bayesian inversion probabilistic programs. shape variability addressed using modeling tools computer graphics nonparametric bayesian statistics deal unknown shape categories. appearance variability handled comparing renderings real-world images feature space based mid-level representations distance metrics computer vision. inference handled mixtures hamiltonian monte carlo standard single-site locally blocked metropolis-hastings moves. approach yields quantitative qualitative performance improvements human pose estimation object reconstruction compared state-of-theart baselines moderate computational cost. additionally data-driven proposals learned synthetic data incorporating representations human pose detectors used improve inference speed. several research directions seem appealing basis results. scaling object scene complexity could handled incorporating object priors based hierarchical shape decompositions inﬁnite mixtures piecewise gps. explicit scenes could augmented physical information kinematic physical constraints integrated undirected potentials; begin practical build systems perform rich physical reasoning directly real-world visual data. image comparison could improved using richer appearance models epitomes could also fruitful experiment directly modeling reﬂectance illumination approach like sirfs though choosing right resolution comparison difﬁcult. seems natural explore richer bottom-up proposal mechanisms integrate state-of-the-art discriminative techniques including modern artiﬁcial neural networks many directions well exploration alternative inference strategies simpliﬁed implementation generative probabilistic graphics programs atop general-purpose probabilistic programming systems generative approximately bayesian approach vision long begin compete ﬂexibility maturity current bottom-up vision pipelines alone computational efﬁciency. basic design trade-offs modeling inference well understood make scene parser performs acceptably object recognition challenges like pascal good proxy general problem visual perception. despite limitations however ways offers clearer scaling path rich percepts uncontrolled settings. results suggest possible realize potential practice produce rich representationally explicit percepts also obtain good quantitative performance. hope many illustrations kind approach future. thank peter battaglia daniel selsam owain evans alexey radul gershman valuable feedback discussions. tejas kulkarni graciously supported henry singleton fellowship. partly funded darpa ppaml program grants google’s rethinking project.", "year": 2014}