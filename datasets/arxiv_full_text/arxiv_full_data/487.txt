{"title": "Spatial Diffuseness Features for DNN-Based Speech Recognition in Noisy  and Reverberant Environments", "tag": ["cs.CL", "cs.NE", "cs.SD", "stat.ML"], "abstract": "We propose a spatial diffuseness feature for deep neural network (DNN)-based automatic speech recognition to improve recognition accuracy in reverberant and noisy environments. The feature is computed in real-time from multiple microphone signals without requiring knowledge or estimation of the direction of arrival, and represents the relative amount of diffuse noise in each time and frequency bin. It is shown that using the diffuseness feature as an additional input to a DNN-based acoustic model leads to a reduced word error rate for the REVERB challenge corpus, both compared to logmelspec features extracted from noisy signals, and features enhanced by spectral subtraction.", "text": "propose spatial diffuseness feature deep neural network -based automatic speech recognition improve recognition accuracy reverberant noisy environments. feature computed real-time multiple microphone signals withrequiring knowledge estimation direction arrival represents relative amount diffuse noise time frequency bin. shown using diffuseness feature additional input dnn-based acoustic model leads reduced word error rate reverb challenge corpus compared logmelspec features extracted noisy signals features enhanced spectral subtraction. automatic speech recognizers based gaussian mixture models hidden markov models wide variety transformations feature extraction steps currently employed extracting normalizing information contained time-domain input signal efﬁciently possible. recently development effective training methods acoustic models based multiple-layer neural networks often summarized term deep neural networks become possible acoustic model learn relationships features phonemes higher degree possible manually implemented feature transformation steps. example found simple ﬁlterbank features outperform mel-frequency cepstral coefﬁcients conceivable that given large amounts training data sufﬁciently complex network structures time-domain signals point even directly used inputs neural network. although trend goes towards replacing explicit processing stages implicit learning noisereverberation-robust using microphone arrays spatial information still predominantly exploited separate speech enhancement preprocessor e.g. form beamforming multichannel linear prediction blocking matrix-based postﬁlters coherence-based postﬁlters single-channel output preprocessor used compute features asr. gmm-hmm-based systems spatial information exploited indirectly uncertainty decoding-based approaches e.g. feature uncertainty derived noise estimate obtained multichannel signal enhancement stage. dnn-based acoustic models noise-aware training proposed noise estimate appended noisy feature vector. evaluated stationary noise estimates noise-estimates derived time-frequency masking principle also used noise estimates obtained spatial processing. feature vectors multiple microphones concatenated form input dnn-based acoustic model however spatial phase information exploited. inspired trend towards moving explicit feature processing steps propose exploit spatial information diffuseness sound ﬁeld directly incorporating acoustic model dnn-based speech recognizer. diffuseness estimate derived complex coherence omnidirectional microphones used signal enhancement based assumption late reverberation noise components modeled diffuse noise using diffuseness feature motivated fact humans exploit similar spatial information speech recognition reverberant noisy environments found human auditory system treats spectro-temporal variations interaural coherence perceptual surrogate spectro-temporal variations energy speech signals learn similar behavior dnn-based acoustic model. ﬁrst describe signal model estimation diffuseness instantaneous spatial coherence reverberated noisy speech signal. then show estimate integrated feature extraction scheme describe structure dnn-based speech recognizer. finally evaluate proposed feature two-channel task reverb challenge showing proposed approach outperforms noisy multi-condition training multichannel spectral subtraction-based signal enhancement. constant forgetting factor shown solved without requiring knowledge using assumption desired signal fully coherent i.e. |γs| yields blind estimator mixture coherence require knowledge estimation signal doa. estimator given bottom page transformed diffuseness thought relative amount diffuse signal power respective time frequency bin. since diffuseness bounded convenient basis feature computation itself. fig. shows block diagram proposed feature extraction scheme. microphone signals ﬁrst windowed transformed stft domain. upper path corresponds classical feature extraction nmel-dimensional logmelspec features microphone signals combined averaging spectral powers computed microphone nmel triangular mel-scaled weighting ﬁlters applied. second path shows extraction enhanced logmelspec features signal enhancement based diffuseness estimate performed multiplication stft domain gain factor computed described according spectral magnitude subtraction rule. third path illustrates computation proposed meldiffuseness features diffuseness estimated described previous section nmel triangular weighting ﬁlters used logmelspec feature extraction applied create output vector dimensionality nmel. finally comparison mel-weighted magnitude-squared coherence computed feature. magnitude-squared coherence consider reverberated noisy speech signal recorded omnidirectional microphones. signal recorded i-th microphone composed desired signal component undesired noise component comprising additive noise late reverberation i.e. microphone desired noise signals represented short-time fourier transform domain corresponding uppercase letters i.e. respectively discrete frame index continuous frequency autocross-power spectra φxixj φsisj φninj note continuous frequency used generality; practice denotes discrete values along frequency axis. assumed auto-power spectra signal components identical microphones i.e. φsisi φnini timefrequency-dependent signal-to-noise ratio microphone signals deﬁned assumed time-invariant i.e. dependent spatial characteristics signal components. furthermore assumed signal noise components orthogonal complex spatial coherence mixed sound ﬁeld written function signal noise coherence functions direct sound modeled plane wave unknown direction arrival therefore unknown time difference arrival undesired noise late reverberation component modeled diffuse sound ﬁeld. corresponding spatial coherence functions direct diffuse sound components given employ kaldi toolkit back-end system using trigram language model reverb challenge context-dependent triphone-states acoustic model. ﬁrst step gmm-hmm baseline system based weninger extracting mean variance normalized mfccs followed frame splicing linear discriminant analysis maximum likelihood linear transform feature-space maximum likelihood linear regression detailed description). conventional maximum likelihood training discriminative training performed boosted maximum mutual information criterion gmmmixed sound ﬁeld also related amount diffuse noise relationship strongly dependent signal microphone spacing therefore melmsc feature expected perform worse proposed diffuseness estimate. interesting question using concatenated logmelspec meldiffuseness features input neural network compares using logmelspec features enhanced stft domain. since trend dnn-based acoustic modeling goes towards replacing explicit feature preprocessing normalization steps implicit learning might consider using complex spatial coherence directly feature. note however proposed diffuseness feature signiﬁcant advantages complex coherence. complex coherence depends additional variables namely microphone spacing would need sufﬁciently represented training data. moreover diffuseness characteristic sound ﬁeld independent microphone array geometry therefore also estimated microphone arrays geometries e.g. spherical arrays arrays consisting directional microphones without requiring adaptation acoustic model. interesting note additional temporal smoothing required estimation coherence parallels human auditory system reaction changes interaural coherence found sluggish reaction changes energy results presented paper time-domain signals windowed using hann window frame shift transformed using point resulting nstft subbands stft domain. spatial coherence estimated using forgetting factor nmel triangular mel-scale weighting ﬁlters used covering frequency range matlab code feature computation provided online. fig. illustrates features computed noisy reverberated speech signal taken multi-condition training reverb challenge corpus coherence-based spectral enhancement visibly reduces noise ﬂoor smearing speech features time. meldhmm system trained clean wsjcam cambridge read news reverb corpus alignment training data states extracted clean training data used later multi-condition training dnn-hmm system. technique known yield better results multi-condition state-frame alignment hybrid dnn-hmm kaldi system based dan’s implementation using maxout network -norm nonlinearities/activation functions hidden layers input dimension output dimension accordance described previous section extract nmel static logmelspec coefﬁcients without applying coherence-based spectral subtraction enhancement stft domain. depending particular setup table also delta acceleration melmsc and/or proposed meldiffuseness features derived. mean variance normalization frame splicing applied entire resulting feature vector. training performed reverb multi-condition training consisting noisy reverberated utterances wsjcam corpus using greedy layer-wise supervised training preconditioned stochastic gradient descent mixing well ﬁnal model combination evaluate proposed system using two-channel task reverb challenge reverb evaluation test consists reverberated noisy utterances partially created convolution clean wsjcam utterances impulse responses mixing recorded noise sequences partially consisting multichannel recordings speakers reverberant noisy room mc-wsjav corpus simdata reverberation times three rooms approx. sourcemicrophone spacing realdata reverberation time approx source-microphone distance cases -channel circular microphone array diameter used microphones spacing selected two-channel recognition task evaluated here. first evaluate word error rate obtained gmm-based recognizer mfcc features used obtain alignment. dnn-based recognizer compare logmelspec features extracted noisy signals enhanced logmelspec features. cases feature vector extended ﬁrst second-order derivatives. then evaluate combination noisy logmelspec features spatial meldiffuseness melmsc features; case ﬁrstorder derivatives computed logmelspec features order keep overall dimension feature vectors table shows results reverb challenge evaluation test average development test set. expected dnn-based acoustic model achieves lower gmm-based model. diffuseness-based signal enhancement negligible effect wer. seems contradict signal enhancement method signiﬁcantly lower however there acoustic models trained clean speech. apparently effect multichannel spectral subtraction signal enhancement compensated noisy multi-condition training. using combined noisy logmelspec diffuseness features input neural network however yields signiﬁcantly reduced wer. conﬁrms spatial information extracted coherence exploited successfully speech enhancement using spectral subtraction even though case frequency resolution meldiffuseness features reduced compared diffuseness estimate used spectral subtraction. melmsc feature also leads reduced compared noisy logmelspec features although improvement smaller meldiffuseness features. shown spatial information extracted multiple microphones necessarily exploited signal enhancement front-end used effectively additional feature input dnn-based speech recognizer. proposed approach number properties make highly suitable practical applications like cloud-based speech recognition smartphones. first diffuseness feature normalized respect microphone array geometry therefore used speech recognition features extracted variety multichannel recording devices without requiring adaptation acoustic model. second feature computed real-time blindly sense knowledge estimation direction arrival required. finally evaluation shows consistent improvements recognition accuracy achieved. hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath kingsbury deep neural networks acoustic modeling speech recognition ieee signal processing magazine vol. nov. weninger watanabe roux hershey tachioka geiger schuller rigoll merl/melco/tum system reverb challenge using deep recurrent neural network feature enhancement proc. reverb workshop florence italy delcroix yoshioka ogawa kubo fujimoto kinoshita espi hori nakatani linear prediction-based dereverberation advanced speech enhancement recognition technologies proc. reverb workshop floreverb challenge rence italy maas schwarz zheng reindl meier sehr kellermann two-channel acoustic frontend robust automatic speech recognition noisy proc. international workreverberant environments shop machine listening multisource environments florence italy schwarz kellermann coherent-to-diffuse power ratio estimation dereverberation ieee/acm trans. audio speech language processing review preprint available http//arxiv.org/abs/.. astudillo kolossa abad zeiler saeidi mowlaee silva neto martin integration beamforming uncertainty-of-observation techniques robust multi-source environments computer speech language vol. swietojanski ghoshal renals hybrid acoustic models distant multichannel large vocabulary speech recognition proc. asru olomouc czech republic kinoshita delcroix yoshioka nakatani sehr kellermann maas reverb challenge common evaluation framework dereverberation recognition reverberant speech proc. waspaa paltz delcroix kubo nakatani nakamura speech enhancement pre-processing still relevant using deep neural networks acoustic modeling? proc. interspeech lyon france", "year": 2014}