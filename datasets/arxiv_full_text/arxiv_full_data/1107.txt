{"title": "full-FORCE: A Target-Based Method for Training Recurrent Networks", "tag": ["cs.NE", "cs.LG", "q-bio.NC", "stat.ML"], "abstract": "Trained recurrent networks are powerful tools for modeling dynamic neural computations. We present a target-based method for modifying the full connectivity matrix of a recurrent network to train it to perform tasks involving temporally complex input/output transformations. The method introduces a second network during training to provide suitable \"target\" dynamics useful for performing the task. Because it exploits the full recurrent connectivity, the method produces networks that perform tasks with fewer neurons and greater noise robustness than traditional least-squares (FORCE) approaches. In addition, we show how introducing additional input signals into the target-generating network, which act as task hints, greatly extends the range of tasks that can be learned and provides control over the complexity and nature of the dynamics of the trained, task-performing network.", "text": "trained recurrent networks powerful tools modeling dynamic neural computations. present target-based method modifying full connectivity matrix recurrent network train perform tasks involving temporally complex input/output transformations. method introduces second network training provide suitable target dynamics useful performing task. exploits full recurrent connectivity method produces networks perform tasks fewer neurons greater noise robustness traditional least-squares approaches. addition show introducing additional input signals target-generating network task hints greatly extends range tasks learned provides control complexity nature dynamics trained task-performing network. principle focus systems circuits neuroscience understand neuronal representations external stimuli internal intentions generate actions appropriate particular task. fruitful approach addressing question construct model neural networks perform analogous tasks. training network model done adjusting parameters generates desired target outputs response given inputs. layered recurrent networks diﬃcult targets provided interior units directly producing output. infamous credit-assignment problem. widely used procedure overcoming challenge stochastic gradient-decent using backpropagation uses sequential diﬀerentiation modify interior connection weights solely basis discrepancy actual target outputs. although enormously successful procedure panacea especially types networks tasks consider particular construct continuous-time networks perform tasks inputs silent thousands model integration time steps. using backpropagation time cases requires unfolding network dynamics thousands eﬀective network layers obtaining gradients time periods which input concerned nothing happening. addition interested methods extend spiking network models alternative gradient-based approaches present method based deriving targets output also interior units using recursive least-squares algorithm activity unit target. targetrather backpropagation-based learning proposed feedforward network architectures discussing number target-based methods recurrent networks presenting ours describe network model consider deﬁne variables parameters. recurrently connected networks continuous variable ﬁring-rate units generate action potentials activity n-unit model network described n-component vector evolves continuous time according sets time scale network dynamics nonlinear function maps vector network activities corresponding vector ﬁring rates tanh). matrix recurrent connections network units. input provided network units vector input weights uin. output network deﬁned unit ﬁring rates weighted vector figure task-performing network. network receives input. training modiﬁes elements network output matches desired target output function fout. targetgenerating network. network receives fout inputs. input connections recurrent connections ﬁxed random. verify dynamics target-generating network suﬃcient performing task optional linear projection activity constructed learning output weights check essential step algorithm. tasks performed network speciﬁed maps given input desired target output fout. successful performance task requires fout desired degree accuracy. network trained perform particular task adjusting parameters. general case amounts adjusting consider modiﬁcations uin. instead elements chosen independently uniform distribution left ﬁxed. cost function minimized angle brackets denote average time trial training examples. credit assignment problem discussed arises target output namely fout vector network activities. along backpropagation number approaches used train recurrent networks type. number involve either ways circumventing credit assignment problem methods deducing targets liquidecho-state networks internal targets required modiﬁcation internal connections avoided entirely. instead modiﬁcation involves output weights case minimizing simple least-squares problem well-known solution optimal price paid simplicity learning however limited performance resulting networks. equivalent replacing matrix connections equation uwt. learning restricted liquidecho-state networks modiﬁcation output weight vector additional term also generates limited modiﬁcation eﬀective connections network. modiﬁcation eﬀective connection matrix limited ways; rank tied modiﬁcation output weight vector. nevertheless combined recursive least-squares algorithm minimizing process known force learning eﬀective train recurrent networks although force approach greatly expands capabilities trained recurrent networks take advantage full recurrent connectivity restrictions rank form modiﬁcations implements. studies found networks trained force perform complex real-world problems speech recognition require many units match performance networks trained gradient-based methods addition reliance force random connectivity activity resulting trained networks overly complex compared example experimental recordings suggestion made extending force algorithm permit general internal learning idea desired output fout generate targets every internal unit network. approach output back network thus governed equation equation instead random vector used generate targets adjusted recursive least-squares algorithm minimizes although extended force procedure produce functioning networks minimizing cost function rather unusual learning goal learning could eﬀective equation network would τdx/dt fout fin. equation incompatible output equal fout fout cannot general constructed low-pass ﬁltered version itself. thus success scheme relies failing make small succeeding enough assure target output partial component response unit. laje buonomano proposed scheme uses second target-generating network produce targets activities network constructed. reasoned rich dynamics randomly connected network operating chaotic regime would provide general basis many dynamic tasks also noted sensitivity chaotic dynamics initial conditions noise ruled chaotic networks source basis solve problem used activities chaotic target-generating network denote xchaos targets actual network wished construct adjusted minimized cost function learning task-performing network matches activity target-generating network non-chaotic stable alleviating sensitivity initial conditions noise truly chaotic system. stabilization achieved target output reproduced accurately possible adjusting output weights minimize cost function like approach laje buonomano proposal uses second network generate targets target-generating network operates driven non-chaotic regime. speciﬁcally target-generating network randomly connected recurrent network driven external input strong enough suppress chaos input target-generating network proportional target output fout gives approach similarities extended force idea discussed however contrast approach goal minimize cost function much possible rather relying limited learning. scheme allows general modiﬁcations full connection matrix otherwise similarities force approach call full-force. following provide detailed description full-force illustrate operation number examples. show full-force construct networks successfully perform tasks fewer units noise resistance networks constructed using force algorithm. networks constructed full-force desirable property degrading smoothly number units decreased noise increased. discuss reasons features. finally note additional signals added target-generating network providing hints task-performing network task performed introducing task hints greatly improves network learning signiﬁcantly extends range tasks learned. also allows construction models span full range complex dynamics inherited random recurrent networks often simple dynamics hand-build solutions. outlined introduction full-force approach involves diﬀerent networks target-generating network used training task-performing network sole ﬁnal product training procedure. target-generating network random recurrent network modiﬁed learning. denote variables parameters target-generating network superscript standing driven. target-generating network receives target output signal input takes part driving activity. ﬁnal term equation identical input term equation connection matrix random elements chose i.i.d. gaussian distribution zero mean variance g/n. generally value slightly greater meaning that absence input target-generating network would exhibit chaotic activity however importantly chaotic activity suppressed inputs included equation input term present equation delivers target output fout network vector weights components like chosen i.i.d. uniform distribution examples present numbers units driven task-generating networks same consider possibility relaxing condition discussion. idea behind target-generating network described equation want ﬁnal task-performing network described equation dynamics recurrent activity signals corresponding target output fout. occurs seems likely linear readout form able extract target output mixture. equation assure activities target-generating network reﬂect exactly mixture. target-generating network presence signals related fout imposed including function driving input. input present equation describing task-performing network; must generate signal internally. thus learning full-force amounts modifying taskperforming network generates signals related target output internally manner matches mixing occurs target-generating network fout provided externally. explicitly want combination internal external signals target-generating network fout matched purely internal signal task-performing network achieved adjusting minimize cost function primary assumption underlying full-force target output extracted linear readout mixture internal external signals within activities target-generating network transferred task-performing network. important note assumption checked adding readout target-generating network determining whether extract desired output. words possible weights fout desired degree accuracy. readout combined fact fout input target-generating network means requiring target-generating network auto-encoder signal fout despite fact strongly-coupled nonlinear network. recurrent networks learning must produce activity supports desired network output must also suppress instabilities might cause small ﬂuctuations network activity grow destroy performance. indeed stability critical diﬃcult part learning recurrent networks non-trivial dynamics show stabilization properties full-force attractive features. activities target-generating task-performing networks same output task-performing network perfect fout equation would reduce +uwt exactly force algorithm would produce original recurrent connection matrix course cannot expect match networks actual desired outputs perfect result might suggest matches close close fullforce practically equivalent force. expectation however incorrect. clarify going focus ﬁrst term equation term involves expression nevertheless expression quite diﬀerent identity matrix close equal happens practice. useful basis correlation matrix task-performing network ﬁring rates diagonal principle component basis. basis diﬀerence identity matrix expressed pcs. magnitude term corresponding equal projection onto divided square root eigenvalue means deviations projection diﬀerence rates target-generating task-performing networks along order away identity matrix. spectrum eigenvalues correlation matrix activities networks discussing falls exponentially increasing therefore small deviations generate large diﬀerences illustrate diﬀerences later section examining eigenvalue spectrum networks trained speciﬁc example task. according analysis deviations cause results force fullforce diﬀer spaces spanned account little variance full network activity. might make appear irrelevant. however discussed above stabilizing ﬂuctuations major task learning recurrent networks diﬃcult ﬂuctuations stabilize space. good stabilization properties full-force result fact deviations aligned account small variances modify illustrate full-force works evaluate performance considered task brief input pulse triggers frequency-modulated oscillation fout pattern repeats periodically every speciﬁcally fout sint) increasing linearly ﬁrst half oscillation period signal reﬂected time around midpoint period resulting periodic accordian-like curve task chosen challenging possible recurrent network models achieve. full-force-trained network units perform task whereas network size trained traditional force cannot random connectivity force network equal target-generating network used full-force equivalent teacher-forced version force network force network fails units cannot generate activity teacher-forcing demands examined generally learning aﬀected number units algorithms test error computed periods network output optimized value cost function equation divided variance fout. network trained using full-force solve oscillation task reliably using units whereas force learning required units. addition performance networks trained full-force degrades gradually decreased force-trained networks abrupt transition good performance. superior stability properties full-force discussed above. networks trained full-force inaccurate still stable. force instabilities limiting factor networks tend either stable performing well unstable result highly inaccurate. figure example outputs unit activities network units trained full-force force oscillation task. fout network trained full-force unit activities units full-force-trained network compared target activities units provided target-generating network fout network trained force. unit activities units force-trained network compared target activities shown random matrix used force network activities functioning force network match activities target-generating network. works task using either full-force force training sets increasing size trained networks using training batches batch consisted periods oscillation. cases training result successful network long training appreciably improve performance either algorithm. algorithms appears minimum required network size independent training duration size smaller full-force force. examined noise robustness networks trained perform frequencymodulated oscillator task. independent gaussian white-noise added input network unit learning testing. studied range network sizes diﬀerent magnitudes white noise diﬀusion coeﬃcient satisfying full-force networks resistant noise performance degrades continuously function force function network size. represents test error random initialization test error computed random initializations value line indicates median value across simulations size proportional diﬀerence point median value speciﬁed network size. figure median test error full-force force computed across random initializations networks trained oscillation task. three diﬀerent size networks shown units larger networks correspond lighter colors. horizontal axis shows number batches used train network batch corresponds oscillation periods. curiously region values noise applied performance forcetrained networks decreases increasing happens partial learning makes network sensitive noise. eﬀect goes away learning successfully produces correct output. occur full-force presumably superior stability properties. figure median test error full-force force computed across random draws various white-noise levels. increasing noise amplitude corresponds lighter colors. levels noise determined units ms−. understand source improved performance full-force compared force learning examined eigenvalues recurrent connectivity matrix training oscillations task compared eigenvalues connectivity relevant force-trained network results force full-force trained network units successfully trained perform oscillations task mean test error force full-force respectively. eigenvalues force trained network modestly perturbed relative eigenvalue distribution initial connectivity eigenvalues approximately within circle radius eigenvalues full-force network significantly changed learning. noticeably range eigenvalues complex plane shrunk circle radius smaller area equivalently norm eigenvalues smaller force-trained network pulling back eigenvalues originally real parts greater toward real parts closer reﬂects stabilization feature full-force mentioned previously. modifying full connectivity matrix full-force allows take advantage expressivity strongly recurrent network culling back unused potentially harmful modes. target-generating network full-force algorithm uses answer task fout suggest target pattern activity task-performing network. procedure described thus fout supervisory information provided targetfigure eigenvalues learned connectivity full-force force respectively. complex norm eigenvalues full-force force respectively. dotted circle dotted line shows range eigenvalues large random matrix constructed generating network. raises question provide more? words aware dynamic features would help solve task would lead particular type network solution might prefer provide information target-generator passed task-performing network training. extra information takes form hints information desired output provided input target-generating network makes sense incorporate hint way. words extra input term equation describing target-generating network weight vector uhint drawn randomly uin. success scheme lies choosing function fhint appropriately. ﬁxed procedure this requires insight dynamics needed solve task. task requires integrating input example fhint might needed integral. task requires timing examples follow fhint might ramping signal. point whatever fhint signal internally generated task-performing network successful training used help solve task. cost functions used training hints equation illustrate utility task hints present examples networks inspired standard tasks used systems neuroscience interval matching delayed comparison. cases including task hints drastically improves performance trained network. also show using hints allows trained networks extrapolate solutions task beyond domain trained. worth emphasizing hint input target-generating network used training. hint provided task-performing network time. ﬁrst example present network performing interval matching task inspired ready-set-go task investigated jazayeri shadlen task network receives pair input pulses amplitude duration network generate output response delay second pulse equal interval ﬁrst second pulses. time interval separating input pulses selected random trial uniform distribution seconds. following input pulses network must respond output pulse fout smooth bump-like function duration peak amplitude trials begin random times inter-trial interval drawn exponential distribution mean seconds. task diﬃcult form recurrent network learning long waiting period external signal received network. assess performance trained network classiﬁed test trials correct network output matched target output normalized error less within window around correct output time. network neurons trained full-force without using hint performs task poorly correctly responding test trials network responded correctly trials interpulse interval short less because desired output pulse fout input provided dynamics targetgenerating network waiting period long intervals insuﬃcient maintain timing information. therefore added hint input target-generating network makes dynamics appropriate solving task. speciﬁcally chose fhint function ramped linearly time ﬁrst second pulses decreased linearly rate following second pulse rate increase trials. temporal signal form figure performance results networks trained interval timing task. fhint fout network units. networks trained full-force learning without hint various interpulse intervals target response time plotted generated response time without hints. represents timing peak network output response single test trial. grey dots indicate network output meet conditions considered correct trial dots show correct trials. providing hint improves performance signiﬁcantly. identical network trained fullforce hint included correctly responded test trials bulk errors made network trained hints modest timing errors predominantly occurring trials long delays seen figure results illustrate power using task hints network training framework including hint allowed network transition performing task extremely poorly performing almost perfectly. without using one. however tasks require hints performed successfully. beneﬁt include hints tasks performed without them? train networks task performed reasonable well without hints show network trained hint extrapolate beyond domain training data. extrapolation important feature indicates general therefore potentially robust task solution constructed. figure performance results networks trained delayed comparison task. fhint fout network units. networks trained full-force learning without hints. three diﬀerent trials shown bottom easy trial diﬃcult trial easy trial. test performance networks trained without hint. indicates test trial color indicates reported output class horizontal axis interpulse delay yellow region indicates training domain. vertical axis indicates pulse amplitude diﬀerence. present version delayed comparison task studied extensively experimental theoretical neuroscience communities task network receives pair input pulses duration pulse amplitude varies randomly trial trial selected uniform distribution furthermore training time interval separating input pulses selected random uniform distribution second thereby preventing network able anticipate timing second pulse. following pulses network must respond output pulse fout deﬁned interval timing task positive diﬀerence magnitude input pulses positive negative diﬀerence negative trials input pulse height diﬀerence small clearly diﬃcult smalls errors cause network misclassify input. interval timing task trials begin random times inter-trial intervals random duration. assess performance trained network classiﬁed test trials correct network output matched target output normalized error less incorrect network output matched opposite class target output normalized error less trials network output meet either criteria classiﬁed undertermined included test performance. networks trained without hint correctly classiﬁed test trials. three example trials shown figure summary test performance seen figure next trained identical network hint could increase extend task performance. hint signal task constant input equal magnitude ﬁrst pulse lasted entire interpulse interval. hint form eﬀect driving network dynamics input speciﬁc ﬁxed-point thereby constructing memory signal value ﬁrst pulse. including task hint increased performance task hint trained network could correctly classify test trials importantly allowed network extrapolate. examine ability trained networks extrapolate beyond range training data tested performance interpulse delays selected uniformly seconds. intervals less greater second never seen network training. network trained without task hint performed chance trials correctly classifying trials. performance network trained hint hand hardly diminished compared performance range trained; compared training range results illustrate potential task hints simplify dynamics used network solve task thereby allowing general solution emerge supports extrapolation beyond training data. presented target-based method training recurrently connected neural networks. method modiﬁes full recurrent connectivity networks constructs perform complex tasks small number units considerable noise robustness. speed simplicity recursive least-squares algorithm makes attractive approach network training. addition dividing problem target generation task performance across separate networks full-force provides straightforward introduce additional input signals hints training. utilizing hints improve post-training network performance assuring dynamics appropriate task. like animal human subject network fail perform task either truly incapable meeting demands fails understand nature task. former case nothing done latter well-chosen hint training improve performance dramatically. indeed used full-force hints train networks perform challenging tasks previously considered beyond range recurrent networks use. dominant method training recurrent neural networks machine learning community backpropagation time backpropagation-based learning used successfully wide range challenging tasks including language modeling speech recognition handwriting generation tasks diﬀer interval timing delayed comparison tasks investigate long periods input network silent. lack input requires network dynamics alone provide memory trace task completion precisely function hint signal. using backpropagation time network needs unrolled suﬃcient number time steps capture long time-scale dependencies which tasks would mean unrolling network least maximum length silent periods greater time steps. given well-known gradient instability problems challenging number unrollings. make claim gradient-based learning unable learn tasks study full-force’s success well-selected hint used striking given algorithmic simplicity architectural simplicity units use. although highlighted hints full-force approach worth noting hints form used types learning including traditional force learning backpropagation-based learning cases fhint would added second target output along fout. requiring learning procedure match extra output network dynamics shaped appropriately. within backpropagation-based learning might avoid gradient instability problems perhaps release methods reliance complex networks units lstms studies recurrent neural networks perform tasks vary considerably degree design. spectrum hand-tuned models particular solution hard-wired network construction networks type advantage easy understand dynamics tends simpler seen activity real neurons extreme networks rely dynamics close chaos randomly connected network category includes work laje buonomano much work force echo-state networks. approach useful constructs solution task fairly unbiased lead insights. networks type tend exhibit fairly complex dynamics interesting feature neuroscience perspective complexity exceed data researchers resort gradient-based methods regularizers included reduce dynamic complexity realistic levels another approach experimental data directly construction model regularization adherence data achieved full-force well-chosen hints imposed target-generating network. generally hints used range purposes imposing design trained network regulating dynamics. thus supply method controlling model lies designed-to-random spectrum. splitting requirements target generation task performance across networks full-force introduces freedom fully exploited. dimension dynamics typical recurrent network considerably less size implies dynamics target-generating network described smaller number factors principle components factors rather full activity target-generating network used produce targets example linear combination. furthermore examples provided target-generating network similar task-performing network structure parameters size. also made standard choice construct randomly connected target-generating network. none choices mandatory creative approach construction target-generating network could enhance properties performance networks trained full-force well extending range tasks perform. thank raoul-martin memmesheimer fruitful discussions regarding earlier version work. thank dongsung suggesting name full-force integrates original force acronym david sussillo omri barak vishwa goudar helpful suggestions conversations. research supported grant gatsby charitable foundation simons foundation. supported graduate research fellowship.", "year": 2017}