{"title": "Theory-guided Data Science: A New Paradigm for Scientific Discovery from  Data", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Data science models, although successful in a number of commercial domains, have had limited applicability in scientific problems involving complex physical phenomena. Theory-guided data science (TGDS) is an emerging paradigm that aims to leverage the wealth of scientific knowledge for improving the effectiveness of data science models in enabling scientific discovery. The overarching vision of TGDS is to introduce scientific consistency as an essential component for learning generalizable models. Further, by producing scientifically interpretable models, TGDS aims to advance our scientific understanding by discovering novel domain insights. Indeed, the paradigm of TGDS has started to gain prominence in a number of scientific disciplines such as turbulence modeling, material discovery, quantum chemistry, bio-medical science, bio-marker discovery, climate science, and hydrology. In this paper, we formally conceptualize the paradigm of TGDS and present a taxonomy of research themes in TGDS. We describe several approaches for integrating domain knowledge in different research themes using illustrative examples from different disciplines. We also highlight some of the promising avenues of novel research for realizing the full potential of theory-guided data science.", "text": "abstract—data science models although successful number commercial domains limited applicability scientiﬁc problems involving complex physical phenomena. theory-guided data science emerging paradigm aims leverage wealth scientiﬁc knowledge improving effectiveness data science models enabling scientiﬁc discovery. overarching vision tgds introduce scientiﬁc consistency essential component learning generalizable models. further producing scientiﬁcally interpretable models tgds aims advance scientiﬁc understanding discovering novel domain insights. indeed paradigm tgds started gain prominence number scientiﬁc disciplines turbulence modeling material discovery quantum chemistry bio-medical science bio-marker discovery climate science hydrology. paper formally conceptualize paradigm tgds present taxonomy research themes tgds. describe several approaches integrating domain knowledge different research themes using illustrative examples different disciplines. also highlight promising avenues novel research realizing full potential theory-guided data science. satellites space wearable computing devices credit card transactions electronic health-care records deluge data pervaded every walk life. ability collect store access large volumes information accelerating unprecedented rates better sensor technologies powerful computing platforms greater on-line connectivity. growing size data simultaneous revolution computational statistical methods processing analyzing data collectively referred ﬁeld data science. advances made longlasting impacts sense communicate make decisions trend expected grow foreseeable future. indeed start twenty-ﬁrst century well remembered history golden data science. apart transforming commercial industries retail advertising data science also beginning play important role advancing scientiﬁc discovery. historically science progressed ﬁrst generating hypotheses collecting data conﬁrm refute hypotheses. however data ample data continuously collected without speciﬁc theory hypothesis mind offers opportunity discovering knowledge. indeed role data science scientiﬁc disciplines beginning shift providing simple analysis tools providing full-ﬂedged knowledge discovery frameworks climate science based success data science applications internet-scale data available e.g. natural language translation optical character recognition object tracking recently autonomous driving growing anticipation similar accomplishments scientiﬁc disciplines capture excitement even referred rise data science scientiﬁc disciplines theory idea increasingly large amounts data makes possible build actionable models without using scientiﬁc theories. unfortunately notion black-box application data science limited success scientiﬁc domains well-known example perils using data science methods theory-agnostic manner google trends data-driven model learned estimate number inﬂuenza-related physician visits based number inﬂuenza-related google search queries united states model built using search terms highly correlated propensity center disease control data. despite initial success model later overestimated propensity factor measured number inﬂuenza-related doctor visits subsequent years according data primary characteristics knowledge discovery scientiﬁc disciplines prevented data science models reaching level success achieved commercial domains. first scientiﬁc problems often under-constrained nature suffer paucity representative training samples involving large number physical variables. further physical variables commonly show complex non-stationary patterns dynamically change time. reason limited number labeled instances available training crossvalidation often fail represent true nature relationships scientiﬁc problems. hence standard methods assessing ensuring generalizability data science models break lead misleading conclusions. particular easy learn spurious relationships look deceptively good training test sets generalize well outside available labeled data. main reasons behind failure google trends since data used training model ﬁrst years representative trends subsequent years paucity representative samples prime challenges differentiates scientiﬁc problems mainstream problems involving internet-scale data language translation object recognition large volumes labeled unlabeled data critical success recent advancements data science deep learning. second primary characteristic scientiﬁc domains limited success black-box data science methods basic nature scientiﬁc discovery. common end-goal data science models generation actionable models process knowledge discovery scientiﬁc domains that. rather translation learned patterns relationships interpretable theories hypotheses leads advancement scientiﬁc knowledge e.g. explaining discovering physical cause-effect mechanisms variables. hence even black-box model achieves somewhat accurate performance lacks ability deliver mechanistic understanding underlying processes cannot used basis subsequent scientiﬁc developments. further interpretable model grounded explainable theories stands better chance safeguarding learning spurious patterns data lead non-generalizable performance. especially important dealing problems critical nature associated high risks limitations black-box data science models scientiﬁc disciplines motivate novel paradigm uses unique capability data science models automatically learn patterns models large data without ignoring treasure accumulated scientiﬁc knowledge. refer paradigm attempts integrate scientiﬁc knowledge data science theory-guided data science paradigm tgds already begun show promise scientiﬁc problems diverse disciplines. examples include discovery novel climate patterns relationships closure knowledge gaps turbulence modeling efforts discovery novel compounds material science design density functionals quantum chemistry improved imaging technologies bio-medical science discovery genetic biomarkers estimation surface water dynamics global scale efforts complemented recent review papers workshops industry initiatives running computational simulations dynamical systems alternate approach training examples involving input output variables learning data science model automatically extract relationships variables. depicted figure theory-based data science models represent extremes knowledge discovery depend sources information available scientiﬁc problem i.e. scientiﬁc knowledge data. enjoy unique strengths found success different types applications. theorybased models wellsuited representing processes conceptually well understood using known scientiﬁc principles. hand traditional data science models mainly rely information contained data thus reside bottom-right corner figure wide range applicability domains ample supply representative data samples e.g. internet-scale problems text mining object recognition. despite individual strengths theory-based data science models suffer certain deﬁciencies applied problems great scientiﬁc relevance theory data currently lacking. example number scientiﬁc problems involve processes completely understood current body knowledge inherent complexity processes. settings theory-based models often forced make number simplifying assumptions physical processes leads poor performance representing complex spaces hypotheses encountered physical domains. further since data science models capture associative relationships variables fully serve goal understanding causative relationships scientiﬁc problems. hence neither data-only theory-only approach considered sufﬁcient knowledge discovery complex scientiﬁc applications. instead need explore continuum theory-based data science models theory data used synergistic manner. paradigm theory-guided data science attempts address shortcomings data-only theory-only models seamlessly blending scientiﬁc knowledge data science models integrating scientiﬁc knowledge data science models tgds aims learn dependencies sufﬁcient grounding physical principles thus better chance represent causative relationships. tgds attempts achieve better generalizability models based purely data learning models consistent scientiﬁc principles termed physically consistent models. illustrate role consistency scientiﬁc knowledge ensuring better generalization performance consider example learning parametric model predictive learning problem using limited supply labeled samples. ideally would like learn model shows best generalization performance unseen instance. unfortunately observe model performance available training truly representative true generalization performance recognition fact number learning frameworks explored favor selection simpler models lower accuracy training data likely better generalization performance. methodology builds wellknown statistical principle bias-variance trade-off described using figure figure shows abstract representation succession model families varying levels complexity represents least complex models contains highly complex models. every point curved lines represents model learning algorithm arrive given particular realization training instances. true relationship input output variables depicted star figure observe learned models belonging fig. representation knowledge discovery methods scientiﬁc applications. x-axis measures data y-axis measures scientiﬁc knowledge. theory-guided data science explores space knowledge discovery makes ample available data observant underlying scientiﬁc knowledge. primary objectives hydrology study processes responsible movement distribution quality water across planet. examples processes include discharge water atmosphere precipitation inﬁltration water underneath earth’s surface known subsurface ﬂow. understanding subsurface important intricately linked terrestrial ecosystem processes agricultural water sudden adverse events ﬂoods. however knowledge subsurface using state-of-the-art hydrological models quite limited mainly subsurface operates regime difﬁcult measure directly using in-situ sensors boreholes. addition subsurface involves number complex sub-processes interact non-linear ways difﬁcult encapsulate current theory-based models challenges existing hydrological models make broad range parameters several weakly-informed physical equations. thus global hydrological models tend show poor predictive performance describing subsurface processes addition also lose physical interpretability large number model parameters difﬁcult interpret meaningfully respect domain. average quite close true relationship. however even small change training bring large changes learned models hence shows bias high variance. hand models belonging quite robust changes training thus show variance. however shows high bias models generally farther away true relationship compared models trade-off reducing bias variance heart number machine learning algorithms scientiﬁc applications another source information used ensure selection generalizable models available scientiﬁc knowledge. pruning candidate models inconsistent known scientiﬁc principles signiﬁcantly reduce variance models without likely affecting bias. learning algorithm focused space physically consistent models leading generalizable scientiﬁcally interpretable models. hence overarching visions tgds include physical consistency critical component model performance along training accuracy model complexity. summarized simple following revised objective model performance tgds performance accuracy simplicity consistency. various ways introducing physical consistency data science models different forms capacities. approaches attempt naturally incorporate physical consistency existing learning frameworks data science models others explore innovative ways blending data science principles theory-based models. following sections describe broad categories approaches combining scientiﬁc knowledge data science illustrative emerging examples tgds research diverse disciplines. note many approaches applied together multiple combinations particular problem depending nature scientiﬁc knowledge type data science method. research themes tgds brieﬂy summarized follows. first scientiﬁc knowledge used design model families restrict space models physically consistent solutions e.g. selection response loss functions design model architectures. techniques discussed section second given model family also guide learning algorithm focus physically consistent solutions. achieved instance initializing model physically meaningful parameters encoding scientiﬁc knowledge probabilistic relationships using domain-guided constraints help regularization terms inspired physical understanding. techniques discussed section third outputs data science models reﬁned using explicit implicit scientiﬁc knowledge. discussed section fourth another blending scientiﬁc knowledge data science construct hybrid models aspects problem modeled using theory-based components aspects modeled using data science components. techniques constructing hybrid tgds models discussed section theory-guided design data science models important decision learning data science models choice model family used representing relationships input response variables. scientiﬁc applications domain knowledge suggests particular form relationship inputs outputs care must taken ensure form relationship used data science model. here discuss different ways using scientiﬁc knowledge design data science models. first synergistic combinations response loss functions simplify optimization process thus lead training errors also consistent physical understanding hence result generalizable solutions. another infuse domain knowledge choosing model architecture compliant scientiﬁc knowledge. discuss approaches following. theory-guided speciﬁcation response many data science models provide option specifying form relationship used describing response variable. example generic family models represent broad variety relationships input response variables generalized linear model basic building blocks link function probability distribution using building blocks expected mean target variable determined function weighted linear combination inputs follows ensure learning glms produce physically meaningful results important choose appropriate speciﬁcation response variable matches domain understanding. example modeling response variables show extreme effects e.g. occurrences unusually severe ﬂoods droughts would inappropriate assume response variable gaussian distributed instead regression model uses gumbel distribution model extreme values would accurate physically meaningful. general idea specifying model response using scientiﬁc principles explored many types learning algorithms. example theory-guided speciﬁcation response found ﬁeld ophthalmology zernike polynomials explored classiﬁcation corneal shape using decision trees. theory-guided design model architecture scientiﬁc knowledge also used inﬂuence architecture data science models. example data science model provides ample room tuning model architecture artiﬁcial neural networks recently gained widespread acceptance several applications vision speech language processing. number design considerations inﬂuence construction effective model. examples include number hidden layers nature connections among layers sharing model parameters among nodes choice activation loss functions effective model learning. many design considerations primarily motivated simplify learning procedure minimize training loss ensure robust generalization performance using statistical principles regularization. huge opportunity informing design considerations physical understanding problem obtain generalizable well scientiﬁcally interpretable results. example attempt build model brain learns view-invariant features human faces biologically plausible rules architectures recently explored observed along preserving view-invariance theoryguided models able capture known aspect human neurology missed traditional models. made possible learn scientiﬁcally interpretable models human cognition thus advance understanding inner workings brain. following describe promising directions using scientiﬁc knowledge constructing models using modular design inspired domain understanding specifying connections among nodes physically consistent manner. domain knowledge used design models decomposing overall problem modular sub-problems represents different physical sub-process. every sub-problem learned using different model whose inputs outputs connected accordance physical relationships among sub-processes. example order describe overall hydrological process surface water discharge learn modular models different sub-processes atmospheric process rainfall evaporation process surface water runoff process related groundwater seepage. every model appropriately chosen domain features input output layers. help using power deep learning frameworks following high-level organization architecture motivated domain knowledge. domain knowledge also used design models specifying node connections capture theory-guided dependencies among variables. number variants explored capture spatial temporal dependencies input output variables. example recurrent neural networks able incorporate sequential context time speech language processing models recently explored capture notions long short term memory help skip connections among nodes model information delay models used incorporate time-varying domain characteristics scientiﬁc applications. example surface water runoff directly inﬂuences surface water discharge without delay groundwater runoff longer latency contributes surface water discharge time lag. differences time delay effectively modeled suitably designed lstm model. another variant convolutional neural network widely applied vision image processing applications capture spatial dependencies data. facilitates sharing model parameters learned features invariant simple transformations scaling transformation. similar approaches explored share parameters generic similarity structures among input features based domain knowledge. theory-guided learning data science models chosen suitable model design next step model building involves navigating search space candidate models using learning algorithm. following present four different ways guiding learning algorithm choose physically consistent models. first physically consistent solutions initial points iterative learning algorithms gradient descent methods. second restrict space probabilistic models help theory-guided priors relationships. third scientiﬁc knowledge used constraints optimization schemes ensuring physical consistency. fourth scientiﬁc knowledge encoded regularization terms objective function learning algorithms. describe approaches following. theory-guided initialization many learning algorithms iterative nature require initial choice model parameters ﬁrst step commence learning process. algorithms inferior initialization lead learning poor model. domain knowledge help process model initialization learning algorithm guided example theory-guided initialization model parameters includes recent matrix completion approach plant trait analysis rows matrix correspond plants diverse environments columns correspond plant traits leaf area seed mass root length. since observations plant traits sparsely available plant trait matrix would highly incomplete filling missing entries plant trait matrix help understand characteristics different plant species ability adapt varying environmental conditions. traditional data science approach problem matrix completion algorithms found great success online recommender systems however many algorithms iterative nature ﬁxed random values initialize matrix. presence domain knowledge improve algorithms using species mean every attribute initial values matrix completion process. relies basic principle species mean provides robust estimate average behavior across organisms. approach shown provide signiﬁcant improvements accuracy predicting plant traits traditional methods changes species mean also learned using subsequent matrix completion operations could physically interpreted effect varying environmental conditions plant traits. data science models requires special efforts choosing appropriate combination initial model parameters artiﬁcial neural network known susceptible getting stuck local minimas saddle points regions loss curve. deep learning much progress made avoid problem inferior initialization help pretraining strategies. basic idea strategies train model simpler problem trained model initialize learning original problem. pretraining strategies made major impact ability learn complex hierarchies features several application domains speech image processing. however rely plentiful amounts unlabeled labeled data hence directly applicable scientiﬁc domains data sizes small relative number variables. address challenge devising novel pretraining strategies computational simulations theory-based models used initialize model. especially useful theorybased models produce approximate simulations quickly e.g. approximate model simulations turbulent pretrained theory-guided models ﬁne-tuned using expert-quality ground truth. theory-guided probabilistic models probabilistic graphical models provide natural encode domain-speciﬁc relationships among variables edges nodes representing variables. however manually encoding domain knowledge graphical models requires great deal expert supervision cumbersome problems involving large number variables complex interactions–a common feature scientiﬁc problems. presence large number nodes common apply automated graph estimation techniques graph lasso basic objective techniques estimate sparse inverse covariance matrix maximizes model likelihood given data. assist techniques scientiﬁc knowledge promising research direction explore graph estimation techniques maximize data likelihood limiting search physically consistent solutions. another approach reduce variance model parameters introduce priors model space. example theoryguided priors problem non-invasive electrophysiological imaging heart. problem electrical activity within walls heart needs predicted based signal measured torso subject. approximately locations walls heart electrical activity needs predicted based data collected approximately electrodes torso. given large space model parameters paucity labeled examples ground-truth information traditional black-box model uses information contained data highly prone learning spurious patterns. however apart knowledge contained data also domain knowledge electrical signals transmitted within heart myocardial ﬁbre structure. equations used determine spatial distribution electric signals heart time based predicted electric signals incorporating theory-guided spatial distributions priors using along externally collected data hierarchical bayesian model shown provide promising results traditional data science models another example theory-guided priors found ﬁeld geophysics knowledge convection-diffusion equations used priors determining connectivity structure subsurface aquifers. theory-guided constrained optimization constrained optimization techniques extensively used data science models restricting space model parameters. example support vector machines constraints ensuring separability among classes maximizing margin hyperplane. also rich literature constraint-based pattern mining clustering constraints provides natural integrate domain knowledge learning data science models. scientiﬁc applications theorybased constraints represented using linear equality inequality conditions readily integrated existing constrained optimization formulations known provide computationally efﬁcient solutions especially objective function convex. however many scientiﬁc problems involve constraints represented complex forms e.g. using partial differential equations non-linear transformations variables easily handled traditional conutilize complex forms constraints data science models necessary develop constrained optimization techniques common forms partial differential equations encountered scientiﬁc disciplines. example data-driven approach uses domaindriven pdes found recent work climate science physically constrained time-series regression models developed incorporate memory effects time well nonlinear noise arising energy-conserving interactions. following present detailed discussions illustrative examples theory-guided constraints. example explores constraints predicting electron density computational chemistry example explores elevation-based constraints among locations mapping surface water dynamics. example computational chemistry solving schr¨odinger’s equation basis quantum mechanical calculations predicting properties solids molecules. schr¨odinger’s equation expressed electronic hamiltonian operator wavefunction describes quantum state system total energy consisting three terms kinetic energy electron-electron interaction energy potential energy arising external ﬁelds since computational complexity directly solving schr¨odinger’s equation grows rapidly number particles infeasible solving large many-particle systems practical applications. address this class quantum chemical modeling approaches developed hohenberg kohn uses electron density basic primitive calculations instead wavefunction resulted rise density functional theory methods become standard tool solving many-particle systems. every variable expressed functional electron density function example total energy expressed terms functionals follows however obtaining challenging interaction functional whose exact form unknown. different approximations interaction term developed solve groundstate density system notable class kohn-sham methods. however performance sensitive quality approximation used modeling interactions. also methods computational complexity makes challenging apply large systems. overcome challenges existing methods recent work explored data science models approximate approximations predict ground-state density work kernel ridge regression methods used model kinetic energy -particle system functional electron density learned obtain ground-state energy using following euler-lagrangian equation external potential adjustable constant. imposes theory-guided constraint model learning must show good performance predicting kinetic energy also accurately estimate ground-state density using equation functional adheres constraint called self-consistent. shown regression model focuses minimizing training error leads highly inconsistent solutions ground-state density thus useful quantum chemical calculations. inconsistency traced inability regression models capturing functional derivative forms used equation particular derivative easily leave space densities observed training thus arrive ill-conditioned solutions especially training size small. overcome limitation modiﬁed euler-lagrange constraint proposed restricted space density manifold observed training set. helped learning accurate well self-consistent ground-state densities using knowledge contained data well domain theories. remote sensing data earth observing satellites presents promising opportunity monitoring dynamics surface water body extent regular intervals time. possible build predictive models multi-spectral data satellite images input features classify pixels image water land. however models challenged poor quality labeled data noise missing values remote sensing signals inherent variability water land classes space time address challenges opportunity improving quality classiﬁcation maps using domain knowledge water bodies concave elevation structure. hence locations lower elevation ﬁlled ﬁrst water level reaches locations higher elevations. thus access elevation information constrain classiﬁer minimizes training error feature space also produces labels consistent elevation structure. illustrate this consider example two-dimensional training shown figure squares circles represent training instances belonging water land classes respectively. along features also information elevation every instance shown using intensity colored points figure fig. illustrative example elevation-based ordering learning physically consistent classiﬁcation boundaries water land. along distribution training instances feature space also information elevation shown figure information used learn elevation-aware classiﬁcation boundary produces physically viable labels e.g. labeled land must necessarily labeled land higher elevation shown figure would learn decision boundary shown using dotted line figure classiﬁer would make mistakes lower-left corner feature space class confusion difﬁcult resolve using linear separator. however elevation information entire group instances lower lower-left corner higher elevation instances shown right thus less likely ﬁlled water. example notice location higher elevation hence labeled land would inconsistent classify water instead classiﬁed land. constraints help learning generalizable classiﬁcation model even poorly labeled training data. theory-guided regularization constrain search space model parameters regularization terms objective function penalize learning overly complex models. number regularization techniques explored data science community enforce different measures model complexity. example minimizing norm model parameters extensively used obtaining various effects regularization parametric model learning. norm used avoid overly large parameter values ridge regression support vector machines minimizing norm results lasso formulation dantzig selector encode sparsity model parameters. however techniques agnostic physical feasibility learned model thus lead physically inconsistent solutions. example predicting elastic modulus using bond energy melting point lasso favor melting point bond energy even though direct causal link exists bond energy modulus result elimination meaningful attributes selection secondary attributes directly relevant. hence need devise regularization techniques incorporate scientiﬁc knowledge restrict search space model parameters. example instead using norm regularization solutions physically consistent sub-spaces models. gaussian widths subspaces used regularization term techniques generalized dantzig selector following describe research directions theoryguided regularization explored different applications using variants lasso incorporate domainspeciﬁc structure among parameters multitask learning formulations account heterogeneity data sub-populations. group lasso useful variant lasso explored problems involving structured attributes. assumes knowledge grouping structure among attributes small number groups considered relevant. example bio-marker discovery groups attributes correspond sets bio-markers related common biological pathway. group lasso helps selecting physically meaningful groups attributes data science models various extensions group lasso explored handling different types domain characteristics e.g. overlapping group lasso tree-guided group lasso sparse group lasso recent work applications sparse group lasso explored model domain characteristics climate variables. work climate variables observed range spatial locations used predict climate phenomenon interest. treating variables observed every location group group lasso ensured location selected climate variables observed location used relevant features. features thus represent meaningful regions space studied identify physical pathways relationships climate science. another example lasso-based regularization encodes domain knowledge found problem discovering genetic markers diseases. problem data-driven approaches elastic nets traditionally used determine relative importance genetic markers context disease. however geneticists understand relevant markers typically located close proximity genome sequence property called linkage disequilibrium suggests genetic information closely located travels together generations population. domain knowledge incorporated regularizer ensure discovered genetic markers typically located close proximity genome. fact colleagues introduced smoothed minimax concave penalty lasso captured squared differences regression coefﬁcients adjacent markers ensure difference genetic effects adjacent markers small. domain knowledge also used guide regularization multi-task learning model explored problem forest cover estimation presence heterogeneity data sub-populations different groups instances data show different relationships inputs outputs. example different types vegetation show varying responses target variable remote sensing signals. provides promising solution handle sub-population heterogeneity cases treating learning every sub-population different task. further sharing learning related tasks enforces robust regularization learning across tasks even scarcity training data. require explicit knowledge composition every task similarity structure among tasks always known practical applications. example exact number distribution vegetation types often unavailable known available varying granularties recent work presence heterogeneity varying vegetation types ﬁrst inferred clustering vegetation time series used induce similarity model parameters related vegetation types. resulted formulation task structure inferred using contextual variables theory-guided refinement data science outputs domain knowledge also used reﬁne outputs data science models compliance current understanding physical phenomena. style tgds leverages scientiﬁc knowledge ﬁnal stage model building outputs data science model made consistent domain knowledge. following describe approaches reﬁning data science outputs using domain knowledge either explicitly known implicitly available using explicit domain knowledge data science outputs often reﬁned reduce effect noise missing values thus improve overall quality results. example analysis spatiotemporal data vast body literature reﬁning model outputs enforce spatial coherence temporal smoothness among predictions. data science outputs also reﬁned improve quality measure e.g. discovery frequent itemsets pruning candidate patterns. building methods promising direction develop model reﬁnement approaches make ample domain knowledge encoded form scientiﬁc theories producing physically consistent results. example theory-guided reﬁnement data science outputs found problem material discovery objective novel materials crystal structures show desirable property e.g. ability ﬁlter gases serve catalyst. traditional approaches predicting crystal structure properties rely initio calculations density functional theory methods. however since space possible materials extremely large impractical perform computationally expensive initio calculations every material estimate structure properties. recently number teams material science explored probabilistic graphical models predicting structure properties material given training database materials known structure properties provided computationally efﬁcient approach reduce space candidate materials show desirable property using knowledge contained training data. results data science models cross-checked using expensive initio calculations reﬁne model outputs. line research resulted discovery hundred ternary oxide compounds previously unknown using traditional approaches highlighting effectiveness tgds advancing scientiﬁc knowledge. using implicit domain knowledge scientiﬁc applications domain structure among output variables always known form explicit equations easily integrated existing learning hybrid models theory data science combine strengths scientiﬁc knowledge data science creating hybrid combinations theory-based data science models aspects problem handled theory-based components remaining ones modeled using data science components. several ways fusing theory-based data science models create hybrid tgds models. build two-component model outputs theory-based component used inputs data science component. idea used climate science statistical downscaling climate variables climate model simulations available coarse spatial temporal resolutions used inputs statistical model predict climate variables ﬁner resolutions. theory-based model outputs also used supervise training data science models providing physically consistent estimates target variable every training instance. alternate creating hybrid tgds model data science methods predict intermediate quantities theory-based models currently missed inaccurately estimated. feeding data science outputs theory-based models hybrid model show better predictive performance also amend deﬁciencies existing theory-based models. further outputs theory-based models also used training samples data science components thus creating two-way synergy them. depending nature model requirements application multiple ways introducing data science outputs theory-based models. following provide illustrative example theme tgds research ﬁeld turbulence modeling. example important problems aerospace engineering model characteristics turbulent consists chaotic changes velocity complex dissipation momentum energy. turbulence modeling used number applications design reliability assessment airfoils aeroplanes space vehicles. study ﬂuid dynamics navier–stokes equations describe behavior viscous ﬂuids motion. although navier– stokes equations readily applied simple problems involving incompressible irrotational obtaining exact representation turbulent requires computationally expensive solutions direct numerical simulations spatial grids. high computational costs make infeasible studying practical turbulence problems industry typically solved using inexact computationally cheap approximations. approximation reynolds–averaged navier–stokes equations introduces term called fig. mapping extent lake abhe using implicit theoryguided constraints. remote sensing image water body initial classiﬁcation maps. elevation contours inferred history classiﬁcation labels. final classiﬁcation maps reﬁned using elevation-based constraints. model reﬁnement frameworks. requires jointly solving dual problem inferring domain constraints using learned constraints reﬁne model outputs. illustrate using example mapping surface water dynamics implicit constraints among locations estimated leveraged reﬁning classiﬁcation maps water bodies. example described example difﬁcult dynamics surface water bodies solely using knowledge contained remote sensing data promise using information elevation structure water bodies assist classiﬁcation models. however information seldom available desired granularity water bodies around world. hence need infer latent ordering among locations used produce accurate physically consistent labels. achieve using history imperfect water/land labels produced data science model every location long period time. particular location classiﬁed water longer number time-steps higher likelihood deeper location location classiﬁed water less frequently. implicit elevation ordering extracted effectively help improving classiﬁcation maps postprocessing outputs consistent elevation ordering. further post-processed labels help obtaining better estimate elevation ordering thus resulting iterative solution simultaneously infers elevation ordering produces physically consistent classiﬁcation maps. approach successfully used build global maps surface water dynamics. figure illustrates effectiveness approach using example lake africa post-processed classiﬁcation suffer errors initial classiﬁcation visually matches well remote sensing image water body. reynolds stress represent apparent stress ﬂuctuations caused turbulence. since exact form reynolds stress unknown different approximations explored previous studies resulting variety rans models. despite continued efforts approximating current rans models still insufﬁcient modeling complex ﬂows separation curvature swirling. overcome limitations recent work wang explored machine learning methods assist rans models reduce discrepancies. particular reynolds stress approximated τran obtained rans model model discrepancy estimated using random forest model. although approach used generic rans model estimate discrepancy alter form approximation used obtaining τran since learned independently τran another work singh machine learning component used directly augment rans approximation following manner equation standard boussinesq equation relating reynolds stress effective viscosity equation variant spalart allmaras model estimates function machine learning term physical terms corresponding production destruction transport processes respectively. class modeling framework integrates machine learning terms theory-based models called ﬁeld inversion machine learning works illustrate potential coupling data science outputs theory-based models reduce model discrepancies complex scientiﬁc applications. exact choice data science model contribution theory-based model explored future investigations. similar lines tgds research explored domains current theorybased models lacking e.g. hydrological models studying subsurface augmenting theory-based models using data science many ways data science methods improve effectiveness theory-based models. data assimilated theory-based models improved selection model states numerical models. data science methods also help calibrating parameters theorybased models provide better realization physical system. describe approaches following. long-standing approaches scientiﬁc community integrating data theory-based models data assimilation approaches widely used climate science hydrology domains typically involve dynamical systems progression climate phenomena time represented sequence physical states numerical models. data assimilation infer likely sequence states model outputs agreement observations available every time-step. data assimilation values current state constrained depend previous state values well current data observations. example gaussian distribution model linear transition consecutive states translates kalman ﬁlter. however general dependencies among states data assimilation methods modeled using complex forms distributions governed physical laws equations. data assimilation provides promising step direction integrating data theory-based models knowledge discovery approach relies scientiﬁc knowledge observational data. theory-based models often involve large number parameters equations need calibrated order provide accurate representation physical system. na¨ıve approach model calibration every combination parameter values perhaps searching discrete grid deﬁned parameters choose combination produces maximum likelihood data. however approach practically infeasible number parameters large every parameter takes many possible values. number computationally efﬁcient approaches explored different disciplines parsimoniously calibrating model parameters help observational data. example seminal work model calibration ﬁeld hydrology generalized likelihood uncertainty estimation technique approach models uncertainty associated every parameter combination using monte carlo approaches uses bayesian formulation incrementally update uncertainties observations made available. given iteration parameter combination shows maximum agreement observations employed model results used update uncertainties next iteration. problem parameter selection recently received considerable attention machine learning community context multi-armed bandit problems basic objective problems incrementally select parameter values explore space parameter choices exploit parameter choice provides maximum reward using limited number observations. variants techniques also explored settings parameters take continuous values instead discrete steps conclusion paper formally conceptualized paradigm theory-guided data science seeks exploit promise data science without ignoring treasure knowledge accumulated scientiﬁc principles. provided taxonomy ways scientiﬁc knowledge data science brought together application availability domain knowledge. approaches range methods strictly enforce physical consistency data science models methods allow relaxed usage scientiﬁc knowledge scientiﬁc understanding weak presented examples diverse disciplines illustrate various research themes tgds also discussed several avenues novel research rapidly emerging ﬁeld. central motivations behind tgds ensure better generalizability models anchoring data science algorithms scientiﬁc knowledge. tgds also aims advancing knowledge physical world producing scientiﬁcally interpretable models. reducing search space learning algorithm physically consistent models also additional beneﬁt reducing computational cost algorithm. tgds research themes exhaustive anticipate development novel tgds themes future explore innovative ways blending scientiﬁc theory data science. discussion paper focuses supervised learning problems similar tgds research themes explored traditional tasks data mining machine learning statistics. example physical principles constrain spatiotemporal pattern mining algorithms explored ﬁnding ocean eddies satellite data. need explore tgds models uncertainty quantiﬁcation discussed context understanding projecting climate extremes. scientiﬁc knowledge also used advance aspects data science e.g. design scientiﬁc work-ﬂows generation model simulations hope paper serves ﬁrst step building foundations tgds encourages follow-on work develop in-depth theoretical formalizations paradigm. success endeavor need signiﬁcant innovations ability handle diversity forms scientiﬁc knowledge represented ingested different disciplines concrete tgds approaches presented paper considered stepping stone ambitious journey. anticipate deep integration theory-based data science become quintessential tool scientiﬁc discovery future research. paradigm tgds effectively utilized help realize vision fourth paradigm full economist data deluge special supplement james michael brad jacques richard charles angela data next frontier innovation competition productivity mckinsey global institute h.-j. yang stancu mcgregor boosted decision trees alternative artiﬁcial neural networks particle identiﬁcation nuclear instruments methods physics research section accelerators spectrometers detectors associated equipment vol. press faghmous kumar data guide understanding climate change case theory-guided data science data vol. faghmous kumar shekhar computing climate computing science engineering vol. caldwell bretherton zelinka klein santer sanderson statistical signiﬁcance climate sensitivity predictors obtained data mining geophysical research letters vol. ginsberg mohebbi patel brammer smolinski brilliant detecting inﬂuenza epidemics using search engine query data nature vol. kawale liess kumar steinbach snyder kumar ganguly samatova semazzi graph-based approach teleconnections climate data statistical analysis data mining vol. j.-l. xiao physics-informed machine learning predictive turbulence modeling using data improve rans modeled reynolds stresses arxiv preprint arxiv. hautier fischer jain mueller ceder finding natures missing ternary oxide compounds using machine learning density functional theory chemistry materials vol. curtarolo hart nardelli mingo sanvito levy high-throughput highway computational materials design nature materials vol. snyder pelaschier huang u.-n. niranjan duncan rupp k.-r. ¨uller burke understandp machine-learned density functionals international journal quantum chemistry sapp dehaghani horacek wang robust transmural electrophysiological imaging integrating sparse dynamic physiological models ecg-based inference medical image computing computer-assisted intervention–miccai springer khandelwal mithal kumar post classiﬁcation label reﬁnement using implicit ordering constraint among data instances data mining ieee international conference khandelwal karpatne marlier lettenmaier kumar approach global monitoring surface water extent variations using modis data remote sensing environment ganguly kodra agrawal banerjee boriah chatterjee chatterjee choudhary faghmous ganguli ghosh hayhoe hays hendrix kawale kumar kumar liao liess mawalagedara mithal oglesby salvi snyder steinhaeuser wang wuebbles toward enhanced understanding projections climate extremes using physicsguided data mining techniques nonlinear processes geophysics vol. bierkens global hydrology state trends directions water resources research vol. friedman hastie tibshirani elements statistical learning. springer series statistics springer berlin vol. p.-n. steinbach kumar intorduction data mining. parthasarathy roberts mahmoud raasch bullimore automated decision tree classiﬁcation corneal shape optometry vision science ofﬁcial publication american academy optometry vol. leibo liao anselmi freiwald poggio view-tolerant face recognition hebbian learning imply mirror-symmetric neural tuning head orientation current biology schrodt kattge shan fazayeli joswig banerjee reichstein b¨onisch d´ıaz dickie bhpmf–a hierarchical bayesian approach gap-ﬁlling trait prediction macroecology functional biogeography global ecology biogeography vol. majda yuan fundamental limitations linear quadratic multi-level regression models physical systems discrete continuous dynamical systems vol. karpatne khandelwal chen mithal faghmous kumar global monitoring inland water dynamics state-of-the-art challenges opportunities computational sustainability. springer karpatne jiang vatsavai shekhar kumar monitoring land-cover changes machine-learning perspective ieee geoscience remote sensing magazine vol. mithal khandelwal boriah steinhaeuser kumar change detection temporal sequences class labels application land cover change mapping siam international conference data mining austin usa. citeseer khandelwal gerber carlson west samberg kumar automated plantation mapping southeast asia using remote sensing data department computer science university minnesota twin cities tech. rep. khandelwal guru gerber carlson west kumar predict land covers transition modeling incremental learning siam international conference data mining wilby wigley conway jones hewitson main wilks statistical downscaling general circulation model output comparison methods water resources research vol. sadowski fooshee subrahmanya baldi synergies quantum mechanics machine learning reaction prediction journal chemical information modeling vol. faghmous styles mithal boriah liess vikebo mesquita kumar eddyscan physically consistent ocean eddy monitoring application intelligent data understanding conference oct. paganini oliveira nachman calogan simulating high energy particle showers multi-layer electromagnetic calorimeters generative adversarial networks arxiv preprint arxiv. anuj karpatne anuj karpatne candidate department computer science engineering university minnesota karpatne works area spatio-temporal data mining enviornmental applications. karpatne received b.techm.tech degree mathematics computing indian institute technology delhi. gowtham atluri gowtham atluri assistant professor department electrical engineering computer science university cincinnati. atluri’s research interests include data mining neuroimaging climate science. atluri received computer science m.tech roorkee. james faghmous james faghmous assistant professor founding arnhold global health institute icahn school medicine mount sinai. faghmous’ research interests include data science climate science global health. faghmous received city college york. michael steinbach michael steinbach research associate department umn. steinbach’s research interests include data mining healthcare bio-informatics statistics. steinbach received statistics math umn. arindam banerjee arindam banerjee associate professor department umn. banerjee’s research interests include machine learning data mining optimization. banerjee received university texas austin m.tech electrical engineering kanpur jadavpur university. auroop ganguly auroop ganguly associate professor department civil environmental engineering northeastern university. ganguly’s research encompasses weather extremes water sustainability resilience critical infrastructures. ganguly received massachusetts institute technology. shashi shekhar shashi shekhar mcknight distinguished university professor department umn. shekhar’s research interests include spatial databases spatial data mining geographic information systems. shekhar received business administration university california berkeley b.tech iitk. nagiza samatova nagiza samatova professor department north carolina state university. samatova’s research interests include theory computation data science high performance computing. samatova received applied mathematics computational center russian academy sciences moscow. vipin kumar vipin kumar regents professor william norris chair large scale computing department umn. kumar’s research interests include data mining high-performance computing applications climate/ecosystems biomedical domains. kumar received university maryland philips international institute eindhoven electronics communication engineering roorkee.", "year": 2016}