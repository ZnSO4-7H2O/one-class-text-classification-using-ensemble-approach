{"title": "Semantically Decomposing the Latent Spaces of Generative Adversarial  Networks", "tag": ["cs.LG", "cs.AI", "cs.CV", "cs.NE", "stat.ML"], "abstract": "We propose a new algorithm for training generative adversarial networks that jointly learns latent codes for both identities (e.g. individual humans) and observations (e.g. specific photographs). By fixing the identity portion of the latent codes, we can generate diverse images of the same subject, and by fixing the observation portion, we can traverse the manifold of subjects while maintaining contingent aspects such as lighting and pose. Our algorithm features a pairwise training scheme in which each sample from the generator consists of two images with a common identity code. Corresponding samples from the real dataset consist of two distinct photographs of the same subject. In order to fool the discriminator, the generator must produce pairs that are photorealistic, distinct, and appear to depict the same individual. We augment both the DCGAN and BEGAN approaches with Siamese discriminators to facilitate pairwise training. Experiments with human judges and an off-the-shelf face verification system demonstrate our algorithm's ability to generate convincing, identity-matched photographs.", "text": "propose algorithm training generative adversarial networks jointly learns latent codes identities observations ﬁxing identity portion latent codes generate diverse images subject ﬁxing observation portion traverse manifold subjects maintaining contingent aspects lighting pose. algorithm features pairwise training scheme sample generator consists images common identity code. corresponding samples real dataset consist distinct photographs subject. order fool discriminator generator must produce pairs photorealistic distinct appear depict individual. augment dcgan began approaches siamese discriminators facilitate pairwise training. experiments human judges off-the-shelf face veriﬁcation system demonstrate algorithm’s ability generate convincing identity-matched photographs. many domains suitable generative process might consist several stages. generate photograph product might wish ﬁrst sample space products space photographs product. given disentangled representations multistage generative process online retailer might diversify catalog depicting products wider variety settings. retailer could also process imagining products ﬁxed setting. datasets domains often contain many labeled identities fewer observations know identity subject photograph know contingent aspects observation kind data ubiquitous; given commonalities might want incorporate structure latent representations. generative adversarial networks learn mappings latent codes low-dimensional space points space natural data achieve power adversarial training scheme pitting generative model discriminative model minimax game. gans popular owing ability generate high-ﬁdelity images original form explicitly disentangle latent factors according known commonalities. paper propose semantically decomposed gans encourage speciﬁed portion latent space correspond known source variation. technique decomposes latent code portion corresponding identity remaining portion corresponding contingent aspects observations. sd-gans learn pairwise training scheme sample real dataset consists distinct images common identity. sample generator consists pair images common differing order fool discriminator generator must produce diverse photorealistic images also images depict identity ﬁxed. sd-gans modify discriminator determine whether pair samples constitutes match. case study experiment dataset face photographs demonstrating sd-gans generate contrasting images subject generator learns certain properties free vary across observations identity. example sd-gans learn pose facial expression hirsuteness grayscale color lighting vary across different photographs individual. hand aspects salient facial veriﬁcation remain consistent vary observation code also train sd-gans dataset product images containing multiple photographs product various perspectives demonstrate sd-gans trained faces generate stylistically-contrasting identity-matched image pairs human annotators state-of-the-art face veriﬁcation algorithm recognize depicting subject. measures identity coherence image diversity sd-gans perform comparably recent conditional method sd-gans also imagine identities conditional gans limited generating existing identities training data. gans leverage discriminative power neural networks learn generative models. generative model ingests latent codes sampled known prior produces sample implicit distribution learning process consists minimax game parameterized discriminative model parameterized original formulation discriminative model tries maximize likelihood yielding training proceeds follows iterations sample minibatch real distribution distribution generated images updating discriminator weights increase stochastic gradient ascent. sample minibatch updating decrease stochastic gradient descent. sample identity vector uniformdi sample observation vectors adding minibatch label sample identity uniformly random real data set. sample images without replacement pair minibatch assigning label update discriminator weights using stochastic gradient. sample another minibatch identity-matched latent vectors update generator weights stochastic gradient descent zhao propose energy-based gans discriminator viewed energy function. speciﬁcally devise discriminator consisting autoencoder dd). minimax game discriminator’s weights updated minimize reconstruction error real data maximizing error generator. recently berthelot extend work introducing boundary equilibrium gans optimize wasserstein distance autoencoder loss distributions yielding formulation additionally introduce method stabilizing training. positing training becomes unstable discriminator cannot distinguish real generated images introduce hyperparameter updating value function iteration maintain desired ratio reconstruction errors γe]. began model produces appear subjectively sharpest images faces generated gan. work adapt dcgan began algorithms sd-gan training scheme. sd-gan formulation consider data’s identity random variable discrete index seek learn latent representation conveniently decomposes variation real data parts factors variation data packaged random variable ideally decomposition variation data correspond exactly decomposition latent space would permit convenient interpolation operations inferred subspaces conventional samples joint distribution. gan’s generative model samples directly unstructured prior latent space. disentangle variation instance modeling conditional distributions models average respect prior sd-gan method learns latent space decomposition partitioning coordinates parts representing subspaces written concatenation identity representation contingent aspect representation sd-gans achieve pairwise training scheme sample real data consists pair images common identity sample generator consists pair images generated common identity vector i.i.d. observation vectors assign identity-matched pairs label zi-matched pairs label discriminator thus learn reject pairs either primary reasons photorealistic plausibly depicting subject. algorithm sd-gan training pseudocode. figure sd-gan architectures vanilla counterparts. sd-gan models incorporate decomposed latent space siamese discriminators. dashed lines indicate shared weights. discriminators also observe real samples addition generator sd-gans need alter architecture generator. however discriminator must upon images producing single output. moreover effects input images output score independent. images might otherwise photorealistic deserve rejection clearly depict different identities. devise novel discriminator architectures adapt dcgan began respectively. cases ﬁrst separately encode image using convolutional neural network choose siamese setup problem symmetrical images thus it’s sensible share weights encoders. adapt dcgan stack feature maps along channel axis applying additional strided convolution. allows network aggregate information images ﬂattening fully connecting sigmoid output. began discriminator autoencoder architecture complicated. encoding image concatenate representations apply fully connected bottleneck layer linear activation. alignment began sd-began bottleneck dimensionality tuple latent codes generated pair images. following bottleneck apply second layer taking ﬁrst components output input ﬁrst decoder second components input second decoder. shared intermediate layer gives sd-began mechanism push apart matched unmatched pairs. specify exact architectures full detail appendix experimentally validate sd-gans using datasets ms-celeb-m dataset celebrity face images dataset shoe images collected amazon datasets contain large number identities multiple observations each. in-the-wild nature celebrity face images offers richer test method identities contingent factors signiﬁcant sources variation. contrast amazon’s shoe images tend vary camera perspective given product making data useful sanity-checking approach. faces aligned face images ms-celeb-m dataset select celebrities random associated images each resizing pixels. split celebrities subsets dataset small number duplicate images label noise detect shoes synthesizing novel product images another promising domain method. shoes dataset product photographs captured white backgrounds primarily differ orientation distance. accordingly expect sd-gan training allocate observation latent space capture aspects. choose study shoes prototypical example category product images. amazon dataset contains around unique products category shoe multiple product images. split hash images ensure splits disjoint. photos product average. train sd-dcgans datasets iterations using batches identitymatched pairs. optimize sd-dcgan adam optimizer hyperparameters recommended radford also consider non-siamese discriminator simply stacks channels pair real fake images encoding sample latent vectors uniform). sd-gans partition latent codes according r−di using values algorithm trivially applied k-wise training explore effects using also experiment sd-dcgan sample instances experiments unless otherwise stated also train sd-began datasets. increased complexity sd-began model signiﬁcantly increases training time limiting ability perform more-exhaustive hyperparameter validation adam optimizer default hyperparameters sd-began experiments. results sd-dcgan model compelling experiment variant sd-began resulted early mode collapse hence excluded sd-began evaluation. also compare dcgan architecture trained using auxiliary classiﬁer method ac-gan differs sd-gan ways random identity codes replaced one-hot embedding identities training ac-gan method encourages generated photos depict proper identity tasking discriminator predicting identity generated real image. unlike sd-gans ac-dcgan model cannot imagine identities; generating ac-dcgan must sample random identity existing training data. table evaluation pairs ms-celeb-m generative models; half matched identities half not. identity veriﬁcation metrics demonstrate facenet human annotators mechanical turk verify generated data similarly real data. sample diversity metrics ensure generated samples statistically distinct pixel space. data generated best model performs comparably real data. pairs pairs. evaluation generative models fraught topic. quantitative measures sample quality poorly correlated accordingly design evaluation match conceivable uses algorithm. hope produce diverse samples humans deem depict person evaluate identity coherence sd-gans baselines using pretrained face veriﬁcation model crowd-sourced human judgments obtained amazon’s mechanical turk platform. recent advancements face veriﬁcation using deep convolutional neural networks yielded accuracy rivaling humans. evaluation procure facenet publicly-available face veriﬁer based inception-resnet architecture facenet model pretrained casia-webface dataset achieves accuracy benchmark facenet ingests normalized color images produces embedding training objective facenet learn embeddings minimize distance matched pairs faces maximize distance mismatched pairs. accordingly embedding space yields function measuring similarity faces given images label match accuracy-maximizing threshold class-balanced pairs ms-celeb-m validation data. threshold evaluating real synthetic data facenet. compare performance facenet pairs images ms-celeb-m test generated samples trained sd-gan models ac-dcgan baseline. match facenet’s training data preprocess images resizing normalizing image individually. prepare pairs ms-celeb-m half identity-matched half unmatched. generative model generate pairs pairs sample draw observation vectors randomly. also want ensure identity-matched images produced generative models diverse. propose intra-identity sample diversity metric. multi-scale structural similarity metric reports similarity images scale report minus mean ms-ssim pairs table report area receiver operating characteristic curve accuracy false accept rate facenet real generated data. also report proposed diversity statistics. facenet veriﬁes pairs real data accuracy compared pairs sd-began model. though comparable accuracy achieved pairs ac-dcgan baseline model produces samples diverse pixel space facenet higher comparable pairs sd-gans ac-dcgan; indicates sd-gans produce images less semantically diverse average ac-dcgan. also report combined memory footprint methods table conditional approaches number parameters grows linearly number identities training data. especially case ac-gan discriminator computes softmax identities linear scaling prohibitive. k-identity subset ms-celeb-m requires ac-dcgan model ac-dcgan identities would parameters devoted weights discriminator’s softmax layer. contrast complexity sd-gan constant number identities. addition validating identity-matched sd-gan samples veriﬁed facenet also demonstrate humans similarly convinced experiments using mechanical turk. experiments balanced subsets pairs ms-celeb-m promising generative methods facenet evaluation. human annotators determine pair depicts same person different people. annotators presented batches pairs time. pair presented three distinct annotators predictions determined majority vote. additionally provide benchmark assessing quality mechanical turk ensembles manually judged pairs ms-celeb-m. results table datasets human annotators mechanical turk answered same person less frequently facenet latter uses accuracy-maximizing threshold even real data balanced pairs identity-matched annotators report same person time annotators achieve higher accuracy pairs acdcgan pairs sd-began also answer same person often acdcgan pairs real data. contrast annotators answer same person rate sd-began pairs real data. attributable lower sample diversity produced ac-dcgan. samples sd-dcgan sd-began shown figures respectively. style transfer novel view synthesis active research areas. early attempts disentangle style content manifolds used factored tensor representations applying results face image synthesis. recent work focuses learning hierarchical feature representations using deep convolutional neural networks separate identity pose manifolds faces products gatys features convolutional network pretrained image recognition means discovering content style vectors. since introduction gans used generate increasingly highquality images conditional gans introduced mirza osindero extend gans generate class-conditional data. odena propose auxiliary classiﬁer gans combining cgans semi-supervised discriminator recently cgans used ingest text full-resolution images conditioning information addressing variety image-to-image translation style transfer tasks. chen devise information-theoretic extension gans maximize mutual information subset latent variables generated data. unsupervised method several related papers gans novel view synthesis faces. tran huang zhao address synthesis different body/facial poses conditioned input image ﬁxed number pose labels. antipov propose conditional gans synthesizing artiﬁcially-aged faces conditioned face image vector. approaches require explicit conditioning relevant factor addition identity image. contrast sd-gans model contingent factors implicitly mathieu combine gans traditional reconstruction loss disentangle identity. approach trains encoder-decoder generator enforce variational bound encoder embedding enabling sample decoder without input image. experiments method address small grayscale face images training procedure complex reproduce. contrast work offers simpler approach synthesize higher-resolution color photographs. might think work offering generative view siamese networks often favored learning similarity metrics approaches used discriminative tasks like face signature veriﬁcation share many classes examples structure study here. work adopt siamese architecture order enable discriminator differentiate matched unmatched pairs. recent work tuzel propose architecture weight sharing across multiple generators discriminators different problem formulation objective ours. evaluation demonstrates sd-gans disentangle factors variation corresponding identity rest. moreover sd-gans sample never-before-seen identities beneﬁt shared conditional gans. figure demonstrate varying observation vector sd-gans change color clothing remove sunnies change facial pose. also perturb lighting color saturation contrast image keeping apparent identity ﬁxed. note subjectively samples sd-dcgan tend appear less photorealistic sd-began. given generator trained sd-gan independently interpolate along identity observation manifolds shoe dataset sd-dcgan model produces convincing results. desired manipulating keeping ﬁxed yields distinct shoes consistent poses identity code appears capture broad categories shoes surprisingly neither original began sd-began produce diverse shoe images paper presented sd-gans algorithm capable disentangling factors variation according known commonalities. several promising directions future work. logical extension disentangle latent factors corresponding known commonality. also plan apply approach domains identity-conditioned speech synthesis. authors would like thank anima anandkumar john berkowitz miller puckette helpful feedback work. work used extreme science engineering discovery environment supported national science foundation grant number gpus used research donated nvidia corporation. chen duan rein houthooft john schulman ilya sutskever pieter abbeel. infogan interpretable representation learning information maximizing generative adversarial nets. nips michael mathieu junbo jake zhao junbo zhao aditya ramesh pablo sprechmann yann lecun. disentangling factors variation deep representation using adversarial training. nips john towns timothy cockerill maytal dahan foster kelly gaither andrew grimshaw victor hazlewood scott lathrop dave lifka gregory peterson xsede accelerating scientiﬁc discovery. computing science engineering estimate latent vectors unseen images demonstrate disentangled representations sd-gans used depict estimated identity different contingent factors. order latent vector similar unseen image minimize distance minˆz figure depict estimation linear interpolation across subspaces pairs images using sd-began. also display corresponding source images estimated. pairs consistent consistent column. section describe ac-gan baseline uses embedding matrix real identities latent identity codes ˆx). place random identity vectors tried combining identity representation pairwise discrimination experiment discriminator receives either either real images identity hyperparameters sd-dcgan experiment show results figure figure generator one-hot identity embedding trained pairwise discriminator. shares identity vector column shares observation vector. random sample real images corresponding identity right. appendix detail modiﬁcation dr-gan method uses encoding network transform images identity representations ˆx). also tried combining encoder-decoder approach pairwise discrimination. discriminator figure generator encoder-decoder architecture trained pairwise discriminator. shares identity vector column shares observation vector. input image right. tran propose disentangled representation learning-gan approach face frontalization similar setup sd-gan algorithm. dr-gan generator accepts input image pose code noise vector dr-gan discriminator receives either style discriminator tasked determining image real fake also classifying pose suggesting disentangled representation generator. experiments demonstrate dr-gan explicitly disentangle pose illumination rest latent space addition ac-dcgan baseline tried modifying dr-gan disentangle identity used dcgan discriminator architecture linearly projecting ﬁnal convolutional layer altered discriminator predict identity rather pose information modiﬁcations analogous sd-gan generator analogous furthermore setup identical ac-dcgan baseline except embedding matrix replaced encoding network unfortunately found generator quickly learned produce single output image input regardless observation code accordingly excluded experiment evaluation stated section ac-gans odena provide obvious imagine identities. evaluation ac-gan generator receives identity input one-hot identities. possible approach imagining identities would query found strategy produced little identity variety compared normal one-hot strategy excluded evaluation. list full architectural details sd-dcgan sd-began models. descriptions number images generator produces discriminator observes identity number dimensions latent space experiments dimensionality always concrete example bottleneck layer sd-began discriminator autoencoder output dimensionality emphasize generators parameterized tables clarity symmetry discriminators. implementations need modify generator; instead collapsed batch size. present samples model reported table qualitative comparison. matrix across images across images column. draw identity observation vectors randomly samples. figure generated samples sd-dcgan trained wasserstein loss model optimized using rms-prop evaluation facenet accuracy data generated model. excluded table brevity.", "year": 2017}