{"title": "Deep Lambertian Networks", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Visual perception is a challenging problem in part due to illumination variations. A possible solution is to first estimate an illumination invariant representation before using it for recognition. The object albedo and surface normals are examples of such representations. In this paper, we introduce a multilayer generative model where the latent variables include the albedo, surface normals, and the light source. Combining Deep Belief Nets with the Lambertian reflectance assumption, our model can learn good priors over the albedo from 2D images. Illumination variations can be explained by changing only the lighting latent variable in our model. By transferring learned knowledge from similar objects, albedo and surface normals estimation from a single image is possible in our model. Experiments demonstrate that our model is able to generalize as well as improve over standard baselines in one-shot face recognition.", "text": "visual perception challenging problem part illumination variations. possible solution ﬁrst estimate illumination invariant representation using recognition. object albedo surface normals examples representations. paper introduce multilayer generative model latent variables include albedo surface normals light source. combining deep belief nets lambertian reﬂectance assumption model learn good priors albedo images. illumination variations explained changing lighting latent variable model. transferring learned knowledge similar objects albedo surface normals estimation single image possible model. experiments demonstrate model able generalize well improve standard baselines one-shot face recognition. multilayer generative models recently achieved excellent recognition results many challenging datasets models share underlying principle ﬁrst learning generatively data using learned latent variables discriminative tasks. advantage using indirect approach discrimination possible learn meaningful latent variables achieve strong generalization. vision illumination major cause variation. light source direction intensity changes scene dramatic changes image intensity occur. detrimental recognition performance algorithms image intensities inputs. natural attacking problem learn model albedo surface normals lighting explicitly represented latent variables. since albedo surface normals physical properties object features invariant w.r.t. illumination. separating surface normals albedo objects using multiple images obtained different lighting conditions known photometric stereo hayakawa described method photometric stereo using estimated shape albedo linear transformation. using integrability constraints yuille proposed similar method reduce ambiguities generalized relief ambiguity. related problem estimation intrinsic images however works shading instead surface normals estimated. addition three color channels simpliﬁes task. domain face recognition belhumeur kriegman showed images object varying lighting conditions polyhedral cone assuming lambertian reﬂectance ﬁxed object pose. recognition algorithms developed based estimation illumination cone main drawback models require multiple images object varying lighting conditions estimation. zhang samaras wang present algorithms single training image algorithms require bootstrapping morphable face model. every generic object class building morphable model would labor intensive. plied tasks including image classiﬁcation video action recognition speech recognition grbms viewed mixture diagonal gaussians shared parameters number mixture components exponential wijhj. additional layers binary rbms often stacked grbm form deep belief inference approximate eﬃcient probability higher layer states function lower layer states grbms dbns generate intensity particular pixel generative model inefﬁcient dealing illumination variations speciﬁcally hidden activations needed generate bright image object diﬀerent activations needed generate dark image object. lambertian reﬂectance model widely used modeling illumination variations good approximation diﬀuse object surfaces lambertian model illustrated fig. i-th pixel intensity modelled albedo also known reﬂection coeﬃcient diﬀuse reﬂectivity surface pixel material dependent illumination invariant. contrast generative process grbm image object diﬀerent lighting conditions generated without changing albedo surface normals. multiplications within hidden variables lambertian model give rise nice property. paper introduce generative model incorporates albedo surface normals lighting latent variables; uses multiplicative interaction approximate lambertian reﬂectance model; learns sets images distributions object shapes; capable one-shot recognition single training example. deep lambertian network hybrid undirected-directed model gaussian restricted boltzmann machines modeling prior albedo surface normals. good priors albedo normals necessary since inference single image number latent variables times number observed pixels. estimation ill-posed problem requires priors unique solution. density model albedo normals also allows parameter sharing across individual objects belong class. conditional distribution image generation follows lambertian reﬂectance model. estimating albedo surface normals amounts performing posterior inference model requirements number observed images. inference eﬃcient alternating gibbs sampling approximately sample latent variables higher layers. permutation invariant model learn object class strikes balance between laborious approaches vision generic unsupervised deep learning approaches. brieﬂy describe gaussian restricted boltzmann machines used model albedo surface normals. extension binary rbms real-valued visible units grbms successfully aplambertian model. second line corresponds quadratic energy soft norm constraint constraint critical correct estimation albedo since interpret albedo pixel norm pixel surface normal. third line contains grbm energies represents binary hidden variables albedo grbm grbms modeling albedo surface normals posterior complicated closed form solution. however resort gibbs sampling using sets conditional distributions number pixels image. ﬁrst layer hidden variables albedo surface normals light source vector. speciﬁcally every pixel corresponding latent random variables albedo direction light source scene. grbms model albedo surface normals gaussian prior model important grbms since expect distribution albedo surface normals multi-modal fig. shows architecture model panel displays standard network ﬁlled triangles denote multiplicative gating pixels ﬁrst hidden layer. panel demonstrates desired latent representations inferred model given input grbms prior models albedo surface normals deep belief network priors obtained stacking additional binary layers layers. clarity presentation section grbm priors. combines elegant properties lambertian model grbms resulting deep model capable learning albedo surface normal statistics images weakly-supervised fashion. following generative process grbm prior approximate since enforce soft constraint norm equal achieve extra energy term represents probabilistic version lambertian reﬂectance model. dropped convenience. critical model maximum likelihood learning regulates generation process. addition prior lighting direction well psychophysical observations human perception shape relies assumpfigure graphical model deep lambertian network. yellow weights model surface normals green weights model albedo. arrow left ﬁgure light source direction vector pointing towards light source. note light vector shared pixels image. best viewed color. auxiliary variable mcmc method combines hamiltonian dynamics metropolis algorithm sample continuous random variables. order must diﬀerentiable energy function variables. case energy conditional takes form learning accomplished using variant algorithm. e-step mcmc samples drawn approximate posterior distribution ﬁrst sample conditional distributions sec. approximate posterior proximately drawn posterior distribution e-step. maximum likelihood learning grbms intractable. therefore turn contrastive divergence compute approximate gradient learning. complete training algorithm presented alg. rather starting randomly initialized weights achieve better convergence ﬁrst training albedo grbm separate face database. transfer learned weights learning complete dln. experiment yale extended yale face databases. combined databases contain frontal images diﬀerent subjects. images subject divided subsets increasing illumination variations. fig. shows samples yale extended yale database. subject used approximately frontal images experiments. separated subjects extended yale database training held-out subjects original yale database testing. preprocessing step involved using equations sec. infer albedo image surface normals subjects. training albedo surface normal samples insuﬃcient multilayer generative models millions parameters. therefore leverage large face images toronto face database collection face images variety datasets. create training data surface normals randomly translated sets learning investigated inference process dln. although multiple images object inference important investigate well performs single test image. also interested number iterations sampling would take posterior modes. ﬁrst experiment presented model single yale face image held-out test subject shown fig. light source illuminates subject bottom right causing signiﬁcant shadow across left subject’s face. since albedo captures lighting invariant representation face correct posterior distribution automatically perform illumination normalization. using algorithm described sec. clamp visible nodes test face image sample conditionals alternating fashion. used sample total perform iterations alternating gibbs sampling. iteration variables sampled using leapfrog iterations epochs. step size momentum acceptance rate around pixel plot color images bottom row. note gibbs chain quickly jumps correct mode. good results obtained knowledge transfer albedo surface normals learned subjects. next randomly selected single test images yale test subjects. using exactly sampling algorithm fig. shows inferred albedo surface normals. ﬁrst column displays test image middle right columns contain estimated albedo surface normals. also found using test images subject improves perfigure left single input test image. right intermediate samples alternating gibbs sampling iterations contains estimated albedo. bottom contains estimated surface normals. albedo surface normal initialized visible biases respective grbms. best viewed color. task face relighting useful demonstrate strong generalization capabilities model. goal generate face images particular person never-before seen lighting conditions. realistic images generated albedo surface normals particular person correctly inferred. ﬁrst sample lighting variable next test performance task face recognition. test subjects yale image subset used training. images subsets used testing. order recognition ﬁrst infer albedo surface normals conditioned provided training image test subjects. every subject dimensional linear subspace spanned inferred albedo surface normals. particular consider matrix fig. plots recognition errors function number training images used. results obtained training layer directly training images linear trained top-most hidden activations dbn. standard handle lighting variations accurately. anapproach called normalized correlation ﬁrst normalizes images unit norm. test image figure left inference results using single test image. column test images column albedo column surface normals. middle results improve slightly using additional test image diﬀerent illumination. right using estimated albedo surface normals show synthesized images novel lighting conditions. best viewed color. cosine similarity training images computed. test image takes label closest training image. normalized correlation performs signiﬁcantly better nearest neighbor normalization removes lighting variations. finally method ﬁnds dimensional linear subspace spanned training images test subjects. test image assigned closest subspace. note important task one-shot recognition signiﬁcantly outperforms many methods. computer vision literature zhang samaras wang report lower error rates yale dataset. however algorithms make pre-existing morphable models whereas learns information automatically images. applicable face images also images generic objects. used objects amsterdam library images database every object images varying lighting divided training testing. using provided masks object images cropped rescaled resolution used layer layer also added. training performed posterior inference using held-out image. fig. shows results. contains test images middle figure recognition results yale face database. nearest neighbor. deep belief network. correlation normalized cross correlation. singular value decomposition. deep lambertian network. introduced generative model meaningful latent variables multiplicative interactions simulating lambertian reﬂectance model. shown learning priors illuminationinvariant variables directly data improve one-shot recognition tasks well generate images novel illuminations. grosse ranganath convolutional deep belief networks scalable unsupervised learning hierarchical representations. intl. conf. machine learning jeﬀrey kriegman david. acquiring linear subspaces face recognition variable lighting. ieee transactions pattern analysis machine intelligence figure inference conditioned test objects using gibbs iterations. images objects illumination. middle inferred albedo. bottom inferred surface normals.", "year": 2012}