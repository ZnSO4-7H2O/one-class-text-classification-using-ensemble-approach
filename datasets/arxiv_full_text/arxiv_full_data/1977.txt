{"title": "Robust Blind Deconvolution via Mirror Descent", "tag": ["cs.CV", "cs.AI", "cs.NA", "stat.ML"], "abstract": "We revisit the Blind Deconvolution problem with a focus on understanding its robustness and convergence properties. Provable robustness to noise and other perturbations is receiving recent interest in vision, from obtaining immunity to adversarial attacks to assessing and describing failure modes of algorithms in mission critical applications. Further, many blind deconvolution methods based on deep architectures internally make use of or optimize the basic formulation, so a clearer understanding of how this sub-module behaves, when it can be solved, and what noise injection it can tolerate is a first order requirement. We derive new insights into the theoretical underpinnings of blind deconvolution. The algorithm that emerges has nice convergence guarantees and is provably robust in a sense we formalize in the paper. Interestingly, these technical results play out very well in practice, where on standard datasets our algorithm yields results competitive with or superior to the state of the art. Keywords: blind deconvolution, robust continuous optimization", "text": "revisit blind deconvolution problem focus understanding robustness convergence properties. provable robustness noise perturbations receiving recent interest vision obtaining immunity adversarial attacks assessing describing failure modes algorithms mission critical applications. further many blind deconvolution methods based deep architectures internally make optimize basic formulation clearer understanding sub-module behaves solved noise injection tolerate ﬁrst order requirement. derive insights theoretical underpinnings blind deconvolution. algorithm emerges nice convergence guarantees provably robust sense formalize paper. interestingly technical results play well practice standard datasets algorithm yields results competitive superior state art. image deblurring active area study computer vision nearly decades. early proposals sought sharpen deblur images photographs relying parameters relating exposure ampliﬁer gain e.g. stroke/zech division ﬁlter stroke halioua contemporary algorithms deblurring however pose problem blind deconvolution refers separating true unknown signal unknown kernel ﬁlter provided knowledge noisy measurement signal convolved ﬁlter. fundamental topic today signal processing vision remains challenging non-convex ill-posed nature within last years brisk progress made towards methods gracefully handle real images encountered practice levin campisi egiazarian recent developments notwithstanding foregoing technical challenges often unable guarantee provably good solutions modern approaches generally prefer related distinct strategies blind deconvolution. statistical side research primarily revolved around bayesian methods ruiz taking advantage useful priors ranging fundamental image geometry context relation edge detection saliency expert knowledge speciﬁc application domain interest ideas provide guarantees terms robustness development efﬁcient sampling inference algorithms remains active topic research. optimization side total variation regularization proven extremely effective general image deblurring perrone favaro chan wong osher variety image domains. mathematical properties total variation well studied applied mathematics signal processing machine learning understanding robustness convergence behavior even best performing algorithms blind deconvolution based construct remains limited although exciting progress made srinivasan primary motivation work shed light theoretical issues. separate from complementary lines work enormous success deep convolutional architectures vision number papers schuler chakrabarti noroozi exploring successes adapted deconvolution general. initial attempts showed machine learning methods non-blind image deconvolution discriminatively trained architectures shown work quite well general setting without priors motion blur types. natural question whether in-depth study core blind deconvolution formulation properties relevant light still evolving body convolutional neural networks based literature. reader work complementary. recent proposals line work reformulate deconvolution supervised learning problem synthesizing blurred sharp image pairs often based form blind deconvolution sub-routine internally schuler methods closer practical deployment mission critical applications detailed assessment behavior proﬁle ﬁrst order requirement regulation compliance. enable investigating robustness convergence properties architectures resilience adversarial examples happening last years problems computer vision machine learning moosavi-dezfooli moosavi dezfooli necessarily rely beneﬁt ﬁrst principles understanding properties standalone blind deconvolution. contribution. paper provide quantiﬁably provably robust algorithm blind deconvolution guaranteed convergence properties. knowledge algorithm currently known offers properties once. convergence guarantees match best known results optimization time. technical analysis also backed practical performance. extensive experimental study show available benchmarks simple algorithm competes favorably state provide user-friendly implementation easily extended complete user-interactive deblurring package. methods image deblurring blind deconvolution employed variety regularizations derived wide range image priors. literature vast restrict discussion subset works closely related motivate proposed strategy. earlier forms regularization based -norm kaveh alternating minimization scheme proposed. recent improvements proposed hand total variation regularization defacto choice many state methods today initially deployed image denoising applications rudin vogel oman brought image deconvolution problem chan wong chan wong nice result osher gives variational iterative procedure solving total variation objective. conceptually distinct results blind deconvolution adopt statistical approach instead. levin levin provide analysis algorithms following maximum posteriori estimators. recent work ruiz gives nice comprehensive overview bayesian methods blind deconvolution. years back perrone favaro built analysis levin demonstrated experimentally behavior chan wong follow-up work authors showed advantage logarithmic prior perrone obtaining state results mild modiﬁcation classical tv-norm based formulation present shortly. separate total variation regularization based approaches interesting results shown michaeli irani regularization text images michaeli irani patch priors. recently detailed comparative study conducted participants asked qualitatively compare results multiple algorithms subset described review above. last years ideas based specialized deep networks started yielding interesting results problem. example among ﬁrst approaches motion blur removal posing problem supervised learning task training convolutional neural network infer parameters. schuler built results schuler chakrabarti chakrabarti constructed network predict fourier coefﬁcients ﬁlter necessary deblur speciﬁc image patches. taking advantage modern convolutional architectures constructed deep multi-scale networks dynamic scene deblurring strong empirical results. past year generative adversarial networks also applied measured success ramakrishnan blind deconvolution problem throughout paper assume image n−dimensional vector taking values without loss generality. denote vectorized sharp image blur kernel estimated given vectorized blurry image observe number parameters estimated much larger number observations kernel large. solve solutions many regularization functions and/or constraints proposed literature levin ruiz campisi egiazarian keep presentation simple focus attention generic components shown strong empirical performance specify full model. component total variation p-norm shown promote smoothness estimated image chambolle lions image norm deﬁned norm discrete gradient ﬁeld image lattice ∇ifp ∇jfp)p note corresponds classical anisotropic isotropic norm respectively. theoretical analysis extends assume describe results. component order deﬁne reasonable constraint appeal fundamentals image capture process. pixel values explicitly positive function photon count speciﬁc point image sensor enforce constraint kernel must nonnegative. further blurred image interpreted weighted average sharp image captured slight shifts typically stemming extended exposure time variety reasons. together requirements form constraint probability simplex pieces problem solve formally written principle problem easily amenable many continuous optimization methods practice perrone favaro provides compelling evidence choosing right algorithm critical successful recovery sharp image notice important straightforward properties optimization objective smooth convex argument individually jointly convex feasible convex compact. roadmap. shortly properly exploiting simple properties suggest natural choice algorithm familiar non-linear optimization broadly used machine learning vision. interestingly motivate choice algorithm properties provide certain technical results yield guarantees fast convergence rates subsequently suggest strategies rigorous robustness analysis. ﬁrst analyze obvious simpliﬁcations and/or direct alternating scheme effective strategy model. potential idea ignore nonconvexity? natural strategy solve algorithm exploits convexity individually respect well known method offers capability alternating minimization algorithm hardt algorithm model performs following calculation iteration potential problem alternating minimization random versus structured blur. recent results analyze convergence behavior algorithm random blur kernels hardt offer guarantees performance. unfortunately still open question whether guarantees available structured blur kernels universally encounter vision. fact perrone favaro explicitly constructs illustrative example algorithm converges strict saddle point nonconvexity context blind deconvolution problem strict saddle points correspond blur solution kernel nonzero entry. perrone favaro authors give clear example algorithm converges blur solution thereby propose speciﬁc work-arounds solve subproblem algorithm empirically converges desired instead. authors also show scheme performs consistently better many standard benchmark datasets. however knowledge clear procedure suggested perrone favaro guarantees convergence general. whether method perrone favaro provably returns minimizer also described work. revisit gradient methods? instead alternating scheme take classical approach problem propose updating simultaneously iteration. choice algorithm described shortly motivated insights problem first smooth optimization problem recently become known initial points ﬁrst order gradient method converges saddle point lebesgue measure zero panageas piliouras immediately entails high probability gradient method converge local minimizer. second geometry allow provably speed convergence interesting theoretical standpoint practical one. mirror-descent style algorithm. describe algorithm easiest brieﬂy review form classical mirror descent scheme used convex optimization. recall standard solve constrained optimization problems projections ﬁrst take gradient step euclidean projection feasible assuming easy procedure often referred projected gradient descent figure visualization projected gradient descent mirror descent probability simplex. step size selected carefully projected updates likely solutions along boundary. completely disregards geometry feasible uses local behavior objective function. hence algorithm inefﬁcient particularly high dimensional large scale settings vision mahadevan luong intuitively mirror descent addresses problem following simple modiﬁcation better choose function acts like metric depending feasible set. function called distance generating function moreover enough function metric feasible juditsky al.. exploiting property used design algorithms provably faster nesterov preferred algorithm many applications srebro jain thakurta excellent description algorithm variants given nemirovski recently zhou showed extend class nonconvex problems called variationally coherent problems. unfortunately problem satisfy assumptions hence clear results shown zhou apply. motivated discussion propose provably robust image deconvolution algorithm shown alg. alluded previously prida similar spirit algorithm convex optimization. main difference standard algorithm prida step size chosen independently coordinate. intuition behind step size rule seen follows coordinate ﬁlter t−th iteration large magnitude expect remain reasonably high iteration. empirical results show effective practice. next show prida converges provably minimizer. represents usual kullback-leibler divergence inner product denotes element-wise multiplication. note divergence function replaced euclidean norm algorithm becomes standard update. observe acts distance-generating function simplex hence unique. order show convergence following intermediate result. lemma minx∈∆z that theorem step sizes ﬁxed prida converges local minimizer almost surely. proof assume without loss generality analysis step size prove convergence steps. step show iterates prida algorithm converges ﬁxed point. step show subsequence converges stationary point point approximately satisﬁes ﬁrst order necessary conditions. show stationary point locally optimal solution. smoothness gradient cauchy-schwarz inequality pinsker’s inequality note minimizer respect exactly corresponds update rule prida strongly convex hence bound iteration improvement inequality follows summing inequalities limt→∞ algorithm converges ﬁxed point. step since update rule standard gradient descent know iterates converge point gradient vanishes section nesterov focus update rule lemma taking there that taking limit showed point satisﬁes ﬁrst order optimality conditions optimization problem. thus shown steps point optimal. prida iterates satisfy assumptions proposition corollary therein directly follows prida converge strict saddle point almost surely. convergence rate efﬁciency prida comes fact iteration prida takes time compared required details) trivially parallelizable/amenable implementation. details included supplement. shown convergence prida natural follow-up investigation characterize behavior terms noise tolerance. call algorithm robust produces output different images slightly perturbed version other. notion robustness recently introduced machine learning literature context algorithmic stability hardt recent results community show critically desirable property algorithms used vision-based deployments since often sensitive small perturbations moosavi dezfooli plan attack. using main concepts stability measure robustness algorithm. typical stability analyses noise often introduced gradient computation proxy stochastic approximate gradient updates. follow idea bound difference result noisy gradient update clean one. speciﬁc assume images noise without produce gradients approximately same. would like bound distance ˜kt+ follows look update kernel note analogous argument made sharp image update step essentially gradient step argument simpler. lemma initial point coordinates equal. gradient δ-close sense. proof order study robustness properties algorithm interpretation prida given noisy gradient used analyze much iterates stray updates separately. deﬁne intermediate iterate noisy one. make proof simple assume step size coordinates note argument easily extended general case. then distance bounded follows triangle inequality reverse triangle inequality inequality follows noise level satisﬁes know iterates computed using noisy true gradients away. remark result clearly shows interplay noise level step size sharp image undergoes convolution followed addition noise lemma tells better take short steps instead overtly aggressive. remark short steps sufﬁcient practice? given every pixel blurred image nonnegative combination neighboring pixels sharp image enough search among neighbors form realistic image rather searching whole image space. performed efﬁciently using short steps. implementation details initialization. follow standard practice common across many vision problems estimate many resolutions. speciﬁcally estimation proceeds coarseto-ﬁne pyramid scheme. level prida upscale resulting estimated image kernel next level. choice initialization critical many existing algorithms perrone favaro important prida. objective function bilinear case initial gradient steps push coordinates kernel euclidean projection. problematic remain entire course optimization thus reducing pyramid scheme’s effectiveness. prida hand thought version soft-removal multiplicative nature naturally force elements given kernel remain strictly positive times hence steps necessarily hurt overall performance. numerical considerations. calculating step size pixel case given point kernel already driven close case gradient negative however small computed step fallen machine precision. avoid issues apply correction nemirovski step taken minimum {exp{−ηigi} large positive constant. intuitively large allow prida take larger steps thus encouraging faster convergence. throughout experiments. experiments conducted using matlab running -core xeon machine ram. experiments images size ﬁxed regularization hyperparameter time image ﬁnest scale approximately minutes. ﬁrst sets experiments goal validate theoretical properties prida shown earlier sections viz. convergence robustness. finally test prida efﬁcient real world color images. compare recent standard baselines closely related algorithm perrone favaro perrone provide additional experimental details comparisons algorithms supplement. figure shows function value convergence rates prida perrone favaro using pyramid scheme compute function value iterations algorithms ﬁnest level ﬁxing stated prida default setting provided authors perrone favaro notice perrone favaro method initially drops quickly method eventually converges much faster lower objective function. note also prida updates signiﬁcantly stable providing evidence robustness analysis above. figure left right input blurred images added gaussian noise. result perrone favaro result perrone result. ground truth. bottom corresponds added noise standard deviation respectively. blur kernels ranging size pixels square. evaluate robustness varying levels noise image qualitatively evaluate result. compare method algorithms presented perrone favaro perrone show results prida comparison standard baselines figure supplement results. generate noisy blurred images gaussian random noise mean added blurred image. clearly observe ability procedure handle large amounts noise. entire dataset observe interesting cases algorithms perrone favaro perrone able recover reasonably sharp image presence noise. entire dataset levin however note results signiﬁcantly variable prida. average figure color image recovery presence intensity noise. left right -mean gaussian random noise variance respectively. ﬁrst shows blurred noisy input second recovered kernel third ﬁnal image recovery. standard denoising methods applied deblurred image. results valuable validating theoretical claims also evaluate algorithms’ robustness real world images. computationally interesting property prida operations involve convolutions elementwise operations beneﬁt efﬁciencies. provide code supplement. apply prida large color images synthetically blurred. recent comparative study modern blind deconvolution algorithms compiled dataset syntheticallyblurred spanning wide range image sizes image content blur difﬁculty real-world images collected internet uniformly blurred known kernels various size support. applying algorithm images results comparable state-of-the-art. demonstrate robustness prida color images noise added pixel’s lightness value space wyszecki stiles converted back original color space. figure shows recovery affected increasing amounts gaussian random noise. kernel recovery degrades added noise clear still able recover kernel structure ﬁnal recovered image fact deblurred. here present output proposed model. since literature denoising algorithms mature necessary denoising algorithm easily prida remove noise depending type. fact common practice non-blind stage scale many existing deblurring algorithms. propose algorithm prida recovering sharp images blind deconvolution. prida uniquely takes advantage speciﬁc problem domain employing mirror descent simplex constraint set. present theoretical analysis prida derive guarantees convergence robustness extra assumptions. real world settings noted milanfar light conditions auto-focus software systems introduce extra blur noise since depend exposure time camera settings. exhaustive experimentation shows prida comprehensive solution real world problems. showed qualitatively quantitively prida performs good state noise conditions unarguably better presence noise. believe results strong foundation single image blind deconvolution problems also furthering success recent data driven approaches deep learning architectures. comparison prida even though prida achieve convergence result smooth function said main paper prida general since smoothness assumption relaxed seen inequalities moreover prida implemented atomic fashion coordinate updated individually followed simple normalization thus iteration complexity contrast efﬁcient algorithms project onto probability simplex requires least figure duchi penalty seems innocuous algorithms least require sorting hence cannot easily implemented", "year": 2018}