{"title": "Training a Fully Convolutional Neural Network to Route Integrated  Circuits", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "We present a deep, fully convolutional neural network that learns to route a circuit layout net with appropriate choice of metal tracks and wire class combinations. Inputs to the network are the encoded layouts containing spatial location of pins to be routed. After 15 fully convolutional stages followed by a score comparator, the network outputs 8 layout layers (corresponding to 4 route layers, 3 via layers and an identity-mapped pin layer) which are then decoded to obtain the routed layouts. We formulate this as a binary segmentation problem on a per-pixel per-layer basis, where the network is trained to correctly classify pixels in each layout layer to be 'on' or 'off'. To demonstrate learnability of layout design rules, we train the network on a dataset of 50,000 train and 10,000 validation samples that we generate based on certain pre-defined layout constraints. Precision, recall and $F_1$ score metrics are used to track the training progress. Our network achieves $F_1\\approx97\\%$ on the train set and $F_1\\approx92\\%$ on the validation set. We use PyTorch for implementing our model. Code is made publicly available at https://github.com/sjain-stanford/deep-route .", "text": "figure training samples dataset. shows input data containing pins single case. bottom shows input labels containing pins routes vias. pins routed using wire classes wire class color coding m=green m=red m=grey m=blue. formally circuit layout consists several sub-blocks input/output ports connections between pins channels several metal layers orthogonal another separated insulating layers connecting vias. treat cells edges node circuit graph corresponds layout connects driver’s output input receiver. traditionally circuit sizes tractable routing primarily manual task. however past couple decades exploding circuit sizes billion transistors routed present deep fully convolutional neural network learns route circuit layout ‘net’ appropriate choice metal tracks wire class combinations. inputs network encoded layouts containing spatial location pins routed. fully convolutional stages followed score comparator network outputs layout layers decoded obtain routed layouts. formulate binary segmentation problem per-pixel per-layer basis network trained correctly classify pixels layout layer ‘on’ ‘off’. demonstrate learnability layout design rules train network dataset train validation samples generate based certain pre-deﬁned layout constraints. precision recall score metrics used track training progress. network achieves train validation set. pytorch implementing model. code made publicly available. introduction routing complex spatial optimization problem physical design integrated circuits known np-complete cases task optimally connect circuit segments spanning multiple layout hierarchies multiple wire classes complying strict design rules dictated foundry’s process design quality routing determines circuit performance reliability also impact area. depending type circuit routing objective prioritize other general expectation minimize path delay minimize congestion maximize routability maximize repeatability ∗corresponding author sambhavalumni.stanford.edu †indicates equal contribution. code https//github.com/sjain-stanford/deep-route auto-routers indispensable. shrinking technology nodes stringent design rules impact routability. commercial electronic design automation tools tackle non-linear optimization problem using various algorithmic approaches exponential algorithms exhaust search space solution heuristic algorithms optimal algorithms special cases problem approximation techniques. approaches iterative nature rely continually evolving/changing design rules. routed layouts require signiﬁcant manual effort tuning improve non-optimal routes. explore learning-based approach wherein train deep fully convolutional network route layout relying ability learn implicit design rules training data. order demonstrate learnability layout design rules network pre-deﬁne basic constraints embedded ground truth layouts generated single case. network trained dataset train validation samples. input data labels ﬁrst encoded binary basis per-pixel per-layer feeding stage fcn. outputs score comparator give -layer encoded layouts decode -bit visualization. various architectural choices covered depth sections network shows ability learn identity-map pins optimal track locations routes suitable wire class combination locations. related work task producing routes using orthogonal layers parallel channels vias intersections often tackled heuristically since optimal solution exist np-complete problem previous work ﬁeld mostly rely explicit rule-based algorithms tackle parts complex task. instance zajc proposed using hierarchical algorithms automatic routing interconnects layer channels. rivest show greedy heuristic channel router assuming pins wiring common grid. class routers received attention lately objective function based. alpert proposed combination minimum spanning tree shortest path tree objectives performance driven global routing. constructing routing tree different objectives also explored timing objective buffer insertion wire sizing objective congestion thermal objective completely different objective diagonal routing opposed orthogonal routing also proposed ﬁrst ideas using neural networks circuit routing came green noakes divided routing task several stages combined multiple small back propagation networks form complex neural system. proposed restrict routing task predeﬁned areas slide context window complete routes sections. divide conquer approach helped reduce complexity artiﬁcial neural network router. work takes inspiration recent advances convolutional neural networks better suited visual tasks preserve spatial information inputs. similar routing window predeﬁned layout size however contrast develop single end-to-end deep network using convolutions holistically learns multiple design rules training able route using different wire class combinations depending spatial spread pins. best knowledge ﬁrst attempt routing circuit layout using convolutional neural network. dataset overview. develop dataset owing lack publicly available layout dataset need simplistic design rules assess learnability network section discuss design choices constraints used generating layouts training layouts validation. layout sample contains data labels single image pixelwise binary encoded layers layout viz. pixel given layer either indicating presence absence layer spatial location. reasoning behind encoding scheme discussed section thus training data stored tensors shape labels tensors shape layouts sized pixels found computationally feasible. chunked storing loading large dataset avoid memory bottlenecks. design rules. design rules fundamental traditional layout design correspond speciﬁc technology node. higher metals normally less wire resistance unit length compared lower metals large cross sectional area and/or better material properties. however higher metals also require additional vias jump up/down to/from higher layers adds total resistance. result break-even route distance higher metal preferred. moreover given layout size depending wire performance data limited wire classes make sense routing. using higher lower wire classes necessary would non-optimal. case empirical wire resistance data four wire classes select size context window gave balanced dataset among three wire class combinations viz. deﬁning context window routing possibility open slide entire layout complete routing segments similar leave slide-and-route implementation future work. route algorithm. layout ﬁrst sample npins co-ordinates given conﬁguration direction largest spread pins chosen dominant. dominant direction uses branch non-dominant direction uses legs connect individual pins branch. choice metals branch legs done optimize combined wire resistance explained earlier. figure qualitatively shorter routes lower metals longer routes higher metals. also branch always assigned dominant direction legs direction. visualization routed layouts decoded -bit follows green grey blue. model overview. proposed model consists single endto-end deep network using convolutions takes locations inputs generates routes three wire class combinations using layout design rules learns training data. ﬁrst present binary scheme encoding input data section model architectural details covered section sections describe loss function details training respectively. binary encoding scheme typical image generation problems generative adversarial nets point weight initialization networks intrinsically capable generate arbitrary color pixel coordinate. subsequently course training meaningful color/coordinate combinations must learned. standard -bit color gamut color representations signiﬁcantly larger need. since data deals layout layers immediately upper bound representation combinations pixel take advantage insight choose encode data binary basis per-pixel per-layer. hence instead representing images tensors shape range encode dataset tensors shape ×h×w binary range able formulate layer-wise binary segmentation task cross entropy loss scores network make binary decision presence layers every pixel context window network architecture figure illustrates model activation volumes stage. total convolutional stages convolutions except last followed batch normalization leaky rectiﬁed linear unit last convolution stage outputs scores hence followed leaky relu would affect relative scores. encoded inputs tensors shape n××h×w mini-batch size ﬁrst stage uses convolution ﬁlters whereas stages convolution ﬁlters. believe large receptive ﬁeld head network allows fast grasp overall locations helps network learn spatial information better explored section strides padding convolutions preserve spatial dimension feature maps stage. thus activations stage shape generally number layout layers learned number segmentation classes activations last stage passed score comparator pick class higher score. thus scores shape reduced layout maps shape pixel either indicating presence absence layer spatial location. visualization routes decode score comparator outputs -bit rgb. figure model overview. encoded layouts stage performs convolutions preserving spatial dimensions. ﬁlter size padding stride used stage indicated. scores processed score comparator generate routed layouts visualized decoding -bit rgb. training optimization train model scratch starting default weight initialization. adam train weights components. experiment different minibatch sizes viz. learning rates respectively mini-batch runs approximately mini-batch takes tesla gpu. pytorch train implement network. experiments score accuracy metric. given nature training data massively unbalanced towards class metric comparing pixels predicted actual layouts easily present unreasonably high pixel-wise accuracy even model incorrectly predicts pixels background. instead score metric uses equally weighted harmonic mean precision recall based confusion matrix. precision measure true positives among pixels predicted positive. recall measure true positives among pixels ground truth positive. loss function implement network objective layer-wise binary segmentation task wherein every pixel every layer classiﬁed classes perform simple critical reshape operations follows. train time scores shape ﬁrst reshaped matrix shape n.h.w.α corresponding labels shape reshaped vector length n.h.w.α. averaged cross entropy loss predicted score matrix label vector train model class imbalance. since majority pixels input labels background active pixels observe network quickly learns classify pixels background struggles learn further. mitigate sparse learning difﬁculties class imbalance weighted cross entropy loss weights regularization. regularization term added loss improve generalization. squared α×β) stage figure first stage experiment. compare training curves ﬁrst stage using ﬁlters size small receptive ﬁeld head network prevents model learning seen train accuracy left compared right epochs. network depth receptive ﬁeld. choose depth overall receptive ﬁeld network cover entire input image assuming stages unit-strided convolutions would need least nstages allow network learn reasonably well. observe reducing depth makes difﬁcult model perfectly overﬁt even tiny dataset train samples. note model uses convolutions ﬁrst stage signiﬁcance ﬁrst stage. discussed section convolutional ﬁlters ﬁrst stage believe large receptive ﬁeld head network helps model quickly learn correspondence spatial spread pins input crucial route decisions wire class combinations track usage branch-leg assignment. demonstrate signiﬁcance architecture compare models differing ﬁrst stages viz. rest model unchanged. experiment train models subset dataset using mini-batches learning rate regularization strength figure learning stagnates around epochs whereas model able quickly overﬁt small dataset fairly well interestingly increasing training validation accuracies small dataset size used experiment causing model overﬁt final training different mini-batches. taking inspiration conduct ﬁnal training using different mini-batch sizes viz. linear scaling rule suggests adjusting learning rate linearly function mini-batch size. makes intuitive sense make fewer iterative steps epoch larger mini-batch hence step size needs proportionally larger. learning rates mini-batches respectively worked reasonably well hyperparameter tuning experiments. overcome overﬁtting seen figure complete dataset train validation samples training. figure shows loss accuracy curves mini-batches. overall trends look comparable. mini-batch model achieves accuracies train validation sets epochs takes epochs reach validation accuracy contrast mini-batch model achieves train validation sets epochs takes epochs reach validation accuracy total train time signiﬁcantly improved hours minibatch hours mini-batch tesla gpu. curves show good generalization model validation small training validation accuracies. also included precision recall curves second case. figure loss accuracy curves training validation sets ﬁnal training. left shows case mini-batch learning rate right shows case mini-batch learning rate precision recall curves included second case. best accuracy recorded train validation within epochs. results gain insight learning process show routed example validation pins left image shows actual routed layout center right images show predicted model outputs epochs training respectively. ﬁrst notice model grasps orthogonality adjacent metal layers assigning vertical tracks horizontal tracks only. second model learns connect different wire classes using vias intersections. third model learns assign branch dominant direction legs non-dominant direction however since pins roughly evenly spaced either direction model attempts vertical branch horizontal legs. eventually learns optimal using horizontal branch vertical legs route thus matching ground truth expectation. epochs training. seen actual predicted layouts network well learning identity mapping pins assigning vias connect metals adjacent layers identifying correct wire class combination overall conﬁguration choosing optimal track positions branch legs. uses lower metals route pins closer higher metals widespread pins. cases however routing perfect model misses connections adds routes undesired locations. typically notice higher error rate layouts pins. could likely improved increase ratio training samples dataset containing pins. room improvement model shows good overall ability learn laydesign rules intrinsic dataset used training. future work. complexity involved routing real layouts several requirements need addressed. worth mentioning routing multiple nets presence previously occupied tracks using ﬁner grid valid metal tracks customized wire class training complex route conﬁgurations trunk-branch-leg adding driver receiver awareness pins adding dedicated layers wire class supporting routing bigger layout segments using sliding context window integrating timing models timing-driven routing training industry standard layouts converting layer-encoded binary standard. requirements implemented direct scaling model and/or training dense figure examples training validation datasets showing actual layouts left corresponding predicted layouts right epochs training. model demonstrates good ability learn layout design rules intrinsic dataset. wire class color coding m=green m=red m=grey m=blue. datasets containing design rules interest. however plausible requirements warrant sophisticated architectures possibly combining several neural models construct complex neural system route ics. conclusion inspired challenges facing circuit layout routing optimization recent advances ﬁeld convolutional neural networks introduced unique approach routing using deep fully convolutional networks. explore learnability layout design rules model created dataset based predeﬁned layout constraints. implemented encoding scheme efﬁciently represent inputs model. proposed architecture efﬁciently learns route single design constraints. model achieves good performance training accuracy validation accuracy within epochs. acknowledgements thank nishith khandwala wenbin huang helpful comments discussion. gratefully acknowledge staff google cloud educational credits used towards work. samanta ghosal rahaman dasgupta. heuristic method constructing hexagonal steiner minimal trees routing vlsi. ieee international symposium circuits systems pages pp.– song jang chong. timing driven global router partition method stacked inth ieee international sympotegrated circuits. sium consumer electronics pages june tang tian xiang wong. algorithm routing tree construction buffer insertion ieee/acm wire sizing obstacle constraints. international conference computer aided design. iccad ieee/acm digest technical papers pages yoshimura. efﬁcient channel router. design automation conference proceedings pages june yoshimura kuh. efﬁcient algorithms channel ieee transactions computer-aided design routing. integrated circuits systems january zajc tomasevic zemva. automatic routing interconnections cells integrated circuits. mediterranean electrotechnical conference pages vol.", "year": 2017}