{"title": "Multimodal Transfer: A Hierarchical Deep Convolutional Neural Network  for Fast Artistic Style Transfer", "tag": ["cs.CV", "cs.AI"], "abstract": "Transferring artistic styles onto everyday photographs has become an extremely popular task in both academia and industry. Recently, offline training has replaced on-line iterative optimization, enabling nearly real-time stylization. When those stylization networks are applied directly to high-resolution images, however, the style of localized regions often appears less similar to the desired artistic style. This is because the transfer process fails to capture small, intricate textures and maintain correct texture scales of the artworks. Here we propose a multimodal convolutional neural network that takes into consideration faithful representations of both color and luminance channels, and performs stylization hierarchically with multiple losses of increasing scales. Compared to state-of-the-art networks, our network can also perform style transfer in nearly real-time by conducting much more sophisticated training offline. By properly handling style and texture cues at multiple scales using several modalities, we can transfer not just large-scale, obvious style cues but also subtle, exquisite ones. That is, our scheme can generate results that are visually pleasing and more similar to multiple desired artistic styles with color and texture cues at multiple scales.", "text": "transferring artistic styles onto everyday photographs become extremely popular task academia industry. recently ofﬂine training replaced online iterative optimization enabling nearly real-time stylization. stylization networks applied directly high-resolution images however style localized regions often appears less similar desired artistic style. transfer process fails capture small intricate textures maintain correct texture scales artworks. propose multimodal convolutional neural network takes consideration faithful representations color luminance channels performs stylization hierarchically multiple losses increasing scales. compared state-of-the-art networks network also perform style transfer nearly realtime conducting much sophisticated training ofﬂine. properly handling style texture cues multiple scales using several modalities transfer large-scale obvious style cues also subtle exquisite ones. scheme generate results visually pleasing similar multiple desired artistic styles color texture cues multiple scales. style transfer repaint existing photograph style another considered challenging interesting problem arts. recently task become active topic academia industry inﬂuential work gatys pre-trained deep learning network visual recognition used capture style content representations achieves visually stunning results. unfortunately transfer time prohibitively long online iterative optimization procedure. resolve issue feed-forward network trained ofﬂine loss criterion generate stylized results visually close single inference pass feed-forward network needed application time. results computational algorithm hundreds times faster though past work creates visually pleasing results many different types artworks important drawbacks stand current feed-forward networks trained speciﬁc resolution style image deviating resolution results scale mismatch. example applying model trained style guide size higher-resolution images would generate results whose texture scale smaller artistic style current networks often fail capture small intricate textures like brushwork many kinds artworks high-resolution images. shown feed-forward networks function quite well artworks abstract large-scale textures easily discernible strokes e.g. starry night vincent gogh artistic styles much encompassing demonstrated. different artistic styles characterized exquisite subtle brushes strokes hence observations results style-transfer networks often satisfactory large variety artistic styles. paper propose novel hierarchical deep convolutional neural network architecture fast style transfer. contribution fourfold introduce hierarchical network design associated training scheme able learn coarse large-scale texture distortion exquisite brushwork artistic style utilizing multiple scales style image; hierarchical training scheme end-to-end network architecture allow combine multiple models network handle increasingly larger image sizes; instead taking figure style guide close tomas king content image. result gatys al’s optimization-based method. results generated different feed-forward networks bottom zoom-in display regions enclosed boxes row. seen results repainted color style image. however closer examination shows brush strokes captured well zoom-in region little blurry. comparing others multimodal transfer capable simulating closely brushwork original artwork high-resolution images. color channels consideration network utilizes representations color luminance channels style transfer; experimentation show hierarchical style transfer network better capture coarse intricate texture patterns. hierarchical style transfer network trained multiple stylization losses different scales using mixture modalities distinguish multimodal transfer feed-forward style transfer networks stylization loss call singular transfer. fig. give example compares results multimodal transfer network current state-of-the-art singular transfer networks. fig. shows advantages multimodal transfer learning different levels textures including style color large texture distortion brushwork. note speciﬁcally method simulate closely brushwork artwork. sec. show multimodal transfer also used train combination model stylize single image multiple distinct artistic styles. related work understanding representations deep neural networks. recently seminal work done understanding deep neural networks. deconvnet method zeiler fergus learns certain network outputs obtained identifying image patches responsible certain neural activation. yosinski aims understand computation performed deep networks visualizing internal neurons. mahendran vedaldi inverts image representations certain layers learn information preserved networks. latter approaches generate visualization images optimization procedure whose objective perceptual understanding network functions. similar optimization procedure also adopted cases based better understanding powerful representations deep convoluntional networks many traditional vision tasks addressed much improved outcomes. optimization-based style transfer example. different previous texture synthesis algorithms usually non-parametric methods gatys ﬁrst proposed optimization method synthesizing texture images objective loss computed based representations pre-trained convolutional neural network texture loss combined content loss derived mahendran vedaldi perform style transfer task feed-forward networks image generation. optimization-based methods image generation computationally expensive iterative optimization procedure. contrary many deep learning methods perceptual objective computed neural network loss function construct feed-forward neural networks synthesize images resolution using perceptual losses deﬁned gatys similar architecture texture introduced synthesize textured stylized images recently ulyanov shows replacing spatial batch normalization feed-forward network instance normalization signiﬁcantly improve quality generated images fast style transfer. present improvement style transfer algorithms handle progressively larger images using hierarchical networks mixed modalities. furthermore allows multiple distinct styles repainting single input image. proposed network shown fig. comprised main components feed-forward multimodal network loss network. feed-forward multimodal network hierarchical deep residual convolutonal neural network. consists three subnetworks style subnet enhance subnet reﬁne subnet. subnets parameterized respectively high level network takes image input trained generate multiple output images increasing sizes output images taken separately inputs loss network calculate stylization loss each. total loss weighted combination stylization losses. show later sec. loss network deﬁnition total loss. test time order produce stylization effect correct texture scale artworks applied larger images network stylizes image hierarchically input image ﬁrst resized bilinear downsampling layer stylized style subnet capturing large color texture traits artwork. next stylized result ﬁrst output upsampled transferred output enhance subnet enhances stylization strength. resized back finally reﬁne subnet removes local pixelization artifacts reﬁnes result. high-resolution visually appealing result obtained three-stage processing. note illustrate process using two-level hierarchy concept extended recursively enable stylization progressively larger images. section ﬁrst introduce single stylization loss funtion present hierarchical stylization loss function adopted train multimodal transfer network. similar loss deﬁnition previous work fast style transfer stylization loss also derived gatys loss network used extract image representations. multimodal transfer network generate output results increasing sizes stylization loss computed output result βltext αlcontent corresponding content target style target input subnet outputs scaled versions artwork trainˆ subnets different style scales control types artistic features learned different subnets. again want emphasize concept easily extended layers. since stylization losses computed based outputs different layers whole network total loss cannot used directly propagate update weights backward. thus parallel criterion adopted different stylization losses used back-propagate weights different ranges layers. deﬁne hierarchical stylization loss function weighted stylization losses weight stylization loss therefore end-to-end learning natural images subnet denoted trained minimize parallel weighted stylization losses computed latter outputs even though subnets designed different purposes totally independent. former subnets also contribute minimize losses latter. thus shallower structure used latter subnets saves computing memory running time. content loss content loss function used denote sure dissimilarity i-th feature l-th layer loss network applied image content loss squared-error loss feature representations layer texture style loss gatys propose correlations feature maps layer loss network seen texture representations image correlations given gram matrix whose elements pairwise scalar products feature maps gram matrices used texture representations discard spatial information retain statistic proﬁles color intensity distribution input image. texture loss function deﬁned drawbacks singular transfer networks scale singular transfer network trained limits range style details captured. since trained particular scale style image training need choose learns coarse texture brushwork. learns expense other. remedy problem design hierarchical architecture different subnets trained different scales style image learn different levels artistic texture cues. design enables test image transferred using different levels style increasing resolutions. furthermore subnets combined network trained hierarchically latter subnets also able enhance reﬁne results previous ones making collaborative scheme improved efﬁciency robustness. experimented several architectures varying levels hierarchy different internal structures. introduce general architecture network shown fig. best stylization quality experience. stated before multimodal transfer network consists three learnable subnetworks style subnet enhance subnet reﬁne subnet following ﬁxed bilinear upsampling/downsampling layer. note upsampling layer enhance subnet reﬁne subnet inserted test time training input reﬁne subnet still size hugely reduces required memory speeds training process. salient features networks explained below. luminance-color joint learning better address issue preserving small intricate textures network utilizes representations color luminance channels visual perception sensitive changes luminance color separate luminance channel color image independent branches learn representations distinctively. feature maps calculated branches joined together along depth dimension processed ensuing conv-block. rgb-block comprises three strided convolutional layers three residual blocks lblock similar structure except depth convolution different. conv-block composed three residual blocks resize-convolution layers upsampling last convolutional layer obtain output figure content image style image. show outputs three subnets whose sizes respectively. third depicts absolute difference between content image output image output images output images image non-residual convolutional layers followed instance normalization relu nonlinearity. part style subnet designed based work nearest neighbor interpolation upsampling layer convolutional layer called resize-convolution layer used instead deconvolutions avoid checkerboard artifacts generated images although style subnet intended stylize input image large texture distortion match style guide found difﬁcult optimally adjust texture content weights achieve style transfer preserving content large variety styles. thus allow style subnet perform texture mapping toward preserving content train separate enhance subnet large texture weight enhance stylization. fig. illustrates speciﬁc role subnet. evidently style subnet changes color texture heavily enhance subnet also contributes greatly texture mapping adding detail. reﬁne reﬁnes adds detail ﬁnal result. figure comparison style subnet singular transfer networks tested styles here mountain defeo venus manierre dawson results size notice second style also zoomed region better compare texture. accordingly sake enhancing stylization adopt similar structure style subnet enhance subnet. difference enhance subnet convolutional layer downsampling resize-convolution layer upsampling enlarges receptive ﬁeld sizes. needed input enhance subnet twice larger style subnet. finally reﬁne consists three convolutional layers three residual blocks resize-convolution layers last convolutional layer obtain ﬁnal output much shallower style enhance subnet. know former subnets also contribute learning tasks latter. shortening reﬁne subnet advantageous. signiﬁcantly reduces memory computational complexity critical images size furthermore identity connection beginning forcing learn difference input output. experiments training details network trained subset microsoft coco dataset contained images cropped images resized adam optimization used train models iterations batch size learning rate initially iterations. content losses computed layer relu vgg- texture losses layers relu relu relu relu subnets. content weights texture weights depended different styles universal ratio texture content artistic styles. weights stylization losses rationale that training parameters former subnets updated incorporate current latter stylization losses. latter losses smaller weights order totally dominate optimization process former subnets. experiments revealed however results fairly robust changes took around hour fully train hierarchical model nvidia model size disk comparison among different singular transfer networks mentioned before singular transfer feedforward style-transfer network single stylization loss multimodal transfer hierarchical network multiple stylization losses mixture modallities separated style subnet network singular transfer network compared state-of-the-art networks johnson ulyanov three networks trained images size figure compared multimodal transfer singular transfer networks trained different scales style image generated results pixels. seen texture scale mismatch issue results singular transfer texture scale apparently smaller original artworks. singular transfer failed learn texture distortion brushwork although rendering correct color. results multimodal transfer resolved issues managed learn coarse texture intricate brushwork. multimodal transfer multiple styles multimodal transfer allowed interesting application possible before could trained multiple styles ﬁnal stylized result fused content test image coarse texture distortion style image brushwork another style image. gave example fig. model trained different styles. processing speed memory compared quantitatively speed memory usage multimodal transfer network singular transfer networks also constructed deep singular transfer network comparison structure net. took average test time generations shown table although twice deeper johnson speed memory usage close johnson generating high-resolution images beneﬁted hierarchical transfer procedure computation done resolutions. singular transfer network performed worst even number parameters. therefore multimodal transfer suitable real-world applications usually required high image resolution able generate results similar desired artistic styles small cost. present hierarchical training scheme fast style transfer learn artistic style cues multiple scales including color coarse texture structure exquisite brushwork. scheme solves texture scale mismatch issue generates much visually appealing stylized results high-resolution images. future plan investigate losses better capture artistic style different scales. also want explore alternate loss networks costs less memory extend scheme onto much larger images. figure multimodal transfer styles. model trained style still life skull leeks pitcher pablo picasso close tomas king. test image ﬁnal stylized result large texture distortion small detailed brushwork comparison gave results transferred models trained single style content texture weights used instance normalization. generally speaking style subnet generated qualitatively comparable results. particularly performed better others capturing texture details cases. fig. gave comparison examples. ﬁrst example result ulyanov visibly darker style image color texture scale johnson al’s result match style image well. result style subnet seemed better aspects. second example comparing networks style subnet performed better simulating small detailed texture. therefore chose style subnet representative singular transfer compared multimodal transfer next. singular transfer multimodal transfer highresolution images tested method numerous artistic styles. fig. compared multimodal transfer network high-resolution images singular transfer network number learning weights. examining results shown fig. comparing singular transfer multimodal transfer results visually similar original artistic styles coarse texture structure brushwork singular transfer style size caused texture scale mismatch texture scale much smaller original artwork. furthermore singular transfer style size failed learn distortion", "year": 2016}