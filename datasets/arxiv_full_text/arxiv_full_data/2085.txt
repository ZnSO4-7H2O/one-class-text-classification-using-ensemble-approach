{"title": "Learning Scale-Free Networks by Dynamic Node-Specific Degree Prior", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Learning the network structure underlying data is an important problem in machine learning. This paper introduces a novel prior to study the inference of scale-free networks, which are widely used to model social and biological networks. The prior not only favors a desirable global node degree distribution, but also takes into consideration the relative strength of all the possible edges adjacent to the same node and the estimated degree of each individual node.  To fulfill this, ranking is incorporated into the prior, which makes the problem challenging to solve. We employ an ADMM (alternating direction method of multipliers) framework to solve the Gaussian Graphical model regularized by this prior. Our experiments on both synthetic and real data show that our prior not only yields a scale-free network, but also produces many more correctly predicted edges than the others such as the scale-free inducing prior, the hub-inducing prior and the $l_1$ norm.", "text": "learning network structure underlying data important problem machine learning. paper presents novel degree prior study inference scale-free networks widely used model social biological networks. particular paper formulates scale-free network inference using gaussian graphical model regularized node degree prior. degree prior promotes desirable global degree distribution also exploits estimated degree individual node relative strength edges single node. fulﬁll this paper proposes ranking-based method dynamically estimate degree node makes resultant optimization problem challenging solve. deal this paper presents novel admm procedure. experimental results synthetic real data show prior yields scalefree network also produces many correctly predicted edges existing scale-free inducing prior hub-inducing prior norm. graphical models widely used describe relationship variables estimating structure undirected graphical model dataset extensively studied gaussian graphical models widely used model data penalty used yield sparse graph structure. ggms assume observed data follows multivariate gaussian distribution covariance matrix. ggms used network structure encoded zero pattern precision matrix. accordingly structure learning formulated minimizing negative log-likelihood penalty. however widely-used penalty assumes pair variables equally likely form edge. suitable many real-world networks gene networks proteinprotein interaction networks social networks scale-free contain small percentage nodes. scale-free network node degree following power-law distribution. particular scale-free network contain nodes whose degrees much larger others. node likely forms edge others. real-world applications node usually functionally important. example gene network gene playing functions many biological processes tends hub. methods proposed infer scale-free networks using reweighed norm. example proposed joint regression sparse method learn scale-free networks setting penalty proportional estimated degrees. proposed method iteratively reweighs penalty norm based inverse previous estimation precision matrix. method suppress large bias norm magnitude non-zero entries vary also closer norm. recent papers follow idea node-based learning using group lasso since group lasso denote permutation |xi| |xi| |xi| shufﬂe vector excluding element xii. dimension positive vector dimension vector. deﬁne |xi|mu. permutation denote element zero vector also write respectively. promote sparse graph natural penalty regulate however norm cannot induce scale-free network. scale-free network node degree following power-law distribution i.e. degree constant ranging rather uniform distribution. simple prior scale-free networks logarithm node degree follows. indicator function. constant added handle situation norm non-differentiable thus hard optimize. resolve problem approximate norm shown since logarithm approximation non-convex convex envelope based submodular function lovasz extension introduced recently papers follows. although approximations used induce scale-free graph still issues explained theorem theorem denote logarithm node degree graph graph satisfying scalefree property exists another graph number edges satisfying scale-free property penalty promotes similar patterns among variables group tends strengthen signal nodes suppress non-hub nodes. such group lasso produce edges adjacent nodes large degree order capture scale-free property minimizes negative log-likelihood scalefree prior approximates degree variable norm. however objective function nonconvex thus hard optimize. approximates global node degree distribution submodular convex envelope node degree function. convex envelope lovasz extension logarithm node degree. methods consider global node degree distribution degree individual node. however approximation function used model global degree distribution induce power-law distribution many possible distributions power-law optimizing approximation function. theorem details. improve scale-free network inference paper introduces novel node-degree prior promotes desirable global node degree distribution also exploits estimated degree individual node relative strengths edges adjacent node. fulﬁll this node edge ranking dynamically estimate degree individual node relative strength potential edge. dynamic ranking used prior objective function challenging optimize. paper presents novel admm method this. denote graph vertex edge set. also denote adjacency matrix i.e. paper assume variable gaussian distribution precision matrix then graph structure encoded zero pattern estimated i.e. edge formed denote objective function. ggms empirical covariance matrix. induce sparse graph penalty applied obtain following objective function. ﬁrst property implies favors graph following given degree distribution. suppose true graph node degree denote edge sets size. degree distribution prove following result denote expected number nodes degree estimate prior degree distribution given. supposing nodes ranked descending order degree denote estimated degree ranked node based power-law distribution further know desired number predicted edges node assumed proportional told output edges expected degree following content would denote expected degree node question rank nodes degrees? although exact degree node available approximate lovasz extenion i.e. rank nodes lovasz extension. note although lovasz extension implementation approximations norm also used rank nodes without losing accuracy. since would like regularizer smaller value denoted always favorable. brieﬂy prove theorem since scale-free large percentage nodes small degrees. reasonable assume nodes degree. denote degree. without loss generality exists node connecting construct graph connecting disconnecting since concave function nodes degree construct .... procedure ﬁnally obtain non-scale-free graph smaller value. theorem proved. since theorem shows global description scalefree property ideal choice inducing scalefree graph propose prior describe degree individual node target graph. intuitively given node rank potential edges adjacent descending order |xuv| higher rank likely true edge lower rank receive less penalty. account intuition introduce nondecreasing positive sequence following prior node represents node ranked position. elements same prior simply norm. work moderately increasing positive sequence pair larger estimated |xuv| smaller penalty. hand want penalize edges differently since penalty based upon rough estimation edge strength. dual vector updated step size. actually small percentage nodes large degrees speed using condition much smaller instead ranking nodes need select them done much faster. propose algorithm solve spirit dual decomposition algorithm. note ranking nodes degrees static. instead determined dynamically optimization algorithm. whenever estimation node edge ranking changed. node-speciﬁc degree prior dynamic instead static. used control sparsity level. challenge minimizing lies fact know ranking nodes edges advance. instead determine ranking dynamically. admm algorithm solve introducing dual variables follows. ﬁrst-order method gradient descent optimize ﬁrst subproblem since convex. paper assume gaussian likelihood case solved eigen-decomposition. describe novel algorithm here simply denote permutation denote element permutation. reason introduce given without constraint optimal adding constraint relaxed solving following problem parameter node smooth scale-free distribution. without prior knowledge easy determine value note objective function convex even convex log-sum function involved. objective optimized reweighing penalty step method guaranteed converge local optimal. parameter diagonal estimated previous iteration sug\u0001i gested authors. control sparsity i.e. number predicted edges. recently proposed lovasz extension approach approximate node degree convex function. convex function reweighed larger penalty applied edges relatively larger strength. turns kind convex function prior work well need predict edges shown experiments. further consider global degree distribution instead degree node. obviously holds consider remaining section. yv={ ˆyv} feasible solution deﬁne cluster structure follows. deﬁnition ˆyv} ranked feasible solution. supposing ˆyv| ˆyv| ˆyv| ˆyv| ˆyv} form cluster denote similarly deﬁne assume ˆyv} clustered groups. supplementary material detailed proof based propose novel dynamic programming algorithm solve reduced problem ﬁnding constrained optimal partition bv}. bv}. {|bv| following theorem. {c|y theorem equal theorem clearly shows problem satisﬁes optimal substructure property thus solved dynamic programming. algorithm solve proposed. supplementary material proof substructure property correctness algorithm. algorithm duplicates times. tested method real gene expression datasets types simulated networks scale-free network generated barabasi-albert model network nodes. generated data simulated scale-free network corresponding multivariate gaussian distribution. compared method graphical lasso neighborhood selection reweighted regularization lovasz extenion recent detection method generated network nodes model. entry precision matrix forms edge otherwise. make precision matrix positive deﬁnite diagonal minimum eigenvalue plus total generate data samples corresponding multivariate gaussian distribution hyperparameters methods described last section. figure simulation results scale free network. gaussian graphical model used x-axis number predicted edges y-axis number correctly predicted edges. forms others terms prediction accuracy. surprising outperform glasso since former methods speciﬁcally designed scale-free networks. lovasz also designed scale-free networks would outperform glasso number predicted edges increase. figure displays log-log degree distribution true network networks estimated glasso. yield networks satisfying power-law distribution glasso conﬁrms indeed favor scale-free networks. figure visualization network nodes edges. visualization purpose ignore connected component less equal nodes. also highlight nodes whose degree least proposes method speciﬁcally graph hubs applies group lasso penalty. particular decompose sparse symmetric matrix matrix whose column almost entirely zero non-zero. intuitively describes relationship non-hubs hubs. formulate problem follows. figure left right log-log degree distribution true network estimated networks glasso respectively. linear relationship expected since true network scale-free. network yielded glasso violates power-law distribution most evidenced point close also tested method network contains nodes large degrees strictly follows scale-free property. figure visualization larger dots indicate nodes. dream network inference challenge dataset simulated gene expression data samples. dream also provides ground truth network dataset. details. result figure shows method outperforms others although method speciﬁcally designed networks. shows also performs well graph non-uniform degree distribution without strict scale-free property. test method used dream dataset respectively. dataset contains samples genes ground truth consists edges. dataset contains samples genes ground truth consists edges. datasets challenging data noisy without gaussian scale-free property. dataset predicted edges allowed submission team competing contest. detailed description data sets. determine hyper parameters methods output exactly number edges. shown figure method obtains much higher accuracy others dream dataset compare degree distribution different methods chose values hyper-parameters also tested result dream dataset algorithms time consuming method glasso. according test algorithm glasso perform good dataset algorithm still outperforms glasso terms accuracy. actually accuracy times glassso presented novel node-speciﬁc degree prior study inference scale-free networks widely used model social biological networks. prior promotes desirable global node degree distribution also takes consideration estimated degree individual node relative strength possible edges adjacent node. fulﬁll this developed ranking-based algorithm dynamically model degree distribution given network. optimization problem resulting prior quite challenging. developed novel admm algorithm solve demonstrated superior performance prior using simulated data three dream datasets. prior greatly outperforms others terms number correctly predicted edges especially real gene expression data. idea presented paper potentially useful degree-constrained network inference problem. particular might applied infer protein residueresidue interaction network multiple sequence alignment predict degree distribution residue using supervised machine learning method. d’aspremont alexandre. model selection sparse maximum likelihood estimation multivariate journal machine gaussian binary data. learning research boyd stephen parikh neal eric peleato borja eckstein jonathan. distributed optimization statistical learning alternating direction method multipliers. foundations trends machine learning defazio aaron caetano tiberio convex formulation learning scale-free networks submodular relaxation. advances neural information processing systems wainwright martin lafferty john ravikumar pradeep high-dimensional graphical model selection using l-regularized logistic regression. advances neural information processing systems friedman jerome hastie trevor tibshirani rob. regularization paths generalized linear models coordinate descent. journal statistical software fukushima masao. application alternating direction method multipliers separable convex programming problems. computational optimization applications kwang-il cusick michael valle david childs barton vidal marc barab´asi albert-l´aszl´o. human disease network. proceedings national academy sciences marbach daniel costello james k¨uffner robert vega nicole prill robert camacho diogo allison kyle kellis manolis collins james stolovitzky gustavo wisdom crowds robust gene network inference. nature methods mohan karthik london palma fazel maryam witten daniela su-in. node-based learning multiple gaussian graphical models. journal machine learning research", "year": 2015}