{"title": "Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from  Simulation", "tag": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "abstract": "Learning-based approaches to robotic manipulation are limited by the scalability of data collection and accessibility of labels. In this paper, we present a multi-task domain adaptation framework for instance grasping in cluttered scenes by utilizing simulated robot experiments. Our neural network takes monocular RGB images and the instance segmentation mask of a specified target object as inputs, and predicts the probability of successfully grasping the specified object for each candidate motor command. The proposed transfer learning framework trains a model for instance grasping in simulation and uses a domain-adversarial loss to transfer the trained model to real robots using indiscriminate grasping data, which is available both in simulation and the real world. We evaluate our model in real-world robot experiments, comparing it with alternative model architectures as well as an indiscriminate grasping baseline.", "text": "fig. multi-task domain adaptation instance grasping. multi-task domain adaptation framework trains deep neural network instance grasp prediction simulation utilizing real simulated indiscriminate grasping data mitigate domain shift simulation real world. robot hardware details relevant paper blurred images preserve conﬁdentiality. domain another. context transferring learned policy simulation real world transfer achieved feeding real simulated data neural network applying similarity loss regularize difference extracted features domains. process usually still needs collect sufﬁcient amount realworld data order learn target task. paper address problem sim-to-real transfer labeled data available real world. speciﬁcally address problem context instance grasping goal grasp particular object instance cluttered scene. challenging terms perception control compared refer indiscriminate grasping robot grasp objects workspace indiscriminately. importantly unlike recent works indiscriminate grasping labeled real-world data instance grasping would need sophisticated perception system robustly identify track target object across time. overcome hurdle propose simulation collect labeled data instance grasping. furthermore resolve domain shift issue propose multi-task domain adaptation framework trains deep neural abstract— learning-based approaches robotic manipulation limited scalability data collection accessibility labels. paper present multi-task domain adaptation framework instance grasping cluttered scenes utilizing simulated robot experiments. neural network takes monocular images instance segmentation mask speciﬁed target object inputs predicts probability successfully grasping speciﬁed object candidate motor command. proposed transfer learning framework trains model instance grasping simulation uses domain-adversarial loss transfer trained model real robots using indiscriminate grasping data available simulation real world. evaluate model real-world robot experiments comparing alternative model architectures well indiscriminate grasping baseline. recent progress deep learning reinforcement learning large scale learning-based methods used robotic manipulation methods enable replace manually designed perception control pipelines end-to-end neural networks learned large training datasets. however chanllenging apply methods complex real-world manipulation tasks reasons first collecting data repeated robot experiments real world time consuming. second evaluation annotation ground truth success labels expensive sometimes infeasible. although previous works designed experimental platforms automatically collect label data non-semantic tasks indiscriminately grasping object tray quickly challenging terms data collection switching tasks different settings. alternative solution large scale data collection robotics robot experiments simulation simulated robot experiments parallelizable easily reset. addition simulation also provides access ground-truth states robot environment making straightforward generate labeled data. however learning simulated data yield robust real-world performance reality real world simulation terms robotic perception physics. general phenomenon known domain shift model trained data domain generalize well another target domain. common approach mitigate domain shift domain adaptation transfer learned knowledge network instance grasp prediction simulation utilizing real simulated indiscriminate grasping data mitigate domain shift intuition using indiscriminate grasping data indiscriminate instance grasping share similar properties regarding robot action space perception. framework shares model parameters indiscriminate grasp prediction instance grasp prediction trains tasks simultaneously. meanwhile enforces extracted features transferable simulation real world domain adaptation. method demonstrated robot instance grasping using images inputs captured moving monocular camera mounted robot arm. mask r-cnn segmentation masks object instances sampled specify target object grasping. method relies single segmentation mask obtained beginning grasp rather requiring segmentation mask time-step. evaluate method showing robot grasping variety household dishware objects well generalization unseen objects instance grasp training simulation. main contributions multi-task domain adaptation framework trains model instance grasping simulation uses domain-adversarial loss transfer trained model real robots using indiscriminate grasping data available simulation real world. deep neural network architecture takes monocular images instance segmentation mask speciﬁed target object inputs predicts probability successfully grasping speciﬁed object candidate motor command. demonstrate method robot platform mounted moving monocular camera. showed instance grasping variety household dishware objects generalization unseen objects instance grasp training simulation. rest paper laid follows. section discuss related work. section introduce necessary background end-to-end grasp prediction domain adaptation upon work based. describe main algorithmic contributions section experimental method results real robots presented section finally discuss potential directions future work section robotic grasping. grasping fundamental robot manipulation tasks. geometry-based data-driven methods proposed address problem robotic grasping. recent works used deep learning train models predict grasp success directly visual sensor inputs beneﬁt generalization. works focused semantic grasping robot picks object transfer learning simulation real robots. deep learning methods robotic manipulation usually require large amounts data order million trials recent works considered using simulation train robotic manipulation scale data collection. saxena used rendered objects learn vision-based grasping model. rusu introduced progressive neural networks adapt existing deep reinforcement learning policy trained reaching task simulation real world. however differences dynamics observation models solving problem simto-real transfer ensuring policies trained simulation work real world addressing sim-to-real transfer choose input modalities reality signiﬁcant. option depth image abstracts away many appearance properties real-world objects hard render. number recent works used simulated depth images learn indiscriminate grasping deep convolutional neural networks deploy trained policy real robot calibrated ﬁxed depth camera wrist mounted depth camera indiscriminate grasping. work tackles instance grasping problem much difﬁcult. addition monocular images without relying either camera calibration object geometry information. believe considerable value studying grasping systems images only considering relatively cost monocular cameras limitations depth cameras recent works shown success using domain randomization transferring deep neural network trained simulated images real world solving end-to-end robot manipulation mobility tasks works extended prior works data augmentation computer vision applied randomization parameters camera position lighting texture simulation. however simple geometries like cubes free space motions considered prior methods. contrast address problem grasping diverse naturalistic household objects like bowls cups much complex terms perception contact physics. furthermore also demonstrate sim-toreal transfer generalization objects never seen training simulation. domain adaptation process allows learning model trained samples source domain case simulation domain generalize target domain real world. feature-level domain adaptation focuses learning domain-invariant features either learning transformation ﬁxed pre-computed features source target domains learning domain-invariant feature extractor often tzeng perform sim-to-real transfer fig. pipeline obtaining segmentation mask target object. given initial camera image forward mask r-cnn predict instance segmentation masks detection bounding boxes segmentation masks different object instances shown different colors assigned object shown upper left corner. target object sampled segmentation mask deﬁned target mask manipulation task using adversarially trained domain discriminator nearest neighbor learned feature space weak pairings. recent study used combined feature-level pixel-level domain adaption learning robotic hand-eye coordination grasping variety everyday objects training primarily simulation data small amount labeled real-world data. work uses feature-level domain adaptation particularly propose multi-task domain adaption method address lack labeled data instance grasping real world. instance segmentation object detection. object detection segmentation long standing computer vision problem. several recent deep learning techniques made signiﬁcant progress direction. work mask rcnn trained synthetic images segment objects background real-world images. gives easy specify object grasp without manually labeling objects image. proposed method could potentially also trained bounding pixels object input instead instance mask. however exploration alternative input modalities left future works. work follow formulation real-world experimental setup end-to-end grasp prediction described goal choose sequence robot actions step step given current input image order control robot gripper grasp object cluttered scene. denote grasp prediction network input images robot camera initial time step current time step given robot command sampled action space represents neural network parameters. time step grasping network predicts probability grasp success sampled actions chooses action highest predicted probability success. cross-entropy method iterations action sampling distributions centered around regions high grasp success probability. dataset training grasp prediction network collected controlling gripper repeatedly attempt grasp objects tray randomly selected objects drop back. process starts exploring random policy beginning switches updated network parameters. real world ground truth success label automatically determined hard coded perception system grasping episode. done taking images tray comparing pixel differences dropping object. simulation determine success label checking object position. grasp prediction network trained using loss ground truth success labels. adversarial loss training penalize domain shift simulation real world similar recent study adversarial loss regularizes neural network weights domain classiﬁer represents parameters domain classiﬁer. problem setup target domain real world source domain simulation. training data different domains grasp prediction network. domain classiﬁer takes input intermediate feature extracted neural network trained predict domain feature from maximizing binomial cross-entropy respect meanwhile minimize adversarial loss respect fig. multi-task domain adaptation framework. framework composed three grasp prediction towers domain classiﬁer. tower takes training data three task domains real-world indiscriminate grasping simulated indiscriminate grasping simulated instance grasping. neural networks three towers share parameters denoted dashed lines. framework neural network trained predict instance grasp success probability transferable features simulation real world minimizing four losses simultaneously respect network parameters. goal instance grasp prediction predict probability successfully grasping speciﬁed object candidate motor command. target object speciﬁed segmentation mask given beginning episode grasping starts. predict success probability instance grasping deﬁne instance grasp prediction network extending formulation indiscriminate grasping addition images robot commands instance grasp prediction network also uses segmentation mask target object input. order predict instance grasp success given sampled action network required understand relative location gripper target object fusing information together. training collect instance grasping data simulation. crucial keep labels successful failed trials balanced training. directly running random policy data collection yields successful trials. improve sample efﬁciency hindsight data collection trick inspired ﬁrst indiscriminate grasping data collection described successful indiscriminate grasping trial generate successful instance grasping trial taking mask grasped object input target mask failed instance grasping trial using mask sampled objects. result grasping trials pipeline sampled segmentation mask shown fig. given initial image test time ﬁrst mask r-cnn predict instance segmentation masks mask assigned unique object instance sample object corresponding segmentation mask target object. note rely initial segmentation mask input instance grasp prediction neural network. since robot camera attached pan-tilt unit mounted ﬁrst link results viewpoint changing moves around. therefore align target object following images however still effective provide information location target object fusing segmentation images input neural network discussed section iv-c. multi-task domain adaptation framework shown fig. framework composed domain classiﬁer three grasp prediction towers training data three task domains real-world indiscriminate grasping data simulated indiscriminate grasping data simulated instance grasping data simplicity notation represent simulation real world represent indiscriminate grasping instance grasping respectively. three grasp predicfig. representative synthetic image training mask r-cnn. image consist real background image objects rendered ground truth detection bounding segmentation mask overlaid rendered object. pixel candidate object grasped. interpretation mask object covered mask grasped robot order achieve success interpretation consistent across instance grasping indiscriminate grasping tasks. enables train three task domains input modalities avoid training additional layers simulated instance grasping data. show architecture details instance grasp prediction network fig. original images target masks cropped input network. candidate gripper motor command vector dimensions translation vector sine-cosine encoding change orientation. adopt layers extract level features images motor commands. extract target mask features introduce separate stream convolutional layers. mask stream maps target mask convolutional feature matches spatial size features stream. features streams concatenated ﬁnal convolutional layer fully connected layers merge information predict instance grasp success probability. fast convergence rate training convolutional layers fully connected layers usually need batch normalizations however discussed sharing batch normalization parameters across domains significantly harm performance testing domain adaptation framework. inconsistent behaviors batch normalization layers training testing. resolve problem remove batch normalization layers grasp prediction network. instead instance normalization convolutional layers layer normalization fully connected layers also guarantees fast convergence rate consistent behaviors training testing. fig. instance grasp prediction network. taking initial current camera images candidate motor command target mask inputs network predicts instance grasp success probability candidate motor command. convolutional layer parameters shown fully-connected layer parameters shown pooling layer parameters shown weights loss terms. instance grasp prediction loss trains neural network predict instance grasp success probability simulation. indiscriminate grasp prediction loss train neural network extract meaningful features grasp prediction simulation real world. adversarial loss ladversarial regularizes neural network parameters domain classiﬁer. attempting confuse domain classiﬁer neural network learns extract features transferable simulation real world. three towers instance grasp prediction network architecture share network parameters. since segmentation mask input available instance grasping task feed constant mask indiscriminate grasping towers. constant mask marks every fig. examples models used data collection simulation. totally models scanned real-world dishware objects including bowls mugs cups teapots etc. object textures rendered simulation. fig. testing objects real world. grasping trial combination objects chosen tray front robot. target object sampled detected objects tray using mask-rcnn. order provide instance detection segmentation apply mask r-cnn initial image. mask r-cnn trained synthetically generated images i.e. images consist real background image objects rendered ensure training uniformly covers whole pose space interest including possible translations rotations could potentially observe objects. although occlusion explicitly covered training trained mask-rcnn demonstrates capability detecting segmenting object instances cluttered scenes. collect real-world indiscriminate grasping data automatic data collection platform similar indiscriminate grasping jaco robot arms random policy well policy using trained model collect grasping trials total around unique dishware objects. standard data augmentation methods including random cropping random image distortion increase data diversity. collect instance indiscriminate grasping data simulation basic virtual environment built based bullet physics simulator simple software renderer shipped bullet used rendering. scanned models household dishware objects objects grasped simulation environment emulates jaco robot setup simulating physics grasping rendering moving camera mounted robot would perceive robot gripper contains objects dishware objects grasped. collect million indiscriminate grasping trials using random policy policy iteratively trained models objects tray episode. data labeled post-hoc instance grasping described sec. iv-a. train gpus iterations learning rate decayed every iterations momentum batch size data three task domains. training starts three grasp prediction losses adversarial loss added iterations weights loss terms iv-b chosen hyperparameters selected experiments without tuning instance grasping validation datasets. evaluate instance grasping performance real world trials method across jaco robot arms. trial place combination objects tray. object combinations chosen dishware objects various colors shapes shown fig. objects chosen present real-world indiscriminate grasping dataset however held instance grasping dataset collected simulation. table shows detail results. framework achieves success rate instance grasping. among failed instance grasping attempts attempts ended grasping wrong object attempts failed grasping anything tray. details videos found https//sites.google.com/view/multi-task-domainadaptation/ number ablations evaluation settings analyze instance grasping results multitask domain adaptation framework. detailed comparisons shown table fig. indiscriminate instance grasp prediction network instance grasp prediction network controls gripper grasp speciﬁed target object. indiscriminate grasp prediction network distinguish objects. show difference indiscriminate grasping trials using network trained indiscriminate grasp prediction sim-to-real domain adaptation algorithm single task indiscriminate policy robot gripper table performance instance grasping real-world experiments. method trials across jaco robot arms. show numbers successful instance grasps wrong object grasps failed grasps instance grasping success rate. method achieves highest instance grasping success rate among four described v-d. mask. thus modify framework sharing convolutional layer parameters stream instance indiscriminate networks train fully connected layers instance grasping. layers trained simulation framework achieves grasping success rate instance grasping. shows performance gains introducing constant masks using network architectures. work introduce multi-task domain adaptation framework instance grasping cluttered scenes using simulated robot experiments. framework collects labeled instance grasping data simulation uses domain-adversarial loss transfer trained model real robots using indiscriminate grasping data simulation real world. also presented deep neural network takes monocular images instance segmentation mask input predicts probability successfully grasping speciﬁed object candidate motor command. demonstrated method real robot platform grasping household dishware objects never seen training simulation. showed model outperforms alternative model architectures indiscriminate grasping baseline. limitation using mask r-cnn predict segmentation masks work well objects occluded robot gripper happens frequently grasping. addition cannot mask r-cnn every single time step computational expenses. therefore predict segmentation mask initial image. model extracts effective information single segmentation mask would interesting instance grasping performance improved updating segmentation masks later time steps. work segmentation mask input modality specifying target object. options specifying target objects detection bounding boxes user-speciﬁed pixels object. straightforward extend method alternative input modalities. although choose instance grasping indiscriminate grasping problem setup framework potentially applied tasks share similar properties e.g. robot picking placing. incorporating framework robot tasks exciting avenue future works. successfully grasps objects tray trials. since targets speciﬁed many grasps easy objects. show discrepancy objectives tasks also sample target masks evaluate grasp hits target trial instance grasping task. trials grasping correct target objects. two-tower three-tower transferring ability adversarial loss comes training network confuse adversarial loss. domain shift difﬁcult resolve using real world indiscriminate grasping data simulated instance grasping data since objective perception task domains different. demonstrate this take twotower domain adaptation framework using data task domains. adversarial loss applied real world indiscriminate grasping data simulated instance grasping data without using simulated indiscriminate grasping data bridge gap. instance grasp success rate two-tower framework comparing three-tower model two-tower model failed grasping objects trials. suggests framework transfers learned instance grasping policy better two-tower framework. using constant masks training additional layers dealing different input modalities indiscriminate instance grasping alternative using constant masks using different network architectures tasks. however additional layers used instance grasping since extracted features different without information target thank adrian peter pastor wilkes kurt konolige contributions software hardware development grasping infrastructures. thank alex irpan paul wohlhart konstantinos bousmalis discussions training implementation domain classiﬁer. thank john-michael burke supports real-world robot experiments. levine pastor krizhevsky ibarz quillen learning hand-eye coordination robotic grasping deep learning large-scale data collection international journal robotics research tobin fong schneider zaremba abbeel domain randomization transferring deep neural networks simulation real world arxiv preprint arxiv. james davison johns transferring end-to-end visuomotor control simulation real world multi-stage task arxiv preprint arxiv. mahler liang niyaz laskey doan ojea goldberg dex-net deep learning plan robust grasps synthetic point clouds analytic grasp metrics arxiv preprint arxiv. ganin ustinova ajakan germain larochelle laviolette marchand lempitsky domain-adversarial training neural networks journal machine learning research vol. tzeng devin hoffman finn abbeel levine saenko darrell adapting deep visuomotor representations weak pairwise constraints workshop algorithmic foundations robotics bousmalis irpan wohlhart kelcey kalakrishnan downs ibarz pastor konolige levine vanhoucke using simulation domain adaptation improve efﬁciency deep robotic grasping arxiv preprint arxiv. girshick donahue darrell malik rich feature hierarchies accurate object detection semantic segmentation ieee conference computer vision pattern recognition l.-c. chen papandreou kokkinos murphy yuille deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs ieee transactions pattern analysis machine intelligence rubinstein kroese cross-entropy method uniﬁed approach monte carlo simulation randomized optimization machine learning information science statistics springer verlag ioffe szegedy batch normalization accelerating deep network training reducing internal covariate shift international conference machine learning", "year": 2017}