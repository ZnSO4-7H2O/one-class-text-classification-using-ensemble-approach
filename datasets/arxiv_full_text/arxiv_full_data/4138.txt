{"title": "Automatic learning of gait signatures for people identification", "tag": ["cs.CV", "cs.AI"], "abstract": "This work targets people identification in video based on the way they walk (i.e. gait). While classical methods typically derive gait signatures from sequences of binary silhouettes, in this work we explore the use of convolutional neural networks (CNN) for learning high-level descriptors from low-level motion features (i.e. optical flow components). We carry out a thorough experimental evaluation of the proposed CNN architecture on the challenging TUM-GAID dataset. The experimental results indicate that using spatio-temporal cuboids of optical flow as input data for CNN allows to obtain state-of-the-art results on the gait task with an image resolution eight times lower than the previously reported results (i.e. 80x60 pixels).", "text": "works given low-level optical maps directly extracted video frames able learn extract higher-level features suitable representing human gait gait signature. best knowledge ﬁrst work convolutional neural networks applied problem gait identiﬁcation using input optical features. therefore main contributions preprocessing stage extract organize normalize low-level motion features deﬁning input data; convolutional neural network architecture extract discriminative gait signatures low-level motion features; thorough experimental study validate proposed framework standard tum-gaid dataset gait identiﬁcation obtaining state-of-the-art results video frames whose size eight times smaller ones used previously reported results. rest paper organized follows. start reviewing related work sec. overview fundamentals convolutional neural networks presented sec. sec. explains approach learning gait signatures identifying people. sec. contains experiments results. finally present conclusions future work sec.. work targets people identiﬁcation video based walk classical methods typically derive gait signatures sequences binary silhouettes work explore convolutional neural networks learning high-level descriptors low-level motion features carry thorough experimental evaluation proposed architecture challenging tum-gaid dataset. experimental results indicate using spatio-temporal cuboids optical input data allows obtain state-of-the-art results gait task image resolution eight times lower previously reported results goal gait recognition identify people walk. type biometric approach considered non-invasive since performed distance require cooperation subject identiﬁed contrast methods irisﬁngerprint-based approaches. gait recognition application context video surveillance ranging control access restricted areas early detection persons interest example v.i.p. customers bank ofﬁce. computer vision point view gait recognition could seen particular case human action recognition. however gait recognition requires ﬁne-grained features action recognition differences different gait styles usually much subtle common action categories included state-of-the-art datasets last years great effort problem people identiﬁcation based gait recognition however previous approaches mostly used hand-crafted features representing human gait easily scalable diverse datasets. therefore propose end-to-end approach based convolutional neural net. related work hand-crafted features. traditional representation used gait recognition. main approaches stand rest silhouette-based dense trajectoriesbased. silhouette-based descriptors used state-of-the-art frameworks. sense popular silhouette-based gait descriptor called gait enery image idea compute temporal averaging binary silhouette target subject. improve performance gait recognition propose computation descriptors chrono-gait image martin-felez xiang using basic gait descriptor propose ranking model allows leverage training data different datasets. proposes regularized local tensor discriminant analysis method enhanced gabor representation gei. addition author deﬁnes method identify camera viewpoints test time patch distribution features. lately guan proposed novel approach deal covariate factors gait recognition using descriptor basis. although binary silhouettes widely extended shown excellent results several scenarios computation noiseless silhouettes critical issue always easy achieve. therefore paper choose features. recently increasing number publications based dense trajectories appeared context action recognition video. main idea approaches compute short-term trajectories densely sampled points describing mainly human motion. dense trajectories described concatenation different histograms like histograms oriented gradients histograms optical flow motion boundary histograms alternative representation proposed jain instead using kind descriptor based partial derivatives optical ﬂow. finally trajectories summarized video level using fisher vectors successful gait descriptor based approach called ‘pyramidal fisher motion’ reported state-of-the-art results several gait datasets however requires application carefully selected feature extraction steps machine learning techniques goal paper. deep-learnt features. traditionally deep learning approaches based convolutional neural networks used image-based tasks great success last years deep architectures video appeared specially focused action recognition inputs subsequences stacked frames. simonyan zisserman proposed input volume obtained concatenation frames channels contain optical x-axis y-axis respectively. normalize size inputs split original sequence subsequences frames considering subsample independently. donahue propose another point view deep learning using novel architecture called long-term recurrent convolutional networks. architecture combines recurrent neural networks obtain model able deal visual temporal features time. recently wang combined dense trajectories deep learning. idea obtain powerful model combines deep-learnt features temporal information trajectories. train traditional dense trajectories extract deep features build ﬁnal descriptor combines deep information time. hand perronnin propose traditional approach using fisher vectors input deep neural network instead using classiﬁers like svm. although several papers found task human action recognition using deep learning techniques hard type approaches applied problem gait recognition. hossain chetty propose restricted boltzmann machines extract gait features binary silhouettes small probe used validating approach. approach takes idea simonyan zisserman uses spatio-temporal volume optical input specially designed gait recognition. convolutional neural network model important type feed-forward neural network special success applications target information represented hierarchy local features deﬁned composition several convolutional layers several fully connected layers. convolutional layer general composition non-linear layer pooling sub-sampling layer spatial invariance. images non-lineal layer takes advantage local connections weight sharing structure present data. conditions impose strong regularization total number weights model allows successful training model using back-propagation. approach although feed model directly image pixels approach remains relevant since optical information also shares local dependency property pixels figure pipeline gait recognition. input sequence video frames. optical computed along sequence. optical maps cropped stacked subsequences maps. optical subsequences passed obtain gait signatures. classiﬁcation extracted gait signatures. note positive ﬂows displayed pink negative ﬂows blue results many different complex applications however extent knowledge applied problem gait recognition yet. great success model part data target represented feature hierarchy increasing semantic complexity. successfully trained output last hidden layer seen coordinates target high level representation space. fully connected layers convolutional ones allow reduce dimensionality representation therefore improve classiﬁcation accuracy. section describe proposed framework address problem gait recognition using cnn. pipeline proposed gait recognition based represented fig. compute optical along whole sequence; build data cuboid consecutive maps; feed cuboid extract gait signature; apply classiﬁer decide subject identity. input data optical input data action representation video already shown excellent results nevertheless human action represented wide usually well deﬁned local motions. case motions differentiating gait style another much subtle local. important question whether gait information decoded simple resolution optical ﬂow. computed time therefore value vector component located coordinates either horizontal vertical component corresponding vector. input data cuboids built stacking consecutive maps corresponds value horizontal vertical components located spatial position time respectively ranging interval since original video sequence probably different temporal length requires ﬁxed size input extract subsequences frames fulllength sequences. fig. show frames distributed every frames along subsequence twenty-ﬁve frames total frames show horizontal component bottom frames show vertical component observed concentrated horizontal component displacement person. order remove noisy located background observed fig. might think applying preprocessing step ﬁltering vectors whose magnitude given interval. however since goal work minimize manual intervention process gait signature extraction maps returned algorithm. implementation details first resize video frames common size pixels keeping original aspect ratio video frames. then compute dense pairs frames using method farneback implemented opencv library. parallel people located rough manner along video sequences background substraction then crop video frames remove part background obtaining video frames pixels align subsequences fig. finally cropped maps build subsequences frames stacking maps overlap frames. case chose build subsequence frames previous subsequence frames. state-of-the-start datasets frames cover almost complete gait cycle stated authors order increase number samples available training compute spatial displacements pixels directions i.e. then corresponding mirror sequences computed. procedure allows obtain training samples. finally feeding sample mean value whole training dataset subtracted. architecture propose gait recognition based described general action recognition video. however case input size obtained sequence frames corresponding channels explained previous section. proposed composed following sequence layers ‘conv’ ﬁlters size applied stride followed normalization pooling ‘conv’ ﬁlters size applied stride followed pooling ‘conv’ ﬁlters size applied stride followed pooling ‘conv’ ﬁlters size applied stride figure proposed architecture gait signature extraction. four convolutional layers followed fully connected layers. layer softmax classiﬁer used directly derive identity. ‘full’ fully-connected layer units dropout; ‘full’ fully-connected layer units dropout; ‘softmax’ softmax layer many units subject identities. convolutional layers rectiﬁcation activation function. implementation details implementation provided matconvnet library library allows develop architectures easy fast manner using matlab environment. addition takes advantage cuda cudnn improve performance algorithms. perform training following iterative process speed facilitate convergence. iterative process initially train simpliﬁed version then weights initializing layers complex version simpler train four incremental versions using previous weights obtain ﬁnal architecture represented fig. training weights learnt using mini-batch stochastic descent algorithm momentum equal ﬁrst three version iterations last one. weight decay dropout learning rate initially divided validation error become stagnant. epoch minibatch samples constructed random selection balanced training obtained gait signatures ﬁnal stage consists classifying signatures derive subject identity. although softmax layer already classiﬁer fully-connected layers play role gait signatures used input support vector machine classiﬁer. since dealing multiclass problem deﬁne ensemble binary classiﬁers linear kernel ‘one-vs-all’ fashion number possible subject identities. previous works indicate conﬁguration binary classiﬁers suitable obtain top-tier results problem. note l-normalize fullyconnected layer using feature vector. classical alternative discriminative classiﬁers nearest neighbour classiﬁer require training step. actually easily extend gait recognition system adding samples subjects gallery note sec. split whole video sequence overlapping subsequences ﬁxed length subsequences classiﬁed independently. therefore order derive ﬁnal identity subject walking along whole sequence apply majority voting strategy labels assigned subsequence. experiments recent ‘tum gait audio image depth’ dataset gait recognition. tum-gaid subjects perform walking trajectories indoor environment. ﬁrst trajectory performed left right second right left. therefore sides subjects recorded. recording sessions performed january subjects wore heavy jackets mostly winter boots second april subjects wore different clothes. action captured microsoft kinect sensor provides video stream resolution pixels frame rate approximately fps. examples seen fig. depicting different conditions included dataset. hereinafter following nomenclature used refer four walking conditions considered normal walk carrying backpack approximately wearing coating shoes used clean rooms hygiene conditions elapsed time subject dataset composed sequences normal walking sequences carrying sequences wearing coating shoes addition subjects recorded sessions additional sequences therefore overall amount videos standardize experiments performed dataset authors deﬁned three subsets subjects training validation testing. training used obtaining robust model different covariates dataset. partition composed subjects figure tum-gaid dataset. people walking indoors four walking conditions normal walking wearing coats carrying wearing coating shoes. bottom rows show subjects different months year. sequences validation used validation purposes contains different subjects sequences finally test contains different subjects used test phase. subjects different test training training identiﬁcation model must performed. purpose authors reserve sequences subject test train model rest sequences used testing obtain accuracy model. elapsed time experiment temporal sequences used instead normal ones subsets subjects training subjects validation subjects test set. viability experiments resized videos resolution pixels nevertheless show experimental results obtain state-of-theart results resolution what opinion highlights potential gait recognition. test sample return sorted list possible identities identity corresponds largest scored one. therefore following metrics quantitative measure performance proposed system rank- rank-. metric rank- measures percentage test samples assigned identity corresponds right one. whereas rank- measures percentage test samples ground truth identity included ﬁrst ranked identities corresponding test sample. note rank- less strict rank- real system would allow verify target subject probably ones. experiment gait recognition clothing carrying conditions. core experiment paper evaluating capacity proposed model extract gait signatures robust enough deal covariate factors clothing changes carrying conditions fact model trained used subsequent experiments. training convolutional ﬁlters carried using sequences standard training validation subject partitions tumgaid including three scenarios. model trained samples learnt weights layers ‘conv’ ‘full’ frozen order evaluate performance cnn-based gait signatures test subject partition softmax layer ﬁne-tuned using training sequences scenario test subject partition subject identities changed. however classiﬁers ﬁne-tuning needed output layer ‘full’ directly gait signature results experiment summarized tab. corresponds different combination features classiﬁers softmax ‘sm’ support vector machine ‘svm’ nearest neighbour ‘nn’. column contains recognition results diverse scenarios included dataset plus average three scenarios completeness report rank- rank- results. moreover comparison purposes implemented ‘pyramidal fisher motion’ descriptor described since need binary silhouettes input computation previously reported stateof-the-art results problem gait recognition note used descriptor original resolution video sequences resolution version sequences allow fair comparison cnnbased gait signatures resolution version. ‘pfm used whole video sequence compute single descriptor original paper whereas ‘pfm computed several using subsequences extracted making even much fairer comparison. classiﬁcation sequence majority voting applied obtain ﬁnal identity. experiment elapsed time. goal experiment evaluate robustness cnn-based gait signatures changes people appearance different periods time. experiment apply model trained ‘experiment ‘elapsed time’ subset tum-gaid composed subjects training validation testing. training sequences ‘normal’ scenario test subjects obtained samples used ﬁne-tune softmax layer trained previous experiment subject identities changed. then used test sequences three elapsed time scenarios evaluate performance. results experiment summarized tab. corresponds different combination features classiﬁers including pfm. column presents recognition results diverse scenarios included elapsed time subset plus average three scenarios completeness report rank- rank- results. experiment gait-based gender recognition. gender recognition based gait signatures considered kind soft biometric allows prune subset subjects subsequent ﬁner identiﬁcation. goal experiment validate quality gait signatures learnt ﬁrst experiment train binary linear gender classiﬁcation. evaluation purposes train gender classiﬁer gait sequences included training validation subject partitions. tum-gaid provides labels video level task proportion male female subjects test respectively. results experiment summarized tab. show confusion matrices scenario plus overall accuracy classiﬁer. comparison purposes bottom contains accuracy reported task paper experiments computer cores nvidia tesla matconvnet library running matlab ubuntu splitting training sequences subsequences training composed samples used learning ﬁlters ‘conv’ ‘full’ layers second training composed samples training softmax layer subset test subjects. samples whole training process took hours. table experiment percentage correct recognition scenarios n-b-s tum-gaid dataset using rank- rank- metrics. corresponds different combination features classiﬁers. best average results marked bold. represented ﬁlter component spans pixels. ﬁrst aspect appreciable ﬁlters seems main types ﬁlters ﬁlters acting spatial derivatives patterns distinguishable like rows ﬁlters acting temporal derivatives mask frame mainly uniform changes intensity along frames like rows ‘c’. observations shared ones made simonyan zisserman applied action datasets. second aspect perceive difference x-ﬂow ﬁlters y-ﬂow ﬁlters. x-ﬂow ﬁlters exhibits structure deﬁned y-ﬂow ﬁlters noisy blurry. opinion difference fact main motion gait located horizontal axis displacement subject along axis. contrast vertical movements softer subtler getting ﬁlters less deﬁned. focusing ‘experiment results tab. indicate resolution frames trained model able extract gait signatures used combination standard classiﬁers attained average rank- correct recognition rank- accuracy. comparing obtained results quite similar although accuracy slightly better indicating good linear separability test subjects given extracted gait signatures. speeding-up classiﬁer -dimensional gait descriptors compressed standard principal components analysis algorithm vectors l-normalized mean subtracted obtaining compact signatures dimensions. average results reported rows ‘cnn-nn+pcax’ comparable ones yielded parametric classiﬁers making attractive combination cnnbased signatures training stage needed adding identities recognition system required. furthersubsets number samples walking scenario converged continued training different subset. training phase samples original training passed least twice guarantee good performance model. step performed would learn mainly specialized ﬁlters ‘normal’ walk four times samples kind others. method seim svim cnn-svm cnn-nn table state-of-the-art gaid. percentage correct recognition tum-gaid diverse methods published literature. bottom corresponds proposal instead using video frames resolution used. column corresponds different scenario. best results marked bold. table experiment confusion matrices gender recognition based convolutional gait signatures. scenario cell ‘cm’ contains percentage probe samples assigned gender. rows ‘acc’ contain overall accuracy scenario. gender recognition successfully addressed based motion features regardless scenario accuracy female recognition lower male recognition ratio among female male samples dataset. comparing results reported hofmann average three scenarios method whereas average method despite lower resolution video inputs. paper presented thorough study convolutional neural networks applied demanding problem people identiﬁcation based gait. experimental validation carried challenging dataset tum-gaid using resolution version original video sequences results indicate starting sequences optical proposed able extract meaningful gait signatures allow obtain high recognition rates available scenarios achieving state-of-the-art results contrast classical approaches gait recognition hand-crafted features mainly based binary silhouettes dense tracklets. terms classiﬁcation strategies ensemble ‘one-vs-all’ linear good choice although approach compressed descriptors offers similar accuracy requiring training step. finally shown table experiment percentage correct recognition scenarios tn-tb-ts tum-gaid dataset using rank- rank- metrics. corresponds different combination features classiﬁers. best average results marked bold. more proposal outperforms descriptor used resolution video sequences although average rank- accuracy full resolution around better cnn. nevertheless cnn-based signature extractor trained fully automatic manner contrast hand-crafted steps need computing pfm. focusing results scenarios conclude signatures able successfully represent discriminative motion patterns characterize different subjects regardless clothing shoes worn bags carried. remember used individuals totally different training ﬁlters used testing signatures obtained them. moving ‘experiment ‘elapsed time’ experiment proposed tum-gaid challenging previous temporal months recordings subjects. higher level difﬁculty reﬂected results tab. directly previously trained ‘experiment terms rank- accuracy behaves average better previously reﬂected ‘experiment however classiﬁers improves suggests subjects linearly separable given gait signatures. comparing full resolution version obtains average results slightly better good results achieved normal scenario. note results reported equal lower ones. comparing best results previously published ones observe tab. accuracy methods even though using video frames resolution eight times lower others. note average accuracy sets experiments greater ones reported compared papers emphasizes quality gait signatures returned proposed cnn. automatically learnt gait signatures suitable gender recognition would allow ﬁlter individuals running ﬁner identiﬁcation procedure. future work plan extend study datasets gait recognition multiple viewpoints available architectures combining data.", "year": 2016}