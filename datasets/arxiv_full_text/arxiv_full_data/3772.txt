{"title": "Clustering multi-way data: a novel algebraic approach", "tag": ["cs.LG", "cs.CV", "cs.IT", "math.IT", "stat.ML"], "abstract": "In this paper, we develop a method for unsupervised clustering of two-way (matrix) data by combining two recent innovations from different fields: the Sparse Subspace Clustering (SSC) algorithm [10], which groups points coming from a union of subspaces into their respective subspaces, and the t-product [18], which was introduced to provide a matrix-like multiplication for third order tensors. Our algorithm is analogous to SSC in that an \"affinity\" between different data points is built using a sparse self-representation of the data. Unlike SSC, we employ the t-product in the self-representation. This allows us more flexibility in modeling; infact, SSC is a special case of our method. When using the t-product, three-way arrays are treated as matrices whose elements (scalars) are n-tuples or tubes. Convolutions take the place of scalar multiplication. This framework allows us to embed the 2-D data into a vector-space-like structure called a free module over a commutative ring. These free modules retain many properties of complex inner-product spaces, and we leverage that to provide theoretical guarantees on our algorithm. We show that compared to vector-space counterparts, SSmC achieves higher accuracy and better able to cluster data with less preprocessing in some image clustering problems. In particular we show the performance of the proposed method on Weizmann face database, the Extended Yale B Face database and the MNIST handwritten digits database.", "text": "abstract paper develop method unsupervised clustering twoway data combining recent innovations diﬀerent ﬁelds sparse subspace clustering algorithm groups points coming union subspaces respective subspaces t-product introduced provide matrix-like multiplication third order tensors. algorithm analogous aﬃnity diﬀerent data points built using sparse self-representation data. unlike employ t-product self-representation. allows ﬂexibility modeling; fact special case method. using t-product three-way arrays treated matrices whose elements n-tuples tubes. convolutions take place scalar multiplication. framework allows embed data vector-space-like structure called free module commutative ring. free modules retain many properties complex inner-product spaces leverage provide theoretical guarantees algorithm. show compared vector-space counterparts ssmc achieves higher accuracy better able cluster data less preprocessing image clustering problems. particular show performance proposed method weizmann face database extended yale face database mnist handwritten digits database. clustering algorithms objects assumed embedded normed linear space similarity measured distance-like function. among many diﬀerent options followed construction weighted graph similar points joined strong edges. then using tools spectral graph theory possible clusters connected graph components contrast subspace clustering techniques take diﬀerent perspective geometry clustering. approaches points assumed come union subspaces rather disjoint volume-ﬁlling clusters. subspace clustering methods using spectral graph theory ﬁnal step relevant notion similarity reﬂect whether points belong subspace. simple variations distance longer eﬀective. problem diverse array subspace clustering methods sparse subspace clustering employed resolve clusters. even reject outliers clustering data two-way structure images typical subspace clustering methods must unfold data vector. approach sacriﬁces two-way structure potentially failing exploit useful information. outside subspace clustering hand many methods take advantage multi-way array structure particularly dimensionality reduction ﬁnding best subspace approximate data. examples these references therein. know work exploiting multi-way structure techniques similar subspace clustering goal gap. paper present novel algebraic approach clustering multi-way data. whereas existing subspace clustering methods concatenate data columns matrix method group data three-way array clustering slices tensor. using tensor products factorizations outlined extend sparse subspace clustering tensor data. although strategy could process -way data incorporating technical tools style chose focus work clustering two-way data. demonstrate model able achieve higher accuracies previous solutions especially data undergone less preprocessing. contributions first propose algebraic generative model based characterization third order tensors operators multiplication called t-product introduced space oriented matrices. model explained sections inference model propose novel clustering algorithm section characterize algorithm’s performance section paper mathematical framework given constructs used derive performance bounds section completely results similar ﬂavor ability separate data characterized terms worst case tubal-angles submodules. however generalizations geometrical notions linear algebra tensor t-product framework immediately obvious technical development paper makes possible stated theoretical results present manuscript supplementary material. section conduct experiments synthetic data weizmann face data base extended yale face database mnist handwritten digits sparse subspace clustering recent method solving subspace clustering problem. like many clustering methods constructs aﬃnity matrix whose entry designed large data points subspace relatively small zero otherwise. construct aﬃnity matrix sparse subspace clustering makes fact datum expressed eﬃciently linear combination members subspace. particular data point expressed linear combination others regularization term promote sparsity spectral clustering used segment data using sparse coeﬃcients aﬃnity matrix. variants considered guarantee correctness bounded noise. similar algorithms include lowrank representation uses nuclear norm penalty place regularization also theoretical guarantees performance. paper wish instead promote idea clustering matrix objects maintaining objects two-dimensional form opposed vectorizing matrices clustering vector representations. course linear method multiplying tube ﬁbers method writing linear combinations oriented matrices weights tube ﬁbers scalars. method employ multiplication t-product speciﬁed product central development algorithm associated theoretical constructs introduce method. indexing elements tensor; treat tensors multiway arrays stored matlab. readers unfamiliar matlab colon notation colon place index indicates entire cross-section array computing t-product using t-product eﬀectively computed using fast fourier transform. using matlab notation built-in functions ifft tensors multiplied using following steps proofs) noted above elemental objects tubes rather scalars standard scalar addition multiplication forms referred abstract algebra ﬁeld. equipped ﬁeld forms vector space. equipped form ﬁeld non-zero tubes invertible. however form referred ring unity module ring thought generalization concept vector space ﬁeld corresponding scalars elements ring. linear algebra ring analog subspace free submodule. algorithm relies submodules such need carefully rest framework. begin section presenting theorem corollaries imply many useful properties subspaces still present free submodules. variation notation work denote length tubes oriented matrices size represents tensors size note forms ring identity using multiplication given usual addition. theorem follows. theorem oriented matrices subspace basis free submodule generating element free submodule written t-linear combination generating elements t-linear combination mean oriented matrices multiplied t-product coeﬃcients illustrate figure next deﬁne mathematically rigorous ideas linear independence disjointness submodules useful subsequent analysis. exception linear independence previously deﬁnited elsewhere literature t-product. case scalars depth deﬁnitions reduce linear algebraic deﬁnitions seen since convolution reduce scalar multiplication case. also deﬁne linear independence lists oriented matrices. article consider free submodules. explaining t-linear combinations. deﬁnition t-product introduced written terms block circulant matrices include help interpret model. denote d-th frontal slice given t-linear combination like figure figure focuses single oriented matrix scalar coeﬃcient. illustrative purposes coeﬃcient shown single nonzero position nonzero element selects second column block circulant matrix folded back oriented matrix. folding observe scalar multiple shifted relative original. takeaway demo every oriented matrix spans subspace containing multiples itself generates submodule containing multiples certain permutations column ﬁbers well. presence shifted copies distinguishes t-linear combinations linear combinations. terms signal processing t-linear combination uses coeﬃcient tube represent ﬁlter. proposed approach succeed structure imposed ﬁlter must capture patterns data argue note course could construct pathological case model adequate creating clusters consisting shifted copies other’s elements. would distinguishable subspace clustering submodule clustering. even though pathological examples exist theory believe shifting image columns allow particularly suited images since many causes within-cluster variation–for instance moving subjects camera panning–can approximately represented shifts betweencluster variation usually resemble shifting. modeling image collections submodules warranted success previous applications video restoration missing pixels face recognition prior work shows low-dimensional-submodule assumption provide useful framework regulate model complexity accurately capturing natural imaging data. what’s more variety potential models phrased terms submodules limited shifting circular boundary conditions. work group found entire family tensor-tensor products might replace t-product also well suited imaging tasks. example tube-scalar product replaces convolution periodic boundary conditions convolutions using reﬂected boundary conditions; shown improve image de-blurring algorithms methods presented paper easily extended adaptations. algorithm development based following algebraic assumption. assume data viewed list oriented matrices comes union disjoint free submodules. task submodules group data respective clusters. norms like used select relevant groups factors regression problems tend force terms inside f-norms survive group corresponding multiplicands contribute enough model driven zero group otherwise. here hope select relevant samples reconstruction cluster. algorithm based following principle. seek sparse t-linear representation oriented matrix ideally matrices submodule contribute. words samples submodule provide eﬃcient generating submodule. idea shown figure compactness submodules good chance successful self-representation datum provided coeﬃcients diﬀerent clusters remain zero. intuition hopefully probability coeﬃcients remaining zero increase. develop three results give conditions sparse representation point others submodule. results analogous results sparse subspace clustering indicates richness proposed framework ability borrow intuition traditional vector space setting. ﬁrst theorem requires strict condition apply submodules must linearly independent. second third establish conditions submodules merely disjoint. note linear independence special case disjointness union contained within sum. peril disjointness t-linear combination points pair submodules case si∩j result holds. symbol indicates submodules deﬁnition theorem consider oriented data matrices {−→y within submodules {sj}j dimensions {dj}j denote tensor lateral slices drawn submodule dimension none fourier-domain frontal slices zero singular values. then lateral slices form generating submodule. denote size full-rank sub-tensors words every element tensor kh×di whose lateral slices drawn element viewed fourier domain frontal faces full rank. synthetic data order assess speed reliability modestly sized datasets synthetic data generated lying along multiple submodules. test parameters chosen mimic size subset mnist handwritten digit dataset. synthetic image images distributed along clusters. total dataset size varied images. test parameters chosen larger scale face database. synthetic image images distributed along clusters. total dataset size varied images. runtime seconds tests displayed table tests ssmc misclassiﬁcation rate zero synthetic data. real data tests section implementation contained special case implementation ssmc. implementation lacks portion algorithm presented make provision sparse outlying entries solving problem. t-product performed well past tool face recognition also known images object various lighting conditions approximately form low-dimensional subspace following test performance method clustering images various data bases weizmann face data base experiment group together faces regardless lighting condition setting selected training four faces four lighting conditions monitoring quality heuristic. using values test faces four illuminations another series tests training stage ssmc displays robustness choice time images used four people nine lighting conditions. succeeded narrow range ssmc succeeds useful itself take sign union submodules reasonable model database form added complexity t-product warranted. furthermore ssmc withstand level additive noise foils images preceding paragraph. pixel values ranged zero isotropic gaussian noise standard deviation yale face data bases tested approach yale data bases original extended original data base contains contains grayscale images individuals. images subject diﬀerent facial expression conﬁguration center-light w/glasses happy leftlight w/no glasses normal right-light sleepy surprised wink. reduce preprocessing terms centering rotating etc. performed. figure illustrates clustering error various values ssmc ssc. note optimal clustering error ssmc whereas clustering error shows clustering performance ssmc averaged trials. ssmc able achieve perfect clustering not. believe shift invariant nature ssmc method requires less preprocessing. borne following experiment mnist handwritten character clustering problem. mnist handwritten data base experiment seek cluster digits randomly taking instances digit labeled data. clustering error performance curve averaged random trials shown figure turns data remains competitive ssmc ssmc slightly better optimal order check shift invariance property ssmc randomly shifted digits horizontally uniformly respect center pixels either side. case best value ssmc exhibited clustering error clustering error remained values implies ssmc presented novel method cluster data preserving multi-way aspect data. initial results show robustness compared existing approaches. future plan carry experiments data sets amerisign language lexicon video dataset computational front current implementation ssmc multiple processors suited large datasets takes minutes test examples. however believe algorithm eﬀectively parallelized. project paper proposed fast alternative work could extended quickly perform submodule clustering well. proof theorem applies ||−→a i||f ||−→a−i||f proof derive ||−→a i||f ||−→a||f middle statement holding exactly condition note since element columns terms role suboptimal zeros form ni××d array di××d array placing zeroes elements aren’t present subtensor ||−→a i||f then ˜−→a ˜−→a ˜−→a following also relationship ff-norms ˜−→a i||f di|| ˜−→a i||f shown taking f-norms tubes ﬁrst proof ﬁrst restate conclusion tensor lateral slices drawn free submodule dimension singular values fourier-domain frontal slices nonzero element must show existence coeﬃcient tensor t-product prove lemma contradiction. ﬁrst show module dimension considered vector space complex numbers. violates claim consequence submodule generated t-product linear combinations columns represented simply fourier domain face-by-face matrix multiplication fourier representation interacting coeﬃcient vectors face. latter case fact full rank implies rest coeﬃcients columns augmented matrix indeed linearly independent. thus face direct summand complex dimension", "year": 2014}