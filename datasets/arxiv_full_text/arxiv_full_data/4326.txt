{"title": "Zero-Shot Object Recognition System based on Topic Model", "tag": ["cs.CV", "stat.ML"], "abstract": "Object recognition systems usually require fully complete manually labeled training data to train the classifier. In this paper, we study the problem of object recognition where the training samples are missing during the classifier learning stage, a task also known as zero-shot learning. We propose a novel zero-shot learning strategy that utilizes the topic model and hierarchical class concept. Our proposed method advanced where cumbersome human annotation stage (i.e. attribute-based classification) is eliminated. We achieve comparable performance with state-of-the-art algorithms in four public datasets: PubFig (67.09%), Cifar-100 (54.85%), Caltech-256 (52.14%), and Animals with Attributes (49.65%) when unseen classes exist in the classification task.", "text": "abstract—object recognition systems usually require fully complete manually labeled training data train classiﬁer. paper study problem object recognition training samples missing classiﬁer learning stage task also known zero-shot learning. propose novel zero-shot learning strategy utilizes topic model hierarchical class concept. proposed method advanced cumbersome human annotation stage eliminated. achieve comparable performance state-of-the-art algorithms four public datasets pubfig cifar- caltech- animals attributes unseen classes exist classiﬁcation task. object classiﬁcation natural images useful content-based image retrieval video surveillance robot localization image understanding. according lampert humans able distinguish least relevant classes. however training conventional object detectors classes would require millions welllabeled training images likely reach years come. such zero-shot learning paradigm motivated human ability learn abstract examples capability describe completely unseen classes existing classes. instance recognize unseen objects using list high-level attributes serve intermediate layer classiﬁer cascade. attributes enable systems recognize object classes even without single training example. others like semantic relationships different reference classes predict unseen classes. though promising results obtained aforementioned approaches require either extensive human supervision build attributes tight semantic relationship unseen classes training classes. paper propose topic model replace attributes extensive human supervision longer required hierarchical class concept relate unseen classes existing seen classes. concept loose relationship image hierarchy compared framework starts building bag-of-words model using image features seen classes. herein concept utilized build codebook. topic model learned using generated model. based learned plsa model concept signature topics seen unseen classes deduced finally object classiﬁcation performed using deduced signature topics representation. experimental results using four publicly available datasets namely pubfig cifar caltech- datasets shown effectiveness proposed method. rest paper structured follows. section presents related work. section details proposed methodology. section shows experimental results section presents discussion. fig. comparison weakly supervised learning conventional learning algorithms; learning classiﬁer including association images attributes tags respectively; hierarchical class concept. high-level classes. thus attributes facilitate transfer zero-shot learning alleviate issues lack labeled training data expressing classes terms well-known attributes. followed lampert extended work animal categorization introducing direct attributes prediction indirect attributes prediction unlike parikh grauman introduced relative attributes perform zero-shot learning. approach captures relationships images objects terms humannameable visual properties. example models capture animal ‘taller’ animal subject ‘happier’ subject allows richer language supervision description commonly used categorical attributes. though relative attributes seem efﬁcient zeroshot learning dataset needs intra-class also binary relative relationship classes needs deﬁned beforehand. process require extensive human supervision efforts decision always subjective. proposed strategy replace attributes topic model order reduce human supervision needed. others topic models zero-shot learning propose hybrid attribute-topic model deal group social activities. speciﬁcally deﬁne three unique attributes user-deﬁned latent class-conditional latent generalized free attributes. attributes learned jointly semi-latent attribute space multi-modal latent attribute topic model motivation reduce annotation effort introduction latent attributes proposed framework. contrast focus paper object recognition learns topic model directly representations infers unseen classes using proposed concept. eliminate time consuming human annotation process replacing attributes topic models. instead learning topic models user-deﬁned latent attributes choose plsa topic model require prior comparison latent dirichlet allocation model. extend topic model representation mapping algorithm object classes zeroshot learning would possible. figure shows conventional solutions associate image class label further describe image content association attributes image tags insufﬁcient zero-shot learning attributes tags redundant useful many introduced. speciﬁc evaluation method what effective attribute tag. therefore introduce codebook learning method i.e. concept utilizes hierarchical class characteristics codebook learning stage. concept inspired common objects clustered different classes order deduce relationship among them. speciﬁcally integrate different levels image class labels namely coarse class fine class then class hierarchy learned topic model identify signiﬁcant differences among classes improve model prediction capability. approach better attributesbased classiﬁcation commonly applicable inter-class problems only. concept manages deal inter-class well intra-class problems. similar work employed hierarchical class strategy zero-shot learning paradigm includes rohrbach frome approaches frameworks incorporate semantic information language model/set assist zero-shot learning studied. employed wordnet wikipedia language model learned similarity measure represent hierarchy/attributes/objectness measure object classes. extended idea learn class relationship directly unannotated data using deep visual-semantic embedding model another approach mensink used different concept distance metric seen classes errors seen unseen classes learned. order classify object classes nearest class mean classiﬁer employed. approach require semantic relationship manages generalize unseen classes near zero computational cost. proposed framework although similar hierarchy-based knowledge transfer need language model build hierarchy. instead concept relates unseen classes seen classes. also learnt topic model perform zero-shot learning different attributes-based direct similarity-based knowledge transfer uses attributes objectness measure uses metric learning. section ﬁrst discuss prerequisites proposed framework model topic model. secondly explain concept detail perform zero-shot learning plsa concept. finally show inference method image classiﬁcation purposes. build model engaged random forest algorithm random decision tree constructed using random subset training data replacement. labeled training images particular node inode recursively split left node ileft right node iright subsets according threshold split function feature vectors training images associated class labels. split node random subsets features generated compare process maximizes expected information gain selected shannon entropy probability class histogram such leafnodes trees form codebook. then codebook used quantize representation passing tree count occurrence leafnode. model based latent topic model particular plsa model. brieﬂy introduce using terminology context. suppose given collection images image represented collection features shows frequent particular used word basic item codebook indexed joint probability model deﬁned however current setting could infer unseen classes algorithm needs prior knowledge belongs labeled training image learning model. zero-shot paradigm information simply available. order handle issue proposed concept infer unseen classes perform zero-shot learning using plsa model. introduced concept nested class concept illustrated figure image consists class labels broader visual concept namely coarse class; class labels narrow visual concept namely fine class. table shows examples concept. learning described section iii-a except substitute shannon entropy respectively. illustrate figure utilizing codebook optimum setting codebook representations varies drastically although belong therefore built variant namely j-cofi. property j-cofi codebook strategy adapts information learning. speciﬁcally denote total number trees uses trees govern similarity trees distinguish within associated result model similar histogram shape codebook bins created trees. hence eliminates limitations property table summarizes difference property still exist limitations property employed compute time could optimize either tree node splitting introduce cofi codebook handle limitation. property cofi proposed learn trees utilizes simultaneously tree node splitting. speciﬁcally modiﬁed cofi tree consider total maximum simultaneously split node △etotal fig. effects coarse class j-cofi codebook compare ordinary f-based codebook. examples include building random forest trees. example trees only. another example tree tree. trees built feature similar different trees. notice signiﬁcant differences leafnode f-based codebook. however help j-cofi codebook feature similar path choice tree different tree. this build model retains similarities images belong indicates conceptual similarity plsa model introduce novel mapping algorithm namely topic sets indicate index associate speciﬁc creates relationship idea unseen class could related pair unseen classes high similarity respective therefore could relate deﬁning satisﬁes conditions denote signature topic seen class pubfig public figures face database total images celebrities faces. used identical subsets random identities extracted class images. plsa model built using similar number attributes addition phog features also re-implement framework using features identical combination gist features color histograms. employ class relationship however optimum nearest seen classes pair unseen classes chosen assume relationship similar relationship. table shows proposed method better accuracy compared lampert uses binary attributes parikh grauman uses relative attributes. results achieved without annotation required number unseen classes increased consistent drop system accuracy phog features gist color histogram features. expected number unseen classes increases system accuracy decreases tradeoffs computational complexity system accuracy. ensure parameters number trees number leafnodes tree number topics number unseen class learn codebook using either using codebook j-cofi codebook cofi codebook build histogram based codebook step learn plsa model using histogram. experiments employed four public datasets pubfig cifar- caltech- animals attributes datasets designed pose different visual challenges terms illumination effects scales viewpoints well support objects. implementation details evaluate m|dtest) -vs-all classiﬁcation performed. pyramid levels angle bins. speciﬁcally phog however concatenate phog descriptors found. instead features codebook learning mechanism using algorithm therefore obtain descriptors quantize shape information locally globally nature phog. codebook learn image shapes whole well local patch characteristic. learned using trees codebook performed consistency test tested accuracy proposed method across different figure shows proposed method better consistency comparison also performed worst terms accuracy performed worst terms consistency. results shown effectiveness consistency proposed algorithm handle intra-class variation problem opposed extensive attributes annotation cifar- dataset classes class contains images resolutions. classes grouped coarse class. unseen. thus total picked training images randomly rest used testing. dataset major semantic topics exist i.e. mammals size trees vehicles food household insects reptiles people ﬂowers. dataset challenging limited resolution pyramid levels phog features codewords tree codebook learning. table shows proposed method without concept performed much better compared approach also outperformed total unseen training classiﬁer. however approach still able achieve accuracy comparison approaches addition computational cost proposed method lower employed small number training images. similar pubfig dataset also observed using fewer seen classes learning process accuracy drops. accuracy differences differ fraction even difference number large indicates proposed method robust capable handle cifar- dataset tiny images causes collected features vector similar. besides comparison three different codebook learning strategies cofi codebook method performs best utilized simultaneously tree node splitting. binoculars boom-box bread maker calculator computer keyboard computer monitor computer mouse ﬂoppy-disk head-phones ipod joystick laptop light bulb megaphone microwave palm-pilot papershredder pci-card photocopier refrigerator rotary-phone toasters treadmill tripod video-projector washing machine bathtub chandelier chess-board desk-globe doorknob ewer ﬂashlight hammock hot-tub hourglass mailbox mattress menorah picnic table buddha eiffel-tower golden-gate-bridge light-house minaret pyramid skyscraper smokestack teepee tower-pisa windmill duck goat goose raccoon skunk swan unicorn zebra greyhound blimp bulldozer cannon canoe car-tire covered-wagon ﬁghtingjet ﬁre-truck helicopter hot-air-ballon kayak ketch license-plate motorbikes mountain-bike pram school-bus segway self-propelledlawn-mower snowmobile speedboat steering-wheel touring-bike tricycles wheelbarrow airplanes car-side beer-mug chopsticks coffee-mug knife spoon stained-glass paperclip paper-shredder coins dice drinking-straw dumb-bell ﬁreextinguisher frying-pan ladder pez-dispenser playing-card roulettewheel screwdriver swiss-army-knife tweezer umbrella baseball-bat baseball-glove baseball-hoop billiards bowling-ball bowling-pin boxing-glove football-helmet frisbee golf-ball skateboard soccer-ball tennis-ball tennis-court tennis-racket yo-yo cowboy-hat diamond-ring football-helmet necktie sneaker socks top-hat t-shirt human-wear wielding-mask yarmulke tennis-shoes saddle stirrups electric-guitar french-horn grand-piano guitar-pick harmonica harp harpsichord mandolin sheet-music tambourine tuning-fork xylophone caltech- dataset consists images grouped object classes background class. unfortunately provide concepts dataset. therefore group classes manually similar cifar- except speciﬁc classes introduce table show distribution selected caltech- classes existing cifar newly introduced table shows minor ﬂuctuations compared pubfig cifar- results different values employed. classiﬁcation settings interestingly proposed method performs better without applying concept. found semantically related visual similarity e.g.‘computer keyboard’ ‘computer monitor’ ‘computer mouse’ belong ‘household electrical devices’; introducing tree codebook help boosting codebook discriminating power might visual similarity among well; complexity objects caltech-. however zero-shot learning still provides reasonable results. dataset perform comparisons classes extracted. object dataset animal classes corresponding attributes attached class. total animal classes attributes dataset. similar experimental settings features partitions seen unseen classes employed. build relationships adopt attributes relationships pick attributes lowest number possible. result grouped shown table vii. achieved also show confusion matrix test classes figure observe proposed method better average classiﬁcation results compared though proposed method predict ‘humpback whale’ class well achieve better accuracy ‘giant panda’ class leads better overall accuracy. results beneﬁt concept deﬁned ‘giant panda’ class {‘grazer’}. note ‘humpback whale’ class resides {‘ﬂippers’‘strainteeth’} contains therefore observe accuracy drops ‘humpback whale’ class. situation applies ‘rat’ class ‘raccoon’ class share {‘hibernate’}. paper compared proposed method public datasets achieves better performance compared state-of-the-art methods zero-shot learning. even conventional classiﬁcation problem training images object classes available still manage state-ofthe-art accuracy pubfig cifar- datasets. conducted experiments cases predicted redundant. lower number chosen numbers possible reduced well hence possibility obtain similar different redundant representation. order based experiments caltech- dataset aware classiﬁcation accuracy ﬂuctuating quality collection though within grouped based semantic relationship; might visually dissimilar. limitation likely solved introducing middle-level class group extend within high-visual similarity group e.g. group extend ‘head-phones’ ‘rotary-phones’ ‘megaphone’ ‘household electrical devices’ ‘phones’. pick random model {‘megaphone’} ‘head-phones’ ‘rotary-phones’ priority related nonetheless future work includes introducing tighter relationship fine class coarse class better performance achieved. c.h. lampert nickisch harmeling learning detect unseen object classes between-class attribute transfer ieee conference computer vision pattern recognition bosch zisserman munoz representing shape spatial pyramid kernel international conference image video retrieval large-scale goodfellow courville bengio feature learning spike-and-slab sparse coding international conference machine learning huang darrell beyond spatial pyramids receptive ﬁeld learning pooled image features ieee conference computer vision pattern recognition rohrbach stark schiele evaluating knowledge transfer zero-shot learning large-scale setting ieee conference computer vision pattern recognition frome corrado shlens bengio dean mikolov m.a. ranzato mikolov devise deep visual-semantic embedding model advances neural information processing systems mensink verbeek perronnin csurka metric learning large scale image classiﬁcation generalizing classes near-zero cost european conference computer vision springer c.h. lampert nickisch harmeling attribute-based classiﬁcation zero-shot visual object categorization ieee transactions pattern analysis machine intelligence vol. palatucci pomerleau hinton mitchell zeroshot learning semantic output codes advances neural information processing systems silberer ferrari lapata models semantic representation visual attributes proceedings annual meeting association computational linguistics", "year": 2014}