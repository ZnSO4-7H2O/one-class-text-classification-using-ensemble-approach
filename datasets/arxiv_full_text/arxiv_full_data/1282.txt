{"title": "Discriminative Unsupervised Feature Learning with Exemplar Convolutional  Neural Networks", "tag": ["cs.LG", "cs.CV", "cs.NE"], "abstract": "Deep convolutional networks have proven to be very successful in learning task specific features that allow for unprecedented performance on various computer vision tasks. Training of such networks follows mostly the supervised learning paradigm, where sufficiently many input-output pairs are required for training. Acquisition of large training sets is one of the key challenges, when approaching a new task. In this paper, we aim for generic feature learning and present an approach for training a convolutional network using only unlabeled data. To this end, we train the network to discriminate between a set of surrogate classes. Each surrogate class is formed by applying a variety of transformations to a randomly sampled 'seed' image patch. In contrast to supervised network training, the resulting feature representation is not class specific. It rather provides robustness to the transformations that have been applied during training. This generic feature representation allows for classification results that outperform the state of the art for unsupervised learning on several popular datasets (STL-10, CIFAR-10, Caltech-101, Caltech-256). While such generic features cannot compete with class specific features from supervised training on a classification task, we show that they are advantageous on geometric matching problems, where they also outperform the SIFT descriptor.", "text": "abstract—deep convolutional networks proven successful learning task speciﬁc features allow unprecedented performance various computer vision tasks. training networks follows mostly supervised learning paradigm sufﬁciently many input-output pairs required training. acquisition large training sets challenges approaching task. paper generic feature learning present approach training convolutional network using unlabeled data. train network discriminate surrogate classes. surrogate class formed applying variety transformations randomly sampled ’seed’ image patch. contrast supervised network training resulting feature representation class speciﬁc. rather provides robustness transformations applied training. generic feature representation allows classiﬁcation results outperform state unsupervised learning several popular datasets generic features cannot compete class speciﬁc features supervised training classiﬁcation task show advantageous geometric matching problems also outperform sift descriptor. recent years convolutional neural networks trained supervised manner backpropagation dramatically improved state performance variety computer vision tasks image classiﬁcation detection semantic segmentation interestingly features learned networks often generalize datasets example feature representation network trained classiﬁcation imagenet also performs well pascal moreover network adapted task replacing loss function possibly last layers network ﬁne-tuning problem i.e. adjusting weights using backpropagation. approach typically much smaller training sets sufﬁcient. despite success approach least potential drawbacks. first need huge labeled datasets used initial supervised training. difﬁcult collect diminishing returns making dataset larger larger. hence unsupervised feature learning quick access arbitrary amounts data conceptually large interest despite limited performance far. second although cnns trained classiﬁcation generalize well similar tasks object class detection semantic segmentation image retrieval transfer becomes less efﬁcient task differs original training task. particular object class annotation beneﬁcial learn features class-independent tasks descriptor matching. unlabeled images. surrogate task designed yield generic features descriptive robust typical variations data. variation simulated randomly applying transformations ’seed’ image. image transformed versions constitute surrogate class. contrast previous data augmentation approaches single seeding sample needed build class. consequently call thus trained networks exemplar-cnn. representation learned exemplar-cnn discriminative also invariant typical transformations. properties make useful various vision tasks. show feature representation learned exemplar-cnn performs well different tasks object classiﬁcation descriptor matching. classiﬁcation accuracy obtained exemplar-cnn representation exceeds previous unsupervised methods four benchmark datasets stl- cifar- caltech- caltech-. descriptor matching show feature representation outperforms representation alexnet trained supervised class-speciﬁc manner imagenet. moreover outperforms popular sift descriptor. convolutional training commonly used supervised unsupervised methods utilize invariance image statistics translations similar approach successful methods employing convolutional neural networks object recognition rely data augmentation generate additional training samples classiﬁcation objective share architecture approaches method rely labeled training data. unsupervised learning several studies learning invariant representations exist. denoising autoencoders example learn features robust noise trying reconstruct data randomly perturbed input samples. learn invariant features video enforcing temporal slowness constraint feature representation learned linear autoencoder. sohn learn features invariant local image transformations. contrast discriminative approach methods rely directly modeling input distribution typically hard jointly training multiple layers cnn. idea learning features invariant transformations also explored supervised training neural networks. research similar early work tangent propagation aims learn invariance small predeﬁned transformations neural network directly penalizing derivative output respect magnitude transformations. contrast algorithm regularize derivative explicitly. thus less sensitive magnitude applied transformation. work also loosely related unlabeled data regularizing supervised algorithms example self-training entropy regularization contrast semi-supervised methods exemplar-cnn training require labeled data. creating surrogate training data input proposed training procedure unlabeled images come roughly distribution images later compute learned features. randomly sample patches size pixels different images varying positions scales forming initial training xn}. interested patches containing objects parts objects hence sample regions containing considerable gradients. precisely sample patch probability proportional mean squared gradient magnitude within patch. exemplary patches sampled stl- unlabeled dataset shown fig. deﬁne family transformations {tα| parameterized vectors possible parameter vectors. transformation composition elementary transformations. learn features approach ﬂexible regard extending list transformations order serve applications learned features better. instance section show descriptor matching beneﬁts adding blur transformation. numerical parameters elementary transformations concatenated together form single parameter vector initial patch sample ran} apply cordom parameter vectors responding transformations patch yields transformed versions tixi ti}. example shown fig. afterwards subtract mean pixel whole resulting dataset. apply preprocessing. learning algorithm given sets transformed image patches declare sets class assigning label class sxi. train discriminate surrogate classes. formally minimize following loss function denotes function computing values output layer given input data standard basis vector. note limit inﬁnite number transformations surrogate class objective function takes form intuitively classiﬁcation problem described serves ensure different input samples distinguished. time enforces invariance speciﬁed transformations. following sections provide foundation intuition. ﬁrst present formal analysis objective separating well deﬁned classiﬁcation problem regularizer enforces invariance discuss derived properties classiﬁcation problem compare common practices unsupervised feature learning. formal analysis denote random vector transformation parameters vector activations secondto-last layer network presented input patch matrix weights last network layer last layer activations applying softmax softmax output network. plugging deﬁnition softmax activation function objective falls back transformation-free instance xi∈x eα]. general equality hold thus ﬁrst enforces correct classiﬁcation average representation given input sample. second seen regularizer enforcing close average value i.e. feature representation sought approximately invariant transformations show convexity function jensen’s inequality yields suppose want unsupervisedly learn feature representation useful recognition task example classiﬁcation. mapping input images feature representation satisfy requirements must least feature similar images category must least feature sufﬁciently different images different categories unsupervised feature learning methods learn representation modeling input distribution based assumption good model contains information category distribution representation learned given sample reconstructed perfectly representation expected also encode information category sample additionally learned representation invariant variations samples irrelevant classiﬁcation task i.e. adhere manifold hypothesis recent discussion). invariance classically achieved regularization latent representation e.g. enforcing sparsity robustness noise contrast discriminative objective directly model input distribution learns representation discriminates input samples. representation required reconstruct input unnecessary recognition matching task. leaves degrees freedom model desired variability sample. shown analysis enforce invariance transformations applied during surrogate data creation requiring representation transformed image patch predictive surrogate label assigned original image patch noted approach assumes transformations change identity image content. example color transformation force network invariant change cannot expect extracted features perform well task compare discriminative approach previous unsupervised feature learning methods report classiﬁcation results stl- cifar- caltech- caltech- datasets. datasets tested differ number classes number samples class. especially well suited unsupervised learning contains large unlabeled samples. experiments except dataset transfer experiment extracted surrogate training data unlabeled subset stl-. testing cifar- resized images pixels pixels make scale depicted objects similar datasets. caltech- images resized pixels caltech- images pixels worked three network architectures. smaller network used evaluate inﬂuence different components augmentation procedure classiﬁcation performance. consists convolutional layers ﬁlters each followed fully connected layer units. last layer succeeded softmax layer serves network output. network referred c-c-f explained appendix compare method state-of-the-art trained bigger networks network consists three convolutional layers ﬁlters respectively followed fully connected layer units even larger network consisting three convolutional layers ﬁlters respectively fully connected layer units models convolutional ﬁlters connected region input. max-pooling performed ﬁrst second convolutional layers. dropout applied fully connected layers. trained networks using implementation based caffe details training procedure hyperparameter settings provided appendix test time applied network arbitrarily sized images convolutionally computing responses network layers except softmax feature maps layer applied pooling method commonly used respective dataset datasets used standard training test protocols. stl- trained pre-deﬁned folds training data. report mean standard deviation achieved ﬁxed test set. cifar- report results caltech- follow usual protocol selecting random samples class training samples class testing. caltech- randomly selected samples class training used rest testing. caltech- caltech- repeated testing procedure times. table compare exemplar-cnn several unsupervised feature learning methods including current state dataset. also list state methods involving supervised feature learning additionally show dimensionality feature vectors produced method ﬁnal pooling. smallest network trained surrogate classes containing samples larger ones classes samples each. features extracted larger networks outperform best prior result datasets. despite fact dimensionality feature vectors smaller approaches networks trained stl- unlabeled dataset increase performance especially pronounced labeled samples available training case datasets except full cifar-. agreement previous evidence increasing feature vector dimensionality number labeled samples training becomes less dependent quality features remarkably stl- achieve accuracy large improvement previously reported results. cases could covered either careful selection applied transformations combining features multiple networks trained different sets transformations letting ﬁnal classiﬁer choose features use. caltech- either measure average accuracy samples calculate accuracy class average values differ classes contain fewer test samples. researchers average overall accuracy. algorithm convolutional k-means network multi-way local pooling slowness videos hierarchical matching pursuit multipath view-invariant k-means exemplar-cnn exemplar-cnn exemplar-cnn supervised state detailed analysis performed additional experiments using c-cf network study effect various design choices exemplar-cnn training validate invariance properties learned features. clearly classiﬁcation accuracy increases number surrogate classes reaches optimum surrogate classes change even decreased. expected larger number surrogate classes likely draw similar even identical samples hard impossible discriminate. cases detrimental classiﬁcation performance soon collisions dominate surrogate labels discriminative loss longer reasonable training network surrogate task longer succeeds. check validity explanation also plot fig. validation error surrogate data training network. rapidly grows number surrogate classes increases showing surrogate classiﬁcation task gets harder growing number classes. observed larger powerful networks reach peak performance surrogate classes smaller networks. however performance achieved larger networks saturates seen limitation sampling many similar images training even decrease performance learned features. makes number selection samples relevant parameter training procedure. however drawback avoided example clustering. demonstrate this given stl- unlabeled dataset containing images ﬁrst train c-c-cf exemplar-cnn subset image patches. exemplar-cnn extract descriptors images dataset perform clustering similar discarding noisy similar clusters automatically leaves clusters approximately images them. images cluster apply augmentation original exemplar-cnn. augmented cluster serves surrogate class training. table shows classiﬁcation performance features learned cnns training data. clustering increases classiﬁcation accuracy datasets particular depending network. shows small modiﬁcation allows approach make large amounts data. potentially using even data performing clustering network training within uniﬁed framework could improve quality learned features. number samples surrogate class fig. shows classiﬁcation accuracy number training samples surrogate class varies performance improves samples surrogate class saturates around samples. indicates amount sufﬁcient approximate formal objective hence increasing number samples signiﬁcantly change optimization problem. hand number samples small enough data learn desired invariance properties. performance. ’seed’ patches ﬁxed. result shown fig. value corresponds applying random compositions elementary transformations scaling rotation translation color variation contrast variation. different columns plot show difference classiﬁcation accuracy discarded types elementary transformations. several tendencies observed. first rotation scaling minor impact performance translations color variations contrast variations signiﬁcantly important. secondly results cifar- consistently show spatial invariance color-contrast invariance approximately equal importance classiﬁcation performance. indicates variations color contrast though often neglected also improve performance supervised learning scenario. thirdly caltech- color contrast transformations much important compared spatial transformations datasets. surprising since caltech- images often well aligned dataset bias makes spatial invariance less useful. tried applying several transformations addition ones shown fig. none seemed improve classiﬁcation accuracy. matching task section though found using blur additional transformation improves performance. fig. inﬂuence removing groups transformations generation surrogate training data. baseline applying transformations. group three bars corresponds removing transformations. classiﬁcation results shown table best classiﬁcation results dataset obtained training patches extracted dataset itself. however difference drastic indicating learned features generalize well datasets. applied feature learning algorithm images sampled three datasets stl- unlabeled dataset cifar caltech- evaluated performance learned feature representations classiﬁcation tasks inﬂuence network architecture classiﬁcation performance perform additional experiment evaluate inﬂuence network architecture classiﬁcation performance. results experiment shown table networks trained using surrogate training containing either classes samples fig. invariance properties feature representation learned exemplar-cnn. transformations applied image patch bottom invariance different feature representations. normalized euclidean distance feature vectors original translated image patches magnitude transformation classiﬁcation performance transformed image patches magnitude transformation various magnitudes transformations applied creating surrogate training data. classes samples vary number layers layer sizes ﬁlter sizes. classiﬁcation accuracy generally improves network size indicating classiﬁcation problem scales well relatively large networks without overﬁtting. invariance properties learned representation analyzed extent representation learned network invariant transformations applied training. randomly sampled images stl- test applied range transformations image. avoid empty regions beyond image boundaries applying spatial transformations cropped central pixel sub-patch pixel image. applied measures invariance patches. first explicit measure invariance calculated normalized euclidean distance normalized feature vectors original image patch transformed downside approach distance extracted features take account informative discriminative are. therefore evaluated second measure classiﬁcation performance depending magnitude transformation applied classiﬁed patches come problem. compute classiﬁcation accuracy trained central pixel patches fold stl- training measured classiﬁcation performance transformed versions samples test set. classiﬁcation accuracy depending network architecture. name coding follows stands convolutional layer ﬁlters size pixels stands fully connected layer units. example c-c-f denotes network convolutional layers containing ﬁlters spanning pixels each followed fully connected layer units. also show number surrogate classes fig. show stronger transformations surrogate training data lead invariant classiﬁcation respect transformations. however adding much contrast variation deteriorate classiﬁcation performance possible reason contrast level useful feature example strong edges image usually important weak ones. experiments descriptor matching recognition tasks image classiﬁcation object detection invariance requirements largely deﬁned object class labels. consequently providing class labels already learning features advantageous. seen comparison supervised state-of-the-art table supervised feature learning performs better presented approach. contrast matching interest points images independent object class labels. consequence apparent reason feature learning using class annotation outperform unsupervised feature learning. could even imagine class annotation confusing yields inferior features matching. compared features compare features learned supervised unsupervised convolutional networks sift features. long time sift preferred descriptor matching tasks comparison). supervised used alexnet model trained imagenet available architecture network follows krizhevsky contains convolutional layers followed fully connected layers. experiments extract features convolutional layers network. large input patch sizes output dimensionality high especially lower layers. descriptors comparable sift decided max-pool extracted feature ﬁxed spatial size corresponds spatial resolution sift pooling. even though spatial size same number features cell larger sift. unsupervised evaluated matching performance c-c-c-f architecture referred exemplar-cnn-orig following. experiments show neural networks cannot handle blur well. increasing image blur always leads matching performance drop. hence also trained another exemplarcnn deal speciﬁc problem. first increased ﬁlter size introduced stride ﬁrst convolutional layer resulting following architecture cs-c-c-f. allows network identify edges blurry images easily. secondly used unlabeled images flickr training represent general distribution natural images better stl. thirdly applied blur variable strength training data additional augmentation. thus call network exemplar-cnn-blur. alexnet max-pooled feature maps produced exemplarcnns spatial size. datasets common matching dataset mikolajczyk contains image pairs. dataset size limits reliability conclusions drawn results especially compare various design choices depth network layer draw features. additional dataset contains image pairs. generated applying different types transformations varying strengths base images obtained flickr. images contained used train unsupervised cnn. base image applied geometric transformations rotation zoom perspective nonlinear deformation. cover rigid afﬁne transformations well complex ones. furthermore applied changes lighting focus adding blur. transformation applied various magnitudes effect performance could analyzed depth. base images matched transformed versions image original resulted matching pairs. dataset mikolajczyk generated synthetically contains real photos taken different viewpoints different camera settings. reﬂects reality better synthetic dataset also comes drawback transformations directly coupled respective images. hence attributing performance changes either different image contents applied transformations becomes impossible. contrast dataset enables evaluate effect type transformation independently image content. performance measure evaluate matching performance pair images followed procedure described ﬁrst extracted elliptic regions interest corresponding image patches images using maximally stable extremal regions detector chose detector shown perform consistently well widely used. detected region extracted patch according region scale rotated according dominant orientation. descriptors extracted patches greedily matched based euclidean distance. yielded ranking descriptor pairs. pair considered true positive ellipse descriptor target image ground truth ellipse target image intersection union least pairs considered false positives. assuming recall corresponds best achievable overall matching given detections computed precisionrecall curve. average precision i.e. area curve used performance measure. patch size network layer mser detector returns ellipses varying sizes depending scale detected region. compute descriptors elliptic regions normalized image patches ﬁxed size. immediately clear patch size best larger patches provide higher resolution enlarging much introduce interpolation artifacts effect high-frequency noise emphasized. therefore optimized patch size flickr dataset method. using convolutional neural networks region description aside patch size another fundamental choice network layer features extracted. features higher layers abstract. fig. shows average performance method varying patch size chose maximum patch size value ellipses smaller that. found case sift performance monotonously grows saturates maximum patch size. sift based normalized ﬁnite differences thus robust blurred edges caused interpolation. contrast networks especially lower layers optimal patch size performance starts degrading. lower network layers typically learn gabor-like ﬁlters tuned certain frequencies. therefore suffer over-smoothing caused interpolation. features higher layers access larger receptive ﬁelds thus beneﬁt larger patch sizes. results fig. shows scatter plots compare performance pairs methods terms average precision. corresponds image pair. points diagonal indicate better performance ﬁrst method points diagonal second method higher. scatter plots also give intuition variance performance difference. fig. show features alexnet exemplar-cnn outperform sift flickr dataset. however especially features alexnet image pairs sift performs clearly better. mikolayczyk dataset sift even outperforms features alexnet. analyze detail next paragraph. fig. compare alexnet exemplar-cnn-blur show loss function based surrogate classes superior loss function based object class labels. contrast object classiﬁcation class-speciﬁc features advantageous descriptor matching. loss function focuses invariance properties required descriptor matching yields better results. fig. analyze reason clearly inferior performance alexnet image pairs. ﬁgures show mean average precision various transformations datasets using optimized parameters. flickr dataset alexnet performs better sift transformations except blur drop performance. also mikolayczyk dataset blur zoomout transformations main reason sift performing better overall. actually effect surprising. lower layers networks mostly contain ﬁlters tuned certain frequencies. also features higher layers seem expect certain sharpness certain image structures. consequently blurred version image activates different features. contrast sift robust image blur uses simple ﬁnite differences indicate edges frequencies edge strength normalized out. exemplar-cnn-blur much less affected blur since learned robust demonstrate importance adding blur transformations also included exemplar-cnn used classiﬁcation task i.e. without blur among transformations. like alexnet problems matching blurred images original image. fig. scatter plots different pairs descriptors flickr dataset mikolajczyk dataset point scatter plot corresponds image pair coordinates values obtained compared descriptors. alexnet exemplar-cnn yield features outperform sift images flickr dataset alexnet inferior sift mikolajczyk dataset. features obtained unsupervised training procedure outperform features alexnet datasets class labels. core idea generate surrogate labels data augmentation applied transformations deﬁne invariance properties learned network. learned features yield large improvement classiﬁcation accuracy compared features obtained previous unsupervised methods. results strongly indicate discriminative objective superior objectives previously used unsupervised feature learning. unsupervised training procedure also lends learn features geometric matching tasks. comparison long standing state-of-the-art descriptor task sift revealed problem matching neural network features case blur. showed adding blur transformations applied training features obtained network much affected problem anymore outperform fig. mean average precision flickr dataset various transformations. except blur transformation networks perform consistently better sift. network trained blur transformations keep sift even blur. fig. mean average precision mikolajczyk dataset. networks perform better viewpoint transformations sift robust strong blur lighting transformations. sift image pairs. simple inclusion blur demonstrates ﬂexibility proposed unsupervised learning strategy. strong relationship approach data augmentation supervised settings also emphasizes value data augmentation general suggests diverse transformations. appendix method details describe detail network architectures evaluated explain network training procedure. also provide details clustering process used improve exemplar-cnn. network architecture tested various network architectures combination training procedure. coded follows stands convolutional layer ﬁlters size pixels stands fully connected layer units. example c-c-f denotes network convolutional layers containing ﬁlters spanning pixels followed fully connected layer units. last speciﬁed layer always succeeded softmax layer serves network output. applied max-pooling outputs ﬁrst second convolutional layers. stated paper used c-c-f architecture experiments evaluate inﬂuence different components augmentation procedure large network coded c-c-c-f used achieve better classiﬁcation performance. training networks adopted common practice training network stochastic gradient descent ﬁxed momentum started learning rate gradually decreased learning rate training. trained improvement validation error decreased learning rate factor repeated procedure convergence. training times titan roughly days c-c-f network days c-c-c-f network days c-c-c-f network. clustering judge similarity clusters following simple heuristics. method gives linear svms. apply svms whole unlabeled dataset select npercluster ﬁring images gives initial clusters. compute overlap pair clusters. thresholds tmerge tdiscard perform greedy procedure starting overlapping pair clusters merge clusters overlap exceeds tmerge discard clusters overlap tdiscard tmerge. appendix details computing measure invariance explain detail motivate computation normalized euclidean distance used measure invariance paper. constant depend immediately gives proves second statement proposition. proposition random vector values bounded continuous function. inequality first compute feature vectors image patches transformed versions. normalize feature vector unit euclidean norm compute euclidean distances original patch transformed versions. transformation magnitude average distances patches. finally divide resulting curves maximal values normalizations performed compensate possibly different scales different features. normalizing feature vectors unit length ensures values range different features. ﬁnal normalization curves maximal value allows compensate different variation different features extreme constant feature would considered perfectly invariant without normalization certainly desirable. resulting curves show quickly feature representation changes image transformed more. representation curve steeply goes remains constant cannot considered invariant transformation feature vector transformed patch becomes completely uncorrelated original feature vector even small magnitudes transformation. hand curve grows gradually indicates feature representation changes slowly transformation applied meaning invariance rather covariance representation. acknowledgments acknowledge funding starting grant videolearn supported brainlinks-braintools cluster excellence funded german research foundation acknowledges fellowship deutsche telekom stifung. convolutional networks eccv donahue vinyals hoffman zhang tzeng darrell decaf deep convolutional activation feature generic visual recognition icml razavian azizpour sullivan carlsson features off-the-shelf astounding baseline recognition cvpr workshops girshick donahue darrell malik rich feature hierarchies accurate object detection semantic segmentation cvpr hariharan arbelez girshick malik hypercolumns object segmentation ﬁne-grained localization cvpr long shelhamer darrell fully convolutional networks semantic segmentation cvpr hinton srivastava krizhevsky sutskever salakhutdinov improving neural networks preventing co-adaptation feature detectors preprint arxivcs/.v. srivastava hinton krizhevsky sutskever salakhutdinov dropout simple prevent neural networks overﬁtting journal machine learning research vol.", "year": 2014}