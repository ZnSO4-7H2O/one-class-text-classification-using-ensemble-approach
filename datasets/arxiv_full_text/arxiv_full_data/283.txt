{"title": "Analyzing the Behavior of Visual Question Answering Models", "tag": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "abstract": "Recently, a number of deep-learning based models have been proposed for the task of Visual Question Answering (VQA). The performance of most models is clustered around 60-70%. In this paper we propose systematic methods to analyze the behavior of these models as a first step towards recognizing their strengths and weaknesses, and identifying the most fruitful directions for progress. We analyze two models, one each from two major classes of VQA models -- with-attention and without-attention and show the similarities and differences in the behavior of these models. We also analyze the winning entry of the VQA Challenge 2016.  Our behavior analysis reveals that despite recent progress, today's VQA models are \"myopic\" (tend to fail on sufficiently novel instances), often \"jump to conclusions\" (converge on a predicted answer after 'listening' to just half the question), and are \"stubborn\" (do not change their answers across images).", "text": "recently number deep-learning based models proposed task visual question answering performance models clustered around paper propose systematic methods analyze behavior models ﬁrst step towards recognizing strengths weaknesses identifying fruitful directions progress. analyze models major classes models with-attention without-attention show similarities differences behavior models. also analyze winning entry challenge visual question answering recentlyintroduced problem given image natural language question task automatically produce accurate natural language answer ﬂurry recent deep-learning based models proposed curiously performance methods clustered around mere top- entries challenge seems clear ﬁrst step understand models meaningfully compare strengths weaknesses different models develop insights failure modes identify fruitful directions progress crucial develop techniques understand behavior models. paper develop novel techniques characterize behavior models. concrete instantiations analyze models major classes models with-attention without-attention. also analyze winning entry challenge language model. provided analysis tools facilitate detailed meaningful investigation object detector performance. paper aims perform behavior analyses ﬁrst step towards diagnosing errors vqa. categorize errors made model four categories model focuses attention incorrect regions model focuses attention appropriate regions predicts incorrect answers predicted answers different labels might acceptable labels wrong. coarse useful failure modes interested understanding behavior models along speciﬁc dimensions whether generalize novel instances whether listen entire question whether look image. generalization novel instances investigate whether test instances incorrectly answered ones novel i.e. similar training instances. novelty test instances ways test questionimage pair novel i.e. different training pairs; test pair familiar answer required test time novel i.e. answers seen training different needs produced test pairs. complete question understanding investigate whether model understanding input question analyze model ‘listens’ ﬁrst words question entire question ‘listens’ question words nouns words question. complete image understanding absence large performance languagealone language vision models provides evidence current models seem heavily reliant language model perhaps really understanding image. order analyze behavior investigate whether predictions model change across images given question. dataset largescale free-form natural-language dataset containing images questions answers open-ended multiple-choice modalities answering visual questions. experimental results reported validation using following models trained training open-ended task lstm based model without-attention best performing model achieves accuracy validation set. channel model channel processes image extract image features) channel processes question recurrent neural network obtain question embedding). image question features obtained channels combined passed fully connected layer obtain softmax distribution space answers. lstm based model with-attention top-entry challenge leaderboard achieves accuracy validation set. model jointly reasons image question attention hierarchical fashion. attended image question features obtained different levels hierarchy combined passed layer obtain softmax distribution space answers. challenge winning entry multimodal compact bilinear pooling model real image track challenge model achieves accuracy validation set. model multimodal compact bilinear pooling used predict attention image features also combine attended image features question features. combined features passed layer obtain softmax distribution space answers. models make mistakes test instances different training ones? analyze ﬁrst type novelty measure correlation test accuracy distance test pairs nearest neighbor training pairs. test pair k-nns training compute average distance test pair k-nns. k-nns computed space combined image question embedding three models correlation accuracy average distance signiﬁcant cnn+lstm model model). high negative correlation value tells model less likely predict correct answers test pairs similar training pairs suggesting model good generalizing novel test pairs. correlation accuracy average distance signiﬁcant model suggesting better generalizing novel test pairs. also found mistakes made cnn+lstm model successfully predicted checking distance test pair k-nn training pairs thus analysis exposes reason mistakes made models also allows build human-like models predict oncoming failures potentially refuse answer questions ‘too different’ ones seen past. analyze second type novelty compute correlation test accuracy average distance test ground truth answer answers k-nn training pairs. distance answers computed space average wordvec vectors answers. correlation turns quite high cnn+lstm models signiﬁcant model. high negative correlation value tells model tends regurgitate answers seen training. distance features also good predicting failures failures predicted checking distance test answer answers k-nn training pairs cnn+lstm model note unlike previous analysis analysis explains failures cannot used predict failures fig. qualitative examples. fig. test pair semantically quite different k-nn training pairs explaining mistake. shows example model seen question training since seen green cone training instances unable answer test pair correctly. shows current models lack compositionality ability combine concepts cone green answer green cone test pair. compositionality desirable central intelligence. figure x-axis shows length partial question input. y-axis shows percentage questions responses partial questions full questions accuracy partial questions. fig. shows test accuracy percentage questions responses remain function partial question length. questions cnn+lstm model seems converged predicted answer ‘listening’ half question. shows model listening ﬁrst words question words towards end. also model ﬁnal accuracy making predictions based half original question. making predictions based image accuracy model model seems converged predicted answer listening half question often achieving ﬁnal accuracy model converges predicted answer listening half question time achieving ﬁnal accuracy fig. qualitative examples. also analyze change responses model’s predictions words particular part-of-the-speech dropped question. experimental results indicate wh-words effect model’s decisions pronouns effect model’s decisions least. model really ‘look’ image? analyze this compute percentage time response change across images given question plot histogram across questions analysis questions occurring atleast images validation resulting total questions. cumulative plot indicates questions cnn+lstm model outputs answer least half images. fairly high suggesting model picking answer matter image promisingly models produce response least half images fewer questions figure histogram percentage images model produces answer given question comparison test accuracy. cumulative plot shows questions model produces answer atleast images. model respective average accuracy entire validation thus producing response across images seems statistically favorable. fig. shows examples cnn+lstm model predicts response across images given question. ﬁrst shows examples model makes errors several images predicting answer images. second shows examples model always correct even predicts answer across images. questions what covers ground? asked image dataset ground covered snow thus analysis exposes label biases dataset. label biases also reported develop novel techniques characterize behavior models ﬁrst step towards understanding models meaningfully comparing strengths weaknesses different models developing insights failure modes identifying fruitful directions progress. behavior analysis reveals despite recent progress today’s models myopic often jump conclusions stubborn ﬁnal thought note somewhat pathological behaviors exposed paper sense correct given model architectures dataset trained ignoring optimization error maximum-likelihood training objective clearly intended capture statistics dataset. motive simply better understand current generation models behaviors observations guide future choices need novel model classes? dataset different biases? etc. finally clear anthropomorphic adjectives stubborn myopic etc. purely pedagogical reasons easily communicate observations readers. claims made today’s models human-like. acknowledgements. would like thank emnlp reviewers valuable feedback yash goyal sharing code. work supported part career awards army research ofﬁce awards ictas junior faculty awards google faculty research awards awarded grant n--- education research grant nvidia donation awarded paul allen family foundation allen distinguished investigator award alfred sloan fellowship awarded views conclusions contained herein authors interpreted necessarily representing ofﬁcial policies endorsements either expressed implied u.s. government sponsor. cnn+lstm models feeding question feeding image computed percentage responses change feeding question well compared feeding image percentage responses change feeding image well compared feeding question. found responses changed much addition question addition image. suggests models heavily driven question rather image. average distance) random subset test points. test points accuracy average distance higher compared test points high accuracy. correlation between accuracy average distance signiﬁcant fig. shows cnn+lstm model produces correct response nearest neighbor pairs training set. seen nearest neighbor pairs training similar test pair. addition labels training similar test label. fig. shows test pairs cnn+lstm model produces incorrect response nearest neighbor pairs training set. mistakes probably test pair similar pairs training mistakes probably labels training similar test label fig. shows variation accuracy test point w.r.t average distance k-nn training points cnn+lstm model. point plot represents average statistics tags matter three major categories questions yes/no number other categorized yes/no questions whose answers either number questions whose answers numbers other rest questions. figure x-axis shows length partial yes/no question input. y-axis shows percentage yes/no questions responses partial yes/no questions full yes/no questions accuracy partial yes/no questions. figure x-axis shows length partial other question input. y-axis shows percentage other questions responses partial other questions full other questions accuracy partial other questions. figure x-axis shows length partial number question input. y-axis shows percentage number questions responses partial number questions full number questions accuracy partial number questions. yes/no questions model seems particularly ‘jumpy’ converging predicted answer listening ﬁrst words question surprisingly accuracy also much ﬁnal accuracy making predictions based ﬁrst words question. contrast cnn+lstm model converges predicted answer later listening atleast question achieving much ﬁnal accuracy convergence. number other questions cnn+lstm model show similar trends probably often yes/no questions attributes objects number questions cnn+lstm model sensitive adjectives whereas model sensitive whwords other questions models sensitive nouns figure histogram percentage images model produces answer given number question. cumulative plot shows number questions model produces answer atleast images. fig. shows examples cnn+lstm model converges predicted answer without listening entire question. model gets answer correct pairs incorrect others figure histogram percentage images model produces answer given other question. cumulative plot shows other questions model produces answer atleast images. figure histogram percentage images model produces answer given yes/no question. cumulative plot shows yes/no questions model produces answer atleast images. fig. fig. fig. show breakdown percentage questions model produces answer across images yes/no number other respectively. model seems stubborn yes/no questions compared cnn+lstm model less stubborn number questions compared cnn+lstm model.", "year": 2016}