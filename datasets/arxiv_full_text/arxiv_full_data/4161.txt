{"title": "Learning recurrent representations for hierarchical behavior modeling", "tag": ["cs.AI", "cs.CV"], "abstract": "We propose a framework for detecting action patterns from motion sequences and modeling the sensory-motor relationship of animals, using a generative recurrent neural network. The network has a discriminative part (classifying actions) and a generative part (predicting motion), whose recurrent cells are laterally connected, allowing higher levels of the network to represent high level phenomena. We test our framework on two types of data, fruit fly behavior and online handwriting. Our results show that 1) taking advantage of unlabeled sequences, by predicting future motion, significantly improves action detection performance when training labels are scarce, 2) the network learns to represent high level phenomena such as writer identity and fly gender, without supervision, and 3) simulated motion trajectories, generated by treating motion prediction as input to the network, look realistic and may be used to qualitatively evaluate whether the model has learnt generative control rules.", "text": "propose framework detecting action patterns motion sequences modeling sensory-motor relationship animals using generative recurrent neural network. network discriminative part generative part whose recurrent cells laterally connected allowing higher levels network represent high level behavioral phenomena. test framework types data fruit behavior online handwriting. results show taking advantage unlabeled sequences predicting future motion signiﬁcantly improves action detection performance training labels scarce network learns represent high level phenomena writer identity gender without supervision simulated motion trajectories generated treating motion prediction input network look realistic used qualitatively evaluate whether model learnt generative control rules. behavioral scientists strive decode functional relationship sensory input motor output brain particular ethologists study natural behavior animals neuroscientists psychologists study behavior controlled environment manipulating neural activations environmental stimuli. studies require quantitative measurements behavior discover correlations causal relationships behaviors time behavior stimuli; automating process allows objective precise measurements signiﬁcantly increased throughput many industries also concerned automatic measurement prediction behavior applications surveillance assisted living sports analytics self driving vehicles robotic/virtual assistants. behavior complex perceived different time-scales resolution position trajectory action activity. position trajectory geometrical notions action activity semantic nature. analysis behavior therefore divided steps detection tracking pose body time estimated action/activity detection classiﬁcation motion segmented meaningful intervals associated goal purpose. work focuses going detect classify actions motion trajectories. data tracking pose estimation relatively simple lets focus modeling temporal dynamics pose trajectories without worrying errors stemming level feature extraction. supervised learning powerful tool learning classiﬁers examples actions provided expert however drawbacks. first requires training examples involves time consuming painstaking annotation. second behavior measurement limited actions human perceive believes important. propose framework takes advantage labeled unlabeled sequences simultaneously predicting future motion detecting actions allowing system learn action classiﬁers fewer expert labels discover unbiased behavior representations. framework models sensory-motor relationship agent predicting motion based sensory input motion history. used simulate agent iteratively feeding motion predictions input network updating sensory inputs accordingly. model simulate realistic behavior learnt emulate generative control laws underlying behavior could useful tool behavior analysis model constructed goal learn represent discover behaviors different semantic scales offering unbiased measuring behavior minimal human input. recent work berman wiltschko shows promising results towards unsupervised behavior representation. compared work framework offers three advantages. model learns hierarchical embedding behavior trained semi-supervised learn speciﬁc behaviors interest sensory-motor representation enables model learn interactive behavior agent agents environment. experiments focus mainly behavior fruit ﬂies drosophila melanogaster popular relatively simple model organism study behavior explore generality approach also test model online handwriting data interesting human behavior produces dimensional trajectories. hidden markov models extensively used sequence classiﬁcation. motivating assumption hmms exists process transitions probability discrete states emits observations according distribution objective learn functions given sequence observations states. model limited transition functions linear state space discrete emission distribution generally assumed gaussian although generalizations model fall category dynamic bayesian networks expressive recurrent neural networks recently shown extremely successful classifying time series data especially popularization long short term memory cells applications speech recognition rnns also used generative sequence prediction handwriting well speech synthesis imitation learning involves learning state action demonstrated sequences actions. supervised learning technique which implemented trained backpropagation using action-error computed every time step. problem approach domain states agent trained consists states demonstrators encounter agent makes mistake ﬁnds situation never experienced training. reinforcement learning handles letting agent explore domain using action policy updating policy based goal-speciﬁc penalty reward obtained taking several actions. exploration extremely expensive therefore common precede reinforcement learning imitation learning start agent reasonable policy. strategy used agent trained play atari games mastering game autoencoders used semi-supervised classiﬁcation pretrain network auxiliary task denoising prevent overﬁtting small number labeled data recent work area proposes train primary auxiliary task concurrently using lateral connections encoding decoding layers allow higher layers network focus high level features. model recurrent neural network long short term memory simultaneously classiﬁes actions predicts future motion agents rather actions function recurrent state common practice model embeds actions recurrent state units. recurrent function encodes action transition probabilities motion prediction direct function actions similar hmm. network takes input agent’s motion sensory input every time step outputs agent’s next move according policy effectively learnt imitation learning. similar autoencoders model discriminative path used embed high level information generative path used reconstruct input domain case ﬁlling future motion. discriminative recurrent cell fully connected corresponding generative cell allowing higher level states represent higher level information similar idea ladder networks figure left depiction network unrolled timesteps. highlighted cells show path input classiﬁcation cell motion prediction output. training motion prediction loss computed every timestep classiﬁcation loss computed frames labels provided. diagonal connections discriminative generative cells enable higher levels network represent high level information. vector represents agent’s sensory input motion internal state labeled actions. right zoom blue green cells showing recurrent state inputs recurrent cell function merging arrows represents vector concatenation branching vector duplication. model thought parallel recurrent networks discriminative network takes input agent’s motion environmental sensory input propagates hidden states encode high level information including action labels generative network decodes states discriminative network propagating information predict agents locomotion next time step networks number layers connected diagonally layer information encoded hidden units discriminative network propagated corresponding layer generative network next time step. intuitively diagonal connections allow higher levels network represent high level phenomena goals individuality lower levels represent level information motion. experiments conﬁrm intuition. model trained without action labels case hidden state used discover high level information data action labels subset data case action assigned hidden state unit thus contribute subsequent motion prediction action classiﬁcation. recurrent cell function transformation loss functions total cost combines misclassiﬁcation cost misprediction cost using tradeoff two. number labeled actions number levels number frames layer index frame index. classiﬁcation labels assigned ﬁrst units present model part general framework number levels/units architectural choices optimized dataset. experiments found levels recurrent cells units worked well gated recurrent unit cell linear transformation. choice loss functions depends target type; sigmoid cross entropy multitask classiﬁcation softmax cross entropy multiclass classiﬁcation squared differences regression optimal value depends output domain whether primary goal classiﬁcation simulation. data-speciﬁc modeltraining parameters described section training details discussed supplementary material. evidence suggests animal behavior nondeterministic thus motion prediction better represented probability distribution function. future motion multimodal best regression model pick average motion different modes within actual modes observation made others context modeling real-valued sequences rnns model output gaussian mixture model additionally model hidden recurrent states random variables. take nonparametric approach making assumption shape distribution. discretize motion bins treat task predicting future motion independent multiclass classiﬁcation problems motion feature results probability distribution bins dimension. concretely dimension assigned bins target ˆxi+ becomes binned version denoted ˜xi+ exactly nonzero entry dimension prediction ˆxi+ becomes discrete distribution bins feature dimension opposed euclidean distance case real valued vector. number bins determines granularity motor control; greater number bins means precise motion control also expensive train. given model predict agent’s future motion current state virtual agent simulated iteratively feeding predicted motion ˆxi+ input network. pick sampling distribution given ˆxi+ assign real value sampling uniformly selected bin. agent’s perception environment depends agent’s location therefore sensory features must computed forward simulation step agents perspective time simulating multiple agents interact another agent moved according computed agent based conﬁguration agents. framework agent centric models behavior single agent based moves experiences world including agents. applicable data represented terms motor control sensory input captures context environment test model types data fruit behavior online handwriting. thought type behavior represented form trajectories complementary first ﬂies behave spontaneously performing actions interest sporadically response environment handwritten text intensional highly structured. second handwriting varies signiﬁcantly different writers terms size speed slant proportions inter-ﬂy variation relatively small. datasets selected experiments listed below interested answering following questions motion prediction improve action classiﬁcation model generate realistic simulations model discover novel behavioral phenomena? fly-vs-ﬂy contains pairs fruit ﬂies engaging labeled courtshipaggressive behaviors. include dataset experiments model compares previous action detection work relies handcrafted window features. flybowl video male female fruit ﬂies interacting labeled male wing extensions part courtship behavior. dataset particularly interested whether model could simulate virtual complex dynamic environment. synthfly synthetic dataset containing single moving inside rectangular chamber stationary object located center. synthesized move according control laws listed figure purpose dataset test whether model could learn generative control rules particularly ones enforce non-deterministic behavior iam-ondb contains handwritten text different writers acquired using smart whiteboard records list coordinates stroke. data weakly labeled sequence separated short lines transcribed text. consistency framework hand annotated strokes writers marking start lower case characters along data unlabeled writers experiments. figure snapshots three labeled datsets used evaluation list control laws used generate synthetic trajectories. table summarizes statistics experimental dataset total frames sums trials within experiment agents within trial total instances sums action classes frames percent frames labeled sequences containing actions interest. iam-ondb* subset iam-ondb additional annotations trials. figure left sensory input fruit ﬂies represents sees ﬂies chamber walls motor control lets move body along dimensions. right motor control handwriting represented vector along binary stroke visibility representation motor control features describe locomotion ﬂies tracked video using flytracker tracked poses extract motion features represented ﬂy’s frame reference. motion features displayed figure designed animate virtual agents. sensory input features inspired ﬂy’s compound consist compactly aligned ommatidia. approximating vision dimensional view place circular sectors around aligned orientation project ﬂies overlap sector onto artiﬁcial retina. flies close agent yield high intensity several ommatidia ﬂies away take ommatidia intensity. represent chamber walls similarly projecting onto separate channel decreasing intensity exponentially distance representation invariant shape chamber number ﬂies present chamber. order compare model methods presented eyjolfsdottir independently feature representation features provided fly-vs-fly dataset. assign ﬁrst dimensions describe ﬂy’s locomotion motor control remaining features describe position relative feature derivatives sensory input. handwriting representation represent motor control displacements previous recording binary variable denoting segment visibility. normalize writer providing invariance writing speed character size slant variations explicitly accounted for. handwriting inﬂuenced changing environment rather function internal state current motion writer leave sensory input empty. evaluate framework three objectives classiﬁcation simulation discovery. classiﬁcation show beneﬁt motion prediction auxiliary task compare performance fly-vs-fly previous work analyze performance iam-ondb. qualitatively show simulation results behavior handwriting look convincing model able learn control laws used generate synthfly dataset. discovery show hidden states model trained predict motion cleanly capture high level phenomena affect behavior gender writer identity. model details trained separate model dataset using sequence length batch size bins dimension motion prediction. behavior data used levels cells units each handwriting used levels cells units each. parameters determined using rough parameter sweep subset training data. training details described supplementary material. model implemented tensorﬂow figure performance model trained without motion prediction varying number training labels. performance fly-vs-fly compared results eyjolfsdottir example input ground truth classiﬁcation score iam-ondb. sequence frame-wise classiﬁcations extract consecutive classiﬁcations intervals actions. measure duration counting accuracy performance measures described eyjolfsdottir namely score per-frame per-bout level. bout-wise precision recall computed assigning predicted bouts ground truth bouts one-to-one maximizing intersection overlap. harmonic mean f-frame f-bout scores. main goal terms classiﬁcation reduce number training labels without loss performance using motion prediction auxiliary task. measure beneﬁt semisupervision compare model refer behavior embedding sensory-motor network model without generative part refer behavior embedding network trained models dataset using available labels. besnet trained predict future motion makes unlabeled sequences training whereas benet not. figure shows frame-wise score trained models averaged action classes dataset. experiment shows motion prediction auxiliary task signiﬁcantly improves classiﬁcation performance especially labels scarce. figure compare performance network best performing method flyvs-fly window based support vector machine uses hand crafted window features output smoother classiﬁcation outperforming sophisticated methods structured svm. comparison used features published dataset described section although recurrent networks implicitly enable smooth classiﬁcation different actions require different levels smoothness. avoid segmentation action intervals smooth output network applying ﬁlter size equal mean duration class. results show ﬁltering signiﬁcantly improves bout-wise performance performance fly-vs-fly test comparable eyjolfsdottir using handcrafting context future frames applied type ﬁltering classiﬁcation output iam-ondb flyvs-fly obtained averaged classes averaged instances figure demonstrates beginning characters tends confusion towards unsurprising beginning characters looks approximately same. look simulation results quantitatively measure accuracy one-step predictions. compute log-likelihood flybowl test sequences motion prediction model ground truth indicator vector bins probability distribution bins predicted model. compare model following motion prediction policies uniform distribution bins distribution bins computed training constant motion policy copies previous indicator vector motion prediction smooth version ﬁltered using optimized gaussian kernel. results shown figure demonstrate recurrent models learn signiﬁcantly better policy. addition compare variants model standard within framework shows recurrence essential good motion prediction diagonal connections provide slight performance gain. section show main beneﬁt diagonals. one-step prediction performance clearly reveal whether model learnt generative process underlying training data. order better notion look simulations produced learnt models thought long term predictions. motion prediction probabilistic comparing long term predictions ground truth becomes difﬁcult domain probable positions becomes exponentially large. qualitative inspection however gives good intuition whether simulated agent learnt reasonable control laws. underlying generative process motion real ﬂies unknown simulations model trained imitate suggest model learnt reasonable policy. simulation place physical constraints ﬂies move results show simulated flybowl agents avoid collisions chamber walls ﬂies agents attracted ﬂies occasionally engage courtship-like behavior. shown figure better visualized video supplementary material. simulated handwriting easier visualize image used recognizing structure produce. figure shows model trained iam-ondb produces character-like trajectories word-like combinations. note handwriting generated vector time character composed roughly points average. right hand side figure show increase generation speciﬁc characters activating classiﬁcation units simulation. figure shows output recurrent units synthfly model indicate model able learn control rules designed ensure multimodal motion prediction target. unit ﬁres correlation either left right wing extension toggles negative positive state agent turns left right avoid object. supplementary material show video simulation compare simulation model trained deterministic motion prediction. comparison clearly demonstrates beneﬁt treating motion prediction distribution bins deterministic agent quickly becomes degenerate. figure -frame lookaheads test current location demonstrating non-deterministic nature motion prediction. ground truth -frame future trajectory outlined black comparison. shows trajectories ﬂies simulated frames shows -frame trajectories real ﬂies interacting. simulation shows model learnt preference staying near boundary avoid walking boundary. figure left text generated model vector time right text generated model activating character classiﬁcation units model simulation shown lines character. figure comparison synthetic simulation model. wing angles distance object left/right turn show agent’s motion time hidden units indicate model learnt represent control laws used generate synthetic trajectories. motivated structure network speciﬁcally diagonal connections discriminative generative cells intuition would allow higher levels network better represent high level phenomena. verify train models predict future motion classiﬁcation target visualize hidden states capture. apply model obtaining hidden state vectors prediction data points state dimensions using t-distributed stochastic neighbor embedding plot colors based known phenomena. figure left hidden state values level model trained without labels iam-ondb reduced dimensions using tsne mapping. network discovers writer identity highest level lower level phenomena stroke length represented lower levels. right tsne mapped input output hidden state values flybowl model colored gender male wing extension. figure plot data points level model trained iam-ondb dimensional embedding color code according three criteria stroke length character class writer identity. results show stroke length well clustered levels high levels characters best clustered discriminative levels writer identity extremely well clustered generative level levels. experiment model trained without diagonal connections learn represent writer identity hidden states. intuitively network carry level information every state predict level information whereas besnet carries directly level diagonal connections leaving higher hidden states free capture high level information. visualization comparing models shown supplementary material along quantitative measurement observation. visualization model trained flybowl data points color coded gender left/right wing extension shows gender mixed input output states well separated generative state lower level information wing extension well represented lower levels network. proposed framework modeling behavior animals simultaneously classiﬁes actions predicts motion. showed empirically motion prediction good auxiliary task training action classiﬁers especially labels scarce. also showed generative task used simulate trajectories look natural human activating classiﬁcation units increases frequency action simulation. finally showed model lends well discovery high level information data. moving forward interested working hierarchical label embedding states assigning higher order activities units higher network. along lines discrete recurrent network could trained separately wealth available text placed realvalued handwriting network. also explore framework used understand neural mechanisms underlying generation behavior ﬂies. references mart´ın abadi ashish agarwal paul barham eugene brevdo zhifeng chen craig citro greg corrado andy davis jeffrey dean matthieu devin sanjay ghemawat goodfellow andrew harp geoffrey irving michael isard yangqing rafal jozefowicz lukasz kaiser manjunath kudlur josh levenberg man´e rajat monga sherry moore derek murray chris olah mike schuster jonathon shlens benoit steiner ilya sutskever kunal talwar paul tucker vincent vanhoucke vijay vasudevan fernanda vi´egas oriol vinyals pete warden martin wattenberg martin wicke yuan xiaoqiang zheng. tensorflow large-scale machine learning heterogeneous systems http//tensorflow.org/. software available tensorﬂow.org. gordon berman daniel choi william bialek joshua shaevitz. mapping stereotyped behaviour freely moving fruit ﬂies. journal royal society interface kyunghyun bart merri¨enboer caglar gulcehre dzmitry bahdanau fethi bougares holger schwenk yoshua bengio. learning phrase representations using encoder-decoder statistical machine translation. arxiv preprint arxiv. junyoung chung kyle kastner laurent dinh kratarth goel aaron courville yoshua bengio. recurrent latent variable model sequential data. advances neural information processing systems eyrun eyjolfsdottir steve branson xavier burgos-artizzu eric hoopfer jonathan schor david anderson pietro perona. detecting social actions fruit ﬂies. computer vision– eccv springer alan graves abdel-rahman mohamed geoffrey hinton. speech recognition deep recurrent neural networks. acoustics speech signal processing ieee international conference ieee mayank kabra alice robie marta rivera-alba steven branson kristin branson. jaaba interactive machine learning automatic annotation animal behavior. nature methods marcus liwicki horst bunke. iam-ondb-an on-line english sentence database acquired handwritten text whiteboard. document analysis recognition proceedings. eighth international conference ieee volodymyr mnih koray kavukcuoglu david silver andrei rusu joel veness marc bellemare alex graves martin riedmiller andreas fidjeland georg ostrovski human-level control deep reinforcement learning. nature william roberts steven augustine kristy lawton theodore lindsay thiele eduardo izquierdo serge faumont rebecca lindsay matthew cale britton navin pokala stochastic neuronal model predicts random search behaviors multiple spatial scales elegans. elife rumenlhart geoffrey hinton ronald williams. learning internal representation error propagation parallel distributed processing. explor. microstruct. cognition david silver huang chris maddison arthur guez laurent sifre george driessche julian schrittwieser ioannis antonoglou veda panneershelvam marc lanctot mastering game deep neural networks tree search. nature alexander wiltschko matthew johnson giuliano iurilli ralph peterson jesse katon stan pashkovski victoria abraira ryan adams sandeep robert datta. mapping sub-second structure mouse behavior. neuron", "year": 2016}