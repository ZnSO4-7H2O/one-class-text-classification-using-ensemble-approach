{"title": "DID: Distributed Incremental Block Coordinate Descent for Nonnegative  Matrix Factorization", "tag": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "abstract": "Nonnegative matrix factorization (NMF) has attracted much attention in the last decade as a dimension reduction method in many applications. Due to the explosion in the size of data, naturally the samples are collected and stored distributively in local computational nodes. Thus, there is a growing need to develop algorithms in a distributed memory architecture. We propose a novel distributed algorithm, called \\textit{distributed incremental block coordinate descent} (DID), to solve the problem. By adapting the block coordinate descent framework, closed-form update rules are obtained in DID. Moreover, DID performs updates incrementally based on the most recently updated residual matrix. As a result, only one communication step per iteration is required. The correctness, efficiency, and scalability of the proposed algorithm are verified in a series of numerical experiments.", "text": "means element-wise nonnegative k·kf frobenius norm. problem nonconvex respect variables finding global minimum np-hard thus practical algorithm usually converges local minimum. solve least alternating direction multiplier method alternating nonnegative least square amongst algorithms anls largest reduction objective value iteration since exactly solves nonnegative least square subproblems using block principal pivoting method unfortunately computation iteration costly. algorithm hals hand solves subproblems inexactly cheaper computation achieved faster convergence terms time instead iteratively solving subproblems admm obtains closed-form solutions using auxiliary variables. drawback admm sensitive choice tuning parameters even point poor parameter selection lead algorithm divergence proposed algorithms intended centralized implementation assuming whole data matrix loaded single computer node. massive data sets however assumption often satisﬁed since number samples large stored single node. result growing need develop algorithms distributed system. thus paper assume number samples large data matrix collected stored distributively. applications found e-commerce digital content streaming technology hundreds millions users. nonnegative matrix factorization attracted much attention last decade dimension reduction method many applications. explosion size data naturally samples collected stored distributively local computational nodes. thus growing need develop algorithms distributed memory architecture. propose novel distributed algorithm called distributed incremental block coordinate descent solve problem. adapting block coordinate descent framework closed-form update rules obtained did. moreover performs updates incrementally based recently updated residual matrix. result communication step iteration required. correctness efﬁciency scalability proposed algorithm veriﬁed series numerical experiments. nonnegative factors extracts latent dimensional subspace. popularity ability learn parts-based representation nonnegative constraints. numerous successes found document clusterlu hong wang computer signal etc. suppose collection samples nonnegative measurements denoted matrix form column sample. purpose approximate product nonnegative matrices desired dimension min{m columns matrix considered basis dimension subspace columns matrix coordinates. formulated optimization problem optimization problem biconvex i.e. either factor ﬁxed updating another fact reduced nonnegative least square problem. thus anls minimizes nnls subproblems respect alternately. procedure given parallel cminimization step column-by-column manner b-minimization step row-by-row manner. hpc-anls divides matrix d-grid blocks matrix blocks matrix column blocks memory requirement node number rows processor number columns processor pcpr total number processors. really perform updates intermediate variables computed broadcasted using totally communication steps. cost latency inverse bandwidth distributed memory network model analysis summarized table since optimal solution subproblem required updating factor comparable method called hals achieves approximate solution proposed algorithm hals successively updates column optimal solution closed form. ever suffers slow convergence kannan ballard park performance anls using d-grid partition data matrix node stores submatrix data matrix. nevertheless communication steps iteration required obtain intermediate variables solve subproblems. thus communication overhead signiﬁcant. moreover computation costly anls framework. recent work distributed hals however assume factors stored shared memory computer nodes case large. boyd suggested admm potential solve distributively. demonstrated idea algorithm called maxios. similar hpc-anls communication overhead expensive since every latent factor auxiliary variable gathered broadcasted computational nodes. result eight communication steps iteration necessary. addition maxios works sparse matrices since assume whole data matrix stored every computer node. propose novel distributed algorithm called distributed incremental block coordinate descent splitting columns data matrix capable updating coordinate matrix parallel. leveraging recent residual matrix basis matrix updated distributively incrementally. thus communication step needed iteration. paper organized follows. section previous works brieﬂy reviewed. section introduces distributed admm comparison purpose. novel algorithm detailed section section algorithms evaluated compared. finally conclusions drawn section notations. given nonnegative matrix rows columns denote i-th denote j-th column denote entry i-th j-th column. addition denote transpose i-th j-th column respectively. broadcasted computational nodes. consequence maxios requires theoretically eight communication steps iteration works sparse matrices. table summarizes analysis. zdunek fonal proposed distributed version hals called dhals. also divide data matrix d-grid blocks. comparing hpc-anls resulting algorithm dhals requires communication steps. however assume matrices loaded shared memory single node. therefore dhals applicable scenario assume even latent factors stored distributively. detailed analysis table rk×n lagrangian multipliers matrix inner product penalty parameter equality constraints. minimizing respect time ﬁxing rest obtain update rules follows rk×k identity matrix. auxiliary variables facilitate minimization steps small however update rules result unstable convergence large admm suffers slow convergence. hence selection signiﬁcant practice. analogous hpc-anls update parallelized column-by-column manner update row-by-row manner. thus maxios divides matrix column blocks matrix blocks. however communication overhead expensive since factor update depends others. thus factor updated expensive required optimal solutions subproblems ensure convergence. section propose another distributed algorithm adapts block coordinate descent framework achieves approximate solutions iteration. moreover leveraging current residual matrix facilitates update matrix columns updated incrementally. ﬁrstly introduce naive parallel distributed algorithm inspired hals called distributed block coordinate descent since objective function separable matrix partitioned columns processor able update columns parallel prepare messages concurrently update matrix based equation j-th column required update thus updating column sequential. however update executed parallel j’s. therefore columns matrix updated independently component column optimized sequence. doubt intermediate variables calculated distributively. λi/ρ called scaled dual variable. using scaled dual variable express dadmm efﬁcient compact way. simple implementation algorithm dadmm computational node summarized algorithm line algorithm theoretically need master processor gather every local processor broadcast updated value back. result master processor needs storage however collaborative operation called allreduce leveraging master processor discarded storage processor reduced popularity admm ability carrying subproblems parallel dadmm algorithm however computation admm costly since generally involves introducing auxiliary variables updating dual variables. computational cost even identify vectors scalars update matrix computation executed concurrently among computational nodes. implementation algorithm processor summarized algorithm complexity algorithm dbcd iteration perfectly parallelizing sequential block coordinate descent algorithm. however performance dbcd could deﬁcient delay network. principle dbcd sends totally messages master processor iteration even implement dbcd using allreduce. delay message could cause diminished performance. contrast algorithm novel update matrix incrementally using single message processor iteration. successfully update matrix bottleneck iteratively compute associated since updated recomputed change occurred matrix equation nevertheless discovered change represented several arithmetic operations. thus fact need communicate every time order update unfortunately parallel since equation involves whole matrices reason sequential algorithms easily implemented shared memory cannot directly applied distributed memory. thus works either gather operations collect messages local processors assume small size latent factors. thus update matrix executed parallel indirectly. complexity updating reserve error vector concurrently compute complexity updating entire matrix conduct series numerical experiments compare proposed algorithm hals admm dbcd dadmm hpc-anls. algorithm sequential version dbcd. convergence admm maxios derive dadmm section default. since assume much smaller hpc-anls column partition matrix i.e. cluster consists supermicro servers cores memory gige inﬁniband interconnects. algorithms implemented code. linear algebra operations scientiﬁc library message passing interface implementation openmpi used communication. note multi-cores server. instead single core node want achieve consistent communication overhead cores. synthetic datasets generated number samples storage limits computer system dimension rank utilize number computational nodes cluster. random numbers synthetic datasets generated matlab command rand uniformly distributed interval also perform experimental comparisons four realworld datasets. mnist dataset handwritten digits samples image. news dataset collection documents across different newsgroups totally keywords. umist dataset http//www.hpc.iastate.edu/ http//www.gnu.org/software/gsl/ https//www.open-mpi.org/ http//yann.lecun.com/exdb/mnist/ http//qwone.com/~jason/newsgroups/ https//cs.nyu.edu/~roweis/data.html equation ﬁrst terms general update rule matrix dbcd eci+ computed distributively computational node. hand last term allows update column still closed form without communication step. therefore update matrix carried incrementally general update rule given comparing messages used dbcd i.e. need compute coefﬁcients extra term thus message communicated among processors contains parts weighted current residual matrix lower triangular matrix maintaining inner product matrix matrices deﬁned processor store column column matrix execute algorithm implementation incremental algorithm computational node summarized algorithm clearly entire computation unchanged volume message stays dbcd number communication reduced iteration. efﬁciency presented table always converges faster algorithms term time. hals usually similar number iterations reach stopping criteria. anls admm much fewer iterations converge. thanks auxiliary variables admm usually converges faster anls. figure shows comparing hals actually reduces objective value beginning takes longer ﬁnally converge. phenomenon also observed comparison anls admm. figure faster dbcd. reason shown figure involves much less communication overhead dbcd. based result table faster dbcd incrementally updating matrix anls works better mnist news datasets datasets sparse. scalability presented table runtime scales linearly number samples increases much better others. usually speed factor least using nodes. admm also linearly scalable slightly better anls. costly computation admm preferred solve problems. paper proposed novel distributed algorithm solve distributed memory architecture. assume number samples huge divides matrices column blocks updating matrix perfectly distributed. using variables maalgorithms hals could fail kbik close zero. could appear badly scaled. means entries strictly negative. avoid issue using well scaled initial points synthetic datasets k-means method generate initial values real datasets. algorithms provided initial values. residual matrix t-th iteration. throughexperiments default. addition combine stopping criterion limit time hours maximum iteration real datasets. experimental results summarized table correctness principle algorithms hals update rules latent factors difference update order. algorithm exact number iterations dbcd demonstrates correctness did. trix updated distributively incrementally. result single communication step iteration required. algorithm implemented code openmpi. numerical experiments demonstrated faster convergence algorithms. update requires basic matrix operations achieves linear scalability observed experimental results. future work applied cases updating matrix also carried parallel. using techniques introduced possibility accelerated. better treat sparse datasets also potential research direction.", "year": 2018}