{"title": "Evolution and the structure of learning agents", "tag": ["cs.AI", "cs.LG", "I.2; I.2.6"], "abstract": "This paper presents the thesis that all learning agents of finite information size are limited by their informational structure in what goals they can efficiently learn to achieve in a complex environment. Evolutionary change is critical for creating the required structure for all learning agents in any complex environment. The thesis implies that there is no efficient universal learning algorithm. An agent can go past the learning limits imposed by its structure only by slow evolutionary change or blind search which in a very complex environment can only give an agent an inefficient universal learning capability that can work only in evolutionary timescales or improbable luck.", "text": "learning agents ﬁnite information size limited informational structure goals efﬁciently learn achieve complex environment. evolutionary change critical creating required structure learning agents complex environment. thesis implies efﬁcient universal learning algorithm. agent past learning limits imposed structure slow evolutionary change blind search complex environment give agent inefﬁcient universal learning capability work evolutionary timescales improbable luck. computing machine learn achieve goals complex environment? complex machine needs order paper attempt deﬁne questions discuss possible answer constraints limitations answer implies learning machines algorithms. machine learning widely studied area. cases machine learning deals supervised assisted learning information passed learning machine training learning phase example list labeled examples patterns learning concept. assisted supervised learning mature ﬁeld good progress made years example back propagation training multilayer neural networks support vector machines probably approximately correct model computational learning discovering patterns important achieving certain goal unknown environment important learning problem right. machine learning also studies unsupervised learning example neural networks learn statistical structure input data without training examples clustering unlabeled data feature extraction dimensionality reduction large input datasets steps direction. paper study unassisted learning unknown environment learning machine receive information environment external agent. henceforth learning always mean unassisted learning sense. environment. term agent-body this assume agent-body sufﬁcient sensing physical action capabilities achieving sufﬁciently large goals complex environment allow meaningful discussion goal achieving learning capabilities. deﬁning exact speciﬁcations agent-body relevant thesis presented except compare goal achieving capabilities different machines assume physically identical agent-bodies. machine also requires computing platform part information processing algorithm able achieve goals complex environment. deﬁne term agent algorithm turing machine running computing platform part processes physical actions agent-body. consider agents identical binary string representation including data identical agent representation scheme. agent learns change modifying code data. start size denote size number bits binary string representation agent including data start learning experiments. assume agent much blank memory available requires. important emphasize paper consider agents constrained limited amount memory. expression ﬁnite sized agent agent means ﬁnite start size assumption agent allowed unlimited amount memory grow arbitrary size. extension churchturing thesis premised states learning goal achieving capabilities physically realizable system implemented turing machine running computing platform comparable throughput controlling agent-body physically equal terms physical action capabilities sensory capabilities. equivalently stated physical symbol system hypothesis newell simon pair environment states starting state state. physical state agent-body outside computing platform part considered part environment state. term goalset denote goals. goals denote goals environment agent-body physically achieve. agent achieves goal using sequence actions takes environment path sequence states cost example energy cost environmental cost elapsed time cost possibly costs. represent costs achieving goal path positive real number denote cost. note cost different different paths used goal different paths goal result agent repeating sequence actions randomness environment resulting state transitions actions. note amount memory used number computing steps executed agent achieving goal counted measurement cost. determine agent knows achieve goal target cost goal using function pcost goals agent knows achieve goal phrase agent effectively achieve goal agent achieve goal median) pcost repeated trials identical start state identical agent start. agent effectively achieve goalset mean caneffectivelyachieveg. exploring environment intelligent agent learn effectively achieve goal even effectively achieve goal start with. denote cost explorations agent learning effectively achieve goal starting state learning cost. cost would depend well agent state knowledge environment. also cost vary repeat experiment learning cost identical start state identical agent learning cost denote cost learning effectively achieve every goal goalset agent determine agent efﬁciently learn effectively achieve goalset target learning cost goalset using function lcost phrase agent efﬁciently learn effectively achieve goalset agent efﬁciently learn goalset median) lcost repeated trials identical agent start. although energy elapsed time included cost measurement thesis impose limit number computational steps executed given elapsed time period amount energy. interesting result show dependence thesis presented theoretically inﬁnite computing speed. note universe upper limit physical computing device many computational steps executed within given time period amount energy. choice pcost arbitrary immaterial thesis presented here choose value pcost appropriately approaching optimal cost indicate agent’s goal achieving capability within certain cost good enough success rate. hypothesize ﬁnite body information agent start effectively achieve arbitrary goalset environment unbounded complexity. start size smallest agent effectively achieve given goalset smaller certain critical size start size would grow larger goalsets requiring environmental information. deﬁne term description complexity goalset environment integer value agents effectively achieve start size description complexity. ﬁrst principle stated below. principle description complexity smallest effectively achieve goalset grows monotonically larger goalsets. description complexity grows inﬁnity grows goals environment unbounded complexity. phrase description environment goalset short description respect clear context denote agent start size description complexity effectively achieve note smallest agent goalset unique. words multiple alternative descriptions environment respect goalset discuss constraints learning agents would limited hypothesize general domain independent algorithm would allow agent efﬁciently learn arbitrary goalset environment starting zero information goal domain. agent must environment representational building blocks call icroconcepts henceforth able efﬁciently learn required description environment able effectively achieve goals. icroconcepts bit-strings found evolutionary search bring agent higher ﬁtness landscape allow agent efﬁciently learn goalset. phrase efﬁciently learn deﬁned important here. algorithm learns evolutionary change starting zero information environment learn achieve arbitrary goalset large evolutionary timescale. term evolutionary change means change pre-calculated change made known ﬁtness beneﬁt. ﬁtness beneﬁt change towards knowledge environment target goalset evaluated experimenting environment change made since agent required knowledge environment idea kolmogorov complexity also strings. description complexity extends concept deﬁne complexity goalset environment assuming agent-body part environment possible agent codes possible sequences bits gives size agent code points. apart size complexity ﬁtness landscape distances i.e. hamming distances searched code point ﬁtness landscape move point higher ﬁtness value. assume ﬁtness landscape code point point higher ﬁtness value within hamming distance bits. since starting zero knowledge environment cost evaluation ﬁtness function based testing agent’s learning capability agent’s learning exercise environment. assume cost evaluation ﬁtness function grow linearly number bits agent accumulates towards right sequence bits agent moves higher ﬁtness landscape agent’s capability grows efﬁciently learn larger subsets since interested estimating fast evolutionary learning steepest ascent hill climbing algorithm estimate growth evol cost growth denote proportionality constant relates cost ﬁtness function evaluate agent efﬁciently learn goalset smallest size agent efﬁciently learn goalset agent evolves capability efﬁciently learn larger goalsets leading bits added generation number added bits grows bits generations. cost evaluation generation ×κ×r×i since agents evaluated select agent creating next generation total size accumulated bits agent evaluated generation. median cost evolution cost evaluation generation agents except ﬁnal generation count half cost. therefore evolution cost agent efﬁciently learn goalset starting zero knowledge environment grows exponentially grows square size smallest agent efﬁciently learn evaluation beforehand. also assume luck physical system limited laws probability. case agents means probability success generating large description string random guessing would exponentially diminishing increasing size description string. second principle states hypothesis below. environment goalset agent must have start goalset speciﬁc strings denoted icroconcepts class possible sets able efﬁciently learn goalset agent goalset complete required possible icroconcepts would limited inefﬁcient learning evolutionary change learn missing members icroconcepts capacity efﬁciently learn deﬁne critical agent size goalset environment integer value agents efﬁciently learn start size critical agent size. extend principle increasing complexity learning agents third principle stated below. much slower evolutionary learning compared efﬁcient learning? consider cost evolutionary learning goalset starting zero knowledge environment. deﬁned lcost cost efﬁcient learning. start size smallest agent efﬁciently learn goalset deﬁned critical agent size. start agent number differences hamming distance closest agent efﬁciently learn goalset principles learning imply learn bits evolutionary change. since start agent zero information environment critical agent size. denote evol cost median cost evolution agent efﬁciently learn goalset presented thesis capable agents larger complexity precisely smallest agents efﬁciently learn larger goalsets complex environment larger start size. proposed efﬁcient learning machine must start pre-encoded information environment icroconcepts gained evolutionary changes decide efﬁcient learning boundaries machine. machine learn beyond efﬁcient learning boundaries much slower pace using evolutionary methods. also discounts possibility would cross certain threshold development would allow system recursively create increasingly powerful systems short span time thereby creating system much larger intelligence. paper made simplifying assumptions estimating cost evolution example asexual evolution. allow possible methods lowest cost evolution agent efﬁciently learn given goalset environment starting agent zero information environment thank scott aaronson reviewing earlier draft providing valuable suggestions. would also like thank providing easy access vast amount work done ﬁeld people whose work work builds reasonable estimates values lcost critical agent size goalset estimate value assuming size smallest agent earth like environment learn years goalset average human learn years million bits. measure evaluation cost year units evaluation cost evaluating learning capability agent would years. value thus estimated using value earth like environment example estimate evol cost agent learn goalset years average human learn years following assumptions environment support billion simultaneous agents generation million bits bits example make equal number agents generation local maxima generation billion agents. evolution cost using agent start required icroconcepts goalset total start size million bits learn goalset efﬁciently years another agent starting zero environmental information start with learn goalset inefﬁciently using evolutionary methods around years using evolutionary algorithm used example possibly improved upon enough make cost comparable efﬁcient learning cost. total size useful information human genome variously estimated range million bits. size smallest algorithm learning capability average human could much different size useful information human genome. turing intelligent machinery machine intelligence meltzer michie eds. edinburgh edinburgh university press vol. national physical laboratory report", "year": 2012}