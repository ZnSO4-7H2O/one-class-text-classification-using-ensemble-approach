{"title": "Relating Input Concepts to Convolutional Neural Network Decisions", "tag": ["cs.LG", "cs.AI", "cs.CV", "I.2.10; I.4.m"], "abstract": "Many current methods to interpret convolutional neural networks (CNNs) use visualization techniques and words to highlight concepts of the input seemingly relevant to a CNN's decision. The methods hypothesize that the recognition of these concepts are instrumental in the decision a CNN reaches, but the nature of this relationship has not been well explored. To address this gap, this paper examines the quality of a concept's recognition by a CNN and the degree to which the recognitions are associated with CNN decisions. The study considers a CNN trained for scene recognition over the ADE20k dataset. It uses a novel approach to find and score the strength of minimally distributed representations of input concepts (defined by objects in scene images) across late stage feature maps. Subsequent analysis finds evidence that concept recognition impacts decision making. Strong recognition of concepts frequently-occurring in few scenes are indicative of correct decisions, but recognizing concepts common to many scenes may mislead the network.", "text": "many current methods interpret convolutional neural networks visualization techniques words highlight concepts input seemingly relevant cnn’s decision. methods hypothesize recognition concepts instrumental decision reaches nature relationship well explored. address paper examines quality concept’s recognition degree recognitions associated decisions. study considers trained scene recognition adek dataset. uses novel approach score strength minimally distributed representations input concepts across late stage feature maps. subsequent analysis ﬁnds evidence concept recognition impacts decision making. strong recognition concepts frequently-occurring scenes indicative correct decisions recognizing concepts common many scenes mislead network. cnns mainstay model classiﬁcation computer vision performance impressive cnns opaque black nature growing concern inability interpret internal actions hinder human conﬁdence trust systems practice number current efforts make cnns interpretable relates internal node activations aspects input image. aspect particular color texture pattern like processed early stage feature maps. aspects also broad patterns deﬁne objects depicted image. semantically meaningful image aspects like pointy ears paws whiskers lead human decide image observing sand water blue shells image determine image depicts beach. deﬁne semantically meaningful image aspect input concept. current research relates node activations input concepts visualization techniques. example zeiler developed idea deconvolution activations across feature maps related patterns input image. recently selvaraju developed coarse localization maps based broad pattern input image gradient model highlight associated network regions. dosovitskiy brox mahendran vedaldi hand ‘hidden’ features used inversion process up-convolutional neural networks. zhang generates task-speciﬁc attention maps input image excitation backprop. aforementioned techniques provide nice viewpoints internal activations related qualities input research whether input concepts recognized associated decisions made cnn. zintgraf bach montavon developed ways measure every input pixel supports cnn’s classiﬁcation result conditional multivariate model layer-wise relevance backpropagation method deep taylor decomposition respectively. however methods focus pixel-level explanation remains unclear groups pixels representing input concept highlighted resulting visualizations impact decisions. paper investigate relationship well recognizes input concepts image decisions makes. speciﬁcally consider input concepts decisions scene recognition task adek dataset study powered novel algorithm compute well concept recognized across feature maps convolutional layer. analysis along concept types including appear often within scene often across multiple scenes unique scene reveal weak relationship correct decision making concept recognition. relationship dampened recognition ‘sparse’ concepts seldom appear images scene ‘misleading’ concepts appear often across images many different scenes. however recognition concepts unique images speciﬁc scenes promote correct decisions. studying relationship input concepts decisions requires measure well concepts recognized cnn. deﬁne concept ‘recognized’ late stage convolutional layer nodes activate input concept’s presence. whereas much research assumes nodes must within feature assert concept recognition could occur distributed across many feature maps convolutional layer. past studies suggested demonstrated neural networks learn representation input features distributed fashion thus consider possibility input concepts recognized within single feature map. context scene classiﬁcation recognition concept would manifested nodes collectively respond input pixels representing concept. nodes good recognizer concept collectively respond pixels representing concept pixels representing concept. call node activated takes non-zero value sigmoid tanh non-linearity relu non-linearity. deconvolution feature recovers pixels input image causing nodes activate deconvolutions thus seem like natural identify input concepts scenes represented feature deconvolution feature covers pixels concept consider ‘recognized’ feature map. however patterns activating nodes feature always consistent image image. illustrate point figure feature taken last convolutional layer alexnet trained object recognition deconvolution computed different input images. deconvolution ﬁrst image suggests feature recognizes facial features texture cat’s fur. deconvolution second image however recognizes nothing unclear concept third image recognized feature map. recent approaches concept recognition limited number feature maps consistently recognize speciﬁc concept instead focusing concept recognitions localized single feature figure summarizes approach evaluate concepts recognized across multiple feature maps convolutional layer. given binary segmentation mask concept deconvolutions feature maps latest stage convolutional layer greedy algorithm selects subset feature maps collectively best\" recognize given concept according scoring function. selected feature maps recognition quality score returned user. speciﬁcs recognition scoring greedy algorithm discussed next. ideally pixel area given concept covered deconvolutions selected feature maps precisely possible. score thus consider combined coverage deconvolutions chosen feature maps pixels concept. based idea evaluate well feature maps recognizes concept image using binary segmentation mask denotes pixel positions assume available dataset generated object segmentation methods deconvolutions {di} respect combined dsum representing node activations across concept recognition score deﬁned jaccard like similarity measure similar devise greedy algorithm identify best recognizes listed algorithm intuition behind greedy approach feature maps recognizes well small possible composed feature maps minimally ‘overlap’ e.g. recognizes parts qualities concept. latter criteria capture idea good distributed representation nodes feature activate different signiﬁcant parts concept. thus greedy iteration algorithm searches feature whose addition would yield largest improvement recognition score large improvements would possible newly added feature activates pixels representing feature activates over. moreover feature cannot signiﬁcant activations pixels represent without reducing greedy iterations continue feature whose inclusion would yield improvement score greater used experiments below. algorithm recognize concept given input image study relationship recognition quality cnn’s scene classiﬁcation accuracy. consider alexnet model trained places scene dataset tune network weights using adek consider subset scenes adek least example images. choose subset ensure sufﬁcient number examples available training able take representative measurements cnn’s ability classifying scene correctly. scenes adek least example images listed table images class randomly sampled training data tuning testing. ﬁne-tuned achieves top- classiﬁcation accuracy testing images training epochs higher performance scene classiﬁers note test scenes abundance images adek’s training data. randomly choose images class compute well concepts recognized feature maps last convolutional layer cnn. sample images feature distinct concepts. sense whether recognition score relatively low\" high\" plot score distribution across concepts sampled images figure note mean recognition score median lower upper quartiles respectively. figure illustrates output algorithm sampled bedroom scene. eight concepts annotated image binary segmentation mask label visualization deconvolutions chosen greedy algorithm recognition score presented. highest quality recognition concept score well upper quartile recognition score distribution across concepts summed deconvolution captures texture information shape patterning frame activates pixels represent concept. chair concept lower recognition score happens close median concept recognition score distribution. case selected feature maps able recognize parts chair including legs back also happens activate straight line texture patterns wall ﬂoor surrounding chair. stairs concept lowest score caused feature maps’ inability activate pixels concept also activate across pixels representing nearby concepts explore relationship concept recognition performance. scene sampled images compare average recognition score concepts within scene’s images cnn’s average classiﬁcation accuracy scene. figure shows weak linear relationship although interesting observations scenes. scenes best classiﬁcation recognition scores skyscraper mountain_snowy scenes whose images include concepts especially emblematic. example mountain concept captured well across mountain_snowy scenes concepts like skyscraper building identiﬁed well skyscraper scenes airport_terminal challenging scene identify despite achieving high average concept recognition. strong recognitions concepts like floor ceiling appear least sampled airport_terminal images concepts generic could apply kind indoor scene. concepts better capturing notion airport terminal also recognized e.g. armchair shops sparse concepts appear often enough training learn recognize well relate particular scene. example able recognize armchair shops concepts airport_terminal well infrequency could mean enough observations establish relationship concepts scene label. figure explores prevalence concepts well recognized across scene classes. illustrates that every class majority concepts emerge less images sampled scene. scenes relatively uniform look instance skyscraper mountain_snowy street scene fewer sparse concepts. moreover scenes tend non-sparse concepts recognized strongly scenes non-uniform could look like example bedroom hotel_room dining_room images depict different styles design tend exhibit larger number sparse concepts. sparse concepts high recognition scores suggesting learns recognize them. sparse concept could observed across large number different scenes. example although every bedroom chair imagine chair appear across variety different scenes giving enough examples learn recognize concept. ﬁgure discussion suggest following hypothesis fewer number sparse concepts present greater number well recognized non-sparse concepts appear across images scene higher chance correctly identify scene. moreover scenes whose images dominated variety sparse concepts prove challenging classify. test this plot slope linear scatter plot figure cnn’s accuracy scene figure moderate linear relationship suggests many non-sparse well recognized concepts associated correct decisions lending support hypothesis. investigate non-sparse concepts further. intuitively non-sparse concepts greater beneﬁt correct decisions appear across smaller number different types scenes. example concepts like sand shell present many beach scenes closely associated notion beach unlikely appear types scenes. thus high quality recognition sand shell concepts would help classify beach scenes correctly. hand non-sparse concepts emerging across variety scenes less helpful. example since expect images indoor scenes include concepts like wall floor ceiling recognition help differentiate different indoor scenes. fact recognitions limited help best case could confuse mislead make wrong classiﬁcation worst case. explore ideas compute uniqueness score concept reﬂects variety scenes appears uniqueness concept calculated figure gives distribution uniqueness scores concept. skewed average uniqueness score lower quartile median upper quartile respectively. concepts appear scene class although many concepts likely sparse. following fact many scenes used analysis indoors concepts least unique scores pertain generic aspects room. example concepts three lowest uniqueness scores hypothesize recognition unique concepts helps make correct classiﬁcations concepts uniqueness scores ‘mislead’ cnn. evaluate hypothesis comparing cnn’s classiﬁcation accuracy average recognition score calculated unique\" concepts misleading concepts respectively. concept labeled unique\" uniqueness score uniqueness threshold however recall figure number unique concepts likely ‘sparse’ thus hindering classiﬁcation accuracy thus ﬁlter away sparse concepts deﬁning popularity score respect scene images appears scene class images sampled scene class consider concepts whose popularity threshold compute pearson’s correlation coefﬁcient cnn’s accuracy scene class average recognition score unique misleading concepts respectively various values figure presents grid thresholds varying values increments left heatmap shows unique concepts considered. area shows positive relationship unique concepts recognition quality accuracy. larger uniqueness popularity thresholds making unique concepts even smaller lead even stronger relationship. note concept causing empty cells right columns. middle heatmap considers misleading concepts. shaded blue areas indicate negative relationship misleading concepts recognition quality model performance. valid settings exists moderate strong negative correlation. provides evidence recognition misleading concepts e.g. concepts appearing across many different scene types hindering cnn’s ability classify scenes correctly. right heatmap reports using synthesized average concept recognition score deﬁned scene class ssyn sunique average concept recognition score unique concepts smislead misleading concepts. synthetic score uniﬁes results unique misleading heatmaps together search threshold settings maximize unique concepts minimize misleading concepts. highest positive correlation using synthetic scores thresholds unique concepts misleading concepts. p-values correlation scores computed classes indicate signiﬁcant negative correlation misleading concept recognition cnn’s accuracy moderate positive correlation unique concept recognition cnn’s accuracy. paper investigated relationship cnn’s recognition input concepts classiﬁcation accuracy. novel approach developed quantify well concept recognized across latest convolutional layer cnn. analysis using image object annotations adek scene dataset revealed weak relationship average recognition image concepts scene classiﬁcation accuracy. found evidence suggest relationship hindered recognized concepts sparse appear small number images scene misleading concepts appear many images across many different scenes. recognizing unique concepts appear often limited scenes moderately positively correlated cnn’s classiﬁcation accuracy. future work analyze feature maps necessary accurately model object scene. effects unique misleading sparse concepts explored detail. particular investigate common misclassiﬁcations scene seek explanations recognized concepts common them. study effect sparse concepts classiﬁcation occlusion image. also explore mechanics concept recognitions impact downstream network activations leading decision devise measure importance concept recognition decision making. references bach binder montavon klauschen müller k.-r. samek pixel-wise explanations non-linear classiﬁer decisions layer-wise relevance propagation. plos chen l.-c. papandreou kokkinos murphy yuille deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs. arxiv preprint arxiv.. girshick donahue darrell malik rich feature hierarchies accurate object detection semantic segmentation. proc. ieee conference computer vision pattern recognition pages", "year": 2017}