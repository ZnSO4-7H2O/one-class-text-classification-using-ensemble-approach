{"title": "A Novel Rough Set Reduct Algorithm for Medical Domain Based on Bee  Colony Optimization", "tag": ["cs.LG", "cs.AI", "cs.NE"], "abstract": "Feature selection refers to the problem of selecting relevant features which produce the most predictive outcome. In particular, feature selection task is involved in datasets containing huge number of features. Rough set theory has been one of the most successful methods used for feature selection. However, this method is still not able to find optimal subsets. This paper proposes a new feature selection method based on Rough set theory hybrid with Bee Colony Optimization (BCO) in an attempt to combat this. This proposed work is applied in the medical domain to find the minimal reducts and experimentally compared with the Quick Reduct, Entropy Based Reduct, and other hybrid Rough Set methods such as Genetic Algorithm (GA), Ant Colony Optimization (ACO) and Particle Swarm Optimization (PSO).", "text": "abstract— feature selection refers problem selecting relevant features produce predictive outcome. particular feature selection task involved datasets containing huge number features. rough theory successful methods used feature selection. however method still able find optimal subsets. paper proposes feature selection method based rough theory hybrid colony optimization attempt combat this. proposed work applied medical domain find minimal reducts experimentally compared quick reduct entropy based reduct hybrid rough methods genetic algorithm colony optimization particle swarm optimization introduction main goal feature selection find minimal feature subset problem domain high accuracy representing original features real world problems feature selection important process must abundance noisy irrelevant misleading features. extensive method used purpose quite impractical datasets. usually feature selection algorithms involve heuristic random search strategies attempt avoid prohibitive complexity. however degree optimality final feature subset often reduced. rough theory provides mathematical tool used feature selection knowledge discovery. helps find minimal attribute sets called ‘reducts’ classify objects without deterioration classification quality. idea reducts encouraged many researchers studying effectiveness rough theory number real world domains including medicine pharmacology control systems fault-diagnosis text categorization social sciences switching circuits economic/financial prediction image processing however possible theory whether attribute values similar extent same; example close values differ result noise standard rst-based approach considered different values different order magnitude. dataset discretization must take place reduction methods based crisp rough sets applied. often still inadequate. however degrees membership values discretised values considered all. solve problem number variations theory proposed. among methods swarm intelligence based methods perform better rest methods. assistant professor computer science engg. akshaya college engineering technology coimbatore tamil nadu india. director akshaya college engineering technology coimbatore tamil nadu india. swarm intelligence property system whereby collective behaviours simple agents interacting locally environment cause coherent functional global patterns emerge provides basis possible explore collective problem solving without centralized control provision global model. techniques colony optimization particle swarm optimization hybridized rough theory improve performance. major limitations methods parameter values random. performance reduct varies based parameter settings. also parameters changed based applications. paper proposed novel hybridization rough theory colony optimization require random parameters. thus provides consistent performance application specific. rest paper structured follows. section discusses fundamentals rough theory particular focusing dimensionality reduction; rough based attribute reduction entropy-based reduction genetic algorithm based feature selection methods. section presents hybrid methods rough theory colony optimization particle swarm optimization section introduces main concepts colony optimization framework used rough based feature selection. section details experimentation carried presents discovered results. paper concludes discussion observations highlights scope future work area. rough theory rough theory extension conventional theory supports approximations decision making. rough attribute reduction provides filterbased tool knowledge extracted domain concise way; retaining information content whilst reducing amount knowledge involved. central rsar concept indiscernibility. journal computing volume issue june issn https//sites.google.com/site/journalofcomputing/ www.journalofcomputing.org information system non-empty finite objects non-empty finite attributes every associated equivalence relation positive region contains objects classified classes using knowledge attributes important issue data analysis discovering dependencies attributes. intuitively attributes depends totally attributes denoted attribute values uniquely determined values attributes exists functional dependency values depends totally dependency defined following depends totally depends partially depend based fundamental discussed important reduction methods quickreduct entropy-based method. quickreduct reduction attributes achieved comparing equivalence relations generated sets attributes. attributes removed reduced provides quality classification original. reduct defined subset conditional attribute given dataset many attribute reduct sets reducts defined intersection sets called core elements attributes cannot eliminated without introducing contradictions dataset. rsar reduct minimum cardinality searched for; words attempt made locate single element minimal reduct rmin rmin basic solution locating reduct simply generate possible reducts choose minimal cardinality. obviously expensive solution problem practical simple datasets. time minimal reduct required calculations involved discovering rest pointless. improve performance method element pruning introduced. noting cardinality prediscovered reducts current possible reduct ignored contains elements. however better approach needed avoid wasted computational effort. quickreduct algorithm given figure attempts calculate minimal reduct without exhaustively generating possible subsets. starts empty adds turn time attributes result greatest increase dependency produces maximum possible value dataset. quickreduct conditional features; decision features. note intuitive understanding quickreduct implies that dimensionality evaluations dependency function performed worstcase dataset. according quickreduct algorithm dependency attribute calculated best candidate chosen. next best feature added dependency reduct candidate equals consistency dataset process however guaranteed find minimal reduct. using dependency function discriminate candidates lead search non-minimal path. impossible predict combinations attributes lead optimal reduct based changes dependency addition deletion single attributes. result close-to-minimal reduct though still useful greatly reducing dataset dimensionality. entropy based feature reduction another technique discovering rough reducts entropy-based reduction developed work carried based entropy heuristic employed machine learning techniques motivation behind approach observation rough dependency measure maximized given subset entropy minimized. consistent datasets resulting entropy dependency degree concerned examining dataset determining attributes provide gain information. entropy attribute respect conclusion defined colony based reduct ability real ants find shortest routes mainly depositing pheromone travel; probabilistically prefers follow direction rich chemical. feature selection task reformulated acosuitable problem. requires problem represented graph; nodes represent features edges denoting choice next feature search optimal feature subset traversal graph minimum number nodes visited satisfies traversal stopping criterion. heuristic desirability traversal edge pheromone levels combined form so-called probabilistic transition rule denoting probability feature choosing travel feature time unvisited number ants features heuristic desirability choosing feature feature amount virtual pheromone edge choice determined experimentally. overall process feature selection begins generating number ants placed randomly graph alternatively number ants place graph equal number features within data; starts path construction different feature. initial positions traverse edges probabilistically traversal stopping criterion satisfied. resulting subsets gathered evaluated. optimal subset found algorithm executed certain number times process halts outputs best feature subset encountered. neither condition holds pheromone updated ants created process iterates more. tailor mechanism find rough reducts necessary dependency measure stopping criterion. means stop building feature subset dependency subset reaches maximum dataset dependency function also chosen heuristic desirability measure necessary. particle swarm based reduct given decision table condition attributes consists attributes. search space defined dimensions reduction problem. accordingly particle’s position represented binary string length dimension particle’s position maps condition attribute. domain dimension limited value means corresponding attribute selected means selected. position decoded potential reduction solution subset particle’s position series priority levels attributes. sequence attribute changed iteration. updating velocity position particles particle's position appear real values etc. meaningless reduction. therefore introduce discrete particle swarm optimization combinatorial problem search procedure individual evaluated using fitness. according definition rough reduct reduction solution must ensure decision ability primary decision table extended dealing sets attributes instead individual attributes only. using entropy measure algorithm used rsar modified shown figure upon iteration subset lowest resulting entropy chosen. algorithm requires thresholds order function search best feature subset stopped resulting subset entropy equal entropy full conditional attributes. however entropy measure costly operation dependency evaluation important factor processing large datasets. conditional features; figure entropy-based reduct algorithm genetic based reduct genetic algorithms generally quite effective rapid search large nonlinear poorly understood spaces unlike classical feature selection strategies solution optimized population solutions modified time result several optimal feature subsets output. feature subset typically represented binary string length equal number features present dataset. zero position chromosome denotes absence presence feature particular subset. initial population chromosomes created; size population created important issues. pool feature subsets typical genetic operators applied. again choice types crossover mutation used must carefully considered well probabilities application. generates feature subset pool evaluated different ways. filter approach adopted fitness individuals calculated using suitable criterion function. function evaluates goodness feature subset; larger value indicates better subset. initial population consists randomly generated feature subsets probability mutation crossover respectively number generations fitness function defined follows swarm intelligence based reduct algorithms section discussed different swarm intelligence based reduct algorithms antrsar psorsar hybrid rough theory. artificial colony algorithm proposed karaboga real parameter optimization recently introduced optimization algorithm simulates foraging behaviour colony unconstrained optimization problems solving constrained optimization problems constraint handling method incorporated algorithm.in real colony tasks performed specialized individuals. specialized bees maximize nectar amount stored hive performing efficient division labour self-organization. minimal model swarm-intelligent forage selection honey colony algorithm adopts consists three kinds bees employed bees onlooker bees scout bees. half colony comprises employed bees half includes onlooker bees. employed bees responsible exploiting nectar sources explored giving information waiting bees hive quality food source site exploiting. onlooker bees wait hive decide food source exploit depending information shared employed bees. scouts randomly search environment order find food source depending internal motivation possible external clues randomly. main steps algorithm simulating behaviours given figure initialize food source positions. employed produces food source food journal computing volume issue june issn https//sites.google.com/site/journalofcomputing/ www.journalofcomputing.org number attributes feasible solution kept possible. algorithm first evaluate whether potential reduction solution satisfies pose upos feasible solution calculate number solution lowest number selected. particle swarm lesser number position better fitness individual. pose upos used criterion solution validity.as summary particle swarm model consists swarm particles initialized population random candidate solutions. move iteratively d-dimension problem space search solutions fitness measured calculating number condition attributes potential reduction solution. particle position represented position-vector velocity represented velocity-vector particle remembers best position vector j-th dimensional value bpij best position-vector among swarm stored vector j-th dimensional value gpj. particle moves state space restricted zero dimension change probability time steps defined follows bpij gpj) probability function positive constant called coefficient self-recognition component positive constant called coefficient social component. random numbers interval variable called inertia factor whose value typically setup vary linearly near iterated processing. random number closed interval step particle decides move next considering current state experience memory best past position experience successful particle swarm. main limitations genetic swarm intelligence methods deal parameters random changes made values affect total performance parameters well tuned deduct better reduct parameter values adjusted based dataset combat this used artificial colony algorithm require random parameters find optimum reduct discussed following section. colony based reduct nature inspiring researchers develop models solving problems. optimization field models frequently developed applied. genetic algorithm simulating natural selection genetic operators particle swarm optimization algorithm simulating flock birds school fishes artificial immune system simulating cell masses immune system algorithm simulating foraging behaviour ants artificial colony algorithm simulating foraging behaviour honeybees typical exprocedure implemented feature reduction. bees select feature subsets random calculate fitness find best iteration. procedure repeated number iterations find optimal subset.in first step algorithm employed bees produce feature subset random. consider conditional feature containing features. number bees chosen population size. population half bees considered employed bees remaining considered onlooker bees. employed random numbers generated assigned. random numbers feature subset constructed performing round operation extracting unique numbers set. example consider random numbers first perform round operation modified result unique numbers alone extracted represent feature subset. features alone chosen. second step algorithm employed whose total number equals half number food sources source produced uniformly distributed real random number within range index solution chosen randomly colony journal computing volume issue june issn https//sites.google.com/site/journalofcomputing/ www.journalofcomputing.org dimension problem. producing solution compared xith solution employed exploits better source. third step algorithm onlooker chooses food source higher probability produces source selected food source site. employed better source decided exploited. indiscernibility relation calculated feature subset objective value value maximized. objective value fitness value calculated given following equation table shows reduct results various methods different medical datasets. shows size reduct found method. quickreduct methods produced reduct every time unlike genrsar antrsar psorsar beersar found different reducts sometimes different reduct cardinalities. whole appears case beersar outperforms methods. compared methods beersar consumes time find reduct. conclusion feature selection important research direction rough application. however technique often fails find better reducts. paper starts fundamental concepts rough theory explains basic techniques quickreduct entropy-based reduct. methods produce close minimal reduct optimal. swarm intelligence methods used guide method find minimal reducts. discussed three different computational intelligence based reducts genrsar antrsar pso-rsar. though methods performing well consistency since dealing random parameters. paper proposed colony optimization algorithm hybrid rough theory find minimal reducts. method require random parameter assumption. methods analyzed using medical datasets. shown results proposed method exhibits consistent better performance methods. employed beersar approach datasets numerical attributes. future approach extended categorical attributes also handle missing values. iti fitness solution onlookers distributed sources sources checked whether abandoned. number cycles source improved greater predetermined limit source considered exhausted. employed associated exhausted source becomes scout makes random search problem domain following equation. roughbee conditional features; decision features. select initial parameter values initialize population calculate objective fitness value find optimum feature subset global. produce feature subset apply greedy selection calculate fitness probability values produce solutions onlookers apply greedy selection onlookers determine abandoned solution scouts calculate cycle best feature subset memorize best optimum feature subset maximum number cycles experiments results performance reduct calculation approaches discussed paper tested different medical datasets obtained machine learning data repositolars area power system engineering power electronics computer networks. principal in-charge dean government college engineering bargur. served senate member periyar university salem. served member research board anna university chennai. served member academic council anna university chennai. serving member board studies electrical engineering anna university chennai. serving member board studies electrical electronics electronics communication engineering amritha viswa vidya peetham deemed university coimbatore. serving governing council member sacs mavmm engineering college madurai. served professor head departments government college technology coimbatore. serving syndicate member anna university coimbatore. currently director akshaya college engineering technology coimbatore. alpigini j.j. peters j.f. skowronek zhong ‘rough sets current trends computing’ third international conference rsctc malvern usa. bonabeau dorigo theraulez swarm intelligence natural artificial systems oxford university press inc. york usa. chouchoulas shen ‘rough set-aided keyword reduction text categorization’ applied artificial intelligence vol. dash ‘feature selection classification’ intelligent data analysis vol. holland adaptation natural artificial systems university michigan press arbour. jensen shen rough set-aided system sorting bookmarks’ zhong intelligence research development jensen shen ‘finding rough reducts colony optimization’ proceedings workshop computational intelligence kudo skalansky ‘comparison algorithms select features pattern classifiers’ pattern recognition vol. karaboga idea based honey swarm numerical optimization’ technical report erciyes university engineering faculty computer engineering department. karaboga basturk artificial colony algorithm numeric function optimization’ ieee swarm intelligence symposium indiana usa. karaboga basturk powerful efficient algorithm numerical function optimization artificial colony algorithm’ journal global optimization vol. karaboga basturk ‘artificial colony optimization algorithm solving constrained optimization problems’ foundations fuzzy logic soft computing’ lncs springer-verlag vol. karaboga basturk performance artificial colony algorithm’ applied soft computing vol. abraham ‘nature inspired population-based heuristics rough reduction’ rough theory springer-verlag vol. pawlak ‘rough sets’ international journal computer information sciences vol. pawlak rough sets theoretical aspects reasoning data kluwer academic publishers. pawlak ‘rough sets present state future’ foundations computing decision sciences vol. pawlak ‘rough sets intelligent data analysis’ information sciences vol. quinlan j.r. programs machine learning morgan kaufmann series machine learning. morgan kaufmann publishers mateo .suguna received degree computer science engineering madurai kamaraj university m.e. degree computer science engineering bangalore university decade teaching experience various engineering colleges tamil nadu karnataka. currently akshaya college engineering technology coimbatore tamilnadu india. research interests include data mining soft computing object oriented systems. r.k.thanushkodi years teaching experience various government private engineering colleges. published papers international journals conferences. currently guiding research scho-", "year": 2010}