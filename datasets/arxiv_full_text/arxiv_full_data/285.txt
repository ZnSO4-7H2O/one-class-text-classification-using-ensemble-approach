{"title": "Mean Box Pooling: A Rich Image Representation and Output Embedding for  the Visual Madlibs Task", "tag": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "abstract": "We present Mean Box Pooling, a novel visual representation that pools over CNN representations of a large number, highly overlapping object proposals. We show that such representation together with nCCA, a successful multimodal embedding technique, achieves state-of-the-art performance on the Visual Madlibs task. Moreover, inspired by the nCCA's objective function, we extend classical CNN+LSTM approach to train the network by directly maximizing the similarity between the internal representation of the deep learning architecture and candidate answers. Again, such approach achieves a significant improvement over the prior work that also uses CNN+LSTM approach on Visual Madlibs.", "text": "present mean pooling novel visual representation pools representations large number highly overlapping object proposals. show representation together ncca successful multimodal embedding technique achieves state-of-the-art performance visual madlibs task. moreover inspired ncca’s objective function extend classical cnn+lstm approach train network directly maximizing similarity internal representation deep learning architecture candidate answers. again approach achieves signiﬁcant improvement prior work also uses cnn+lstm approach visual madlibs. question answering real-world images relatively research thread requires chain machine visual perception natural language understanding deductive capabilities successfully come answer question visual content. although similar nature image description requires focused attention details visual content easier evaluate different architectures task. moreover contrast many classical computer vision problems recognition detection task evaluate internal representation methods requires holistic understanding image. arguably also less prone over-interpretations compared classical turing test foster progress task metrics datasets proposed recently introduced visual madlibs task removes ambiguities question scene interpretations introducing multiple choice ﬁlling blank task machine complete prompted sentence. completed sentence next matched four ground truth answers. thanks problem formulation traditional accuracy measure used monitor progress task. unambiguous evaluation work focuses task. contributions. present main contributions. mean pooling argue rich image representation form pooled representations objects. although related ideas explored visual question answering even used visual madlibs ﬁrst show signiﬁcant improvement representation using object proposals. precisely argue approach pools large number highly overlapping object proposals. this arguably increases recall extracting bounding boxes describe object also allows multi-scale multi-parts object representation. approach combination normalized correlation analysis embedding technique improves state-of-the-art visual madlibs task. text-embedding loss motivated popularity deep architectures visual question answering combine global image representation lstm question representation well leading performance ncca multi-choice visual madlibs task propose novel extension cnn+lstm architecture chooses prompt completion four candidates measuring similarities directly embedding space. contrasts prior approach uses post-hoc comparison discrete output cnn+lstm method four candidates. achieve this directly train lstm cosine similarity loss output embedding network language representation ground truth completion. approach integrates tightly multi-choice ﬁlling blanks task signiﬁcantly outperforms prior cnn+lstm method question answering images relatively task switches focus recognizing objects scene holistic image understanding. ﬁrst work topic considered real world indoor scenes associated natural language questions answers. since different variants larger datasets proposed fm-iqa coco-qa although answering questions images arguably susceptible automatic evaluation image description task ambiguities output space still remain. ambiguities handled using appropriate metrics visual madlibs taken another direction handles directly within task. asks machines blank prompted natural language description phrase chosen four candidate completions general phrase together prompted sentence serve accurate description image. problem formulation standard accuracy measure sufﬁcient automatically evaluate architectures. ﬁrst proposed architecture deal question answering images task uses image analysis methods hand-deﬁned schemas create database visual facts. mapping questions executable symbolic representations done semantic parser later deep learning approaches question answering either generate answers predict answers ﬁxed choices. recently attention based architectures weights ﬁxed grid figure overview full model i.e. proposed image representation using mean pooling text encoding using average wordvec representations normalized learning joint space. image yield state results another focused hard attention also studied image-to-text retrieval scenario well ﬁne-grained categorization person recognition zero-shot learning representations computed objects visual fragments parts aggregated form visual representation. closer work edge boxes form memories consisting different image fragments either pooled softmax weighted order provide ﬁnal score. however contrast experiments indicate strong improvement using object proposals. majority recent work visual question answering combine lstm concatenation summation piece-wise multiplication canonical correlation analysis also shown effective multimodal embedding technique work investigates embedding method well brings ideas cnn+lstm formulation. normalized embed textual embedding answers visual representation image joint space candidate sentence completions compared image. furthermore also extend popular community cnn+lstm approach learning compare answer space. section propose richer representation entire image obtained pooling representations extracted object proposals. figure illustrates proposed mean pooling image representation figure illustrates whole method. section describe ncca approach encode modalities joint space greater details. section also investigate cnn+lstm architecture. instead generating prompt completion next compared candidate completions post-hoc process propose choose candidate completion directly comparing candidates embedding space. puts cnn+lstm approach closer ncca tighter integration multi-choice visual madlibs task. approach depicted figure figure cnn+lstm architecture learns choose right answer directly embedding space. output embedding jointly trained whole architecture backpropagation. mean pooling image representation figure illustrates proposed image representation starts extracting object proposals image. next object proposals encoded pooled order create feature vector representation image. extracting region proposals. since questions mainly salient parts image seems reasonable object detection order extract parts image. time however important miss object image. moreover arguably sampling context objects capturing multi-scale multi-parts properties seem important well. given reasons choose edge boxes order generate object bounding proposals feature extraction. edge boxes extract number bounding boxes along score bounding interpreted conﬁdence score bounding contains object. study hyper parameters important non-maxima suppression number proposals. latter deﬁnes many object proposals want maintain hence implicitly inﬂuence recall proposals former deﬁnes threshold predicted bounding boxes intersection union greater removed. practice lower spread object proposals are. feature extraction. object proposals extracted output layer network extracted image crops encode proposals. among best performing recognition architectures large scale object recognition task pooling image representation. ﬁnal image representation constructed pooling encoded object proposals together global image representation. since want associate particular order extracted object proposals investigate popular order-less pooling schemes. pooling answer representation. encode word answer dimensional word embedding embedded words next mean pooled form vector representation answer. note that encode prompts follow pattern visual madlibs category. multimodal embedding normalized canonical correlation analysis learn mapping modalities image textual answers joint embedding space. embedding method shown outstanding performance visual madlibs task test time given encoded image choose answer four candidate answers similar encoded image multimodal embedding space. formally canonical correlation analysis maximizes cosine similarity modalities embedding space matrix trace views normalized canonical correlation analysis reported work signiﬁcantly better plain cca. here columns projection matrices scaled p-th power corresponding eigen values. improvement consistent ﬁndings ncca performs better percentage points average hard task. cnn+lstm text-embedding loss present novel architecture extends prior approaches question answering images learning similarity candidate labels internal output embedding neural network. figure depicts architecture. similarly prior work encode image encoder next concatenated word embeddings prompt sentence recurrent neural network. special ‘<blank>’ token denote empty blank space image description. side completion candidate compute representation averaging wordvec representations words contributing however contrast prior work instead comparing discrete output network representation directly optimize objective embedding space. training maximize similarity measure output embedding representation optimizing following objective evaluate method multiple choice task visual madlibs dataset. dataset consists descriptions spanning different categories speciﬁed different types templates images. selected images coco dataset comes rich annotations. multi-choice scenario textual prompt given blank ﬁlled together candidate completions every category represents different type question including scenes affordances emotions activities since category ﬁxed prompt need include prompt modeling given training done category. finally visual madlibs considers easy difﬁcult tasks differ negative candidate completions chosen. easy task distractors randomly chosen three descriptions question type images. hard task distractors chosen images contain objects given question image hence requires careful detailed image understanding. adam gradient descent method default hyper-parameters. different maxima suppression thresholds. table shows accuracy model mean edge-box pooling different maxima suppression thresholds experiments object proposals observed saturation higher numbers. table tasks easy hard higher thresholds preferred. precisely threshold outperforms average percentage points easy task percentage points hard task. also experimented pooling mean pooling performed percentage points better average experiments. experiments counterintuitively suggest many selected bounding boxes high overlap still beneﬁcial achieving better performance. experiments mean pooling threshold easy task hard task image’s scenes image’s emotion image’s past image’s future image’s interesting object’s attribute object’s affordance object’s position person’s attribute person’s activity person’s location pair’s relationship average table accuracies computed different maxima suppression thresholds easy hard tasks visual madlibs dataset. mean pooling object proposals used experiments. results table accuracies computed different number edge proposals easy hard tasks visual madlibs dataset. threshold mean-pooling used experiments. results different number object proposals. maximal number object proposals second factor edge boxes study work. larger number proposals tend cover larger fraction input image. moreover higher number together higher threshold assign proposals object parts effectively forming multi-scale multi-parts object representation. table shows accuracy model different number edge proposals. experiments suggest using larger numbers proposals however gain diminishes larger numbers. comparison state-of-the-art. guided results previous experiments compare ncca uses edge boxes object proposals state-ofthe-arts visual madlibs models convolutional neural network encode images wordvec encode words. models trained category table shows using large number object proposals table accuracies computed different approaches easy hard tasks. ncca uses representation object proposals ncca uses whole image representation. results table accuracies computed different approaches easy hard task. ncca uses representation object proposals ncca mean-pools representations computed available ground-truth bounding boxes train test time. averages computed categories. results improves global full frame ncca percentage points easy task percentage points difﬁcult task average. however ncca also consistently outperforms state-of-the-art every category except ‘scenes’ category. suggests better localized object oriented representation beneﬁcial. however edge boxes roughly localize objects. naturally leads following question better localization helps. limits compare ncca ncca crops ground truth bounding boxes coco segmentations next averages representations shows ground truth bounding boxes outperforms automatically detected bounding boxes hence seen upper bound detection method trained detect objects coco). surprisingly ncca outperforms ncca large margin table shows. arguably object proposals better recall captures multi-scale multi-parts phenomena. cnn+lstm comparison output embedding space. hand ncca tops leaderboard visual madlibs task hand largest body work question answering images combines lstm hypothesize that likewise ncca order choose table comparison embedded cnn+lstm approach computes similarity input candidate answers embedding space plain cnn+lstm original approach since accuracies cnn+lstm unavailable categories report average categories case. results completion prompt sentence four candidates comparison candidate completions directly done output embedding space. contrasts post-hoc process used image description architecture ﬁrst generates completion next compared candidates wordvec space moreover since neurons architecture suitable question answering task extend method comparisons directly embedding space note that feed sentence prompt lstm even though ﬁxed category. table shows performance different methods. embedded cnn+lstm outperforms methods tasks conﬁrming hypothesis. neurons also slightly better original cnn+lstm study image representation formed averaging representations object proposals show effectiveness experimental evaluation visual madlibs dataset achieve state performance multi-choice ﬁlling blank task. also shown discussed effects different parameters affect proposals obtained. surprisingly larger number proposals better overall performance. moreover model beneﬁts even highly overlapping proposals. model even outperforms prior work uses ground truth bounding boxes coco dataset. proposed representation considered valid alternative ‘soft’ attention representations implemented recent work visual question answering using memory networks popularity question answering images tasks also investigate cnn+lstm approach chooses prompt completion candidate comparisons directly embedding space. approach contrasts posthoc solution previous work allowing tighter integration model", "year": 2016}