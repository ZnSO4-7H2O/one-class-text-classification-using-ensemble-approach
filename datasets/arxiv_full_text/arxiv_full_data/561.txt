{"title": "A Deep Learning Approach to Data-driven Parameterizations for  Statistical Parametric Speech Synthesis", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "Nearly all Statistical Parametric Speech Synthesizers today use Mel Cepstral coefficients as the vocal tract parameterization of the speech signal. Mel Cepstral coefficients were never intended to work in a parametric speech synthesis framework, but as yet, there has been little success in creating a better parameterization that is more suited to synthesis. In this paper, we use deep learning algorithms to investigate a data-driven parameterization technique that is designed for the specific requirements of synthesis. We create an invertible, low-dimensional, noise-robust encoding of the Mel Log Spectrum by training a tapered Stacked Denoising Autoencoder (SDA). This SDA is then unwrapped and used as the initialization for a Multi-Layer Perceptron (MLP). The MLP is fine-tuned by training it to reconstruct the input at the output layer. This MLP is then split down the middle to form encoding and decoding networks. These networks produce a parameterization of the Mel Log Spectrum that is intended to better fulfill the requirements of synthesis. Results are reported for experiments conducted using this resulting parameterization with the ClusterGen speech synthesizer.", "text": "even parameterization technique invented could comply three four requirements technique would useless least partially satisfy remaining one. therein lies difﬁculty inventing parameterization. cepstral coefﬁcients satisfy requirements reasonable extent. however representation perfect places major bottleneck naturalness modern parametric speech synthesizers. techniques rectify problems occur representation cepstral representation still leaves plenty room improvement. neural networks existed many years training algorithms used incapable effectively training networks large number hidden layers. standard technique used training neural network backpropagation algorithm. algorithm works propagating errors made neural network output layer back hidden layers adjusting weights hidden layers using gradient descent techniques minimize error. network deep propagated error ﬁrst hidden layers becomes small. result parameters ﬁrst layers change little training. strategy developed recent years start training neural network pair layers time building next pair previous ones. step called pretraining weights obtained process used initialization backpropagation algorithm. pretraining techniques believed provide initialization much closer global optimum compared random initializations originally used. search technique create purely data-driven parameterization stacked denoising autoencoder developed pretraining deep neural networks. trained manner less identical layer-wise pretraining procedure described name suggests stacked denoising autoencoder constructed stacking several denoising autoencoders together form deep neural network. denoising autoencoder neural network trained reconstructs correct input sequence artiﬁcially corrupted version input provided process shown figure network fully connected nearly statistical parametric speech synthesizers today cepstral coefﬁcients vocal tract parameterization speech signal. cepstral coefﬁcients never intended work parametric speech synthesis framework little success creating better parameterization suited synthesis. paper deep learning algorithms investigate data-driven parameterization technique designed speciﬁc requirements synthesis. create invertible low-dimensional noiserobust encoding spectrum training tapered stacked denoising autoencoder unwrapped used initialization multi-layer perceptron ﬁne-tuned training reconstruct input output layer. split middle form encoding decoding networks. networks produce parameterization spectrum intended better fulﬁll requirements synthesis. results reported experiments conducted using resulting parameterization clustergen speech synthesizer. index terms statistical parametric speech synthesis deep learning parameterization speech coder used modern statistical parametric speech synthesis remained largely unchanged number years. standard coding technique usually variant cepstral analysis. many different parameterizations spectrum developed synthesis managed survive long run. obvious indications systems submitted annual blizzard challenge. statistical parametric systems submitted challenge since inception vocoders cepstral coefﬁcients. even highly successful techniques like various ﬂavors straight rarely used synthesizer directly. usually converted cepstral coefﬁcients used statistical parametrical systems. lack parameterizations perform better mceps especially intriguing considering amount research effort gone ﬁnding replacement. ideal parameterization statistical parametric synthesis fulﬁll following requirements ’pretraining’ process approach identical speech recognition. build features stacking multiple denoising autoencoders built learning reconstruct corrupted versions input. trained unwrap shown ﬁgure particular interest parametric speech synthesis network learns reconstruct noisy version input lower dimensional features. therefore apparent deﬁnition network ﬁrst three four requirements ideal parameterization. discuss fourth requirement later section. actually rarely used task input needs reconstructed representation transforms input into. nearly always used provide lower dimensional representation classiﬁer logistic regression support vector machines used. example deep bottleneck features used speech recognition. however approaches less relevant parametric synthesis since classiﬁcation problem. unwrapped acts initialization multilayer perceptron layer produce layers. backpropagation used ﬁnetune output layer reconstruct input provided ﬁrst layer bottleneck middle. ﬁnetuning completed network split middle parts. section input layer bottleneck region encoding network section bottleneck region output layer decoding network. encoding network codes speech signal representation design invertible robust noise dimensional. representation encoding synthesizer uses parameterization speech signal i.e. learns mapping phonemes text values encoding. synthesis time synthesizer predicts values encoding based input text. decoding network converts code back representation speech signal. approach similar proposed efﬁcient speech coding apart fact proposes code applications also different speciﬁcally looks binary encoding. binary encodings useful statistical synthesis framework binary representations interpolable synthesis inherently generative task. previous sections discussed deep neural network build low-dimensional noise-robust representation speech signal deep neural network actually encode? explicitly input deep neural network learn reconstruct? actual speech signal itself magnitude spectrum complex spectrum representations signal processing research provided theory input representation matter since proven multilayer feedforward networks universal approximators. however proof places constraints size structure network. provide training algorithm reaches global optimum. therefore sensible train network representation known highly correlated speech perception. human hearing known logarithmic amplitude frequency. propose spectrum spectrum suitable representations network trained despite using input output layers linear network difﬁculty working wide range values spectrum. therefore rest paper describe attempts using deep neural network invertible low-dimensional noise-robust representation spectrum. experiments results built sdas mlps using theano python library parametric speech synthesizer using clustergen. input neural network dimensional spectral vector obtained -point speech frame. encoding obtained using network -dimensional. encoding size chosen make easier compare quality -dimensional mcep representation used baseline system. stacked denoising autoencoder built conﬁguration i.e. nodes input layer ﬁrst hidden layer second output layer. results conﬁguration ﬁne-tuning. encoding network therefore conﬁguration decoding network networks layer contact spectra linear layer non-linear function involved. layer deal range values spectra take. layers neurons sigmoid activations. evaluating quality systems built poses interesting problem. standard objective metric used nearly evaluations parametric speech synthesis cepstral distortion. however metric likely inherently unfair technique. default system compare against like statistical parametric synthesizers works directly mceps. systems optimize root-mean-squared error mcep prediction. words directly optimize metric. technique proposing gives encoding optimized parametric synthesis. optimizing prediction encoding need necessarily optimize cepstral distortion directly. therefore mcd-based results presented paper must taken pinch salt. synthesizer might directly optimize nevertheless good indicator listener perception; argument natural-sounding speech natural-appearing cepstral parameters. measure quality synthesis using cepstra obtained spectra decoding network. major hinderance deep neural networks amount effort needs tuning hyperparameters want technique would require tuning speaker. neural network settings tuned speaker identical conﬁgurations used others. sdas pretrained batch size epochs mlps trained batch size epochs. based results shown table appears identical hyperparameter settings work well multiple speakers. test also tried using encoding decoding networks analysis-resynthesis held data. resulted implying encoding learned deep neural network speaker speciﬁc. next tests using deep neural network’s -dimensional encoding parameterization clustergen statistical parametric synthesizer. scores three described voices shown table cepstral distortion higher deep neural network encoding compared default system. addition this baseline system preferred informal subjective tests. mentioned earlier section believe however makes much bigger impact performance. line deep learning theory. deep narrow network also takes substantially less time train compared shallow wide network. trends encouraging expect investigation directions improve performance further. earlier section described training process denoising autoencoder mentioned trained reconstruct original input noisy version input. traditionally ’noise’ added involves arbitrarily setting input parameters zero. also investigated using gaussian noise since closer noise introduced statistical parametric synthesizers. unfortunately effect making synthesis quality worse compared traditional ’noising’ strategy. experiments described paper following nvidia gpus tesla grid gtx. finding right stable hardware combination offers efﬁcient training platform also investigatory task. although tried build work related ﬁelds order reasonable topologies networks generative nature speech synthesis inherently different requirements thus feel likely signiﬁcant improvements possible within core technology. stands work concentrates ﬁnding encoding modeling vocal tract speaker allows direct comparison mcep parameterization. however technology constrained restriction adding excitation prosodic information networks still within method. systems affected fact deep neural network directly optimizing score like default system doing. lack good objective metric would work approach parameterization exacerbated problem making difﬁcult make design decisions. inturn prevented making full capability deep neural network; probably reason lower subjective quality. believe better objective metric would reﬂect positive light results. would also help make better decisions would contribute towards better parameterizations improved subjective results. results actually quite promising relatively good scores encoding strongly indicate encoding exists interpolable space. important synthesizers like clustergen form clusters data vectors leaves trees represent cluster mean. therefore representations like mceps line spectral pairs found suitable. interpolable space constraint probably difﬁcult achieve four earlier stated constraints. even data-driven parameterization currently slightly worse compared mceps extremely encouraging able parameterization manages satisfy four requirements. considering close difference performance data-driven parameterization mceps expect judicious design neural network coupled better learning strategies lead great results future. investigation deep neural network parameterization would incomplete without exploring various possible structures neural network. tested neural network varying width well depth. table summarizes results experiments. tests voice. ﬁrst column describes structure stacked denoising autoencoder. unwrapped multi layer perceptron corresponds would twice deep. network described ﬁrst table network table seen table constant depth increasing width layers neural network improves performance network. increasing depth bergstra breuleux bastien lamblin pascanu desjardins turian warde-farley bengio theano math expression compiler proceedings python scientiﬁc computing conference jun. kubichek mel-cepstral distance measure objective speech quality assessment communications computers signal processing ieee paciﬁc conference vol. ieee moulines charpentier pitch-synchronous waveform processing techniques text-to-speech synthesis using diphones speech communication vol. blizzard challenge http//www.synsig.org/index.php/blizzard kawahara morise takahashi nisimura irino banno tandem-straight temporally stable power spectral representation periodic signals applications interference-free spectrum aperiodicity estimation acoustics speech signal processing icassp ieee international conference ieee tokuda kobayashi imai speech parameter generation using dynamic features acoustics speech signal processing icassp-. international conference vol. tomoki tokuda speech parameter generation algorithm considering global variance hmm-based speech synthesis ieice transactions information systems vol. vincent larochelle bengio p.-a. manzagol extracting composing robust features denoising autoencoders proceedings international conference machine learning. hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath deep neural networks acoustic modeling speech recognition shared views four research groups signal processing magazine ieee vol. gehring miao metze waibel extracting deep bottleneck features using stacked auto-encoders acoustics speech signal processing ieee international conference", "year": 2014}