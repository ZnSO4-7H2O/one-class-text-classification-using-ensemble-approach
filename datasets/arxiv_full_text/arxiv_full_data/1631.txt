{"title": "Investigation of Language Understanding Impact for Reinforcement  Learning Based Dialogue Systems", "tag": ["cs.CL", "cs.AI", "cs.LG"], "abstract": "Language understanding is a key component in a spoken dialogue system. In this paper, we investigate how the language understanding module influences the dialogue system performance by conducting a series of systematic experiments on a task-oriented neural dialogue system in a reinforcement learning based setting. The empirical study shows that among different types of language understanding errors, slot-level errors can have more impact on the overall performance of a dialogue system compared to intent-level errors. In addition, our experiments demonstrate that the reinforcement learning based dialogue system is able to learn when and what to confirm in order to achieve better performance and greater robustness.", "text": "end-to-end learning approaches offer potential solution issue. instance policy learner adapted noise trickling component well error downstream component back-propagated tune component eventually yields dialogue system robust individual component errors. despite widespread interest building task oriented dialogue systems work investigated relationship mutual inﬂuence components impact overall dialogue system performance. instance lemon compared policy transfer properties different environments showing policies trained high-noise conditions better transfer properties trained low-noise conditions. brieﬂy investigated effect dialogue action level semantic error rates dialogue performance. work extensive quantitative analysis ﬁne-grained level errors goal provide meaningful insights language understanding component impacts overall performance dialogue system. contributions three-folds natural language understanding fundamental component many downstream tasks dialogue system state tracking policy learning dialogue policy often sensitive noise types errors accumulated module especially modular pipeline based dialogue systems policy learning trained separately. recently end-to-end learning approaches building dialog systems varying optimization objective functions offer many beneﬁts policy learning policy learning adapted noise component part tuned guided policy learner’s performance. language understanding component spoken dialogue system. paper investigate language understanding module inﬂuences dialogue system performance conducting series systematic experiments task-oriented neural dialogue system reinforcement learning based setting. empirical study shows among different types language understanding errors slot-level errors impact overall performance dialogue system compared intent-level errors. addition experiments demonstrate reinforcement learning based dialogue system able learn conﬁrm order achieve better performance greater robustness. index terms spoken language understanding task-completion dialogue policy learning reinforcement learning task-oriented dialogue systems microsoft’s cortana apple’s siri amazon’s echo google’s home etc. assist users completing speciﬁc tasks booking movie tickets setting calendar items ﬁnding restaurants natural language interactions. traditional dialogue system consists following components natural language understanding module receives utterances free texts maps structured semantic frame; usually three tasks module domain classiﬁcation intent determination slot ﬁlling. typically exist kinds recipes single-task learning concatenated approach multi-task learning joint approach dialogue manager consists state tracker policy learner state tracker offers ability access external database knowledge base tracks evolving state dialogue constructs state estimation whereas policy learner takes state estimation input chooses dialogue action; natural language generation module translates structured dialogue action representation natural language form. exist literature main approaches building dialogue systems modular pipeline based dialog systems end-to-end dialogue systems typical modular pipeline component trained separately processed sequence form pipelined dialog system. biggest problem dialogue systems error upstream module propagated downstream components pipeline making challenging downstream components adapt errors accumulated upstream components eventually degrading overall dialogue system performance. recently dialogue system huge impact either development understanding module policy learning natural language generation etc. downstream tasks. experiments conducted user simulation environment dialogue community researchers typically seek optimize dialogue policies either supervised learning reinforcement learning methods. approaches policy trained imitate observed actions expert. supervised learning approaches often require large amount expert-labeled data training. task-speciﬁc domains intensive domain knowledge usually required collecting annotating actual human-human human-machine conversations often expensive time-consuming. additionally even large amount training data parts dialogue state space well-covered training data lack sufﬁcient exploration prevents supervised learner ﬁnding optimal policy. contrast approaches allow agent learn withexpert-generated examples. given reward signal agent optimize dialogue policy interaction users. unfortunately require many samples environment making learning scratch real users impractical. overcome limitation many dialogue researchers train agents using simulated users goal user simulation generate natural reasonable conversations allowing agent explore policy space. simulation-based approach allows agent explore trajectories exist previously observed data overcoming central limitation imitation-based approaches. dialogue agents trained simulators serve effective starting point deployed real humans improve reinforcement learning. understand impact dialogue system draw convincing conclusion hard control possible variations real user setting also requirement large data makes impossible. user simulation much easier control variable directly analyze importance dialogue system. task-completion dialogue setting user simulator ﬁrst generates user goal. agent know user goal tries help user accomplish course conversations. hence entire conversation exchange around implicit goal. user goal generally consists parts inform slots slot-value pairs serve constraints user request slots slots whose value user information about wants values agent conversation. user goals generated using labeled conversational data course dialogue user simulator maintains compact stack-like representation called user agenda training testing policy based semantic frames user actions error model introduced simulate noise component noisy communication between user agent. here introduce different levels noise error model intent level slot level. level ﬁne-grained noise. speciﬁc task example movie-booking scenario multiple inform request intents like request theater request starttime request moviename etc. different intents group. symbolic dialogue form passed dialogue manager classic charge state tracking policy learning. state tracker keep tracking evolving slot value pairs agent user based conversation history query formed interact external database retrieve available result. every turn dialogue state tracker updated based retrieved results database latest user dialogue action outputs dialogue state dialogue state often includes latest user action latest agent action database results turn information conversation history etc. conditioned dialogue state dialogue policy generate next available agent action optimize policy apply reinforcement learning end-to-end fashion. work represent policy using deep q-network takes state state tracker input outputs actions using network parameter given state policy chooses action highest q-value maxa important tricks target network experience replay applied intent slot error types random error rates rule-based agent reports success rates error rates respectively. constrast rl-based agent achieves success rate error rates respectively. compare performance types agents rl-based agent greater robustness less sensitive noisy inputs. therefore following experiments performed using dialogue agent robustness consideration. fig. dialogue agents degrade remarkably error rate increases understand impact intent-level noises dialogue systems experimental groups performed ﬁrst group focuses difference among intent error types; second group focuses impact intent error rates. factors identical groups random slot error type slot error rate. experiments settings slot errors intent error rate different intent error types includes noisy intents categories includes noisy intents different categories includes random selection. fig. shows learning curves intent error types difference among three curves insigniﬁcant indicating incorrect intents similar impact matter categories belong experiments settings investigate difference among different intent error rates. intent error rate increases dialogue agent performs slightly worse difference subtle. suggests rl-based agent better robustness noisy intents. shown fig. agents converge similar success rate intent error type intent error rate settings. experiments performed neural task-completion dialogue system helps users book movie tickets. system gathers information customers’ desires multiturn conversations ultimately books intended movie tickets. environment assesses binary outcome conversation success movie booked booked movie satisﬁes users constraints. measure quality agent three evaluation metrics {success rate average reward average turns}. provides different information quality agents. three metrics strongly correlated generally good policy higher success rate higher average reward lower average turns. train reinforcement learning based agents interacting simulated user end-to-end fashion different error settings report success rate average turns analysis. table summarizes settings investigating impact different elements dialogue systems learning curves averaged runs. data collected amazon mechanical turk annotated internal schema. intents slots slots informable slots users constrain search requestable slots users values agent. example numberofpeople cannot requestable since arguably user knows many tickets wants buy. total labeled dialogues movie domain average number turns dialogue approximately experiments settings investigate impact different slot error types. corresponding learning curves given fig. among single error types incorrect slot value performs worst means slot name recognized correctly wrong value extracted slot case agent receives wrong value slot eventually books wrong ticket fails book probable reason dialogue agent difﬁculty identifying mistakes based rl-based belief tracking using incorrect slot values following dialogue actions could signiﬁcantly degrade performance. slot deletion incorrect slot difference limited indicating agent similar capability handling kinds slotlevel noises. experiments settings focus different slot error rates report results fig. clear fig. dialogue agent performs worse slot error rate increases comparing fig. dialogue system performance sensitive slot error rate intent error rate. important ﬁnding suggested empirical results slot-level errors important intent-level errors. possible explanation related dialogue action representation intent. intent predicted wrong example inform predicted incorrectly request ticket dialogue agent handle unreliable situation decide make conﬁrmation order keep correct information following conversation. contrast slot moviename predicted wrong slot value identiﬁed correctly dialogue turn might directly pass wrong information agent might lead agent book wrong ticket. another reason dialogue agent still maintain correct intent based slot information even though predicted intent wrong. order verify hypotheses experiments needed leave future work. finally noted experiments paper based task-completion dialogue setting chit-chat another setting different optimization goals interesting conduct similar experiments impact language understanding errors chit-chat dialogue system’s performance. paper conduct series extensive experiments understand impact natural language understanding errors performance reinforcement learning based taskcompletion neural dialogue system. results suggest several interesting conclusions slot-level errors greater impact intent-level errors; different slot error types different impacts agents; agents robust certain types slot-level errors agents learn double-check conﬁrm users cost slightly longer conversations. pietquin consistent goal-directed user model realisitc man-machine task-oriented spoken dialogue simulation ieee international conference multimedia expo. ieee schatzmann weilhammer stuttle young survey statistical user simulation techniques reinforcementlearning dialogue management strategies knowledge engineering review mnih kavukcuoglu silver rusu veness bellemare graves riedmiller fidjeland ostrovski petersen beattie sadik antonoglou king kumaran wierstra legg hassabis humanlevel control deep reinforcement learning nature vol. sarikaya convolutional neural network based triangular joint intent detection slot ﬁlling automatic speech recognition understanding ieee workshop hakkani-t¨ur celikyilmaz y.-n. chen deng y.-y. wang multi-domain joint semantic frame parsing using bi-directional rnn-lstm proceedings annual meeting international speech communication association y.-n. chen hakkani-t¨ur celikyilmaz deng syntax semantics? knowledge-guided joint semantic frame parsing proceedings ieee workshop spoken language technology seneff glass polifroni hazen hetherington jupiter telephone-based conversational interface weather information ieee transactions speech audio processing vol. dhingra y.-n. chen ahmed deng end-to-end reinforcement learning dialogue agents information access arxiv preprint arxiv. lemon dialogue policy learning combinations noise user simulation transfer results proc. sigdial lipton ahmed deng efﬁcient exploration dialogue policy learning networks replay buffer spiking arxiv preprint arxiv. lipton dhingra y.-n. chen user simulator task-completion dialogues arxiv preprint arxiv. eckert levin pieraccini user modeling spoken dialogue system evaluation automatic speech recognition understanding proceedings. ieee workshop", "year": 2017}