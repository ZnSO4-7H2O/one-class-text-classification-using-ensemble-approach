{"title": "Properties of the Sample Mean in Graph Spaces and the  Majorize-Minimize-Mean Algorithm", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "One of the most fundamental concepts in statistics is the concept of sample mean. Properties of the sample mean that are well-defined in Euclidean spaces become unwieldy or even unclear in graph spaces. Open problems related to the sample mean of graphs include: non-existence, non-uniqueness, statistical inconsistency, lack of convergence results of mean algorithms, non-existence of midpoints, and disparity to midpoints. We present conditions to resolve all six problems and propose a Majorize-Minimize-Mean (MMM) Algorithm. Experiments on graph datasets representing images and molecules show that the MMM-Algorithm best approximates a sample mean of graphs compared to six other mean algorithms.", "text": "fundamental concepts statistics concept sample mean. properties sample mean well-deﬁned euclidean spaces become unwieldy even unclear graph spaces. open problems related sample mean graphs include non-existence non-uniqueness statistical inconsistency lack convergence results mean algorithms non-existence midpoints disparity midpoints. present conditions resolve problems propose majorize-minimize-mean algorithm. experiments graph datasets representing images molecules show mmm-algorithm best approximates sample mean graphs compared mean algorithms. fr´echet functions euclidean spaces fr´echet functions graph edit kernel spaces necessary conditions optimality existence consistency suﬃcient conditions uniqueness existence midpoints majorize-minimize-mean algorithm statistical inference deduces properties population analyzing subset sampled data. central path departs fundamental concept mean leads normal distribution central limit theorem statistical estimation using maximum likelihood method. maximum likelihood method turn fundamental approach provides probabilistic interpretations learning methods pattern recognition. central path well-deﬁned euclidean spaces becomes unclear mathematically less structured spaces. since increasing amount non-euclidean data collected analyzed ways realized before statistics undergoing evolution examples evolution contributions statistical analysis shapes complex objects tree-structured data focus contribution statistical analysis graphs less explored than example space shapes. graphs occur diﬀerent areas computer vision network analysis chemobioinformatics problem adopting statistical techniques analyzing graphs referred structural statistical pattern recognition graph edit distance. attention sample mean graphs predominantly focused devising eﬃcient algorithms minimizing hardly studies understanding statistical geometrical properties sample mean lack comprehensive theoretical studies face fundamental problems related sample mean graphs addition theoretical problems sample mean graphs suﬀers computational issues function non-convex many local minima computation graph edit distance np-hard. consequences problems manifold first unclear whether concept sample mean graphs useful describe population graphs. second without understanding concept mean understand adaptions concepts results traditional statistics domain graphs. examples include normal distribution central limit theorem. turn means bread-and-butter tools statistics remain inaccessible narrowing structural statistical pattern recognition. third stated problems propagate problems learning methods prototype-based clustering principal component analysis. understand graph spaces well graph edit distance metric. results geometry show metric space necessary condition eliminate problems establish theory statistical analysis graphs need restrict representative ﬂexibility graph edit distance favor analytical ﬂexibility. example analytically well-behaved graph edit distance graph edit kernel metric graph edit kernel metric artiﬁcial construction sole purpose analyzing graphs rather common widely applied similarity function graphs theory propose conditions resolve problems graph spaces endowed graph edit kernel metric. proposed approach combines results sample fr´echet means metric spaces results geometry graph edit kernel spaces algorithms propose mean algorithm belongs class majorizeminimize algorithms class algorithms includes algorithm special case provides access general convergence results. experiments compared majorize-minimize-mean algorithm common related variants reported literature. rest paper structured follows discussing related work section introduces attributed graphs graph edit kernel metric. section develop theory sample mean graph edit kernel spaces basis fr´echet functions presents mmm-algorithm. section assess performance mmm-algorithm discuss results. finally section concludes summary main result outlook research. proofs delegated appendix. theory. research sample mean graphs based fr´echet’s formulation started pioneering work jiang used general graph edit distance studied types minimizers sample fr´echet function ﬁrst type minimizers medoid picks minimum sample graphs second type sample median minimizes entire graph space. following refer measures central tendency sample mean sake convenience. work jiang simultaneously triggered directions research. ﬁrst direction focused devising algorithms minimizing diﬀerent formulations sample fr´echet function second direction developed prototype-based clustering algorithms partly resulting novel ways compute sample mean studies neither consider fundamental statistical geometrical properties sample mean. beginning well-known sample mean unique unclear whether sample mean exists whether mean algorithm converges solution furthermore unclear wether sample mean converges population mean number sample graphs tends inﬁnity. sample mean approaches dissimilarity representations compounded consistency problem. connected sample mean graphs theory fr´echet functions mathematical statistics provides deep results proposed statistical consistency without presenting proof. since little progress made understanding sample mean graphs. consequence statistical analysis graphs less developed statistical analysis data structures shapes complex objects tree-structured data geometric part contribution inspired feragen algorithms. diﬀerent types algorithms proposed approximate sample mean. examples include genetic algorithms greedy algorithms graph spectral methods fusion methods based optimal alignments majority fusion methods process sample graphs incrementally loop sample. performance incremental fusion methods depend initialization reference graph order graph presented. fusion approaches lack convergence consistency statements. exception incremental fusion method proposed prior work belongs class stochastic generalized gradient algorithms theoretically ﬁeld stochastic optimization provides diﬀerent resolve consistency convergence issues. statistical consistency established stochastic optimization valid class stochastic generalized gradient methods whereas statistical consistency proposed work independent algorithm depends global minima sample fr´echet function. prior work empirically studied algorithm closely related proposed mmm-algorithm. studied batch version sgg-algorithm without presenting convergence result. contrast batch uses step size parameter. results batch convincing selected sub-optimal values step-size parameter. however diﬀerence batch mmm-algorithm choice step size parameter underlying concepts algorithms derived. underlying concept batch concept generalized gradient underlying concept necessary condition optimality proposed theorem though concepts result almost algorithms signiﬁcant impact theory practice. theoretically prove convergence invoking zangwill’s theorem practically step size parameter thereby gain increase solution quality compared results fusion methods mean computation piled without unifying theory provides mathematical justiﬁcation place proper context. unifying scheme suggest theorem necessary conditions optimality proved prior work theorem include result pivotal importance sake coherence completeness. importance theorem result multiple applications. example theorem follows problem minimizing fr´echet sample function equivalent multiple alignment problem result brings together algorithms diﬀerent domains ordinary sample mean computation graph-based representation fusion schemes progressive alignment multiple sequence alignment placed common umbrella theorem figure upper left shows attributed graphs attributes weights. white numbers inside nodes node attributes numbers attached edges edge attributes. small black numbers next nodes unique identiﬁers. identiﬁers correspond order nodes according matrix representation given graph. example assume graphs bounded order matrix graph padding zero column row. upper right shows identiﬁers nodes graph optimally aligned towards graph matrix representation graph edit kernel metric deﬁned section studies properties concept sample mean graph edit kernel spaces. provide conditions resolve problems propose majorizeminimize-mean algorithm. deﬁnition requires well-deﬁned vector addition available arbitrary distance spaces. generalize concept sample mean distance spaces resort equivalent formulation sample mean suggested fr´echet main idea based fact sample mean unique minimum sample fr´echet function using fr´echet’s optimization-based formulations generalize concept sample mean measures central tendencies graph edit kernel spaces. sake convenience subsume measures central tendency common term sample mean mean. probability distribution graph edit kernel space suppose sample graphs drawn i.i.d. according probability distribution sample fr´echet function form general minimum sample fr´echet function arbitrary distance spaces exist minimum exists necessarily unique sample fr´echet function diﬀerentiable unless underlying space euclidean banach space. thus unclear minimize sample fr´echet function eﬃciently state necessary conditions optimality cope issues more precisely abstract probability space. random element mapping measurable respect borel σ-algebra induced metric probability measure measurable space arbitrary distance spaces fr´echet function suﬀer similar anomalies sample fr´echet function. addition statistical justiﬁcation sample mean unclear distance spaces happen sample mean systematically misestimates population mean even tries estimate something exist. ﬁrst result presents necessary conditions optimality sample fr´echet function squared loss. result proved prior work theorem include result revised proof importance sake coherence completeness. figure shows example sample mean three graphs shows form according equation addition describing form sample mean theorem following implications matrix representations obtained equation this consider possible combinations selecting matrix representation sample graphs take average equation average minimum sample variation represents sample mean. unfortunately figure upper left shows three sample graphs right show sample mean rounded attribute values. lower right shows sample graphs optimally aligned sample mean matrix representations. matrix representation mean mean matrix representations aligned sample graphs. show mean graphs exists sample mean consistent estimator mean sense bhattacharya-patrangenaru addition show sample variation strongly consistent estimator variation. consequence unlikely systematically misestimate population parameter even present suﬃcient conditions population mean sample mean uniquely determined. this adopt geometric ﬁgures euclidean space combine graph-theoretic concepts. figure geometric visualization cone circumscribing ball center radius cone shown yellow ball shown red. graph element non-negative scalar lies ball blue polyhedral cone depicts graph space point view cone apex obtained boundary permutation only. asymmetric graph graph trivial automorphism group. graph asymmetric called symmetric. example asymmetric graphs graphs nodes mutually distinct attributes. figure depicts symmetric asymmetric graph. thus shortest euclidean distance diﬀerent matrix representations addition asymmetric graphs closer asymmetric graph symmetric lower degree asymmetry. therefore deﬁne symmetric graphs. figure left shows symmetric right asymmetric graph together representation matrices. white numbers inside balls show node attributes numbers attached lines show edge attributes. small black numbers attached node unique identiﬁers showing position respective node representation matrix consideration. left permutation left example non-trivial automorphism leaves representation matrix unchanged. right node attributes asymmetric graph right mutually diﬀerent. permutation reorders nodes results diﬀerent representation matrix. hence non-trivial permutation leaving representation matrix unchanged. permutation results diﬀerent matrix representation closest ﬁrst one. degree asymmetry sample mean midpoint elements coincide euclidean spaces generally certain metric spaces called geodesic spaces. moreover existence midpoint every pair elements equivalent characterization geodesic spaces. therefore midpoints non-metric distance spaces graph spaces endowed graph edit distance exist. consequence theorem propose mean algorithm belongs class majorize-minimize minorize-maximize algorithms class includes algorithm special case provides access general convergence results. next result establishes convergence mmm-algorithm solution satisfying necessary conditions optimality. eliminate last remaining anomaly proof adopts zangwill’s convergence theorem algorithms described section medoid-algorithm serves baseline reasons general algorithm applied distance space requires fusion elements minimizes sample fr´echet function sample instead whole graph space. consequence latter issue attain sample mean general. letter. letter dataset consists graphs represent distorted letter drawings capital letters class prototype letter drawn. prototype letters converted prototype graphs representing lines undirected edges ending points lines nodes. node labeled two-dimensional attribute giving position relative reference coordinate system. edges unlabeled. given noise level distorted copies prototype graph generated giving total graphs. dataset divided training validation test consisting graphs each. grec. grec dataset consists graphs representing symbols architectural electronic drawings classes. images occur diﬀerent distortion levels. depending distortion level either erosion dilation morphological operations applied. result thinned obtain lines pixel width. finally graphs extracted resulting denoised images tracing lines detecting intersections well corners. nodes represent ending points corners intersections circles. node labeled four types line-segments represent two-dimensional position. nodes connected undirected edges labeled line arc. additional attribute speciﬁes angle respect horizontal direction diameter case arcs. graphs distorted nine times obtain data containing graphs uniformly distributed classes. resulting split training validation test size respectively. aids. aids data consists graphs representing molecular compounds aids antiviral screen database active compounds. molecules divided classes molecules active inactive not. mutag. mutagenesis dataset consists graph representing mutagenic aromatic heteroaromatic nitro compounds labeled according whether mutagenic eﬀect salmonella typhimurium. dataset divided subset regression friendly subset regression unfriendly molecules. class samples samples coincide classes eight datasets giving total diﬀerent samples. replicated sample times giving total samples. datasets considered graphs training set. measure performance measure used sample dispersion solution quality. runtimes used number iterations number solved graph matching problems performance measures. recorded runtime best solution found account last iterations waiting time termination. figure results pairwise comparisons seven mean algorithms. element heatmaps shows percentage method lower sample dispersion method column percentage figure shows result pairwise comparisons seven mean algorithms using sample dispersion performance measure. inspecting figure made following observations results show competitions mean algorithms large margin pairwise comparisons. indicates likely return better approximation sample mean mean algorithms. therefore suggest ﬁrst choice solver runtime issue. observed batch-arithmetic-mean pairwise comparisons mmm. ﬁrst glance result appears surprising because single-loop version iterative algorithm mmm. closer look algorithms shows randomly select sample graph initial solution. indicates choice initial solution substantially inﬂuence quality ﬁnal solution sense iterations always compensate poor initialization. therefore assume room improvement considering diﬀerent initialization schemes. found incremental-arithmetic-mean lost competitions similar large margin pairwise comparisons. addition performed substantially worse single-loop algorithms pac. indicates order sample graphs fused matters random order poor choice. figure ranks seven mean algorithms pairwise competition provides information diﬀerences solution quality. generally rankings provide information percentage problems mean algorithm deviates within given factor best solution. therefore performance proﬁles introduced evaluate compare solution quality mean algorithms. refer observed worst factor τmax random samples τmax class samples. worst factors random samples class samples lower τmax mmm. shows longer ﬁrst choice example accept solutions deviate best solution conﬁdence. ﬁndings indicate robust random samples robust class samples mmm. comparison results across random class samples shows mean algorithm guarantees solutions within factor conﬁdence. since deviation best solution large application problems compromise perfect conﬁdence tighter factor. suggest ﬁrst choice practical setting ﬁndings item shown observation figure failed solve problem within factor best solution class samples. interested understanding causes result degraded performance mmm. table shows datasets failed solution within factor respectively. notable performed worse predominantly class samples grec dataset. opposed datasets considered study distinguishing feature grec dataset substantially diﬀerent scaling node attributes three orders magnitude. shown mean node attribute vector standard deviation hypothesize diﬀerent scalings attributes inﬂuences performance mmm. test hypothesis ﬁrst normalized node edge attributes grec graphs mean zero standard deviation dimension. replaced original grec dataset normalized one. finally conducted experiment class samples before restricted classes grec. control experiment repeated experiment attributes normalized grec graphs rescaled constant factor control experiment serves exclude possibility eﬀects degraded performance caused scale attribute values. figure shows result pairwise comparisons using sample dispersion performance measure. results show normalization strongest positive eﬀect strongest negative eﬀect sgg. rescaling normalized graph factor gave almost results normalized graphs slight diﬀerences caused random factors experiments. ﬁndings indicate diﬀerent scalings attribute values substantially degrade performance fusion-based mean algorithms. runtime comparisons considered batch-arithmetic-mean representative single-loop algorithms linear time complexity median algorithm representative mean algorithms quadratic time complexity. details times complexities refer section figure shows runtime logarithmic scale function sample size. curves mmm-algorithm stochastic-gradient-descent obtained ﬁtting polynomials degree two. made following observations observed shape quadratic iterative algorithms similar linear curve quadratic curve med. ﬁnding indicates likely depend linearly quadratically sample size. vation suggests scales better sample size sgg. however larger empirical study could determine algorithms scale increasingly large sample size. smaller sample size often slower med. seen clearly figure observed slower samples average size average number iterations samples respectively. results show similar eﬀect less often. assume eﬀect caused comparably large waiting time best solution found termination mmm. waiting time current best solution found improved turn restarts waiting time. waiting time iterations large compared sample size eﬀect runtime iterations repeated improvements. waiting time iterations corresponds runtime samples size therefore considered large samples average size large samples waiting time iterations suﬃciently small prevent quadratic runtimes. would explain slower samples size larger conclude ﬁnal remark. runtime depends choice step size. larger step size faster terminate. fairly assess runtime ﬁrst selected step size sggη gave best sample variation average. measured runtime selected step size ignored time required issue considered runtime issue. often failed ﬁnding good approximations sample mean scaling attributes diﬀered strongly. application admits normalizing attribute values dimension help improve results. goal experiment assess trade-oﬀ classiﬁcation accuracy computation time nearest-neighbor classiﬁers using condensed datasets classiﬁcation. condensed datasets reducing training subset consisting sample mean class. empirical study motivated fact simple nearest-neighbor classiﬁer still belongs state-of-the-art graph classiﬁcation computationally expensive used whole training classiﬁcation. classiﬁed test dataset using eight diﬀerent nearest-neighbor classiﬁers. ﬁrst nearest-neighbor classiﬁer used whole training classiﬁcation test set. refer classiﬁer -nn. seven classiﬁers used condensed dataset consisting sample mean class. used seven mean algorithms listed section approximating sample mean class respective training sets. dataset condensed nn-classiﬁer conducted trials recorded average classiﬁcation accuracy standard deviation. compared condensed nn-classiﬁers results show mmmaddition based condensed nn-classiﬁer eight datasets. three datasets best performing -nn. indicates good approximation sample mean likely results good condensed nn-classiﬁers. argument also supported poor results pac. mean-algorithm performed worst ﬁnding good approximation sample mean algorithms resulted condensed worst average classiﬁcation accuracy particular datasets letter mutag- mutag-. give comparable even better results substantially faster. classiﬁcation compares test graph graphs training condensed classiﬁers compare test graphs class means only. rizing classes single prototype result uncontrolled loss relevant information nearest neighbor classiﬁcation. propose solutions problem centroid-based clustering using sample means class proposed theoretically justiﬁed adaption supervised learning vector quantization algorithms graphs proposed theoretically justiﬁed graph edit kernel space sample mean exists consistent estimator population mean. addition graphs concept sample mean midpoint coincide. necessary conditions optimality describe form sample mean give rise majorize-minimize-mean algorithm outperformed mean algorithms based fusing graphs optimal alignments provide unifying scheme fusion-based algorithms. contribution serves ﬁrst step towards theory statistical analysis graphs. ultimate goal adapt standard tools traditional statistics develop novel tools inferring properties populations graph edit kernel spaces. possible next steps include adaption normal distribution central limit theorem parameter estimation using maximum likelihood principal component analysis. compare performance mean algorithms used performance proﬁles performance proﬁle cumulative distribution function performance metric. considered performance metrics average sample dispersion sample dispersion number iterations iteration loop estimated probability solution algorithm deviate factor best solution algorithms consideration. value estimated probability algorithm algorithms. medoid algorithm. medoid algorithm picks minimum sample fr´echet function sample instead whole space this comδ sample graphs medoid sample graph sample fr´echet variation medoid upper bound sample fr´echet variation sample mean. furthermore applied distance space requires fusion techniques constructing elements given ones. here baseline. greedy-neighbor-joining. igreedy-neighbor-joining algorithm combines medoid algorithm incremental-arithmetic-mean. ﬁrst determines compute sample mean invokes incremental mean commedoid putation sample graphs presented order increasing distances medoid used prototype-based clustering pairwise distance calculations dropped medoid replaced current centroid respective cluster. progressive-alignment-construction. progressive-alignment-construction algorithm ﬁrst computes pairwise distance matrix medoid algorithm. graphs clustered using agglomerative single linkage clustering starting clusters consisting singletons closest clusters merged graphs single cluster. process cluster represented sample mean. merging stochastic generalized gradient. stochastic-generalized-gradient algorithm minimizes non-diﬀerentiable sample f´echet function similar fashion stochastic grasquared graph edit kernel metric pointwise minimum convex diﬀerentiable functions non-diﬀerentiable non-convex. shown diﬀerentiable almost everywhere locally lipschitz non-diﬀerentiable points furthermore generalized diﬀerentiable sense norkin ermoliev calculus generalized diﬀerentiable function fr´echet function also generalized differentiable. update rule sgg-algorithm replaces gradient stochastic gradient descent method element generalized gradient given sample graphs randomly drawn underlying probability distribution sgg-algorithm directly minimizes fr´echet function. mild assumptions sgg-algorithm converges almost surely solution fr´echet function satisfying necessary conditions optimality almost surely main contribution runtime mean algorithm number graph matching problems need solved minimize sample fr´echet function. consider computations negligible. runtime mean algorithms follows number refers sample size. value number iterations complexity greedy-neighbor-joining algorithm depends choice reference graph. here consider medoid reference graph. suppose another sample mean distinct theorem representations representation group node permutations simultaneously permutes columns matrix representations. since asymmetric prop. since interior interior prop. follows finally third property also follows applying triangle inequality. suppose sample mean. minimizes right hand side equation since midpoint exists minimizer satisﬁes equation thus midpoint. sample fr´echet function takes role function theorem item need show continuous satisﬁes properties zangwill’s convergence theorem. show continuity rewrite sample fr´echet function equivalent form squared euclidean distance continuous. minimum ﬁnite continuous functions continuous. shows continuous. next show properties show every point-to-set determined mm-algorithm. combining equations gives strict inequality remains show closed map. ﬁrst show closed optimal alignments representations graph convergent sequences follows since", "year": 2015}