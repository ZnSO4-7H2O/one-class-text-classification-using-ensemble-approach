{"title": "Leveraging Deep Neural Network Activation Entropy to cope with Unseen  Data in Speech Recognition", "tag": ["cs.LG", "cs.CL", "stat.ML"], "abstract": "Unseen data conditions can inflict serious performance degradation on systems relying on supervised machine learning algorithms. Because data can often be unseen, and because traditional machine learning algorithms are trained in a supervised manner, unsupervised adaptation techniques must be used to adapt the model to the unseen data conditions. However, unsupervised adaptation is often challenging, as one must generate some hypothesis given a model and then use that hypothesis to bootstrap the model to the unseen data conditions. Unfortunately, reliability of such hypotheses is often poor, given the mismatch between the training and testing datasets. In such cases, a model hypothesis confidence measure enables performing data selection for the model adaptation. Underlying this approach is the fact that for unseen data conditions, data variability is introduced to the model, which the model propagates to its output decision, impacting decision reliability. In a fully connected network, this data variability is propagated as distortions from one layer to the next. This work aims to estimate the propagation of such distortion in the form of network activation entropy, which is measured over a short- time running window on the activation from each neuron of a given hidden layer, and these measurements are then used to compute summary entropy. This work demonstrates that such an entropy measure can help to select data for unsupervised model adaptation, resulting in performance gains in speech recognition tasks. Results from standard benchmark speech recognition tasks show that the proposed approach can alleviate the performance degradation experienced under unseen data conditions by iteratively adapting the model to the unseen datas acoustic condition.", "text": "data hungry data sensitive model performance typically found improve data disparate conditions used train model. unfortunately labeled data expensive. although large volumes data become available every properly transcribed reflective varying acoustic conditions systems must tackle. scarce data acoustic models found quite sensitive acoustic condition mismatches subtle change background acoustic conditions noise reverberation microphone conditions significantly worsen model performance. combat data-mismatch problems multicondition training accompanied data augmentation typically used expose acoustic models various possible background conditions. multi-condition training reported acoustic model found benefit training thousands hours acoustic data collected diverse sources. data augmentation found benefit performance reverberant conditions simulating different room relatively easy compared simulating non-stationary background noise sources. typically data augmentation relies artificially coloring speech additive noise reverberation effects. multi-condition training data-augmentation approaches prior knowledge generally assumed kind distortion model often true. augmentation expose model anticipated acoustic variations; reality acoustic variations difficult anticipate. real-world applications encounter diverse acoustic conditions mostly unique hence difficult model. condition reverberation noise practically open-set problem. systems trained several thousands hours data collected different realistic conditions typically found quite robust background conditions expected contain variations; however data contain possible variations world specifically data available popular languages others. nseen data conditions inflict serious performance degradation systems relying supervised machine learning algorithms. data often unseen traditional machine learning algorithms trained supervised manner unsupervised adaptation techniques must used adapt model unseen data conditions. however unsupervised adaptation often challenging must generate hypothesis given model hypothesis bootstrap model unseen data conditions. unfortunately reliability hypotheses often poor given mismatch training testing datasets. cases model hypothesis confidence measure enables performing data selection model adaptation. underlying approach fact unseen data conditions data variability introduced model model propagates output decision impacting decision reliability. fully connected network data variability propagated distortions layer next. work aims estimate propagation distortion form network activation entropy measured shorttime running window activation neuron given hidden layer measurements used compute summary entropy. work demonstrates entropy measure help select data unsupervised model adaptation resulting performance gains speech recognition tasks. results standard benchmark speech recognition tasks show proposed approach alleviate performance degradation experienced unseen data conditions iteratively adapting model unseen data’s acoustic condition. learning technologies become preferred technique building automatic speech recognition systems demonstrating impressive performance gains almost tried languages acoustic conditions. interestingly deep neural network -based systems aurora- test data includes test sets different channel conditions different added noises addition clean condition. signal-to-noise ratio test sets varied evaluation consists words different channel conditions. original audio data test conditions recorded sennheiser microphone test conditions recorded using second microphone randomly selected different microphones results evaluation presented follows clean matched-channel noisy matched-channel clean varying-channels noisy varying-channels work treated reverberation unseen data condition training models aurora- corpus assessing model performance real-world reverberated data. adaptation optimization evaluation purposes used training development evaluation sets distributed reverb challenge respectively. reverb speech dataset contains singlespeaker utterances single-microphone part dataset used experiments reported paper. reverb training consists clean wsjcam dataset convolved room impulse responses corrupted background noise; hence training consisted artificially noisereverberation-corrupted data. please note reverb training used unsupervised adaptation transcriptions used experiments except oracle experiment model trained using noisy reverberated acoustic conditions. evaluation development data contain real recordings simulated data real data borrowed mc-wsj-av corpus consists utterances recorded noisy reverberant room. simulated evaluation contained utterances farnearmicrophone conditions split three room conditions real evaluation contained utterances split equally farnear-microphone conditions. note none experiments used speaker-level information. used gammatone filterbank energies acoustic features processing input speech signal analyzed using bank gammatone filters equally spaced equivalent rectangular bandwidth scale. within analysis window approximately power bandlimited time signals computed frame rate subband powers root-compressed using reverb challenges) shown vulnerable dnn-hidden markov model acoustic models realistic varying unseen acoustic conditions. celebrated resource-constrained approaches coping unseen data conditions performing unsupervised adaptation necessity data. reliable adaptation technique supervised adaptation assumes annotated target-domain data; however annotated data often unavailable real-world scenarios. constraint often makes unsupervised adaptation practical. unsupervised speaker adaptation dnns explored much success adaptation based maximum transforms i-vectors etc. showing impressive performance gains un-adapted models. stacked bottleneck neural network architecture proposed cope limited target-domain data used feature extractor. system used handle unseen languages extended cope unseen reverberation conditions. kullbackleibler divergence regularization proposed model parameter adaptation differs typically used regularization sense constrains model parameters rather output probabilities. feature-space maximum likelihood linear regression transformed feature found improve acoustic model performance mismatched cases. using confidence filtering shown improve acoustic performance. work focus understanding acoustic condition mismatch training testing data impacts internal information flow within fully connected neural network. similar efforts pursued researchers paper investigates data mismatch impacts neural activations given knowledge work investigates neural activations predict dnn’s decision less accurate. neural activations create reliability measure selecting untranscribed data acoustic model adaptation. explored process improve recognition performance unseen acoustic condition iterative adaptation process generate performance good seen acoustic conditions acoustic models work trained using multi-conditioned noisechannel-degraded training data aurora- noisy wall street journal corpus. aurora- contains total additive noise types channel-matched mismatched conditions. created standard database contains training utterances approximately -hours duration test utterances. entropy defined probability density function note according entropy obtained running window activation experiments used samples centered time instant used frame hopping frames estimate entropy note selection value done maximizing correlation run-time estimated entropy measure observed word error rate aurora- test set. finally run-time entropy obtained neurons hidden layer summary measure obtained estimating mean entropy neuron activation resulting vector dimension equal number neurons layer. vector sorted percentile entropy measures across activations selected mean value computed generate final normalized ranked summary entropy measure note nrse measure single real number computed audio file present adaptation dataset. observed estimated entropy correlated correlation coefficient approximately unseen noisy speech dataset. given this natural question follows layer activation used estimate nrse question explored speech recognition studies presented paper. earlier work showed models perform much better acoustic models aurora- speech recognition task. typically cnns give lower wers compared dnns using filterbank features tasks gfbs perform better well melfilterbank energies generate alignments necessary training system gmm-hmm model used produce senone labels. altogether gmm-hmm system produced context-dependent states aurora- training data. input features acoustic models formed using context window frames acoustic models trained using cross-entropy alignments gmm-hmm system. five hidden layered neurons layer trained using alignments gmm-hmm system turn used generate alignments drawback existing supervised learning approaches resulting models learn information present training set. faced unknown variations models fail generalize well consequently propagate distortion input features resulting distorted outputs represent relevant aspects input fully connected anomalies propagate layer next like ripple effect spread localized distortions across dimensions layers. techniques drop-out training usually help cases reduce reliability neuron help model improve generalization capability. grossly mismatched situations detecting test cases cause system completely fail versus generate reasonable output quite useful. generate detection confidence measure generally indicative trustworthy hypothesis test files. fully connected network interpreted cascade several feature-transformation steps goal making target class discriminative possible respect other. hence cases model fails generate reasonable performance transformations fail generate reliable features therefore model decision impacted. veracity statement observed figure show neural activations generated seen versus unseen data corrupted noise. ables reflect impact unseen data conditions performance acoustic model found degrade relative unseen reverberated condition opposed seen reverberated condition reflected oracle experiments. cases tfcnns found perform slightly better counterparts. based observations shown tables focused tfcnn acoustic models subsequent experimental evaluations. evaluate relevance nrse measure layer tfcnn acoustic model derived from treated reverb training unsupervised adaptation dataset performed following experiments first evaluated case entire reverb training decoded hypothesis tfcnn acoustic model used generate alignments adapting tfcnn acoustic model trained aurora- data. resulting adapted tfcnn acoustic model treated baseline system named tfcnnall_p reflects entire reverb hypothesis used adapt model reflects first pass unsupervised adaptation. next extracted activations hidden layers tfcnn acoustic model estimated nrse measures acoustic models consisted filters size resulting feature maps sub-sampled using max-pooling three samples without overlap. subsequent fully connected network four hidden layers neurons hidden layer output layer included many nodes number states given dataset. networks trained using initial four iterations constant learning rate followed learning rate halving based cross-validation error decrease. training stopped significant reduction cross-validation error noted crossvalidation error started increase. backpropagation performed using stochastic gradient descent minibatch training examples. observed timefrequency architecture) performed better one-dimensional frequency convolution typically done acoustic models hence almost experiments used tfcnn acoustic model report findings. tfcnn architecture similar parallel convolutional layers used input performing convolution across time across frequency axis input filterbank features. tfcnn acoustic models input acoustic features formed using context window frames tfcnns filters perform time convolution filters perform frequency convolution. time frequency convolution eight bands used followed maxpooling three samples frequency convolution max-pooling five samples time convolution. feature maps convolution operations concatenated fully connected neural nodes four hidden layers. baseline acoustic model trained aurora- multi-condition training dataset held-out crossvalidation used train neural acoustic models similar reverberated acoustic condition treated unseen data condition experiments experimental analysis performed using development test data reverb challenge dataset. oracle experiment trained cnnoracle tfcnnoracle system trained jointly aurora- reverb training data. results baseline tfcnn systems tfcnnoracle system shown tables aurora- test reverb test sets respectively. table shows conditions tfcnn acoustic model performed better counterpart interestingly augmenting training data additional reverberated data improved performance intermediate layers network) better choice data selection. observation could related role intermediate layers known perform different discriminative features decision-making task final intermediate layers likely correlated word error rates higher distortions feature space contributing confusion decision-making task final layers. figure distribution nrse activations obtained third hidden layer tfcnn acoustic model trained aurora- multi-conditioned data. green nrse aurora- training data. blue nrse unseen reverberated noisy data vertical dotted lines indicate respective means. comparing tables tables shows selection significantly simulated reverberation condition relative improvement quite significant whereas real reverberation conditions improvements greater test sets respectively. significant improvement simulated reverberation condition extent expected adaptation used case reverb training consists simulated reverberation only; hence helped model real reverberation condition. used select segments case found lower entropy. tables reflect results tfcnn acoustic model adaptation aurora- test reverb test sets respectively. note adaptation unsupervised adaptation dataset used addition original aurora- training dataset update acoustic model parameters. adaptation model parameters updated norm initial learning rate learning rate halved every step. early stopping performed based crossvalidation error aurora- cross validation used. note reverberated data cross-validation purposes. analyze recognition performance improved subsequent adaptation acoustic model performed multiple passes adaptation hypothesis adaptation step used adapt acoustic model continued steps. goal investigating multiple iteration adaptation improve performance model. ables show data selection followed model adaptation obtained better performance using entire adaptation data. indicates data-selection process helps prune hypothesis parent recognition system. comparing tables including aurora- training data adaptation helped model retain performance noisy conditions improving performance significantly reverberated speech conditions. tables state nrse measures layer contract hr--c-. views opinions and/or findings contained article authors interpreted representing official views policies department defense u.s. government. mohamed g.e. dahl hinton acoustic modeling using deep belief networks ieee trans. aslp vol. seide conversational speech transcription neural networks proc. interspeech hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath kinsgbury deep neural networks acoustic modeling speech recognition ieee signal process. mag. vol. grézl egorova karafiát further investigation multilingual training adaptation stacked bottle-neck neural network structure proc. sainath r.j. weiss wilson a.w. senior vinyals learning speech front-end waveform cldnns proc. interspeech peddinti chen manohar povey khudanpur aspire system robust lvcsr tdnns i-vector adaptation rnn-lms proc. asru karafiát grézl burget szöke cernocký three ways adapt recognizer unseen reverberated speech system aspire challenge proc. interspeech bell m.j.f. gales hain kilgour lanchantin mcparland renals wester p.c. woodland challenge evaluating multigenre broadcast media recognition proc. asru barker marxer vincent watanabe third ‘chime’ speech separation recognition challenge dataset task baselines proc. asru harper automatic speech recognition reverberant environments challenge proc. asru yoshioka ragni m.j.f. gales investigation unsupervised adaptation acoustic reverberated model conditions relative reduction obtained third-pass adapted model compared first-pass adapted model interestingly fourth-pass adapted model show significant gain thirdpass model work investigated whether activations neural hidden layers used predict reliability neural net’s decision hence prediction perform data selection unsupervised model adaptation. fully connected network information flows left right unseen distortions introduced input propagate hidden layers output nodes. distortions propagated detectable hidden layers. detected inform whether network likely generate reliable decision versus less reliable one. based assumptions proposed measure normalized ranked summary entropy measure estimates overall percentile entropy neural net’s activation given input segment. observed high nrse indicates network likely generate erroneous hypothesis compared lower nrse indicates hypothesis likely reliable one. based this explored data selection unsupervised model adaptation demonstrated data-selection process helpful unsupervised model adaptation reducing error rates unseen data conditions. addition found performing multiple passes unsupervised adaptation resulted improvement recognition performance reducing performance acoustic models trained seen unseen acoustic conditions. work performed data selection rank-sorting nrse measures estimated audio file present unsupervised dataset. pragmatic approach would perform data selection thresholding nrse measures direction plan kinoshita delcroix yoshioka nakatani habets haeb-umbach leutnant sehr kellermann maas gannot reverb challenge common evaluation framework dereverberation recognition reverberant speech proc. ieee workshop applications signal processing audio acoustics robinson fransen foote renals wsjcam british english speech corpus large vocabulary continuous speech recognition proc. icassp lincoln mccowan vepa h.k. maganti multi-channel wall street journal audio visual corpus specification initial experiments proc. ieee workshop automatic speech recognition understanding hermansky burget cohen dupoux feldman godfrey khudanpur maciejewski s.h. mallidi menon ogawa peddinti rose stern wiesner veselý towards machines know know summary work done frederick jelinek memorial workshop proc. icassp mitra hout wang bartels franco vergyri fusion strategies robust speech recognition keyword spotting channelnoise-degraded speech proc. interspeech zaragoza d’a-b. florence confidence measures neural network classifiers proc. int. conf. information processing management uncertainty knowledge based systems models filterbank input proc. icassp saon soltau nahamoo picheny speaker adaptation neural network acoustic models using i-vectors proc. asru s.h.k. parthasarathi hoffmeister matsoukas mandal strom garimella fmllr based feature-space speaker adaptation acoustic models proc. interspeech seide kldivergence regularized deep neural network adaptation improved large vocabulary speech recognition proc. icassp bilmes regularized adaptation discriminative classifiers proc. icassp’ walker strassel rats radio traffic collection system proc. odyssey -the speaker language recognition workshop stolcke srilm—an extensible modeling toolkit proc. icslp venkataraman wang techniques effective vocabulary selection proc. eighth european conference speech communication technology mandal hout y-c. mitra zheng vergyri ferrer graciarena kathol franco strategies high accuracy keyword detection noisy channels proc. interspeech mitra franco graciarena mandal normalized amplitude modulation features large vocabulary noise-robust speech recognition proc. icassp mitra franco graciarena damped oscillator speech recognition proc. interspeech hsiao zhang karakos s.h. mallidi karafiat vesely szoke zhang nguyen schwartz progress keyword search system darpa rats program proc. interspeech mitra wang franco bartels graciarena evaluating robust features deep neural networks speech recognition noisy channel mismatched conditions proc. interspeech singapore gehring miao metze waibel extracting deep bottleneck features using stacked autoencoders proc. icassp mitra franco time-frequency convolution networks robust speech recognition proc. asru thomas drugman janne pylkko reinhard kneser active semi-supervised learning benefits acoustic language models proc. interspeech", "year": 2017}