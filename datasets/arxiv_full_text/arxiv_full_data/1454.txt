{"title": "An Automated Text Categorization Framework based on Hyperparameter  Optimization", "tag": ["cs.CL", "cs.AI", "stat.ML"], "abstract": "A great variety of text tasks such as topic or spam identification, user profiling, and sentiment analysis can be posed as a supervised learning problem and tackle using a text classifier. A text classifier consists of several subprocesses, some of them are general enough to be applied to any supervised learning problem, whereas others are specifically designed to tackle a particular task, using complex and computational expensive processes such as lemmatization, syntactic analysis, etc. Contrary to traditional approaches, we propose a minimalistic and wide system able to tackle text classification tasks independent of domain and language, namely microTC. It is composed by some easy to implement text transformations, text representations, and a supervised learning algorithm. These pieces produce a competitive classifier even in the domain of informally written text. We provide a detailed description of microTC along with an extensive experimental comparison with relevant state-of-the-art methods. mircoTC was compared on 30 different datasets. Regarding accuracy, microTC obtained the best performance in 20 datasets while achieves competitive results in the remaining 10. The compared datasets include several problems like topic and polarity classification, spam detection, user profiling and authorship attribution. Furthermore, it is important to state that our approach allows the usage of the technology even without knowledge of machine learning and natural language processing.", "text": "great variety text tasks topic spam identiﬁcation user proﬁling sentiment analysis posed supervised learning problem tackle using text classiﬁer. text classiﬁer consists several subprocesses general enough applied supervised learning problem whereas others speciﬁcally designed tackle particular task using complex computational expensive processes lemmatization syntactic analysis etc. contrary traditional approaches propose minimalistic wide system able tackle text classiﬁcation tasks independent domain language namely µtc. composed easy implement text transformations text representations supervised learning algorithm. pieces produce competitive classiﬁer even domain informally written text. provide detailed description along extensive experimental comparison relevant state-of-the-art methods. compared diﬀerent datasets. regarding accuracy obtained best performance datasets achieves competitive results remaining compared datasets include several problems like topic polarity classiﬁcation spam detection user proﬁling authorship attribution. furthermore important state approach allows usage technology even without knowledge machine learning natural language processing. large continuously growing volume textual data automated text classiﬁcation methods taken increasing interest research community. although many eﬀorts proposed direction remains open problem. arrival massive data sources like micro-blogging platforms introduces challenges many prior techniques failed. among challenges volume noisy nature data shortness texts implies little context informal style also plagued misspellings lexical errors among others. data sources made popular tasks sentiment analysis user proﬁling. sentiment analysis problem consists determining polarity given text global polarity particular subject entity. user proﬁling task consists given text predicting facts author like her/his demographic information importance problems research community several international competitions carried recent years. example semeval tass sentipolc challenges sentiment classiﬁers twitter data english spanish italian languages respectively. also opens calls author proﬁling systems english spanish german languages. problems closely related traditional text classiﬁcation applications topic classiﬁcation authorship attribution spam detection. usually aforementioned problems treated particular i.e. method proposed solve adequately classiﬁcation task. traditionally approach cannot generalize related task consequently methods dependent problem; however worth mention specialization produces insight problem’s domain. conversely contribution proposed framework create text classiﬁer regardless domain language based training labeled examples. idea creating text classiﬁer almost independent language domain novel fact previous work introduced combinatorial framework sentiment analysis. there aspects language considered stopwords tokenizers special attention lexical structures negations. also particularities domain like emoticons emojis considered. presented manuscript generalization formalization previous work; allows simplify entire framework work independently language particular task empower sophisticated text treatments whenever possible http//alt.qcri.org/semeval/ http//www.sepln.org/workshops/tass//tass.php http//www.di.unito.it/ tutreeb/sentipolc-evalita/ http//pan.webis.de/ stated above tackle problem creating text classiﬁers work regardless domain language nothing training learned. general idea orchestrate number simple text transformations tokenizers weighting schemes along support vector machine classiﬁer produce eﬀective text classiﬁcation. detailed look problem creating eﬀective text classiﬁers combinatorial optimization problem; search space containing possible combinations diﬀerent text transformations tokenizers weighting procedures respective parameters search space meta-heuristic used search conﬁguration produces highly eﬀective text classiﬁer. model selection procedure commonly named literature hyper-parameter optimization. emphasize simplicity approach named micro text classiﬁcation simply µtc. manuscript organized follows. related work presented section section describes contribution depth. section experimental details described. section show extensive experimental comparison approach relevant state-of-the-art methods diﬀerent benchmarks. finally conclusions listed section start describing typical text classiﬁer summarized complex parts firstly input text passed lexical analyzer parses normalizes text outputs list tokens represent input text. lexical analyzer typically includes simple transformation functions like removal diacritic symbols lower casing text also make sophisticated techniques like stemming lemmatization misspelling correction etc. whereas tokens commonly represented words pairs triplets adjacent words general sequences words also possible extend approach sequences characters allowed drop middle words word n-grams obtain skip-grams. usage techniques driven human knowledge particular problem tackled. also worth mention entire process tightly linked input language. secondly output lexical analyzer commonly used create high dimensional vectors token vocabulary corresponding coordinate vector. value coordinate associated weight token. traditional weighting local global statistics tokens popular examples approach tfidf okapi alternatively information measures like entropy commonly used weight terms. many times desirable reduce dimension vector space several techniques used purpose like finally output weighting scheme used create training learned classiﬁer. classiﬁer machine learning algorithm learns instances training detailed training ﬁnite number inputs outputs i.e. function could evaluated element input space. general possible function learns perfectly. consequently good classiﬁer ﬁnds function minimizes error function maximizes score function. perhaps ﬁrst generic text classiﬁer proposed rocchio works generating object prototypes based centroids voronoi partition tfidf vectors. strategy shows eﬀort reduce necessary memory hardware available time. rocchio uses nearest neighbor classiﬁers prototypes perform predictions preprocessing text left expertise user. rocchio baseline study object area long time; case work presented joachims describes probabilistic analysis rocchio algorithm. purpose improving quality text classiﬁcation task cardoso proposes centroids enhance power several typical classiﬁers also cardoso published number datasets various preprocessing stages popular among text classiﬁcation community using allows focusing weighting classiﬁcation algorithms avoiding tackle text processing problem. machine learning used create spam detector. proposed method uses combination features preprocessing steps setup details using lemmatization using stop-list keywords patterns varying length training corpus etc. similar work presented androutsopoulos topic classiﬁcation task presents experimental scheme reuters dataset three machine learning methods also three-term selection functions proposes topic modelling algorithm based latent dirichlet allocation assign topic unlabeled document. also combination expectation-maximization algorithm proposed. another approach text classiﬁcation move focus text processing text classiﬁcation improve term-weighting; successful strategy followed recent works. cummins proposes method based genetic programming determine evaluate several term weighting schemes vector space model. escalante present approach improve performance classical term-weighting schemes using genetic programming. approach outperforms standard schemes based extensive experimental comparison. authors also compare cummins approach recurrent convolutional neural networks produce term-weighting scheme captures semantics text. similarly word embeddings authors represent words based context also skip-grams text representation. experimental results show higher values macro-f comparison state-of-the-art methods. vilares introduce unsupervised approach multilingual sentiment analysis driven syntax-based rules; words weighted based analysis syntax-graphs. authors provide experimental support english spanish german. however support additional language needs implement several rules proper syntax parser. mozetiˇc study eﬀect agreement among human taggers performance sentiment classiﬁers. compare several classiﬁers traditional text normalization vector representation tfidf weighting.they provide tagged datasets european languages; selected benchmarks. section details. author proﬁling another important task related text categorization several advances proposed. authors report approach perform author proﬁling; particular describe best classiﬁer pan’ contest consists distributional word representation based membership class along number text standard text preprocessing recently pan’ current works related user proﬁling presented. case user proﬁling related gender language-region classiﬁcation. aspect linear kernel combination word unigrams character -grams features employed. features selected word n-grams number emojis text document sentiment character ﬂooding finally lexicon important word also employed. approach consists ﬁnding competitive text classiﬁer given task among candidates classiﬁers. text classiﬁer represented parameters determine classiﬁer’s functionality along input dataset. search desired text classiﬁer performed eﬃciently accurately sense ﬁnal classiﬁer competitive concerning best possible classiﬁer deﬁned space classiﬁers. ﬁrst part section describe structure approach state parameters deﬁning conﬁguration space. then deﬁne graph core structure used meta-heuristics implemented good performing text classiﬁer given task. road also describe score function encapsulates functionality classiﬁer provides numerical output necessary maximize eﬃciency classiﬁer. mentioned previously text classiﬁer consists well diﬀerentiated parts. purposes classiﬁer following parts list functions normalize transform input text input tokenizers tokenizer functions transform given text multiset tokens iii) function generates vector multiset tokens; ﬁnally classiﬁer knows assign label given vector. pieces deﬁne {gi} tokenizer functions. deﬁned either function returns simple tokenizer function i.e. tokenizer argument. precisely function g|g| deﬁned; extracts list subsequences simplest setup conﬁguration space grows exponentially number possible transformations tokenizers. thus order best item necessary evaluate entire space; computationally feasible. typical conﬁguration space contain billions conﬁgurations exhaustive evaluation feasible current computers. remain main assumption simple feasible function score slowly varies similar conﬁgurations assume degree locally concaveness sense well-performing local maximum reached using greedy decisions given point. even true general solver algorithm robust enough good approximation even assumption valid degree certainty. induce search properties neighborhood deﬁned neighborhoods describe similar conﬁgurations. matter deﬁne distance function conﬁgurations. first must deﬁne comparison function steps modiﬁed support cross-validation schemes like k-folds bagging provide robust measure performance classiﬁer. details measurement strategies beyond scope manuscript interested reader referenced using combination meta-heuristics. following paragraphs brieﬂy review techniques used solve combinatorial problem proper survey area beyond scope manuscript. however interested reader referred hand core idea behind hill climbing explore conﬁguration’s neighborhood initial setup greedily update best performing conﬁguration process repeated improvement possible improve whole optimization process applying hill climbing procedure best conﬁguration found random search. also memory avoid conﬁguration evaluated twice. summarizing optimization process driven tuple space means training labeled texts iii) optimization algorithm uses score almost optimal conﬁguration section describes general setup used characterize compare method related state-of-the-art. particular deﬁne functions used create space; also detail benchmarks used comparison. experiments intel xeon .ghz threads running centos linux. implemented python. characterize performance compare relevant state selected number popular benchmarks literature; datasets described below. worth mention bias selection benchmarks coming popular international challenges. purpose avoiding over-ﬁtting performed model selection using score -fold cross-validation speciﬁed performance measure table decided cross-validation stage observed over-ﬁtting small datasets like found authorship attribution static train-test partitions perform model selection. brief experimental study eﬀect validation schemes state before framework create text classiﬁers searching best models conﬁguration space. space adjusted particular problem here consider general enough space match disparity knowledge domain large generic conﬁguration space used. could tempting learn domain using information found optimization process; clearly possible. however encouraged take account search process take decisions match particular dataset domain generalization knowledge must curated expert domain. important mention large conﬁguration spaces consume computational time optimized. hand hand-crafted conﬁguration space given problem yield fast processing times; however vast knowledge domain required reach state. case discard possibility discovering knowledge domain take advantage particularities dataset general conﬁguration space provide. allow remove group single hash tags remove htags group htags respectively; identity function lets text unmodiﬁed. format hash introduced twitter words popular along many data sources. contains functions remove group left untouched users host domains text. pattern tackled user popular denote users several social networks; pattern also matches naturally domain part email addresses. tains functions remove left untouched diacritic symbols text. objective reduce composed symbols like ´a¨a~a^a simply well known source errors informal text written languages making hard diacritic symbols skip-grams. skip-grams similar word n-grams allowing skip middle parts. example skip-grams previous example i-the like-red the-car. idea behind family tokenizers capture occurrence related words separated unrelated words. matter instead selecting another tokenizer scheme allow select available tokenizers perform union ﬁnal multisets tokens. instance conﬁguration space considers three word n-grams tokenizers nine character n-grams three skip-grams tokenizers must create vector space. selected small frequency ﬁlters tfidf scheme weight coordinates vector. hand consider sequential list ﬁlters max-ﬁlter min-ﬁlter then select term frequency tfidf weight. maxﬁlter delete tokens surpassing frequency threshold αmax-freq max-freq maximum frequency token collection. consider classiﬁer decide singleton populated linear kernel. well known performs excellently large dimensional input linear kernel also performs well conditions. optimize parameters classiﬁer since pretty interested rest process. classiﬁer liblinear conﬁguration number possible tokenizers also diﬀerent weighting combinations. conﬁguration space contains million conﬁgurations. instance conﬁguration needs close minutes evaluated i.e. sentiment analysis benchmark thousand tweets. therefore exhaustive evaluation conﬁguration space need years. even implementing large distributed cluster process needs much time complete. power computing easily accessible. nonetheless soften problem ﬁnding best model excellent algorithm combinatorial optimization since considers preprocessing step among parts tried collect datasets text without kind preprocessing transformations. possible general case mostly aging datasets; consider following text preparation states style cachopo text classiﬁcation literature myriad datasets performance measures validation schemes. select several prominent popular benchmark conﬁgurations literature; instance select work topic classiﬁcation spam identiﬁcation author proﬁling authorship attribution sentiment analysis. avoid implementation mistakes directly reported performances literature; nevertheless restricted compare circumstances. table describes language number classes dataset; also describes kind validation; particular consider validation schemes -fold cross-validation static train-test partition speciﬁed sizes. diversity benchmarks validation schemes help prove functionality approach many circumstances. reuters- used collection text categorization research. documents manually labeled personnel reuters ltd. newsgroup dataset popular text classiﬁcation area contains news related diﬀerent topics originally collected lang. webkb dataset contains university webpages. dataset composed webpages classiﬁed seven diﬀerent categories student faculty staﬀ department course project other. four popular classes experiments. cade dataset another collection webpages speciﬁcally brazilian webpages classiﬁed human experts. collection contains total classes e.g. services sports science education news among others. collection emails written english languages classiﬁed spam non-spam messages; collection contains following datasets ling-spam dataset also spam dataset. contest several tasks author identiﬁcation author proﬁling. author proﬁling task forensic linguistics problem consisnts detecting gender author pan’ identiﬁcation task replaced task determining language variety writter also number diﬀerent languages increased four. listed table oﬃcial dataset undisclosed algorithm must evaluated tira evaluation platform. authorship attribution datasets http//www.daviddlewis.com/resources/testcollections/reuters/ http//people.csail.mit.edu/jrennie/newsgroups http//www.cs.cmu.edu/~webkb/ https//tira.io diﬀerent types topics business poetry travel cricket. objective datasets determine authorship document. multilingual sentiment analysis tweets diﬀerent languages arabic german portuguese russian swedish spanish. purpose datasets classifying tweet negative neutral positive polarity. detailed description datasets provided table found particularities dataset like written language number documents kind evaluation number classes performance measure optimized µtc. section dedicated comparing work relevant state-of-theart methods described above. also characterize generalization power terms validation scheme. ﬁrst task analyzed authorship attribution table shows macrof accuracy performances authorship attribution benchmarks. here compare term-weighting schemes pre-processing stage µtc’s input all-terms; others stemmed stage. best performing classiﬁers created except alternatives perform better. case business escalante performs slightly better terms accuracy. please notice bussiness among smaller dataset tested performance produced number exemplars alternative schemes take advantage samples compute better weights. table results pan’ competition presented. according contest report best results achieved pastor santosh meina. benchmark produces best result average cases. ﬁne-grained comparison meina surpasses gender identiﬁcation english. based term-weighting scheme beyond scope contribution; interested reader referenced plain described manuscript achieves accuracies respectively gender variety identiﬁcation. joint prediction classes achieves accuracy score values locate plain eighth position oﬃcial rank experiments considered several news datasets. approach reaches best results datasets exception news- news- reaches second third best performance. sentiment analysis task compared datasets reported moreover reported results obtained bmsa approach bmsa method multilingual polarity classiﬁcation considered baseline build complex approaches. important note dataset reported approaches bmsa subset speciﬁed table e.g. arabic language used german used dataset finally table shows results spam classiﬁcation task. here seen best results macro-f measure obtained approach µtc; nevertheless best results accuracy score achieved androutsopoulos except ling-spam dataset reached best performance. here pre-processing step analyzed; this table shows diﬀerent performances correspond news benchmark various stages normalization process used inputs µtc. found achieves high performances without using additional sophisticated pre-processing steps almost them language dependent. instance using text points performance using stemmed collection. human intervention prepare input text barely needed without signiﬁcantly reducing performance practice. alternatively methods like escalante cachopo need stemmed version dataset achieve optimal performance i.e. accuracy values ranging details table score function leads model selection procedure fulﬁll requirements task. process necessary determine precise quality’s measure needed e.g. macro-f accuracy. learning algorithm necessary protect score validation schemes avoid latent overﬁtting. matter consider validation schemes stratiﬁed k-folds random binary partition size train learn choose right criteria review predicted actual performance validation schemes. predicted macro-f performance achieved model selection procedure using mentioned validation schemes. actual performance obtained directly evaluating gold-standard collection. figure shows performance small databases. stability k-folds terms predicted actual performance supported figures also true larger datasets like depicted figures ﬁgures show even achieves almost optimal actual performance; even predicted performance times better larger values. hand binary partition method prone overﬁt especially small datasets performance nfl; please note yields competitive performances i.e. higher macro-f accuracy. performances pretty higher achieved alternatives however yields actual performances contrasting perfect predicted performance. similar case happens business dataset figure case actual performance relatively stable. behaviour binary partition larger dataset less prone overﬁt like figures illustrate. nonetheless case figure shows overﬁtting issue still latent; however barely aﬀects actual performance since score function applied large enough test set. rule thumb safe k-fold cross-validation compute score model selection stage. encourage small values since actual performance relatively stable computational cost kept low. please notice k-folds procedure introduces factor computational cost score algorithms solve underlying combinatorial optimization problem need evaluate considerable number conﬁgurations achieve good results. cases number samples figure ﬁnal performance medium sized datasets function validation’s stage score function µtc; consider validation schemes purpose k-folds random binary partitions sizes actual performance illustrated experiments corresponding binary partition performances figures please remember stage selecting proper conﬁguration subsequent step ﬁnal work minimalistic global approach text classiﬁcation proposed. moreover approach evaluated broad range classiﬁcation tasks topic classiﬁcation sentiment analysis spam detection user proﬁling; matter total databases related tasks employed. order evaluate performance approach results obtained task compared state-of-the-art methods related task. additionally analyze eﬀect pre-processing stage. experiment observed approach competitive alternative methods even using text input without penalty performance; therefore possible create text classiﬁers little knowledge natural language processing machine learning techniques. also studied simple strategies avoid overﬁtting problem; consider using k-fold cross-validation scheme binary partition perform model selection. based experimental observation properly dataset speedup construction step using small values cross-validation schemes small training sets binary random partitions. also found perform k-folds preferred validation scheme small medium sized datasets large datasets binary partition scheme without signiﬁcant reduction performance also keeping cost entire process low.", "year": 2017}