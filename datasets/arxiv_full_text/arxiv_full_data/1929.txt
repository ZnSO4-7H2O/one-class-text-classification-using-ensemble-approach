{"title": "Inferring and Executing Programs for Visual Reasoning", "tag": ["cs.CV", "cs.CL", "cs.LG"], "abstract": "Existing methods for visual reasoning attempt to directly map inputs to outputs using black-box architectures without explicitly modeling the underlying reasoning processes. As a result, these black-box models often learn to exploit biases in the data rather than learning to perform visual reasoning. Inspired by module networks, this paper proposes a model for visual reasoning that consists of a program generator that constructs an explicit representation of the reasoning process to be performed, and an execution engine that executes the resulting program to produce an answer. Both the program generator and the execution engine are implemented by neural networks, and are trained using a combination of backpropagation and REINFORCE. Using the CLEVR benchmark for visual reasoning, we show that our model significantly outperforms strong baselines and generalizes better in a variety of settings.", "text": "figure compositional reasoning critical component needed understanding complex visual scenes encountered applications robotic navigation autonomous driving surveillance. current models fail reasoning paper argue successfully perform complex reasoning tasks might necessary explicitly incorporate compositional reasoning model structure. speciﬁcally investigate model visual question answering consists parts program generator execution engine. program generator reads question produces plan program answering question composing functions function dictionary. execution engine implements function using small neural module executes resulting module network image produce answer. program generator modules execution engine neural networks generic architectures; trained separately ground-truth programs available jointly end-to-end fashion. existing methods visual reasoning attempt directly inputs outputs using black-box architectures without explicitly modeling underlying reasoning processes. result black-box models often learn exploit biases data rather learning perform visual reasoning. inspired module networks paper proposes model visual reasoning consists program generator constructs explicit representation reasoning process performed execution engine executes resulting program produce answer. program generator execution engine implemented neural networks trained using combination backpropagation reinforce. using clevr benchmark visual reasoning show model signiﬁcantly outperforms strong baselines generalizes better variety settings. many applications computer-vision systems need answer sophisticated queries reasoning visual world deal novel object interactions object-attribute combinations visual reasoning needs compositional without ever seen person touching bike model able understand phrase putting together understanding person bike touching. compositional reasoning hallmark human intelligence allows people solve plethora problems using limited basic skills contrast modern approaches visual recognition learn mapping directly inputs outputs; explicitly formulate execute compositional plans. direct input-output mapping works well classifying images detecting objects small ﬁxed categories. however fails outperform strong baselines tasks require model understand exponentially large space objects attributes actions interactions visual question answering instead models learn direct input-output mappings tend rely hand-tuned program generator based syntactic parsing hand-engineered modules. contrast model rely heuristics deﬁne function vocabulary universal module architecture hand learning everything else. evaluate model recently released clevr dataset proven challenging stateof-the-art models. clevr dataset contains ground-truth programs describe compositional reasoning required answer given questions. small amount reasoning supervision model outperforms state-of-the-art non-compositional models percentage points clevr. also show model’s compositional nature allows generalize novel questions composing modules ways seen training. though model works well algorithmically generated questions clevr true test whether answer questions asked humans wild. collect dataset human-posed free-form natural language questions clevr images. many questions out-of-vocabulary words require reasoning skills absent model’s repertoire. nevertheless ﬁnetuned dataset without additional program supervision model learns compose modules novel intuitive ways best answer types questions. result interpretable mapping freeform natural language programs point improvement accuracy best competing models. visual question answering popular proxy task gauging quality visual reasoning systems like clevr dataset benchmark datasets typically comprise questions images associated answers questions answers generally posed natural language. many systems employ similar architecture combine rnn-based embedding question convolutional network-based embedding image classiﬁcation model possible answers. recent work questioned whether systems capable developing visual reasoning capabilities simple baseline models found perform competitively benchmarks exploiting biases data experiments clevr designed control biases revealed current systems learn reason spatial relationships learn disentangled representations model aims address problems explicitly constructing intermediate program deﬁnes reasoning process required answer question. show model succeeds several kinds reasoning models fail. reasoning-augmented models components neural network models facilitate development reasoning processes models. example models neural turing machines memory networks stack-augmented recurrent networks explicit memory components neural networks facilitate learning reasoning processes involve long-term memory. long-term memory likely crucial component intelligence prerequisite reasoning especially kind reasoning required answering questions images. therefore consider memory-augmented models study. reasoningaugmented models syntactic parse question determine architecture network ﬁnal network composed trained neural modules execute program produced parser. main difference models existing module networks replace hand-designed off-the-shelf syntactic parsers perform poorly complex questions clevr learnt program generator adapt task hand. semantic parsers attempt natural language sentences logical forms. often goal answer natural language questions using knowledge base recent approaches semantic parsing involve learnt programmer however semantics program execution engine ﬁxed known priori learn program generator execution engine. program-induction methods learn programs input-output pairs ﬁtting parameters neural network predict output corresponds particular input value. models take form feedforward scoring function operators domain-speciﬁc language used guide program search recurrent network decodes vectorial program representation actual program recurrent networks incorporate compositional structure allows learn programs combining previously learned sub-programs approach differs prior work program induction type input-output pairs used domain-speciﬁc language implemented. prior work neural program interpreters considers simple algorithms sorting list integers; contrast consider inputs comprise image associated question program induction approaches also assume knowledge low-level operators arithmetic operations. contrast learnt execution engine assume minimal prior knowledge. develop learnable compositional model visual question answering. model takes input image visual question image. model selects answer question ﬁxed possible answers. internally model predicts program representing reasoning steps required answer question. model executes predicted program image producing distribution answers. organize system components program generator predicts programs questions execution engine executes program image predict answer program generator execution engine neural networks learned data. contrast prior work manually design heuristics generating executing programs. present learning procedures settings ground-truth programs available training settings without ground-truth programs. practice models need program supervision training program generator requires programs order learn generalize programs like programming languages programs deﬁned syntax giving rules building valid programs semantics deﬁning behavior valid programs. focus learning semantics ﬁxed syntax. concretely syntax pre-specifying functions ﬁxed arity interested visual question answering include vocabulary special constant scene represents visual features image. represent valid programs syntax trees node contains function node many children arity function program generator program generator predicts programs natural-language questions represented sequence words. preﬁx traversal serialize syntax tree non-sequential discrete structure sequence functions. allows implement program generator using standard lstm sequence-tosequence model; details. system overview. program generator figure sequence-to-sequence model inputs question sequence words outputs program sequence functions sequence interpreted preﬁx traversal program’s abstract syntax tree. execution engine executes program image assembling neural module network mirroring structure predicted program. tions converted syntax tree; straightforward since arity function known. generated sequences correspond preﬁx traversals tree. sequence short sequence scene constants. sequence long unused functions discarded. given predicted program input image execution engine executes program image predict answer execution engine implemented using neural module network program used assemble question-speciﬁc neural network composed modules. function execution engine maintains neural network module given program execution engine creates neural network mapping function corresponding module order deﬁned program outputs child modules used input corresponding parent module. modules generic architecture contrast module arity receives features maps shape c×h×w produces feature shape c×h×w unary module standard residual block convolutional layers. binary modules concatenate inputs along channel dimension project channels using convolution feed result residual block. scene module takes visual features input pretrained imagenet passes features four table question answering accuracy clevr dataset baseline models humans three variants model. strongly supervised variant model uses ground-truth programs training whereas semi-supervised variants ground-truth programs respectively. †human performance measured subset clevr questions. using architecture modules ensures every valid program corresponds valid neural network inputs visual features image outputs feature shape c×h×w ﬁnal feature ﬂattened passed multilayer perceptron classiﬁer outputs distribution possible answers. given dataset containing tuples ground truth programs train program generator execution engine supervised manner. speciﬁcally pairs questions corresponding programs train program generator amounts training standard sequence-to-sequence model; triplets image program answer train execution engine using backpropagation compute required gradients annotating ground-truth programs free-form natural language questions expensive practice ground-truth programs. address problem train program generator execution engine jointly triples without ground-truth programs. however cannot backpropagate argmax operations program generator. instead replace argmaxes sampling reinforce estimate gradients outputs program generator; reward outputs negative zero-one loss execution engine moving-average baseline. practice joint training using reinforce difﬁcult program generator needs produce right program without understanding functions mean execution engine produce right answer programs accurately implement question asked. propose practical semi-supervised learning approach. ﬁrst small ground-truth programs train program generator program generator train execution engine using predicted programs large dataset triples. finally reinforce jointly ﬁnetune program generator execution engine. crucially ground-truth programs used train initial program generator. evaluate model recent clevr dataset standard methods perform poorly dataset showing challenging benchmark. questions equipped ground-truth programs allowing experiments varying amounts supervision. ﬁrst perform experiments using strong supervision form ground-truth programs. show strongly supervised setting combination program generator execution engine works much better clevr alternative methods. next show strong performance maintained small number ground-truth programs capture fraction question diversity used training. finally evaluate ability models perform compositional generalization well generalization free-form questions posed humans. code reproducing results experiments available https//github.com/ facebookresearch/clevr-iep. lstm similar questions processed learned word embeddings followed word-level lstm ﬁnal lstm hidden state passed multi-layer perceptron predicts distribution answers. method uses image information figure visualizations norm gradient predicted answer scores respect ﬁnal feature map. left right question adds module program; module underlined question. visualizations illustrate objects model attends performing reasoning steps question answering. images validation set. figure accuracy predicted programs answers vary number ground-truth programs. blue green give accuracy joint ﬁnetuning; dashed line shows accuracy strongly-supervised model. cnn+lstm images questions encoded using convolutional network features ﬁnal lstm hidden states respectively. features concatenated passed predicts answer distribution. cnn+lstm+sa questions images encoded using lstm above combined using rounds soft spatial attention; linear transform attention output predicts answer. cnn+lstm+sa+mlp replaces linear transform better comparison methods. models similar neural module networks unfortunately neural module networks hand-engineered off-the-shelf parser produce programs parser fails complex questions clevr therefore unable include module networks experiments. figure question answering accuracy clevr-cogent dataset train models condition test condition condition ﬁnetune models condition using images questions test conditions. model uses programs training condition programs ﬁnetuning condition bottom investigate effects using different amounts data ﬁnetuning condition show overall accuracy well accuracy color-query shape-query questions. tions clevr train program generator execution engine separately. question answering accuracy resulting model clevr shown table results show using strong supervision model achieve near-perfect accuracy clevr practical scenarios ground-truth programs available questions. semi-supervised training process described section determine many ground-truth programs needed match fully supervised models. first program generator trained supervised manner using small number questions ground-truth programs; next execution engine trained clevr questions using predicted rather ground-truth programs. finally components jointly ﬁnetuned without ground-truth programs. table shows accuracy semi-supervised models trained ground-truth programs results show ground-truth programs sufﬁcient train model performs almost fully supervised model strong performance program generator simply remembering programs total number unique programs clevr approximately implies observing small fraction possible programs model able understand underlying structure clevr questions understanding generalize questions. figure analyzes accuracy predicted programs ﬁnal answer vary number groundtruth programs used. measure accuracy program generator deserializing function sequence produced program generator marking correct matches ground-truth program exactly. results show ground-truth programs program generator achieves near perfect accuracy ﬁnal answer accuracy almost good strongly-supervised training. training execution engine using predicted programs program generator instead groundtruth programs leads loss points accuracy loss mitigated joint ﬁnetuning. obtain additional insight modules execution engine learned visualized parts image used answer different questions; figure speciﬁcally ﬁgure displays norm gradient predicted answer scores respect ﬁnal feature map. visualization reveals several important aspects model. first clearly attends correct objects even complicated referring expressions involving spatial relationships intersection union constraints etc. second examples show changing single module results drastic changes predicted answer model attention demonstrating individual modules fact perform intended functions. modules learn specialized functions localization operations without explicit supervision outputs. figure examples long questions program answer predicted incorrectly model trained short questions program answer correctly predicted model ﬁnetuned long questions. image show ground-truth question program length; below show manual english translation predicted program answer ﬁnetuning long questions. table question answering accuracy short long clevr questions. left columns models trained short questions; model uses ground-truth short programs. right columns models trained short long questions. model trained short questions ﬁnetuned entire dataset; ground-truth programs used ﬁnetuning. johnson proposed clevr-cogent dataset investigating ability models perform compositional generalization. dataset contains data different conditions condition cubes gray blue brown yellow cylinders green purple cyan; condition cubes cylinders swap color palettes. johnson found models trained data condition performed poorly data condition suggesting models well capable generalizing conditions. performed experiments model clevrcogent figure report accuracy semisupervised variant model trained data condition evaluated data condition although resulting model performs better baseline methods condition still appears suffer problems identiﬁed detailed analysis results revealed model outperform cnn+lstm+sa baseline questions object’s shape color. surprising model never sees cubes incentive learn attribute refers color shape. also performed experiments used small amount training data without ground-truth programs condition ﬁnetuning. varied amount data condition available ﬁnetuning. shown figure model learns attribute combinations questions outperforms similarly trained baselines across board. believe model’s compositional nature allows quickly learn semantics attributes little training data. tuning program generator execution engine combined short long questions without groundtruth programs. pinpoint problem short-program bias program generator leave execution engine ﬁxed ﬁnetuning; used compute reinforce rewards program generator. ﬁnetuning model substantially outperforms baseline models trained entire dataset; table experiments section showed relatively ground-truth programs required train model effectively. large number unique programs clevr impossible capture possible programs small ground-truth programs; however synthetic nature clevr questions possible small number programs could cover possible program structures. real-world scenarios models able generalize questions novel program structures without observing associated ground-truth programs. test this divide clevr questions categories based ground-truth programs short long. clevr questions divided question families questions family share program structure. question short question family mean program length less otherwise long. train program generator execution engine short questions semi-supervised manner using ground-truth short programs test resulting model short long questions. experiment tests ability model generalize short long chains reasoning. results shown table results show evaluated long questions model trained short questions underperforms cnn+lstm+sa model trained set. presumably result program generator learning bias towards short programs. indeed figure shows program generator produces programs refer right objects short. fact questions clevr benchmark generated algorithmically favor approaches others. particular natural language tends ambiguous algorithmically generated questions. performed experiment assess extent models trained clevr ﬁnetuned answer human questions. collected dataset naturallanguage questions answers clevr images. clevr-humans dataset. inspired workers amazon mechanical turk asked write questions clevr images would hard smart robot answer; workers primed questions clevr restricted answers clevr. ﬁltered questions asking three workers answer question removed questions majority workers could correctly answer. collected question image; ﬁltering obtained training validation test questions clevr images. data available ﬁrst author’s website. human questions challenging synthetic clevr questions exhibit linguistic variety. unlike existing datasets however clevr-humans questions require common-sense knowledge focus entirely visual reasoning abilities makes good testbed evaluating reasoning. figure shows example human questions. questions rewordings synthetic clevr questions; others answerable using basic functions clevr potentially altered semantics skills. example people spatial relationships left right etc. differently meanings clevr questions. finally questions require skills needed answering synthetic questions. figure examples questions clevr-humans dataset along predicted programs answers model. question words appear clevr questions underlined. predicted programs exactly match semantics question programs closely match question semantics programs appear unrelated question results. train model clevr ﬁnetune program generator clevr-humans training adapt additional linguistic variety; adapt execution engine limited quantity data. ground-truth programs available ﬁnetuning. embeddings sequence-to-sequence model question words appear clevr synthetic questions initialized randomly ﬁnetuning. ﬁnetuning model learns reuse reasoning skills already mastered order answer linguistically diverse natural-language questions. shown figure learns novel words known modules. human questions expressible using clevr functions model still learns produce reasonable programs closely approximating question’s intent. model often fails questions cannot reasonably approximated using model’s module inventory rightmost example figure quantitatively results table show model outperforms baselines clevr-humans test without ﬁnetuning. results show model able generalize novel scenes questions even infer programs free-form human questions using learned modules. whilst results encouraging still many questions cannot reasonably approximated using ﬁxed modules. example question what color object unique shape? requires model identify unique shapes module currently available. adding modules model straightforward generic module design automatically identifying learning modules without program supervision still open problem. path forward design turing-complete modules; would allow programs expressed without learning modules. example adding ternary operators loops question what color object unique shape? answered looping shapes counting objects shape returning count one. control-ﬂow operators could incorporated framework example loop could apply module input aggregate results. emphasize learning programs limited supervision open research challenge leave future work. paper long line work incorporating symbolic representations machine learning models shown explicit program representations make easier compose programs answer novel questions images. generic program representation learnable program generator universal design modules makes model much ﬂexible neural module networks thus easily extensible problems domains. experiments program generator lstm sequence-to-sequence model comprises learned recurrent neural networks encoder receives naturallanguage question sequence words summarizes question ﬁxed-length vector; decoder receives ﬁxed-length vector input produces predicted program sequence functions. encoder decoder share weights. encoder converts discrete words input question vectors dimension using learned word embedding layer; resulting sequence vectors processed two-layer lstm using hidden units layer. hidden state second lstm layer ﬁnal timestep used input decoder network. timestep decoder network receives function previous timestep output encoder network. function converted -dimensional vector learned embedding layer concatenated decoder output; resulting sequence vectors processed two-layer lstm hidden units layer. timestep hidden state second lstm layer used compute distribution possible functions using linear projection. supervised training program generator adam learning rate batch size train maximum iterations employing early stopping based validation accuracy. execution engine uses neural module network compile custom neural network architecture based predicted program program generator. input image ﬁrst resized pixels passed convolutional network extract image features; architecture network shown table predicted program takes form syntax tree; leaves tree scene functions receive visual input convolutional network. ground-truth programs root tree function corresponding question types clevr dataset count query shape. predicted programs root program tree could principle function practice trained models tend table network architecture convolutional network used execution engine. resnet- model pretrained imagenet remains ﬁxed execution engine trained. output network passed modules representing scene nodes program. function predicted program associated module receives either inputs; association gives rise custom neural network architecture corresponding program. previous implementations neural module networks used different architectures module type customizing module architecture function module perform. contrast generic design modules module small residual block exact architectures used unary binary modules shown tables respectively. initial experiments used batch normalization convolution modules found prevented model converging. since image minibatch different program implementation execution engine iterates program minibatch one; result module batch size training leading poor convergence modules contain batch normalization. training execution engine alone train using adam learning rate batch size train maximum iterations employ early stopping based validation accuracy. joint training jointly training program generator execution engine train using adam learning rate batch size train maximum iterations employing early stopping based validation accuracy. moving average baseline reduce variance gradients estimated using reinforce; particular baseline exponentially decaying moving average past rewards decay factor table architecture unary modules used execution engine. modules receive output module except special scene module instead receives input convolutional network architecture binary modules execution table engine. modules receive output modules. binary modules system intersect union equal size equal color equal material equal shape greater than. reimplement baselines used lstm. lstm baseline receives input question sequence words converts words dimensional vectors using learned word embedding layer processes resulting sequence two-layer lstm hidden units layer. lstm hidden state second layer ﬁnal timestep passed hidden layers units each relu nonlinearities layer. cnn+lstm model encodes question using learned -dimensional word embeddings followed twolayer lstm hidden units layer. image encoded using architecture execution engine shown table encoded question image features concatenated passed two-layer hidden layers units each relu nonlinearities layer. cnn+lstm+sa. question image encoded exactly manner cnn+lstm baseline. however rather concatenating representations consecutive stacked attention layers hidden dimension units; results -dimensional vector linear layer predict answer scores. cnn+lstm+ however output ﬁnal stacked attention module two-layer hidden layers units each relu nonlinearities layer. since models terminate predict ﬁnal answer distribution cnn+lstm+sa+mlp gives fair comparison methods. minor architectural change replacing linear transform signiﬁcantly improves performance clevr dataset cnn+lstm+sa achieves overall accuracy cnn+lstm+sa+mlp achieves much gain comes improved performance comparison questions; example shape comparison questions cnn+lstm+sa achieves accuracy cnn+lstm+sa+mlp achieves training. baselines trained using adam learning rate batch size maximum iterations employing early stopping based validation accuracy. closest method andreas dynamic neural module networks ﬁrst perform dependency parse sentence; heuristics used generate layout fragments dependency parse. fragments heuristically combined giving candidate layouts; ﬁnal network layout selected candidates learned reranking step. unfortunately found parser used questions perform well longer questions clevr. table show random questions clevr training together layout fragtable examples random questions clevr training parsed using code andreas parsing questions dataset parse gives layout fragments separated semicolons; fragments combined produce candidate layouts module network. parser fails produces default fallback fragment ments computed using parser many questions parser fails falling back fragment happens resulting module network respect structure question all. questions parser fall back default layout resulting layout fragments often fail capture elements question; example parsing question material purple cylinder? none resulting fragments mention cylinder.", "year": 2017}