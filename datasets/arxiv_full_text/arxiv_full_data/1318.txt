{"title": "DeepSentiBank: Visual Sentiment Concept Classification with Deep  Convolutional Neural Networks", "tag": ["cs.CV", "cs.LG", "cs.MM", "cs.NE", "H.3.3"], "abstract": "This paper introduces a visual sentiment concept classification method based on deep convolutional neural networks (CNNs). The visual sentiment concepts are adjective noun pairs (ANPs) automatically discovered from the tags of web photos, and can be utilized as effective statistical cues for detecting emotions depicted in the images. Nearly one million Flickr images tagged with these ANPs are downloaded to train the classifiers of the concepts. We adopt the popular model of deep convolutional neural networks which recently shows great performance improvement on classifying large-scale web-based image dataset such as ImageNet. Our deep CNNs model is trained based on Caffe, a newly developed deep learning framework. To deal with the biased training data which only contains images with strong sentiment and to prevent overfitting, we initialize the model with the model weights trained from ImageNet. Performance evaluation shows the newly trained deep CNNs model SentiBank 2.0 (or called DeepSentiBank) is significantly improved in both annotation accuracy and retrieval performance, compared to its predecessors which mainly use binary SVM classification models.", "text": "visual features high-level sentiment. therefore borth proposed tractable approach models sentiment related visual concepts mid-level representation gap. concepts adjective noun pairs happy beautiful combine sentimental strength adjectives detectability nouns. though concepts directly express emotions sentiments discovered based strong co-occurrence relationships emotion tags photos thus useful eﬀective statistical cues detecting emotions depicted images. binary classiﬁers anps trained whole images denoted sentibank later chen improve classiﬁers considering object-based concept localization leveraging semantic similarity among concepts. dataset training visual sentiment concepts involves thousands categories consisting million images downloaded flickr. recently krizhevsky show deep convolutional neural networks able achieve great classiﬁcation performance improvement eﬃciency similar datasets imagenet model much larger learning capacity controlled varying network depth breadth compared learning methods. strong assumptions stationarity statistics locality pixel dependencies nature images also mostly correct. cnns also easier train standard feedforward neural networks layers similar size since much fewer connections parameters slightly degraded theoretic performance. cnns also capability incorporate model weights learned general dataset applied case transferring model learned imagenet specialized dataset like sentibank.. work introduces sentibank called deepsentibank visual sentiment concepts classiﬁcation model trained caﬀe based deep learning framework. adopt similar cnns architecture used training ilsvrc dataset. initializing model model weights trained imagenet provides much better performance training visual sentiments dataset alone. performance evaluation comparisons predecessors show newly trained deepsentibank signiﬁcantly improves annotation accuracy classiﬁcation well moderately improves retrieval performance. abstract paper introduces visual sentiment concept classiﬁcation method based deep convolutional neural networks visual sentiment concepts adjective noun pairs automatically discovered tags photos utilized eﬀective statistical cues detecting emotions depicted images. nearly million flickr images tagged anps downloaded train classiﬁers concepts. adopt popular model deep convolutional neural networks recently shows great performance improvement classifying largescale web-based image dataset imagenet. deep cnns model trained based caﬀe newly developed deep learning framework. deal biased training data contains images strong sentiment prevent overﬁtting initialize model model weights trained imagenet. performance evaluation shows newly trained deep cnns model sentibank signiﬁcantly improved annotation accuracy retrieval performance compared predecessors mainly binary classiﬁcation models. explosive growth social media online visual content motivated research large-scale social multimedia analysis. among research eﬀorts understanding emotion sentiment visual media content attracted increasing attention research practical applications.. images videos depicting strong sentiments strengthen opinion conveyed content eﬀectively inﬂuence audience. understanding sentiment expressed visual content greatly beneﬁt social media communication enable broad applications education advertisement entertainment. modeling generic visual concepts studied extensively computer vision modeling adjectives correlated visual sentiments like amazing remains diﬃcult impossible aﬀective low-level work sentiment analysis based textual information sentiment models demonstrated useful various applications including human behavior prediction business political science compared text-based sentiment analysis modeling sentiment based images much less studied. relevant work proposed design largescale visual sentiment ontology based adjective-noun pairs chen improve model considering object-based concept localization leveraging semantic similarity among concepts. concept modeling widely studied multimedia computer vision concepts modeled mostly objects scenes activities work trying solve grained recognition task categories usually organized hierarchical structure. also work trying model non-conventional concepts properties images image aesthetic quality memorability interestingness aﬀection/emotions models usually trained layer lacking learning methods. deep convolutional networks long studied computer vision. successful results digit recognition using supervised back-propagation networks achieved early research. recently similar networks applied large benchmark datasets consisting million images imagenet competition-winning results learned deep representations transferred across tasks. extensively studied unsupervised setting however models convolutional networks limited relatively small datasets cifar mnist achieved modest success sermanet propose unsupervised pre-training followed supervised ﬁne-tuning solve problem insuﬃcient training data. supervised pretraining approach using concept-bank paradigm also proven successful computer vision multimedia settings. learns features large-scale data supervised setting transfers diﬀerent tasks diﬀerent labels. recently girshick shows supervised pre-training large dataset followed domain-adaptive ﬁne-tuning smaller dataset eﬃcient paradigm scarce data. analysis emotion aﬀect sentiment visual content become exciting area multimedia community allowing build applications brand monitoring advertising opinion mining. create corpora sentiment analysis visual content stimulate innovative research challenging issue database constructed borth database contains visual sentiment ontology consisting adjective noun pairs sentibank trained visual concept detectors providing mid-level representation sentiment associated training images acquired flickr. construction founded psychological research data-driven discovery emotions deﬁned plutchik’s theory images videos retrieved flickr youtube respectively extract concurrent tags. adjectives nouns used form anps beautiful ﬂowers eyes. sentibank trained images tagged anps. dataset database contains flickr images training testing classiﬁers sentibank images tagged downloaded resulting million images anps. train visual sentiment concept classiﬁers ﬁrst ﬁlter anps associated less images. anps images left ﬁltering. images randomly selected testing others used training ensuring least training images anp. prevent bias test training image test image pair associated must share publisher flickr. tags flickr users used labels image. note labels suﬀer incompleteness noisiness i.e. true labels annotated sometimes falsely assigned labels also. however huge amount annotation tasks. labels thus refer pseudo ground truth. also build subset compare retrieval performance diﬀerent models. subset contains images associated nouns namely dress face ﬂower food. nouns frequently tagged social multimedia also associated diverse adjectives form large anps training corresponding subset full training set. test however contains manually annotated images positive negative. retrieval performance evaluated average precision ranking result test images anp. dataset compare deepsentibank earlier version sentibank using object-based localization called sentibank caﬀe deep learning framework developed taking full account cleanliness readability speed. created active development berkeley vision learning center community contributors. caﬀe released clause license using caﬀe deep learning programming multiple advantages. clean architecture enables rapid deployment. networks speciﬁed simple conﬁg ﬁles hardcoded parameters code. switching simple setting models trained machine used commodity clusters. architecture describe overall architecture deep convolutional neural networks training visual sentiment concept classiﬁcation model sentibank deepsentibank. architecture mostly follows depicted figure contains eight main layers weights; ﬁrst convolutional three fullyconnected. output last fully-connected layer -way softmax produces distribution class labels. network maximizes average across training instances log-probability correct label prediction distribution multinomial logistic regression. kernels second layers connected half kernel maps previous layer. kernels third convolutional layer connected kernel maps second layer. neurons fullyconnected layers connected neurons previous layer. following rectiﬁed linear units non-linearity applied output every convolutional fully-connected layer. overlapping max-pooling layers follow ﬁrst second ﬁfth relu layers pooling layer consists grid pooling units spaced pixels apart summarizing neighborhood size centered location pooling unit. local response normalization layers http//caffe.berkeleyvision.org/ activity neuron computed maxpooling runs adjacent kernel maps spatial position total number kernels layer. constants dropout layers applied ﬁrst fully-connected layers. input/output data size layer shape layer shown table training test images ﬁrst normalized without keeping aspect ratio. prevent overﬁtting apply data augmentation consists generating image translations horizontal reﬂections. extracting random patches images training network extracted patches. ﬁrst convolutional layer ﬁlters input image kernels size stride pixels. second convolutional layer takes input output ﬁrst convolutional layer ﬁlters kernels size third fourth ﬁfth convolutional layers connected another without pooling normalization. third convolutional layer kernels size connected outputs second convolutional layer. fourth convolutional layer kernels size ﬁfth convolutional layer kernels size fully-connected layers neurons each. learning details regression objective minimized stochastic gradient descent batch size examples momentum weight decay small weight decay regularizer also reduces model’s training error. insuﬃcient data bias images strong sentiment training dataset suﬀer overﬁtting. since dataset domain imagenet promising ﬁne-tuning. initialized weights model trained ilsvrc except layer. pre-trained model downloaded http//caffe.berkeleyvision.org/getting_ pretrained_models.html. learning rate initialized regarding full forward-backward pass batch iteration total iterations divide learning rate every iterations comparison also train similar model without ﬁne-tuning. initialize weights layer zero-mean gaussian distribution standard deviation initialize neuron biases second fourth ﬁfth convolutional layers well fullyconnected hidden layers constant remaining layers constant learning rate initialized testing center crop test images apply forward propagation trained model weights softmax predicted probability concept. experiment done single server machine -core dual intel processor memory nvidia gpu. training images takes days testing test images takes minutes. maximum memory used storing data takes disk space. performance comparisons annotation accuracy evaluated full test anps mentioned section measured top-k accuracy percentage images pseudo ground truth label detected concepts. accuracies anps computed compared among ﬁne-tuned deep cnns model deep cnns model without ﬁne-tuning sentibank overall accuracies listed table diﬀerent genetic visual concepts visual sentiment concepts abstract terrible crime strong community. anps usually classiﬁcation performance meaningless included classiﬁers library generating mid-level sentiment related features. thus important compare performances anps acceptable detectability. similar approach select anps ranked accuracy. note diﬀerent approach produce diﬀerent subsets. overall accuracies subsets also shown table figure shows curve ranked top- accuracy subset. according table ﬁgure clear cnns-based approaches greatly outperform based approach much performance gain top- accuracy top- top-. fine-tuned model also better without ﬁne-tuning. figure shows examples detected concepts test images ﬁne-tuned model. shows despite serious problem incomplete incorrect labels dataset detected concepts still accurate. since pseudo ground truth labels correct thus top- top- accuracies appropriate top- accuracy. also realize important reason performance boost based sentibank trains binary classiﬁers rather general multi-label classiﬁcation approach. binary classiﬁcation setting suitable retrieval instead annotation. thus next section evaluate performance deepsentibank terms image retrieval. figure examples concepts detected test images ﬁne-tuned deepsentibank model. concepts pseudo ground truth concepts. credits images ©mauricio gelfuso wright frakara melanie bateman photographs-n-memories matt swanson twan goossens debras erin nichols yael levine years later... anda stavri flickr. developed deep learning framework. deal biased training data contains images strong sentiment prevent overﬁtting initialize model model weights trained imagenet. performance evaluation shows newly trained deep cnns model deepsentibank signiﬁcantly better annotation retrieval compared previous work using independent binary classiﬁcation models. future incorporate concept localization deep cnns model improve network structure leveraging concept relations. high performance boost also help improve applications built sentibank assistive comment robot twitter sentiment prediction applications sentiment-aware image editing. breuel shih-fu chang. large-scale visual sentiment ontology detectors using adjective noun pairs. proceedings international conference multimedia. hong-yuan mark liao shih-fu chang. predicting viewer aﬀective comments based image content social media. proceedings international conference multimedia retrieval. deng berg satheesh khosla fei-fei. large scale visual recognition challenge. www. image-net. org/challenges/lsvrc/ retrieval performance evaluated subset anps mentioned section apply models trained sentibank deepsentibank test set. test images ranked estimated probability anp. performance measured average precision mean noun categories shown figure although designed retrieval deepsentibank still outperforms sentibank sentibank note deepsentibank trained whole images consider concept localization concept similarity. means performance could improved incorporate factors deep learning. recently r-cnn shows state-of-the-art performance object detection promising candidate approach concept localization. paper presents visual sentiment concept classiﬁcation model based deep convolutional neural networks. deep cnns model trained based caﬀe newly deng jonathan krause fei-fei. fine-grained crowdsourcing ﬁne-grained recognition. computer vision pattern recognition ieee conference pages ieee karayev jonathan long ross girshick sergio guadarrama trevor darrell. caﬀe convolutional architecture fast feature embedding. proceedings international conference multimedia. hinton. imagenet classiﬁcation deep convolutional neural networks. pereira c.j.c. burges bottou k.q. weinberger editors advances neural information processing systems pages curran associates inc. quoc building high-level features using large yann lecun bernhard boser john denker donnie henderson richard howard wayne hubbard lawrence jackel. backpropagation applied handwritten code recognition. neural computation marchesotti perronnin larlus csurka. assessing aesthetic quality photographs using generic image descriptors. proceedings international conference computer vision grégoire mesnil yann dauphin xavier glorot salah rifai yoshua bengio goodfellow erick lavoie xavier muller guillaume desjardins david warde-farley unsupervised transfer learning challenge deep learning approach. icml unsupervised transfer learning pages chintala yann lecun. pedestrian detection unsupervised multi-stage feature learning. computer vision pattern recognition ieee conference pages ieee andranik tumasjan timm sprenger philipp sandner isabell welpe. predicting elections twitter characters reveal political sentiment. proceedings international aaai conference weblogs social media recognizing contextual polarity phrase-level sentiment analysis. proceedings conference human language technology empirical methods natural language processing herbold sebe j.m. geusebroek. emotional valence categorization using holistic image features. proceedings ieee international conference image processing pages", "year": 2014}