{"title": "Spatial Variational Auto-Encoding via Matrix-Variate Normal  Distributions", "tag": ["cs.LG", "cs.CV", "cs.NE", "stat.ML"], "abstract": "The key idea of variational auto-encoders (VAEs) resembles that of traditional auto-encoder models in which spatial information is supposed to be explicitly encoded in the latent space. However, the latent variables in VAEs are vectors, which are commonly interpreted as multiple feature maps of size 1x1. Such representations can only convey spatial information implicitly when coupled with powerful decoders. In this work, we propose spatial VAEs that use latent variables as feature maps of larger size to explicitly capture spatial information. This is achieved by allowing the latent variables to be sampled from matrix-variate normal (MVN) distributions whose parameters are computed from the encoder network. To increase dependencies among locations on latent feature maps and reduce the number of parameters, we further propose spatial VAEs via low-rank MVN distributions. Experimental results show that the proposed spatial VAEs outperform original VAEs in capturing rich structural and spatial information.", "text": "idea variational auto-encoders resembles traditional auto-encoder models spatial information supposed explicitly encoded latent space. however latent variables vaes vectors commonly interpreted multiple feature maps size representations convey spatial information implicitly coupled powerful decoders. work propose spatial vaes latent variables feature maps larger size explicitly capture spatial information. achieved allowing latent variables sampled matrix-variate normal distributions whose parameters computed encoder network. increase dependencies among locations latent feature maps reduce number parameters propose spatial vaes low-rank distributions. experimental results show proposed spatial vaes outperform original vaes capturing rich structural spatial information. mathematical computational modeling probability distributions high-dimensional space generating samples highly useful challenging. development deep learning methods deep generative models shown effective scalable capturing probability distributions high-dimensional data spaces generating samples them. among them variational auto-encoders promising approaches. machine learning auto-encoder architecture applied train scalable models learning latent representations. image modeling tasks preferred encode spatial information latent space explicitly. however latent variables vaes vectors interpreted feature maps explicit spatial information. lack explicit spatial information lead major performance problems simple tasks digit generation mnist dataset greatly limits model’s abilities images complicated overcome limitation propose spatial vaes employ feature maps latent representations. latent feature maps generated matrix-variate normal distributions whose parameters computed encoder network. speciﬁcally distributions able generate feature maps appropriate dependencies among locations. increase dependencies among locations latent feature maps reduce number parameters propose spatial vaes low-rank distributions. low-rank formulation mean matrix distribution computed outer product vectors computed encoder network. experimental results image modeling tasks demonstrate capabilities spatial vaes complicated image generation tasks. worth noting original vaes considered special case spatial vaes distributions. size feature maps generated distributions spatial vaes distributions reduce original vaes. importantly size feature maps larger direct structural ties built elements feature maps distributions. thus proposed spatial vaes intrinsically different original vaes size feature maps larger speciﬁcally proposed spatial vaes cannot obtained enlarging size latent representations original vaes. auto-encoder model architecture used tasks like image segmentation machine translation denoising reconstruction consists parts encoder encodes input data lower-dimensional latent representations decoder generates outputs decoding representations. depending different tasks latent representations focus different properties input data. nevertheless tasks usually require outputs similar exactly structure inputs. thus structural information expected preserved encoder-decoder process. computer vision tasks structural information usually means spatial information images. main strategies preserve spatial information image tasks. apply powerful decoders like conditional pixel convolutional neural networks generate output images pixel-by-pixel. decoders recover spatial information form dependencies among pixels. however pixel-by-pixel generation slow resulting major speed problems practice. method latent representations explicitly contain spatial information apply decoders make information. apply strategy image tasks usually latent representations feature maps size size pixel input image decoders deconvolutional neural networks since computer vision tasks require high-level spatial information like relative locations objects instead detailed relationships among pixels preserving rough spatial information enough strategy proved effective efﬁcient. unsupervised learning generative models modeling underlying data distribution. formally data space ptrue denote probability density function true data distribution given dataset {x}n i.i.d samples generative models approximate ptrue using model distribution represents model parameters. train model maximum likelihood inference performed parameters pθ). approximation quality relies generalization ability model. machine learning highly depends learning latent representations encode common features among data samples disentangle abstract explanatory factors behind data data generation tasks apply resentations represents complex mapping latent space data space. major advantage using latent representations dimensionality reduction data since low-dimensional. prior simple easy model mapping represented learned complicated deep learning models automatically. recently kingma welling point model intractability problems trained costly sampling-based methods. tackle this propose variational approximation model intractable parameterized represents kullback-leibler divergence. vaes modeled multivariate gaussian distributions diagonal covariance matrices. here computed deep neural networks like cnns. figure shows architecture vaes. model parameters trained using reparameterization trick sampling process decomposed steps section analyze problem original vaes propose spatial vaes section overcome afterwards several ways implement spatial vaes discussed. naïve implementation introduced analyzed section followed method incorporates matrix-variate normal distributions section finally propose ﬁnal model spatial vaes low-rank distributions applying low-rank formulation distributions section overview note vaes resemble encoder decoder respectively image reconstruction tasks represents latent representations. however commonly vector considered multiple feature maps. implicitly preserve spatial information input image raises requirement complex decoder. given ﬁxed architecture hypothesis space decoder models limited. result optimal decoder hypothesis space problem signiﬁcantly hampers performance vaes especially spatial information important images based analysis beneﬁcial either larger hypothesis space decoders explicitly contain spatial information. note methods correspond strategies introduced section gulrajani follow ﬁrst strategy propose pixelvaes whose decoders conditional pixelcnns instead simple dcnns. conditional pixelcnns also generative models pixelvaes considered conditional pixelcnns conditions replaced spite impressive results performance pixelvaes conditional pixelcnns similar indicates conditional pixelcnns responsible capturing properties images case contributes little performance. addition applying conditional pixelcnns leads slow generation process practice. work second strategy explored constructing spatial latent representations form feature maps size larger feature maps explicitly contain spatial information. term vaes spatial latent representations spatial vaes. main distinction spatial vaes original vaes size latent feature maps. feature maps instead ones total dimension latent representations signiﬁcantly increases. however spatial vaes essentially different original vaes higher-dimensional latent vector suppose vector extended times order match total dimension number hidden nodes layer decoders explode correspondingly. results explosion number decoders’ parameters slows generation process. whereas spatial vaes decoders becomes even simpler since closer required size output images. side using decoders similar capacities spatial vaes must higher-dimensional latent representations original vaes. demonstrated slightly inﬂuences training process requiring outputs encoders generation process involves decoders remains unaffected. experimental results show proper designs spatial vaes substantially outperform original vaes applying similar decoders. figure illustration differences proposed spatial vaes low-rank distributions original vaes. architecture original vaes latent vector sampled multivariate gaussian distribution diagonal covariance matrix. proposed model explained detail section brieﬂy modiﬁes sampling process incorporating low-rank formulation distributions produces latent representations explicitly retain spatial information. achieve spatial vaes direct naïve simply reshape original vector feature maps size naïve problematic since sampling process change. note original vaes vector sampled σφ). covariance matrix diagonal meaning variable uncorrelated. particular multivariate gaussian distributions uncorrelation implies independence. therefore components independent random variables variances distributions correspond entries diagonal speciﬁcally suppose c-dimensional vector component random variable follows univariate normal distribution diag)i) diag represents vector consisting matrix’s diagonal entries. applying reparameterization trick rewrite equation sample feature maps size naïve spatial vaes process followed reshape operation setting however different components relationship respective distribution parameters diag)i) diag)j) computed dependencies implicit weak. obvious reshaping direct relationship among locations within feature spatial latent representations contain spatial information like dependencies among locations. overcome limitation propose spatial vaes matrix-variate normal distributions. spatial vaes matrix-variate normal distributions instead obtaining feature maps size ﬁrst sampling dn-dimensional vector multivariate normal distributions reshaping propose directly sample matrices feature maps matrix-variate normal distributions resulting improved model known spatial vaes distributions. speciﬁcally modify original vaes keep parts same. explained below distributions model dependencies rows columns matrix. dependencies among locations within feature established. proceed providing deﬁnition distributions. deﬁnition random matrix rm×n said follow matrix-variate normal distribution mean matrix rm×n covariance matrix rm×m rn×n follows multivariate normal distribution here denotes kronecker product denotes transforming rm×n matrix mn-dimensional vector concatenating columns. distributions capture relationships across rows columns respectively matrix. constructing covariance matrix kronecker product matrices dependencies among values matrix modeled. spatial vaes feature considered rd×d matrix follows distribution rd×d rd×d rd×d diagonal. although within random variables corresponding location still independent since diagonal distributions able direct structural ties among locations variances. example locations here independently sampled univariate gaussian distributions. however variances diagi∗j diagi∗j built direct interactions kronecker product. based this propose spatial vaes distributions samples feature maps size independent distributions ψkφ) computed encoder. here compared original vaes replaced remains same. since distributions deﬁned based multivariate gaussian distributions term dkl|pθ] equation calculated similar way. demonstrate differences naïve spatial vaes reexamine original vaes. note naïve spatial vaes sampling process original vaes. original samples dn-dimensional vector c-dimensional vector rc×c diagonal matrix. diagonal represented c-dimensional vector diag). summarize encoder original vaes outputs values interpreted diag). spatial vaes distributions according equation rd×d matrix rd×d diagonal matrices represented ddimensional vectors. case required number outputs encoder changed corresponding diag)] diag)]. explained section since diagonal sampling matrix equivalent sampling scalar numbers independent univariate normal distributions. modiﬁed sampling process reparameterization trick diag ψkφ)i∗j )diagt here take advantage fact diagonal matrices kronecker product equivalent out-product vectors. speciﬁc suppose rd×d diagonal matrices diag diag d-dimensional vectors satisfy diag vecn. result spatial vaes distributions leads simpler model adding structural ties among locations. note original vaes considered special case spatial vaes distributions. spatial vaes distributions reduce original vaes. distributions makes locations directly related within feature adding restrictions variances. however probability theory variance measures expected distance mean. direct relationships preferred restricted means. section introduce low-rank formulation distributions spatial vaes. low-rank formulation distribution denoted mean matrix computed out-product instead. here mdimensional n-dimensional vectors respectively. similar computing covariance matrix kronecker product separate matrices explicitly forces structural interactions among entries mean matrix. applying low-rank formulation leads ﬁnal model spatial vaes low-rank distributions illustrated figure using distinct d-dimensional vectors construct rd×d equation modiﬁed d-dimensional vectors. encoder number outputs reduced replacing outputs outputs another outputs contrast equation two-step sampling process expressed diag ψkφ)i∗j )diagt demonstrated section spatial vaes require outputs encoders original vaes slows training process. spatial vaes low-rank distributions properly address problem achieving appropriate spatial latent representations. according experimental results outperform original vaes several image generation tasks similar decoders used. section report experimental results spatial vaes celebfaces attributes dataset cifar- dataset seen spatial vaes improve visual quality generated samples similar decoder networks used. original vaes baseline models experiments recent improvements vaes derived vector latent representations easily incorporated matrix-based models. elucidate performance differences various spatial vaes compare results three different spatial vaes introduced section namely naïve spatial vaes spatial vaes distributions spatial vaes low-rank distributions. train models celeba dataset cifar- dataset analyze sample images generated models evaluate performance. task encoders compared models composed convolutional neural networks fullyconnected output layer fully-connected layer differ required different numbers output units slightly affects training process. discussed section reasonable compare spatial vaes original vaes case decoders figure sample face images generated different vaes trained celeba dataset. ﬁrst second rows shows training images images generated original vaes. remaining three rows results naïve spatial vaes spatial vaes distributions spatial vaes low-rank distributions respectively. similar architectures model capabilities. therefore following original vaes deconvolutional neural networks used decoders spatial vaes. meanwhile total number trainable parameters decoders compared models similar possible accommodating different input sizes. celeba celeba dataset contains colored face images size generative models supposed generate faces similar exactly dataset. task cnns encoders layers decoders -layer dcnns corresponding spatial vaes original vaes respectively. difference caused fact spatial vaes feature maps latent representations require fewer up-sampling operations obtain outputs. dimension original vaes order decoders similar numbers trainable parameters. figure shows sample face images generated original vaes three different variants spatial vaes. clear spatial vaes generate images details original vaes. lack explicit spatial information original vaes produce face images little details like hair near borders. naïve spatial vaes seem address problem faces incomplete hairs naïve spatial vaes cannot capture relationships among different locations. theoretically spatial vaes distributions able incorporate interactions among locations. however results strange faces distortions. believe reason adding dependencies among locations restrictions distribution variances effective sufﬁcient. tackle this spatial vaes low-rank distributions restricted means proposed generate faces appealing visual appearances. cifar- cifar- dataset consists color images classes. vaes usually perform poorly generating photo-realistic images since signiﬁcant differences among images different classes indicating underlying true distribution data multi-model. case vaes tend output blurry images however comparison among different models still demonstrate differences terms generative capabilities. experiment figure sample images generated different vaes trained cifar- dataset. bottom rows training images images generated original vaes naïve spatial vaes spatial vaes distributions spatial vaes low-rank distributions respectively. table training generation time different models trained celeba dataset using nvidia tesla gpu. average time training epoch time generating images reported compared. dimension original vaes encoders layers decoders layers. sample images provided figure original vaes produce images composed several colored areas consistent results similar model reported obvious three implementations spatial vaes generate images details. however naïve spatial vaes still produce meaningless images relationship among different parts. images generated spatial vaes distributions look like distorted objects similar problems results celeba dataset. again spatial vaes low-rank distributions outperform models producing blurry object-like images. show inﬂuence different spatial vaes training process compare training time celeba dataset. theoretically spatial vaes slow training larger numbers outputs encoders. note keep number trainable parameters decoders roughly equal dimension original vaes spatial vaes. according section numbers outputs encoders original naïve spatial spatial distributions spatial low-rank distributions respectively. train models nvidia tesla report average time training epoch table comparisons time generating images also provided show increase total dimension latent representations affect generation process. results show consistent relationships training time number outputs encoders; spatial vaes cost time original spatial vaes low-rank distributions alleviate problem. moreover spatial vaes slightly slow training process since affect single layer models. work propose spatial vaes image generation tasks improve vaes requiring latent representations explicitly contain spatial information images. speciﬁcally spatial vaes feature maps sampled serve spatial latent representations contrast vector. achieved sampling latent feature maps distributions model dependencies rows columns matrix. propose employ low-rank formulation distributions establish stronger dependencies. qualitative results different datasets show spatial vaes low-rank distributions substantially outperform original vaes. work supported part national science foundation grant iis- washington state university. gratefully acknowledge support nvidia corporation donation tesla used research.", "year": 2017}