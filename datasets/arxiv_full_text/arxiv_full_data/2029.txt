{"title": "Effect of Tuned Parameters on a LSA MCQ Answering Model", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "This paper presents the current state of a work in progress, whose objective is to better understand the effects of factors that significantly influence the performance of Latent Semantic Analysis (LSA). A difficult task, which consists in answering (French) biology Multiple Choice Questions, is used to test the semantic properties of the truncated singular space and to study the relative influence of main parameters. A dedicated software has been designed to fine tune the LSA semantic space for the Multiple Choice Questions task. With optimal parameters, the performances of our simple model are quite surprisingly equal or superior to those of 7th and 8th grades students. This indicates that semantic spaces were quite good despite their low dimensions and the small sizes of training data sets. Besides, we present an original entropy global weighting of answers' terms of each question of the Multiple Choice Questions which was necessary to achieve the model's success.", "text": "paper presents current state work progress whose objective better understand effects factors significantly influence performance latent semantic analysis difficult task consists answering biology multiple choice questions used test semantic properties truncated singular space study relative influence main parameters. dedicated software designed fine tune semantic space multiple choice questions task. optimal parameters performances simple model quite surprisingly equal superior grades students. indicates semantic spaces quite good despite dimensions small sizes training data sets. besides present original entropy global weighting answers’ terms question multiple choice questions necessary achieve model's success. paper following goals search method enables obtain better input features inverse document frequency latent semantic analysis nonsupervised learning method define concrete task allows hand evaluate semantic nature obtained vector spaces hand measure relative influence parameters used build spaces describe original aspects dedicated tool developed realize processes compare model results obtained grades students. proven provide reliable information long-distance semantic dependencies words context using words model order words document unimportant. combines classical vector space model singular value decomposition. thus words representations texts mapped modified vector space reflects degree semantic structure. consequence reduction paper presents state ongoing work similar work wild stahl stermsek neumann measure effects tuning parameters input textual features precisely effects lemmatisation stopwords lists weighting terms terms-by-documents matrix pseudo-documents normalization document vectors. semantic spaces extent semantic? able objectively judge quality space referred semantic define external semantic task considered semantic space produce results variable quality. moreover task make possible evaluate best possible result relative influence various parameters. unlike free answer questions frequently used research paper addresses automatically find right answers multiple choice questions using lsa. answer question could interesting cognitive point view practical applications. design evaluation multiple choice questions without need cohort students beginning process example application. built model capable answering multiple choice questions nontrivial problem received enough attention even though frequently used e-learning questionnaire processing. model propose based following assumptions question associated three answers represented words correct answer three highest similarity question. results presented indicate much rough assumptions effective limitations are. limited number available terms words compute meaningful similarities needed choose correct answer multiple choice questions determines difficulty task. small size corpora compared usual ones increases difficulty. elsa motivation dedicated tool quesada chapter entitled creating spaces recommend building one’s toolkit complexity presents frequently used softwares nevertheless given complexity links successive steps processing well desire monitor detail different processing stages find necessary develop software order implement specific algorithms. multiple choice questions dedicated elsa software extended semantic tasks future needed. performance considered theory meaning model semantic memory according this allows computing relative importance textual statements necessary summarize text predicting movements readers function importance statements cognitive relevance learning summarizing generally accepted proved case multiple choice questions. compare performances students multiple choice remaining paper structured follows. original aspects elsa software sequence processing specific multiple choice questions detailed section section presents data used experiments corpora optimized semantic spaces multiple choice questions. typology questions answers various forms differentiation answers presented section section describes relative influence parameters quality results. finally comparisons elsa model student performances presented section elsa tool implementation elsa developed using python interpreted language addition claims python software foundation about section site motivation professional quality friendly language follow numerous ready libraries exist particular numerical matrix calculation library numpy particular importance efficient related heavy computations. effects stemming lemmatisation preprocessing operations input vector space model controversial probably depend hand quality type pre-processing hand size used corpora. stemming lemmatisation different techniques language dependent word morphology sought-after effect semantically similar words vocabulary merged create equivalence class traditionally called term vector-space model less statistical noise; consequence merging vector space dimension reduced. unifying framework equivalence class words given term also used take account abbreviations synonymy etc. limit risks spurious equivalence classes future extensions developed solution. lemmatizer uses rules like porter’s stemmer triggers words equivalence co-occurrence predefined suffices present pair words corpus share prefix. \"respirons\" respectively singular verb \"respirer\" french. \"ons\" list components permissible pair suffices membership equivalent class co-triggered. order limit noise lemmatizer takes account quite rare exceptions co-triggered rules. similarity computed terms belong training corpus. similarity computed multiple choice questions pseudo-documents take account terms training corpus. given lemmatization based pairs words joint lemmatization conducted order increase number possible common terms corpus multiple choice questions i.e. lemmatization resulting vocabulary training corpus multiple choice questions. start recalling definition entropy global weighting invoked paper three different uses computer aided stop list design section specific entropy global weighting three multiple choice questions answers terms’ question section global weighting corpus terms section latter classic weighting term vector terms-by-documents matrix vector space model also paper term assigned global weight indicating overall importance corpus. case entropy weighting global weight uses although classical employ well know property definition varies term present documents frequency term present document. value measure information given term building specific stop lists make entropy global weighting original good candidate stop word list must global weighting values although true specialized corpora used here. following procedure adopted elsa lists first terms ranked increasing filter manually specialized terms -set entropy weighting specific entropy global weighting multiple choice questions answers model multiple choice questions question three answers pseudodocuments pseudodocument answer compared pseudo-document question semantic space training corpus. produce pseudo-documents recommended weightings used corpus however given case reduced number terms frequencies little significance. fortunately make profit following multiple choice questions specificity three concurrent answers question. makes possible apply entropy global weighting three answers whole multiple choice questions supplied maxicours private course enterprise authors collaborate context infomgic project supported competitiveness pole france region. multiple choice questions designed authors implements elsa. details given along section conduct useful experiment take account consistency basic assumptions model multiple choice questions data namely question answer multiple choice questions initial questions multiple choice questions rejected related topics longer treated corpora like cigarette associated harmful effects corresponding words even present vocabulary corpora. question characterized absence correlation question answers. contradicts basic assumptions model parmi trois affirmations suivantes seule juste. laquelle four french corpora dealing grade biology program built different sources public scholar book private remedial course either basic format restricted content course extended version containing definitions explanations concepts additional relevant information. chapters dealing «respiration» extracted part functioning body need energy muscular activity need energy need organs dioxygen air. main characteristics corpora presented table table displays statistics french considered whole corpus. questions number documents last columns number words terms present interaction different corpora. give results optimization obtained varying main parameters. interdependence parameters examined discrepancy best score parameter time. since authors confirmed best result local function obtained entropy global weighting resulting so-called classical log-entropy weighting used build terms-by-documents matrix. titles table means obtained without paragraph titles corpora titles table table select worst choice parameter best score tuning titles means tables used opposite selection table document normalisation normalisation columns terms-by-documents matrix applying logentropy weighting. joint lemmatisation special consequence co-triggered lemmatisation frequency normalisation means frequencies components document vectors normalized log-entropy weighting applied. -set entropy weighting table table table means weighting scheme described section used three answers associated question. stop words stop words list designed truncation selection right dimension semantic space following call undecidability hard distinguish soft described later. example question leads systematically following situation rmcq best hard undecidable words. question elsa automatically pointed questions hard undecidable words. illusory seek distinguish correct answer among representations matter identical algorithm used. soft undecidability previous undecidability qualified hard leads undecidability correct incorrect answers. another kind undecidability less serious consequences. define kind undecidable answer follows incorrect answers identical words soft undecidability occurs. example answers question undergo soft undecidability. occurs corpus include word \"thermometer\" word \"oscilloscope\" \"the\" stop word rmcq best soft undecidable words. question allows thermometer. oscilloscope. soft undecidable questions opposed hard undecidable ones elsa potentially able choose correct answer; therefore questions discarded. stop words lemmatization side effect results normalisations documents term frequencies negative effect results. positive role recommended pre-processing features vector space model confirmed injection external semantic lemmatisation stop word lists partially compensates size training corpora number terms multiple choice questions. optimal semantic space stop word list play major role entropy weighting specific problem important influence corpora leading best multiple choice questions answering scores. case corpora joint lemmatisation done elsa detects occurrence hard undecidability first answers question even correct found chance cosine question answer value answers first chosen default rmcq best hard undecidable words. question raises. hand joint lemmatisation occurs multiple choice questions corpus word \"risen\" corpus word \"raise\" answer fall class \"raise\". words answers become discernible essential characteristics resulting semantic spaces used experiments presented table figure depicts variation number correct answers versus semantic space dimensionality corpus example. example shows relevance joint lemmatisation adding semantics works relatively words also case limit risk parasitic phenomena hard undecidability. nevertheless mean correct answer found particular case. recalling dimension eigen spaces terms documents correlation matrix same given mean degree correlation terms textual data useful dimensionality semantic space quasi constant fraction empirically. suggest substituting number terms wild rule better generality. concerning point results fact carry small size data case exhaustive scanning interval dimensionality eliminated totally risk false optimum artifact partial scanning. optimal dimension must completely independent task evaluating i.e. rely solely corpus case would filtering dimensionality number concepts denoted questions multiple choice questions. high redundancy restricted scope corpora induces numerical point view relative poverty concepts consequently number important singular vectors comparison general scope corpora leads small dimensionality seen table above. classes grades participate three phases experimentation paper pencil questionnaire «classic» «evidential» multiple choice questions free answer questions assigned «classic» multiple choice questions «classic» multiple choice questions composed questions three candidate answers. grades results mean percentages correct answers grades similar distributions performances close shown significant correlation results example questions lead worst results best score obtained relatively values semantic space dimensions quite unusual practice. wild also obtained dimensionalities deal question best dimensionality remains open since years long time magic values even proposed literature. today turning quite better founded statistical methods example wild give four simple methods apparently remain little used. simplest consider fraction number terms application rule corpus leads respectively appears correct order magnitude comparison experimental results table satisfactory given easiness use. explain intuitively latent values corresponding cosines affected elsa three answers remaining questions frequency choice answers grades’ presented table correlations indicate significantly strong link elsa students’ performances. strong correlations elsa students’ performances encouraging despite simplicity model. demonstrated used analyse multiple choice questions performances similar students’ results. special global entropy weighting answers question multiple choice questions call -set entropy weighting proved necessary achieve model's success. dedicated tool elsa enables build typology multiple choice questions answers specificity. model proposed easily improved deal complex tasks. example automatic selection different strategy find correct answer case question answers lack substitute cosines vector angles order linear thus probably nearer spreading student answers’ distribution. would like thank patenotte headmaster linhart assistant head lopez lechner professors allowing computing means jean-baptiste college necessary work students. also would like thank murat ahat laisc laboratory ephe-paris help translating paper well nicolas usunier maha abdallah marc-ismaël jeannin-akodjènou attentive kind proof reading paper. grateful reviewers help improve document. correspondence concerning article addressed lifchitz dapa université pierre marie curie cnrs avenue président kennedy paris france stop words stop lemmatized terms list used corpus auraient aurait avait avec avoir avons cette chez comme dans étaient était être grâce leur leurs permet permettant permettent permis peut peut-on peuvent plus pour quand soient soit sont sous suis très unes vers denhière lemaire representing children's semantic knowledge multisource corpus. proceedings annual meeting society text discourse chicago erlbaum. denhière hoareau jhean-larose lehnard baïer bellissens human hierarchization semantic information proceedings international conference latent semantic analysis technology enhanced learning heerlen diaz rifqi bouchon-meunier jhean-larose denhiere imperfect answers multiple choice questionnaires. proceedings european conference technology-enhanced learning maastricht dillenbourg specht lecture notes computer science heidelberg springer-verlag. ding similarity-based probability model latent semantic indexing. proceedings annual international sigir conference research development information retrieval berkeley harman experimental study factors important document ranking. proceedings annual international sigir conference research development information retrieval pisa jhean-larose leclercq diaz denhière bouchon-meunier knowledge evaluation based mcqs free answer questions. special edition mobile ad-hoc networks kantrowitz mohit mittal stemming effects tfidf ranking. proceedings annual international sigir' conference research development information retrieval athens martin berry mathematical foundation behind latent semantic analysis. landauer mcnamara dennis kintsch handbook latent semantic analysis erlbaum. tisserand jhean-larose denhiere movement analysis latent semantic analysis comprehension recall activity. proceedings international conference latent semantic analysis technology enhanced learning heerlen", "year": 2008}