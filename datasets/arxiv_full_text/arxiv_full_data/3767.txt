{"title": "Forest Sparsity for Multi-channel Compressive Sensing", "tag": ["cs.LG", "cs.CV", "cs.IT", "math.IT", "stat.ML"], "abstract": "In this paper, we investigate a new compressive sensing model for multi-channel sparse data where each channel can be represented as a hierarchical tree and different channels are highly correlated. Therefore, the full data could follow the forest structure and we call this property as \\emph{forest sparsity}. It exploits both intra- and inter- channel correlations and enriches the family of existing model-based compressive sensing theories. The proposed theory indicates that only $\\mathcal{O}(Tk+\\log(N/k))$ measurements are required for multi-channel data with forest sparsity, where $T$ is the number of channels, $N$ and $k$ are the length and sparsity number of each channel respectively. This result is much better than $\\mathcal{O}(Tk+T\\log(N/k))$ of tree sparsity, $\\mathcal{O}(Tk+k\\log(N/k))$ of joint sparsity, and far better than $\\mathcal{O}(Tk+Tk\\log(N/k))$ of standard sparsity. In addition, we extend the forest sparsity theory to the multiple measurement vectors problem, where the measurement matrix is a block-diagonal matrix. The result shows that the required measurement bound can be the same as that for dense random measurement matrix, when the data shares equal energy in each channel. A new algorithm is developed and applied on four example applications to validate the benefit of the proposed model. Extensive experiments demonstrate the effectiveness and efficiency of the proposed theory and algorithm.", "text": "intrainterchannel correlations enriches family existing model-based compressive sensing theories. proposed theory indicates measurements required multi-channel data forest sparsity number channels length sparsity number channel respectively. result much better tree sparsity joint sparsity better standard sparsity. addition extend forest sparsity theory multiple measurement vectors suppose rm×n sampling matrix measurement vector problem recover sparse data solving linear system sometimes data sparse compressible base wavelet corresponding problem aφ−θ denotes wavelet coefﬁcients. although problem underdetermined data mutually connected trees. give mathematical deﬁnition forest sparsity. based compressive sensing theory prove forest k-sparse trees measurements required successful recovery high probability. much less bounds joint sparsity tree sparsity data. theory extended case problems ignored existing structured sparsity theories compressive sensing capture sparse signal compression integrated capture sparse data directly rather capture single process linear measurements based measurement matrix rm×n stably recover k-sparse data measurements measurement matrix required satisfy restricted isometry a-rip property proved sufﬁcient robust recovery structured-sparse signals noisy conditions required number measurements quantiﬁed sub-gaussian random matrix a-rip could intuitively observe less reducing number subspaces coincides intuition result improved priors utilized. standard k-sparse data constraint reduce number possible subspaces reviewed standard sparsity tree sparsity single channel data. multi-channel data contains channels vectors standardly k-sparse bound number measurement channel tree-sparse independently measurement bound sub-gaussian random matrix cases bound reduced proofs lemma well lemma included appendices. using ftk-rip forest-sparse data robustly recovered noisy compressive measurements. measurement matrix assumed dense sub-gaussian matrix. however many practical problems data channel measured distinct compressive matrix rm×n called multiple measurement vectors problems multi-task learning dense matrices i.i.d sub-gaussian entries bound also depends energy data. hard best case ||x|| ||x|| ||xt|| measurement bound shows similar performance dense sub-gaussian matrix theorem worst case energy data concentrate single channel/task i.e. ||xt|| except single index ||xt|| measurement bound even worse theorem independent tree sparse channels. even block-diagonal matrix analysis makes clear performance second step closed form solution soft-thresholding. joint sparsity problem second step also closed form solution. call version fista joint joint sparsity. however problem overlapped groups directly apply fista order transfer problem non-overlapping version introduce binary matrix rd×t duplicate overlapped coefﬁcients. contains else appears i-th column corresponds i-th coefﬁcient intuitively ﬁrst second coordinates respectively; positive parameter. compared algorithm need µ||x||t corresponding subproblem already solved combined algorithm called fcsa forest used experiments. therefore independent highly correlated. multi-contrast images typically forestsparse wavelet basis. suppose {xt}t multi-contrast images anatomical cross section {bt}t corresponding undersampled data fourier domain forest-sparse reconstruction formulated reconstructed simultaneously joint-sparse model forest-sparse model. image cropped convenience. number wavelet decomposition levels snrs recovered images band shown fig. could observe modeling forest", "year": 2012}