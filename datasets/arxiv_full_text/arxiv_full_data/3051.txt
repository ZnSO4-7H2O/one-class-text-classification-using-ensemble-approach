{"title": "High-Order Attention Models for Visual Question Answering", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "The quest for algorithms that enable cognitive abilities is an important part of machine learning. A common trait in many recently investigated cognitive-like tasks is that they take into account different data modalities, such as visual and textual input. In this paper we propose a novel and generally applicable form of attention mechanism that learns high-order correlations between various data modalities. We show that high-order correlations effectively direct the appropriate attention to the relevant elements in the different data modalities that are required to solve the joint task. We demonstrate the effectiveness of our high-order attention mechanism on the task of visual question answering (VQA), where we achieve state-of-the-art performance on the standard VQA dataset.", "text": "quest algorithms enable cognitive abilities important part machine learning. common trait many recently investigated cognitive-like tasks take account different data modalities visual textual input. paper propose novel generally applicable form attention mechanism learns high-order correlations various data modalities. show high-order correlations effectively direct appropriate attention relevant elements different data modalities required solve joint task. demonstrate effectiveness high-order attention mechanism task visual question answering achieve state-of-the-art performance standard dataset. quest algorithms enable cognitive abilities important part machine learning appears many facets e.g. visual question answering tasks image captioning visual question generation machine comprehension common trait recent cognitive-like tasks take account different data modalities example visual textual data. address tasks recently attention mechanisms emerged powerful common theme provides form interpretability applied deep models also often improves performance latter effect attributed expressive concise forms various data modalities. present attention mechanisms like example however often lacking main aspects. first systems generally extract abstract representations data ad-hoc entangled manner. second present attention mechanisms often geared towards speciﬁc form input therefore hand-crafted particular task. address issues propose novel generally applicable form attention mechanism learns high-order correlations various data modalities. example second order correlations model interactions data modalities e.g. image question generally k−th order correlations model interactions modalities. learning correlations effectively directs appropriate attention relevant elements different data modalities required solve joint task. demonstrate effectiveness novel attention mechanism task visual question answering achieve state-of-the-art performance dataset figure results multi-modal attention image different questions unary image attention identical construction. pairwise potentials differ questions images since modalities taken account ﬁnal attention illustrated column. results visualized fig. show visual attention correlates textual attention. begin reviewing related work. subsequently provide details proposed technique focusing high-order nature attention models. conclude presenting application high-order attention mechanism compare state-of-the-art. attention mechanisms investigated image textual data. following review mechanisms both. image attention mechanisms past years single image embeddings extracted deep extended variety image attention modules considering vqa. example textual long short term memory augmented spatial attention similarly andreas employ language parser together series neural modules attends regions image. language parser suggests neural module use. stacking attention units also investigated yang stacked attention network predicts answer successively. dynamic memory network modules capture contextual information neighboring image regions considered xiong shih object proposals rank regions according relevance. multi-hop attention scheme proposed extract ﬁne-grained details. joint attention mechanism discussed fukui suggest efﬁcient outer product mechanism combine visual representation text representation applying attention combined representation. additionally suggested glimpses. recently kazemi showed similar approach using concatenation instead outer product. importantly approaches model attention single network. fact multiple modalities involved often considered explicitly contrasts aforementioned approaches technique present. recently presented technique also interprets attention multi-variate probabilistic model incorporate structural dependencies deep net. recent techniques work dual attention mechanisms work bilinear models. contrast latter models approach easy extend number data modalities. textual attention mechanisms also want provide brief review textual attention. address challenges e.g. long sentences faced translation models hermann proposed rnnsearch. address challenges arise ﬁxing latent dimension neural nets processing text data bahdanau ﬁrst encode document query bidirectional lstm used compute attentions. mechanism later reﬁned word based technique reasons sentence representations. joint attention hierarchies discussed among attention mechanisms relevant approach work approach presented discuss attention mechanisms operate jointly modalities. pairwise interactions form similarity matrix ignore attentions individual data modalities. suggest alternating model directly combines features modalities attending. additionally suggested parallel model uses similarity matrix features modality other. hard extend approach modalities. contrast model develops probabilistic model based high order potentials performs mean-ﬁeld inference obtain marginal probabilities. permits trivial extension model number modalities. additionally jabri propose model answers also used inputs. approach questions need attention mechanisms develops alternative solution based binary classiﬁcation. contrast approach captures high-order attention correlations found improve performance signiﬁcantly. overall early work propose combination language image attention e.g. attention mechanism several potentials haven’t discussed detail yet. following present approach joint attention number modalities. attention modules crucial component present decision making systems. particularly taking account data different modalities attention mechanisms able provide insights inner workings oftentimes abstract automatically extracted representations systems. example system captured research efforts recent years visual question answering considering example immediately note dependence even three different data modalities visual input question answer processed simultaneously. formally denote representation visual input question answer respectively. hereby number pixels number words question number possible answers. denote dimensionality data. simplicity exposition assume identical across data modalities. dependence multiple data modalities present decision making systems decomposed three major parts data embedding; attention mechanisms; decision making. state-of-the-art system developed here three parts immediately apparent considering high-level system architecture outlined fig. attention modules deliver decision making component succinct representation relevant data modalities. such performance depends represent data modalities themselves. oftentimes attention module tends expressive concise data embedding algorithms better capture correlations consequently improve decision making performance. example data embeddings based convolutional deep nets constitute state-of-the-art many visual recognition scene understanding tasks. language embeddings heavily rely lstm able capture context sequential data words phrases sentences. give detailed account data embedding architectures sec. apparent aforementioned description attention crucial component connecting data embeddings decision making modules. subsequently denote attention words question word index. similarly attention image referred attention possible answers denoted na}. consider attention mechanism probability model attention mechanism computing potentials. first unary potentials denote importance feature task. second pairwise potentials express correlations modalities. last third-order potential θvqa captures dependencies three modalities. obtain marginal probabilities potentials model performs mean-ﬁeld inference. combine unary potential marginalized pairwise potential marginalized third order potential linearly including bias term hereby learnable parameters smax refers soft-max operation respectively. soft-max converts combined potentials probability distributions corresponds single mean-ﬁeld iteration. linear combination potentials provides extra ﬂexibility model since learn reliability potential data. instance observe question attention relies unary question potential pairwise question answer potentials. contrast image attention relies pairwise question image potential. given aforementioned probabilities attended image question answer vectors denoted attended modalities calculated weighted image features rnv×d question features rnq×d answer features rna×d i.e. figure illustration k−order attention. unary attention module pairwise attention module marginalized data modalities. ternary attention module marginalized three data modalities.. attended modalities effectively focus data relevant task passed classiﬁer decision making e.g. ones discussed sec. following describe attention mechanisms unary pairwise ternary potentials detail. unary potentials illustrate unary attention schematically fig. input unary attention module data representation i.e. either visual representation question representation answer representation using representations obtain ‘unary potentials’ using convolution operation kernel size data representation additional embedding step followed non-linearity followed another convolution operation kernel size reduce embedding dimensionality. since convolutions kernel size identical matrix multiplies formally obtain unary potentials rd×d trainable parameters. pairwise potentials besides mentioned mechanisms generate unary potentials speciﬁcally taking advantage pairwise attention modules able capture correlation representation different modalities. approach illustrated fig. similarity matrix image question modalities qwq. alternatively entry correlation i-th column j-th column rd×d trainable parameters. consider pairwise potential represents correlation i-th word question j-th patch image. therefore retrieve attention speciﬁc word convolve matrix along visual dimension using dimensional kernel. speciﬁcally figure illustration correlation units used decision making. unit approximately sample outer product space attention vectors unit approximately sample outer product space three attention vectors. decision making component receives input attended modalities predicts desired output. attended modality vector consists relevant data making decision. decision making component consider modalities independently nature task usually requires take account correlations attended modalities. correlation attended modalities represented outer product respective vectors e.g. correlation attended modalities represented matrix correlation k-attended modalities represented k-dimensional tensor. ideally attended modalities high-order correlation tensors deep produces ﬁnal decision. number parameters network grows exponentially number modalities seen fig. overcome computational bottleneck follow tensor sketch algorithm pham pagh recently applied attention models fukui multimodal compact bilinear pooling pairwise setting multimodal compact trilinear pooling extension pools data three modalities. tensor sketch algorithm enables reduce dimension rank-one tensor referring implicitly. relies count sketch technique randomly embeds attended vector another euclidean space tensor sketch algorithm projects rank-one tensor i=ai consists attention correlations order using convolution example attention modalities correlation randomly projected convolution ψ∗ψ. matrix attended modalities high-order correlations fully connected neural complete decision making. data embedding attention module requires question representation rnq×d image representation rnv×d answer representation rna×d computed follows. image embedding embed image pre-trained convolutional deep nets extract last layer fully connected units. dimension case dimension resnet case hence obtain table comparison results multiple-choice dataset variety methods. observe combination three unary pairwise ternary potentials yield best result. method hiecoatt hiecoatt -modalities unary+pairwis -modalities unary+pairwise -modalities unary pairwise ternary -modalities unary pairwise ternary embed vgg- resnet features dimensional space obtain image representation question embedding obtain question representation rnq×d ﬁrst -hot encoding word question d-dimensional embedding space using linear transformation plus corresponding bias terms. obtain richer representation accounts neighboring words -dimensional temporal convolution ﬁlter size combination multiple sized ﬁlters suggested literature didn’t beneﬁt using approach. subsequently capture long-term dependencies used long short term memory layer. reduce overﬁtting caused lstm units used lstm layers hidden dimension uses input word embedding representation operates conv layer output. output concatenated obtain also note constant hyperparameter i.e. questions words questions less words zero-padded. answer embedding embed possible answers regular word embedding. vocabulary speciﬁed taking frequent answers training set. answers included answers embedded vector. answers containing multiple words embedded n-grams single vector. assume real dependency answers therefore need using additional conv lstm layers. example investigate techniques combine vectors three modalities. first attended feature representation modality i.e. combined using unit. feature element form ﬁrst solution general cases like experiments show better second approach -layer unit combination. permits greater expressiveness employ features form therefore also allowing image features interact themselves. note terms parameters approaches identical neither parametric modules. beyond tested several techniques suggested literature including element-wise multiplication element-wise addition concatenation optionally followed another hidden fully connected layer. tensor sketching units consistently performed best. results experimental setup rmsprop optimizer base learning rate well batch size dimension hidden layers unit feature dimension apply dropout rate word embeddings lstm layer ﬁrst conv layer unary potential units. additionally last fully connected layer dropout rate frequent figure image show attention generated different questions columns columns respectively. attentions ordered unary attention pairwise attention combined attention image question. observe combined attention signiﬁcantly depend question. answers possible outputs covers answers train set. implemented models using torch framework comparison attention mechanism approach technique fukui methods based hierarchical attention mechanism multi-modal compact bilinear pooling. contrast approach demonstrate relatively simple technique based probabilistic intuition grounded potentials. comparative reasons only visualized attention based modalities image question. evaluate attention modules real-image test-dev test-std datasets dataset consists training images test images. image comes questions along multiple choice answers. quantitative evaluation ﬁrst evaluate overall performance model compare variety baselines. tab. shows performance model baselines test-dev test-standard datasets multiple choice questions. obtain multiple choice results follow common practice highest scoring answer among provided ones. approach multiple choice answering task achieved reported result iterations requires hours training ‘train+val’ dataset using titanx gpu. despite fact model million parameters techniques like million parameters observe state-of-the-art behavior. additionally employ -modality model similar experimental setup. observe signiﬁcant improvement -modality model shows importance high-order attention models. fact lower embedding dimension compared existing -modality models -modality model achieves inferior performance. believe higher embedding dimension proper tuning improve -modality starting point. additionally compared proposed decision units. generic extension -modalities -layers greater expressiveness evaluating ’val’ dataset training ’train’ part using features setup yields -layer yields also tested different ordering input -modality found yield inferior results. qualitative evaluation next evaluate technique qualitatively. fig. illustrate unary pairwise combined attention approach based modality architecture without multiple choice input. image show multiple questions. observe unary attention usually attends strong features image pairwise potentials emphasize areas correlate question words. importantly combined result dependent provided question. instance ﬁrst observe question many glasses table? pairwise potential reacts image area depicting glass. contrast question anyone scene wearing blue? pairwise potentials reacts blue shirt. fig. illustrate attention -modality model. attention multiple choice answers favor unusual results. fig. compare ﬁnal attention obtained approach results obtained techniques discussed observe approach attends reasonable pixel question locations. example considering ﬁrst fig. question refers battery operated device. compared existing approaches technique attends laptop seems help choosing correct answer. second question wonders girl?. correct answers produced attention focuses hair. fig. illustrate failure case attention approach identical despite different input questions. system focuses colorful umbrella opposed object queried question. conclusion paper investigated series techniques design attention multimodal input data. beyond demonstrating state-of-the-art performance using relatively simple models hope work inspires researchers work direction. acknowledgments research supported part israel science foundation material based upon work supported part national science foundation grant thank nvidia providing gpus used research. abhishek harsh agrawal lawrence zitnick devi parikh dhruv batra. human attention visual question answering humans deep networks look regions? arxiv preprint arxiv. akira fukui dong park daylen yang anna rohrbach trevor darrell marcus rohrbach. multimodal compact bilinear pooling visual question answering visual grounding. arxiv preprint arxiv. kelvin jimmy ryan kiros kyunghyun aaron courville ruslan salakhudinov rich zemel yoshua bengio. show attend tell neural image caption generation visual attention. icml", "year": 2017}