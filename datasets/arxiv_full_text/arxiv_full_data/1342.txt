{"title": "Inverting Visual Representations with Convolutional Networks", "tag": ["cs.NE", "cs.CV", "cs.LG"], "abstract": "Feature representations, both hand-designed and learned ones, are often hard to analyze and interpret, even when they are extracted from visual data. We propose a new approach to study image representations by inverting them with an up-convolutional neural network. We apply the method to shallow representations (HOG, SIFT, LBP), as well as to deep networks. For shallow representations our approach provides significantly better reconstructions than existing methods, revealing that there is surprisingly rich information contained in these features. Inverting a deep network trained on ImageNet provides several insights into the properties of the feature representation learned by the network. Most strikingly, the colors and the rough contours of an image can be reconstructed from activations in higher network layers and even from the predicted class probabilities.", "text": "hand-designed learned ones often hard analyze interpret even extracted visual data. propose approach study image representations inverting up-convolutional neural network. apply method shallow representations well deep networks. shallow representations approach provides signiﬁcantly better reconstructions existing methods revealing surprisingly rich information contained features. inverting deep network trained imagenet provides several insights properties feature representation learned network. strikingly colors rough contours image reconstructed activations higher network layers even predicted class probabilities. figure train convolutional networks reconstruct images different feature representations. input features. bottom reconstructed image. reconstructions sift realistic. reconstructions alexnet preserve color rough object positions even reconstructing higher layers. feature representation useful pattern recognition tasks expected concentrate properties input image important task ignore irrelevant properties input image. example handdesigned descriptors sift explicitly discard absolute brightness considering gradients precise spatial information binning gradients precise values gradients normalizing histograms. convolutional neural networks trained supervised manner expected discard information irrelevant task solving paper propose approach analyze information preserved feature representation information discarded. train neural networks invert feature representations following sense. given feature vector network trained predict expected pre-image average natural images could produced given feature vector. content expected pre-image shows image properties conﬁdently inferred feature vector. amount blur corresponds level invariance feature representation. obtain insights structure feature space apply networks perturbed feature vectors interpolations feature vectors random feature vectors. apply inversion method alexnet convolutional network trained classiﬁcation imagenet well three widely used computer vision features histogram oriented gradients scale invariant feature transform local binary patterns sift representation comes nonuniform sparse oriented keypoints corresponding descriptors various scales. additional challenge inversion task. features differentiable respect input image. thus existing methods based gradients representations could applied them. tion feature vectors given image. special case deterministic function ideally would like direct application bayes’ theorem feasible. therefore paper resort point estimate minimizes following mean squared error objective shallow features. invert three traditional computer vision feature representations histogram oriented gradients scale invariant feature transform local binary patterns chose features reason. work inverting compare existing approaches. interesting differentiable hence gradient-based methods cannot invert sift keypoint-based representation network stitch different keypoints single smooth image. three methods implementations vlfeat library default settings. precisely version felzenszwalb cell size version sift similar original implementation lowe version similar ojala cell size before extracting features convert images grayscale. details found supplementary material. representation alexnet network trained imagenet available caffe website. consists convolutional layers fully connected layers rectiﬁed linear units layer local contrast normalization max-pooling them. exact architecture shown supplementary material. follows approach related large body work inverting neural networks. include works making backpropagation sampling similar approach neural networks however recent advances neural network architectures allow invert modern large convolutional network another network. approach confused deconvnet propagates high level activations backward network identify parts image responsible activation. addition high-level feature activations reconstruction process uses extra information maxima locations intermediate maxpooling layers. information shown crucial approach work visualization method similar deconvnet springenberg also makes intermediate layer activations. mahendran vedaldi invert differentiable image representation using gradient descent. given feature vector seek image minimizes loss function squared euclidean distance plus regularizer enforcing natural image prior. method fundamentally different approach optimizes difference feature vectors image reconstruction error. additionally includes hand-designed natural image prior case network implicitly learns prior. technically involves optimization test time requires computing gradient feature representation makes relatively slow contrast presented approach costly training inversion network. reconstruction given feature vector requires single forward pass network takes roughly image gpu. method requires gradients feature representation therefore could directly applied non-differentiable representations recordings real brain research inverting various traditional computer vision representations dense sift keypoint-based sift local binary descriptors bag-of-visual-words methods either tailored inverting speciﬁc feature representation restricted shallow representations method applied feature representation. denote random variables representing natural image feature vector denote joint probability distribution distribution natural images distribusay ‘output layer’ mean output last processing step layer. example output ﬁrst convolutional layer conv would result after relu pooling normalization output ﬁrst fully connected layer relu. denotes last layer softmax. up-convolutional layer also often referred ‘deconvolutional’ combination upsampling convolution upsample feature factor replacing value block original value left corner entries equal zero. architecture up-convolutional networks shown table architectures networks shown supplementary material. lbp. image size features image form -dimensional arrays sizes respectively. similar architectures inverting feature representations. networks include contracting part processes input features series convolutional layers occasional stride resulting feature times smaller input image. expanding part network upsamples feature full image resolution series up-convolutional layers. contracting part allows network aggregate information large regions input image. found necessary successfully estimate absolute brightness. sparse sift. running sift detector descriptor image gives keypoints i-th keypoint described coordinates scale orientation feature descriptor dimensionality order apply convolutional network arrange keypoints grid. split image cells size yields cells. rare cases several keypoints cell randomly select one. assign vector cells zero vector cell without keypoint vector cell keypoint. results feature size w/d×h/d×. apply described above. alexnet. reconstruct layer alexnet trained separate network. used basic architectures reconstructing convolutional layers reconstructing fully connected layers. network reconstructing fully connected layers contains three fully connected layers up-convolutional layers shown table network reconstructing convolutional layers consists three convolutional several up-convolutional layers training data used imagenet training set. cases predicted downsampled images speed computations. used adam optimizer minibatch size networks found initial learning rate work well. gradually decreased learning rate towards training. duration training depended network epochs shallower networks epochs deeper ones. quantitative evaluation. quantitative measure performance used average normalized reconstruction error mean ||xi )||/n example test function implemented inversion network normalization coefﬁcient equal average euclidean distance images test set. test used quantitative qualitative evaluations subset imagenet validation set. figures show reconstructions several images imagenet validation set. normalized reconstruction error different approaches shown table clearly method signiﬁcantly outperforms existing approaches. expected since method explicitly aims minimize reconstruction error. colorization. mentioned above compute features based grayscale images task networks reconstruct color images. features contain color information predict colors network analyze content image make natural image prior learned training. successfully learn seen figures quite often colors predicted correctly especially grass trees. cases network cannot predict color leaves areas gray. occasionally network predicts wrong color bottom figure hog. figure shows example image representation results inversion existing methods approach. interestingly network able reconstruct overall brightness image well example dark regions reconstructed dark. quite surprising since descriptors normalized contain information absolute brightness. normalization always performed smoothing ’epsilon’ might imagine information brightness present even normalized features. checked network make information multiplying input image hardly changes reconstruction. therefore hypothesize network reconstructs overall brightness analyzing distribution features accumulating gradients space much black-to-white gradient direction probably brightness direction goes dark bright using semantic information. keypoints detected image. although made sparse keypoints reconstruction looks natural little blurry. achieve clear reconstruction network properly rotate scale descriptors stitch together. obviously successfully learns this. reference also show result another existing method reconstructing images sparse sift descriptors. results directly comparable sift detector providing circular keypoints weinzaepfel harris afﬁne keypoint detector yields elliptic keypoints number locations keypoints different case. however rough number keypoints same qualitative comparison still valid. applied inversion method different layers alexnet performed several additional experiments better understand feature representations. results shown supplementary material. figure shows reconstructions various layers alexnet. using features convolutional layers reconstructed images look similar input lose details progress higher layers. obvious drop reconstruction quality going conv however reconstructions higher convolutional layers even fully connected layers preserve color approximate object location well. reconstructions still look similar input images blurry. means high level features much less invariant color pose might expect principle fully connected layers need preserve information colors locations objects input image. somewhat contrast results shown figure reconstructions sharper color position completely lost reconstructions higher layers. quantitative evaluation computing error up-sample reconstructions input image size bilinear interpolation. error curves shown figure support conclusions made above. reconstructing error roughly twice large conv. even reconstructing error fairly network manages color rough placement large objects images right. lower layers reconstruction error still much higher method even though visually images look somesharper. reason reconstructions color precise placement small details perfectly match input image results large overall error. autoencoder training inversion network interpreted decoder representation encoded alexnet. difference autoencoder encoder part stays ﬁxed decoder optimized. comparison also trained autoencoders architecture reconstruction nets i.e. also allowed training ﬁne-tune parameters alexnet part. provides upper bound quality reconstructions might expect inversion networks figure effect color classiﬁcation reconstruction layer left right input image reconstruction reconstruction largest activations reconstruction activations except largest ones. network prediction conﬁdence shown. much better reconstructions autoencoders. even conv features input image reconstructed alperfectly. reconstructing fully connected layers autoencoder results blurred compressed representation much ﬁxed alexnet weights. autoencoder training training ﬁxed alexnet gives estimate amount image information lost training objective alexnet based reconstruction quality. interesting observation autoencoders reconstruction error quite high even reconstructing conv features best reconstructions actually obtained conv. explanation convolution stride consequent max-pooling conv loses much information image. decrease reconstruction error beneﬁcial network slightly blur image instead guessing details. reconstructing deeper layers deeper networks learn better prior resulting slightly sharper images slightly lower reconstruction error. even deeper layers representation gets compressed error increases again. observed without stride ﬁrst layer reconstruction error autoencoders much lower. performed simple experiment illustrating color information inﬂuences classiﬁcation preserved high level features. took image apple flickr modiﬁed make green blue. extracted alexnet features resulting images. remind last layer network features application softmax give network’s prediction class probabilities. largest activation hence corresponds network’s prediction image class. check class-dependent results inversion passed three versions feature vector inversion network vector itself activations except largest ones zero largest activations zero. leads several conclusions. first color clearly important classiﬁcation feature representation network sensitive least cases. second color image precisely reconstructed even equivalently predicted class probabilities. third reconstruction quality depend much predictions network rather small probabilities classes. consistent ’dark knowledge’ idea small probabilities non-predicted classes carry information prediction itself. examples shown supplementary material. shown high level feature maps preserve rich information image. information represented feature vector? difﬁcult answer question precisely gain insight perturbing feature representations certain ways observing images reconstructed perturbed features. perturbing features certain change reconstruction much perturbed property important. example setting non-zero feature zero change reconstruction feature carry information useful reconstruction. applied binarization dropout. binarize feature vector kept signs entries absolute values ﬁxed number selected euclidean norm vector remained unchanged layers except feature vector entries nonnegative hence binarization sets non-zero entries ﬁxed positive value. perform dropout randomly feature vector entries zero normalize vector keep euclidean norm unchanged qualitative results perturbations features different layers alexnet shown figure quantitative results shown figure surprisingly dropout leads larger decrease reconstruction accuracy binarization even layers applied training. layers especially binarization hardly changes reconstruction quality all. although known binarized convnet features perform well classiﬁcation comes surprise reconstructing input image exact values features important. virtually information image contained binary code given pattern non-zero activations. figures show binary code emerges training classiﬁcation objective dropout autoencoders sensitive perturbations features. test robustness binary code applied binarization dropout together. tried dropping random activations least non-zero activations binarizing. dropping least activations reduces error much less dropping random activations even better applying dropout layers. however layers interesting ones dropping random activations decreases performance substantially dropping least activations results small decrease. possibly exact values features affect reconstruction much estimate importance different features. sponding images generated reconstruction networks. seen reconstructions feature vectors actual images feature vector generated natural image? figure show reconstructions obtained networks interpolating feature vectors images. interesting interpolating conv features leads simple overlay images behavior interpolations reconstructing different images smoothly morph other. examples together results autoencoders shown supplementary material. another analysis method sampling feature vectors randomly. networks trained reconstruct images given feature representations distribution feature vectors unknown. hence simple principled sample model. however assuming independence features approximate distribution dimension feature vector separately. simply computed histogram feature images sampled those. ensured sparsity random samples actual feature vectors. procedure contrast images perhaps independently sampling dimension introduce interactions features. multiplying feature vectors constant factor increases contrast without affecting properties generated images. random samples obtained four layers alexnet shown figure pre-selection performed. samples conv look much like abstract samples fully convolutional layers much realistic. shows networks learn natural image prior allows produce somerealistically looking images random feature vectors. found much simpler sampling procedure ﬁtting single shifted truncated gaussian feature dimensions produces qualitatively similar images. shown supplementary material together images generated autoencoders look much less like natural images. proposed invert image representations up-convolutional networks shown yields less accurate reconstructions original images depending level invariance feature representation. networks implicitly learn natural image priors allow retrieval information obviously lost feature representation color brightness sift. method fast test time require gradient feature representation inverted. therefore applied virtually image representation. application method representations learned alexnet convolutional network leads several conclusions features layers network including ﬁnal layer preserve precise colors rough position objects image; higher layers almost information input image contained pattern non-zero activations precise values; layer information input image contained small probabilities classes top- network predictions. acknowledge funding starting grant videolearn grateful aravindh mahendran sharing reconstructions achieved method mahendran vedaldi thank jost tobias springenberg comments.", "year": 2015}