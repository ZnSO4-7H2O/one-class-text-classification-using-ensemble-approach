{"title": "Learning Heterogeneous Similarity Measures for Hybrid-Recommendations in  Meta-Mining", "tag": ["cs.LG", "cs.AI"], "abstract": "The notion of meta-mining has appeared recently and extends the traditional meta-learning in two ways. First it does not learn meta-models that provide support only for the learning algorithm selection task but ones that support the whole data-mining process. In addition it abandons the so called black-box approach to algorithm description followed in meta-learning. Now in addition to the datasets, algorithms also have descriptors, workflows as well. For the latter two these descriptions are semantic, describing properties of the algorithms. With the availability of descriptors both for datasets and data mining workflows the traditional modelling techniques followed in meta-learning, typically based on classification and regression algorithms, are no longer appropriate. Instead we are faced with a problem the nature of which is much more similar to the problems that appear in recommendation systems. The most important meta-mining requirements are that suggestions should use only datasets and workflows descriptors and the cold-start problem, e.g. providing workflow suggestions for new datasets.  In this paper we take a different view on the meta-mining modelling problem and treat it as a recommender problem. In order to account for the meta-mining specificities we derive a novel metric-based-learning recommender approach. Our method learns two homogeneous metrics, one in the dataset and one in the workflow space, and a heterogeneous one in the dataset-workflow space. All learned metrics reflect similarities established from the dataset-workflow preference matrix. We demonstrate our method on meta-mining over biological (microarray datasets) problems. The application of our method is not limited to the meta-mining problem, its formulations is general enough so that it can be applied on problems with similar requirements.", "text": "abstract—the notion meta-mining appeared recently extends traditional meta-learning ways. first learn meta-models provide support learning algorithm selection task ones support whole data-mining process. addition abandons called black-box approach algorithm description followed meta-learning. addition datasets algorithms also descriptors workﬂows well. latter descriptions semantic describing properties algorithms cost functions learning biases etc. availability descriptors datasets data-mining workﬂows traditional modelling techniques followed meta-learning typically based classiﬁcation regression algorithms longer appropriate. instead faced problem nature much similar problems appear recommendation systems. however time requirements metamining tasks make direct tools recommender systems rather inappropriate. important meta-mining requirements suggestions datasets workﬂows descriptors cold-start problem e.g. providing workﬂow suggestions datasets. paper take different view meta-mining modelling problem treat recommender problem. order account meta-mining speciﬁcities derive novel metric-based-learning recommender approach. method learns homogeneous metrics dataset workﬂow space heterogeneous dataset-workﬂow space. learned metrics reﬂect similarities established dataset-workﬂow preference matrix. latter constructed performance results obtained application workﬂows datasets. demonstrate method meta-mining biological problems. application method limited meta-mining problem formulations general enough applied problems similar requirements. meta-learning learning learn computer science application machine learning techniques metadata describing past learning experience typically applications learning algorithms speciﬁc datasets order derive meta-learning models support selection appropriate algorithm dataset meta-learning models usually classiﬁcation regression models learned standard classiﬁcation regression algorithms. recently meta-learning focusing learning part data mining process trying model behavior different learning algorithms treating learning algorithms black-boxes making effort describe concepts underline properties. authors made effort address limitations extending meta-learning process whole data mining process resulting comprehensive task called meta-mining. addition made data mining ontology order provide detailed descriptions data mining algorithms terms core components underlying assumptions cost functions optimization strategies well detailed descriptions data mining workﬂows latter composed operators implementing data mining algorithms. even though introduction data mining algorithm workﬂow descriptors important step authors made rather poor modelling meta-mining problem classiﬁcation problem following thus traditional metalearning modelling approach. classiﬁcation problem meta-mining instances corresponded data mining experiments applications workﬂows algorithms datasets consisted types features features described dataset features describe data mining workﬂow. class label determined basis performance result estimated application workﬂow dataset indicating appropriateness workﬂow dataset. paper take different approach modelling meta-learning meta-mining tasks. view matching problem datasets hand data mining algorithms workﬂows other matching criterion performance latter applied former. address three different meta-mining tasks. given dataset want recommend rank available algorithms data mining workﬂows terms expected performance speciﬁc dataset; call task learning workﬂow preferences. symmetrically want given data mining workﬂow algorithm know datasets appropriate; call task learning dataset preferences. finally given dataset workﬂow algorithm want able determine goodness match i.e. degree latter good performance applied former; call learning dataset-workﬂow preferences. obvious determined without actual application algorithms datasets basis meta-mining model learned past mining experiences. type problems similar nature problems appear recommender systems users items want suggest additional items given user based preferences users similar preferences. meta-mining meta-learning case matrix containing preferences users items replaced performance based matrix datasets workﬂows algorithms indicates performance latter applied former. performance-based preference matrix component metamining data; addition dataset workﬂow algorithm descriptors. ﬁnal meta-mining models dataset workﬂow descriptors return preferences. recommender systems relevant stream work makes descriptors users items similar descriptors datasets workﬂows called hybrid recommendation systems however also number differences nature recommendation problem meta-mining typical recommendation problems. latter preferences matrix often sparse high dimensionality hundreds thousands rows/users. contrast preferences matrix metamining rather dense involves hundreds datasets workﬂows. features datasets workﬂows meta mining problems quite informative contrast typical recommendation problems rather hard informative features especially concerns user descriptions. finally meta mining setting cold-start problem central typical example predicting workﬂow preferences dataset. however recommendation problem partly information content features describing users also nature problem itself main focus completion missing values preferences matrix based historical ratings items similar users. speciﬁcally learn three different metrics. dataset descriptor space reﬂect fact similar datasets similar workﬂow preferences given performance-based preference matrix. workﬂow descriptor space reﬂect fact similar workﬂows similar dataset preferences given performancebased preference matrix. last heterogeneous metric spaces dataset workﬂow descriptors directly give similarity/appropriateness given dataset given workﬂow. learned metrics alone combination address three metamining tasks described previous paragraphs. best knowledge metric learning approach present ﬁrst kind meta-mining also general context hybrid recommendation problems. even though developed address speciﬁc requirements meta-mining setting speciﬁc used kind recommendation system similar requirements i.e. preference based matchings users items based descriptions cold-start problem. rest paper organized follows. section deﬁne meta-mining tasks. section describe metric-learning based approach problem learning hybrid recommendations meta-mining. section present brieﬂy characteristics—features— describe datasets workﬂows. section give experiments evaluation approach. section discuss related work ﬁnally conclude section vii. proceeding deﬁnition different metamining tasks address give necessary notations. description dataset dataset matrix dataset. thus given matrix datasets meta-mining take place. addition description data mining workﬂow workﬂow matrix workﬂow i.e. data mining workﬂow matrix meta-mining take place. finally matrix entry depends performance result obtained application data mining workﬂow dataset. notation denote vector given corresponds dataset contains performance measures obtained application data mining workﬂows notation denote vector given column contains performance results application data-mining workﬂow datasets. thus matrix since focus meta-mining classiﬁcation problems performance measure using based classiﬁcation accuracy estimate ten-fold cross-validation. accuracies achieved different workﬂows comparable different datasets much important meta-learning meta-mining relative performance order data mining workﬂows algorithms given dataset; relative order compared meaningful manner different datasets. devise relative order following way. given pair classiﬁcation data mining workﬂows applied dataset compute statistical signiﬁcance accuracies differences using mcnemar’s test pvalue workﬂow statistically signiﬁcant better assigned score score zero case signiﬁcant difference assigned score given dataset score workﬂow points gets pairwise comparisons workﬂows. score populate matrix i.e. entry score obtained workﬂow dataset also notation rxiaj denote entry given deﬁne three different metamining tasks. ﬁrst given unseen dataset i.e. dataset experimented with want estimate relative performance order data mining workﬂows. words want estimate relative workﬂow performance workﬂow preference vector dataset. call task learning workﬂow preferences. second meta-mining task symmetric ﬁrst; want estimate appropriateness unseen workﬂow datasets i.e. want estimate dataset preference vector workﬂow. call task learning dataset preferences finally third last difﬁcult meta-mining task want estimate appropriatness unseen workﬂow unseen dataset i.e. estimate value. call meta-mining task learning datasetworkﬂow preferences. address three tasks rely appropriate similarity measures. learn workﬂow preferences need dataset similarity measure given dataset establish similar datasets training workﬂow preference vectors datasets estimate workﬂow preference vector manner learn dataset preferences need workﬂow similarity measure given workﬂow establish similar workﬂows training dataset preference vectors workﬂows estimate dataset preference vector last task rely heterogeneous similarity measure computes directly similarities workﬂows datasets thus given unseen dataset unseen workﬂow produce corresponding appropriateness starting describe detail address three meta-mining tasks take step back give abstract picture type learning setting want address. types learning instances training matrices respectively. additionally also instance alignment preference matrix entry gives measure appropriateness preference match instances. construct similarity matrix instances exploiting idea similar instances similar preferences respect instances matrix. rely anymore original representation instances order deﬁne similarities preferences respect instances. instances similarity matrix matrix entry give similarity instances. exactly manner construct similarity matrix instances learn mahalanobis metrics space reﬂect instance similarities given similarity matrices respectively. addition want learn third metric heterogeneous spaces reﬂect similarity/preference instance instance given preference value. since learning mahalanobis metric equivalent learning linear transformation following paragraphs actually need learn eventually linear transformations space optimize three objective functions sketched. this reﬂects basic assumptions metalearning fact trying reﬂect similarity datasets terms relative performance/appropriateness different learning paradigms/algorithms describe learn mahalonobis metric matrix dataset space manner reﬂect datasets similarity terms similarity workﬂow preference vectors. instead using matrix establish similarity datasets terms preference vectors dataset similarity simply inner product workﬂow preference vectors rely pearson rank correlation coefﬁcient preference vectors. latter appropriate measure dataset similarity since focuses relative workﬂow performance relevant wants measure dataset similarity. nevertheless simplify notation continue using notation. ||.||f frobenius matrix norm matrix trace parameter controlling trade-off empirical error metric complexity used control overﬁtting convex optimization problem. already mentioned learning mahalanobis metric matrix equivalent learning linear transformation original feature space. thus rewrite metric learning problem help linear transformation metric matrix associated linear transformation dimensionality projects dataset description space dimensionality unlike previous optimization problem longer convex. work optimization problem make easier variable sharing different optimization problems deﬁne. solve using gradient descent. using learned metric similarity datasets xiuut given dataset similarity establish consisting datasets similar respect similarity relative workﬂow preferences computed original feature space help compute workﬂow preference vector weighted average workﬂow preference vectors nearest neighbors normalization factor given pxi∈x thus using learned metric compute workﬂow preference vector dataset computing similarity training datasets feature space similarity learned manner reﬂects datasets similarity terms relative workﬂow preferences. learn mahalanobis metric matrix data mining workﬂow space proceed exactly manner datasets using matrix elements give rank correlation coefﬁcients dataset preference vectors workﬂows measuring thus similarity workﬂows terms relative performance different datasets. precisely start metric learning optimization problem metric matrix associated linear transformation dimensionality projects workﬂow descriptions space dimensionality. convex optimization problem. solve using gradient descent. similar dataset case using learned metric similarity workﬂows aivvt given workﬂow workﬂow neighborhood consists workﬂows similar respect similarity relative dataset preferences computed original feature space help compute dataset preference vector weighted average dataset preference vectors nearest neighbors normalization factor given pai∈a thus using learned metric compute dataset preference vector workﬂow computing similarity training workﬂow feature space similarity learned manner reﬂects workﬂows similarity terms relative dataset preferences. last metric want learn relate datasets data mining workﬂows reﬂecting appropriateness/preference given workﬂow given dataset terms relative performance former applied latter. starting following metric learning optimization problem essentially project descriptions datasets workﬂows common space dimensionality compute similarity manner reﬂects preference matrix rank). words learn heterogeneous metric computes similarities datasets workﬂows terms relative performance latter applied former. using similarity metric compute directly match dataset workﬂow clearly determine goodness match dataset data mining workﬂow also given dataset workﬂows order latter according appropriateness respect former thus solving meta-mining task vice versa given workﬂow datasets order latter according appropriateness former thus solving meta-mining task objective function optimization problem focus exclusively trying learn metric reﬂect appropriateness workﬂow dataset given entries preference matrix. however additional information bring exploit objective functions optimization problems additionally regularize objective function overall idea learn three different metrics spaces datasets workﬂows datasets-workﬂows parametrized linear transformations manner reﬂect basic meta-mining assumptions namely similar datasets similar workﬂow preference vectors similar workﬂows similar dataset preference vectors heterogeneous metric datasets workﬂows reﬂect appropriateness datasets workﬂows. combining three optimization problems following metric learning optimization problem achieves goals positive parameters control importance three different optimization terms. case optimization problem optimization problem also used address three meta-mining tasks. fact general formulation metric-learning based hybrid reccomendation problem includes special cases problems matrix factorization often used recommender systems also learns decomposition matrix component matrices different constraints. however nature cannot handle well out-of-sample problem. objective function problem uses additional constraints objective functions learns common space datasets workﬂows induced projection matrices result out-of-sample problem i.e. cold start problem recommender system naturally handled optimization problem originally proposed statlog project idea characterizing datasets main stream meta-learning last decades various characterizations subsequently proposed selected relevant ones summarized follows statistical measures number instances number classes proportion missing values proportion continuous categorical features noise signal ratio. information-theoretic measures class entropy mutual information. geometrical topological measures non-linearity volume overlap region maximum ﬁsher’s discriminant ratio fraction instance class boundary ratio average intra/inter class nearest neighbour distance. model-based measures error rates pairwise values obtained landmarkers zeror one-nearestneighbor naive bayes decision stumps random trees linear distributions weights learned relief svmrfe feature selection algorithms. overall large spectrum dataset characteristics simple ones number instances elaborated ones model-based measures giving total number dataset characteristics. ability describe data mining algorithms workﬂows descriptors meta-learning metamining recent development authors used dmop data mining ontology describe learning algorithms data-processing algorithms feature selection discretization normalization respect mathematical concepts implement different properties bias/variance proﬁle sensitivity type attributes learning strategy etc. addition ontology allows anotate operators data mining workﬂows respective concepts. data mining workﬂow typically direct acyclic graph data mining operators. order describe data mining workﬂows follow propositionalization approach used derive annotated direct acyclic graphs describe data mining workﬂows frequent closed workﬂow patterns using tree-structured apriori algorithm description workﬂow given binary vector indicates presence absence frequent patterns; ﬁnal workﬂow description contains features. ﬁgure give examples workﬂow patterns abstracted ground feature selection classiﬁcation workﬂows based dmops algorithm hierarchy. patterns help understand workﬂow space structured describing frequent workﬂow structures using dmop concepts. section perform systematic evaluation examine performance different metric learning optimization problems meta-mining presented previous sections. precisely evaluate performance dataset metric learning optimization problem given meta-mining task learning workﬂow preferences given dataset; performance workﬂow metric learning optimization problem meta-mining task learning dataset preferences; ﬁnally performance metric learning optimization problems three meta-mining tasks. order meta-mine ﬁrst need perform base-level experiments construct meta-mining models. used real world cancer microarray datasets taken national center biotechnology information microarray datasets characterized high-dimensionality small sample size relatively number classes often two. datasets average instances attributes classes. datasets applied total classiﬁcation data mining workﬂows; workﬂows contained feature selection classiﬁcation algorithm seven remaining ones single classiﬁcation algorithm. used four following feature selection algorithms information gain chi-square relieff recursive feature elimination svmrfe ﬁxed number selected features ten. classiﬁcation used seven following algorithms one-nearest-neighbor cart decision tree algorithms naive bayes algorithm normal probability estimation logistic regression algorithm linear svml svmr kernels. used implementations algorithms provided rapidminer data mining suite default parameters. overall total base-level experiments i.e. applications workﬂows datasets. construct preference matrix estimated performance workﬂows using -fold cross-validation applied scoring mcnemar based scoring schema described section table give workﬂows full datasets number times ranked positions. order assess well different variants perform need compare default baseline strategies. meta-mining task workﬂow preference learning default strategy preference vector given average workﬂow preference vectors different training datasets given testing dataset. note rather difﬁcult baseline respectively. spearman’s rank correlation coefficient give average accuracy five workflows proposed strategy mean average error. indicates number times method better beat since different workﬂows ranked according average performance training datasets workﬂows perform consistently well ranked top. second task providing dataset preference vector given testing workﬂow similar default strategy average dataset preference vectors different training workﬂows. however strategy workﬂows leads trivial constant vector dataset preferences fact total workﬂow points given dataset ﬁxed compare workﬂows nature workﬂow ranking schema given dataset. finally last meta-mining task default strategy prediction appropriateness workﬂow dataset average values preference matrix training set. denote default strategy used three meta-mining tasks def. addition also baseline strategy provision recommendation simple euclidean distance i.e. attributes treated equally learning denote however baseline applicable ﬁrst meta-mining tasks learning workﬂow preferences learning dataset preferences since cannot applied kind heterogeneous similarity problem third meta-mining task. resampling techniques leave-one-datasetestimate performance workﬂow preference learning task leave-one-workﬂow-out dataset preference learning task leave-one-dataset-and-one-workﬂowthird task predicting appropriateness quantify performance number evaluation measures. ﬁrst meta-mining tasks report average spearman’s rank correlation coefﬁcient predicted preference vector real preference vector testing instances. denote average measure indicate degree different methods predict correctly preference order. note quantity computable default strategy case learning dataset preferences task fact dataset preference vector produces ﬁxed explained previously spearman rank correlation coefﬁcient computable vectors ﬁxed. addition spearman rank correlaction coefﬁcient meta-mining task learning workﬂow preferences also report average accuracy workﬂows suggested method measure denote finally three meta-mining tasks also report mean average error respective testing instances predicted values learning workﬂow preferences dataset preferences dataset-workﬂow preferences respectively true values. measure method meta-mining task give number times method better respective default baseline strategies total number datasets workﬂows dataset workﬂow pairs well statistical signiﬁcance result binomial test statistical signiﬁcance level comparison learning workﬂow preferences learning algorithm preferences popular formulation traditional stream meta-learning. given dataset description seek identify algorithm probably deliver best results given dataset. sense meta-mining task similar typical metalearning task. presented three different objective functions used address problem. optimization problem makes dataset descriptors learns similarity measure space best approximates similarity respect relative workﬂow preference vectors. traditional metalearning similarity computed directly dataset space learned importantly model relative workﬂow preference vector experimental setting strategy implements traditional meta-learning approach euclidean distancebased dataset similarity addition homogeneous metric learning approach also heterogeneous metric learning variants provide workﬂow preferences. simplest corresponding optimization function optimization problem uses dataset workﬂow characteristics tries directly approximate relative preference matrix. however approach ignores fact learned metric reﬂect basic meta-mining requirements similar datasets similar workﬂow preferences similar workﬂows similar dataset preferences. optimization function optimization problem reﬂects exactly bias regularizing appropriately learned metrics dataset workﬂow spaces reﬂect well similarities respective preference vectors. discussing actual results given left table table give parameter settings different variants. parameters reﬂect think appropriate choices based prior knowledge meta-mining problem. better results would obtained tuned least them inner cross validation. looking actual results right away approach makes dataset characteristics performance statistically signiﬁcant different neither default baseline respect spearman’s rank correlation coefﬁcient average accuracy workﬂows statistically signiﬁcant suggests worse respect mean average error criterion lower value datasets. looking performance heterogeneous metric tries directly approximate preference matrix results quite disappointing. signiﬁcant worse default strategy baseline almost performance measures. trying learn heterogeneous metric relies exclusively approximation preference matrix deﬁnitely option. however turn objective function learns heterogeneous metrics manner reﬂect preference manner also fact similar datasets similar workﬂow preferences vice versa performance excellent. beats statistically signiﬁcant manner default strategy well baseline almost cases exception spearman’s correlation coefﬁcient comparison default level signiﬁcance high overpass signiﬁcance threshold overall recommendation scenario best strategy consists learning combination homogeneous heterogeneous metrics reﬂect similarities datasets respect workﬂow preferences similarities workﬂows respect dataset preference vectors well similarities workﬂowsdatasets according preference matrix. learning dataset preferences goal metamining task given workﬂow collection datasets provide dataset preference vector reﬂect order appropriateness datasets given workﬂow. already mentioned default strategy provides vector equal ranks thus cannot compute sperman’s rank correlation coefﬁcient. compare performance objective function makes workﬂow descriptors tries approximate similarity dataset preference vectors used following parameter looking results middle table table comes mean average error methods achieve performance statistically signiﬁcant better default strategy suggesting metamining task probably easier ﬁrst one. makes sense since easier describe workﬂow similarity terms concepts workﬂows describe dataset similarity terms datasets characteristics. neither performance statistically signiﬁcant better euclidean baseline. nevertheless statistically signiﬁcant better euclidean comes sperman’s rank correlation coefﬁcient. thus meta-mining task learning dataset-workﬂow preferences last meta-mining task difﬁcult one. want predict appropriateness workﬂow dataset value. metric functions applicable since ones heterogeneous i.e. compute similarity dataset workﬂow. note also euclidean baseline strategy longer applicable used objects type. comes mean average error poor performance compared default strategy. considerably better performance thus providing support incorporation additional constraints objective function nevertheless performance still signiﬁcantly worse default default strategy. overall tested number metric-learning-based algorithms solve different variants meta-mining problem following hybrid recommendation approach. metric-based-learning ﬂavors homogeneous heterogeneous. homogeneous ﬂavor learn metric original space objects described datasets workﬂows tries approximate similarity deﬁned different space relative preference vectors. heterogeneous approach learn metric different spaces tries reﬂect directly goodness match different objects. turns best approach comes appropriate regularization heterogeneous metric exploiting additional constrains imposed original object spaces. words seek heterogeneous metric deﬁned common projection space datasets workﬂows projection matrices datasets workﬂows constrained reﬂect vector preference similarities. immediate future want evaluate performance approach presented recommendations problems meta-mining similar problem requirements. meta-mining problem formulation gave closely related work hybrid recommender systems goal accurately recommend items users using information historical user preferences descriptors items users. examples recommender user item descriptors found instance movielens dataset demographic activity information users gender occupation taxonomic information movies genre release date. state recommender methods rely matrix factorization methods directly approximate preference matrix optimization problem authors proposed bayesian approach probabilistic bi-linear rating model inferred combination expectation propagation variational message passing. users items features modelled gaussian priors matrices latent traits inner product deﬁnes user-item similarities. variational approximation users items used regularize latent factors. experiments movielens dataset showed including user item descriptors improves performance. propose also generative probabilistic model model ﬁtting done monte carlo algorithm variational approximations. regularize model using regression-based approach user item factors latter determined using topic modelling also experimented movielens dataset showed model based meta-data weak predictive performance regression-based approach latent factors regularization gave best performance improvements. metric-learning-based approach problem hybrid recommendation uses different regularization approach learning factorization matrices focus constraining manner reﬂect original feature spaces similarities respective preference vectors approach meta-mining experiments best performance. additional advantage linear projection matrices learned dataset workﬂow spaces naturally handle out-of-sample problem i.e. cold-start problem recommender systems case typical matrix factorization models. paper take view relatively concept meta-mining view also relevant traditional work meta-learning. model problem selection appropriate workﬂow algorithm dataset hybrid recommendation problem suggestions provided based descriptors dataset workﬂow algorithm. propose metric-learning-based approach hybrid recommendation problem learns homogeneous metrics original dataset workﬂow spaces constrained manner reﬂect workﬂow preference dataset preference vector similarities combines heterogeneous metric datasetworkﬂow space reﬂects appropriateness given workﬂow given dataset. homogeneous metriclearning problems additional relevant regularizers heterogeneous metric learning problem. addition thanks linear projections core method able handle natural manner cold-start problem. combined three metrics achieves best results. best knowledge ﬁrst approach kind meta-mining problem well general problem hybrid recommendation. immediate goal experiment approach standard hybrid recommendation problems movielens dataset compare performance typical recommendation approaches used problems. hilario nguyen woznica kalousis ontology-based meta-mining knowledge discovery workﬂows meta-learning computational intelligence jankowski duch grabczewski eds. springer agarwal b.-c. chen matrix factorization latent dirichlet allocation proceedings third international conference search data mining ser. wsdm york soares brazdil zoomed ranking selection classiﬁcation algorithms based relevant performance information proceedings european conference principles data mining knowledge discovery ser. pkdd london springer-verlag k¨opf taylor keller meta-analysis data characterisation meta-learning meta-regression proceedings pkdd- workshop data mining decision supportmeta-learning hilario kalousis fusion meta-knowledge meta-data case-based model selection proceedings european conference principles data mining knowledge discovery ser. pkdd london springer-verlag langley induction one-level decision trees proceedings ninth international workshop machine learning ser. francisco morgan kaufmann publishers inc. zaki efﬁciently mining frequent trees forest algorithms applications ieee transactions knowledge data engineering vol. special issue mining biological data. breiman friedman olshen stone classiﬁcation regression trees ser. statistics/probability series. belmont california u.s.a. wadsworth publishing company", "year": 2012}