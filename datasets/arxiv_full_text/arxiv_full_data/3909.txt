{"title": "Evolution of a Subsumption Architecture Neurocontroller", "tag": ["cs.AI", "cs.NE", "I.2.9; I.2.6"], "abstract": "An approach to robotics called layered evolution and merging features from the subsumption architecture into evolutionary robotics is presented, and its advantages are discussed. This approach is used to construct a layered controller for a simulated robot that learns which light source to approach in an environment with obstacles. The evolvability and performance of layered evolution on this task is compared to (standard) monolithic evolution, incremental and modularised evolution. To corroborate the hypothesis that a layered controller performs at least as well as an integrated one, the evolved layers are merged back into a single network. On the grounds of the test results, it is argued that layered evolution provides a superior approach for many tasks, and it is suggested that this approach may be the key to scaling up evolutionary robotics.", "text": "abstract. approach robotics called layered evolution merging features subsumption architecture evolutionary robotics presented advantages discussed. approach used construct layered controller simulated robot learns light source approach environment obstacles. evolvability performance layered evolution task compared monolithic evolution incremental modularised evolution. corroborate hypothesis layered controller performs least well integrated evolved layers merged back single network. grounds test results argued layered evolution provides superior approach many tasks suggested approach scaling evolutionary robotics. introduction layered evolution chief problems evolutionary robotics scaling evolving robot controllers solve complicated problems tackle complicated variable environments. many strategies achieve scaling devised tried prominent incremental evolution modularised evolution. incremental evolution refers practice changing fitness function evolution controller e.g. coke can-collecting robot might evolved fitness initially dependent close average gets objects mean population fitness high enough fitness function changed fitness made dependent many cans actually collected evolvability thus increased smoothing fitness landscape evolutionary algorithm; latter criterion used beginning fitness landscape would probably steep allow progress random population neurocontrollers would pick cans all. modularised evolution term work performed number different authors example stefano nolfi’s research team evolve robot controllers consisting neural network experiments several networks present start others network evolved duplicated none experiments functional differentiation networks decided humans. believe strategies combined much learn looking neighbouring research fields. behaviour-based robotics active research field since mid-eighties rodney brooks invented subsumption architecture upon variations majority work field done relative complexity tasks solvable robots tradition merits closer look features paradigm. subsumption architecture robot controller divided layers layer human-designed piece hardware software responsible particular behaviour. lower layers responsible simpler vital behaviours higher layers complicated behaviours. chain command strictly unidirectional higher layers allowed influence ovveride outputs lower layers allowed dependent lower layers functioning; lower layers never allowed depend higher layers order function properly. typical robot layers receive inputs sensors lower layers directly influence actuators. approach evolutionary robotics advocating pursuing paper layered evolution combining incremental modularised evolution elements subsumption architecture. basically robot layered evolution controlled subsumption-style controller layer evolutionary neural network several possible types. neural network-layers evolved sequence lowest layer evolved first desired fitness layer reached development stopped another layer added fitness function changed evolution layer commences. evolution layer lower layers present frozen configuration identical individuals population undergoing evolution; configuration highest layer differs individuals. beyond incremental evolution begin with advantages incremental evolution carry layered evolution. separate layers perform different parts task must evolved different fitness criteria case incremental evolution smoothens fitness landscape. network size updating speed search dimensionality complexity operation measured number times frequent operation performed comes updating neural networks number synapses counts also direct encodings synapse occupies position genome string thus contributes dimension evolutionary search space reducing dimensionality essential many classic learning algorithms number synapses interesting network topologies. separating networks theoretically able wonders scalability networks neurons times fewer synapses network neurons difference gets greater moves towards complexity real nervous systems. forcing functional separation helps evolving completed mechanism anymore starting evolve evolution benefits several ways. computations wasted trying solutions something that’s already finished risk destroying completed mechanism case search runs flat area behavioural differences affect fitness also eliminated. apart less obvious advantages consider nolfi’s recent observation could actually improve evolvability fully connected network strategic lesion generally evolution mechanisms benefits hindering mechanisms obstructing them fully connected network every neuron affects every change ceteris paribus lowers fitness several network types controller noted above several different types neural networks used evolutionary robotics research. although researchers networks incorporating features several network types adding features network adds network updating time dimensionality search space layered architecture hand makes easy select right type network layer perceptron-like reactive behaviour plastic learning behaviour etcetera. good design principles reusability finally consider main engineering argument layered evolution introduces good engineering principles layered evolution. though evolution good coming creative indeed surprising solutions many problems solutions often look like mess schooled engineer might scale simplistic behaviours ever evolved. layered evolution introduces modularity evolutionary robotics modularity comes reusability. time modular future might even universal repository ready-evolved layers free anyone include controller architecture build upon. interpretations objections scientific side evolutionary robotics subsumption architecture interpreted terms neurophysiologic behavioural layers inspired hypotheses fields. discuss possible uses layered evolution scientific modelling dissertation also respond possible criticisms approach. test main hypothesis layered evolution faster reliably produces desired behaviours monolithic incremental evolution compared methodologies applied problem designing neural controller simulated robot would perform goal-seeking behaviour lifetime learning cluttered environment. task interesting requires quite different behaviours simple reflexlike obstacle avoidance less predictable still possibly reactive conditional phototaxis non-reactive learning behaviour. also interesting learning behaviours usually quite difficult evolve know done environment obstacles methods robot simulation based existing robot though loosely inspired khepera. robot circular moves rectangular world fixed dimensions. world includes light sources possibly also rectangular obstacles randomly placed. light sensor mounted robot’s movement direction correspond light source each signal intensity dependent angle distance respective light source. three obstacle sensors signal close obstacles; running obstacle stops robot’s motion. robot controlled architecture incorporating three feedforward neural networks. case single network network’s outputs drive wheels directly; cases subsumption mechanism connects outputs layer wheels thus third output layer higher first outputs layer connected wheels otherwise outputs layer used. neurons tanh squashing function. synapses either fixed case number synapse encoded directly genome plastic updating rules encoding plastic synapses taken directly work floreano mondada neural networks consist fixed plastic combination synapse types. networks extra input constant value one. evolving networks algorithm least half genome population replaced clones half genomes except five best mutated every generation used. genome’s fitness calculated lowest fitness five trials. done generations times task. robot’s ultimate task divided three subtasks conditional phototaxis means moving staying close correct light source specified external input obstacle avoidance learning. fitness first subtasks measured mean distance correct light source time steps without obstacles. learning subtask robot told light source right gets feedback light source touched whether correct upon touching time sources moved random locations. fitness measured number times right light source touched minus number times wrong touched robot moved time steps. fig. incremental evolution conditional phototaxis obstacle avoidance. fitness runs along vertical axis evolutionary time along horizontal axis. upper line shows fitness best genome population every generation lower line shows average fitness population. fitness scores averaged runs subexperiment. conventions apply subsequent graphs paper. monolithic evolution network nine inputs interneurons outputs hybrid synapses evolved full task. mean population fitness never differed significantly zero. help monolithic evolution it’s distribution target light sources changed three cases target light source condition evolved robots displayed rudimentary phototaxis towards light neither obstacle avoidance learning. fitness stayed low. removing learning element network evolved conditional phototaxis; obstacles present fitness stayed chance level without obstacles satisfactory phototaxis evolve. incremental evolution network mentioned evolved generations without obstacles obstacles added evolution continued generations more. conditional phototaxis evolved quickly before obstacles added fitness fell drastically remained remarkably controllers generation performed much worse tested environment without obstacles generation obstacle avoidance evolve conditional phototaxis also lost probably genetic drift absence selection pressure. modularised evolution controller networks evolved conditional phototaxis obstacle avoidance. first network four inputs three interneurons outputs; second network three inputs three outputs networks fixed synapses evolved simultaneously. controllers good phototaxis reasonable obstacle avoidance. approach would work learning well third layer added four inputs interneurons output connected conditional output layer networks evolved scratch simultaneously. systematic fitness increase seen sensible behaviour. layered evolution layers evolved sequentially building upon other readyevolved layers frozen. networks used. secondly obstacle avoidance network added evolution continued first layer frozen. decent obstacle avoidance evolved generations; systematic mean fitness thirdly learning network added. five generations controllers good learning capability present thirty generations substantial fitness increases seen suggests learning taken hard behaviour evolve. analysis evolved network confirms suggestion. controller following case default mode covariance negative connection reward input interneurons another interneuron output neuron plain hebbian connection stable input interneuron. layer always outputted zero robot ever touched wrong light switched always outputting one. different simpler would designed mechanism. certainly seems layered evolution quickly reliably evolves desired behaviours cannot excluded advantages integrating behaviours network. first investigation topic decided merge together layers ready-evolved layered architecture would increase fitness beyond pure layered structure. methods ready-evolved controllers neural connection layers added capable propagating activations like fixed synapses higher lower layers. layers zero connections outset evolutionary every generation particular genome mutated every connection connection layers probability mutation rate deleted; also every layer probability mutation rate adding connection random neuron layer random neuron below strength results best genomes results evolutionary runs sub-experiment used seed runs. first controllers evolved generations more networks mutable. small fall mean population fitness observed within first generations probably loss homogeneity population mean fitness stood still. repeating sub-experiment added connection layers showed discernible difference first condition; mean fitness never exceeded first generation. mean size connection layers three connections indicates selection pressure interlayer connections hard-coded ones. results presented paper show particular robot task conditional phototaxis changing goals environment obstacles evolvability drastically improved organizing controller according subsumption architecture evolving layers time. fact evolutionary robotics approach seems able evolve solution complete task advantages combining behaviours network found. whether enhanced evolvability layered evolution truly generalizable represents something golden road scaling evolutionary robotics certainly interesting question future. possible many interesting problems amenable behavioural deconstruction fashion possible behavioural layers practically impossible evolve themselves. needs investigated. article based dissertation done university sussex supervision ezequiel paolo thanks dyre bjerknes ziemke anonymous reviewers valuable comments.", "year": 2004}