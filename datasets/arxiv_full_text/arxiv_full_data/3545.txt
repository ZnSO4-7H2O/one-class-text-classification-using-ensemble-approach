{"title": "Few-shot Learning by Exploiting Visual Concepts within CNNs", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Convolutional neural networks (CNNs) are one of the driving forces for the advancement of computer vision. Despite their promising performances on many tasks, CNNs still face major obstacles on the road to achieving ideal machine intelligence. One is that CNNs are complex and hard to interpret. Another is that standard CNNs require large amounts of annotated data, which is sometimes hard to obtain, and it is desirable to learn to recognize objects from few examples. In this work, we address these limitations of CNNs by developing novel, flexible, and interpretable models for few-shot learning. Our models are based on the idea of encoding objects in terms of visual concepts (VCs), which are interpretable visual cues represented by the feature vectors within CNNs. We first adapt the learning of VCs to the few-shot setting, and then uncover two key properties of feature encoding using VCs, which we call category sensitivity and spatial pattern. Motivated by these properties, we present two intuitive models for the problem of few-shot learning. Experiments show that our models achieve competitive performances, while being more flexible and interpretable than alternative state-of-the-art few-shot learning methods. We conclude that using VCs helps expose the natural capability of CNNs for few-shot learning.", "text": "convolutional neural networks driving forces advancement computer vision. despite promising performances many tasks cnns still face major obstacles road achieving ideal machine intelligence. cnns complex hard interpret. anstandard cnns require large amounts annotated data sometimes hard obtain desirable learn recognize objects examples. work address limitations cnns developing novel ﬂexible interpretable models few-shot learning. models based idea encoding objects terms visual concepts interpretable visual cues represented feature vectors within cnns. ﬁrst adapt learning few-shot setting uncover properties feature encoding using call category sensitivity spatial pattern. motivated properties present intuitive models problem few-shot learning. experiments show models achieve competitive performances ﬂexible interpretable alternative state-of-theart few-shot learning methods. conclude using helps expose natural capability cnns few-shot learning. introduction debut convolutional neural networks played ever increasing role computer vision researchers even claimed cnns surpassed human-level performance although work suggests otherwise recent studies also show cnns vulnerable adversarial attacks nevertheless successes cnns inspired computer vision community develop increasingly sophisticated models despite impressive achievements cnns limited insights cnns effective. everincreasing depth complicated structures cnns make difﬁcult interpret non-linear nature cnns makes hard perform theoretical analysis. addition cnns require large annotated datasets problematic many real world applications. argue ability learn examples few-shot learning characteristic human intelligence strongly desirable ideal machine learning system. goal paper develop approach interpretable ﬂexible few-shot learning builds successes cnns. start intuition objects represented terms spatial patterns parts implies objects learned examples built parts already known learned examples. recall previous researchers argued object parts represented convolutional layers cnns provided cnns trained object detection. speciﬁcally build recent work learns dictionary visual concepts cnns representing object parts figure original work proves combined detect semantic parts. recently also shown used represent objects using vc-encoding obvious described applied few-shot learning. firstly learned independently object category using deep network features cnns already trained categories. secondly learned using large numbers examples object category ranging hundreds thousands. contrast few-shot learning learn much smaller number examples moreover deep network features trained datasets including object categories hope learn within shots. means although extract using similar algorithms motivation problem domain different. summarize paper learn models object categories figure visualizations vcs. group consists patches original images closest general patches roughly correspond semantic parts objects e.g. cushion sofa side windows trains wheels bicycles referred indices stress learned unsupervised manner terms likesofa cushion inferred observing closest image patches used describe informally. section review detail. brieﬂy speaking extracted clustering intermediate-level features cnns e.g. features produced pool- layer serving cluster centers feature space divide intermediate-level features discrete dictionary. show learned few-shot learning setting desirable properties used image encoding call category sensitivity spatial pattern. speciﬁcally develop approach few-shot learning ﬂexible interpretable. learn dictionary described enables represent novel objects vc-encoding. propose intuitive models nearest neighbor factorizable likelihood model based vc-encoding. nearest neighbor model uses similarity measure capture difference vc-encodings. factorizable likelihood model learns likelihood function vc-encoding which assuming spatial independence learned examples. emphasize models ﬂexible sense applied directly few-shot learning scenarios. differs approaches trained speciﬁcally scenarios -way -shot ﬂexibility attractive real world applications numbers object categories number examples category variable. despite simplicity models achieve comparable results state-of-the-art few-shot learning methods learning metric learning learn. deeper perspective results show cnns potential few-shot learning novel categories achieve potential required studies internal structures cnns re-express simpler interpretable terms. based properties present simple interpretable ﬂexible models few-shot learning. models yield competitive results compared state-of-the-art methods speciﬁc few-shot learning tasks also applied directly without additional training few-shot scenarios. related work work few-shot learning motivated builds attempts understand internal representations neural networks. therefore review previous literature topics. neural network internal representations recently numerous studies aimed understanding behavior neural networks particular uncover internal representations within cnns. visualize internal representations sampling generating backpropagating images order maximize activations hidden units. particularly relevant work shows object object parts detectors emerge cnns. conversely works investigate discriminative power hidden features cnns assessing speciﬁc problems overall ﬁndings suggest deep networks internal representations object parts. relevant work paper study discovered mid-level visual cues internal features cnns showed relationships visual cues semantic parts work described detail section few-shot learning growing attempts perform few-shot learning motivated attempts mimic human abilities avoid limitations conventional data-demanding learning. early attempt made building probabilistic program induction recent efforts few-shot learning broadly categorized classes. ﬁrst design methods embed inputs feature space friendly few-shot settings goal good similarity measure applied rapidly novel categories. second meta-learning efﬁciently trains ordinary model budget examples alternative approach performs few-shot learning estimating parameters prediction layer using regression previously learned objects. emphasize approach paper differs works many tailored speciﬁc few-shot learning scenarios methods simple ﬂexible work normal almost few-shot settings. figure terms formalization. left n-th input image deﬁned image lattice height width middle lattice layer n-th image noted height width right feature vector position dimensionality background visual concepts discovered internal representations within deep networks roughly correspond mid-level semantic visual cues. play core role work understanding properties cnns developing interpretable few-shot learning models. section review deﬁned learned describe later section modify few-shot learning. ﬁrst summarize formalization illustrated figure cnns contain hierarchy lattices stands layer lattice. particular input image deﬁned lattice lattice derive speciﬁed denote spatial mappings πk→. deﬁne feature vector n-th image refers position lattice feature vectors coma)) function speciﬁed puted subregion n-th neural network input image centered point words responses channels position constitute feature vector images interest. note collecting feature vectors spatial image identity information removed. since layer usually pre-selected different network architectures applications typically studied layer work) subscript omitted remainder paper simplicity. describe extracted. approach assumes represented population code feature vectors. extracted using unsupervised clustering algorithm. since ﬁrst normalize feature vectors unit length instead using k-means proposed assume feature vectors generated mixture mises-fisher distributions learn mixture algorithm goal maximize likelihood function feature vector intermediate layer vmfm parameters represent mixing proportion mean direction concentration values respectively. deﬁne alternatively since {µv} dimensionality {fm} denote speciﬁc center denotes distance feature vector n-th image position call distances. select feature vectors smallest distances trace back original input image using πk→. yields visualization patches shown figure observe patches roughly correspond semantic parts objects justiﬁes assertion semantic visual cues. previous studies cnns used generate feature vectors trained large scale object classiﬁcation task included object categories interest. moreover extracted using hundreds images within speciﬁc category object resulted category speciﬁc visual cues useful interpreting behaviors building novel models semantic part detections. recent work used encode semantic parts objects using vc-encoding could applied detection tasks presence occlusion. vcencoding described next section. emphasize none prior work addressed few-shot learning addressed situations many training examples object categories. few-shot learning section describes technical ideas paper. section introduce learn few-shot setting. section introduce vc-encoding show desirable properties few-shot classiﬁcation tasks. section section propose simple interpretable vc-encoding models few-shot learning. few-shot obvious applied few-shot learning tasks examples available novel category. possible train cnns object categories also enough data good clusters. hence modify learned learn small number examples novel object categories using features cnns trained object categories. similar metric-learning meta-learning trained large datasets include novel categories ensures used feature extraction never seen categories perform few-shot threshold ensuring average coverage few-shot training images. yields ﬁnal vc-encoding used models following desirable properties category sensitivity despite fact learned images different category labels ﬁrst insight many tend intensively speciﬁc object categories. figure calculate occurrence distributions several object categories pascald+ column represents speciﬁc occurrence frequencies tend high object categories others. suggests identities provide useful informations object classiﬁcation. moreover corresponding visualized patches figure support understanding category sensitivity capture semantic parts speciﬁc object categories. spatial pattern spatial pattern ﬁrings also indicative object category. although spatial information ignored feature clustering learned give binary maps contain regular spatial patterns images category relatively similar viewpoints consistent general conjecture spatial patterns semantic parts play vital role object recognition shows vc-encoding capture spatial patterns semantic parts certain extend. nearest neighbor spatial patterns first propose simple template matching model similar traditional nearest neighbor algorithms. novelty similarity metric vc-encodings spatially fuzzy tolerate small spatial shifts parts images. formally similarity metric takes following form factorizable likelihood model apart intuitive nearest neighbor method present second method models likelihood vcencoding. observe specify distribution vc-encoding using bernoulli distribution probability θpv. following na¨ıve bayes assume elements vc-encoding independent hence express likelihood figure properties vcs. illustrate three closest patches occurrence distributions object categories pascald+ showing category sensitivity vc-encoding. visualize closest patches green randomly select images cars negative distance maps binary maps w.r.t. plotted bottom orange box. negative distance given scaled binary drawn based section details. task. extract novel categories examples each pool feature vectors different categories together perform clustering algorithm them. gives little data encourages sharing different categories also makes easier apply models multiple novel categories. modiﬁcations described above obtain fewshot i.e. suitable few-shot learning. critical application differentiates work previous studies surprisingly need images extract high quality which used vc-encoding possess similar desirable properties traditional hence suitable few-shot object classiﬁcation task. vc-encoding assume objects decomposed semantic parts. perspective means {fp} assigned single requires specifying explicit relationships {fp} vcs. natural choice compute distances v-th threshold produce binary value refer {bpv vc-encoding. note image index omitted since operations identical images interest. criteria specify good encoding coverage irerate deﬁned following choice encoding threshold trade-off between requiring sufﬁcient coverage ﬁring rate close one. practice choose testing trial grid-search step size outputs smallest table average classiﬁcation accuracies mini-imagenet conﬁdence intervals. evaluations baseline-ft baseline-nn pool-nn stands nearest neighbor method based pool- features vgg- methods. bottom nearest neighbor method factorizable likelihood method based vcs. marked bold best published results scenario. marked bold bottom best results corresponding setup. note adopt results matching network result nearest neighbor matching using features pool- layer addition present performances state-of-the-art few-shot learning methods including matchingnet meta-learner maml results show vcs-based methods compare well current methods speciﬁcally designed few-shot learning. compared metalearning-based methods achieve higher accuracy meta-learner -shot -shot set-ups slightly behind maml. compared metricbased methods similar ours marginally outperform matchingnet. moreover evaluate methods’ few-shot learning ability variances settings results listed table exactly model ones table trained training validation set. knowledge state-of-the-art few-shot learning methods listed table cannot deal changes table average classiﬁcation accuracies mini-imagenet conﬁdence intervals randomly selected few-shot settings. models used ones used table method adapts easily different number categories different number shots minimal re-training consistently outperform baseline methods state-of-the-art cannot directly applied settings. note this fact implementing discriminative model obtained generative distribution. smooth distribution using gaussian ﬁlter guard unlikely events. experiments section suggests images enough learning object models represented vc-encodings. indeed experiments show vcs-based few-shot learning models competitive performance alternative methods designed speciﬁcally few-shot learning addition previous few-shot methods trained work speciﬁc few-shot scenarios -way classiﬁcations methods applied large range few-shot scenarios without additional training. experimental results show trained cnns potential recognize novel objects examples exploiting vc-encoding. mini-imagenet assess capability few-shot methods ﬁrst evaluate common few-shot learning benchmark namely mini-imagenet. mini-imagenet dataset ﬁrst proposed benchmark evaluating few-shot learning methods. selects categories categories imagenet examples category. split proposed consisting training categories validation categories testing categories. accordance convention mini-imagenet perform numerous trials few-shot learning testing. trial randomly sample unseen categories preserved testing set. category composed training images -shot setting training image -shot setting. evaluation randomly select images category following methods train vgg- training validation objective cross entropy. preserve images category validate network. then extract pool- layer current testing pool. reason choosing pool- features grid pool- lattices correspond patch original image plausible size semantic part. gaussian ﬁlter used smooth factorizable likelihood model figure visualizing inference procedure factorizable likelihood model better visualization rescale variance aggregated likelihood visualizations universal color bar. ﬁgure best viewed color. section details. number categories easily. contrast few-shot learning methods based vc-encoding extended minimal re-training number shots number categories consistently outperform baseline methods. pascald+ apply methods pascald+ dataset larger high quality images miniimagenet. originally tailored object detection pose estimation augmenting rigid categories pascal since interpret few-shot recognition mainly visualizing every step inference input images sufﬁcient sizes obtain large vcencoding distribution maps whose visualizations easy humans understand. pascald+ ﬁrst give intuition interpretability model. figure visualize every step inference process using method based example looking closest patches interest likely relate corners monitors. then given test image convert original pool- features vc-encoding observe example mainly appears upper right corner encoding map. calculating pixel-wise likelihood using distributions learned training images candidate category clearer except monitor categories show likelihood area corner. finally aggregate likelihood make correct classiﬁcation decision assigning test image monitor category. meanwhile quantitatively evaluate methods pascald+. feature extractor subset imagenet classiﬁcation dataset excludes object categories relate categories used pascald+ train ordinary vgg- achieves top- accuracy. testing crop objects using annotated bounding boxes provided pascald+ resize pool- features implement few-shot methods. comparison propose baseline models. nearest neighbor method based pool- features using cosine distance metric; table average classiﬁcation accuracies pascald+. baseline methods including nearest neighbor exemplar-svm based pool- features vgg- used methods. middle bottom factorizable likelihood models vcs-based nearest neighbor models using different number respectively. marked bold best results within group scenario. exemplar-svm trained using hinge loss. pre-trained vgg- methods. evaluation trials -shot -shot learning categories pascald+. also assess methods using different numbers vcs. results shown table general vc-based methods consistently outperform baselines large margins. particular improvements achieve compared baseline methods thus claim decomposing fuzzy features explicit semantic cues improves interpretability performance. also notice methods sensitive number since changes number cause slight differences among accuracies. conclusion paper address challenge developing simple interpretable models few-shot learning exploiting internal representations cnns. adapt few-shot learning setting extracted small images novel object categories using features cnns trained object categories. extend vc-encoding observe properties namely category sensitivity spatial pattern leads propose novel methods few-shot learning simple interpretable. methods show comparable performances much superior ﬂexibility current state-of-the-art methods applied range different few-shot scenarios minimal re-training. summary show vcencodings enable ordinary cnns perform few-shot learning tasks. future work include improving quality extracted extending approach few-shot detection. david bolei zhou aditya khosla aude oliva antonio torralba. network dissection quantifying interpretability deep visual representations. computer vision pattern recognition deng dong richard socher lijia fei-fei. imagenet large-scale hierarchical image database. computer vision pattern recognition cvpr ieee conference pages ieee chelsea finn pieter abbeel sergey levine. model-agnostic meta-learning fast adaptation deep networks. arxiv preprint arxiv. jonathon shlens christian szegedy. explaining harnessing international conference adversarial examples. learning representations kaiming xiangyu zhang shaoqing jian sun. delving deep rectiﬁers surpassing human-level performance imagenet classiﬁcation. proceedings ieee international conference computer vision pages aravindh mahendran andrea vedaldi. understanding deep image representations inverting them. proceedings ieee conference computer vision pattern recognition pages karen simonyan andrew zisserman. deep convolutional networks international conference large-scale image recognition. learning representations karen simonyan andrea vedaldi andrew zisserman. deep inside convolutional networks visualising image classiﬁcation models saliency maps. arxiv preprint arxiv. christian szegedy sergey ioffe vincent vanhoucke alexander alemi. inception-v inception-resnet impact residual connections learning. aaai pages jianyu wang zhishuai zhang cihang vittal premachandran alan yuille. unsupervised learning object semantic parts internal states cnns population encoding. arxiv preprint arxiv. jianyu wang cihang zhishuai zhang lingxi alan yuille. detecting semantic parts partially occluded objects. proceedings british machine vision conference xiang roozbeh mottaghi silvio savarese. beyond pascal benchmark object detection wild. applications computer vision ieee winter conference pages ieee jason yosinski jeff clune yoshua bengio lipson. transferable features deep neural networks? advances neural information processing systems pages bolei zhou aditya khosla agata lapedriza aude oliva antonio torralba. object detectors emerge deep scene cnns. international conference learning representations zhuotun lingxi alan yuille. object recognition without objects. proceedings twenty-sixth international joint conference artiﬁcial intelligence ijcai melbourne australia august pages", "year": 2017}