{"title": "Generalized Prediction Intervals for Arbitrary Distributed  High-Dimensional Data", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "This paper generalizes the traditional statistical concept of prediction intervals for arbitrary probability density functions in high-dimensional feature spaces by introducing significance level distributions, which provides interval-independent probabilities for continuous random variables. The advantage of the transformation of a probability density function into a significance level distribution is that it enables one-class classification or outlier detection in a direct manner.", "text": "paper generalizes traditional statistical concept prediction intervals arbitrary probability density functions highdimensional feature spaces introducing signiﬁcance level distributions provides interval-independent probabilities continuous random variables. advantage transformation probability density function signiﬁcance level distribution enables one-class classiﬁcation outlier detection direct manner. prediction interval interval will speciﬁed degree conﬁdence contain future realizations terminology pattern recognition feature vectors appeal concept clear stochastic meaning. great disadvantage deﬁnition usually restricted example multimodal distributions. intuitively clear that case interval probable feature vectors exist would better speak prediction regions. even complicated situation high-dimensional feature spaces. lack generality probably reason prediction intervals rarely used pattern recognition. actually pity prediction regions would useful example recognition outliers detection novelty normality. instead prediction intervals numerous applying method propose outlier detection belongs ﬁrst category probability normality score. going details give short overview related works. simple distance-based methods rely concept neighborhood point example nearest neighborhood outliers points less points within distance dataset. ramaswamy propose method choose threshold automatically based upon dataset. idea consider outliers points highest distances nearest neighbors. course also threshold necessary statistical reasoning quartile nearest neighbor distance distribution simpliﬁes choice. recent article based idea published angiulli apply weighted nearest distances point. although idea quite simple methods computation costs. furthermore make minor assumptions underlying distribution. another category algorithms related outlier detection robust regression. outlier detection means goal avoid outliers inﬂuence estimation regression function. means case suﬃcient detect outliers indirectly. ting example apply outlier-score control inﬂuence point parameter estimation process regression function. purpose weights introduced estimated based assumption noise gaussian distributed. often suﬃcient example sensor signals. algorithm real-time capable away generality. method also belongs category one. idea second category diﬀerent. ﬁrst glance seems impossible classiﬁers detect outliers classiﬁers need estimation parameters samples inliers outliers. usually samples inliers available. idea create enclosing cloud outlier samples synthetically random generator. afterwards possible train classiﬁer. singh markou example apply neural network purpose. classiﬁers also possible example regardless applied classiﬁer probabilistic methods need generation hull measure degree generated sample point outlier. singh markou example purpose simple prediction intervals conclusion categories solve problem appropriate zero level inlier generating density. subsequent sections show problem mapped choice signiﬁcance level possible generalize traditional statistical concept prediction intervals prediction regions. prediction interval denotes region future feature vectors occur predetermined probability. computation essential generating probability density function random variable known. case prediction interval region borders established probability outliers lower given ﬁxed threshold signiﬁcance level typical example mean region determined possible feature vectors fall usually inﬁnite number borders fulﬁll requirement. thus gaussian distributions region centered expectation value. deﬁnition appropriate special case. proof feature vectors interpreted realizations vectorial random variable this also random variable. contrary scalar valued. relation strictly deterministic cumulative distribution function deﬁnition monotonic. even strictly monotonic inverse function exists compute given expression otherwise could obtain value interval possible values values interval result integration value interval used solve equation. summarization signiﬁcance level usually applied statistics transformed scalar valued function level threshold threshold possible classify feature signiﬁcance level distribution true sense word probability distribution provides probability every continuous realization unfortunately term probability distribution already used probability density functions provide probabilities probability density values. note signiﬁcance level distribution deliver probability single realization itself probability even unlikely realizations nevertheless provides valuable information assessment realization allows decide sure probable possible. figure unimodal symmetric distributions signiﬁcance level distribution prediction interval lead results. multimodal distributions signiﬁcance level distribution reasonable simple standard distributions gaussian distribution cauchy distribution signiﬁcance level distribution given closed form. note symmetric unimodal distribution signiﬁcance level distribution prediction interval identically complex distributions usually valid seldom possible give signiﬁcance level distribution closed form. cases reasonable estimate cumulative distribution function next section proposes method investigates convergence speed. figure shows example signiﬁcance level distribution non-trivial probability density function. please note signiﬁcance level distributions restricted one-dimensional case. figure example probability density function related signiﬁcance level distribution. white zones outlier regions signiﬁcance level threshold corresponds contrary complicated integration expression easily computed estimate assume probability density distribution known appropriately estimated. knowledge possible generate correspondingly distributed random samples glivenko-cantelli theorem guarantees convergence empirical distribution function true cumulative distribution function note unnecessary elements formula makes possible calculate number samples necessary desired accuracy given signiﬁcance level important convergence speed neither depend generating density dimension original problem follows proof expression usually inlier generating density unknown estimated. reason quality proposed method outlier detection depends signiﬁcantly quality applied density estimation algorithm. inﬂuence estimation however marginal rmse reduced arbitrarily contrast estimation increasing random sample number following experiment veriﬁes comparing theoretically determined signiﬁcance level distribution estimated version ˜bx. experiment estimated signiﬁcance level distribution standard normal distribution proposed method varying random sample number averaged value squared diﬀerences closed form estimated versions single estimations. results summarized fig. shows experiment conﬁrms theoretical predictions. figure ﬁgure shows averaged root mean squared errors single experiments signiﬁcance level distribution estimation standard normal distribution diﬀerent random sample numbers comparison theoretical errors article shown always possible compute prediction regions generalization prediction intervals matter generating density high-dimensional multimodal. density known estimated. problem transforming signiﬁcance level deﬁning prediction interval level threshold. shown easily accomplished cumulative distribution function probability density function values. advantage complicated integration high-dimensional feature space mapped dimensional function evaluation. furthermore introduced probability measure significance level distribution easily derived probability density function. advantage enables assessment plausibility realization feature vector provides probabilities also continuous realizations. transformation procedure computation costs estimation error method negligible. please note practice performance proposed method one-class classiﬁcation tasks depends signiﬁcantly quality applied density estimation method like quality bayes classiﬁer multi-class classiﬁcation. contrary optimal estimated density method would necessarily optimal one-class classiﬁcation like bayes classiﬁer optimal multi-class classiﬁcation case. density estimation topic article deliberately omitted experimental comparisions outlier recognition one-class classiﬁcation methods.", "year": 2008}