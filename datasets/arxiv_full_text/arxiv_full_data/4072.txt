{"title": "Using Descriptive Video Services to Create a Large Data Source for Video  Annotation Research", "tag": ["cs.CV", "cs.AI"], "abstract": "In this work, we introduce a dataset of video annotated with high quality natural language phrases describing the visual content in a given segment of time. Our dataset is based on the Descriptive Video Service (DVS) that is now encoded on many digital media products such as DVDs. DVS is an audio narration describing the visual elements and actions in a movie for the visually impaired. It is temporally aligned with the movie and mixed with the original movie soundtrack. We describe an automatic DVS segmentation and alignment method for movies, that enables us to scale up the collection of a DVS-derived dataset with minimal human intervention. Using this method, we have collected the largest DVS-derived dataset for video description of which we are aware. Our dataset currently includes over 84.6 hours of paired video/sentences from 92 DVDs and is growing.", "text": "work introduce dataset video annotated high quality natural language phrases describing visual content given segment time. dataset based descriptive video service encoded many digital media products dvds. audio narration describing visual elements actions movie visually impaired. temporally aligned movie mixed original movie soundtrack. describe automatic segmentation alignment method movies enables scale collection dvs-derived dataset minimal human intervention. using method collected largest dvs-derived dataset video description aware. dataset currently includes hours paired video/sentences dvds growing. tremendous recent interest task image annotation. increased interest likely part recent innovations high capacity neural network based techniques images processing generation natural language phrases. unlike many previous approaches techniques able produce syntactically semantically rich descriptions. however techniques typically require signiﬁcant quantities paired data yield high quality results. recent success fueled availability large labeled datasets flickrk mscoco descriptive video service us-based provider descriptive narrations included audio tracks variety movies programs distributed dvds visual media. purpose make visual media accessible visually impaired. different regions world type annotation known names descriptive video described video canada audio description lists dvds audio tracks available many websites wgbh media group canada canadian radio-television telecommunications commission maintains list television channels described video wgbh television station early pioneer creation technology number providers similar services. work outline solution semi-automated construction large dataset using dvds audio narrations. also present montreal video annotation dataset created using technique. narrations describes visual elements video changes scene people’s appearance gestures actions interaction scene’s objects concise precise language. soundtracks dvds carefully positioned within movies natural pauses dialogue mixed original movie soundtrack professional postproduction. video description written professional writers using rich natural sentences maximum misalignment described scene limited seconds. reasons similar audio narrations therefore appealing terms quality narrations relatively high degree alignment. recently parallel work shown dvds better source visual description precisely aligned visual content movie compared movie scripts. movie scripts written advance movie production sometimes changed movie production. moreover many automatic alignment techniques scripts movies imprecise require heavy manual cleaning used source high quality training evaluation data. such automated scripts construct large sources paired video annotations problematic. despite advantages offered creating completely automated approach extracting relevant narration annotation audio track reﬁning alignment annotation scene still poses challenges. paper discuss solution. main challenges automating construction video annotation dataset derived audio accurately segmenting output mixed original movie soundtrack. segments detected exploiting similarity comparison track original movie soundtracks using fast fourier transform techniques. comparisons using similarity measures sort provide partial solution alignment problem interested automating annotation video alignment much possible. work describe methods narration isolation video alignment. narrations typically carefully placed within locations movie edited post-production supervisor continuity. example scene changes rapidly narrator speak multiple sentences without pauses. content kept together describing part movie. scene changes slowly narrator instead describe scene sentence pause moment later continue description. detecting short pauses able align movie video descriptions automatically. collected dvs-derived dataset dvds researchers contact discuss obtain access information necessary replicate well deﬁned evaluation follows experiments dataset presented present qualitative examples automatically generated descriptions work section paper. list dvds collection jump street minutes less year virgin days summer abraham lincoln vampire hunter good hard thousand words teacher battle angeles mommas like father like blind dating bruno burlesque captain important advances deep learning natural language description generation images existing relatively open-domain image datasets filckrk filckrk mscoco played important role recent breakthroughs image annotation natural sentences. contrast video annotation natural language descriptions investigated extensively much success. recently proposed d-convnet video description generation transferring knowledge images captions. main issue associated automatic video annotation lack open-domain paired video/caption datasets. majority available video datasets domains small word vocabularies tacos tacos multi-level youcook msvd recently work parallel presented movie description dataset dvds descriptions come either scripts. comparative study shown richer accurate source descriptions movie scripts less reliable many cases well temporally aligned movies work semi-automatic fft-based segmentation method used requires human alignment post-processing. collection movies description movies came rest came scripts. best knowledge dataset largest dvs-derived movie dataset available. currently working increasing size. america charlie cloud chasing mavericks chronicle cinderella colombiana dear john death funeral dinner schmucks district easy flight friends benefits greek ghost rider spirit vengeance green zone grown hansel gretel witch hunters know hugo ides march inside time iron complicated jack jill julie julia karate katy perry part knocked land lost larry crowne life little fockers morning glory poppers penguins nanny mcphee returns strings attached parental guidance percy jackson lightening thief prometheus public enemies robin hood ruby sparks salt sanctum snow flower sorcerers apprentice soul surfer sparkle super adventures tintin getting year bounty hunter call descendants girl dragon tattoo guilt trip roommate sitter social network watch think like means thor titanic titanic tooth fairy true grit ugly truth bought whats number xmen first class young adult zombieland zookeeper. figure dataset collection. movie life pie. line vocal isolation movie soundtrack. second third rows shows movie audio signals voice isolation. circles show segments mono channel track. pause narration parts shows natural narration segmentation narrator stops continues describing movie. automatically segment audio based natural pauses. ﬁrst also transcription related ﬁrst second narration parts second third image shots. narrations audio track rich source data describes videos professionally written natural sentences. according american council blind wgbh media access group number dvds featured growing rapidly every year. makes narrations appealing source data collecting large paired video/sentence datasets. narrations mixed original movie sound track. we’ve found efﬁcient methods minimal human intervention sufﬁcient build large dvsderived dataset processing large amount audio aligning movies transcribing text. vocal isolation technique boosts vocals including dialogues narrations suppressing background movie sound stereo signals. technique used widely karaoke machines stereo signals remove vocal track reversing phase channel cancel signal perceived come center leaving signals perceived coming left right. main reason vocal isolation segmentation based fact narration mixed within natural pauses dialogue narration dialogue. therefore vocal isolated signals narrator speaks movie signal almost line relative signal allowing cleanly separate narration dialogue comparing signals. figure illustrates example movie life original movie soundtrack sounds ocean waves background. approach three main steps ﬁrst isolate vocal including dialogues narrations second separate narrations dialogues ﬁnally apply simple thresholding method extract segment isolate vocals using adobe audition’s center channel extractor implementation boost narrations movie dialogues suppressing movie background sounds movie audio signals. align movie audio signals taking fast fourier transform audio signals computing crosscorrelation measure similarity offset select offset corresponds peak cross-correlation. alignment apply least mean square noise cancellation subtract mono squared signal movie mono squared signal order suppress dialogue signal. majority movies applying results cleaned narrations audio signal. even cases standard movie audio signal signal shapes different mixing process procedure sufﬁcient automatic segmentation narration. finally extract audio tracks detecting beginning narration segments audio signal using simple thresholding method applied dvds without changing threshold value. contrast recent work audio segementation done comparing similarity signals fourier domain threshold. found similar approach types thresholds usually adjusted movie. moreover found thresholds depend intensity background audio signal level narrator’s voice. segmenting signal without background audio suppression requires human cleaning. audio narration segments time-stamped based order automatic narration segmentation. compensate potential seconds misalignment narrator speaking corresponding scene movie automatically added seconds video clips without human intervention. believe movie/dvs narrations alignment done manually partially imprecise detection narrations segments signal explained above. order obtain high quality text descriptions audio segments transcribed percent transcription accuracy using professional transcription services services combination automatic speech recognition techniques human transcription produce high quality transcription. audio narration isolation technique allows process audio small dataset currently contains video clips dvds covering variety movie genre. since beginning movie narrator reads text shown movie discard sentences time-stamped within three minutes beginning minutes movie. table shows overall statistics un-ﬁltered ﬁltered dataset. ﬁltered data contains video clips average length seconds number sentences meaning clips paired sentence. table compare dataset existing paired sentence/video datasets. best knowledge dataset biggest dvs-derived dataset available. recent movie description dataset similar however source text descriptions combination movie scripts dvs. part consists dvds dataset contains dvds. existing datasets limited number videos domains source text description based crowdsourcing. contrast dvs-derived dataset variety videos professionally written captions. tagged words dataset corpus using standford part-of-speech tagger toolbox table illustrates vocabulary size number nouns verbs adjective adverbs dataset. interesting number adjectives larger number verbs shows describing characteristics visual elements movie detail. also ﬁgure shows frequent verbs nouns dataset. interesting among frequent verbs synonyms seeing dataset proper names. training video description model usually interested learning generate names. moreover recent work training lstm-based model dataset suggests removing proper names dataset beneﬁcial. dataset replaced people’s name single token word figure shows preliminary qualitative results recent lstm video description model dataset based ofﬁcial dataset split. lstm generated sentence original sentence. examples even though samples necessarily reference still meaningful closely related visual context. work introduced large dvsderived video dataset. publicly available research community. automatic segmentation alignment method enabled collect dataset minimal human intervention. also provide balanced split data deﬁning ofﬁcial task.", "year": 2015}