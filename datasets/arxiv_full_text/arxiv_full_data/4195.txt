{"title": "A Review on Deep Learning Techniques Applied to Semantic Segmentation", "tag": ["cs.CV", "cs.AI"], "abstract": "Image semantic segmentation is more and more being of interest for computer vision and machine learning researchers. Many applications on the rise need accurate and efficient segmentation mechanisms: autonomous driving, indoor navigation, and even virtual or augmented reality systems to name a few. This demand coincides with the rise of deep learning approaches in almost every field or application target related to computer vision, including semantic segmentation or scene understanding. This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. Firstly, we describe the terminology of this field as well as mandatory background concepts. Next, the main datasets and challenges are exposed to help researchers decide which are the ones that best suit their needs and their targets. Then, existing methods are reviewed, highlighting their contributions and their significance in the field. Finally, quantitative results are given for the described methods and the datasets in which they were evaluated, following up with a discussion of the results. At last, we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques.", "text": "abstract—image semantic segmentation interest computer vision machine learning researchers. many applications rise need accurate efﬁcient segmentation mechanisms autonomous driving indoor navigation even virtual augmented reality systems name few. demand coincides rise deep learning approaches almost every ﬁeld application target related computer vision including semantic segmentation scene understanding. paper provides review deep learning methods semantic segmentation applied various application areas. firstly describe terminology ﬁeld well mandatory background concepts. next main datasets challenges exposed help researchers decide ones best suit needs targets. then existing methods reviewed highlighting contributions signiﬁcance ﬁeld. finally quantitative results given described methods datasets evaluated following discussion results. last point promising future works draw conclusions state semantic segmentation using deep learning techniques. images video even volumetric data problems ﬁeld computer vision. looking picture semantic segmentation high-level task paves towards complete scene understanding. importance scene understanding core computer vision problem highlighted fact increasing number applications nourish inferring knowledge imagery. applications include autonomous driving human-machine interaction computational photography image search engines augmented reality name few. problem addressed past using various traditional computer vision machine learning techniques. despite popularity kind methods deep learning revolution turned tables many computer vision problems semantic segmentation among tackled using deep architectures usually convolutional neural networks surpassing approaches large margin terms accuracy sometimes even efﬁciency. however deep learning maturity achieved old-established branches computer vision machine learning. that lack unifying works state reviews. ever-changing state ﬁeld makes initiation difﬁcult keeping evolution pace incredibly time-consuming task sheer amount literature produced. makes hard keep track works dealing garcia-garcia s.o. oprea villena-martinez garciarodriguez department computer technology university alicante spain. e-mail {agarcia soprea vvillena jgarcia}dtic.ua.es orts-escolano department computer science artiﬁcial intelligence universit alicante spain. e-mail sortsua.es. best knowledge ﬁrst review focus explicitly deep learning semantic segmentation. various semantic segmentation surveys already exist works thoma great work summarizing classifying existing methods discussing datasets metrics providing design choices future research directions. however lack recent datasets analyze frameworks none provide details deep learning techniques. that consider work novel helpful thus making signiﬁcant contribution research community. fig. evolution object recognition scene understanding coarse-grained ﬁne-grained inference classiﬁcation detection localization semantic segmentation instance segmentation. in-depth organized review signiﬁcant methods deep learning semantic segmentation origins contributions. thorough performance evaluation gathers quantitative metrics accuracy execution time memory footprint. remainder paper organized follows. firstly section introduces semantic segmentation problem well notation conventions commonly used literature. background concepts common deep neural networks also reviewed. next section describes existing datasets challenges benchmarks. section reviews existing methods following bottomcomplexity order based contributions. section focuses describing theory highlights methods rather performing quantitative evaluation. finally section presents brief discussion presented methods based quantitative results aforementioned datasets. addition future research directions also laid out. last section summarizes paper draws conclusions work state ﬁeld. terminology background concepts order properly understand semantic segmentation tackled modern deep learning architectures important know isolated ﬁeld rather natural step progression coarse inference. origin could located classiﬁcation consists making prediction whole input i.e. predicting object image even providing ranked list many them. localization detection next step towards ﬁne-grained inference providing classes also additional information regarding spatial location classes e.g. centroids bounding boxes. providing that obvious semantic segmentation natural step achieve ﬁne-grained inference goal make dense predictions inferring labels every pixel; pixel labeled class enclosing object region. improvements made instance segmentation even part-based segmentation figure shows aforementioned evolution. review mainly focus generic scene labeling i.e. per-pixel class segmentation also review important methods instance part-based segmentation. elements random variables xn}. label represents different class object e.g. aeroplane trafﬁc sign background. label space possible states usually extended treating background void class. usually image pixels however random variables extended dimensionality volumetric data hyperspectral images. apart problem formulation important remark background concepts might help reader understand review. firstly common networks approaches design decisions often used basis deep semantic segmentation systems. addition common techniques training transfer learning. last data pre-processing augmentation approaches. common deep network architectures previously stated certain deep networks made signiﬁcant contributions ﬁeld become widely known standards. case alexnet vgg- googlenet resnet. importance currently used building blocks many segmentation architectures. reason devote section review them. alexnet alexnet pioneering deep ilsvrc- top- test accuracy closest competitor made traditional techniques instead deep architectures achieved accuracy challenge. architecture presented krizhevsky relatively simple. consists convolutional layers max-pooling ones rectiﬁed linear units non-linearities three fully-connected layers dropout. figure shows architecture. visual geometry group model introduced visual geometry group university oxford. proposed various models conﬁgurations deep cnns submitted imagenet large scale visual recognition challenge model also known vgg- fact composed weight layers became popular thanks achievement top- test accuracy. figure shows conﬁguration vgg-. main difference vgg- predecessors stack convolution layers small receptive ﬁelds ﬁrst layers instead layers googlenet googlenet network introduced szegedy ilsvrc- challenge top- test accuracy architecture characterized complexity emphasized fact composed layers newly introduced building block called inception module approach proved layers could stacked ways typical sequential manner. fact modules consist network network layer pooling operation large-sized convolution layer small-sized convolution layer. computed parallel followed convolution operations reduce dimensionality. thanks modules network puts special consideration memory computational cost signiﬁcantly reducing number parameters operations. resnet microsoft’s resnet specially remarkable thanks winning ilsvrc- accuracy. apart fact network well-known depth introduction residual blocks residual blocks address problem training really deep architecture introducing identity skip connections layers copy inputs next layer. intuitive idea behind approach ensures next layer learns something different input already encoded addition kind connections help overcoming vanishing gradients problem. order extend recurrent neural networks architectures multi-dimensional tasks graves proposed multi-dimensional recurrent neural network architecture replaces single recurrent connection standard rnns connections number spatio-temporal data dimensions. based initial approach visin proposed renet architecture instead multidimensional rnns using usual sequence rnns. number rnns scaling linearly layer regarding number dimensions input image approach convolutional layer replaced four rnns sweeping image vertically horizontally directions figure training deep neural network scratch often feasible various reasons dataset sufﬁcient size required reaching convergence take long experiments worth. even dataset large enough available convergence take long often helpful start pre-trained weights instead random initialized ones fine-tuning weights pre-trained network continuing training process major transfer learning scenarios. yosinski proved transferring features even distant tasks better using random initialization taking account transferability features decreases difference pre-trained task target increases. however applying transfer learning technique completely straightforward. hand architectural constraints must pretrained network. nevertheless since usual come whole architecture common reuse already existing network architectures thus enabling transfer learning. hand training process differs slightly ﬁne-tuning instead training scratch. important choose properly layers ﬁne-tune usually higher-level part network since lower tends contain generic features also pick appropriate policy learning rate usually smaller fact pre-trained weights expected relatively good need drastically change them. inherent difﬁculty gathering creating per-pixel labelled segmentation datasets scale large size classiﬁcation datasets imagenet problem gets even worse dealing rgb-d datasets even smaller. reason transfer learning particular ﬁne-tuning pre-trained classiﬁcation networks common trend segmentation networks successfully applied methods review following sections. data augmentation common technique proven beneﬁt training machine learning models general deep architectures particular; either speeding convergence acting regularizer thus avoiding overﬁtting increasing generalization capabilities typically consist applying transformations either data feature spaces even both. common augmentations performed data space. kind augmentation generates samples applying transformations already existing data. many transformations applied translation rotation warping scaling color space shifts crops etc. goal transformations generate samples create larger dataset preventing overﬁtting presumably regularizing model balance classes within database even synthetically produce samples representative case task hand. augmentations specially helpful small datasets proven efﬁcacy long track success stories. instance dataset portrait images augmented synthesizing four scales four rotations four gamma variations generate dataset training images. process allowed raise accuracy system portrait segmentation intersection union including augmented dataset ﬁne-tuning. kinds readers expected type review either initiating problem either experienced enough looking recent advances made researchers last years. although second kind usually aware important aspects know starting research problem critical newcomers grasp top-quality datasets challenges. therefore purpose section kickstart novel scientists providing brief summary datasets might suit needs well data augmentation preprocessing tips. nevertheless also useful hardened researchers want review fundamentals maybe discover information. arguably data important part machine learning system. dealing deep networks importance increased even more. reason gathering adequate data dataset critical segmentation system based deep learning techniques. gathering constructing appropriate dataset must scale large enough represent case system accurately needs time domain expertise select relevant information infrastructure capture data transform representation system properly understand learn. task despite simplicity formulation comparison sophisticated neural network architecture deﬁnitions hardest problems solve context. that sensible approach usually means using existing standard dataset representative enough domain problem. following approach another advantage community standardized datasets enable fair comparisons systems; fact many datasets part challenge reserves data provided developers test algorithms competition many methods tested generating fair ranking methods according actual performance without kind data cherrypicking. following lines describe popular large-scale datasets currently semantic segmentation. datasets listed provide appropriate pixelwise point-wise labels. list structured three parts according nature data plain datasets rgb-depth ones pure volumetric databases. table shows summarized view gathering described datasets providing datasets throughout years semantic segmentation mostly focused two-dimensional images. reason datasets abundant ones. section describe popular large-scale datasets semantic segmentation considering dataset contains kind two-dimensional representations gray-scale green blue images. pascal visual object classes challenge consists ground-truth annotated dataset images different competitions classiﬁcation detection segmentation action classiﬁcation person layout. segmentation specially interesting since goal predict object class pixel test image. classes categorized vehicles household animals other aeroplane bicycle boat motorbike train bottle chair dining table potted plant sofa tv/monitor bird horse sheep person. background also considered pixel belong classes. dataset divided subsets training validation images respectively. test private challenge. dataset arguably popular semantic segmentation almost every remarkable method literature submitted performance evaluation server validate private test set. methods trained either using dataset either using additional information. furthermore leaderboard public consulted online. pascal context dataset extension pascal detection challenge contains pixel-wise labels training images contains total classes including original classes plus background pascal segmentation divided three categories despite large number categories frequent remarkable. since classes follow power distribution many sparse throughout dataset. regard subset classes usually selected conduct studies dataset relabeling rest background. pascal part database extension pascal detection challenge goes beyond task provide per-pixel segmentation masks part objects original classes pascal kept parts introduced e.g. bicycle decomposed back wheel chain wheel front wheel handlebar headlight saddle. contains labels training validation images pascal well testing images. dataset extended version aforementioned pascal provides semantic segmentation ground truth images labelled voc. contains annotations images pascal annotations provide category-level instance-level information apart boundaries object. since images obtained whole pascal challenge training validation splits diverge. fact provides training validation splits. increased amount training data dataset often used substitute pascal deep learning. microsoft common objects context another image recognition segmentation captioning large-scale dataset. features various challenges detection relevant ﬁeld since parts focused segmentation. challenge features classes provides images training validation test consist images. particular test divided four different subsets splits test-dev additional validation debugging test-standard default test data competition used compare state-of-the-art methods testchallenge split used challenge submitting evaluation server test-reserve split used protect possible overﬁtting challenge popularity importance ramped since appearance thanks large scale. fact results challenge presented yearly joint workshop european conference computer vision together imagenet’s ones. synthetic collection imagery annotations large-scale collection photorealistic renderings virtual city semantically segmented whose purpose scene understanding context driving urban scenarios.the dataset provides ﬁne-grained pixel-level annotations classes large-scale database focuses semantic understanding urban street scenes. instance-wise dense pixel annotations classes grouped categories dataset consist around annotated images coarse annotated ones. data captured cities several months daytimes good weather conditions. originally recorded video frames manually selected following features large number dynamic objects varying scene layout varying background. camvid road/driving scene understanding database originally captured video sequences resolution camera mounted dashboard car. sequences sampled adding frames. stills manually annotated classes void building wall tree vegetation fence sidewalk parking block column/pole trafﬁc cone bridge sign miscellaneous text trafﬁc light tunnel archway road road shoulder lane markings lane markings animal pedestrian child cart luggage bicyclist motorcycle suv/pickup/truck truck/bus train moving object. important remark partition introduced sturgess divided dataset training validation testing images respectively. partition makes subset class labels building tree sign road pedestrian fence pole sidewalk bicyclist. popular datasets mobile robotics autonomous driving. consists hours trafﬁc scenarios recorded variety sensor modalities including highresolution grayscale stereo cameras laser scanner. despite popularity dataset contain ground truth semantic segmentation. however various researchers manually annotated parts dataset necessities. alvarez generated ground truth images road detection challenge three classes road vertical sky. zhang annotated acquisitions velodyne scans tracking challenge object categories building road vegetation sidewalk pedestrian cyclist sign/pole fence. labeled training images testing images classes building tree sign road pedestrian fence pole sidewalk bicyclist. youtube-objects database videos collected youtube contain objects pascal classes aeroplane bird boat horse motorbike train. database contain pixel-wise annotations jain manually annotated subset sequences. took every frame sequences generated semantic labels. totals annotated frames pixels resolution. dataset pixels portrait images collected flickr mainly captured mobile frontfacing cameras. database consist training images reserved testing sets fully binary annotated person background. images labeled semi-automatic ﬁrst face detector image crop pixels persons manually annotated using photoshop quick selection. dataset remarkable speciﬁc purpose makes suitable person foreground segmentation applications. materials context work dataset patch material classiﬁcation full scene material segmentation. dataset provides segment annotations categories wood painted fabric glass metal tile foliage polished stone carpet leather mirror brick water other plastic skin stone ceramic hair food paper wallpaper. contains labeled material segmentations training test validation. main source images opensurfaces dataset augmented using sources imagery flickr houzz. reason image resolution dataset varies. average image resolution approximately densely-annotated video segmentation challenge purposed video object segmentation. dataset composed highdeﬁnition sequences frames training validation respectively. frame resolution varies across sequences downsampled challenge. pixel-wise annotations provided frame four different categories human animal vehicle object. another feature dataset presence least target foreground object sequence. addition designed many different objects signiﬁcant motion. scenes target foreground object class provide separated ground truth allow instance segmentation. stanford background dataset outdoor scene images imported existing public datasets labelme msrc pascal geometric context. dataset contains images least foreground object horizon position within image. dataset pixel-wise annotated evaluating methods semantic scene understanding. siftflow contains fully annotated images subset labelme database images based different outdoor scenes including streets mountains ﬁelds beaches buildings. images belonging semantic classes. unlabeled pixels pixels labeled different semantic class treated unlabeled. advent low-cost range scanners datasets including information also depth maps gaining popularity usage. section review well-known databases include kind depth data. nyudv database consists indoor rgb-d images captured microsoft kinect device. provides per-pixel dense labeling coalesced indoor object classes gupta training testing splits. dataset specially remarkable indoor nature makes really useful certain robotic tasks home. however relatively small scale regard existing datasets hinders application deep learning architectures. sund similar nyudv dataset contains large-scale rgb-d video database annotated sequences. frame semantic segmentation objects scene information camera pose. still progress composed sequences captured different spaces different buildings. moreover places captured multiple times different moments day. sunrgbd captured four rgb-d sensors dataset contains rgb-d images similar scale pascal voc. contains images depth berkeley sund whole dataset densely annotated including polygons bounding boxes orientation well room layout category suitable scene understanding tasks. object segmentation database database designed segmenting unknown objects generic scenes even partial occlusions. dataset contains entries provides depth image color images together withper-pixel annotations evaluate object segmentation approaches. however dataset differentiate category different objects classes reduced binary objects objects. rgb-d object dataset dataset composed video sequences common household objects organized categories arranged using wordnet hypernym-hyponym relationships. dataset recorded using kinect style camera records synchronized aligned depth images frame dataset provides rgb-d depth images cropped ones containing object location mask per-pixel annotation. moreover object placed turntable providing isolated video sequences around degrees. validation process annotated video sequences natural indoor scenes containing objects provided. pure three-dimensional databases scarce kind datasets usually provide computer aided design meshes volumetric representations point clouds. generating large-scale datasets segmentation costly difﬁcult many deep learning methods able process kind data reasons datasets quite popular moment. spite fact describe promising ones task hand. shapenet part subset shapenet repository focuses ﬁne-grained object segmentation. contains meshes sampled categories original dataset shape class labeled parts e.g. shape airplane class labeled wings body tail engine. groundtruth labels provided points sampled meshes. stanford d-d-s multi-modal largescale indoor spaces dataset extending stanford semantic parsing work provides variety registered modalities semantic annotations. database composed full high-deﬁnition images along corresponding depth maps surface normals meshes point clouds semantic annotations data captured indoor areas three different educational ofﬁce buildings. makes total rooms approximately million points annotated labels categories ceiling ﬂoor wall column beam window door table chair bookcase sofa board clutter. benchmark mesh segmentation benchmark composed meshes classiﬁed categories mesh manually segmented functional parts main goal provide sample distribution humans decompose mesh functional parts. sydney urban objects dataset dataset contains variety common urban road objects scanned velodyne hdk-e lidar. individual scans objects across classes vehicles pedestrians signs trees. interesting point dataset that http//cs.stanford.edu/∼ericyi/project page/part annotation/ http//buildingparser.stanford.edu http//segeval.cs.princeton.edu/ http//www.acfr.usyd.edu.au/papers/ large-scale point cloud classiﬁcation benchmark benchmark provides manually annotated point clouds diverse natural urban scenes churches streets railroad tracks squares villages soccer ﬁelds castles among others. dataset features statically captured point clouds details density. contains large-scale point clouds training another testing. scale grasped fact totals billion labelled points. methods relentless success deep learning techniques various high-level computer vision tasks particular supervised approaches convolutional neural networks image classiﬁcation object detection motivated researchers explore capabilities networks pixel-level labelling problems like semantic segmentation. advantage deep learning techniques gives edge traditional methods ability learn appropriate feature representations problem hand e.g. pixel labelling particular dataset end-to-end fashion instead using hand-crafted features require domain expertise effort often much ﬁne-tuning make work particular scenario. fig. fully convolutional network ﬁgure long transforming classiﬁcation-purposed produce spatial heatmaps replacing fully connected layers convolutional ones. including deconvolution layer upsampling allows dense inference learning perpixel labeling. successful state-of-the-art deep learning techniques semantic segmentation stem common forerunner fully convolutional network long insight approach take advantage existing cnns powerful visual models able learn hierarchies features. transformed existing well-known classiﬁcation models alexnet googlenet resnet fully convolutional ones replacing fully connected layers convolutional ones output spatial maps instead classiﬁcation scores. maps upsampled using fractionally strided convolutions produce dense per-pixel labeled outputs. work considered milestone since showed cnns trained end-to-end problem efﬁciently learning make dense predictions semantic segmentation inputs arbitrary sizes. approach achieved signiﬁcant improvement segmentation accuracy traditional methods standard datasets like pascal preserving efﬁciency inference. despite power ﬂexibility model still lacks various features hinder application certain problems situations inherent spatial invariance take account useful global context information instance-awareness present default efﬁciency still real-time execution high resolutions completely suited unstructured data point clouds models. problems reviewed section well state-of-the-art solutions proposed literature overcome hurdles. table provides summary review. shows reviewed methods base architecture main contribution classiﬁcation depending target work accuracy efﬁciency training simplicity sequence processing multi-modal inputs data. target graded decoder variants apart architecture variants developed transform network whose purpose classiﬁcation make suitable segmentation. arguably fcn-based architectures popular successful alternatives also remarkable. general terms take network classiﬁcation remove fully connected layers. part segmentation network often receives name encoder produce low-resolution image representations feature maps. problem lies learning decode low-resolution images pixel-wise predictions segmentation. part named decoder usually divergence point kind architectures. segnet clear example divergence decoder stage segnet composed upsampling convolution layers last followed softmax classiﬁer predict pixel-wise labels output resolution input image. upsampling layer decoder stage corresponds max-pooling encoder part. layers upsample feature maps using max-pooling indices corresponding feature maps encoder phase. upsampled maps convolved trainable ﬁlter banks produce dense feature maps. feature maps restored original resolution softmax classiﬁer produce ﬁnal segmentation. hand fcn-based architectures make learnable deconvolution ﬁlters upsample feature maps. that upsampled feature maps added elementwise corresponding feature generated convolution layer encoder part. figure shows comparison approaches. integrating context knowledge semantic segmentation problem requires integration information various spatial scales. also implies balancing local global information. hand ﬁne-grained local information crucial achieve good pixel-level accuracy. hand also important integrate information global context image able resolve local ambiguities. fig. comparison segnet decoders. segnet uses max-pooling indices corresponding encoder stage upsample learns deconvolution ﬁlters upsample figure reproduced vanilla cnns struggle balance. pooling layers allow networks achieve degree spatial invariance keep computational cost dispose global context information. even purely cnns without pooling layers limited since receptive ﬁeld units grow linearly number layers. many approaches taken make cnns aware global information reﬁnement post-processing step conditional random fields dilated convolutions multi-scale aggregation even defer context modeling another kind deep networks rnns. conditional random fields mentioned before inherent invariance spatial transformations architectures limits spatial accuracy segmentation tasks. possible common approach reﬁne output segmentation system boost ability capture ﬁne-grained details apply post-processing stage using conditional random field crfs enable combination lowlevel image information interactions pixels output multi-class inference systems produce per-pixel class scores. combination especially important capture long-range dependencies cnns fail consider local details. deeplab models make fully connected pairwise kr¨ahenb ¨uhl koltun separated post-processing step pipeline reﬁne segmentation result. models pixel node ﬁeld employs pairwise term pair pixels matter using model short long-range interactions taken account rendering system able recover detailed structures segmentation lost spatial invariance cnn. despite fact usually fully connected models inefﬁcient model efﬁciently approximated probabilistic inference. figure shows effect crf-based post-processing score belief maps produced deeplab model. material recognition wild network bell makes various cnns trained identify patches minc database. cnns used sliding window fashion classify patches. weights transferred networks converted fcns adding corresponding upsampling layers. outputs averaged generate probability map. last deeplab discretely optimized applied predict reﬁne material every pixel. another signiﬁcant work applying reﬁne segmentation crfasrnn zheng main contribution work reformulation dense pairwise potentials integral part network. unrolling mean-ﬁeld inference steps rnns make possible fully integrate train whole network end-to-end. work demonstrates reformulation crfs rnns form part deep network contrast pinheiro employed rnns model large spatial dependencies. dilated convolutions dilated convolutions also named `a-trous convolutions generalization kronecker-factored convolutional ﬁlters support exponentially expanding receptive ﬁelds without losing resolution. words dilated convolutions regular ones make upsampled ﬁlters. dilation rate controls upsampling factor. shown figure stacking l-dilated convolution makes receptive ﬁelds grow exponentially number parameters ﬁlters keeps linear growth. means dilated convolutions allow efﬁcient dense feature extraction arbitrary resolution. side note important remark typical convolutions dilated convolutions. fig. shown dilated convolution ﬁlters various dilation rates -dilated convolutions unit receptive ﬁelds -dilated ones receptive ﬁelds -dilated convolutions receptive ﬁelds. practice equivalent dilating ﬁlter usual convolution. means expanding size according dilation rate ﬁlling empty elements zeros. words ﬁlter weights matched distant elements adjacent dilation rate greater one. figure shows examples dilated ﬁlters. important works make dilated convolutions multi-scale context aggregation module already mentioned deeplab real-time network enet combinations dilated convolutions increasing dilation rates wider receptive ﬁelds additional cost without overly downsampling feature maps. works also show common trend dilated convolutions tightly coupled multi-scale context aggregation explain following section. multi-scale prediction another possible deal context knowledge integration multi-scale predictions. almost every single parameter affects scale generated feature maps. words architecture impact number pixels input image correspond pixel feature map. means ﬁlters implicitly learn detect features speciﬁc scales furthermore parameters usually tightly coupled problem hand making difﬁcult models generalize different scales. possible overcome obstacle multi-scale networks generally make multiple networks target different scales merge predictions produce single output. propose multi-scale version fully convolutional vgg-. network paths processes input original resolution another doubles ﬁrst path goes shallow convolutional network. second goes fully convolutional vgg- extra convolutional layer. result second path upsampled combined result ﬁrst path. concatenated output goes another convolutional layers generate ﬁnal output. result network becomes robust scale variations. architecture introduced eigen networks devoted ﬁnding semantic labels scene. network extracts features progressively coarse-to-ﬁne sequence scales fig. skip-connection-like architecture performs late fusion feature maps making independent predictions layer merging results. figure extracted fig. multi-scale architecture proposed eigen network progressively reﬁnes output using sequence scales estimate depth normals also perform semantic segmentation input. figure extracted another remarkable work network proposed bian network composition fcns operate different scales. features extracted networks fused together additional convolutional layer produce ﬁnal segmentation. main contribution architecture two-stage learning process involves ﬁrst training network independently networks combined last layer ﬁne-tuned. multi-scale model allows arbitrary number newly trained networks efﬁcient manner. feature fusion another adding context information fully convolutional architecture segmentation feature fusion. technique consists merging global feature local feature extracted subsequent layer. common architectures original make skip connections perform late fusion combining feature maps extracted different layers another approach performing early fusion. approach taken parsenet context module. global feature unpooled spatial size local feature concatenated generate combined feature used next layer learn classiﬁer. figure shows representation process. feature fusion idea continued pinheiro sharpmask network introduced progressive reﬁnement module incorporate features previous layer next top-down architecture. work reviewed later since mainly focused instance segmentation. recurrent neural networks noticed cnns successfully applied multi-dimensional data images. nevertheless networks rely hand speciﬁed kernels limiting architecture local contexts. taking advantage topological structure recurrent neural networks successfully applied modeling shortlong-temporal sequences. linking together pixel-level local information rnns able successfully model global contexts improve semantic segmentation. however important issue lack natural sequential structure images focus standard vanilla rnns architectures one-dimensional inputs. based renet model image classiﬁcation visin proposed architecture semantic segmentation called reseg represented figure approach input image processed ﬁrst layers fig. representation reseg network. vgg- convolutional layers represented blue yellow ﬁrst layers. rest architecture based renet approach ﬁne-tuning purposes. figure extracted vgg- network feeding resulting feature maps renet layers ﬁne-tuning. finally feature maps resized using upsampling layers based transposed convolutions. approach gated recurrent units used strike good performance balance regarding memory usage computational power. vanilla rnns problems modeling longterm dependencies mainly vanishing gradients problem. several derived models long short-term memory networks grus stateof-art ﬁeld avoid problem. inspired renet architecture novel long short-term memorized context fusion model scene labeling proposed approach different data sources depth. pipeline relies variant deeplab architecture concatenating features three different scales enrich feature representation global context modeled vertically both depth photometric data sources concluding horizontal fusion direction vertical contexts. noticed modeling image global contexts related recurrent approaches unfolding vertically horizontally network input images. based idea byeon purposed simple lstmbased architecture input image divided non-overlapping windows four separate lstms memory blocks. work emphasizes computational complexity single-core model simplicity. another approach capturing global information relies using bigger input windows order model larger contexts. nevertheless reduces images resolution also implies several problems regarding window overlapping. however pinheiro introduced recurrent convolutional neural networks recurrently train different input window sizes taking account previous predictions using different input window sizes. predicted labels automatically smoothed increasing performance. undirected cyclic graphs also adopted model image contexts semantic segmentation nevertheless rnns directly applicable solution decomposing several directed graphs approach images processed three different layers image feature produced model image contextual dependencies dag-rnns deconvolution layer upsampling feature maps. work demonstrates rnns used together graphs successfully model long-range contextual dependencies overcoming state-of-the-art approaches terms performance. instance segmentation instance segmentation considered next step semantic segmentation time challenging problem comparison rest lowlevel pixel segmentation techniques. main purpose represent objects class splitted different instances. automation process straightforward thus number instances initially unknown evaluation performed predictions pixelwise semantic segmentation. consequently problem remains partially unsolved interest ﬁeld motivated potential applicability. instance labeling provides extra information reasoning occlusion situations also counting number elements belonging class detecting particular object grasping robotics tasks among many applications. purpose hariharan proposed simultaneous detection segmentation method order improve performance already existing works. pipeline uses ﬁrstly bottom-up hierarchical image segmentation object candidate generation process called multi-scale combinatorial grouping obtain region proposals. region features extracted using adapted version region-cnn ﬁne-tuned using bounding boxes provided method instead selective search also alongside region foreground features. then region proposal classiﬁed using linear support vector machine features. finally reﬁnement purposes non-maximum suppression applied previous proposals. later pinheiro presented deepmask model object proposal approach based single convnet. model predicts segmentation mask input patch likelihood patch containing object. tasks learned jointly computed single network based deepmask architecture starting point effectiveness authors presented novel architecture object instance segmentation implementing top-down reﬁnement process achieving better performance terms accuracy speed. goal process efﬁciently merge low-level features highlevel semantic information upper network layers. process consisted different reﬁnement modules stacked together purpose inverting pooling effect generating upsampled object encoding. figure shows reﬁnement module sharpmask. fig. sharpmask’s top-down architecture progressive reﬁnement using signature modules. reﬁnement merges spatially rich information lower-level features high-level semantic cues encoded upper layers. figure extracted another approach based fast r-cnn starting point using deepmask object proposals instead selective search presented zagoruyko combined system called multipath classiﬁer improved performance coco dataset supposed three modiﬁcations fast r-cnn improving localization integral loss provide context using foveal regions ﬁnally skip connections give multi-scale features network. system achieved improvement baseline fast r-cnn. seen methods mentioned rely existing object detectors limiting model performance. even instance segmentation process remains unresolved research problem mentioned works small part challenging research topic. rgb-d data noticed signiﬁcant amount work done semantic segmentation using photometric data. nevertheless structural information spurred advent low-cost rgb-d sensors provide useful geometric cues extracted depth information. several works focused rgb-d scene segmentation reported improvement ﬁne-grained labeling precision using depth information photometric data. using depth information segmentation considered challenging unpredictable variation scene illumination alongside incomplete representation objects complex occlusions. however various works successfully made depth information increase accuracy. depth images approaches focused photometric data straightforward. depth data needs encoded three channels pixel images. different techniques horizontal height angle used encoding depth three channels follows horizontal disparity height ground angle local surface normal inferred gravity direction. input depth images models designed data improve performance learning features structural information. several works based encoding technique. zeng present object segmentation approach leverages multi-view rgb-d data deep learning techniques. rgb-d images captured viewpoint network returns -class probability pixel image. segmentation labels threshold using three times standard deviation mean probability across views. moreover work multiple networks feature extraction trained vgg- evaluating beneﬁts using depth information. found adding depth yield major improvements segmentation performance could caused noise depth information. described approach presented amazon picking challenge. work micontribution towards multi-view deep learning systems since images independently network. propose novel approach object-class segmentation using multi-view deep learning technique. multiple views obtained moving rgb-d camera. training stage camera trajectory obtained using rgb-d slam technique rgb-d images warped ground-truth annotated frames order enforce multi-view consistency training. proposed approach based fusenet combines depth images semantic segmentation improves original work adding multi-scale loss minimization. data geometric data point clouds polygonal meshes useful representations thanks additional dimension provides methods rich spatial information intuitively useful segmentation. however vast majority successful deep learning segmentation architectures cnns particular originally engineered deal unstructured irregular inputs aforementioned ones. order enable weight sharing optimizations convolutional architectures researchers resorted voxel grids projections transform unstructured unordered point clouds meshes regular representations feeding networks. instance huang semantic labeling point clouds. clouds undergo dense voxelization process produces pervoxel labels mapped back point cloud. figure extracted pointnet pioneering work presents deep neural network takes point clouds input providing uniﬁed architecture classiﬁcation segmentation. figure shows two-part network able consume unordered point sets observe pointnet deep network architecture stands crowd fact based fully connected layers instead convolutional ones. architecture features subnetworks classiﬁcation another segmentation. classiﬁcation subnetwork takes point cloud applies transforms multi layer perceptrons generate features aggregated using max-pooling generate global feature describes original input cloud. global feature classiﬁed another produce output scores class. segmentation subnetwork concatenates global feature perpoint features extracted classiﬁcation network applies another mlps generate features produce output scores point. video sequences observed signiﬁcant progress single-image segmentation. however dealing image sequences many systems rely na¨ıve application algorithms frame-by-frame manner. approach works often producing remarkable results. nevertheless applying methods frame frame usually non-viable computational cost. addition methods completely ignore temporal continuity coherence cues might help increase accuracy system reducing execution time. arguably remarkable work regard clockwork shelhamer network adaptation make temporal cues video decrease inference time preserving accuracy. clockwork approach relies following insight feature velocity temporal rate change features network across frames varies layer layer features shallow layers change faster deep ones. assumption layers grouped stages processing different update rates depending depth. this deep features persisted frames thanks semantic stability thus saving inference time. figure shows network architecture clockwork fcn. important remark authors propose kinds update rates ﬁxed adaptive. ﬁxed schedule sets constant time frame recomputing features stage network. adaptive schedule ﬁres clock data-driven manner e.g. depending amount motion semantic change. figure shows example adaptive scheduling. zhang took different approach made dcnn originally created learning features volumes learn hierarchical spatio-temporal features multi-channel inputs video clips. parallel over-segment input clip supervoxels. supervoxel graph embed learned features ﬁnal segmentation obtained applying graph-cut supervoxel graph. another remarkable method builds idea using convolutions deep end-to-end voxel-tovoxel prediction system tran work make convolutional network introduced previous work extend semantic segmentation adding deconvolutional layers end. system works splitting input clips frames performing predictions clip separately. main contribution convolutions. convolutions make three-dimensional ﬁlters suitable spatio-temporal feature learning across multiple channels case frames. figure shows difference convolutions applied multi-channel inputs proving usefulness ones video segmentation. discussion previous section reviewed existing methods literary qualitative point view i.e. take quantitative result account. section going discuss methods numeric standpoint. first describe popular evaluation metrics used measure performance semantic segmentation systems three aspects execution time memory footprint accuracy. fig. difference convolutions applied frames. convolutions weights whole depth stack frames results single image. convolutions ﬁlters produce volume result convolution thus preserving temporal information frame stack. next gather results methods representative datasets using previously described metrics. that summarize draw conclusions results. last enumerate possible future research lines consider signiﬁcant ﬁeld. evaluation metrics segmentation system useful actually produce signiﬁcant contribution ﬁeld performance must evaluated rigor. addition evaluation must performed using standard well-known metrics enable fair comparisons existing methods. furthermore many aspects must evaluated assert validity usefulness system execution time memory footprint accuracy. depending purpose context system metrics might importance others i.e. accuracy expendable certain point favor execution speed real-time application. nevertheless sake scientiﬁc rigor utmost importance provide possible metrics proposed method. execution time speed runtime extremely valuable metric since vast majority systems must meet hard requirements much time spend inference pass. cases might useful know time needed training system usually signiﬁcant unless exaggeratedly slow since ofﬂine process. case providing exact timings methods seen meaningless since extremely dependant hardware backend implementation rendering comparisons pointless. however sake reproducibility order help fellow researchers useful provide timings thorough description hardware system executed well conditions benchmark. done properly help others estimate method useful application well perform fair comparisons conditions check fastest methods. results stated before section provided functional description reviewed methods according targets. gathered quantitative results methods stated authors corresponding papers. results organized three parts depending input data used methods rgb-d images volumetric video sequences. used datasets selected purpose. important remark heterogeneity papers ﬁeld reporting results. although evaluate methods standard datasets provide enough information reproduce results also expressed widely known metrics many others fail leads situation hard even impossible fairly compare methods. furthermore also came across fact authors provide information metrics rather accuracy. despite importance metrics papers include data execution time memory footprint. cases information provided reproducibility information given impossible know setup produced results use. single image category selected seven datasets pascal pascal context pascal person-part camvid cityscapes stanford background siftflow. selection accounts wide range situations targets. ﬁrst arguably important dataset vast majority methods evaluated pascal voc-. table shows results reviewed methods provide accuracy results pascal voc- test set. results shows clear improvement trend proposed methods commonly used accelerate deep networks pack copious amount memory. regard considering implementation-dependent aspects runtime documenting peak average memory footprint method complete description execution conditions extraordinarily helpful. many evaluation criteria proposed frequently used assess accuracy kind technique semantic segmentation. metrics usually variations pixel accuracy iou. report popular metrics semantic segmentation currently used measure per-pixel labeling methods perform task. sake explanation remark following notation details assume total classes amount pixels class inferred belong class words represents number true positives usually interpreted false positives false negatives respectively mean intersection union standard metric segmentation purposes. computes ratio intersection union sets case ground truth predicted segmentation. ratio reformulated number true positives true positives false negatives moving general-purpose dataset pascal also gathered results important urban driving databases. table shows results methods provide accuracy metrics camvid dataset. case rnn-based approach iou. regarding category i.e. datasets also include depth information apart typical channels selected three analysis sunrgb-d nyudv. table shows results sunrgb-d provided lstm-cf achieves iou. datasets chosen discussion shapenet part stanford-d-d-s. cases analyzed methods actually scored them. case pointnet achieved shapenet part stanford-d-d-s respectively. sequences last category included discussion video sequences. part gathered results datasets suitable sequence segmentation cityscapes youtube-objects. reviewed methods video segmentation provides quantitative results datasets clockwork convnet. method reaches cityscapes youtube-objects light results draw various conclusions. important related reproducibility. observed many methods report results nonstandard datasets even tested all. makes comparisons impossible. furthermore describe setup experimentation provide source code implementation thus signiﬁcantly hurting reproducibility. methods report results standard datasets exhaustively describe training procedure also make models weights publicly available enable progress. another important fact discovered thanks study lack information metrics execution time memory footprint. almost paper reports kind information suffer reproducibility issues mentioned before. void fact methods focus accuracy without concern time space. however important think methods applied. practice running embedded devices e.g. self-driving cars drones robots fairly limited sides computational power memory. regarding results themselves conclude deeplab solid method outperforms rest almost every single images dataset signiﬁcant margin. multimodal datasets dominated recurrent networks lstm-cf. data segmentation still long pointnet paving future research dealing unordered point clouds without kind preprocessing discretization. finally dealing video sequences another green area clear direction clockwork convnets promising approach thanks efﬁciency accuracy duality. convolutions worth remarking power ﬂexibility process multichannel inputs making successful capturing spatial temporal information. datasets methods make full information starting rise even proposals techniques engineered still lack important components data. strong need large-scale datasets semantic segmentation harder create lower dimensional counterparts. although already promising works still room more better varied data. important remark importance real-world data since already existing works synthetic databases. proof importance fact ilsvrc feature data sequence datasets lack large-scale data hinders progress segmentation also impacts video segmentation. datasets sequence-based thus helpful developing methods take advantage temporal information. bringing high-quality data nature either unlock research lines without doubt. point cloud segmentation using graph convolutional networks already mentioned dealing data point clouds poses unsolved challenge. unordered unstructured nature traditional architectures cnns canapplied unless sort discretization process applied structure promising line research aims treat point clouds graphs apply convolutions advantage preserving spatial cues every dimension without quantizing data. context knowledge fcns consolidated approach semantic segmentation lack several features context modelling help increasing accuracy. reformulation crfs rnns create end-to-end solutions seems promising direction improve results real-life data. multi-scale feature fusion approaches also shown remarkable progress. general works represent important steps towards achieving ultimate goal problems still require research. real-time segmentation many applications precision important; however also crucial implementations able cope common camera frame rates current methods framerate e.g. fcn-s takes roughly process lowresolution pascal image whilst crfasrnn needs therefore next years expect stream works coming focusing real-time constraints. future works trade-off accuracy runtime. memory platforms bounded hard memory constraints. segmentation networks usually need signiﬁcant amounts memory executed inference training. order devices networks must simpliﬁed. easily accomplished reducing complexity another approaches taken. pruning promising research line aims simplify network making lightweight keeping knowledge thus accuracy original network architecture temporal coherency sequences methods addressed video sequence segmentation either taking advantage temporal cues increase accuracy efﬁciency. however none explicitly tackled coherency problem. segmentation system work video streams important produce good results frame frame also make coherent whole clip without producing artifacts smoothing predicted per-pixel labels along sequence. multi-view integration multiple views recently proposed segmentation works mostly limited rgb-d cameras particular focused single-object segmentation. conclusion best knowledge ﬁrst review paper literature focuses semantic segmentation using deep learning. comparison surveys paper devoted rising topic deep learning covering advanced recent work front. formulated semantic segmentation problem provided reader necessary background knowledge deep learning task. covered contemporary literature datasets methods providing comprehensive survey datasets methods. datasets carefully described stating purposes characteristics researchers easily pick best suits needs. methods surveyed perspectives contributions results i.e. accuracy. also presented comparative summary datasets methods tabular forms classifying according various criteria. discussed results provided useful insight shape future research directions open problems ﬁeld. conclusion semantic segmentation approached many success stories still remains open problem whose solution would prove really useful wide realworld applications. furthermore deep learning proved extremely powerful tackle problem expect ﬂurry innovation spawns research lines upcoming years. ¨uller grabner gool segmentationbased urban trafﬁc scene understanding. bmvc vol. geiger lenz urtasun ready autonomous driving? kitti vision benchmark suite ieee conference computer vision pattern recognition june cordts omran ramos rehfeld enzweiler benenson franke roth schiele cityscapes dataset semantic urban scene understanding proceedings ieee conference computer vision pattern recognition oberweger wohlhart lepetit hands deep deep learning hand pose estimation arxiv preprint arxiv. yoon h.-g. jeon j.-y. kweon learning deep convolutional network light-ﬁeld image superresolution proceedings ieee international conference computer vision workshops wang zhang deep learning content-based image retrieval comprehensive study proceedings international conference multimedia. ning delhomme lecun piano bottou barbano toward automatic phenotyping developing embryos videos ieee transactions image processing vol. ciresan giusti gambardella schmidhuber deep neural networks segment neuronal membranes electron microscopy images advances neural information processing systems farabet couprie najman lecun learning hierarchical features scene labeling ieee transactions pattern analysis machine intelligence vol. hariharan arbel´aez girshick malik simultaneous detection segmentation european conference computer vision. springer gupta girshick arbel´aez malik learning rich features rgb-d images object detection segmentation european conference computer vision. springer beyond pixels comprehensive survey bottom-up semantic image segmentation cosegmentation journal visual communication image representation vol. available http//www.sciencedirect.com/ science/article/pii/s szegedy sermanet reed anguelov erhan vanhoucke rabinovich going deeper convolutions proceedings ieee conference computer vision pattern recognition visin kastner matteucci courville bengio renet recurrent neural network based alternative convolutional networks corr vol. abs/. available http//arxiv.org/abs/. ahmed gong xing training hierarchical feed-forward visual recognition models using transfer learning pseudo-tasks european conference computer vision. springer oquab bottou laptev sivic learning transferring mid-level image representations using convolutional neural networks proceedings ieee conference computer vision pattern recognition yosinski clune bengio lipson transferable features deep neural networks? advances neural information processing systems deng dong socher l.-j. fei-fei imagenet large-scale hierarchical image database computer vision pattern recognition cvpr ieee conference russakovsky deng krause satheesh huang karpathy khosla bernstein imagenet large scale visual recognition challenge international journal computer vision vol. wong gatt stamatescu mcdonnell understanding data augmentation classiﬁcation warp? corr vol. abs/. available http//arxiv.org/abs/. shen hertzmann paris price shechtman sachs automatic portrait segmentation image stylization computer graphics forum vol. wiley online library everingham eslami gool williams winn zisserman pascal visual object classes challenge retrospective international journal computer vision vol. jan. mottaghi chen n.-g. s.-w. fidler urtasun yuille role context object detection semantic segmentation wild ieee conference computer vision pattern recognition chen mottaghi fidler urtasun yuille detect detecting representing objects using holistic models body parts ieee conference computer vision pattern recognition sellart materzynska vazquez lopez synthia dataset large collection synthetic images semantic segmentation urban scenes proceedings ieee conference computer vision pattern recognition sturgess alahari ladicky torr combining appearance structure motion features road scene understanding bmvc british machine vision conference. bmva alvarez gevers lecun lopez road scene segmentation single image european conference computer vision. springer ramos granados bakhtiary vazquez lopez vision-based ofﬂine-online perception paradigm autonomous driving applications computer vision ieee winter conference ieee zhang candra vetter zakhor sensor fusion semantic segmentation urban scenes robotics automation ieee international conference ieee gould fulton koller decomposing scene geometric semantically consistent regions computer vision ieee international conference ieee yuen torralba nonparametric scene parsing label transfer dense scene alignment computer vision pattern recognition cvpr ieee conference ieee jain grauman supervoxel-consistent foreground propagation video european conference computer vision. springer bell upchurch snavely bala material recognition wild materials context database proceedings ieee conference computer vision pattern recognition perazzi pont-tuset mcwilliams gool gross sorkine-hornung benchmark dataset evaluation methodology video object segmentation computer vision pattern recognition pont-tuset perazzi caelles arbel´aez sorkinehornung gool davis challenge video object segmentation arxiv. silberman hoiem kohli fergus indoor segmentation support inference rgbd images european conference computer vision. springer xiao owens torralba sund database spaces reconstructed using object labels ieee international conference computer vision song lichtenberg xiao rgb-d rgb-d scene understanding benchmark suite proceedings ieee conference computer vision pattern recognition ceylan i.-c. shen huang sheffer guibas scalable active framework region annotation shape collections siggraph asia armeni zamir savarese joint d-dsemantic data indoor scene understanding arxiv e-prints feb. quadros underwood douillard occlusionaware feature range images robotics automation icra’. ieee international conference ieee hackel wegner schindler contour detection unstructured point clouds proceedings ieee conference computer vision pattern recognition prest leistner civera schmid ferrari learning object class detectors weakly annotated video computer vision pattern recognition ieee conference bell upchurch snavely bala opensurfaces richly annotated catalog surface appearance trans. graphics vol. gupta arbelaez malik perceptual organization recognition indoor scenes rgb-d images proceedings ieee conference computer vision pattern recognition janoch karayev barron fritz saenko darrell category-level object dataset putting kinect work. london springer london available http//dx.doi.org/./---- richtsfeld object segmentation database chang funkhouser guibas hanrahan huang savarese savva song shapenet repository arxiv preprint information-rich model arxiv. armeni sener zamir jiang brilakis fischer savarese semantic parsing large-scale indoor spaces proceedings ieee conference computer vision pattern recognition long shelhamer darrell fully convolutional networks semantic segmentation proceedings ieee conference computer vision pattern recognition kendall badrinarayanan cipolla bayesian segnet model uncertainty deep convolutional encoderdecoder architectures scene understanding arxiv preprint arxiv. deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs arxiv preprint arxiv. zheng jayasumana romera-paredes vineet huang torr conditional random ﬁelds recurrent neural networks proceedings ieee international conference computer vision eigen fergus predicting depth surface normals semantic labels common multi-scale convolutional architecture proceedings ieee international conference computer vision visin ciccone romero kastner bengio matteucci courville reseg recurrent neural network-based model semantic segmentation ieee conference computer vision pattern recognition workshops june pinheiro t.-y. collobert doll´ar learning reﬁne object segments european conference computer vision. springer zagoruyko lerer t.-y. pinheiro gross chintala doll´ar multipath network object detection arxiv preprint arxiv. huang point cloud labeling using convolutional neural network proc. international conf. pattern recognition vol. tran bourdev fergus torresani paluri deep endend voxelvoxel prediction proceedings ieee conference computer vision pattern recognition workshops rother kolmogorov blake grabcut interactive foreground extraction using iterated graph cuts transactions graphics vol. shotton winn rother criminisi textonboost image understanding multi-class object recognition segmentation jointly modeling texture layout context international journal computer vision vol. kr¨ahenb ¨uhl koltun parameter learning convergent inference dense random ﬁelds. icml zhou j.-n. zhou exploiting local structures kronecker layer convolutional networks arxiv preprint arxiv. hochreiter schmidhuber long short-term memory neural computation vol. girshick donahue darrell malik rich feature hierarchies accurate object detection semantic segmentation proceedings ieee conference computer vision pattern recognition zeng song rodriguez xiao multi-view self-supervised deep learning estimation amazon picking challenge pose corr vol. abs/. available http //arxiv.org/abs/. tran bourdev fergus torresani paluri learning spatiotemporal features convolutional networks proceedings ieee international conference computer vision henaff bruna lecun deep convolutional networks graph-structured data arxiv preprint arxiv. kipf welling semi-supervised classiﬁcation graph convolutional networks arxiv preprint arxiv. sergiu-ovidiu oprea student university alicante. received bachelor’s degree institution june main research interests include deep learning computer vision parallel computing gpus computer graphics. also member european networks like hipeac. victor villena-martinez student university alicante. received master’s degree automation robotics june bachelor’s degree computer engineering june collaborated project acquisition modeling growing plants main research focused calibration rgb-d devices reconstruction human body using devices. alberto garcia-garcia student university alicante. received master’s degree bachelor’s degree institution june june respectively. main research interests include deep learning computer vision parallel computing gpus. intern j¨ulich supercomputing center nvidia working jointly camera/solutions engineering team mobile visual computing group nvidia research. also member european networks hipeac iv&l. sergio orts-escolano received computer science university alicante respectively. currently assistant professor department computer science artiﬁcial intelligence university alicante. previously researcher microsoft research leading members holoportation project research interests include computer vision sensing real-time computing computing deep learning. authored publications journals conferences like cvpr siggraph bmvc neurocomputing neural networks applied soft computing etcetera. also member european networks like hipeac eucog. jose garcia-rodriguez received ph.d. degree specialization computer vision neural networks university alicante currently associate professor department computer technology university alicante. research areas interest include computer vision computational intelligence machine learning pattern recognition robotics man-machine interfaces ambient intelligence computational chemistry parallel multicore architectures. authored publications journals conferences revised papers several journals like journal machine learning research computational intelligence neurocomputing neural networks applied softcomputing image vision computing journal computer mathematics image processing spie optical engineering many others chairing sessions last decade wcci/ijcnn participating program committees several conferences including ijcnn icra icann iwann iwinac icdp many others. also member european networks excellence cost actions like eucog hipeac aapele i&vl director research center university alicante program computer science.", "year": 2017}