{"title": "Attention Correctness in Neural Image Captioning", "tag": ["cs.CV", "cs.CL", "cs.LG"], "abstract": "Attention mechanisms have recently been introduced in deep learning for various tasks in natural language processing and computer vision. But despite their popularity, the \"correctness\" of the implicitly-learned attention maps has only been assessed qualitatively by visualization of several examples. In this paper we focus on evaluating and improving the correctness of attention in neural image captioning models. Specifically, we propose a quantitative evaluation metric for the consistency between the generated attention maps and human annotations, using recently released datasets with alignment between regions in images and entities in captions. We then propose novel models with different levels of explicit supervision for learning attention maps during training. The supervision can be strong when alignment between regions and caption entities are available, or weak when only object segments and categories are provided. We show on the popular Flickr30k and COCO datasets that introducing supervision of attention maps during training solidly improves both attention correctness and caption quality, showing the promise of making machine perception more human-like.", "text": "attention mechanisms recently introduced deep learning various tasks natural language processing computer vision. despite popularity correctness implicitly-learned attention maps assessed qualitatively visualization several examples. paper focus evaluating improving correctness attention neural image captioning models. specifically propose quantitative evaluation metric consistency generated attention maps human annotations using recently released datasets alignment regions images entities captions. propose novel models different levels explicit supervision learning attention maps training. supervision strong alignment regions caption entities available weak object segments categories provided. show popular flickrk coco datasets introducing supervision attention maps training solidly improves attention correctness caption quality showing promise making machine perception human-like. recently attention based deep models proved effective handling variety problems machine translation object detection visual question answering image captioning inspired human attention mechanisms deep models learn dynamic weightings input vectors allow ﬂexibility expressive power. work focus attention models image captioning. state-of-the-art image captioning models adopt convolutional neural networks extract image features recurrent neural networks decode features sentence description. within encoder-decoder framework models proposed apply attention mechanism i.e. attending different areas image generating words one. copyright association advancement artiﬁcial intelligence rights reserved. figure image captioning models attend different areas image generating words. however generated attention maps correspond region words phrases describe image evaluate phenomenon quantitatively deﬁning attention correctness alleviate inconsistency introducing explicit supervision. addition show positive correlation attention correctness caption quality. although impressive visualization results attention maps image captioning shown authors provide quantitative evaluations attention maps generated models. since deep network attention viewed form alignment language space image space argue attention maps fact carry important information understanding deep networks. therefore paper study following questions often extent attention maps contioning performance? towards goals propose novel quantitative metric evaluate correctness attention maps. deﬁne correctness consistency attention maps generated model corresponding region words/phrases describe image. speciﬁcally alignment annotations image regions noun phrase caption entities provided flickrk entities dataset ground truth maps. using metric show attention model performs better uniform attention baseline still room improvement terms attention consistency human annotations. based observation propose model explicit supervision attention maps. model used detailed ground truth attention maps given also semantic labelings image regions available experiments show scenarios models perform consistently signiﬁcantly better implicit attention counterpart terms attention maps accuracy quality ﬁnal generated captions. best knowledge ﬁrst work quantitatively measures quality visual attention deep models shows signiﬁcant improvement adding supervision attention module. image captioning models growing interest ﬁeld image captioning lots work demonstrating impressive results however uncertain extent captioning models truly understand recognize objects image generating captions. proposed attention model qualitatively showed model attend speciﬁc regions image visualizing attention maps images. work takes step quantitatively measuring quality attention maps. role attention maps also relates referring expressions goal predicting part image relevant expression. deep attention models machine translation introduced extra softmax layer rnn/lstm structure generates weights individual words sentence translated. quality attention/alignment qualitatively visualized quantitatively evaluated using alignment error rate. image captioning used convolutional image features spatial information input allowing attention space. targeted attention concepts extracted image generate image captions. visual question answering proposed several models attend image regions questions generating answer. none models quantitatively evaluates quality attention maps imposes supervision attention. concurrently analyzed consistency human deep network attention visual question answering. goal differs interested attention changes progression description. image description datasets image captioning flickrk flickrk coco commonly used benchmark datasets. developed original caption annotations flickrk providing region phrase correspondences. speciﬁcally annotators ﬁrst asked identify noun phrases captions mark corresponding regions bounding boxes. work dataset ground truth evaluate quality generated attention maps well train strongly supervised attention model. model also utilize instance segmentation annotations coco train weakly supervised version. deep attention models image captioning section ﬁrst discuss attention model learns attention weights implicitly introduce explicit supervised attention model. implicit attention model implicit attention model consists three parts encoder encodes visual information decoder decodes information words attention module performs spatial attention. visual feature extractor produces vectors correspond different spatial locations image given visual features goal decoder generate caption length yc}. represent one-hot encoding dictionary size. schmidhuber used decoder ftct− ittanh ottanh input gate forget gate memory output gate hidden state lstm respectively. weight matrices biases. rm×k embedding matrix sigmoid function. αtiai dynamic vector represents relevant part image feature time step scalar weighting visual vector time step deﬁned follows fattn function determines amount attention allocated image feature conditioned lstm hidden state ht−. function implemented multilayer perceptron. note consupervised attention model work interested attention generated model αααt {αti}i=...l. limitation model even prior knowledge attention able take advantage information learn better attention function fattn. tackle problem introducing explicit supervision. concretely ﬁrst consider case ground truth attention βββt {βti}i=...l provided since considered probability distributions attention natural cross entropy loss. words alignment image region simply ltattn attention βββt depending types annotations. strong supervision alignment annotation simplest case direct annotation links ground truth word region image encourage model attend constructing ˆβˆβˆβt ˆβtˆi}ˆi=.. where note resolution region attention different could different therefore need resize ˆβˆβˆβt resolution αααt normalize βββt. weak supervision semantic labeling ground truth alignment expensive collect annotate. much general cheaper annotation bounding boxes segmentation masks object class labels case provided regions image associated object classes number object bounding boxes segmentation masks image. although ideal annotations contain important information guide attention model. instance caption playing model attend region person generating word attend region generating word dog. suggests approximate image-to-language consistency language-to-language similarity. denote embeddings word respectively. embedding learned model off-the-shelf word embedding resize normalize ˆβˆβˆβt strong supervision scenario. time step implicit attention model lstm predicts next word also generates attention αtαtαt across locations. however attention module merely intermediate step error backpropagated word-likelihood loss equation opens question whether implicitly-learned attention module indeed effective. therefore section introduce concept attention correctness evaluation metric quantitatively analyzes quality attention maps generated attention-based model. score intuitively value captures attention score falls within human annotation ˆαˆαˆαt {ˆαtˆi}ˆi=... resized normalized αααt order ensure size consistency. cases phrase yt+l} refers entity therefore individual words share attention region deﬁne phrase attention correctness maximum individual scores. intuition phrase contain less interesting words whose attention ambiguous attention maps words ignored operation. example evaluating phrase group people interested attention correctness people rather ground truth attention region testing order compute attention correctness need correspondence regions image phrases caption. however testing stage generated caption often different ground truth captions. makes evaluation difﬁcult corresponding image regions phrases ground truth caption phrase. propose strategies. ground truth caption option enforce model output ground truth sentence resetting input ground truth word time step. procedure extent allows decorrelate attention module captioning component diagnose learned attention module meaningful. since generated caption exactly matches ground truth compute attention correctness noun phrases test set. generated caption another option align entities generated caption ground truth caption. image ﬁrst extract noun phrases generated caption using tagger exists word-byword match noun phrases ground truth captions. example generated caption jumping hurdle ground truth captions jumping hurdle match noun phrase hurdle appearing sentences. calculate attention correctness matched phrases only. implementation details implicit/supervised attention models implementation details strictly follow resize image shorter side pixels center crop image extracting conv feature layer version pretrained imagenet model trained using stochastic gradient descent adam algorithm dropout used regularization. hyperparameters provided publicly available code. number lstm units flickrk coco. ground truth attention strong supervision model experiment strong supervision model flickrk dataset flickrk entities dataset used generating ground truth attention maps. entity figure ground truth attention maps generated coco. ﬁrst examples show successful cases. third example failed case proposed method aligns girl woman person category. fourth example shows necessity using scene category list. distinguish object scene algorithm proposes align word kitchen objects like spoon oven. propose uniform attention cases. caption flickrk entities dataset provides corresponding bounding entity image. therefore ideally model attend marked region predicting associated words. evaluate noun phrases only types words attention might ambiguous meaningless. ground truth attention weak supervision model coco dataset contains instance segmentation masks classes addition captions makes suitable model weak supervision. construct βββt nouns captions extracted using stanford parser similarity function equation chosen cosine distance word vectors pretrained googlenews empirical threshold βββt generated still contains obvious errors primarily wordvec cannot distinguish well objects scenes. example similarity between word kitchen object class spoon threshold. generating scene word like kitchen model attending whole image instead focusing small object like spoon. address problem refer supplement provides scene category list containing words scenes used collecting dataset. whenever word scene category list appears caption βββt uniform i.e. equal attention across image. greatly improves quality βββt cases comparison metric designs show legitimacy attention correctness metric compute spearsman table attention correctness baseline flickrk test set. implicit supervised models outperform baseline. supervised model performs better implicit model settings. correlation design three metrics negative distance negative distance divergence between ˆβˆβˆβt ˆαˆαˆαt. flickrk test implicit attention ground truth caption spearsman correlations suggesting measurements similar. therefore metric statistically correlates well metrics intuitive. evaluation attention correctness subsection quantitatively evaluate attention correctness implicit supervised attention model. experiments conducted test images flickrk. compare result uniform baseline attends equally across whole image. therefore baseline score simply size bounding size whole image. results summarized table ground truth caption result setting implicit supervised models forced produce exactly captions resulting noun phrase matches. discard attention region full image attention remaining matches resize original attention perform normalization compute attention correctness noun phrase. models evaluated figure horizontal axis improvement baseline therefore better attention module result distribution right. average models perform better baseline. speciﬁcally average gain uniform attention baseline implicit attention model supervised version. visually distribution supervised model right. indicates although implicit model captured aspects attention model learned strong supervision better attention module. figure show examples supervised model correctly recovers spatial location underlined entity implicit model attends wrong region. generated caption result experiment word-byword match able align noun phrases implicit model supervised version. since strategy rather conservative alignments correct reliable veriﬁed manual check. similarly discard attention region full image attention perform resize normalization compute correctness score. results shown figure general conclusion same supervised attention model produces attention maps consistent human judgment. average improvement uniform baseline implicit model supervised model relative gain. order diagnose relationship object size attention correctness split test equally small medium large ground truth bounding report baseline attention correctness individually. table improvement supervised model implicit model greatest small objects pinpointing small objects stronger evidence image understanding large objects. figure provide qualitative results. examples show entity supervised model produces human-like attention implicit model. visualization supplementary material. evaluation captioning performance shown supervised attention models achieve higher attention correctness implicit attention models. although meaningful tasks region grounding many tasks attention serves intermediate step. interested whether supervised attention model also better captioning performance goal. intuition meaningful dynamic figure attention correctness using ground truth captions. left right original image implicit attention supervised attention. marks correct attention region general attention maps generated supervised model higher quality. table comparison image captioning performance. indicates implementation. caption quality consistently increases supervision whether strong weak. report bleu meteor scores allow comparison table show scores reported implementation. note implementation gives slightly improved result reported. observe bleu meteor scores consistently increase introduce supervised attention flickrk coco. speciﬁcally terms bleu- observe signiﬁcant increase percent respectively. show positive correlation attention correctness caption quality split flickrk test equally three sets high middle attention correctness. bleu- scores meteor respectively indicates higher attention correctness means better captioning performance. figure attention correctness using generated captions. marks correct attention region show attention maps words phrase. general attention maps generated supervised model higher quality. table captioning scores flickrk test different attention correctness levels generated caption implicit attention experiment. higher attention correctness results better captioning performance. consistent human perceptions? ﬁrst deﬁne attention correctness terms consistency human annotation word level phrase level. context image captioning evaluated state-of-the-art models implicitly trained attention modules. quantitative results suggest although implicit models outperform uniform attention baseline still room improvement. show introducing supervision attention improve image captioning performance attention quality. fact observe positive correlation attention correctness captioning quality. even ground truth attention unavailable still able utilize segmentation masks object category weak supervision attention maps signiﬁcantly boost captioning performance. gratefully acknowledge support award ccf- army research ofﬁce partially supported iis- ccf-. also thank tianze helpful suggestions early stage work.", "year": 2016}