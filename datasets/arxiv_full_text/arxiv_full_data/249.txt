{"title": "Dense Transformer Networks", "tag": ["cs.CV", "cs.LG", "cs.NE", "stat.ML"], "abstract": "The key idea of current deep learning methods for dense prediction is to apply a model on a regular patch centered on each pixel to make pixel-wise predictions. These methods are limited in the sense that the patches are determined by network architecture instead of learned from data. In this work, we propose the dense transformer networks, which can learn the shapes and sizes of patches from data. The dense transformer networks employ an encoder-decoder architecture, and a pair of dense transformer modules are inserted into each of the encoder and decoder paths. The novelty of this work is that we provide technical solutions for learning the shapes and sizes of patches from data and efficiently restoring the spatial correspondence required for dense prediction. The proposed dense transformer modules are differentiable, thus the entire network can be trained. We apply the proposed networks on natural and biological image segmentation tasks and show superior performance is achieved in comparison to baseline methods.", "text": "idea current deep learning methods dense prediction apply model regular patch centered pixel make pixel-wise predictions. methods limited sense patches determined network architecture instead learned data. work propose dense transformer networks learn shapes sizes patches data. dense transformer networks employ encoder-decoder architecture pair dense transformer modules inserted encoder decoder paths. novelty work provide technical solutions learning shapes sizes patches data efﬁciently restoring spatial correspondence required dense prediction. proposed dense transformer modules differentiable thus entire network trained. apply proposed networks natural biological image segmentation tasks show superior performance achieved comparison baseline methods. recent years deep convolution neural networks achieved promising performance many artiﬁcial intelligence tasks including image recognition object detection segmentation among tasks dense prediction tasks take images inputs generate output maps similar size inputs. example image semantic segmentation need predict label pixel input images examples include depth estimation image super-resolution surface normal prediction tasks generally considered image-to-image translation problems inputs images outputs label maps given success deep learning methods image-related applications numerous recent attempts made solve dense prediction problems using cnns. central idea methods extract square patch centered pixel apply cnns compute label center pixel. efﬁciency approaches improved using fully convolutional encoder-decoder networks. speciﬁcally fully convolutional networks replace fully connected layers convolutional layers thereby allowing inputs arbitrary size training test. contrast deconvolution networks employ encoder-decoder architecture. encoder path extracts high-level representations using convolutional pooling layers. decoder path uses deconvolutional up-pooling layers recovering original spatial resolution. order transmit information directly encoder decoder u-net adds skip connections corresponding encoder decoder layers. common property methods label pixel determined regular patch centered pixel. although methods achieved considerable practical success limitations inherent them. example network architecture determined patches used predict label pixel completely determined commonly size pixels. addition patches usually regular shape e.g. squares. work propose dense transformer networks address limitations. method follows encoder-decoder architecture encoder converts input images high-level representations decoder tries make pixel-wise predictions recovering original spatial resolution. framework label pixel also determined local patch input. method allows size shape every patch adaptive data-dependent. order achieve goal propose insert spatial transformer layer encoder part network. propose nonlinear transformations based thin-plate splines nonlinear spatial transformer layer transforms feature maps different space. therefore performing regular convolution pooling operations space corresponds performing operations irregular patches different sizes original space. since nonlinear spatial transformations learned automatically data corresponds learning size shape patch used inputs convolution pooling operations. prior work allowing spatial transformations deformations deep networks address spatial correspondence problem critical dense prediction tasks. difﬁculty applying spatial transformations dense prediction tasks lies spatial correspondence input images output label maps needs preserved. innovation work provide technical solution allows data-dependent learning patches also enables preservation spatial correspondence. speciﬁcally although patches used predict pixel labels could different sizes shapes expect patches spatial vicinity pixels whose labels predicted. applying nonlinear spatial transformer layers encoder path described above spatial locations units intermediate feature maps spatial transformation layer preserved. thus reverse transformation required restore spatial correspondence. order restore spatial correspondence inputs outputs propose corresponding decoder layer. technical challenge developing decoder layer need values units arranged input regular grid another units arranged output grid nonlinear transformation could input units arbitrary locations output map. develop interpolation method address challenge. altogether work results dense transformer networks allow prediction pixel adaptively choose input patch data-dependent manner. dense transformer networks trained end-to-end gradients back-propagated encoder decoder layers. experimental results natural biological images demonstrate effectiveness proposed dense transformer networks. spatial transformer networks deep models containing spatial transformer layers. layers explicitly compute spatial transformation input feature maps. inserted convolutional neural networks perform explicit spatial transformations. spatial transformer layers consist three components; namely localization network grid generator sampler. localization network takes feature maps input generates parameters control transformation. multiple feature maps transformation applied them. grid generator constructs transformation mapping input output grids based parameters computed localization network. sampler computes output feature maps based input feature maps output grid generator. spatial transformer layers generic different types transformations e.g. afﬁne transformation projective transformation thin-plate spline used. proposed work based transformation described detail original paper thus provide details below. multiple feature maps transformation applied them. thus assume input feature below. transformation determined ﬁducial points among points input feature points output feature map. output feature ﬁducial points whose coordinates denoted evenly distributed ﬁxed regular grid denotes coordinates point. localization network used learn ﬁducial points input feature map. speciﬁcally localization network denoted floc takes input feature maps rh×w×c input height width number channels input feature maps generates normalized coordinates output floc. cascade convolutional pooling fully-connected layers used implement floc. output ﬁnal fully-connected layer coordinates input feature map. therefore number output units localization network order ensure outputs normalized activation function tanh used fully-connected layer. since localization network differentiable ﬁducial points learned data using error back-propagation. unit lying regular grid output feature grid generator computes coordinate corresponding unit input feature map. correspondence determined coordinates ﬁducial points given evenly distributed points output feature ﬁducial points generated localization network transformation matrix expressed follows rk×k elements deﬁned distance ˜fj. mapping unit output feature corresponds unit input feature map. achieve mapping represent units regular output grid {˜pi} -coordinates unit output grid height width output feature maps. note ﬁducial points ˜fi}k subset points {˜pi} apply transformation point ﬁrst extended space space euclidean distance ˜fj. transformation expressed sampler generates output feature maps based input feature maps outputs grid generator. unit output feature corresponds unit input feature computed however coordinates computed exactly input regular grid. cases output values need interpolated input values lying regular grid. example bilinear sampling method used achieve this. speciﬁcally given input feature rh×w output feature obtained value pixel value input feature computed using transformations spatial transformer networks shown invariant transformations inputs. recent studies also attempted make cnns invariant various transformations central idea cnn-based method dense prediction extract regular patch centered pixel apply cnns compute label pixel. common property methods label pixel determined regular patch centered pixel. although methods shown effective dense prediction problems lack ability learn sizes shapes patches data-dependent manner. given network size patches used predict labels center pixel determined network architecture. although multi-scale networks proposed allow patches different sizes combined patch sizes determined network architectures. addition shapes patches used cnns invariably regular squares. ideally shapes patches depend local image statistics around pixel thus learned data. work propose dense transformer networks enable learning patch size shape pixel. order address limitations propose develop dense transformer network model. model employs encoder-decoder architecture encoder path extracts high-level representations using convolutional pooling layers decoder path uses deconvolution un-pooling recover original spatial resolution enable learning size shape patch automatically data propose insert spatial transformer module encoder path network. discussed above spatial transformer module transforms feature maps different space using nonlinear transformations. applying convolution pooling operations regular patches transformed space equivalent operating irregular patches different sizes original space. since spatial transformer module differentiable parameters learned error back-propagation algorithms. equivalent learning size shape patch data. although patches used predict pixel labels could different sizes shapes expect patches include pixel question least. patches spatial vicinity pixels whose labels predicted. using nonlinear spatial transformer layer encoder path spatial locations units intermediate feature maps could changed. nonlinear spatial transformation spatial correspondence input images output label maps retained feature maps spatial transformer layer. order restore spatial correspondence propose corresponding decoder layer known figure proposed dense transformer networks. pair dense transformer modules inserted encoder decoder paths. spatial transformer module values points given previous layer need estimate value point contrast decoder layer value point given previous layer need estimate values points dense transformer decoder layer. decoder layer transforms intermediate feature maps back original input space thereby re-establishing input-output spatial correspondence. spatial transformer module inserted layer encoder path dense transform decoder module inserted corresponding location decoder path. framework spatial transformer module required output transformed feature maps also transformation captures spatial correspondence input output feature maps. information used restore spatial correspondence decoder module. note spatial transformer encoder module transformation computed backward direction i.e. output input feature maps contrast dense transformer decoder module uses forward direction instead; mapping input output feature maps. encoder-decoder pair implemented efﬁciently sharing transformation parameters modules. technical challenge developing dense transformer decoder layer need values units arranged input regular grid another units arranged regular output grid decoder could units arbitrary locations output map. need compute values units lying regular output grid values units lying regular input grid mapping could input unit arbitrary location output feature i.e. necessarily unit lying exactly output grid. address challenge develop sampler method performing interpolation. show proposed samplers differentiable thus gradients propagated modules. makes entire dense transformer networks fully trainable. formally assume encoder decoder layers inserted i-th j-th layers respectively following relationships sampling{u sampling{u feature i-th layer coordinate point transformation deﬁned maps coordinates layer i-th layer sampling denotes sampler function. geometric perspective value associated estimated point bilinear interpolation interpreted linear combination values four neighboring grid points. weights linear combination areas rectangles determined estimated points four neighboring grid points. example figure point mapped input grid contributions points estimated point determined areas rectangles however interpolation problem needs solved dense transformer decoder layer different spatial transformer encoder layer illustrated figure speciﬁcally encoder layer points associated values computed previous layer interpolation problem needs compute value propagated next layer. contrast decoder layer point associated value computed previous layer interpolation problem needs compute values different natures interpolation problems need solved encoder decoder modules propose sampler efﬁciently interpolate decimal points following section. decoder sampler need estimate values regular grid points based arbitrary decimal points i.e. regular grid. example figure value point given previous layer. transformation mapped arbitrary point. therefore values grid points need computed based values arbitrary points. compute values surrounding points encoder layer might deal complex interpolation problem irregular quadrilaterals. complex interpolation methods yield accurate results prefer simpler efﬁcient method work. speciﬁcally propose sampling method distributes value points intuitive manner. geometrically weights associated points area rectangles respectively particular given input feature output feature rh×w obtained value pixel transformed shared transformation value location output feature normalization term used eliminate effect different grid points receive values different numbers arbitrary points order allow backpropagation errors deﬁne gradient respect dunm. gradient respect derived follows evaluate proposed methods image segmentation tasks. u-net adopted base model tasks achieved state-of-the-art performance image segmentation tasks. speciﬁcally u-net adds residual connections encoder path decoder path incorporate low-level high-level features. methods like segnet deconvolutional networks mainly differ u-net up-sampling method table comparison segmentation performance u-net proposed pascal segmentation data set. three different performance measures used here. arrow attached measure denotes higher values indicate better performance denotes lower values indicate better performance. loss↓ figure sample segmentation results pascal segmentation data set. ﬁrst second rows original images corresponding ground truth respectively. third fourth rows segmentation results u-net respectively. residual connections. experiments prior work show residual connections important different up-sampling methods lead similar results. network consists layers encoder path another corresponding layers decoder path. kernels pixel padding retain size feature maps level. order efﬁciently implement transformations insert spatial encoder layer dense transformer decoder layer corresponding positions level. speciﬁcally layers applied layer performance compared basic u-net model without spatial transformations. transformation layers ﬁducial points evenly distributed output feature maps. dense transformer decoder layer pixels selected output feature apply interpolation strategy neighboring pixels previous feature maps produce smooth results. pascal segmentation data evaluate proposed methods natural image semantic segmentation task. task predict label total classes pixel. avoid inconvenience different sizes images resize images multiple performance metrics including loss accuracy mean-iou used measure segmentation performance results reported table observe proposed model achieves higher performance baseline u-net model. especially improves mean-iou example results along images ground truth label maps given figure results demonstrate proposed model boost segmentation performance dramatically. evaluate proposed methods brain electron microscopy image segmentation task ultimate goal reconstruct neurons micro-scale level. critical step neuron reconstruction segment images. data segmentation neurites images snemid data consists image slices. since perform transformations work image slice segmented separately experiments. task predict pixel either boundary non-boundary pixel model process images arbitrary size. however training whole images incur excessive memory requirement. order accelerate training randomly pick patches original images train networks. experimental results terms curves provided figure observe proposed model achieves higher performance baseline u-net model improving results demonstrate proposed model improves upon baseline u-net model dense transformer encoder decoder modules u-net architecture results improved performance. example results along images ground truth label maps given figure table shows comparison training prediction time u-net model proposed model data sets. adding layers leads slight increase training prediction time. since pascal data complex snemeid data channels building network natural image segmentation task. causes increase training prediction time pascal data compared snemeid. work propose dense transformer networks enable automatic learning patch sizes shapes dense prediction tasks. achieved transforming intermediate feature maps different space using nonlinear transformations. unique challenge dense prediction tasks that spatial correspondence inputs outputs preserved order make pixel-wise predictions. develop dense transformer decoder layer restore spatial correspondence. proposed dense transformer modules differentiable. thus entire network trained end. experimental results show adding spatial transformer decoder layers existing models leads improved performance. best knowledge work represents ﬁrst attempt enable learning patch size shape dense prediction. current study adds encoder layer decoder layer baseline models. explore possibility adding multiple encoder decoder layers different locations baseline model. work develop simple efﬁcient decoder sampler interpolation. complex method based irregular quadrilaterals might accurate explored future. work supported part national science foundation grants iis- washington state university. gratefully acknowledge support nvidia corporation donation tesla used research.", "year": 2017}