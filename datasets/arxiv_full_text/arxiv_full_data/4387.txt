{"title": "Indoor Localization by Fusing a Group of Fingerprints Based on Random  Forests", "tag": ["stat.ML", "cs.CV"], "abstract": "Indoor localization based on SIngle Of Fingerprint (SIOF) is rather susceptible to the changing environment, multipath, and non-line-of-sight (NLOS) propagation. Building SIOF is also a very time-consuming process. Recently, we first proposed a GrOup Of Fingerprints (GOOF) to improve the localization accuracy and reduce the burden of building fingerprints. However, the main drawback is the timeliness. In this paper, we propose a novel localization framework by Fusing A Group Of fingerprinTs (FAGOT) based on random forests. In the offline phase, we first build a GOOF from different transformations of the received signals of multiple antennas. Then, we design multiple GOOF strong classifiers based on Random Forests (GOOF-RF) by training each fingerprint in the GOOF. In the online phase, we input the corresponding transformations of the real measurements into these strong classifiers to obtain multiple independent decisions. Finally, we propose a Sliding Window aIded Mode-based (SWIM) fusion algorithm to balance the localization accuracy and time. Our proposed approaches can work better in an unknown indoor scenario. The burden of building fingerprints can also be reduced drastically. We demonstrate the performance of our algorithms through simulations and real experimental data using two Universal Software Radio Peripheral (USRP) platforms.", "text": "goof building assume grids unknown indoor environment received array antennas deployed origin snapshots size collected grid. then build goof using different transformations. different labels also added constructed goof classiﬁcation. goof-rf testing assume obtain samples ﬁngerprint testing. first input testing data trees random forest strong classiﬁers. then classiﬁer outputs prediction vector total prediction matrix depicted fig. proposed localization algorithm synthesize different predictions strong classiﬁers also predictions strong classiﬁer different samples. adopted denote received signal antenna element channel gain delay angle-of-arrival note received signal path consists enormous number unresolvable signals received around mean element complex indoor scenario. signal transmitted location vector received signals expressed here address build proposed goof received signals using snapshots. assume divide indoor environment grids equal spacing. signal transmitted antenna located grid received signals algorithm goof building input received signals number grid location label initial empty goof goof cmfs rssfs psdfs ssfs focfs flomfs group number grid. output goof. {··· calculate using calculate rssq using calculate psdq using calculate calculate calculate transform goof like table. cmfs cmfs rssfs rssfs ∪rssq psdfs psdfs ∪psdq ssfs ssfs focfs focfs flomfs flomfs data vector components represent attributes vector represents constructed goof; dimensionality case represents different ﬁngerprints vector built goof. note vary different kinds ﬁngerprints. general feature space large especially image processing ﬁeld. fortunately extract small portion denotes dimensionality subspace denotes selected dimensions. general node test function binary outputs indicates class label classes denoted empirical distribution extracted points within model parameters impact behavior decision tree include maximum allowed tree depth tree number forest. given binary decision tree calculate number internal nodes number leaf nodes follows leaves. tree testing done parallel thus achieving high computational efﬁciency. goofrf testing algorithm summarized algorithm note function vote algorithm denotes chooses classiﬁcation votes note entry vector algorithm others zeros classiﬁer predicts location transform p··· given strong classiﬁer vector whose entry location label estimated classiﬁer inputting testing sample i.e. algorithm goof-rf training input training sample goof. number decision trees ﬁngerprint goof. weak learner model tree depth number different ﬁngerprints goof. output strong random forest classiﬁers initiate {··· select geometric primitive initiate tree {··· initiate information gain select threshold randomly based select split dimension based call weak learner compute entropy node using compute entropy node using compute information gain using choose split node using tree goof testing samples grid type ﬁngerprint sample vector ﬁngerprint corresponding location label. input testing samples ﬁngerprint random forest strong classiﬁer trained algorithm then strong classiﬁer work predictor give prediction vector samples denotes output classiﬁer inputting testing sample. total prediction matrix shown fig. testing sample strong classiﬁers yield different prediction results strong classiﬁer different testing samples give different prediction results prediction results outputs strong classiﬁers different samples calculated normalized empirical histogram predictions strong classiﬁer denotes robustness classiﬁer environment noise i.e. smaller better robustness predictions strong classiﬁer. calculated normalized empirical histogram predictions testing sample note shows environment adaptability ﬁngerprints i.e. well ﬁngerprints cope multipath changing environment. bigger main drawback timeliness. general value determines speed real localization bigger slower localization speed. order optimize localization speed robustness propose swim fusion algorithm follows. assume rectangular sliding window length used samples. consider fusing submatrice instead total prediction matrix given matrix obtain submatrice number here prediction frequency i.e. localization occurrences unit time shows speed localization based submatrice derive swim algorithm localization time main advantages proposed framework localization time based shortened localization time based sliding window aided strategy improve speed approach also overcome ﬂuctuation siof-based localization approaches seen experimental results. larger smaller slower localization speed. however improve robustness accuracy swim. window different corresponds mean case means small number close zero give stable prediction. however small number close zero determined advance depending shows different predictions. give wrong prediction based certain probability thus strong classiﬁers works well others lower prediction probability. generally speaking larger higher accuracy robustness slower speed swim. balance speed accuracy problem. general chosen based noise level. basic principle choosing choose larger lower. general strong classiﬁers provide robust prediction guarantee fusion result swim worse best strong classiﬁers. algorithm swim input ﬁnal prediction matrix length sliding window output prediction probability compute compute using compute using {··· {··· indoor environment i.e. z=). caoa average time delay transmitted signal calculated locations receiver array location control time delay spread angular spread respectively. paths grid. first gaussian white noise added generated signals. signal-noise-ratio signal noise variance respectively. deﬁned total number snapshots grid samples sample snapshots. snrs interspace. ﬁngerprints considered. build goof using algorithm divide classiﬁers samples used test classiﬁers. tree number random forest tree depth weak learner decision dump. fig. shows average prediction probabilities grids swim versus different samples grids curve proposed swim algorithm obtained using sliding window length seen swim mucus higher prediction probabilities siof-based methods regardless snrs. swim almost performance mucus. however prediction frequency swim prediction frequency mucus means swim give times ﬁngerprints samples testing ﬁngerprints. evaluate prediction probability versus different fig. here decision stump. note prediction probability becomes better increases however performance shows limited improvement increases training time testing time become much longer shown fig. decision dump change interspaces. depict average prediction probability versus snrs different fig. corresponding average training testing time shown fig. seen best problem large cannot improve prediction probability samples group snapshots i.e. snapshots estimate ﬁngerprint grid. kind ﬁngerprints samples incorporated ﬁnal goof. samples training data samples testing data. general oriented hyperplane; sliding window length adopted testing samples. obtain predictions grid. prediction probability swim calculated based predictions using shown fig. mucus uses testing time grid time mucus output location prediction swim produce location predictions proposed algorithm balance localization speed robustness well. criminisi shotton konukoglu decision forests uniﬁed framework classiﬁcation regression density estimation manifold learning semi-supervised learning foundations trends computer graphics vision vol.", "year": 2017}