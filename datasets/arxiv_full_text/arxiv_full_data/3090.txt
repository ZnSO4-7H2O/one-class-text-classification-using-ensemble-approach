{"title": "Fast Planar Correlation Clustering for Image Segmentation", "tag": ["cs.CV", "cs.DS", "cs.LG", "stat.ML"], "abstract": "We describe a new optimization scheme for finding high-quality correlation clusterings in planar graphs that uses weighted perfect matching as a subroutine. Our method provides lower-bounds on the energy of the optimal correlation clustering that are typically fast to compute and tight in practice. We demonstrate our algorithm on the problem of image segmentation where this approach outperforms existing global optimization techniques in minimizing the objective and is competitive with the state of the art in producing high-quality segmentations.", "text": "abstract. describe optimization scheme ﬁnding highquality clusterings planar graphs uses weighted perfect matching subroutine. method provides lower-bounds energy optimal correlation clustering typically fast compute tight practice. demonstrate algorithm problem image segmentation approach outperforms existing global optimization techniques minimizing objective competitive state producing high-quality segmentations. tackle problem generic image segmentation goal partition pixels image sets corresponding objects surfaces scene. cues task come bottom-up top-down closed domains top-down information available problem phrased terms labeling pixel several category labels perhaps background. rapidly developing body research area integrates multiple cues output bank object detectors single model typically formulated markov random ﬁeld pixel labels additional hidden variables top-down information available still quite valuable estimate image segments. bottom-up segmentations provide candidate support novel objects simplify processing scene problem understanding small number salient regions. without predeﬁned labels natural describe segmentation task graph partitioning problem pixels superpixels pairwise higher order similarities number parts must estimated. rich history applying graph partitioning techniques image segmentation consider weighted correlation clustering objective sums edges proposed partitioning graph. edges positive negative weights. correlation clustering appealing since optimal number segments emerges naturally function edge weights rather requiring additional search model order parameter. further objective linear edge weights problem learning approached using techniques structured prediction many non-trivial graph partitioning criteria ﬁnding minimum weight correlation clustering np-hard general graphs demaine provide results hardness approximation general graphs reduction to/from multiway recently bachrach also showed correlation clustering np-hard planar graphs reduction planar independent set. despite diﬃculties correlation clustering seen recent applications image segmentation problem. andres deﬁne model image segmentation scores segmentations based costs associated edge segmentation optimize using integer linear programming branch-and-cut strategy. correlation clustering model segmentation includes higher-order potentials hyper-edges deﬁne cost sets nodes solve using linear programming relaxation techniques. paper describe optimization strategy speciﬁcally exploits planar structure image graph. approach uses weighted perfect matching candidate cuts re-weighted versions original graph combines cuts ﬁnal clustering. collection cuts form constraints linear program lower-bounds energy true correlation clustering. practice lower-bound cost output clustering almost always equal yielding certiﬁcate global optimality. compare optimization scheme existing approaches based standard relaxations approach substantially faster provides tighter lower-bounds wide range image segmentation problems. unlike graph partitioning objectives edge weights positive negative. furthermore specify number segments priori place constraints size. instead arise naturally edge weights. example edge weights negative vertex placed separate cluster. edge weights positive optimal solution place vertices single cluster. means upper-bounded since placing vertices cluster valid partitioning cost correlation clustering objective appears similar standard pairwise markov random field models image labeling. example knew optimal solution consisted clusters could convert problem k-state without unary terms. next section make connection precise. clusterings colorings consider partitioning graph represented call partitioning k-colorable labeling vertices graph every graph minimal represent partitions. partitionings representable colors example four-color theolabels planar graphs. terms vertex labels. label variable vertex produce partitioning labeling simply take collection connected components subgraph induced label turn. kcolorable since optimal partitioning q-colorable. -colorable partitions commonly referred cuts graph. could tackle problem planar correlation clustering using standard tools optimizing -state mixed potentials. since combinatorial optimization hard methods give approximate solutions. furthermore many perform poorly problems unary potentials. since energy function symmetric respect permutations labels true max-marginals node labels uninformative forced look higher-order constraints. example lower-bound provided simply negative edge weights graph. interesting exception case planar binary labeling problems. planar graphs cost optimal binary labeling computed eﬃcient reduction weighted perfect matching suitably augmented planar dual graph idea ﬁrst described statistical physics literature kasteleyn fisher context computing partition function ising model. recently explored tool ﬁnding conﬁgurations general mrfs include external ﬁeld since -colorable partitions subset -colorable partitions ﬁnding optimal -colorable partitioning necessarily give optimal clustering planar graph. space -colorable partitions larger general however optimal -coloring still provides useful information optimal -colorable partition. denote weights edges vertices labeled labeled take -colorable partition whose cost consider -colorable partitions pairs labels -coloring merged. three -colorings following costs ﬁrst inequality follows since three terms must least small total. second inequality follows since none -colorings lower cost optimum -coloring. approach used relate pair since -colorable clustering constant factor provides eﬃcient solution ﬁnding approximate correlation clusterings seems likely candidate segmentation. however practice performs poorly real image segmentation problems. natural images t-junctions three diﬀerent image segments come together common junction cannot -colored next section devise tighter bound uses coloring subroutine. dual-decomposition provides general framework tackling diﬃcult problems splitting collection tractable sub-problems solved independently subject constraint agree solutions. constraint enforced soft using lagrange multipliers results dual solution lower-bounds original minimization problem. decomposition techniques studied optimization community decades. dual-decomposition used wainwright derive algorithms inference graphical models become increasingly popular computer vision literature recently ﬂexibility consider bounding planar correlation clustering decomposition sub-problems easier partitioning problem independent edge problem enforce clustering constraints. make partitioning problem tractable impose constraint decomposition cost optimal clustering computed. recall notation optimal correlation clustering cost associated edge weights edges weights optimal equation decomposed original edge weights across sub-problems. ﬁrst correlation clustering problem second independently optimizes edges choice objectives original problem. since conﬁgurations subproblem optimized independently energies produce lower-bound arbitrary bound made tight equation restrict domain settings clustering sub-problem optimum zero. inequality arises since maximizing bound restrictive set. finally equation simpliﬁed expression since constraint entails ﬁrst term exactly zero optimized independently edge. lagrangian relaxation approaches typically projected sub-gradient ascent non-smooth optimization techniques tackle objectives like shown equation diﬃcult compute required gradient information since given setting isn’t obvious recover full optimizing solutions beyond trivial solution constraint also appears quite complicated. however eﬃcient method testing membership earlier proposition constraint described negative weight -colorable clustering. provides method solve equation using cutting planes successively approximate constraint show optimal deformed satisﬁes additional constraints without loosening bound. practice additional constraints make bound optimization eﬃcient. exponential number constraints every possible -colorable partition solve eﬃciently cutting plane approach successively violated constraints collection. ﬁnal algorithm bound optimization given figure actual implementation perform additional step. constraint partition graph multiple components. break basic cuts isolates component. collection constraints batch. modiﬁcation practice batches constraints necessary order produce solution full linear program. order bound tight need clustering edges cut. noted previous section every must edge constrained includes edge. although none individual minimal cuts agree must edges independent sub-problem minimal agrees one. straightforward valid partitions lives inside cone given valid partition indicator vector write linear combination cuts isolates individual segment cuts assigned weight ﬁrst term objective exactly original correlation clustering objective binary indicator replaced real valued second term objective arises upper-bound constraints imposed eﬀectively cancels beneﬁt cutting negative weight edge amount compute solution since cone planar graphs described polynomial number constraints could directly solve dual equation bound optimization gains considerable eﬃciency using full cuts instead small number cutting planes provides delayed column generation scheme solving dual using subset cuts second term corresponding constraints primal necessary since bound tight without optimal partition vector living subspace cone demonstrate performance algorithm correlation clustering problem instances berkeley segmentation data clustering problem deﬁned superpixel graph given performing oriented watershed transform output generalized probability boundary boundary detector output proposed pair superpixels adjacent image connected edge whose weight given fig. comparison bound optimization image segmentation problems. graph shows distribution results problem instances four diﬀerent threshold settings ranging coarse left column shows diﬀerence lower-bounds returned planarcc bound mplp using face cycle constraints. code returned tight bounds instance relaxation typically gave looser bounds. right column shows running times approach compared branch-and-cut advocated plot relative speedup factors logarithmic scale. planarcc bound computation decoding produces global optima approach much faster. constraints lower-bound found decoding schemes work well. experiments described here computed upper bounds using recursive bipartitioning procedure using random order adding contours. process terminated early lowerupper-bounds equal. tering objective. represent clusterings terms node labels superpixel takes states pairwise potentials encode boundary strength neighboring superpixels. mentioned before standard edge-based relaxation uninformative unary potentials absent include cycle constraints given collection cycles bound planar faces superpixel graph. suﬃcient enforce consistency cycles graph natural choice commonly used literature. experiments used fast in-house implementation mplp. also implemented branch-and-cut technique proposed using cplex solver. approach ﬁnds integral solution correlation clustering objective removes edges speciﬁed solution produces partition ﬁnding connected components resulting graph. searches inconsistent edges namely edges connect nodes within connected component. edges found constraint added enforce consistency edge re-solved. figure shows comparison lower-bounds generated mplp compared generated planarcc. found time needed mplp solve problem comparable planarcc. however diﬀerences lower-bound signiﬁcant. face cycles mplp seldom able produce tight lower-bound. contrast planarcc approach typically gives tight bounds batches constraints. found upper-bounds generated planarcc similar close optimal compare time consumed algorithm function figure show histogram comparative times log. note relative performance planarcc improves move high detail segmentation coarse segmentation coarse segmentations optimal solution contains many long contours planarcc performs well relative whereas detailed segmentations tend favorably. example limit edges negative weight approach relaxation gives correct answer without need constraints. however average planarcc approach performs favorably across range useful thresholds bsds images giving speedups range benchmark quality segmentations produced correlation clustering range thresholds bsds test set. superpixels local cues performing gpb+owt+ucm algorithm arbelaez figure shows benchmark results algorithm fig. evaluation bsds segmentation boundary benchmark. compare segmentation performance state technique proposed superpixels contour cues derived compare diﬀerent variants algorithm based region merging. performs length weighted average along contours merge ucm-l performs uniform average. globally optimal correlation clustering returned algorithm performs slightly better uniform averaging version length-weighted gives better ﬁnal performance. algorithm region merging algorithm successively merges superpixels lowest energy edge them. since algorithm greedy respect clustering objective would expect would occasionally merge segments small break contour contrast fate global optimization approach could avoid. however clear figure practice greedy nature seem signiﬁcantly hurt overall performance. explanation algorithm modiﬁes edge costs proceeds. merging step contours formed re-assigned average underlying global clustering objective cannot capture length weighted averaging. figure shows performance algorithm length-weighted averaging simple averaging approach outperforms non-length weighted version diﬀerences substantial. fig. algorithm returns lower-energy segmentations algorithm. suggests either mismatch correlation clustering model ground-truth model using suboptimal settings local boundary cues another possible explanation greedy merging truly successful optimizing correlation clustering objective. figure shows case usually threshold provides segmentation fairly low-cost clustering still suboptimal compared solutions returned planarcc. suggests learning optimal combination structured prediction improve performance. finally worth noting boundary detection benchmark provide strong penalties small leaks segments total number boundary pixels involved small. found region based benchmarks planarcc outperform slightly optimal segmentation threshold chosen per-image basis expect diﬀerences become apparent application local boundary signal noisier greater cost under-segmentation. presented novel fast algorithm ﬁnding high quality correlation clusterings planar graphs. algorithm appears outperform existing approaches variety real problem instances. method exploits decomposition subproblems lack eﬃcient combinatorial algorithms still tractable sense eﬃcient oracles. oﬀers technique toolkit lagrangian relaxations expect application dual-decomposition vision problems. acknowledgments work supported google research award fees research program dbi-.", "year": 2012}