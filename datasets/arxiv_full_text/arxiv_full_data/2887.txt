{"title": "Learning Social Affordance for Human-Robot Interaction", "tag": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "abstract": "In this paper, we present an approach for robot learning of social affordance from human activity videos. We consider the problem in the context of human-robot interaction: Our approach learns structural representations of human-human (and human-object-human) interactions, describing how body-parts of each agent move with respect to each other and what spatial relations they should maintain to complete each sub-event (i.e., sub-goal). This enables the robot to infer its own movement in reaction to the human body motion, allowing it to naturally replicate such interactions.  We introduce the representation of social affordance and propose a generative model for its weakly supervised learning from human demonstration videos. Our approach discovers critical steps (i.e., latent sub-events) in an interaction and the typical motion associated with them, learning what body-parts should be involved and how. The experimental results demonstrate that our Markov Chain Monte Carlo (MCMC) based learning algorithm automatically discovers semantically meaningful interactive affordance from RGB-D videos, which allows us to generate appropriate full body motion for an agent.", "text": "figure visualization social affordance. green person considered agent illustrate sub-event agent needs given current status move reaction person’s bodyparts execute sub-event. black skeleton indicates current frame estimation greens future estimates. right ﬁgure shows hierarchical activity affordance representation affordance sub-event described motion body joints. also visualize learned affordable joints circles grouping denoted colors. note grouping varies different sub-events. spatial-level motion-level affordances) human examples. ability enables robot planning possible actions also allows robots replicate complicated human activities. based training videos humans performing activities robot infer particular subevents executed move bodyparts order previous works robot affordance learning focused scenario single robot manipulating object systems assumed affordance solely depends spatial location object trajectory intended action robot. consequently affordance deﬁned unary function sense agent involved. however order robot perform collaborative tasks interact humans computing single-robot object manipulation affordances based object recognition insufﬁcient. human-robot interaction scenarios multiple agents scene interact react. thus robot must represent affordance interactions body joints multiple agents learn compute hierarchical affordances paper present approach robot learning social affordance human activity videos. consider problem context human-robot interaction approach learns structural representations human-human interactions describing body-parts agent move respect spatial relations maintain complete sub-event enables robot infer movement reaction human body motion allowing naturally replicate interactions. introduce representation social affordance propose generative model weakly supervised learning human demonstration videos. approach discovers critical steps interaction typical motion associated them learning body-parts involved how. experimental results demonstrate markov chain monte carlo based learning algorithm automatically discovers semantically meaningful social affordance rgb-d videos allows generate appropriate full body motion agent. introduction concept affordance learning receiving increasing amount attention robotics computer vision human-robot interaction researchers. term affordance originally deﬁned action possibilities things attracted researchers study computational modeling concept idea behind modern affordance learning research enable robot learning what activities possible where/how execute activities allowing social affordance time frame computed inferring status activity computing appropriate motion make overall activity successful since consider problem particularly context human-robot interaction activity representation involving multiple agents multiple affordable body-parts must learned inference robot’s affordance made treating agents. problem challenging following reasons human skeletons estimated rgb-d videos noisy occlusion making learning difﬁcult; human interactions much complex temporal dynamics simple actions; affordance learning based small training weak supervision. learning propose markov chain monte carlo based algorithm iteratively discover latent subevents important joints functional grouping noisy limited training data. particular design loops learning algorithm outer loop uses metropolis-hasting algorithm propose temporal parsing sub-events interaction instance inner loop selects groups joints within type sub-event modiﬁed chinese restaurant process based discovered latent sub-events affordable joints learn spatial motion potentials grouped affordable joints sub-event. motion synthesis apply learned social affordance unseen scenarios agent assumed observed human agent assumed robot control interact observed agent evaluate approach collected rgb-d video dataset including human-human interactions human-object-human interactions. note human-object-human interactions existing rgb-d video datasets. knowledge ﬁrst work study robot learning affordances social activities. work differs previous robot affordance learning works aspect considers activities multiple agents decomposes activities multiple sub-events/sub-goals learns affordances grounded skeleton sequences learns spatial motion affordances multiple body-parts involved related works although previous studies vision-based hierarchical activity recognition humanhuman interaction recognition research affordances highlevel activities limited. robotic motion planning object manipulation presented symbolic representation learning methods single agent activities low-level joint trajectories explicitly modeled works. computer graphics motion synthesis approaches proposed learn single agent motion based highly accurate skeleton inputs motion capture systems. contrast paper studying affordances dynamic agents multiple body parts including humanhuman interactions well humanobject-human interactions importance also pointed richest elaborate affordances exploring concept ﬁrst time robots. speciﬁcally denote affordances social affordances present approach learn human activity videos. representation formulation propose graphical model represent social affordance hierarchical structure grounded skeleton sequences representation describes human skeletons likely observed persons performing interactions also indicates interaction need decomposed terms sub-events/sub-goals agents perform sub-events terms joint motion. skeleton sequences. interaction instance represented skeleton sequences agents. denote positions agents’ i}∪{j joints time interaction involves object i}∪ot position i}∪{j object practice select important joints base joint left/right writs left/right ankles social affordance whose indexes denoted reasonable simpliﬁcation helps eliminate noise introduced skeleton extraction rgb-d videos maintaining overall characteristics interaction. interaction label. label given interaction deﬁne category predeﬁned dictionary. latent sub-events. intuitions complex interaction usually consists several steps. order enable robots mimic human behavior necessary discover underlying steps latent subevents. here sub-event deﬁned sub-interval within complete interaction. crucial components sub-event sub-goal achieve sub-goals motion patterns. grouping joints sub-goal sub-event deﬁned spatial relations among joints within functional groups movements affordable joints described motion pattens allow infer agent move. shown figure interaction instance represented parse graph t}t=··· corresponding joint selection grouping formalize social affordance interaction note ﬁxed common knowledge depends observed instance. probabilistic modeling subsection provide approach models joint probability parse graph joint selection grouping allowing learning structure parameters representation based observed human skeletons inferring/synthesizing skeleton sequences robot using learned model interaction social affordance representation major parts optimal body-joint selection grouping parse graph observed interaction instance given probability instance deﬁned spatial potential. shift affordable joints sub-event interaction w.r.t. mass center assigned functional group. shifted joint loai. joint group reference point base joint location agent moment instead. joint sub-event motion patterns follow subevent. since difﬁcult humans manually deﬁne annotate sub-events specify number latent sub-events i.e. learning method automatically searches optimal latent sub-event parsing training instance. here latent sub-event parsing interaction instance whose length represented nonk |tk| sub-event labels corresponding intervals i.e. {sk}k=··· note number sub-events vary different instances. joint selection grouping. another intuition discover affordable joints functional groups latent sub-event. means joints contribute much accomplishing latent subevent lack clear motion and/or speciﬁc spatial relations among them rest joints regarded affordable joints clustered together form several functional groups rigid spatial relations among grouped joints sub-events. figure illustrates selection grouping joints sub-event ﬁrst select affordable joints bernoulli distribution prior remain rest joints group; assign affordable joint functional group inﬁnity number latent functional classes {h··· h∞}. grouping addressed chinese restaurant process functional class table affordable joint perceived customer seated table. introduce auxiliary variables indicate joint selection grouping sub-event interaction assigned otherwise assigned null group. together s}s∈s represents joint selection grouping type interaction learning given skeleton sequences interaction labels learn model interaction category isolation. assume training instances interaction parse graphs {gn}n=...n common type interaction. objective learning algorithm optimal maximize following joint probability outer loop sub-event parsing outer loop optimize sub-event parsing metropolis-hasting algorithm. ﬁrst parse interaction sequence atomic time intervals using k-means clustering agents’ skeletons sub-events formed merging atomic time intervals together. iteration propose sub-event parsing following dynamics merging. dynamics merge sub-events similar skeletons together uniformly sample subevent label forms sub-event parsing this ﬁrst deﬁne distance consecutive sub-events mean joint distance average skeletons sub-events denoted splitting. also split sub-event multiple atomic time intervals non-overlapping sub-events labels. note atomic time interval splittable. similarly compute distance between average skeletons sub-events assume uniform distributions labels. encourage split sub-events different skeletons deﬁne proposal distribution number possible labels. re-labeling. relabel uniformly sampled sub-event dynamics gives proposal distribution numbers possible labels current sub-events respectively. addition type dynamics iteration samthree probabilities weibull distributions horizontal vertical distance joint refai) mises distribution angle points. note spatial potential accounts affordable joints affordable joint weibull distributions horizontal vertical distances mises distribution orientation. encourage static joints assigned group exponential distributions distances keeping prior interaction category sub-event transition. assume uniform distribution compute transition frequency training data sub-event prior. duration sub-event interaction regularized log-normal distribution exp{−/}/. figure visualization discovered sub-events joint grouping interactions number denotes subevent label joint colors show groups. throw catch hand object also displayed additional affordable joint. shown frames last moments corresponding sub-events depict learned sub-goals. learned social affordance agents’ motion. note human skeleton sequence seen training data assume interaction category given. estimated object trajectory {ot}t=··· also used object involved. since deﬁne social affordance interaction instance synthesis essentially infer joint locations second agent maximizing joint probability deﬁned main steps motion synthesis summarized alg. time ﬁrst dynamic programming algorithm estimate current sub-event type based observations human agent well skeletons synthesized far. sample joint locations maximizing spatial motion potentials current sub-event. dynamic programming following algorithm efﬁciently infer latent sub-events given skeletons agents maximizing probability parse graph deﬁned sequence interaction ﬁrst deﬁne probability assigning sub-event type time interval preceding sub-event type computed pt]|z deﬁne highest posterior probability assigning type last sub-event t}t=··· recording pairs maximize easily backtrace optimal latent sub-event parsing including labels s··· corresponding intervals t··· starting last frame ﬁrst frame reverse process. algorithm motion synthesis algorithm give interaction label total length unit time interval simulation input skeletons ﬁrst frames i.e. t}t=··· sub-event current on-going sub-event type sampling complete duration w.r.t. prior deﬁned generate possible samples locations modeled joints i.e. i}i∈in=··· note joints null group assumed static current sub-event choose maximizes likelihood i}i∈i computing motion spatial potentials clustered full body skeletons k-means i}i∈i rotating limbs obtain closest interpolate skeletons update obtain acceptance rate deﬁned outer loop given proposed gibbs sampling iteratively update iteration assign joint group type sub-event ai|z s−ai). motion synthesis purpose learning social affordance teach robot interact human. hence design online simulation method synthesize skeleton sequence robot’s action sequence interact {ji}t human object given observed skeleton sequence length interaction. idea make approach automatically generate agent’s body joint motion based figure comparison synthesized skeletons. agent blue object observed; green agents either skeletons synthesized skeletons ours respectively. numbers frame indexes. includes types human-human interactions i.e. shake hands high-ﬁve pull types human-object-human interactions i.e. throw catch hand cup. average instances interaction performed totally actors recorded various views. interaction lasts seconds presented fps. used kinect sensor collection also took advantage skeleton estimation. objects detected background subtraction depth images. dataset available http//www.stat.ucla.edu/ ˜tianmin.shu/socialaffordance. split instances four folds training testing actor combinations testing different ones training set. interaction training algorithm converges within outer loop iterations takes hours -core cpu. motion synthesis average speed unoptimized matlab code. experiment approach learns affordance representations training uses testing synthesize agent skeletons reaction interacting human skeletons ﬁrst measured average joint distance synthesized skeletons ground truth skeletons since good synthesis different multi-level hidden markov model implemented baseline method four levels bottom quantized distance agents quantized relative orientation agents clustered status human skeleton object clustered status synthesized skeleton. addition also compare full model variants without joint selection grouping without latent sub-events notice social affordance based skeleton synthesis problem unaware exact prior state-of-the-art approach. average joint distance different methods compared table. full model outperforms approaches large margin proves advantage hierarchical generative model latent sub-events joint grouping. note tracking error kinect joint ranges figure demonstrates joint selection grouping results automatically discovered latent sub-events different interactions. also visualize several synthesized table means standard deviations human ratings three questions. highlighted ratings indicate sequences synthesized higher mean ratings sequences. interactions figure synthesized skeletons baseline compared skeletons. experiment addition also conducted user study experiment comparing naturalness synthesized skeleton ground truths. similar asked human subjects rate synthesized interactions. this predeﬁned sets videos videos interaction videos either ours. thus mixture videos ours co-exist interaction. randomly assigned sets subjects asked watch video given rate three different questions purpose interaction successfully achieved? synthesized agent behaving naturally? does synthesized agent look like human rather robot? subjects instructed skeleton real human green skeleton synthesized videos. aware fact synthesized sequences mixed stimuli. table compares mean standard deviation human ratings interaction question. following test equivalence ratings question using conﬁdence interval. equivalence margin shake hands throw catch pass test three questions rest interactions pass test consider equivalence margin pull pass equivalence test overall motion synthesis comparable kinect-based skeleton estimation especially suggesting able learn appropriate social affordance representation. lower ratings pull mainly results much noisier training sequences. interestingly synthesized sequences shake hands throw catch sightly higher ratings model learns affordances multiple training sequences whereas based single noisy kinect measure. distinguishable effect hand touching critical pattern human subjects rate videos according feedgt videos especially shake back experiment. hands throw catch hand touching captured occlusion whereas synthesized skeletons notably better performances since method automatically groups corresponding wrist joints together learn spatial relations shown figure shows approach learning sub-goals interactions correctly even noisy kinect skeletons. also counted frequencies high scores given interactions ours respectively similar turing test measuring whether subjects perceived agent human-like robot-like. synthesizing skeleton sequence applying social affordances learned human activities robot replication straightforward. since explicitly represent spatial motion patterns base joint points limbs match corresponding base position positions limbs robot. consequently movement control positions robot achieved moving based synthesized trajectories human joint counterparts reach desired sub-goals. implement real robotic system future work. conclusion paper discussed concept social affordance. able conﬁrm approach learns affordance human body-parts human interactions ﬁnding important body joints involved interactions discovering latent sub-events learning spatial motion patterns. also conﬁrmed able synthesize future skeletons agents taking advantage learned affordance representation obtains results comparable rgbd-based ground truth skeletons estimated kinect. future work transfer learned human motion model robot motion model. paper focused affordance learning part took advantage synthesize skeleton motion sequences assuming humans robots share body conﬁgurations motion however practice robots different conﬁgurations mechanical constraints humans. order learned social affordance useful robots general motion transfer needed future research challenge. references mohamed amer mingtian zhao sinisa todorovic song-chun zhu. costsensitive top-down/bottom-up inference multiscale activity recognition. eccv abhinav gupta praveen srinivasan jianbo larry davis. understanding videos constructing plots learning visually grounded storyline model annotated videos. cvpr yezhou yang cornelia fermuller yiannis aloimonos. robot learning manipulation action plans watching unconstrained videos world wide web. aaai bogdan moldovan plinio moreno martijn otterlo jose santos-victor raedt. learning relational affordance models robots multiobject manipulation tasks. icra luis montesano manuel lopes alexandre bernardino jose santos-victor. learning object affordances sensory-motor coordination ieee transactions robotics imitation. alessandro pieropan carl henrik hedvig kjellstr¨om. recognizing object affordances terms spatio-temporal object-object relationships. humanoids weihua sheng jianhao cheng gang chun meiqin guoqing robot semantic mapping human activity recognition wearable sensing computing approach. robotics autonomous systems", "year": 2016}