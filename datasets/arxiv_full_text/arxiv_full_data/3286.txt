{"title": "Becoming the Expert - Interactive Multi-Class Machine Teaching", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Compared to machines, humans are extremely good at classifying images into categories, especially when they possess prior knowledge of the categories at hand. If this prior information is not available, supervision in the form of teaching images is required. To learn categories more quickly, people should see important and representative images first, followed by less important images later - or not at all. However, image-importance is individual-specific, i.e. a teaching image is important to a student if it changes their overall ability to discriminate between classes. Further, students keep learning, so while image-importance depends on their current knowledge, it also varies with time.  In this work we propose an Interactive Machine Teaching algorithm that enables a computer to teach challenging visual concepts to a human. Our adaptive algorithm chooses, online, which labeled images from a teaching set should be shown to the student as they learn. We show that a teaching strategy that probabilistically models the student's ability and progress, based on their correct and incorrect answers, produces better 'experts'. We present results using real human participants across several varied and challenging real-world datasets.", "text": "figure interactive machine teaching computer teaches human learner image time. begins showing image larger labeled image dataset concealing true class label. learner/student responds estimate image’s class. teacher updates model student ﬁnally reveals correct answer them. process repeated images teaching ends. generalize either everyday life specialized training. many problems highly specialized domain speciﬁc knowledge acquired extensive training needed someone differentiate potentially multiple highly self-similar object categories. designing teaching images ‘teaching set’ show annotators challenging annotator different degree expertise. possible model uncertainty noise generated groups annotators improve collective performance approaches tend downweight votes weak annotators learning trust experts. paper pose question become expert? posit human’s discriminative ability given visual classiﬁcation task improved better modeling teaching process required make experts. family methods referred machine teaching offers general solution problem teaching humans machine teaching active learning active learning computer’s goal learn accurate models given smallest amount supervision. achieved carefully selecting informative datapoints labeled compared machines humans extremely good classifying images categories especially possess prior knowledge categories hand. prior information available supervision form teaching images required. learn categories quickly people important representative images ﬁrst followed less important images later all. however image-importance individual-speciﬁc i.e. teaching image important student changes overall ability discriminate classes. further students keep learning image-importance depends current knowledge also varies time. work propose interactive machine teaching algorithm enables computer teach challenging visual concepts human. adaptive algorithm chooses online labeled images teaching shown student learn. show teaching strategy probabilistically models student’s ability progress based correct incorrect answers produces better ‘experts’. present results using real human participants across several varied challenging real-world datasets. large manually annotated image datasets contributed recent performance increases core computer vision problems object detection classiﬁcation cases visual categories interest generic everyday objects annotation completed crowd sourcing labels internet using services mechanical turk typical image labeling task begins instructions annotator showing example images classes interest. annotator asked assign class labels images ground truth unknown. human. machine teaching computer rather human oracle tasked delivering teaching human student help learn given task effectively. teaching human skill useful right. further better positioned accurately annotate additional unlableled data outside original teaching set. automatic teaching algorithms applications many domains education language learning medical image analysis biological species identiﬁcation more. crucially automated teaching effective needs able assess student’s current knowledge mechanism selecting teaching examples best improve knowledge. work focus task image classiﬁcation. here possible teacher directly ‘teach’ high-dimensional decision boundary human learner instead student must learn boundary shown teaching images. goal teaching choose teaching images maximize student’s classiﬁcation ability minimum amount teaching time. unlike computers humans limited imperfect memory instance-level recognition especially initial learning task however humans advantage possessing ability generalize unknown examples perform domain adaptation given instances. majority previous work machine teaching focused non-interactive teaching teaching computed ofﬂine independent feedback student work address under-explored problem interactive teaching here teacher adapt teaching online based current performance individual student propose algorithm interactively teaches multiple visual categories human learners. contributions threefold unlike computers humans optimal learners. algorithm models student ability online resulting teaching sets adapted individual student. make assumptions regarding internal learning model used students. instead present teaching images attempt reduce predicted future uncertainty based estimate current knowledge. teaching algorithm reduces amount time takes students learn categorization tasks involving multiple classes. experimentally show real human participants using algorithm perform better baselines several challenging datasets. finally provide based interface framework exploring teaching strategies. intention encourage development diverse teaching strategies variety human visual learning tasks. cover closely related work machine teaching. concerned task image categorization focus research concerning teaching classiﬁcation functions. however worth noting different types teaching tasks explored literature e.g. sequential decision tasks humans acquire represent categories active area research visual psychology. many candidate models category acquisition representation humans exist overview direct readers work goal model internal processes directly instead treat human stochastic black learner. convenience divide related work machine teaching areas batch teaching interactive teaching. recent general introduction machine teaching please machine teaching batch batch-based teaching teacher’s goal construct optimal teaching examples ofﬂine presented student teaching. early work area focused theoretical analysis teaching dimension teaching dimension deﬁned minimum number examples required given concept teach concept student. like many works teaching makes simplifying assumption student perfect memory assumption violated real world teaching. theoretically motivated works interesting provide little validation real human subjects recently attempted minimize joint effort teacher loss student optimizing directly teaching set. proposed noisetolerant model assumes student’s learning model known teacher exponential family. follow-on work patil maintain unlike computers inﬁnite memory capabilities humans limited retrieval capacity. motivated real human studies show modeling limited capacity improves human learning performance tasks involving simple one-dimensional stimuli. related work singla teach binary visual concepts showing images real human learners. method operates ofﬂine tries teaching examples best conveys known linear classiﬁcation boundary. experiments mechanical turkers show improvement compared baselines including random sampling. approach attempts encode noise tolerance teaching still unable adapt student’s responses online teaching because ordering teaching images ﬁxed ofﬂine. real human students often noisy especially early stages learning concepts learned formed minds. additionally students learn rate concepts difﬁcult students easier others. interactive teaching teacher receives feedback student teaching progresses. given feedback teaching strategy adapt current ability individual student time. using probabilistic model student noisefree learning assumption ling propose teaching strategy called ‘worst predicted’. strategy similar uncertainty sampling commonly found active learning however unlike active learning machine teaching teacher access ground truth class labels assess student’s performance teaching. experimentally show strategy performs sub-optimally seeks show student image currently uncertain about without regard informative image relation others. result susceptible teaching outliers i.e. unrepresentative images fringes teaching set. interactive teaching papers deal visual concepts basu christensen evaluate human learning performance binary classiﬁcation using three different teaching methods. students tasked classifying simple synthetically generated depictions mushrooms categories. explicitly model labeling noise student instead investigate different interface designs feature space exploration methods help teach students. section formally deﬁne machine teaching task. teacher-computer access labeled dataset dimensional feature vector encoding image corresponding class label. teacher’s goal ‘teach’ classiﬁcation task human learner showing images dataset refer teaching images ‘teaching set’ subset images |dt| |d|. round interactive teaching teacher ﬁrst selects image represented feature vector show human learner. teacher displays images students possible directly show high dimensional feature vector selection image show based process refer ‘teaching strategy’ used teacher. first teacher shows image display ground truth class label. revealing class label teacher able student state class believe image belongs receiving student’s response teacher updates model student reveals ground truth label. teaching proceeds number teaching rounds iteration teacher acquires better understanding student’s current ability. figure outlines teaching iteration. access ground truth teacher trivially knows conditional distribution datapoint student learner corresponding distribution based training examples seen far. teaching teacher seeks minimize student’s expected loss dataset appropriate classiﬁcation loss function. however teacher directly observing student’s true class conditional distribution instead must approximate ˆpl. paper represent using probabilistic semisupervised classiﬁer. teaching strategies optimal teaching strategy minimizes student’s expected loss equation simple strategy choosing next teaching image randomly sample dataset random sampling model student therefore unable adapt ability. lack adaptation manifest ways redundantly presenting teaching examples concepts already learned student directly reinforcing concepts student shown uncertain about. ling proposed strategy called ‘worst predicted’ related uncertainty sampling commonly used active learning however unlike active learning machine teaching computer access ground truth labels. strategy selects next teaching image whose prediction deviates ground truth argmaxy ground truth class label known teacher. disadvantage approach prone proposing outliers teaching images tend highly uncertain current model. expected error reduction teaching teaching strategy refer seer takes inspiration optimal sampling methods found active learning unlike seer chooses teaching image which labeled correctly would greatest reduction future error images teaching here updated estimate student’s conditional distribution shown turn labeled correctly. strategy advantageous property ﬁrst concentrates regions high density feature space student improves reﬁnes boundaries regions. context active learning referred exploration versus exploitation trade off. related approach learning advocated curriculum learning focuses easy concepts ﬁrst progressively increases difﬁculty work approximate student’s conditional distribution given teaching using graph based semi-supervised learning using gaussian random field semi-supervised method propagate student’s estimate class labels current teaching unobserved images deﬁning similarity matrix rn×n beneﬁt using graph based approach need work directly feature space instead similarity image pairs. gives ﬂexibility allowing similarity deﬁned using feature vectors extracted images human provided attributes using distance metric learning length scale parameter controls much neighboring images inﬂuence other. using matrix notation deﬁne matrix element ˆpl. propagate information labels provided student wij. entries except human learner estimated class label teaching image similarity matrix unobserved images subset full matrix efﬁciently evaluate equation using standard matrix operations datasets featuring images second using unoptimized python code. validate proposed multi-class teaching strategy performed studies real human subjects. participants recruited mechanical turk interacted system remotely using custom made interface built using python-based django framework data experiments selected four different datasets summarized table ensure teaching tasks challenging participants one-shot learning possible chose datasets small inter-class variation large intra-class variation. example images classes presented figure unlike standard classiﬁcation datasets featuring everyday objects e.g. datasets contain image categories challenging non-domain experts discriminate between made uncommon classes. datasets ‘butterﬂies’ ‘seabed’ collated authors paper ongoing scientiﬁc studies visual species identiﬁcation. ‘butterﬂies’ subset larger collection british butterﬂy images museum collection captured period years. ‘seabed’ images underwater species taken study attempting measure effects trawling underwater bio-diversity. datasets curated annotated domain experts. figure example images four datasets used experiments. column shows three random images class. note images challenging categorize exhibit large amount intra-class variation. additionally ‘seabed’ images particularly difﬁcult captured wild’ contain occlusion clutter. image features extracted using publiclyavailable convnet system dataset computed features using network pre-trained imagenet challenge dataset ﬁne-tuned fully connected layers using known ground truth class labels datasets produced separate convnet dataset. construct similarity matrix reduced dimensionality convnet features using length scale parameter datasets. initial experiments explored custom-designed hog-based features found perform worse compared ﬁne-tuned convnet. here additional supervised information provided ﬁne-tuning produces representation images class smoothly distributed feature space. feature space better aligned student’s view similarity beneﬁt probabilistic strategies equally. would also possible compute similarity teaching images crowdsourcing image rankings users e.g. however found convnet features good balance reducing amount additional supervised information required teaching task real students’ performance. code data available project website. evaluate teaching algorithm conducted experiments participants recruited mechanical turk previously crump shown possible replicate results classic category learning experiments using mechanical turk. using similar experimental setup participants ﬁrst presented sequence teaching images followed sequence testing images. figure teaching image participants ﬁrst shown image asked estimate class label clicking corresponding button interface provided correct answer. receiving estimated class label participant teaching strategy updates model student chooses next image shown. contrast teaching phase corrective feedback form true class labels provided testing phase. testing round used evaluation purposes necessary real teaching scenarios. test images randomly chosen participant equal class excluded possible teaching set. participant presented random dataset table combined random teaching strategy. dataset number teaching images shown three times number classes times number testing. lengths teaching testing rounds proportional complexity task. experimented longer teaching rounds testing regular intervals teaching images achieve learning curve. however found feedback students became bored frustrated enforced delay encouraging drop out. worth noting teaching tasks signiﬁcantly difﬁcult crowd-sourced image annotation tasks. typical annotation tasks workers already possess strong prior knowledge concepts involved whereas teaching tasks participants unlikely prior domain expertise. surveyed participants start task ensure possessed prior task knowledge rejected results claimed even moderate familiarity classes. such student’s answer ﬁrst teaching image always random guess. avoid workers seemingly clicking random also rejected results whose average response time image fast testing. encourage conscientious effort learning paid workers bonus scored higher threshold testing. discarding noisy participants collected results participants strategy/dataset combination. addition baseline teaching strategies outlined section also compared baselines sbatch. class centroids computed feature space centroids class given dataset students presented images represented centroids teaching. teaching images selected randomly choosing centroids. little intra-class variation oneshot learning possible classes familiar student would expect baseline perform well. ﬁnal baseline sbatch similar ofﬂine batch teaching algorithms here ordering teaching images computed ofﬂine. computed ordering using seer algorithm assuming shown image student would always label correctly. given assumption selection teaching images deterministic identical students regardless responses. recent strategies ofﬂine binary teaching directly applicable comparison operate challenging interactive multi-class classiﬁcation scenario. results human participants summarized table results individual datasets depicted figure average number testing images answered correctly shown dataset strategy combination. seer method outperforms teaching strategies ‘chinese’ ‘butterﬂies’ ‘seabed’ datasets. three method consistently best performing methods vary performance depending speciﬁc dataset. table clear ‘second-best’ method ofﬂine sbatch uncertainty strategies often outperformed random srnd. seer’s performance pronounced ‘seabed’ dataset also contains haphazard images acquisition data cameras wild’ opposed neatly-framed imaging controlled laboratory conditions. average timings testing different strategies calculated time shown test image submitting answer presented table participants taught using method tend answer quickly compared strategies. srnd also response times students’ poorer performance test time possibly indicates level false-conﬁdence. results. two-tailed tests conducted null hypothesis distributions scores method across datasets competing method statistically similar based gaussian assumption. p-values obtained well within standard measure testing statistical signiﬁcance indicating results chance. figure shows average learning curves teaching strategies obtained teaching. average score progress interval calculated averaging number correct responses students datasets point along teaching phase. note equivalent true learning curve images chosen actively teach student rather assess snapshot performance. general trend improving recognition rates teaching images. however gives false sense performance centroid images repeatedly shown thus student overﬁts images typically fails generalize testing. unlike others uncertainty based strategy relatively learning curve outlier images shown challenging learn. underﬁtting gives students weak understanding class’s variability. figure shows examples teaching images shown students strategies ’chinese’ dataset. capacity seer adapt incorrect responses attention given ’stem’ class incorrect previous answer returning teach ’grass’ previous incorrect answer ﬁnally exploring student’s understanding ’mound’. hand sbatch unable adapt teaching focuses teaching ’mound’ ’stem’ despite student’s figure human experiment results across four datasets described table showing average scores testing phase across participants. human participants mechanical turk using expected error reduction based teaching strategy tend better recognition performance average teaching compared baselines. poor performance ’grass’. begins displaying reasonable examples ends attempting teach unusual examples representative dataset’s distribution. performance seer ‘leaves’ dataset shows example perform better random baseline come joint second. property unique dataset multi-modal nature leaves present class fact represents entire genus composed number different species look same. found human learners typically assumed unimodal distributions teaching would often focus single species within entire genus. currently model attempt directly recover incorrect responses made students past. student previously given incorrect answer future teaching images selected similar regions feature space. however earlier incorrectly labeled images still inﬂuence label propagation. allowing incorrectly labeled images relabeled could result teaching strategy continually presenting images correctly labeled. behavior would appropriate machine learner human would quickly learn cheat learning task. revision style strategy would carefully designed ensure concepts already learned continually revisited de-emphasizing earlier teaching answers. machine teaching potential enable humans learn concepts without human-to-human expert tutoring. automatically adapting curriculum student’s ability performance teaching performed situations difﬁcult prohibitively costly direct access domain-level expertise human teacher. work taken step direction proposing interactive multi-class teaching strategy. objective present student teaching images informative given online estimate current knowledge. unlike proposed strategies less likely teach outliers result waste time showing unrepresentative images. similar curriculum learning strategy initially focuses representative images introduces difﬁcult ones time student’s performance improves. currently present teaching images students time. future plan investigate different methods displaying images. visualizations pairwise comparisons highlighting local regions parts prove effective conveying discriminative details characteristics different categories. images intrinsically ‘memorable’ others incorporating measures teaching image selection also improve test time performance. figure example images responses different teaching strategies sample individual students teaching ’chinese’ dataset. solid boxes indicate correct answers dashed lines incorrect answers colors indicate ground truth class labels. given teach humans visual categorization tasks automated fashion future work intend investigate additional information extract students teaching. contrast machines studies suggest humans learn idealized versions data different distribution test exploring teaching domain adaptation problem could allow acquire annotations data different teaching set. finally assumed feature space correlated student’s concept similarity. effective jointly estimate student’s current ability notion similarity teaching. funding research provided epsrc grant ep/k/ sustainable fisheries greenland. would like thank maciej gryka development advice natural history museum london butterﬂy data. edward johns’ funding provided greenland benthic assessment project institute zoology association greenland institute natural resources.", "year": 2015}