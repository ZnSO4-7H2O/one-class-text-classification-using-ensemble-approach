{"title": "A Probabilistic Linear Genetic Programming with Stochastic Context-Free  Grammar for solving Symbolic Regression problems", "tag": ["cs.NE", "math.PR", "stat.ML"], "abstract": "Traditional Linear Genetic Programming (LGP) algorithms are based only on the selection mechanism to guide the search. Genetic operators combine or mutate random portions of the individuals, without knowing if the result will lead to a fitter individual. Probabilistic Model Building Genetic Programming (PMB-GP) methods were proposed to overcome this issue through a probability model that captures the structure of the fit individuals and use it to sample new individuals. This work proposes the use of LGP with a Stochastic Context-Free Grammar (SCFG), that has a probability distribution that is updated according to selected individuals. We proposed a method for adapting the grammar into the linear representation of LGP. Tests performed with the proposed probabilistic method, and with two hybrid approaches, on several symbolic regression benchmark problems show that the results are statistically better than the obtained by the traditional LGP.", "text": "non-informed search issue motivated design estimation distribution algorithms edas derived genetic algorithms probability model sample individuals. generation individuals selected population used update model. probability sampling good solutions increased search concentrates promising regions search space. increase search eciency also ecacy solving previously unsolvable problems. erefore probability models provide mechanisms largely improve performance search algorithms relevant research topic. popular example used design computer programs genetic programming algorithm research edas usually called probabilistic model building genetic programming algorithms several successful works showing pmb-gp outperforms traditional work propose pmb-gp improve variant. developed probability model linear genetic programming algorithm evaluated resulting technique symbolic regression problems. know grammar-based making work novel. model chose work stochastic context free grammar chosen presents interesting characteristics make perform beer characteristics explained later paper. contributions work introducing scfg lgp; development method updating scfg sampling individuals testing proposed algorithm problems; development hybrid method retain features non-eective code code reuse mutations; brief analysis impact retaining features results. rest work organized follows. sections present works related pmb-gp background needed understanding proposed technique. proposed technique explained detail section section presents experimental setup experimental results using simple grammar complex along discussions. finally conclusion future works discussed section abstract traditional linear genetic programming algorithms based selection mechanism guide search. genetic operators combine mutate random portions individuals without knowing result lead individual. probabilistic model building genetic programming methods proposed overcome issue probability model captures structure individuals sample individuals. work proposes stochastic context-free grammar probability distribution updated according selected individuals. proposed method adapting grammar linear representation lgp. tests performed proposed probabilistic method hybrid approaches several symbolic regression benchmark problems show results statistically beer obtained traditional lgp. reference format l´eo franc¸oso piccol vin´ıcius veloso melo. probabilistic linear genetic programming stochastic context-free grammar solving symbolic regression problems. proceedings genetic evolutionary computation conference berlin germany july pages. ./nnnnnnn.nnnnnnn introduction evolutionary algorithms stochastic methods principles natural evolution search solutions optimization problems. search based random modications individuals population performed mutation crossover operators. traditional mechanism guides search promising regions selection based tness individuals. that knowledge search space. permission make digital hard copies part work personal classroom granted without provided copies made distributed prot commercial advantage copies bear notice full citation page. copyrights third-party components work must honored. uses contact owner/author. gecco berlin germany copyright held owner/author. -x-xxxx-xxxx-x/yy/mm.... ./nnnnnnn.nnnnnnn probabilistic incremental program evolution uses probability prototype trees standard tree containing maximum size individual reach. node table probability specic node assuming terminal non-terminal allowed given problem. however nodes independent other. extended model conditional probability node parent means bayesian network. algorithm called estimation distribution programming extended hybrid version using crossover mutation improving performance. greedy search combined metric used group nodes ppt. grouping strategy makes model multivariate calculation joint probability distribution. automatically identify nonoverlapping building blocks improve recombination reduce chance breaking good building blocks. previously introduced grammars also studied model pmb-gp. proposed program evolution explicit learning uses stochastic grammar le-hand sides also consist depth relative location given tree node. rules rened along evolution process updated colony optimization pheromone value maintained derivation inform preferable paths. similar approach used dierent approach learning grammars used generation specic scfg learned best-ed individual. rules merged order become general grammar longer improved. merging done greedy search using metric. work bosman jong uses search strategy adding rules grammar employed algorithm. wong proposed gbbgp uses bayesian network associated rule scsg. network models probability choosing derivation based parent node sibling nodes context elements. extension technique proposed bayesian network classier used derive probability distribution rule. regarding perhaps similar work present n-grams used system. n-gram probability random variable position conditioned values last positions. authors report system scalable able solve dicult problems frequently. linear genetic programming linear genetic programming variant represents individuals linearly sequences instructions result instruction stored register. instruction consists operator acts operands input data constants registers. example program task shown figure linear representation introduces features non-eective code code reuse. non-eective code instructions attributed registers used compute result. instruction figure instance non-eective used aerwards. instructions help increase number neutral variations make individuals exible genetic operation non-eective instruction make eective. feature code reuse exemplied instruction figure used instruction instruction feature useful result must used program helping evolve simpler individuals. crossover traditional mutation types macro micromutations. macro-mutations change complete instruction either deleting inserting substituting random instruction. hand micro-mutations change element instruction like destination register operator argument. given existence non-eective code neutral variations operators made eective possible change eective code individual. implementation used work called emut uses eective mutations reports show conguration performs best steady-state algorithm explained detail generation tournaments carried yielding winners losers. copy winner replaces loser population original winner undergoes mutation according mutation rates. details operators found number instructions tree depth full binary tree depth would need registers instructions represented program using sampling algorithm. nevertheless individuals sampled grammar tend much shorter that. update rule generation probability distribution associated rule grammar updated towards best individuals. individuals sampled updated grammar supposed beer given problem generated randomly. update rule used proposed algorithm similar used pbil first best individuals selected population. seen figure instruction indicating production grammar used derive information selected individuals calculates proportion productions distribution. probability distribution rule updated according following formula learning rate ranges current generation rule index production index prob probability distribution prop proportion use. proportion calculation carried instructions considering selected individuals time. stands proposed grammar-based method updating model resampling population generation without using genetic operators dierent kind grammar dierence tree represented linearly extra feature present. order introduce non-eective code code reuse make macro micro-mutation operators hybrid scheme developed. hybrid approach designed hybrid approach combines mutation operators resampling scfg. role hybrid approach introduce mutation operators non-eective code code reuse benets evolution technique. also running time algorithm reduced resampling rate lowered costly procedure. hybrid schemes investigated work resampling entire population generations applying mutations ones generation resample half population generate half mutations last scheme tournament performed winner mutated original winner along resulting individual mutation passed next generation. model scfg rule probability distribution associated grammar dened quintuple where terminal symbols; non-terminal symbols; start symbol; production rules; probabilities production rules. work assuming probabilities rule independent. hence given production b|c|d probabilities choosing derive depend neither upon parent derivation depth current derivation tree. figure shows example scfg rules corresponding probabilities derivation. sampling individuals sample individual scfg recursive lemost derivation construct syntax tree; dierence result process sequence instructions instead tree. resulting program linear representation would syntax tree eective code reuse. tree functional paradigm results passed boom linear representation procedural paradigm. seen upside-down tree arguments function must instantiated previously code. begins sampling start symbol grammar represented last instruction program. sampled production requires derivation nonterminals call function recursively most). sequence instructions leside argument binary operator comes individual; thus store register cannot used later store results rightside argument. figure shows example derivation tree equivalent program. example noticed repeated instructions. derivation non-terminal register receives must keep track instruction came from. update correct production rule. explained further. consequence chosen representation maximum depth full binary tree equivalent sampled program limited maximum number registers. given inner node equivalent tree corresponds instruction program figure syntax tree using grammar shown figure right program represents tree along parts tree corresponds part program associated grammar production. order construction order recursive algorithm builds program. production identies production associated instruction number rule number associated production. mutated part grammar productions associated longer valid misleading update rule distributions. change instruction mutated also production parent children. simplify present implementation ignore cascade eect focus instruction mutated. however paramount deal eect avoid breaking model. macro micro-mutations change production instruction whether involves identity operator not. mutation involve identity operator simply replaces production currently associated instruction production selected operator. hand production changed another involves identity operator option possible production. instance grammar figure possibilities generate terminal node following path term term factor factor factor factor productions rules case checks content argument register identity operator. instance sequence argument register content based production used generate instruction knows production associate resulting mutated instruction. experiments section present experimental analysis proposed algorithms well-known benchmark functions distinct difculty levels. experiments elaborated investigate performance proposed techniques emut baseline objective outperforming study interested comparing methods others emut. experimental setup conguration algorithms emut gb-lgp hybrid hybrid presented table values either suggested previous works chosen empirically without ne-tuning. operators allowed emut appear grammar experiments. however emut grammar. gb-lgp hybrids need registers allow larger trees derived explained before. first tested algorithms simpler benchmark functions require multiplication solved using equally simple grammar. later tested using grammar options complex functions. absolute deviation success rate. solution successful mean error less statistical comparison employed pairwise wilcoxon’s rank-sum test signicance level compared emut algorithms employ probabilistic model yielded much beer results. simpler functions success rate gb-lgp least emut reached maximum order polynomial error increased substantially proposed approaches still showed much beer success rate emut. finally sixth order polynomial success rate similar techniques. however probabilistic algorithms found solutions much smaller error. given grammar simple rules need learned clear inferior performance higher order polynomials explained limitation registers limit depth equivalent tree. instance production term factor chosen multiple times sequence although median|vi−median| array numerical values length. result aected tree depth limits representation program. suggestion could removing sequences individuals leaving equivalent productions. however need know productions used generate instructions must advance research elaborate beer tracking system. hybrid approaches although perform better emut primary objective outperform gb-lgp. statistical tests table suggest dierences gb-lgp hybrids part signicant. however observe trend table hybrids worse gb-lgp. know eects productions individuals caused mutation operators reason lower performance; deeply investigated future work. nevertheless hybrids resample less gb-lgp faster could preferable gb-lgp solve problems. order asses impact hybrid approach individuals figure shows evolution mean percentage eective code population function. expected individuals emut eective code. gb-lgp entire code eective genetic operator applied them. hybrid switches eective code lile non-eective code. population resampled every generations time increase amount non-eective code. hybrid programs remained mostly eective small amount non-eective code. conclude hybrid approaches worked well introducing features programs. experiment experiment incorporated functions grammar tested algorithms dierent benchmark functions figure shows resulting grammar table species functions. results experiment follow paern previous experiment gb-lgp yielding best results techniques probabilistic model performing beer emut. functions grammar complex experiment prediction errors small previous experiment. method could perform well korns’ functions likely constants must tuned. although mean error shown table gb-lgp nguyen lower table second experiment algorithm success. population approximated data functions present extended grammar cos. suggests complex grammar lead search easily stagnation sub-optimal solutions. individual updated mutation. nonetheless hybrid versions make possible obtain beer results emut less time gb-lgp less samplings grammar take place. order evaluate solutions using grammar table shows mean size number instructions eective instructions solutions found. eective size solutions created grammar much bigger ones found emut. fact smaller total size. possible show every grammar evolved technique function large amount space needed that. however illustrate grammar evolves figure shows evolution probability distributions gb-lgp korns function. observe instance high probability generating solutions containing number input benchmark function uses. plot strong indicative algorithms working expected improvements obtained investigations. conclusions future work grammars enhance performance genetic programming algorithms well-investigated topic linear counterpart still unexplored know. harder implement tracking changes adequately update model proved trivial. work scfg acquire knowledge search space evolution guide process allowed proposed algorithms obtain beer results standard well-known symbolic regression problems. using simple grammar polynomials gb-lgp able achieve high success rates. hybrid approaches also able outperform standard mut) introducing mutations reducing execution time. promising results open avenue many future investigations. proposed algorithms faced issues existence sequences instructions represent production rule aect result program like identity aribution used several times sequence; eects mutation operators productions associated individual; convergence local optima simply stagnation wrong references b¨ack. evolutionary algorithms eory practice evolution strategies evolutionary programming genetic algorithms. oxford university press oxford baluja. population-based incremental learning method integrating genetic search based function optimization competitive learning. technical report. pisburgh usa. bosman jong. grammar transformations genetic programming. gecco workshop proceedings brameier banzhaf. eective linear genetic programming. technical report. department computer science university dortmund dortmund germany. brameier banzhaf. linear genetic programming. springer. hauschild pelikan. introduction survey estimation distribution algorithms. swarm evolutionary computation shan mckay abbass essam. program evolution explicit learning framework program automatic synthesis. university college university south. ieee press shan mckay baxter abbass essam nguyen. grammar model-based program evolution. evolutionary computation cec. congress vol. vol.. tanev. implications incorporating learning probabilistic contextsensitive grammar genetic programming evolvability adaptive locomotion gaits snakebot. gecco workshop proceedings. seale washington usa. hoai o’neill mckay galvan-lopez. semantically-based crossover genetic programming application realvalued symbolic regression. genetic programming evolvable machines wong wong leung. grammar-based genetic programming dependence learning bayesian network classier. proceedings annual conference genetic evolutionary computation york", "year": 2017}