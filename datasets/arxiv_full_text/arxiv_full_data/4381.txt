{"title": "Synthesizing Normalized Faces from Facial Identity Features", "tag": ["cs.CV", "stat.ML"], "abstract": "We present a method for synthesizing a frontal, neutral-expression image of a person's face given an input face photograph. This is achieved by learning to generate facial landmarks and textures from features extracted from a facial-recognition network. Unlike previous approaches, our encoding feature vector is largely invariant to lighting, pose, and facial expression. Exploiting this invariance, we train our decoder network using only frontal, neutral-expression photographs. Since these photographs are well aligned, we can decompose them into a sparse set of landmark points and aligned texture maps. The decoder then predicts landmarks and textures independently and combines them using a differentiable image warping operation. The resulting images can be used for a number of applications, such as analyzing facial attributes, exposure and white balance adjustment, or creating a 3-D avatar.", "text": "figure input photos encoded using face recognition network feature vectors decoded image face using decoder network invariance encoder network pose lighting expression allows decoder produce normalized face image. resulting images easily model method even produce plausible reconstructions blackand-white photographs paintings faces. intuitively mapping identity normalized face image nearly one-to-one train decoder network learn train decoder network carefully-constructed pairs features normalized face images. best results facenet features method produces similar results features generated publicly-available vgg-face network present method synthesizing frontal neutralexpression image person’s face given input face photograph. achieved learning generate facial landmarks textures features extracted facial-recognition network. unlike previous generative approaches encoding feature vector largely invariant lighting pose facial expression. exploiting invariance train decoder network using frontal neutral-expression photographs. since photographs well aligned decompose sparse landmark points aligned texture maps. decoder predicts landmarks textures independently combines using differentiable image warping operation. resulting images used number applications analyzing facial attributes exposure white balance adjustment creating avatar. recent work computer vision produced deep neural networks extremely effective face recognition achieving high accuracy millions identities networks embed input photograph highdimensional feature space photos person nearby points. feature vectors produced network facenet remarkably consistent across changes pose lighting expression. common neural networks however features opaque human interpretation. obvious reverse embedding produce image face given feature vector. present method mapping facial identity features back images faces. problem hugely underconstrained output image dimensions facenet feature vector. idea exploit invariance facial identity features pose lighting expression posing problem mapping feature vector evenly-lit front-facing neutralexpression face call normalized face image. even successfully operate monochrome photographs paintings. robustness network sets apart related methods directly frontalize face warping input image frontal pose cannot compensate occlusion lighting variation. consistency resulting normalized face allows range applications. example neutral expression synthesized face facial landmark locations make easy morphable model create virtual reality avatar automatic color correction white balancing also achieved transforming color input photograph match color predicted face finally method used exploratory tool visualizing features reliably captured facial recognition system. similar active shape model lanitis decoder network explicitly decouples face’s geometry texture. case decoder produces registered texture image positions facial landmarks intermediate activations. based landmarks texture warped obtain ﬁnal image. developing model tackle technical challenges. first end-to-end learning requires warping operation differentiable. employ efﬁcient easyto-implement method based spline interpolation. allows compute facenet similarity input output images training objective helps retain perceptually-relevant details. second difﬁcult obtain large amounts frontresponse facing neutral-expression training data. employ data-augmentation scheme exploits texture-shape decomposition randomly morph training images interpolating nearest neighbors. augmented training allows ﬁtting high-quality neural network model using unique input images. techniques introduced work decomposition geometry texture data augmentation differentiable warping applicable domains face normalization. interest understanding deep networks’ predictions several approaches creating image particular feature vector. approach directly optimizes image pixels gradient descent producing images similar deepdream pixel space large relative feature space optimization requires heavy regularization terms total variation gaussian blur resulting images intriguing realistic. forward network reverse given embedding dosovitskiy brox pose problem constructing likely image given feature vector. method contrast uses restrictive criterion image must normalized face. perhaps relevant prior work zhmoginov sandler employs iterative feedforward methods inverting facenet embeddings recover image face. require training data method produces better ﬁne-grained details. active appearance model faces active appearance model cootes extension blanz vetter provide parametric models manipulating generating face images. model limited data decoupling faces components texture facial landmark geometry fig. landmark points detected. fig. image warped landmarks located training dataset’s mean landmark locations warping operation aligns textures that example left pupil every training image lies pixel coordinates. authors separate principal components analysis models textures geometry. reliably using substantially less data model images. individual face described coefﬁcients principal components landmarks textures. reconstruct face coefﬁcients un-projected obtain reconstructed landmarks texture texture warped landmarks. various techniques warping. example blanz vetter deﬁne triangulations apply afﬁne transformation triangle corresponding triangle sec. employ alternative based spline interpolation. facenet facenet maps face images taken wild -dimensional features. architecture similar popular inception model facenet trained triplet loss embeddings pictures person similar embedding picture person picture person loss encourages model capture aspects face pertaining identity geometry ignore factors variation speciﬁc instant image captured lighting expression pose etc. facenet trained large dataset encodes information wide variety human faces. recently models trained publicly available data approached exceeded facenet’s performance method agnostic source input features produces similar results features vgg-face network facenet employ facenet source pretrained input features source training loss input image generated image similar facenet embeddings. loss functions deﬁned pretrained networks correlated perceptual rather pixellevel differences prior work face frontalization adopts non-parametric approach registering normalizing face images taken wild landmarks detected input image aligned points reference model. then image pasted reference model using non-linear warping. finally rendered front-facing image downstream models trained front-facing images. approach largely parameter-free require labeled training data normalize variation lighting expression occlusion unsupervised learning generative image models active research area many papers evaluate celeba dataset face images these generated images smaller generally lowerquality ours. contrasting approaches system also challenging draw independent samples whereas generate images conditional input image. therefore achieve high quality simply memorizing certain prototypes. assume training front-facing neutralexpression training images. preprocessing decompose image texture landmarks using off-the-shelf landmark detection tools warping technique sec. test time consider images taken wild substantially variation lighting pose etc. these applying training preprocessing pipeline obtain inappropriate. instead deep architecture encoder takes input image returns fdimensional feature vector need choose encoder carefully robust shifts domains images. response employ pretrained facenet model update parameters. assumption facenet normalizes away variation face images indicative identity subject. therefore embeddings controlled training images mapped space taken wild. allows train controlled images. instead ﬁnal facenet output lowest layer spatially varying avgpool layer architecture. train fully-connected layer dimensions layer. using vgg-face features layer. could mapped output image directly using deep network. would need simultaneously model variation geometry textures faces. lanitis found substantially effective separately generate landmarks textures render ﬁnal result using warping. generate using shallow multi-layer perceptron relu non-linearities applied generate texture images deep cnn. ﬁrst fullyconnected layer localized features. then stacked transposed convolutions separated relus kernel width stride upsample localized features. number channels transposed convolution max. finally apply convolution yield values. generating registered texture images unreasonable fully-connected network rather deep cnn. maps pixel values directly using linear transformation. despite spatial tiling models roughly number parameters. contrast outputs approaches sec. decoder combines textures landmarks using differentiable warping technique described sec. this entire mapping input image generated image trained end-to-end. seek warp image satisﬁes properties landmark points shifted displacements i.e. warping continuous resulting ﬂow-ﬁeld derivatives order controllable. addition require differentiable function describe method terms images generalizes naturally higher dimensions. figure image warping left starting landmark locations middle-left desired ﬁnal locations including zero-displacement boundary conditions middle-right dense ﬁeld obtained spline interpolation right application image. fig. describes warping. first construct dense ﬁeld sparse displacements deﬁned control points using spline interpolation. then apply ﬁeld order obtain second step uses simple bilinear interpolation differentiable. next section describes ﬁrst step. differentiable spline interpolation interpolation done independently horizontal vertical displacements. dimension scalar deﬁned control point seek produce dense grid scalar values. besides facial landmark points include extra points boundary image enforce zero displacement. here radial basis functions. common choices experiments choose since linear interpolant robust overshooting thin-plate spline linearization artifacts difﬁcult detect ﬁnal texture. figure model architecture ﬁrst encode image small feature vector using facenet plus additional multi-layer perceptron layer i.e. fully connected layer relu non-linearities. then separately generate texture using deep convolutional network vector landmarks’ locations using mlp. combined using differentiable warping yield ﬁnal rendered image. solute error respectively. effective loss penalizing reconstruction error ﬁnal rendered image. suppose example model predicts color correctly location eyes incorrectly. penalizing reconstruction error output image encourage color resemble color cheeks. however penalizing landmarks textures separately model incur cost color prediction penalize predicted location. next reward perceptual similarity generated images input images penalizing dissimilarity facenet embeddings input output images. facenet network ﬁxed parameters compute -dimensional embeddings images penalize negative cosine similarity. training facenet loss adds considerable computational cost without need perform differentiable warping training. furthermore evaluating facenet generated image expensive. sec. discussion impact facenet loss training. figure training computation graph dashed line connects terms compared loss function. textures compared using mean absolute error landmarks using mean squared error facenet embedding using negative cosine similarity. figure data augmentation using face morphing gradientdomain compositing. left column contains average images individuals. remaining columns contain random morphs individuals training set. morphing tends preserve details inside face landmarks accurate cannot capture hair background detail. make augmented images realistic paste morphed face onto original background using gradient-domain editing technique element-wise product blending mask deﬁned convex hull global average landmarks softened gaussian blur. equations form over-constrained linear system solve leastsquares sense. ﬁnal result formed warping morphed landmarks variety large publicly-available databases photographs available online. choose dataset used train vgg-face network size emphasis facial recognition. contains photographs requirements front-facing neutral-pose sufﬁcient quality. google cloud vision remove monochrome blurry images faces high emotion score eyeglasses tilt control points minimizes certain definition curvature algorithm shows combined process estimating interpolation parameters training data evaluating interpolant query points. optimal parameters obtained closed form operations either linear algebra coordinate-wise non-linearities differentiable. therefore since differentiable function entire interpolation process differentiable. training model requires large varied database evenly-lit front-facing neutral-expression photos. collecting photographs type difﬁcult publiclyavailable databases small train decoder network response construct small high-quality photos data augmentation approach based morphing. since faces front facing similar expressions generate plausible novel faces morphing. given seed face ﬁrst pick target face selecting nearest neighbors random. measure distance faces matrices landmarks texture maps experiments. given random neighbor linearly interpolate landmarks textures independently interpolation weights drawn uniformly figure averaging images individual produce consistent lighting. example input photographs large variation lighting color. averaging tends produce evenly still detailed result angles beyond remaining images aligned undo roll transformation scaled maintain interocular distance pixels cropped ﬁltering approximately images remove variation lighting average images individual morphing. ﬁltering quality unique identities images identity. given images individual extract facial landmarks image using method kazemi sullivan average landmarks form image warped average landmarks pixel values averaged form average image individual shown fig. operation tends produce images resemble photographs soft even lighting. images form base training set. backgrounds training images widely variable leading noisy backgrounds results. cleaner results could probably obtained manual removal backgrounds. experiments mainly focus labeled faces wild dataset since identities mutually exclusive face dataset. include example sources painting show range method. except otherwise noted results produced architecture section weights landmark loss facenet loss texture loss data augmentation produces images. model implemented tensorflow trained using adam optimizer facenet avgpool- vgg-face features shown middle rows. results facenet features especially stable across different poses illumination vgg-face features comparable. severe occlusions sunglasses headwear signiﬁcantly impact output quality. model even works paintings fig. fig. comparison include state-of-the-art frontalization method based image warping contrast method image warping remove occlusions handle extreme poses neutralize expressions correct variability illumination. fig. contrast output system variations model trained without data augmentation model uses data augmentation employs fullyconnected network predicting textures. training without data augmentation yields artifacts overﬁtting. fully-connected decoder generates images generic since though separate parameters every pixel capacity limited mechanism coordinating outputs multiple scales. fig. shows beneﬁt decoupling texture landmark prediction. compared regular decoder capacity method reproduces ﬁner details. increased performance results main observation lanitis warping input images global mean landmarks aligns features eyes lips across training allowing decoder face images higher ﬁdelity. improvement training facenet loss also measured evaluating facenet test outputs. fig. shows distributions distances between embeddings images corresponding synthesized results models trained without facenet loss. schroff consider facenet embeddings encode person distance less synthesized images pass test using facenet loss without images would mid-identiﬁed facenet different person. landmarks texture normalized face used morphable model fitting morphable model unconstrained image face requires solving difﬁcult inverse rendering problem ﬁtting normalized face image much straightforward. figure face normalization people dataset bottom input photographs result method using facenet features result method using vgg-face features result hassner additional results supplementary material. figure output various conﬁgurations system texture decoder trained images fully-connected decoder trained images using data augmentation technique sec. figure results without loss term penalizing difference facenet embedding. facenet loss encourages subtle important improvements ﬁdelity especially around eyes eyebrows. result lower error embeddings input synthesized images. figure decoder architecture comparison test data. plain decouple texture landmarks method does. decoder capacities training regime identical. process produces well-aligned face mesh could directly used avatar could serve initialization processing example methods track facial geometry video ﬁdelity reconstructed shape limited range morphable model could likely improved diverse model recent lsfm figure histograms facenet error input synthesized images lfw. blue facenet loss green without facenet loss. threshold used schroff cluster identities. without facenet loss synthesized images would considered identity input image. since normalized face image provides ground truth image face easily applied automatically adjust exposure white balance photograph apply following simple algorithm given aligned input photograph corresponding normalized face image extract center average cropped regions form mean face colors adjusted image computed using per-channel piecewise-linear color shift function. sec. supplementary material details. comparison apply general white balancing algorithm barron approach focus face limited adjustment makes whereas algorithm balances face regardless effect regions image producing consistent results across different photos person. introduced neural network maps images faces taken wild front-facing neutralexpression images capture likeness individual. network robust variation inputs lighting pose expression cause problems prior face frontalization methods. method provides varifigure automatic adjustment exposure white balance using color normalized face images dataset. images ﬁrst input images; second outputs method third outputs barron state-of-theart white balancing method. implicit encoding skin tone model crucial exposure white balance recovery. spline interpolation used extensively computer graphics unaware work interpolation used differentiable module inside network. encourage application technique. hope improve images’ quality. noise artifacts likely result overﬁtting images’ backgrounds blurriness likely results using pixel-level squared error. ideally would broad selection training images avoid pixel-level losses entirely combining facenet loss sec. adversarial loss", "year": 2017}