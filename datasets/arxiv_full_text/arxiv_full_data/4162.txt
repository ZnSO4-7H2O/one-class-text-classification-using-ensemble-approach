{"title": "When Saliency Meets Sentiment: Understanding How Image Content Invokes  Emotion and Sentiment", "tag": ["cs.AI", "cs.CV"], "abstract": "Sentiment analysis is crucial for extracting social signals from social media content. Due to the prevalence of images in social media, image sentiment analysis is receiving increasing attention in recent years. However, most existing systems are black-boxes that do not provide insight on how image content invokes sentiment and emotion in the viewers. Psychological studies have confirmed that salient objects in an image often invoke emotions. In this work, we investigate more fine-grained and more comprehensive interaction between visual saliency and visual sentiment. In particular, we partition images in several primary scene-type dimensions, including: open-closed, natural-manmade, indoor-outdoor, and face-noface. Using state of the art saliency detection algorithm and sentiment classification algorithm, we examine how the sentiment of the salient region(s) in an image relates to the overall sentiment of the image. The experiments on a representative image emotion dataset have shown interesting correlation between saliency and sentiment in different scene types and in turn shed light on the mechanism of visual sentiment evocation.", "text": "sentiment analysis crucial extracting social signals social media content. prevalence images social media image sentiment analysis receiving increasing attention recent years. however existing systems black-boxes provide insight image content invokes sentiment emotion viewers. psychological studies confirmed salient objects image often invoke emotions. work investigate fine-grained comprehensive interaction visual saliency visual sentiment. particular partition images several primary scene-type dimensions including open-closed natural-manmade indooroutdoor face-noface. using state saliency detection algorithm sentiment classification algorithm examine sentiment salient region image relates overall sentiment image. experiments representative image emotion dataset shown interesting correlation saliency sentiment different scene types turn shed light mechanism visual sentiment evocation. visual sentiment analysis information explosion increasingly common people express emotions posting images social media like twitter flickr. important psychologists computer vision researchers utilize tremendous information interpret human emotion carried images. early days manually crafted features e.g. pixel level features color texture composition designed study emotional reaction visual content. similar methods pervasive recently large scale image datasets imagenet places dataset became available. power deep learning especially convolutional neural networks figure boxes indicate detected salient objects. left column shows example images whose salient objects share similar sentiment whole images. right column shows example images whose salient objects agree whole images terms sentiment. text image indicates dominant attribute corresponding attribute pair. please refer text detailed description sentiment agreement dominant attribute. harnessed recently discover sentiment carried images however work dedicated fine-tuning pre-trained deep neural network models alexnet vggnet resnet. models used black boxes little research paid attention elements attributes image responsible invoking emotions. work focus effort understanding dominant factors attributes behind image sentiment evocation. saliency detection meantime saliency detection also shifting common visual feature based classifiers deep learning based models. previously low-level saliency priors contrast prior center prior leveraged approximate human observed saliency. recently inspired convolutional neural network’s state-of-the-art performance various computer vision tasks image classification scene recognition researchers start utilize capture high-level visual concepts produce saliency models better detection performance saliency detection focuses attention analysis visual sentiment analysis focuses emotion analysis. various psychologists neuroscientists actively studying underlying relationship attention emotion. ongoing discrepancy suggest emotional perception automatic namely manner independent top-down factors attention illustrating dependence attention best knowledge however computer vision research done discover emotion depends attention especially salient object image. even though active research topic neuroscience neuroscientists fail enough attention following questions given image salient object salient object share similar sentiment entire image? images share similar sentiment salient object category fall into? share common attributes like man-made objects human faces? images share similar sentiment salient objects? therefore target work questions make several contributions investigate fine-grained interaction visual saliency visual sentiment several primary scene types including open-closed natural-manmade indooroutdoor face-noface. employ state saliency algorithm visual sentiment classification model facilitate accurate region-level computational analysis interactions. utilize large public image emotion dataset discover relationship saliency sentiment different scene types order understand evocation mechanism visual sentiment. best knowledge related work combining saliency detection image sentiment classification understand image invokes human emotion. relevant work image sentiment localization. proposed notion affective region specific region image contains salient objects attract viewers’ attention carry significant emotion. work offthe-shelf object detection algorithm adopted generate random proposals sentiment proposals entire image evaluated discover affective regions. however method utilizes explicit object recognition generate thousands proposal windows order yield high recall rate affective regions proposals. also incurs high computational overhead result regions containing tiny objects even catch people’s attention. peng work predict emotion stimuli describes pixels-wise contribution emotion. pre-trained fine-tuned model predict conclude neither saliency objectness correctly predict image regions evoke emotion. however fail justify choice dataset consists predominantly landscape scenes give insight saliency detection method work detecting affective emotion region images. yuan extract scene descriptor low-level features dataset features train svm-based classifier order generate mid-level scene attributes based perform sentiment prediction. zhou work learn deep features images places dataset able generate receptive field image scene recognition task. generated receptive fields reflect part image model looking recognizing scenes. critical understand scene recognition model takes account performing scene recognition similarly great significance sentiment analysis model understand scene attributes account prediction image sentiment. therefore propose framework understand images whose salient object share sentiment entire image scene attributes possess. hand images salient object does/do agree sentiment entire image scene attributes possess. dataset data released visual sentiment prediction. dataset different categories including amusement anger contentment disgust excitement fear sadness. category randomly sample first images experiment. statistics current data shown table notice work actually need exact emotion label image build data using labeled unlabeled images. salient object detection adopt state-of-the-art saliency detection model detect whether image salient object locate salient objects. model leverages high expressiveness vggnet generate scored salient object proposals image based produces compact detected regions using subset optimization formulation. every image given dataset model detect whether salient object save detected salient objects images corresponding folder subsequent scene-attribute based partitioning. framework overview figure illustrates framework annotation. details steps follows step given image state-of-the-art saliency detection model detect salient object image. boxes show detected salient objects. step state-of-the-art sentiment classification model obtain sentiment scores whole image salient objects any. step based obtained scores able find image salient object shares sentiment entire image. consequently partition entire dataset parts images least salient objects shares sentiment whole image images none salient objects express sentiment whole image. simplicity images without salient object detected simply excluded further analysis. please refer visual sentiment analysis section details definition sentiment agreement. step within partitions obtain previous steps apply state-of-the-art scene attribute detector human face detector partition part based detected attribute image. step evaluate results classification mentioned gather interesting findings. search tool detect whether face given image based classify partition images contain face not. summary attribute extraction categorization process follows figure dataset fairly well distributed among evaluated scene attributes. sentiment agreement threshold categorization experiment generates results shown figure conduct experiments different sentiment agreestate-of-the-art convolutional neural network model proposed campos giro-i-bieto work fine-tuned model using several performance boosting techniques improve performance visual sentiment prediction. image extract output nodes last fully connected layer denote sentiment probability outputs image represent probability 𝑆𝐴𝑅𝑖 =min𝑠∈𝑆 𝑤ℎ𝑒𝑟𝑒 𝑠𝑎𝑙𝑖𝑒𝑛𝑡 𝑜𝑏𝑗𝑒𝑐𝑡𝑠 sentiment whole image 𝑆𝐴𝑅𝑖 threshold. words image within range whole image’s sentiment score image regarded image whose salient object agrees sentiment entire image classified partition agree. otherwise image whose salient object disagrees sentiment entire image classified partition disagree. experiment agreement threshold attribute extraction categorization partition obtain previous step fine-tune state scene recognition model placescnn classify indoors outdoors. model architecture used caffe reference network trained places database benchmark scene recognition. given image model produce vector dimension corresponds probability scenes. according given indoors/outdoors label reference labels predicted places categories vote whether indoor outdoor. next deep features last fully connected layers detect scene attributes ranked probability scores descending order. compare scores open closed natural man-made. whichever attribute pair higher probability score used represent image. define attribute dominant attribute attribute pair. example image score open closed natural man-made image classified dominant attribute closed manmade. finally utilize leading cloud-based face recognition service face++ rep_a partition number images dominant attribute opposite. all_a entire dataset number images dominant attribute number images partition number images entire dataset positive discrimination ratio attribute partition indicates image attribute easier classified words higher discrimination ratio likely images partition going attribute vice versa. table suggests similar patterns various sentiment agreement thresholds ranging agreement threshold decreases agree partition decreases disagree partition increases follows intuition stricter rule difficult specific part image represent whole image would like random even split dataset. images whose salient object agree whole images tend contain face outstanding man-made object tend closed likely indoor scene images whose salient objects disagree whole images. face-noface column attributes influential pulling images away other. average discrimination ratio partition disagree partition agree images containing faces highly likely express sentiment faces express images without faces unlikely invoke human emotion solely salient objects. observation also follows intuition faces tend dominate sentiment perception humans. example easily tell sentiment left images figure simply looking human face without paying attention objects elements. conduct another experiment evaluate partitioning power attribute combinations closed manmade outdoor noface great tendency partitioning images agree. experiment partition agree disagree classes according possible combinations four pairs attributes. example class calculate total number closed manmade indoor face images also total number entire opposite namely open natural outdoor noface images. combination partition also calculate metric. teresting findings combination negative image attribute combination open natural outdoor noface likely classified partition disagree. combinations face attribute high confirms images faces likely classified partition agree. surprisingly opposite negative necessarily combination positive instead {closed natural outdoor face} {open natural indoor face} share positive work using state saliency detection model visual sentiment classification model obtain salient object proposals analyze sentiment agreement whole images. extract scene attributes images examine fine-grained interaction between visual saliency visual sentiment. results suggest images contain outstanding man-made objects human faces indoors closed tend express sentiment salient objects. hand images natural objects outstanding man-made objects contain human faces outdoors open usually convey sentiment information solely salient objects. encouraged study evaluate expressiveness salient object terms image sentiment. moreover conduct experiments scene attribute distribution emotion class e.g. amusement anger study evocation mechanism specific emotion. also study scene attributes. potential give insight kind attributes responsible invoking human emotion providing guidance in-depth image sentiment analysis psycho-visual understadning. zoo. computer vision pattern recognition ieee conference ieee. zhou khosla lapedriza oliva torralba object detectors emerge deep scene cnns. international conference learning representations zhang sclaroff shen price mech unconstrained salient object detection proposal subset optimization. proceeding ieee conf. computer vision pattern recognition campos giro-i-nieto pixels sentiment fine-tuning cnns visual sentiment prediction. arxiv preprint arxiv.. yang building large scale dataset image emotion recognition fine print benchmark. thirtieth aaai conference artificial intelligence shelhamer donahue karayev long girshick guadarrama darrell caffe convolutional architecture fast feature embedding. proceedings international conference multimedia acm. patterson hays attribute database discovering annotating recognizing scene attributes. computer vision pattern recognition ieee conference ieee. megvii inc. face++ research toolkit. www.faceplusplus.com december machajdik hanbury affective image classification using features inspired psychology theory. proceedings international conference multimedia acm. deng dong socher fei-fei imagenet large-scale hierarchical image database. computer vision pattern recognition cvpr ieee conference ieee. zhou lapedriza xiao torralba oliva learning deep features scene recognition using places database. advances neural information processing systems jindal singh image sentiment analysis using deep convolutional neural networks domain specific fine tuning. ieee international conference information processing yang robust image sentiment analysis using progressively trained domain transferred deep networks. twenty-ninth aaai conference artificial intelligence krizhevsky sutskever hinton imagenet classification deep convolutional neural networks. advances neural information processing systems wang ruan yang deep networks saliency detection local estimation global search. proceedings ieee conference computer vision pattern recognition zhang wang co-saliency detection looking deep wide. proceedings ieee conference computer vision pattern recognition vuilleumier armony driver dolan effects attention emotion face processing human brain event-related fmri study. neuron grossberg brain build cognitive code?. studies mind brain springer netherlands. russo bowles dutton threatening stimuli draw hold visual attention subclinical anxiety?. journal experimental psychology general yang wang shen. discovering affective regions deep convolutional neural networks visual sentiment prediction. ieee international conference multimedia expo alexe deselaers ferrari object?. computer vision pattern recognition ieee conference ieee. peng c.;sadovnik gallagher chen emotions come from? predicting emotion stimuli map. ieee international conference image processing yuan mcdonough sentribute image sentiment analysis mid-level perspective. proceedings second international workshop issues sentiment discovery opinion mining acm. xiao hays ehinger oliva torralba database large-scale scene recognition abbey", "year": 2016}