{"title": "Volumetric and Multi-View CNNs for Object Classification on 3D Data", "tag": ["cs.CV", "cs.AI"], "abstract": "3D shape models are becoming widely available and easier to capture, making available 3D information crucial for progress in object classification. Current state-of-the-art methods rely on CNNs to address this problem. Recently, we witness two types of CNNs being developed: CNNs based upon volumetric representations versus CNNs based upon multi-view representations. Empirical results from these two types of CNNs exhibit a large gap, indicating that existing volumetric CNN architectures and approaches are unable to fully exploit the power of 3D representations. In this paper, we aim to improve both volumetric CNNs and multi-view CNNs according to extensive analysis of existing approaches. To this end, we introduce two distinct network architectures of volumetric CNNs. In addition, we examine multi-view CNNs, where we introduce multi-resolution filtering in 3D. Overall, we are able to outperform current state-of-the-art methods for both volumetric CNNs and multi-view CNNs. We provide extensive experiments designed to evaluate underlying design choices, thus providing a better understanding of the space of methods available for object classification on 3D data.", "text": "extension convolutional neural networks seems natural additional computational complexity data sparsity introduces signiﬁcant challenges; instance image every pixel contains observed information whereas shape deﬁned surface. seminal work propose volumetric architectures volumetric grids object classiﬁcation retrieval. approaches achieve good results turns training multiple views achieves signiﬁcantly higher performance shown augment pre-training imagenet data results indicate existing architectures approaches unable fully exploit power representations. work analyze observations evaluate design choices. moreover show reduce volumetric cnns multi-view cnns efﬁciently augmenting training data introducing architectures finally examine multiview cnns; experiments show able improve upon state improved training data augmentation multi-resolution component. problem statement consider volumetric representations point clouds meshes input object classiﬁcation problem. primarily inspired recent advances real-time scanning technology volumetric data representations. assume input data already pre-segmented bounding boxes. practice bounding boxes extracted using sliding windows object proposals background subtraction. output method category label volumetric data instance. approach provide detailed analysis factors inﬂuence performance volumetric cnns including network architecture volumn resolution. based upon analysis strive improve performance volumetric cnns. propose volumetric network architectures signﬁcantly improve state-of-the-art shape models becoming widely available easier capture making available information crucial progress object classiﬁcation. current state-of-theart methods rely cnns address problem. recently witness types cnns developed cnns based upon volumetric representations versus cnns based upon multi-view representations. empirical results types cnns exhibit large indicating existing volumetric architectures approaches unable fully exploit power representations. paper improve volumetric cnns multi-view cnns according extensive analysis existing approaches. introduce distinct network architectures volumetric cnns. addition examine multi-view cnns introduce multiresolution ﬁltering overall able outperform current state-of-the-art methods volumetric cnns multi-view cnns. provide extensive experiments designed evaluate underlying design choices thus providing better understanding space methods available object classiﬁcation data. understanding environments vital element modern computer vision research paramount relevance many vision systems spanning wide ﬁeld application scenarios self-driving cars autonomous robots. recent advancements real-time slam techniques crowd-sourcing virtual models additionally facilitated availability data. development encouraged lifting deep learning opening opportunities additional information data; e.g. aligning models easier euclidean space. paper speciﬁcally focus object classiﬁcation task data obtained models commodity rgb-d sensors. volumetric cnns shape classiﬁcation. result also closed volumetric cnns multi-view cnns provided input discretized resolution. ﬁrst network introduces auxiliary learning tasks classifying part object help scrutize details objects deeply. second network uses long anisotropic kernels probe long-distance interactions. combining data augmentation multi-orientation pooling observe signiﬁcant performance improvement networks. also conduct extensive experiments study inﬂuence volume resolution sheds light future directions improving volumetric cnns. addition providing extensive experiments model datasets also introduce dataset realworld data constructed using dense reconstruction taken experiments show networks better adapt synthetic data real-world data previous methods. shape descriptors large variety shape descriptors developed computer vision graphics community. instance shapes represented histograms bag-of-feature models constructed surface normals curvatures alternatives include models based distances angles triangle areas tetrahedra volumes local shape diameters measured densely-sampled surface points heat kernel signatures extensions sift surf feature descriptors voxel grids spherical harmonic descriptor light field descriptor popular descriptors. extracts geometric fourier descriptors object silhouettes rendered several different viewpoints directly applied shape classiﬁcation task. contrast recently developed feature learning techniques features handcrafted generalize well across different domains. convolutional neural networks convolutional neural networks successfully used different areas computer vision beyond. particular signiﬁcant progress made context learning features. turns training large image datasets able learn general purpose image descriptors outperform handcrafted features number vision tasks including object detection scene recognition texture recognition classiﬁcation signiﬁcant improvecnns depth data introduction commodity range sensors depth channel became available provide additional information could incorporated common architectures. ﬁrst approach combines convolutional recursive neural networks learning features classifying rgb-d images impressive performance object detection rgb-d images achieved using geocentric embedding depth images encodes height ground angle gravity pixel addition horizontal disparity recently architecture proposed depth data processed separate streams; streams combined late fusion network descriptors operate single rgb-d images thus processing data. lift dshapenets approach categorizing voxel free space surface occluded depending whether front behind visible surface depth map. resulting representation binary voxel grid input ﬁlter banks. method particularly relevant context work ﬁrst apply cnns representation. similar approach voxnet also uses binary voxel grids corresponding architecture. advantage approaches process different sources data including lidar point clouds rgb-d point clouds models; likewise follow direction. alternative direction exploit established architectures; data extracted representation. context deeppano converts shapes panoramic views; i.e. cylinder projection around principle axis. current state-of-the-art uses multiple rendered views trains process views jointly multi-view pre-trained imagenet uses view-point pooling combine streams obtained view. similar idea stereo views proposed earlier figure classiﬁcation accuracy. yellow blue bars performance drop multi-view discretization models rendering. blue green bars volumetric signiﬁcantly worse multi-view even though inputs similar amounts information. indicates network volumetric weaker multiview cnn. representations generic shapes popularly used object classiﬁcation volumetric multi-view volumetric representation encodes shape tensor binary real values. multi-view representation encodes shape collection renderings multiple viewpoints. stored tensors representations easily used train convolutional neural networks i.e. volumetric cnns multi-view cnns. intuitively volumetric representation encode much information multi-view counterpart. however experiments indicate multiview cnns produce superior performance object classiﬁcation. reports classiﬁcation accuracy modelnet dataset state-of-the-art volumetric/multiview architectures. volumetric based voxel occupancy worse multi-view investigate performance order ascertain improve volumetric cnns. seems caused factors input resolution network architecture differences. multi-view downsamples rendered view pixels maintain similar computational cost volumetric uses occupancy grid shown input multi-view captures detail. train models replicating architecture volumetric cnns multi-view cnns. networks trained endto-end fashion. methods trained/tested split fair comparison. reported numbers average instance accuracy. details. however difference input resolution primary reason performance evidenced experiments. compare networks providing data containing similar level detail. feed multi-view renderings occupancy grid using sphere rendering i.e. occupied voxel ball placed center radius equal edge length voxel train multi-view scratch using sphere renderings. accuracy multi-view reported blue. shown even similar level object detail volumetric worse multi-view still signiﬁcant room improve architecture volumetric cnns. discovery motivates efforts improve volumetric cnns. additionally low-frequency information seems quite discriminative object classiﬁcation—it possible achieve accuracy resolution discovery motivates efforts improve multi-view cnns multi-resolution approach. network architecture propose network variations signiﬁcantly improve state-of-the-art cnns volumetric data. ﬁrst network designed mitigate overﬁtting introducing auxiliary training tasks challenging. auxiliary tasks encourage network predict object class labels partial subvolumes. therefore additional annotation efforts needed. second network designed mimic multiview cnns strong shape classiﬁcation. instead using rendering routines computer graphics network projects shape convolving volume anisotropic probing kernel. kernel capable encoding long-range interactions points. image appended classify projection. note training projection module image classiﬁcation module end-to-end. emulation multi-view cnns achieves similar performance them using standard layers cnn. figure auxiliary training subvolume supervision main innovation auxiliary tasks predict class labels focus part object intended drive heavily exploit local discriminative features. mlpconv layer composition three conv layers interleaved relu layers. numbers mlpconv number channels kernel size stride ﬁrst conv layer number channels second third conv layers respectively. kernel size stride second third conv layers example mlpconv composition conv relu conv relu conv relu layers. note dropout layers rate=. fully connected layers. data augmentation compared image datasets currently available shape datasets limited scale variation. fully exploit design networks augment training data different azimuth elevation rotations. allows ﬁrst network cover local regions different orientations second network relate distant points different relative angles. multi-orientation pooling networks sensitive shape orientation i.e. capture different information different orientations. capture holistic sense object orientation pooling stage aggregates information different orientations. observe signiﬁcant overﬁtting train volumetric proposed end-to-end fashion volumetric overﬁts training data incentive continue learning. thus introduce auxiliary tasks closely correlated main task difﬁcult overﬁt learning continues even main task overﬁtted. auxiliary training tasks also predict object labels predictions made solely local subvolume input. without complete knowledge object auxiliary tasks challenging thus better exploit discriminative power local regions. design different classic multitask learning setting hetergenous auxiliary tasks inevitably requires collecting additional annotations layers extension mlpconv proposed input output mlpconv layers tensors. compared standard combination linear convolutional layers pooling layers mlpconv three-layer structure thus universal function approximator enough neurons provided intermediate layers. therefore mlpconv powerful ﬁlter feature extraction local patches enhancing approximation abstract representations. addition mlpconv validated discriminative fewer parameters ordinary convolution pooling fourth layer network branches two. lower branch takes whole object input traditional classiﬁcation. upper branch novel branch auxiliary tasks. slices tensor vectors dimension classiﬁcation task vector. fully connected layer softmax layer appended independently vector construct classiﬁcation losses. simple calculation shows receptive ﬁeld task covering roughly entire volume. success multi-view cnns intriguing. multiview cnns ﬁrst project objects make well-developed image cnns classiﬁcation. inspired success design neural network archiinteraction early feature extraction stage. thus helpful augment training data varying object orientation combining predictions orientation pooling. similar su-mvcnn aggregates information multiple view inputs view-pooling layer follow-on fully connected layers sample input different orientations aggregate multi-orientation volumetric shown training time generate different rotations model changing azimuth elevation angles sampled randomly. volumetric ﬁrstly trained single rotations. decompose network construct multi-orientation version. mo-vcnn’s weights initialized previously trained volumetric cnn’s weights ﬁxed ﬁne-tuning. common practice extract highest level features multiple orientations average/max/concatenate them train linear combined feature special case mo-vcnn. tecture also composed stages. however multi-view cnns external rendering pipelines computer graphics achieve d-to-d projection using network layers manner similar ‘x-ray scanning’. network elongated anisotropic kernel helps capture global structure volume. illustrated neural network modules anisotropic probing module network network module. anisotropic probing module contains three convolutional layers elongated kernels followed nonlinear relu layer. note input output layer tensors. contrast traditional isotropic kernels anisotropic probing module advantage aggregating longrange interactions early feature learning stage fewer parameters. comparison traditional neural networks constructed isotropic kernels introducing long-range interactions early stage achieved large kernels inevitably introduce many parameters. anisotropic probing adapted network address classiﬁcation problem. anistropic probing network capable capturing internal structures objects x-ray like projection mechanism. ability offered standard rendering. combined multi-orientation pooling possible probing mechanism capture structure relationship radon transform. addition architecture scalable higher resolutions since layers viewed convolution involves computation locations cubic resolution maintain quadratic compute. data augmentation multi-orientation networks proposed sensitive model orientation. subvolume supervision method different model orientations deﬁne different local subvolumes; anisotropic probing method voxels height along probing direction figure left volumetric right multi-orientation volumetric takes various orientations input extracts features shared pass pooled feature another network make prediction. multi-view proposed strong alternative volumetric representations. multi-view representation constructed three steps ﬁrst shape rendered multiple images using varying camera extrinsics; image features extracted view; lastly features combined across views pooling layer followed fully connected layers. although multi-view presented produces compelling results able improve performance multi-resolution extension improved data augmentation. introduce multi-resolution ﬁltering capture information multiple scales. perform sphere rendering different volume resolutions. note spheres discretization view-invariant. particular helps regularize potential noise irregularities real-world scanned data enabling robust performance real-world scans. note multiresolution ﬁltering different classical multiresolution approaches since ﬁltering respects distance convenience following discussions deﬁne resolution discretization resolution shape. volume resolution sphere rendering volume also resolution though higher image resolution. datasets modelnet modelnet training testing datasets. modelnet currently contains models categories. modelnet subset including models categories well annotated downloaded web. authors also provide training testing split website training test models. voxnet uses train/test split provided website report average class accuracy test split. dshapenets mvcnn another train/test split comprising ﬁrst shapes category train folder ﬁrst shapes category test folder respectively. real-world reconstructions provide realworld scanning dataset benchmark comprising objects categories; geometry captured asus xtion dense reconstruction obtained using publicly-available voxelhashing framework scan performed coarse manual segmentation object interest. addition scan aligned world-up vector. existing datasets captured commodity range sensors e.g. ﬁrst containing hundreds annotated models dense reconstructions. goal dataset provide example modern real-time reconstructions; i.e. structured representations complete single rgb-d frame still many occlusions. dataset used test set. volumetric cnns summarizes performance volumetric cnns. ours-mo-subvolumesup subvolume supervision network ours-moaniprobing anistropic probing network data augmentation applied described clarity modenote networks trained additional multi-orientation pooling step reference multi-view performance seen proposed volumetric cnns signiﬁcantly outperform state-of-the-art volumetric cnns. moreover match performance multiview resolution. volumetric cnns multi-view cnns closed resolution modelnet dataset issue motivates study multi-view cnns summarizes performance multi-view cnns. ours-mvcnn-multires result training concatenation features ours-mvcnn-sphere- ours-mvcnn. hogpyramid-lfd result training concatenation features three resolutions. simply refers extracting features renderings. ours-mvcnn-multires achieves state-of-the-art. figure sphere rendering resolution standard rendering. bottom performance image-based volumetric increasing resolution. rightmost points trained/tested standard rendering. study effect resolution types networks. shows performance volumetric multi-view different resolutions computational cost test volumetric resolutions observations ﬁrst performance volumetric multi-view tested resolutions; second performance multiview increases resolution grows improve performance volumetric experiment suggests worth exploring scale volumetric higher resolutions. evaluations data augmentation multi-orientation pooling volumetric model end-to-end learning verion dshapenets train test three variations augmented data similar trend observed volumetric variations. table effects data augmentations multi-orientation volumetric cnn. report numbers classiﬁcation accuracy modelnet without multiorientation pooling described combined multi-orientation pooling applying azimuth rotation elevation rotation augmentations extremely effective. using azimuth augmentation orientation pooling classiﬁcation performance increased combined elevatable comparison performance volumetric architectures. numbers reported classiﬁcation accuracy modelnet. results voxnet obtained ourselves. experiments using azimuth elevation augmented data. comparison volumetric architectures architectures comparison include voxnet implemented caffe ourselves) d-nin designed without prediction partial object branch) subvolumesup aniprobing data augmentation az+el applied. table ﬁrst volumetric cnns propose subvolumesup aniprobing networks show superior performance indicating effectiveness design; second multi-orientation pooling increases performance network variations. especially signiﬁcant anisotropic probing network since orientation usually carries partial information object. comparison multi-view methods compare different methods based multi-view representations table methods second group trained full modelnet train set. methods ﬁrst group su-mvcnn trained subset evaluation real-world reconstruction dataset assess performance volumetric cnns multi-view cnns real-world reconstructions table methods trained models modelnet tested real data highly partial noisy oversmoothed networks continue outperform state-of-the-art results. particular multiresolution ﬁltering quite effective real-world data possibly resolution component ﬁlters spurious noisy micro-structures. example results object retrieval found supplementary. paper addressed task object classiﬁcation data using volumetric cnns multi-view cnns. analyzed performance volumetric cnns multi-view cnns perspectives network architecture resolution. analysis motivates propose architectures volumetric cnns outperform state-of-the-art volumetric cnns achieving comparable performance multi-view cnns resolution evalution inﬂuence resolution indicates resolution likely bottleneck performance volumetric cnns. therefore worth exploring design efﬁcient volumetric architectures scale higher resolutions. acknowledgement. authors gratefully acknowledge support stanford graduate fellowship grants iis- dms- muri grant n--- google focused research award planck center visual computing communications hardware donations nvidia.", "year": 2016}