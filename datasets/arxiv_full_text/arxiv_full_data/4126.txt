{"title": "Building a Large Scale Dataset for Image Emotion Recognition: The Fine  Print and The Benchmark", "tag": ["cs.AI", "cs.CV"], "abstract": "Psychological research results have confirmed that people can have different emotional reactions to different visual stimuli. Several papers have been published on the problem of visual emotion analysis. In particular, attempts have been made to analyze and predict people's emotional reaction towards images. To this end, different kinds of hand-tuned features are proposed. The results reported on several carefully selected and labeled small image data sets have confirmed the promise of such features. While the recent successes of many computer vision related tasks are due to the adoption of Convolutional Neural Networks (CNNs), visual emotion analysis has not achieved the same level of success. This may be primarily due to the unavailability of confidently labeled and relatively large image data sets for visual emotion analysis. In this work, we introduce a new data set, which started from 3+ million weakly labeled images of different emotions and ended up 30 times as large as the current largest publicly available visual emotion data set. We hope that this data set encourages further research on visual emotion analysis. We also perform extensive benchmarking analyses on this large data set using the state of the art methods including CNNs.", "text": "increasing popularity social networks attracts people publish multimedia content online social network platforms. online users easily textual data e.g. title descriptions tags uploaded images videos. however textual information help retrieval multimedia content cognitive level i.e. semantic level. meta text data limited help bridging affective semantic images pixels human feelings. authors call visual emotion prediction affective content analysis. theory different groups manually crafted features designed study emotional reactions towards visual content. example based theory machajdik hanbury deﬁned eight different kinds pixel level features empirically proved related emotional reactions. another recent work principles-or-art based features extracted classify emotions. following works study eight emotions amusement contentment excitement anger disgust fear psychological research results conﬁrmed people different emotional reactions different visual stimuli. several papers published problem visual emotion analysis. particular attempts made analyze predict people’s emotional reaction towards images. different kinds hand-tuned features proposed. results reported several carefully selected labeled small image data sets conﬁrmed promise features. recent successes many computer vision related tasks adoption convolutional neural networks visual emotion analysis achieved level success. primarily unavailability conﬁdently labeled relatively large image data sets visual emotion analysis. work introduce data started million weakly labeled images different emotions ended times large current largest publicly available visual emotion data set. hope data encourages research visual emotion analysis. also perform extensive benchmarking analyses large data using state methods including cnns. psychological studies provided evidence human emotions aroused visual content e.g. images based ﬁndings recently computer scientists also started delve research topic. however differently psychological studies mainly focus studying changes physiological psychological activities human beings visual stimuli works computer science trying predict aroused human emotion given particular piece visual content. indeed affective computing aims recognize interpret process human affects achieved signiﬁcant progress recent years. however problem visual emotion prediction difﬁcult trying predict emotional reactions given copyright association advancement artiﬁcial intelligence rights reserved. sadness. figure shows example images studied emotions. images selected newly constructed data work image labeled amazon mechanical turk workers. recently deep learning enabled robust accurate feature learning turn produces state-of-theart performance many computer vision related tasks e.g. digit recognition image classiﬁcation aesthetics estimation scene recognition main factors prompt success deep learning problems availability large scale data set. imagenet dataset recent places database availability data sets signiﬁcantly promoted development algorithms research areas. visual emotion analysis large data strong labels. recently employed cnns address visual sentiment analysis tries bridge high-level abstract sentiments concept image pixels. employed weakly label images train model. however trying solve binary classiﬁcation problem instead multi-class problem studied work. work interested investigating possibility solving challenging visual emotion analysis problem. first build large scale emotion data set. data intend whether applying cnns visual emotion analysis provides advantages using predeﬁned collection psychology theory inspired visual features visual attributes done prior works. make following contributions work. collect large number weakly labeled emotion related images. next employ amazon mechanical turk manually label images obtain relatively strongly labeled image data makes usage visual emotion analysis possible. data released research community upon publishing work. evaluate performance convolutional neural networks visual emotion analysis establish baseline future research. compared stateof-the-art manually crafted visual features results suggest using achieve signiﬁcant performance improvement visual emotion analysis. work mostly related visual emotion analysis convolutional neural networks recently deep learning achieved massive success wide range artiﬁcial intelligence tasks. particular deep convolutional neural networks widely employed solve traditional computer vision related problems. deep convolutional neural networks typically consist several convolutional layers several fully connected layers. convolutional layers also pooling layers normalization layers. early studies cnns successful document recognition inputs relatively small images. thanks increasing computational power possible train deep convolutional neural network large collections images solve computer vision problems scene parsing feature learning visual recognition image classiﬁcation however best knowledge related works using cnns visual emotion analysis. currently works visual emotion analysis classiﬁed either dimensional approach categorical approach former represents emotion continuous dimensional space later model emotion distinct class. focus categorical approach studied several previous works. extract color features images. additional social relationships build factor graph model prediction emotions. inspired psychology theory machajdik hanbury proposed richer hand-tuned features including color texture composition content features. furthermore exploring principles zhao deﬁned robust invariant visual features balance variety gradation. features achieved best reported performance several publicly accessible emotion data sets. hand-tuned visual features validated several publicly available small data sets however want verify whether deep learning could applied challenging problem importantly much larger scale image set. main issue available well labeled data sets training deep neural networks. work intends provide data research community verify performance widely used deep convolutional neural architecture emotion data set. several small data sets used visual emotion analysis including iapssubset data subset international affective picture system data categorized eight emotional categories shown figure study conducted artphoto machajdik hanbury built data contains photos professional artists. obtain ground truth labels provided owner image. abstract paintings images consisting color texture obtain ground truth image asking people vote emotions image given eight emotion categories. table shows statistics existing three data sets. numbers show data consists small number images. meanwhile images three different data sets highly imbalanced. three data sets relatively small images coming speciﬁc domains. particular categories anger less images. therefore employ methodology several images training data. lead possibility trained models either ﬁtted. results suggest previous efforts visual emotion analysis deal small emotion-centric data sets compared vision data sets imagenet places work present emotion data largest available emotion-centric database. building image emotion dataset wild many different emotion deﬁnition systems psychological cognitive science. work eight emotions deﬁned table derived psychological study using similar approach query image search engines using eight emotions keywords. able collect total million weakly labeled images i.e. labeled queries. next delete images tags different emotions. also remove duplicate images using fdupes. figure shows statistics remaining images. number images different categories imbalanced. particular small numbers contentment disgust images social media platforms. meanwhile number category images instagram varies signiﬁcantly. much images fear sadness. agrees ﬁnding people likely share sadness instagram accounts. next employ amazon mechanical turk label weakly labeled images. particular design qualiﬁcation test ﬁlter workers want work tasks. qualiﬁcation test designed image annotation problem. randomly select images publicly available artphoto data groundtruth labels answers. given image workers choose emotion feel eight emotion categories. ﬁrst conduct experiments within members research group. indeed results suggest qualiﬁcation challenging difﬁcult particular choose emotion image. therefore design tasks much easier veriﬁcation task instead annotation task. since crawled images emotion queries weakly labeled data set. assign workers verify emotion image. given image weak label answer question like feel anger seeing image? workers asked choose image. workers meet rigorous requirement correctly answering least half questions qualiﬁcation test. time ﬁnishing work workers qualiﬁcation task. among them workers meet qualiﬁcation criteria. start veriﬁcation task randomly select images emotion category. collecting batch results keep images receive least three yeses assigned ﬁver workers. able build relatively strongly labeled data visual emotion analysis. table summarizes number images current data set. numbers show different categories different acceptance rates workers reject accept positive samples veriﬁcation task. particular another images make sure number images fear category also larger images. total collect images times large convolutional neural networks proven effective image classiﬁcation tasks e.g. achieving state-of-the-art performance imagenet challenge meanwhile also successful applications ﬁne-tuning pre-trained imagenet model including recognizing image style semantic segmentation work employ strategy ﬁne-tune pre-trained imagenet reference network neural network architecture employed. change last layer neural network remain layers keep imagenet reference network. randomly split collected samples training testing validating sets meanwhile also employ weak labels ﬁne-tune another model described exclude images chosen submitted labeling. next since contentment contains images randomly select images emotion categories. total images. call model noisyfine-tuned cnn. ﬁne-tune models using caffe linux server nvidia titan gpus pre-trained imagenet model. performance convolutional neural networks visual emotion analysis ﬁne-tuning pre-trained model obtain models. compare imagenetcnn also show results using trained features extracted second last layer pre-trained imagenet-cnn model. particular employ reduce dimensionality features. also several different numbers principal components. results almost same. overcome imbalance problem data adjust weights different classes table summarizes performance three groups features randomly chosen testing data. overall accuracy finetuned-cnn almost baseline visual features extracted imagenet-cnn lead overall accuracy half fine-tuned-cnn. noisy-fine-tuned-cnn model overall accuracy suggests model learn knowledge noisily labeled images. however even though much training samples compared fine-tuned fails outperform fine-tuned trained strongly labeled samples. also calculate confusion matrix three algorithms prediction results testing data analyze performance. figure shows confusion matrix fine-tuned model. compared models true negative rates finetuned-cnn best emotion categories. meanwhile confusion matrix noisy-fine-tuned seems balanced except contentment emotion indeed ﬁndings consistent number available labeled samples labeled images higher probability corresponding emotion receive higher true positive rate. figure shows confusion matrix using general imagenet-cnn features. interesting overall performance worse fine-tuned features. however true positive rate fear higher using fine-tuned features. embedding testing images using deep visual features shown figure features also processed using t-sne embedding using imagenetcnn shows images scene similar objects embedded neighboring areas. however embedding using figure seems make images diverse terms objects scenes. indeed comply fact even object could lead different visual emotion different state e.g. angry cute dog. performance convolutional neural networks public existing visual emotion data described several existing data sets section table summarizes statistics three data sets. best knowledge related studies conducted evaluating performance convolutional neural networks visual emotion analysis. section particular extract deep visual features images three data sets using trained deep neural network models second last layer. obtain dimensional feature representation image deep model. next follow evaluation routine described ﬁrst employed reduce dimensions features respectively. three data sets reduce number feature dimensions capable keeping least variance. next linear trained reduced feature space. following experimental approach v.s. strategy employed train classiﬁer. particular randomly split data batches -fold cross validation used obtain results. also assign larger penalties true negative samples training stage order optimize class true positive rate suggested compare performance deep features visual emotion analysis several baseline features including wang yanulevskaya machajdik hanbury zhao figures show performance features three data sets respectively. note since emotion anger contains images iaps-subset abstract paintings data sets enough perform -fold cross validafigure per-class true positive rates machajdik yanulevskaya wang zhao imagenet-cnn noisy-fine-tunedcnn fine-tuned-cnn abstract paintings data set. interesting deep visual features signiﬁcantly outperform state-of-the-art manually crafted visual features emotion categories. however performance using deep visual features consistent across emotion categories present. particular performance directly employing deep visual features imagenet-cnn noisy-fine-tuned-cnn differ signiﬁcantly among categories well across data sets. performance deep visual features fine-tuned-cnn relatively consistent. however poor performance emotions contentment fear artphoto data. results suggest still challenging solve visual emotion analysis even state-of-the-art deep visual features. meanwhile performance deep visual features also suggests promise using cnns visual emotion analysis. overall encourage development advanced deep architectures visual emotion analysis well development approaches. work introduce challenging problem visual emotion analysis. unavailability large scale well labeled data little research work published studying impact convolutional neural networks visual emotion analysis. work introducing data intend release data research community promote research visual emotion analysis deep learning learning frameworks. meanwhile also evaluate deep visual features extracted differently trained neural network models. experimental results suggest deep convolutional neural network features outperform state-of-theart hand-tuned features visual emotion analysis. addition ﬁne-tuned neural network emotion related data sets improve performance deep neural network. nevertheless results obtained work start research employing deep learning learning frameworks visual emotion analysis. continue collection labeled data plan submit additional million images labeling. hope visual emotion analysis results encourage further research online user generated multimedia content wild. better understanding relationship emotion arousals visual stimuli extending understanding valence primary future directions visual emotion analysis.", "year": 2016}