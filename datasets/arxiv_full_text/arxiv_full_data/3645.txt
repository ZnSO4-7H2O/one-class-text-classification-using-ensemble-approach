{"title": "Introduction to Formal Concept Analysis and Its Applications in  Information Retrieval and Related Fields", "tag": ["cs.IR", "cs.AI", "cs.CL", "cs.DM", "stat.ML", "68P20, 06B99, 68T30", "H.3.3; G.2; I.2"], "abstract": "This paper is a tutorial on Formal Concept Analysis (FCA) and its applications. FCA is an applied branch of Lattice Theory, a mathematical discipline which enables formalisation of concepts as basic units of human thinking and analysing data in the object-attribute form. Originated in early 80s, during the last three decades, it became a popular human-centred tool for knowledge representation and data analysis with numerous applications. Since the tutorial was specially prepared for RuSSIR 2014, the covered FCA topics include Information Retrieval with a focus on visualisation aspects, Machine Learning, Data Mining and Knowledge Discovery, Text Mining and several others.", "text": "abstract. paper tutorial formal concept analysis applications. applied branch lattice theory mathematical discipline enables formalisation concepts basic units human thinking analysing data object-attribute form. originated early last three decades became popular human-centred tool knowledge representation data analysis numerous applications. since tutorial specially prepared russir covered topics include information retrieval focus visualisation aspects machine learning data mining knowledge discovery text mining several others. keywords formal concept analysis concept lattices information retrieval machine learning data mining knowledge discovery text mining biclustering multimodal clustering according information retrieval ﬁnding material unstructured nature satisﬁes information need within large collections past specialized professions librarians retrieve information regular basis. days massive amounts information available internet hundreds millions people make information retrieval systems email search engines daily basis. formal concept analysis introduced early rudolf wille mathematical theory became popular technique within ﬁeld. concerned formalisation concepts conceptual thinking applied many disciplines software engineering machine learning knowledge discovery ontology construction last years. informally studies objects hierarchically grouped together common attributes. several related ﬁelds objects scientiﬁc papers attributes relevant terms available title keywords abstract papers. example visualisation figure papers published developed toolset central component used index papers thesaurus containing terms related research generate lattices. tutorial also contains partial overview papers using information retrieval focus visualisation. support activities including limited query analysis document representation text classiﬁcation clustering social network mining access semantic data ontology engineering? since tutorial preparations guided idea present content solid comprehensible level accessible even newcomers balanced combination theoretical foundations practice relevant applications. thus provide intro practice main tools discuss machine learning data mining information retrieval text mining ontology modeling selected applications. many used examples real-life studies conducted course author. target audience computer science mathematics linguistics students young scientists university teachers researchers want models tools data analysis tasks. course features parts. part placed separate section contains short highlight list ease navigation within material. archive supplementary ﬁles exercises examples available section contains introduction related notions lattice order theory. section describe selected tools provide exercises. section provides overview fca-based methods applications data mining machine learning describes fca-based tool supervised learning quda section presents relevant part course information retrieval text mining. penultimate section discusses ontology modeling gives example fca-based attribute exploration technique building taxonomy transportation means. section concludes paper brieﬂy outlines prospects limitations fca-based models techniques. even though many disciplines dated back aristotles time closer prolegomena found example logic port royal philosophical concept logic concept treated pair extent intent section mainly reproduce basic deﬁnitions ganter&wille’s book formal concept analysis however good introductory material focused partial orders lattices book davey priestly ir-oriented reader also following books interesting helpful binary relations partial orders lattices line diagram. galois connection formal context formal concept concept lattice. concept lattice drawing. algorithms concept lattices generation write read less equal partially ordered pair partial order deﬁnition given poset element called lower neighbour fulﬁlling case also upper neighbour write http//www.kbs.uni-hannover.de/~jaeschke/teaching/w/fca/ http//www.upriss.org.uk/fca/fcaintro.html http//ddll.inf.tu-dresden.de/web/introduction_to_formal_concept_ deﬁnition says every formal concept parts namely extent intent. follows tradition logic port royal line international standard formulates following deﬁnition concept considered unit thought constituted parts extent intent. deﬁnition formal concepts context together order relation forms complete lattice called concept lattice denoted basic theorem formal concept analysis deﬁnes supremum inﬁmum arbitrary sets concepts; also answer question whether concept lattices special properties. fact answer since every concept lattice complete lattice. compose formal context objects attributes binary relation obtain whole concepts particular context simply deﬁnition i.e. enough enumerate subsets objects apply derivation operators them. example context example empty objects obtain applying second time thus resulting concept proposition every formal concept context form subset form subset vice since total number formal concept equal worst case na¨ıve approach quite ineﬃcient even small contexts. however assume know concepts going build line diagram concept lattice. na¨ıve concept generation algorithm eﬃcient since enumerates subsets homogeneity follows reproduce pseudocodes algorithms diﬀerent algorithms compute closures subsets eﬃcient test check whether assume linear order algorithm starts examining consisting object maximal respect ﬁnishes canonically generated closure equal currently examined subset generation considered canonical contain max. generation canonical equal next examined obtained follows less note nextclosure algorithm computes concepts diﬀerent lectic order lectically less min\\ order concepts generated beneﬁcial line diagram constructed ﬁrst generation concept always canonical makes possible concept tree draw appropriate diagram edges. nextclosure-like lectic order allows binary search helpful diagram graph generated generation concepts. generation protocol tree-like form given fig. closed objects read tree following path root corresponding node. square bracket means ﬁrst prime operator applied addition lectically next object parent node bracket shows object added application second prime operator i.e. nominal scale deﬁned context type scaling suitable binary representation nominal attributes like color. context university subjects subjects scaled nominal scaling below. particular case nominal scaling called dichotomic scaling suitable attributes mutually exclusive values like example attribute gender scaled way. domains e.g. psychology sociology similar biordinal scaling good representation attributes called polarvalues agree rather agree disagree rather disagree. implication holds note brevity omitted curly brackets around commas elements attributes. exercise find three implications context geometric ﬁgures. since always true second rule applying property proposition have since prove implies exercise prove applying armstrong rules imply check third axiom using implication deﬁnition. exercise write duquenne-guigues base context geometric ﬁgures. using armstrong rules obtained duquenne-guigues base deduce rest implications original context. implications functional dependencies data dependencies reach primary purposes databases attenuate data redundancy enhance data reliability dependencies mainly used data normalisation i.e. proper decomposition interrelated tables deﬁnition functional dependency terms follows ﬁrst functional dependencies sense since students year study subjects. however last says gender functionally dependent mark looks pure coincidence small dataset. concept explorer. conexp probably user-friendly fcabased tools basic functionality; developed java yevtushenko prof. taran supervision beginning later improved several times especially lattice drawing viewpoint important note resulting diagram static perform exploratory analysis interactive manner selecting interesting nodes moving etc. fig. line diagram concept lattice interordinal scale attribute mark drawn conexp shown. details fig. toscanaj. toscanaj project result collaboration groups technical university darmstadt university queensland declared give community platform work with creation professional tool coming research environment still supporting research open project long history several prototypes part umbrella framework conceptual knowledge processing tockit. result developed java supports diﬀerent types database connection jdbc-odbc bridge contains embedded database engine apart conexp features work multi-valued contexts conceptual scaling nested line diagrams. fig. nested line diagram scales university subjects multi-valued context namely attributes gender subject. printing facilities possible print line diagrams vector graphic form. galicia. galicia intended integrated software platform including components operations lattices might required practical applications theoretically-oriented studies. thus addition basic functionality conexp features work multi-valued contexts conceptual scaling iceberg lattices galois hierarchies relational context families popular software engineering software open implementation java cross-platform aimed adaptability extensibility reusability. possible navigate lattice diagrams interactive manner; resulting diagrams contain numbered nodes diﬀerent traditional line diagrams drawing. another galicia’s unique feature lattice drawing. diagram university subjects context nominal scaling attributes obtained galicia depicted fig. galicia supports vector-based graphic formats pdf. authors program paid substantial attention algorithmic aspects incorporated batch incremental algorithms various bases implications association rules generated tool. nested line diagrams list. initial objective tool focus visualization mechanisms representation concept lattices including nested line diagrams thus interesting feature multi-level nested line diagrams help explore comparatively large lattices. decade development fca-based software diﬀerent features produced diﬀerent formats thus requiring interoperability. analogy rosetta stone fcastone proposed. supports convertation commonly used formats comma separated value ﬁles well convertation concept lattices graph formats vector graphics formats also incorporated webpage script generating lattices line diagrams online. another example web-based ported system basic functionality including attribute exploration openfca. fcart. many diﬀerent tools created projects developing anymore software still available; interested reader refer priss’s webpage dozens tools. however challenges handling large heterogeneous datasets coming community eﬀorts inspired successful application fca-based technologies text mining criminology domain laboratory intelligent systems structural analysis tool named formal concept analysis research toolbox developing. three-level extendability settings customisation data access components query builders solvers visualizers; writing scripts macros; developing components originally another fca-based integrated environment knowledge data engineers research tools based formal concept analysis featuring addition work unstructured data pattern structures current distributed version fcart consists following parts authserver authentication authorisation. intermediate data storage storage preprocessing datasets. thick client interactive data processing visualisation integrated workﬂow shown fig. main questions following whether product technological advantages really fruitful methodology? become open addition extendability? ﬁnally handle volumes heterogeneous data suitable fcart analyst? answers posed questions seem forthcoming challenging steps. cryptolatt. tool developed help students researchers neighbouring domains recognise cryptomorphisms latticebased problems i.e. realise particular problem domain isomorphic terms lattice theory thus well-known cryptomorphisms community established lattice binary relation also known basic theorem fca. note even particular formal context concept lattice implications represent information underlying dataset diﬀerent way. exercise practice concept explorer input context geometric ﬁgures build concept lattice diagram duquenne-guigues base. check whether obtained base coincide base found before. play diﬀerent layouts drawing options like labeling node size. find real datasets objects described nominal attributes select objects attributes prepare corresponding context build lattice diagram implication base. interpret found concepts dependencies. exercise practice toscanaj elba tool latest version toscanaj creating scaled contexts attributes context university subjects. save contexts. upload toscanaj draw nested line diagram. result similar fig. pattern structures data complex descriptions fca-based boolean matrix factorisation educational data mining case study exercises jsm-method quda solving knowledge discovery databases introduced non-trivial extraction valid implicit potentially useful ultimately understandable information large databases data mining main step turn association rules frequent itemset mining among techniques data mining. original problem association rules mining market basket analysis. early since current level technologies made possible store large amount transactions purchased items companies started attempts data facilitate typical business decisions concerning what sale design coupons place merchandise shelves order maximize proﬁt. ﬁrstly market basket analysis problem formalised task ﬁnding frequently bought items together form rules customer buys items also buys items ﬁrst rather eﬃcient algorithms period proposed namely apriori. beginning rules tolerant number exceptions strict implications fca. however several years before michael luxenburger introduced partial implications motivated general problem statement generalisation theory implications attributes partial implications since data analysis user interested implications also implications exceptions. author proposed theoretical treatment problem terms formal concept analysis guided idea characterisation sets partial implications arise real data possibility exploration partial implications computer. addition proposed minimal base partial implications known luxenburger’s base association rules well. main task association rules mining formulated follows find association rules context support conﬁdence rules greater predeﬁned thresholds min-conﬁdence min-support denoted conf supp respectively apriori algorithm ﬁnds frequent itemsets. check iteratively itemsets levelwise manner. iteration level considered i.e. subset candidate itemsets composed collecting frequent itemsets discovered previous iteration supports candidate itemsets counted infrequent ones discarded. condensed representation frequent itemsets according basic results formal concept analysis necessary count support frequent itemsets. thus possible derive known supports supports itemsets enough know support frequent concept intents. also necessary compute frequent itemsets solving association rule problem suﬃcient consider frequent concept intents also called closed itemsets data mining. fact closed itemsets independently discovered three groups researches late proposition formal context maximal frequent itemset frequent closed itemsets frequent itemsets minimal support supp. proposition concept lattice formal context lattice frequent closed itemsets supp frequent concepts context threshold also known iceberg concept lattice mathematically corresponds order ﬁlter concept lattice. however idea usage size concept’s extent intent concept quality measure course application domain restricted market basket analysis; thus line diagram built conexp shows largest concepts visitors website terms news websites real datasets association rules mining usually results large number rules. however rules necessary present information. similar compact representation used here; thus represent valid association rules subsets called bases. example luxenburger base association rules form exercise find luxenburger base customers context conf check whether concept explorer generates association rule base consists duquenne-guigues base luxenburger base. ﬁrst algorithms explicitly designed compute frequent closed itemsets close inspired apriori traverses database level-wise manner generates requent closed itemsets computing closures minimal generators. detailed survey multimodal clustering clustering activity ﬁnding homogeneous groups instances data. machine learning clustering part called unsupervised learning. widely adopted idea cluster relates instances feature space. cluster space subset data instances relatively close relatively data points. feature space clustering algorithms popular tool marketing research bioinformatics ﬁnance image analysis mining etc. growing popularity recent data sources example gene expression matrices entries show expression levels gene material captured polymerase reaction. another example would n-ary relations among several sets entities two-mode case cluster approaches demonstrates growing popularity. thus notion bicluster data matrix represents relation itemsets. rather single subset entities bicluster features subsets diﬀerent entities. general larger values submatrix higher interconnection subsets relevant corresponding bicluster. relational data presence-absence facts represented binary values condition expresses proportion unities submatrix density larger better. interesting bicluster density formal concept constituent subsets cannot increased without drop density value i.e. maximal rectangle input matrix w.r.t. permutations rows columns usually related sets entities objects attributes. contrary ordinary clustering bicluster captures similarity objects expressed terms common attributes usually embrace subset whole attribute space. obviously biclusters form homogeneous chunks data learning organized within them. biclustering techniques machinery developed independently independent communities using diﬀerent mathematical frameworks. speciﬁcally mainstream formal concept analysis based ordered structures whereas biclustering relies conventional optimisation approaches probabilistic matrix algebra frameworks however fact diﬀerent frameworks considerably overlap applications example ﬁnding co-regulated genes gene expression data prediction biological activity chemical compounds text summarisation classiﬁcation structuring websearch results browsing navigation information retrieval ﬁnding communities two-mode networks social network analysis recommender systems certain context general regions full non-empty pairs i.e. maximal density since object attribute formal concepts respectively. several black cells indicate non-empty pairs found bicluster. quite clear density parameter would bicluster quality measure shows many non-empty pairs bicluster contains. however constraint ρmin useful properties. means consider oa-biclusters context ρmin every formal concept contained oa-bicluster context i.e. following proposition holds. proposition exists oa-bicluster proposition given formal context ρmin largest number oa-biclusters equal oa-biclusters generated time proposition given formal context ρmin largest number oa-biclusters equal oa-biclusters generated time algorithm oa-bicluster computation input formal context ρmin threshold density value bicluster output bicluster} ρmin else b.removeduplicates return algorithm rather straightforward implementation deﬁnition takes initial formal context minimal density threshold parameters computes biclusters pair relation however latest implementations eﬀectively hashing duplicates elimination. experiments advertising data algorithm produces times less patterns number formal concepts. general worst case therefore useful extend biclustering formal concept analysis process relations among datasets. attempts direction published literature. example zaki proposed tricluster algorithm mining biclusters extended time dimension real-valued gene expression data. triclustering method designed mine gene expression data using black-box functions parameters coming domain. formal concept analysis framework theoretic papers introduced so-called triadic formal concept analysis. triadic formal concepts apply analyse small datasets psychological domain. paper proposed rather scalable method trias mining frequent triconcepts folksonomies. simultaneously less eﬃcient method mining closed cubes ternary relations proposed several recent eﬃcient algorithms mining closed ternary sets even general algorithms trias. thus data-peeler able mine n-ary formal concepts descendant mines fault-tolerant n-sets latter compared algorithm fault-tolerant n-sets mining paper generalises n-ary relation mining multi-relational setting databases using notion algebraic closure. guided idea ﬁnding scalable noise-tolerant triconcepts look triclustering paradigm general triadic binary data i.e. tricontexts input datasets. collection triclusters given tricontext denoted since deal possible cuboids cartesian product evident number oac-triclusters equal |g|·|m|·|b|. however supposed dense especially real data frequently quite sparse. thus proposed possible oac-tricluster deﬁnitions give eﬃcient within polynomial time compared triclustering techniques proposed within formal concept analysis and/or bicluster analysis perspectives oac-box tribox spectric recent oac-prime algorithm. novel algorithm oac-prime overcomes computational substantive drawbacks earlier formal-concept-like algorithms. spectral approach rely extension well-known reformulation bipartite graph partitioning problem spectral partitioning graph comparison purposes proposed developments following components experiment setting result deﬁned absolute winning methods multicriteria choice allows expert decide criteria important speciﬁc case make choice. thus experiments show tribox oac-prime algorithms reasonable alternatives triadic formal concepts lead pareto-eﬀective solutions. fact tribox better respect noise-tolerance number clusters oac-prime best scalability large real-world datasets. paper eﬃcient version online oac-prime proposed. experiments used context popular movies www.imdb.com objects movie titles attributes tags whereas conditions genres. prime oac-triclustering showed rather good results fastest algorithm comparison. {the shawshank redemption cool hand luke amerihistory clockwork orange green mile {prison murder friend shawshank banker} {crime drama} {the godfather part usual suspects {cuba york business {crime drama thriller} {toy story story {jealousy spaceman little fight} {fantasy comedy animation family adventure} matter fact formal concept analysis helped algebraically rethink several models methods machine learning version spaces learning positive negative examples decision trees also shown concept lattice perfect search space learning globally optimal decision trees already early supervised unsupervised machine learning techniques applications based formal concept analysis introduced machine learning community. e.g. ml-related venues reported results concept lattice based clustering galois system suited information retrieval browsing performed comparison seven fca-based classiﬁcation algorithms. propose independently design neural network architecture. used data preprocessing technique transform attribute space improve results decision tree induction. note helps perform feature selection conceptual scaling quite evident relations rough sets theory popular tool feature selection classiﬁcation proposed navigala navigation-based approach supervised classiﬁcation applied noisy symbol recognition. lattice-based approaches also successfully used classiﬁcation data complex descriptions graphs trees moreover suggested alternative learning framework. jsm-method hypothesis generation jsm-method proposed viktor finn late proposed attempt describe induction purely deductive form thus give least partial justiﬁcation induction method named respect english philosopher john stuart mill proposed several schemes inductive reasoning century. example method agreement formulated follows instances phenomenon investigation circumstance common cause given phenomenon. russir audience example jsm-method application paleography might especially interesting used dating birch-bark documents centuries novgorod republic. types attributes individual letter features features common several letters handwriting language features style three subcontexts ﬁrst used training sample respective derivation operators deﬁnition positive hypothesis intent contained intent negative example detailed retrospective survey jsm-method applications found extension jsm-method triadic data target attribute fca-based formulation found there triadic extension jsm-method used cbo-like algorithm classiﬁcation bibsonomy data. problems kind would mention structure-activity relationship problems chemicals given molecular graphs learning semantics graph-based text representations. motivated search possible extensions original machinery analyse data complex structure ganter kuznetsov proposed called pattern structures intervals patterns. obvious similarity operator intervals fulﬁll following condition intervals belong interval contains them. interval minimal contains original taking account constant pressing industry requests data tools several ways ﬁtting context proposed thus pattern structures classiﬁcation setting combination lazy evaluation projection approximations initial data randomisation parallelisation results reduction algorithmic complexity degree polynomial. observations make possible apply pattern structures text mining learning large text collections implementations basic pattern structures algorithms available fcart. exercise compose small program e.g. python enumerates pattern concepts movie recommender example directly deﬁnition adapt end. case possibility perform consider subtable ﬁrst four users ﬁrst four movies movie recommender example. find pattern concepts deﬁnition. build line diagram pattern concept lattice. however pattern structures attempt data complex description boolean one. thus past years research extending theory cope imprecise incomplete information made signiﬁcant progress. underlying model called fuzzy concepts lattice; several deﬁnitions lattice basic assumption usually object posses attributes degree example sociological studies representation requires special care person teenager cannot treated truly adult ﬁrst his/her exceeds threshold years however usually case deal nominal scaling; even ordinal scaling lead information loss chosen granularity level. need ﬂexible measure adult teenage person might degree lying interval attribute. another characterise imprecision roughness done rough sets terms interested reader invited follow survey fuzzy rough correspondence pattern structures fuzzy found matrix factorisation techniques typical inventory machine learning chapter features) data mining chapter dimensionality reduction) information retrieval chapter matrix decompositions latent semantic indexing). thus used dimensionality reduction feature extraction example collaborative ﬁltering recommender techniques considered industry standard among popular types deﬁnitely mention singular value decomposition various modiﬁcations like probabilistic latent semantic analysis svd++ however several existing factorisation techniques example non-negative matrix factorisation boolean matrix factorisation seem less studied context modern data analysis information retrieval. several algorithms ﬁnding calculating formal concepts based theorems thus approximate algorithm avoids computation possible formal concepts therefore works much faster direct approach concepts generation. applications fca-based used feature extraction technique improving results classiﬁcation. another example closely relates thus demonstrated comparable results svd-based collaborative ﬁltering terms precision-recall metrics. extensions triadic n-ary data proposed case study reproduce results paper assuming probable confusion russian educational system must words national research university higher school economics admission process. nowadays acknowledged leading university ﬁeld economics management sociology business informatics public policy political sciences among russian universities. recently number bachelor programmes oﬀered increased. year oﬀered bachelor programmes. consider bachelor programmes investigation. order graduate school enter university college every russian student must pass uniﬁed state exam similar sat–act a-level tests. admission u-hse entrants able send applications three programmes simultaneously. school leavers chose programme chose three. entrants choose programme study among successful applications. used data representing admission consists information entrants. used mainly information programmes entrants apply. exactly entrants successfully applied least programme become students. along data also used data entrants’ survey paper mostly used data applied mathematics informatics programme demonstrate results. total number applications applied mathematics informatics programme successful actually accepted program. might seem confusing eligible prospective students decided enroll since admission process stages stage entrants eligible attend program decided diﬀerent programme university. result number entrants whose applications successful came situation typical bachelor programmes hse. requires object-attribute data. case objects entrants programmes apply attributes. together treated context. series contexts constructed. namely built context every programme objects entrants applying programme attributes programmes applied built separate context every programme meaningless consider programmes programmes diﬀerent size resulting lattice would represent largest them. likewise built context every programme objects entrants attributes programmes entrants successfully applied well programmes entrants decided enroll into including universities. contexts used build concept lattices. since resulting lattices complicated structure interpret ﬁltered concepts extent size thus remaining concepts express common patterns entrants decisions. programmes entrants often apply simultaneously? trying answer question every programme built diagrams similar ﬁgure diagrams help reveal common patterns entrants choices. typical applications imply building formal concept lattices discussed earlier ﬁlter concepts extent size avoid complexity caused noise data. thus order remaining concepts longer lattice partial order. meaning labels diagram obvious. label node programme label node percent entrants applied mathematics informatics programme also applied programmes connected node above. example left bottom node diagram means percent applied math’s entrants also apply mathematics software engineering. look nodes current node notice percent applied mathematics informatics applicants also apply mathematics programme percent also applied software engineering. interpret knowledge unfolded diagram ﬁgure percent entrants applied applied mathematics informatics also apply software engineering. diagram software engineering states percent software engineering applicants also apply applied mathematics informatics. fact explained? firstly easily explained fact programmes require pass exams. therefore additional obstacles apply programmes simultaneously. another possible explanation uneasy entrants distinguish programmes successful application would satisfactory result. entrants’ eﬃcient choice. entrant successfully applied bachelor programme must select programme study. unlike previous case entrants select exactly programme gives precise information entrants preferences. reason deﬁne situation eﬃcient choice eﬃcient sense expressive true entrants preferences. figure presents eﬃcient choice entrants applied mathematics informatics programme. meaning diagram labels almost fig. programmes without plus sign successful applications programmes preceding plus sign programmes chosen study entrants. together diagram fig. diagram provides precise knowledge preferences entrants applied mathematics informatics programme. thirds entrants successfully apply applied math programme nevertheless prefer study another university. whereas percent successful applicants become students applied mathematics informatics programme. exactly percent prefer study software engineering percent entrants choose applied mathematics informatics also successfully applied software engineering. interpreted equality entrants preferences concerning programmes. additionally percent prefer business informatics percent entrants prefer applied mathematics informatics also successfully apply business informatics therefore pair business informatics applied mathematics informatics latter less preferable entrants. built diagrams eﬃcient choice every programme. analysis diagrams helps recognise relations programmes terms entrants preferences. example programmes cases rather backup actual entrants preference. programmes close subject study relations also expressed diagrams. help formalised survey data found possible factors entrants’ choice among particular programmes. knowledge help university quda developed early software environment want learn data mining doing intellectics group darmstadt technical university technology includes various techniques association rule mining decision trees rule-based learning jsm-reasoning bayesian learning interesting subgroup discovery. also provides experimenter error estimation model selection tools well several preprocessing postprocessing utilities including data cleansing tools line diagrams visualisation attribute distributions convenient rule navigator etc. mostly aimed support scientiﬁc teaching activities ﬁeld machine learning data mining. however since quda open architecture support common data formats well predictive model markup language easily integrated working data mining circle. originally acronym qualitative data analysis. since quda ﬁnally includes many quantitative methods integrated weka name backronym since lost original meaning. exercise download quda refer quda’s manual details prepare credit scoring context format opening quda environment. perform nominal scaling attributes apply classiﬁer basic setup. compare obtained rules hypotheses obtained manually. xercise dataset available quda perform nominal scaling comparison jsm-classiﬁcation available methods splitting data training-to-test sample size ration -fold cross-validation. compare learning curves confusion matrices. identify non-covered examples jsm-method. change scaling type attribute number legs. reiterate comparison check methods improved classiﬁcation quality. http//www.dmg.org/ http//www.cs.waikato.ac.nz/ml/weka/ http//en.wikipedia.org/wiki/backronym http//sourceforge.net/projects/quda/; alternative compilation russir lattice-based models mainstream directions modern attracted numerous researchers interpretability human-centerdness intrinsic complexity serious challenge make working scale. thus early works information retrieval known usage lattice search space requires treatment enormous number subsets documents collection million documents time rather natural library classiﬁcation domain consider documents categories form requests combination simple logical operations like thus mooers considered transforperiod soviet russia all-soviet institute scientiﬁc technical information organised facilitate information interchange fulﬁll growing scientiﬁc needs cataloging processing scientiﬁc publications. around yulii shreider leading researchers viniti considered problem automatic classiﬁcation documents retrieval means model featuring triple thus introduced mappings highly resemble conventional prime operators context documents attributes document-term containment relation. middle godin proposed lattice-based retrieval model database browsing objects described associated keywords. resulting lattice used navigation query modiﬁcation using generality/speciﬁcity relation. several fca-based models systems appeared reviews found thus carpineto romano classiﬁed main problems solved means review studies year priss described current state domain year recently survey fca-based systems methods including prospective aﬀordances presented workshop ecir colleagues codocedo napoli taking inspiration summarising latest work topic separate forthcoming survey. text mining scientiﬁc papers survey fca-based applications fca-based meta-search engines fca-based visualisation navigation criminology text mining police reports fca-based approach advertising keywords search fca-based recommender systems triadic ir-tasks folksonomies fca-based approach near-duplicate documents detection exploring taxonomies site users concept-based models crowdsourced platforms recommender system visually represented literature using concept lattices objects scientiﬁc papers attributes relevant terms available title keywords abstract papers. developed tool central component index papers thesaurus containing terms related research generate lattices. helped zoom give extensive overview papers published using information retrieval. developed knowledge browsing environment cordiet support literature analysis process. central components text analysis environment thesaurus containing collection terms describing diﬀerent research topics. initial thesaurus constructed based expert prior knowledge incrementally improved analyzing concept gaps anomalies resulting lattices. layered thesaurus contains multiple abstraction levels. ﬁrst ﬁnest level granularity contains search terms grouped together based semantic meaning form term clusters second level granularity. papers downloaded converted plain text abstract title keywords extracted. open source tool lucene used index extracted parts papers using thesaurus. result cross table describing relationships papers term clusters research topics thesaurus. cross table used basis generate lattices. relevant scientiﬁc sources sources used search primary studies contain work published journals conferences workshops recognized quality within research com-munity. sources ieee computer society digital library sciencedirect springerlink ebscohost google scholar conference repositories icfca iccs conferences. important sources dblp citeseer explicitly included since indexed mentioned sources selected sources used various search terms including formal concept analysis concept lattices information retrieval. identify major categories literature survey also took account number citations papers citeseerx. eﬃcient retrieval relevant information promoted representation makes inherent logical structure information transparent. used multiple purposes first provides elegant language modeling interesting instrument browsing automatic retrieval document collections. second also support query reﬁnement ranking enrichment external resources. document-term lattice structures available information clusters related documents partially ordered lattices used make suggestions query enlargement cases documents retrieved query reﬁnement cases many documents retrieved. third lattices used querying navigation supporting relevance feedback. initial query corresponds start node document-term lattice. users navigate related nodes. further queries used prune document-term lattice help users focus search many purposes extra facilities needed processing large document collections quickly allowing ﬂexible matching operations allowing ranked retrieval give contextual answers user queries. past years many researchers also devoted attention issues. papers information retrieval covered research topics fig. further study intuitively introduced process transforming data repositories browsable representations performing query expansion reﬁnement operations. considered papers using representation navigation image service etc. document collections. deﬁning processing complex queries knowledge representation browsing selected papers used browsing navigation document collections. half papers combination navigation querying based lattices pro-posed. annotation documents ﬁnding optimal document descriptors play important role eﬀective information retrieval fca-based approaches information retrieval browsing large data repositories based underlying model. ﬁrst containing objects pages services images digitally available items. attributes consist terms tags descriptions etc. attributes query result improvement search engines increasingly used amongst others users information need. intent concept corresponds query extent contains search results. query features terms system returns answer evaluating upon evaluating query system places concept becomes current concept example fig. intent current concept extent current concept stands term stands word. since query provided user approximates user’s need many techniques developed expand reﬁne query terms search results. query tuning process searching query best approximates information need user. query reﬁnements help user express original need clearly. query reﬁnement done going lower neighbor current concept lattice adding term query items. minimal conjunctive query reﬁnement user navigate example query enlargement i.e. retrieving additional relevant pages performed navigating upper neighbor current concept lattice removing term query items. user navigate example bination subsequent reﬁne expand operations seen navigation query space. typically navigation querying completely separate processes combination results ﬂexible user-friendly method. topics investigated papers. comprehensive survey query reﬁnement explain concept lattice based ranking proposed compared hierarchical clustering based best-ﬁrst matching rankings. experiments public benchmark collections showed outperformed competitive methods ranked documents match query comparable better rest cases. example fig. provide example concept lattice based ranking previous context papers terms. underlying query conjunction terms browsing fca. query concept follows resulting ranking yields curious reader admit concepts ranks concentric circles around query concept distance. obviously concepts circle need subsequent ranking e.g. best-match ranking product document query proﬁles based term frequency. email retrieval image software knowledge base retrieval deﬁning processing complex queries fca; domain knowledge search results contextual answers ranking. beginning many independent developers proposed called meta-search engines also known search results clustering engines. name project still alive carrots nigma.ru. summarising survey clustered search carpineto used basis many web-based knowledge browsing systems developed past years. especially comprehensible visualisation capabilities seem interest russir audience. results returned search engines given query typically formatted list urls accompanied document title snippet i.e. short summary document. several fca-based systems developed analyzing exploring search results. credo fooca searchsleuth build context individual query contains result query objects terms found title summary result attributes. fooca shows entire formal context user oﬀers great degree ﬂexibility exploring table using ranking attributes selecting number objects attributes applying stemming stop word removal etc. searchsleuth display entire lattice focuses search concept i.e. concept derived query terms. user easily navigate upper lower neighbors siblings. nauer also propose iteratively interactively analyzing search results. user indicate concepts relevant ones retrieval task. based information concept lattice dynamically modiﬁed. research resulted crechaindo system. presented fca-based document navigation system kanavigator small communities specialized domains. relevant documents annotated keywords users. extended search functionality combining lattice-based browsing conceptual scales reduce complexity visualisation. cigarran present jbraindead system combines free-text search organise results query. cole discuss document discovery tool named conceptual email manager based fca. program allows users navigate emails using visual lattice. paper also discusses conceptual ontologies support traditional document retrieval systems knowledge discovery document collections. development software based earlier research retrieval information semi-structured texts building work mail-sleuth software used mine large email archives. eklund displaying searching navigating help content help system. stojanovic presents fca-based method query reﬁnement provides user queries nearby given query. approach query space navigation validated context searching medical abstracts. stojanovic presents smart system navigation online product catalog. products database described elements ontology visualized lattice users navigate general product-attribute cluster containing products speciﬁc clusters seem contain user highly relevant products. spyratos describe approach query tuning integrates navigation querying single process. lattice serves navigation attributes query formulation. grand present method based conjunction semantics provide contextual answers queries. overall lattice built tourism pages. then users formulate query best-matching concepts returned users navigate within lattice generalizing reﬁning query. eklund present annotationsleuth extend standard search browsing interface feature conceptual neighborhood centered formal concept derived curatorial tags museum management system. cigarran focus automatic selection noun phrases documents descriptors build based system. automatic attribute selection important using free text document retrieval framework. optimal attributes document descriptors produce smaller clearer browsable concept lattices better clustering features. recio-garcia perform semantic annotation pages domain ontologies. similarity matching techniques case based reasoning applied retrieve annotated pages cases. optimise personal news search engine help users obtain news content need rapidly. proposed technique combines construction user background using optimisation query keywords based user’s background layout strategy search results based concept tree. lungley implicit user feedback adapting underlying domain model intranet search system. used interactive interface identify query reﬁnement terms help achieve better document descriptions browsable lattices. ahmad build concept lattices descriptions associated images searching retrieving relevant images database. imagesleuth project also used clustering navigation annotated collections images. lattice diagram directly shown user. extent present concept containing thumbnails intent containing image descriptions list upper lower neighbors shown. ducrou author built information space amazon.com online store used discover conceptually similar dvds explore conceptual neighborhood. system called dvdsleuth. amato start initial image given user concept lattice retrieving similar images. attributes lattice facets i.e. image similarity criterion based e.g. texture color shape. values context indicate facet similar image database respect user provided initial image. querying user jump cluster lattice specifying criteria sought cluster must satisfy. navigation cluster user move neighbor cluster thus exploiting ordering amongst clusters. ferre proposed called logical information systems navigation photo collections. fact similarly pattern structures exploit partially ordered object descriptions expressed logical formulas. uses lattice-based navigation queriying formulas overcomes current drawbacks tree-like navigation imposed current restrictions ﬁle-systems. recently previous studies eklund organising navigation annotated collections images virtual museums resulted ipad application allows users explore collection semantically linked pathways generated using formal concept analysis. fact navigation application organised showing context relationships among objects museum collection. domain expert mining real-world enterprise applications makes speciﬁc domain knowledge including human intelligence domain-speciﬁc constraints. approach empirically validated amsterdam-amstelland police identify suspects victims human traﬃcking suspicious activity reports. based guidelines attorney generals netherlands ﬁrst deﬁned multiple early warning indicators used index police reports. report night march stopped bulgarian license plate routine motor vehicle inspection. mercedes license plate xxx. driving around circles prostitution area. backseat noticed well dressed young girls. asked identification papers speak english dutch. driver possession papers told vacation netherlands weeks etc. concept exploration forced prostitution problem amsterdam poelmans fca-based approach automatically detecting domestic violence unstructured text police reports described detail. identifying potential suspects concept lattices allow detection potentially interesting links independent observations made different police oﬃcers. visual suspect proﬁling fca-based methods temporal concept analysis developed visually represent analyse data temporal dimension temporal concept lattices used elzinga create visual proﬁles potentially interesting terrorism subjects. elzinga used combination nested line diagrams analyse pedophile chat conversations. investigations also used model developed bullens horn identiﬁcation loverboys typically force girls dutch nationality prostitution. loverboys love aﬀair woman force work prostitution. forcing girls women prostitution loverboy approach seen special kind human traﬃcking netherlands model resource used amsterdam-amstelland police trainings police oﬃcers topic. typical loverboy approach consists three main phases give rise corresponding indicators pimp also protect organisation. data-set three reports available girl reports girl discovery loverboy suspect ﬁrst report contains notiﬁcation police youth organisation alkmaar girl report suspicious tattoo wrist containing name refers boyfriend carries ﬁrst name years surinamian origin. second report written police oﬃcer works light district knows many women working brothels behind windows. patrol working prostitute conversation observed suspicious included report. next report contains four suspicious facts recorded oﬃcer. first unbelievable story works prostitute girlfriends someone would dare work prostitute. second tattoos tattoo mentioned ﬁrst report belly. third injuries scratches burns leg. according victim dropped iron accident gourmet set. fourth observation making long working days. third document showed observation victim walking possible suspect. document police oﬃcer reports victim walking close other. police oﬃcer knows knows active world prostitution. oﬃcer immediately took distance victim. soon passed oﬃcer walk close together well-known street prostitutes work behind windows. ﬁrst name person name tattooed victims wrist description person described youth organisation. information signals possible loverboy victim. three reports together give serious presumptions loverboy victim. next step investigating need serious investigating reports shows frequently visits light district strong relationships pimps. pimps suspect another loverboy case. observations seen light district four violence related including observation suspicious burn wounds. violence-related observations situations ﬁghts customers unwilling leave pay. violence-related observations related pimps want protect prostitutes customers competing gangs. since netherlands prostitution legal prostitute right police protect her. violence observations suspect strengthened suspicion pimp moreover found another girl also potential victim him. indications enough create summary report send request using investigation techniques public prosecutor. using concept lattices revealed numerous unknown human traﬃcking loverboy suspects. indepth investigation police resulted conﬁrmation involvement illegal activities resulting actual arrestments made. approach embedded operational policing practice successfully used daily basis cope vastly growing amount unstructured information. online advertising keywords matching bread butter modern search companies like google yandex. experimentation used data overture ﬁrst transformed standard context form. consider following context advertising ﬁrms advertising terms phrases means bought advertising term context bounded follows objects attribute context computed formal concepts form coron system constructing association rules; construction association metarules using morphological analysis; construction association metarules using ontologies detecting large market sectors d-miner oa-biclustering. d-miner algorithm constructs concepts satisfying given constraints sizes extents intents d-miner takes input context parameters minimal admissible extent intent sizes outputs band concept lattice concepts satisfying applying biclustering algorithm data obtained oa-biclusters much less number concepts found d-miner. expert interpretation biclusters implies market described formal concepts found d-miner corresponds bicluster among number formal concepts generated d-miner becomes feasible human interpretation ﬁrms terms. thresholds d-miner could large markets ignored important average-size markets. data ignored markets were e.g. ﬂower markets found using biclustering approach. ’bouquet ﬂower’ ’buy ﬂower’ ’buy ﬂower online’ ’delivery ﬂower’ ’ﬂower fresh’ ’ﬂower gift’ ’ﬂower line’ ’ﬂower online’ ’ﬂower online order’ ’ﬂower online send’ ’ﬂower online value supp ﬁrst rule means companies bought phrases vitamin vitamin. value conf means companies bought phrase vitamin also bought phrase vitamin. make recommendations particular company approach proposed company association rules antecedent contain phrases bought company construct unique advertising phrases bought company before. order phrases decreasing conﬁdence rules phrases occur consequences. buying phrase predicted multiple rules take largest conﬁdence. morphology-based metarules attribute context either word phrase. obviously synonymous phrases related market sectors. advertisers companies usually thematic catalogs composed experts however huge number advertising terms manual composition catalogs diﬃcult task. propose morphological approach detecting similar terms. denotes prime operator context morphologybased metarules context corresponds t−−→ association rule context values support conﬁdence rule context exceed certain thresholds association rules constructed context considered interesting. contain terms containing least word stem common word antecedent term. obviously constructing rules type result fusion phrases related diﬀerent market sectors e.g. black jack si)it i.e. rules experimental validation validation association rules metarules used adapted version cross-validation. training randomly divided parts taken training remaining part used test set. conﬁdence rules averaged test note morphology completely automated allows highly plausible metarules without data purchases. rules support conﬁdence tested recommendation systems google adwords uses frequency queries synonyms. thus recommendations ontological rules contained list synonyms output adwords. motivated prospective applications boolean matrix factorisation context recommender systems proposed fca-based approach follows user-based k-nearest neighbours strategy another approach similar biclustering also successfully applied recommender system domain mentioned also used biclustering technique several examples applications recommender systems domain parameter-free approach exploits neighbourhood object concept particular user also proved eﬀectiveness belowe discuss recent studies application recommender systems domain context auxiliary information concerning users and/or items shows user’s mark given item explicitly implicitly describes circumstances evaluation number users number factors. selection users similar given user based factors peculiar them possible based collaborative ﬁltering formulas calculate prospective ratings given user. memory-based algorithms make rating predictions based entire collection previously rated items users. value unknown rating user item usually computed aggregate ratings users item mainly cosine-based normalised hamming-based similarities. apply approach case fca-based recommender algorithm simply consider user-factor matrices obtained factorisation initial data input. indicates whether factor covers user binary vector describing proﬁle user binary vector items belonging factor coordinates obtained projection vector within proposed approach compared ones implemented evaluated movielens-k data set. data features ratings ﬁve-star scale movies contextual information movies users demographic info found bmf-based approach signiﬁcantly lower svd-based approach almost number factor ﬁxed coverage level p-level svd. precision bmf-based approach slightly lower number neighbours couple dozens comparable remaining part observed range. recall lower results lower f-measure. explained diﬀerent nature factors factorisation models. proposed weighted projection alleviates information loss original boolean projection resulting substantial quality gain. also revealed presence auxiliary information results small quality increase terms recall precision. shortly describe studies near duplicate detection within competition internet mathematics organised yandex romip project optimisation search near duplicates images similarity selected rest projects applications experimental data romip collection documents narod.ru domain provided; consists ﬁles general size ﬁles contained pages narod.ru domain. document collection size greater equal words. experiments collection partitioned several parts consisting three ﬁles evaluation benchmark recall precision calculation list duplicate pairs provided yandex; duplicate pairs identiﬁed document pairs perl stringsimilarity similarity threshold. composing document images followed popular shingling approach text program shingle parameters generate contiguous subsequences size length distance beginnings subsequent substrings oﬀset. sequences obtained hashed sequence receives hash code. hash codes corresponds document ﬁxed size subset chosen means random permutations described probability fact minimal elements permutations hash code sets shingles documents coincide equals similarity measure documents removing html-markup documents generating shingles given parameters length-of-shingle oﬀset hashing shingles composition document image selecting subsets shingles means methods minimal elements permutation minimal elements permutations. composition inverted table list identiﬁers documents shingle thus preparing data format programs computing closed itemsets. computation clusters k-similar documents fpmax* algorithm output consists strings ﬁrst elements names documents last element number common shingles documents. unit outputs values number duplicate pairs romip collection number duplicate pairs realisation number unique duplicate pairs romip collection number unique duplicate pairs results number common pairs romip collection results. experimental results experiments used cluto software package clustering high-dimensional datasets including information retrieval domain comparison purposes. chose repeated-bisecting algorithm uses cosine similarity function -way partitioning mostly scalable according author number clusters parameter documents given sets attributes ﬁngerprints case. algorithm outputs disjoint clusters. algorithms fimi repository shingling parameters used experiments follows number words shingles oﬀset always taken sizes resulting document images taken interval shingles. frequency thresholds deﬁning frequent closed sets experimentally studied diﬀerent values intervals maximal value equal number shingles document image. example interval document images shingles interval document images size etc. obviously choosing maximal value interval obtain clusters document images coincide completely. parameters taking values intervals studied relation between resulting clusters duplicates romip collection duplicates consists pairs documents considered near duplicates. similarity pair documents list based edit distance measure documents taken duplicates authors testbed value edit distance measure exceeds threshold show below definition duplicate prone errors however making testbed manual marking duplication large document collection hardly feasible. unfortunately standard lists near-duplicates missing period even standard corpora trec reuters collection validating methods researchers create ad-hoc lists duplicates using slightly transformed documents standard collections. situation drastically better example workshop series plagiarism analysis authorship identiﬁcation near-duplicate detection study pair found intent contains elements pair vice versa cluster similar documents take pair documents cluster looked corresponding pair romip collection. result obtain number common number near duplicate pairs found method romip collection number unique pairs duplicates results experiments showed romip collection duplicates considered benchmark perfect. first detected large number false duplicate pairs collection similar framing documents. example pages following information table historical personalities declared near duplicates. garibald duke bavaria short information full name garibald date birth unknown place birth unknown date death place death unknown father tassilo duke bavaria giovanni duke milan short information full name giovanni visconti date birth unknown place birth unknown date death place death unknown father visconti matteo great lord milan mother uknown second study also looked false duplicate clusters romip collection caused transitive closure binary relation duplicate since similarity relation generally transitive clusters formed transitive closure relation contain absolutely dissimilar documents. note clusters deﬁned maximal frequent itemsets cannot eﬀects like this documents clusters share necessarily large itemsets graphs tables show clusters output clusterrb alvalue f-measure fpmax* threshold however computations took hours clusterrb half second fpmax*. number romip duplicates number found fpmax* number found cluto number unique pairs romip number unique pairs found fpmax* number unique pairs found cluto number common pairs fpmax* romip number common pairs cluto romip goods so-called copyrighters. copyrighter cheat time time provide owner almost identical descriptions diﬀerent items. study demonstrated revealing fast online clustering duplicates real online perfume shop. results also applicable near duplicate detection collections project’s documents four data mining studies triclustering folksonomic data became shootingrange since ﬁrst eﬃcient fca-based algorithm mine tiradic data proposed mining communities folksonomies rich ﬁeld interactive resource-sharing systems like bibsonomy citeulike flickr delicious need fully-ﬂedged functionality including retrieval ranking recommendations. example bibsonomy social bookmarking publication management system. apart dblp collects stores bibliographic data provide publication author search bibsonomy allows create user’s lists bibliographic bookmarks tags social interactions. mentioned section underlying folksonomy structure formal tricontext users tags resources relates entities three sets. sometimes user-speciﬁc subtag/supertag-relation also included deﬁnition i.e. shortly discuss main tasks folksonomic data give rise. first traditional pagerank cannot directly applied folksonomies. authors paper modiﬁed pagerank algorithm folksonomic data considering input triadic data undirected tripartite graph. weights type edge assigned according occurrences third entity e.g. edge weighted however ﬁrst results delicious data rather discouraging even term-frequency ranker combination resulting ranking similar initial edge weights. resulted authors’ ranking algorithm folkrank takes account diﬀerence resulting rankings without preference vector documents potential interest user suggested him. related tags suggested user. thus folkrank additionally considers tagging behavior users used recommendations. moreover studies admitted search query logs naturally forms folksonomic data resources clicked user performing query predictably gave name logsonomy data structure. bibsonomy early stages faced spam abuse problem ecml pkdd discovery challenge addressed problem. year challenging problem recommendations bibsonomy resulted fruitful algorithms contents site. example interaction members group organized special manner. performed study used approach based formal concepts constructing taxonomies groups users. users sites described attributes correspond sites either external internal precisely initial external data consists user records containing user time user ﬁrst entered site time his/her last visit total number sessions period consideration. internal user record hand simply list pages within target website visited particular user. external internal taxonomies mean concept lattices contexts either external internal attributes. example external context form users target site sites sample incidence relation given pairs received external data following ﬁelds user-site pair internal data almost format additional ﬁeld page corresponds particular visited page target site. provided information gathered sites russian segment internet describing users terms sites visited tackle problem dimensionality since resulting concept lattices large reduce size input data used following techniques. user selected sites visited certain number times observation period. gave information permanent interests particular users. target site considered terms sites three groups newspaper sites ﬁnancial sites educational sites. choose interesting groups users employed stability index concept deﬁned considered tool constructing taxonomies. hand stability index shows independence intent particular objects extent hand stability index concept shows much extent concept diﬀerent similar smaller extents detailed motivation stability indices close probably real even description objects noisy. application data stability index shows likely still observe common group interests ignore several users. apart noise-resistance stable group collapse members group stop attending target sites. compared results taking stable concepts taking iceberg lattice. results look correlated nevertheless substantially diﬀerent. stable extents contained important large groups users. figs. present parts concept lattice site described external attributes taken russian e-newspapers visited users www.hse.ru month times. fig. presents iceberg concepts largest extent. many concepts correspond newspapers middle political spectrum read everybody thus interesting characterising social groups. fig. presents ordered concepts largest stability index. compared iceberg part concept lattice contains several sociologically important groups readers expressgazeta cosmopolitan expert etc. success modern collaborative technologies marked appearance many novel platforms holding distributed brainstorming carrying called public examination. crowdsourcing companies europe also kaggle platform beneﬁcial data practitioners companies want select best solutions data mining problems. russian companies launched business area well. representative examples russian companies witology wikivote several all-russian projects already ﬁnished successfully core crowdsourcing systems socio-semantic network data requires approaches analyze. tried accommodate methodological base analysis data generated collaborative systems rule participating project users crowdsourcing platforms discuss solve common problem propose ideas evaluate ideas experts. finally result discussion ranking users ideas best ideas users deeper understanding users’s behavior developing adequate ranking criteria performing complex dynamic statistic analyses special means needed. traditional methods clustering community detection text mining need adapted even fully redesigned. earlier described models data used crowdsourcing projects terms fca. furthermore presented collaborative platform data analysis system crowdm architecture methods underlying steps data analysis principles platforms’ work diﬀerent work onlineshops specialized music/ﬁlms recommender websites. crowdsourcing projects consist several stages results stage substantially depend previous stage results. that’s existing models recommender systems adapted properly. accompanion paper shorter predecessors present methods making recommendations based oa-biclustering original methods idea recommendation like-minded persons recommendation antagonists recommendation initially applied knowledge acquisition mathematics still suitable tool date resulting concept lattice considered non-tree like taxonomy transportation means since allows multiple inheritance concept hierarchy. expert suppose objects attributes missed object exploration done similar manner e.g. procedure transposed context. exercise compare concept lattices previous example before starting completion attribute exploration. is/are concept obtained? it/they interpreted? perform attribute exploration conceptexplorer slightly modiﬁed context often notion ontology computer science introduced related sets concepts typical relation is-a has-a part-of super/subconcept relation. concept lattices could seen ontology-like structures since feature hierarchically related concepts super/subconcept order however simplicity tree-like ontologies seem popular thus early paper cimiano transform concept lattices built text collections tree-like ontologies proposed. thus ontocomp prot´eg´e plugin ontologies completion. enables user check whether ontology contains relevant information application domain extend ontology appropriately otherwise. asks users questions like instances classes also instances class user replies positively axiom application domain discovered axiom added ontology. user provides counterexample question i.e. object instance questions answered ontology supposed complete. seems attribute exploration fruitful technique ontology building reﬁnement. examples rudolph proposed extension relation exploration ontological modeling knowledge speciﬁcation recently combination machine learning techniques attribute exploration used ontology reﬁnement probably seen exercise attribute exploration uneasy laborious fact checking. however help potential users authors paired attribute exploration information retrieval particular posing appropriate queries search engines. invited talk meets workshop prof. carpineto summarised strengths limitations seems evident increasingly relying contextual knowledge structured data improve query pre-processing query postprocessing modern systems. among mentioned technologies could beneﬁt query expansion search diversiﬁcation ontologybased information retrieval querying navigating many others. however community needs endeavour deploy comprehensive fca-based tool information retrieval integrate existing search indexing taking account intrinsic complexity issues problem good features generation. even extensive tutorial possible cover models applications formal concept analysis. example concept lattices applications social sciences including social network analysis deserve special treatment. grounding steps done vincent duquenne linton freeman collaborators sna-related study). another large interesting domain software engineering acknowledgments. author would like thank colleagues made tutorial possible jaume baixeries pavel braslavsky peter becker radim belohlavek aliaksandr birukou jean-francois boulicaut claudio carpineto florent domenach fritjhof vincent duquenne bernhard ganter katja hofmann robert jaeshke evgenia revne nikolay karpov mehdy kaytoue sergei kuznetsov rokia missaoui elena nenova engelbert mephu nguifo alexei neznanov lhouari nourin bjoern koester natalia konstantinova amedeo napoli sergei obiedkov jonas poelmans nikita romashkin paolo rosso sebastian rudolph alexander tuzhilin pavel serdyukov baris serkaya dominik slezak marcin szchuka last least brave listeners. author would also like commemorate ilya segalovich inspired author’s enthusiasm information retrieval studies giving personal explanations near duplicate detection techniques particular. author partially supported russian foundation basic research grants prepared tutorial within project data mining based applied ontologies lattices closed descriptions supported basic research program national research university higher school economics.", "year": 2017}