{"title": "Rotation-invariant convolutional neural networks for galaxy morphology  prediction", "tag": ["astro-ph.IM", "astro-ph.GA", "cs.CV", "cs.LG", "cs.NE", "stat.ML"], "abstract": "Measuring the morphological parameters of galaxies is a key requirement for studying their formation and evolution. Surveys such as the Sloan Digital Sky Survey (SDSS) have resulted in the availability of very large collections of images, which have permitted population-wide analyses of galaxy morphology. Morphological analysis has traditionally been carried out mostly via visual inspection by trained experts, which is time-consuming and does not scale to large ($\\gtrsim10^4$) numbers of images.  Although attempts have been made to build automated classification systems, these have not been able to achieve the desired level of accuracy. The Galaxy Zoo project successfully applied a crowdsourcing strategy, inviting online users to classify images by answering a series of questions. Unfortunately, even this approach does not scale well enough to keep up with the increasing availability of galaxy images.  We present a deep neural network model for galaxy morphology classification which exploits translational and rotational symmetry. It was developed in the context of the Galaxy Challenge, an international competition to build the best model for morphology classification based on annotated images from the Galaxy Zoo project.  For images with high agreement among the Galaxy Zoo participants, our model is able to reproduce their consensus with near-perfect accuracy ($> 99\\%$) for most questions. Confident model predictions are highly accurate, which makes the model suitable for filtering large collections of images and forwarding challenging images to experts for manual annotation. This approach greatly reduces the experts' workload without affecting accuracy. The application of these algorithms to larger sets of training data will be critical for analysing results from future surveys such as the LSST.", "text": "electronics information systems department ghent university sint-pietersnieuwstraat ghent belgium school physics astronomy university minnesota church minneapolis abstract measuring morphological parameters galaxies requirement studying formation evolution. surveys sloan digital survey resulted availability large collections images permitted population-wide analyses galaxy morphology. morphological analysis traditionally carried mostly visual inspection trained experts time-consuming scale large numbers images. although attempts made build automated classiﬁcation systems able achieve desired level accuracy. galaxy project successfully applied crowdsourcing strategy inviting online users classify images answering series questions. unfortunately even approach scale well enough keep increasing availability galaxy images. present deep neural network model galaxy morphology classiﬁcation exploits translational rotational symmetry. developed context galaxy challenge international competition build best model morphology classiﬁcation based annotated images galaxy project. images high agreement among galaxy participants model able reproduce consensus near-perfect accuracy questions. conﬁdent model predictions highly accurate makes model suitable ﬁltering large collections images forwarding challenging images experts manual annotation. approach greatly reduces experts’ workload without aﬀecting accuracy. application algorithms larger sets training data critical analysing results future surveys lsst. galaxies exhibit wide variety shapes colours sizes. properties indicative formation conditions interactions galaxies course many gyr. studies galaxy formation evolution morphology probe physical processes give rise them. particular large all-sky surveys galaxies critical disentangling complicated relationships parameters halo mass metallicity environment morphology; deeper surveys probe changes morphology starting high redshifts taking place timescales billions years. bers galaxies accurate classiﬁcation morphologies. large-scale surveys sloan digital survey resulted availability image data millions celestial objects. however manually inspecting images annotate morphological information impractical either individual astronomers small teams. attempts build automated classiﬁcation systems galaxy morphologies historically diﬃculties reaching levels reliability required scientiﬁc analysis galaxy project conceived accelerate task method crowdsourcing. original goal project obtain reliable lowing members public contribute classiﬁcations platform. project much successful anticipated entire catalog annotated within timespan several months since original inception several iterations project diﬀerent sets images detailed classiﬁcation taxonomies followed. recent sets developments since launch galaxy made automated approach feasible ﬁrst large strides ﬁelds image classiﬁcation computer vision general primarily deep neural networks although neural networks existed several decades recently returned forefront machine learning research. signiﬁcant increase available computing power along techniques rectiﬁed linear units dropout regularization made possible build powerful neural network models large sets reliably annotated images galaxies available consequence success galaxy zoo. data used train machine learning models increase accuracy morphological classiﬁcations. deep neural networks particular tend scale well number available training examples increases. nevertheless also possible train deep neural networks modestly sized datasets using techniques regularization data augmentation parameter sharing model averaging discuss section following. automated approach also becoming indispensable modern telescopes continue collect images every day. future telescopes vastly increase number galaxy images morphologically classiﬁed including multi-wavelength imaging deeper ﬁelds synoptic observing true all-sky coverage. result crowdsourcing approach cannot expected scale indeﬁnitely growing amount data. supplementing expert crowdsourced catalogues automated classiﬁcations logical necessary next step. paper propose convolutional neural network model galaxy morphology classiﬁcation speciﬁcally tailored properties images galaxies. eﬃciently exploits translational rotational symmetry images autonomously learns several levels increasingly abstract representations images suitable classiﬁcation. model developed context galaxy challenge international competition build best model automatic galaxy morphology classiﬁcation based annotated images galaxy project. model ﬁnished ﬁrst place participants. model eﬃciently automatically annotate catalogs images morphology informarest paper structured follows introduce galaxy project section section explains galaxy challenge. discuss related work section convolutional neural networks described section method incorporate rotation invariance models described section provide complete overview modelling approach section report results section analyse model section finally draw conclusions section galaxy online crowdsourcing project users asked describe morphology galaxies based colour images model analysis uses data galaxy iteration project uses colour images sdss detailed classiﬁcation scheme original project participants asked various questions ‘how rounded galaxy?’ ‘does central bulge?’ users’ answers determining question asked next. questions form decision tree designed encompass points traditional hubble tuning fork well range irregular morphologies. classiﬁcation scheme questions answers total structure decision tree individual participant answered subset questions classiﬁcation. many participants classiﬁed image answers aggregated weighted vote fractions entire decision tree. vote fractions used estimate conﬁdence levels answer indicative diﬃculty users experienced classifying image. half million people contributed classiﬁcations galaxy image independently classiﬁed people. data galaxy projects already used wide variety studies galaxy structure formation evolution comparisons galaxy morphologies smaller samples experts automated classiﬁcations show high levels agreement testifying accuracy crowdsourced annotations https//www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge model independently developed kaggle competition. co-designed administered competition shared data code participants closing date. note vote fractions post-processed increase reliability example weighting users based consistency majority compensating classiﬁcation bias induced diﬀerent image apparent magnitudes sizes galaxy sponsored winton capital hosted kaggle platform data prediction contests. held december april goal competition build model could predict galaxy morphology images like ones used galaxy project. images galaxies morphological data competition taken galaxy main spectroscopic sample. galaxies selected cover full observed range morphology colour size since goal develop general algorithm could applied many types images future surveys. total number images provided limited imaging depth sdss elimination uncertain overrepresented morphological categories function colour helped ensure colour used proxy morphology high-performing model would based purely images’ structural parameters. ﬁnal training data consisted jpeg colour images galaxies along probabilities answers decision tree. evaluation images also provided morphological data goal competition predict values. image pixels size. morphological data provided modiﬁed version weighted vote fractions catalog; transformed cumulative probabilities gave higher weights fundamental morphological categories higher decision tree. images anonymized sdss metadata train algorithm explicitly forbidden competition guidelines. goal predict probabilities answer opposed determining likely answer question decision tree models built participants actually solving regression problem classiﬁcation problem strictest sense. predictive performance model determined computing root-mean-square error predictions evaluation corresponding crowdsourced probabilities. answer probabilities associated image corresponding predictions. rmse computed follows table questions asked image corresponding answers participants choose from. question asked every image. ﬁnal column indicates next question asked particular answer given. reproduced table willett provided answer probabilities derived crowdsourced classiﬁcations somewhat noisy biased certain ways. result predictive models built exhibited biases. words models crowd would classify images galaxies necessarily correspond true morphology. example discrepancy discussed section models built participants evaluated follows. kaggle platform automatically computed scores based model predictions public score computed evaluation data private score computed public scores immediately revealed course competition private scores revealed competition ﬁnished. private score used determine ﬁnal ranking. participants know evaluation images belonged could directly optimize private score instead encourmachine learning techniques artiﬁcial neural networks particular popular tool astronomy research decades. neural networks initially applied star-galaxy discrimination classiﬁcation galaxy spectra recently also used photometric redshift estimation galaxy morphology classiﬁcation widespread applications neural networks astronomy. work domain proceeds preprocessing photometric data extracting limited handcrafted features known discriminative ellipticity concentration surface brightness radii log-likelihood values measured various types radial proﬁles support vector machines also applied fashion earlier work domain typically relied much smaller datasets used networks trainable parameters modern network architectures capable handling least parameters another recent trend general purpose image features instead features speciﬁc galaxies wnd-charm feature originally designed biological image analysis applied galaxy morphology classiﬁcation combination nearest neighbour classiﬁers approaches problem attempt forgo form handcrafted feature extraction applying principal component analysis preprocessed images combination neural network applying kernel svms directly pixel data charm) required expert knowledge many hours engineering develop. work directly pixel data convolutional neural networks allows task-speciﬁc features learned data. networks learn hierarchies features allow detect complex patterns images. handcrafted features mostly rely image statistics local pattern detectors making harder recognize complex patterns. furthermore usually necessary perform feature selection handcrafted representations highly redundant many features irrelevant task hand. although many participants galaxy challenge whose algorithms also trained galaxy data research focused classifying galaxies limited number classes predicting scalar values indicative galaxy morphology since classiﬁcations made galaxy users much ﬁne-grained task networks must solve challenging. since many outstanding astrophysical questions require detailed morphological data development models handle diﬃcult tasks crucial. method classifying galaxy morphology exploits rotational symmetry galaxy images; however invariances symmetries exploited convolutional neural networks. bruna deﬁne convolution operations arbitrary graphs generalizing typical grid pixels locally connected structures. sifre mallat extract representations invariant aﬃne transformations based scattering transforms. however representations ﬁxed speciﬁcally tuned task hand unlike representations learned convolutional neural networks. mairal propose train convolutional neural networks approximate kernel feature maps allowing desired invariance properties encoded choice kernel subsequently learned. gens domingos propose deep symmetry networks generalization convolutional neural networks ability form feature maps symmetry group rather translation group. approach exploiting rotational symmetry input images described section quite similar spirit work. major advantage implementation demonstrably eﬀective result reasonable computational cost. idea deep learning build models represent data multiple levels abstraction discover accurate representations autonomously data deep learning models consist several layers processing form hierarchy subsequent layer extracts progressively abstract representation input data builds upon representation previous layer typically computing non-linear transformation input. parameters transformations optimized training model dataset. feed-forward neural network example model layer consists number units compute weighted linear combination layer input followed elementwise non-linearity. weights constitute model parameters. vector input layer matrix weights activation function elementwise non-linear function. common choices activation function linear rectiﬁcation max] gives rise rectiﬁed linear units sigmoidal function tanh]. another possibility compute maximum across several linear combinations input gives rise maxout units consider network layers. network input represented output schematic representation feed-forward neural network shown figure network computes function input output function prediction quantities interest. represent desired output corresponding network input topmost layer network referred output layer. layers hidden layers. training parameters layers network jointly optimized make output approximate desired output closely possible. quantify prediction error using error measure result hidden layers learn produce representations input data useful task hand output layer learn predict desired output representations. determine parameters changed reduce prediction error across dataset gradient descent gradient computed respect model parameters parameter values layer modiﬁed traditionally models many non-linear layers processing commonly used diﬃcult train gradient information would vanish propagated layers making diﬃcult learn parameters lower layers practical applications neural networks limited models hidden layers. since invention several techniques along signiﬁcant increase available computing power made task much feasible. initially unsupervised pre-training proposed method facilitate training deeper networks single-layer unsupervised models stacked trained learned parameters models used initialize parameters deep neural network. ﬁnetuned using standard gradient descent. initialization scheme makes possible largely avoid vanishing gradient problem. nair hinton glorot proposed rectiﬁed linear units deep neural networks. replacing traditional activation functions linear rectiﬁcation vanishing gradient problem signiﬁcantly reduced. also makes pre-training unnecessary cases. introduction dropout regularization made possible train larger networks many parameters. dropout regularization method applied layer randomly removing output values previous layer convolutional neural networks convnets subclass neural networks constrained connectivity patterns layers. used input data exhibits kind topological structure like ordering image pixels grid temporal structure audio signal. restricted connectivity convolutional layers pooling layers. convolutional layer takes stack feature maps input convolves learnable ﬁlters produce stack output feature maps. eﬃciently implemented replacing matrix-vector product wnxn− equation convolutions. represent input layer matrices matrices represents diﬀerent input feature map. output feature maps represented follows here represents two-dimensional convolution operation matrices represent ﬁlters layer represents bias feature note feature obtained computing convolutions feature maps previous layer. bias optionally replaced matrix spatial position feature bias allows sensitivity ﬁlters vary across input. replacing matrix product convolutions connectivity layer eﬀectively restricted take advantage input structure reduce number parameters. unit connected local subset units layer below unit replicated across entire input. shown left side figure means unit seen detecting particular feature across input applying feature detectors across entire input enables exploitation translational symmetry images. consequence restricted connectivity pattern convolutional layers typically fewer parameters traditional dense layers compute transformation input according equation reduction parameters drastically improve generalization performance make model scale larger input dimensionalities. convolutional layers able model local correlations input dimensionality feature maps often reduced convolutional layers inserting pooling layers. allows higher layers model correlations across larger part input albeit lower resolution. pooling layer reduces dimensionality feature computing aggregation function across small local regions input shown right side figure also makes model invariant small translations input desirable property modelling images many types data. unlike convolutional layers pooling layers typically trainable parameters. figure schematic overview convolutional layer followed pooling layer unit convolutional layer connected local neighborhood feature maps previous layer. pooling layer aggregates groups neighboring units layer below. convolutional neural networks constitute state many computer vision problems. since effectiveness large-scale image classiﬁcation demonstrated ubiquitous computer vision research restricted connectivity patterns used convolutional neural networks drastically reduce number parameters required model large images exploiting translational symmetry. however many types symmetries occur images. images galaxies rotating image aﬀect morphological classiﬁcation. rotational symmetry exploited applying feature detectors various rotated versions input. increases parameter sharing positive eﬀect generalization performance. whereas convolutions provide eﬃcient exploit translational symmetry applying ﬁlter multiple rotated versions input requires explicitly instantiating versions. additionally rotating image angle multiple requires interpolation results image whose edges aligned rows columns pixel grid. complications make exploiting rotational symmetry challenging. note original galaxy project experimented crowdsourced classiﬁcations galaxies images vertically diagonally mirrored. land showed votes excess s-wise spiral galaxies z-wise galaxies. since eﬀect seen mirrored images interpreted bias preferences human brain rather true excess number apparent s-wise spirals universe. existence directional bias brain demonstrated gori galaxy probabilities contain structures related handedness rotation-variant quantities rotational translational biases discovered data. biases exist however would presumably reduce predictive power model since assumption rotational invariance output probabilities would longer apply. approach exploiting symmetry visualized figure compute rotated ﬂipped versions input images referred viewpoints process separately convolutional network architecture consisting alternating convolutional layers pooling layers. output feature maps network diﬀerent viewpoints concatenated dense layers stacked top. arrangement allows dense layers aggregate high-level features extracted diﬀerent viewpoints. practice also crop left part viewpoint image reduce redundancy viewpoints reduce size input images images cropped contains centre galaxy part image tends informative. practical implementation viewpoint extraction discussed section modiﬁed network architecture described section section describe practical approach developing training model galaxy morphology prediction. ﬁrst discuss experimental setup problem overﬁtting main driver behind design decisions. describe successive steps processing pipeline obtain answer probabilities image. pipeline consists steps input preprocessing augmentation viewpoint extraction convolutional neural network model averaging. also brieﬂy discuss practical implementation pipeline software perspective. figure schematic overview neural network architecture exploiting rotational symmetry. input image ﬁrst rotated various angles optionally ﬂipped yield diﬀerent viewpoints viewpoints subsequently cropped reduce redundancy cropped viewpoints processed stack convolutional layers pooling layers output representations concatenated processed stack dense layers obtain predictions described section provided dataset consists training images associated answer probabilities evaluation images. feedback could obtained competition submitting predictions images evaluation set. competition submitted predictions scored computing rmse subset approximately evaluation images. revealed images part subset. scores used determine ﬁnal ranking obtained computing rmse remaining images. arrangement typical competitions hosted kaggle platform. split training images real-time evaluation model training trained models remaining train models using approach even though achieved performance terms rmse compared models trained without models make diﬀerent mistakes. useful context model averaging high variance among comparably performing models desirable jpeg colour images). found keeping colour information improved predictive performance considerably despite fact colours artiﬁcial intended human eyes. artiﬁcial colours nevertheless correlated morphology models able exploit correlation. images ﬁrst cropped rescaled reduce dimensionality input. useful crop images because object interest middle image large amount background typically within square side approximately half image height. rescaled images speed training little eﬀect predictive performance. images cropped small subset images cropping operation removed part object interest either unusually large angular size perfectly centred. looked recentering rescaling images detecting measuring objects images using sextractor allowed independently estimate position petrosian radii objects. information used centre rescale images standardize sizes objects processing. limited size training performing data augmentation artiﬁcially increase number training examples instrumental. training example randomly perturbed ways shown figure adjusted described krizhevsky diﬀerences ﬁrst eigenvector much larger eigenvalue used standard deviation scale factor practice amounts brightness adjustment. ﬁrst four aﬃne transformations collapsed single transformation together used preprocessing. means data augmentation step noticeable computational cost. maximize eﬀect data augmentation randomly perturbed images demand training models never presented exact training example once. preprocessing augmentation extracted viewpoints rotating ﬂipping cropping input images. extracted diﬀerent viewpoints image ﬁrst square-shaped crops extracted input image also ﬂipped horizontally obtain crops total. crops architecture best performing network visualized figure four convolutional layers square ﬁlters ﬁlter sizes respectively untied biases rectiﬁcation non-linearity applied layer max-pooling follows ﬁrst second fourth convolutional layers. concatenated feature maps viewpoints processed stack three fully connected layers consisting maxout layers units linear ﬁlters each linear layer outputs real numbers. maxout layers used instead relu layers reduce number connections next layer maxout convolutional layers proved computationally intensive. arrived particular architecture manual parameter search architectures evaluated course competition found yield best predictive performance. network roughly million trainable parameters total. table lists hyperparameter settings trainable layers. values network produces input image converted probabilities. first values passed rectiﬁcation non-linearity normalized question obtain valid categorical probability distribution question. valid probability distributions could also obtained using softmax function question instead rectiﬁcation followed normalization. however decreased overall performance since harder network predict probability exactly distributions still need rescaled however; give probability answer conditional associated question asked user asked subset questions. implies questions lower probability asked probabilities answers questions scaled obtain unconditional probabilities. practice scale probabilities answers preceded decision tree post-processing operation incorporated network. consists diﬀerentiable operations gradient objective function backpropagated guarantees output horizontally obtain crops total. then four overlapping corner patches extracted crop rotated galaxy centre bottom right corner patch. rotated patches constitute viewpoints. ﬁgure best viewed colour. approach allowed obtain diﬀerent viewpoints aﬃne transformation operations thus avoiding additional computation. viewpoints obtained original crops without interpolation also means image edges padding eﬀect input loss image ﬁdelity preprocessing augmentation viewpoint extraction minimal. table hyperparameters trainable layers best performing network trained also depicted figure last columns describe initialization distributions weights biases layer. section description incorporation output constraints last layer network. network violate constraints answer probabilities must adhere resulted small signiﬁcant performance improvement. addition best performing network also trained variants purpose model averaging networks diﬀer slightly best performing network make slightly diﬀerent predictions result. variants included train models used minibatch gradient descent batch size nesterov momentum coeﬃcient nesterov momentum method accelerating gradient descent accumulating gradients time directions consistently decrease objective function value. similar methods commonly used neural network training speed training process often lead improved predictive performance performed approximately million gradient updates corresponding million training examples. following krizhevsky used discrete learning rate schedule improve convergence. began constant learning rate decreased tenfold twice decreased million examples million examples. ﬁrst examples output constraints ignored linear output layer network simply clipped necessary ensure convergence. weights model initialized sampling zero-mean normal distributions variances distributions ﬁxed layer manually chosen ensure proper gradient network. biases initialized positive values decrease risk units getting stuck saturation region. although necessary maxout units strategy used dense layers. initialization strategy layers shown last columns table improve prediction accuracy averaged predictions several diﬀerent models across several transformations input images. requirements model averaging eﬀective individual model must roughly prediction accuracy prediction errors uncorrelated possible. model computed predictions aﬃne transformations input images combination rotations spaced rescalings optional horizontal ﬂipping. unweighted average predictions computed. even though model trained robust types deformations computing averaged predictions fashion still helped increase prediction accuracy aspects model implemented using python theano library allowed acceleration without additional eﬀort. theano also able perform automatic diﬀerentiation simpliﬁes implementation gradient-based optimization techniques. networks trained nvidia geforce cards. data augmentation performed using scikit-image package parallel model training gpu. training network described section took roughly hours real time. competition results models listed table report performance best performing network without averaging across transformations well combination variants. root-meansquare error table metric used score submissions galaxy challenge averaging across transformations averaging across diﬀerent models contributed signiﬁcantly ﬁnal score. table performance best performing network well performance averaging across transformations input across variants network. please refer section details scores computed. worth noting model performs well even without model averaging important fast inference desirable practical applications. predictions generated millions images combining large number predictions image would require impractical amount computation. although morphology prediction framed regression problem competition fundamentally classiﬁcation task. demonstrate capabilities model interpretable fashion look classiﬁcation accuracies. question obtain classiﬁcations selecting answer highest probability image. probabilities obtained galaxy participants probabilities predicted model. compute classiﬁcation accuracy simply counting number images classiﬁcations match reducing probability distributions classiﬁcations fashion clearly causes information discarded classiﬁcation accuracy metric much easier interpret. level agreement galaxy participants aﬀects accuracy predictions model compute entropy probability distribution answers given question. entropy discrete probability distribution options given entropy minimal participants selected answer entropy maximal answers equally likely selected. entropy ranges log. convert measure agreement follows assess conditions predictions model trusted measure conﬁdence prediction using measure applying probability distributions predicted model instead distributions crowdsourced answers. allows relate model conﬁdence prediction accuracy. real-time evaluation least participants answered question. ensure consider images question likely relevant. ranked images subset according measure divided equal bins. seperately crowdsourced answers model predictions. computed average classiﬁcation accuracy using best performing network values visualized graphs question figure circles show classiﬁcation accuracy versus agreement. blue squares show classiﬁcation accuracy versus model conﬁdence. classiﬁcation accuracy across entire subset also shown thick horizontal line. dashed horizontal lines indicate maximal accuracy chance-level accuracy depends number options. number images subset overall classiﬁcation accuracy indicated graphs. questions classiﬁcation accuracy tapers level agreement galaxy participants decreases. makes sense images harder classify. kuminski report similar results using wnd-charm algorithm lowest accuracies features describing spiral irregular structures. model achieves near-perfect accuracy questions level agreement high. classiﬁcations bulge dominance spiral tightness agreement overall also diﬃcult answer model. similarly conﬁdence model predictions correlated classiﬁcation accuracy achieve nearperfect accuracy questions model highly conﬁdent. useful property allows determine able trust predictions defer expert instead. consequence model could used ﬁlter large collection images order obtain much smaller annotated manually experts. two-stage approach would greatly reduce experts’ workload virtually cost terms accuracy. questions particular able make conﬁdent accurate predictions majority examples. would allow largely automate assessment e.g. smoothness roundedness questions hand conﬁdence across board classiﬁcation accuracy usually practical use. result determining bulge dominance spiral tightness would still require manual input. level able automate annotation process depends morphological properties interested well distribution morphology types dataset wish analyse. assess well model able predict various diﬀerent morphology types computed precision recall scores answers individually. precision recall scores deﬁned terms number true could also conducted analysis evaluation competition since true answer probabilities real-time evaluation readily available contains images used instead. scores listed table used strategy obtain classiﬁcations considered examples least galaxy participants answered question. numbers examples available question answer also shown. scores establish model diﬃculty morphology types occur less frequently dataset e.g. star artifact bulge dominant bulge dust lane note images ﬁrst category attempted delibrately excluded galaxy data ﬂags sdss pipeline. precision recall scores aﬀected eﬀect cannot attributed entirely bias towards common morphologies. however recall generally aﬀected strongly precision indicates model conservative predicting rare morphology types. rare answers unable compute precision scores model never predicted examples considered lens boxy bulge four spiral arms rare morphologies considerable scientiﬁc interest constructing model accurately identify still primary goal. traditionally neural networks often treated black boxes perform complicated uninterpretable sequence computations yield good approximation desired output. however analysing parameters trained model informative sometimes even leads insights problem network trying solve especially true convolutional neural networks trained images ﬁrst-layer ﬁlters interpreted visually. figure shows ﬁlters learned ﬁrst layer best performing network described section ﬁlter contrast-normalized individually bring details three colour channels shown separately. comparing ﬁlter weights across colour channels reveals ﬁlters sensitive particular colours others sensitive patterns edges textures. phenomenon observed training convolutional neural networks traditional image datasets. ﬁlters edge detection seem looking curved edges particular expected radial symmetry input images. units convolutional part network. note geometry input image still apparent activations higher convolutional layers. activations layers except third also quite sparse especially fourth layer. possible reason third layer figure level agreement model conﬁdence versus classiﬁcation accuracy questions computed real-time evaluation set. overall classiﬁcation accuracy indicated thick horizontal line. dotted dashed horizontal lines indicate maximal accuracy chance-level accuracy respectively. number images included analysis overall classiﬁcation accuracy question indicated graphs. also possible visualize neurons tophidden layer network learned data selecting representative examples test maximize activations. reveals type inputs unit sensitive kind invariances learned. used maxout units layer also select examples minimally activate units allowing determine types inputs unit discriminates between. variance well scale invariance. units observed selectivity positive negative direction minority units seem multimodal activating direction distinct types galaxies. presumably activation value units disambiguated context unit values. unit visualized figure detects imaging artifacts black lines running across centre images result dead pixels sdss camera. interesting artifacts morphological features depicted galaxies. turns network trying replicate behaviour galaxy participants tend classify images featuring artifacts disturbed galaxies even though intended meaning answer. likely button answer galaxy interface seems feature black line. finally look examples realtime evaluation high prediction errors idea strengths weaknesses model reported rmse values obtained best performing network without averaging without centering rescaling. images diﬃcult classify quite varied. faint look fairly typical otherwise figure negatively aﬀected cropping operation various ways either properly centred large original motivation introducing additional rescaling centering step preprocessing improving overall prediction accuracy. easiest galaxies classify mostly smooth round ellipticals. present convolutional neural network ﬁne-grained galaxy morphology prediction novel architecture allows exploit rotational symmetry input images. network trained data galaxy project able reliably predict various aspects galaxy morphology directly pixel data without requiring form handcrafted feature extraction. automatically annotate large collections images enabling quantitative studies galaxy morphology unprecedented scale. novel approach exploiting rotational symmetry essential achieve state-of-the-art performance winning galaxy challenge hosted kaggle. although winning solution required averaging many sets predictions diﬀerent networks image using single network also yields competitive results. model adapted work collection centered galaxy images arbitrary morphological decision trees. implementation developed using open source tools source code publicly available. model trained used consumer hardware. predictions highly reliable conﬁdent making approach applicable ﬁne-grained morphological analysis large-scale survey data. performing large-scale analyses important direction future research. future work would like train networks larger collections annotated images. previous applications domain computer vision become clear performance convolutional neural networks galaxy images used paper quite small dataset modern standards. even though combined several techniques avoid overﬁtting allowed train large models dataset eﬀectively clear opportunity improve predictive performance train model larger dataset since galaxy already collected annotations much larger number images. recent iterations galaxy project concentrated higher redshift samples care taken ensure model able generalize across diﬀerent redshift slices. larger datasets also allow increase model capacity without risk excessive overﬁtting. high-capacity models could used basis much larger surveys lsst. integration model predictions existing annotation workﬂows experts crowdsourcing platforms also require study. figure activations layer convolutional part best performing network given input viewpoint shown left. number feature maps size indicated ﬁgure. geometry input image still apparent activations higher convolutional layers. activations layers except third also quite sparse. figure example images test maximally minimally activate units topmost hidden layer best performing network. group images represents unit. images group maximally activate unit bottom images minimally activate bottom galaxies primarily correspond galaxy labels loose winding arms edge-on disks irregulars disturbed other tight winding arms. photometric data preprocessed visual inspection humans. networks able learn useful features representation including structural changes multiple wavebands automated classiﬁcation data modalities exhibit radial symmetry also presents interesting opportunity. machine learning point view would like investigate improved network architectures based recent developments trend towards deeper networks excess layers processing smaller receptive ﬁelds figure example images real-time evaluation along prediction rmses best-performing network. images diﬃcult model classify; images bottom easiest. larger angular size non-radially symmetric morphology challenging targets model. would like thank pieter-jan kindermans francis wyffels a¨aron oord pieter buteneers chris lintott philip marshall anonymous reviewer valuable feedback. would like acknowledge joyce noahvanhoucke chris lintott david harvey thomas kitching philip marshall help designing kaggle galaxy challenge. thank winton capital ﬁnancial support competition galaxy volunteers providing original morphology classiﬁcations. eﬀorts individually acknowledged http //authors.galaxyzoo.org. supported part grant-in-aid. bengio boulanger-lewandowski pascanu ieee international conference acoustics speech signal processing advances optimizing recurrent networks. bergstra breuleux bastien lamblin pascanu desjardins turian warde-farley bengio proceedings python scientiﬁc computing conference theano math expression compiler table precision recall scores answer. compute values subset examples real-time evaluation least participants answered question. also give number examples subset answer. question mark indicates unable compute precision score model predict answer considered examples. glorot bordes bengio jmlr w&cp proceedings fourteenth international conference artiﬁcial intelligence statistics deep sparse rectiﬁer neural networks hinton srivastava krizhevsky sutskever salakhutdinov technical report improving neural networks preventing co-adaptation feature detectors. university toronto orlov shamir macura johnston eckley goldberg pattern recognition letters polsterer gieseke kramer astronomical data analysis software systems vol. galaxy classiﬁcation without feature extraction.", "year": 2015}