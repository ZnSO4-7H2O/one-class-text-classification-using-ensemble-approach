{"title": "Canonical dual solutions to nonconvex radial basis neural network  optimization problem", "tag": ["cs.NE", "cs.LG", "stat.ML"], "abstract": "Radial Basis Functions Neural Networks (RBFNNs) are tools widely used in regression problems. One of their principal drawbacks is that the formulation corresponding to the training with the supervision of both the centers and the weights is a highly non-convex optimization problem, which leads to some fundamentally difficulties for traditional optimization theory and methods.  This paper presents a generalized canonical duality theory for solving this challenging problem. We demonstrate that by sequential canonical dual transformations, the nonconvex optimization problem of the RBFNN can be reformulated as a canonical dual problem (without duality gap). Both global optimal solution and local extrema can be classified. Several applications to one of the most used Radial Basis Functions, the Gaussian function, are illustrated. Our results show that even for one-dimensional case, the global minimizer of the nonconvex problem may not be the best solution to the RBFNNs, and the canonical dual theory is a promising tool for solving general neural networks training problems.", "text": "radial basis functions neural networks tools widely used regression problems. principal drawbacks formulation corresponding training supervision centers weights highly non-convex optimization problem leads fundamentally diﬃculties traditional optimization theory methods. paper presents generalized canonical duality theory solving challenging problem. demonstrate sequential canonical dual transformations nonconvex optimization problem rbfnn reformulated canonical dual problem global optimal solution local extrema classiﬁed. several applications used radial basis functions gaussian function illustrated. results show even one-dimensional case global minimizer nonconvex problem best solution rbfnns canonical dual theory promising tool solving general neural networks training problems. second strategy consider weighter centers radial basis functions variables. strategy performed solving following unconstrained optimization problem problem non-convex empirical experiments emerged generally yields neural networks higher precision ones trained strategy used strategies solve optimization problem apply decomposition algorithms however nonconvexity problem fundamental diﬃculties global minimum problem characterize local minima. indeed problem considered np-hard even radial basis function quadratic function another issue characterizes problem choice regularization parameters general cross-validation strategy applied order regularization parameters. cross-validation consists trying diﬀerent values parameters order yields neural network best prediction. until possible closed form optimal values parameters general case. possible least upper bound parameters time needed perform cross validation would greatly decrease. radial basis function neural networks tool introduced ﬁeld function interpolation adapted problem regression last decades rbfnn applied several ﬁelds. problem regression consists trying approximate function generally speaking main optimization strategies train rbfnn. ﬁrst consists optimization weights neural network. case centers generally chosen using clustering strategies problem convex problem variable form global optimization potentially powerful methodology used successfully solving large class challenging problems biology engineering sciences recently network communications paper study canonical duality theory solving general radial basis neural networks optimization problem mainly analyze one-dimensional case order properties intuitions useful multidimensional cases. rest paper arranged follows. section ﬁrst demonstrate rewrite nonconvex primal problem dual problem using sequential canonical dual transformation developed section prove complementarity-dual principle showing obtained formulation canonically dual original problem sense duality gap. section analyze problem gaussian function radial basis neurons show examples. last section presents conclusions. regularization coeﬃcient positive scalar close zero. term comprised original radial basis neural networks formulation consider general mathematical case. non-convex function depends choice radial basis function belong applications parameter also variable original problem convex non-convex respect center radial basis function therefore one-dimensional non-convex primal problem formulated generally speaking possible certain functions canonical dual transformation relation ﬁrst level dual variable second level dual variable means derivatives ﬁrst primal variable general relation would better choose bigger possible order make exponential zero result would never satisfactory error committed approximation would close goes inﬁnity. value good value error zero. hand sign value order exponential equal lowest value exp{−d} order realistic problem consider case sign |w|. cases equivalent suppose positive without losing generality. local minimum dual problem corresponding local maximum primal problem; local maximum dual problem corresponding local minimum primal problem; local minimum dual problem corresponding local minimum primal problem; local maximum dual problem corresponding local maximum primal problem. corresponding critical point primal problem always local minimum. neither conditions satisalways critical point dual problem corresponding critical point primal problem. theorem suppose point critical points dual problem corresponding critical points primal problem. local minima local maxima primal problem following relation always holds results theorem always better search corresponds minimum dual critical point primal problem. order characterize solutions domains search best solution theorems proposed following proof dual problem must singularity point goes local minimum must local maximum local maximum prove condition negating thesis suppose least critical point goes local minimum critical points local maximum relation theorems corresponds second highest local maximum primal function corresponds lowest second lowest local minimum primal function relation satisﬁed. theorem have case three critical points four critical points critical point critical points local minimum. values parameters case easily solved general canonical ducorresponds ality framework local maximum global minimum problem local minimum maximum correspond local minimum maximum primal problem. local maximum considered positive term −yxo always negative always greater condition inﬂection point also satisﬁes ﬁrst order condition corresponding minimum point primal problem theorem remark theorem shows eﬀects parameter pseudo critical point similar eﬀects also obtained respect reason choose hyper-parameter chosen practitioner performing optimization. case five critical points critical points values parameters notice rameter changed respect case parameters problem becomes multi-welled. critical points lowest value objective function belong double well corresponding critical points critical point cors+ responding second best minimizer primal problem situated near boundary visible figure also possible certain values parameters local minimum boundary corresponds global minimum problem case choice value critical point near boundary. critical point corresponds critical point primal value near zero. critical point generated term regularization term used make objective function coercive regular. hand term doesn’t anything original problem. point near zero primal function always corresponding dual critical point near boundary gets close zero exp{−d} gets close also consider exp{−d} error originally want minimize problem critical point boundary always absolute value bigger critical point closer words local minimum boundary nothing original problem high value error considered good solution. order optimal solution original problem local minimum primal problem corresponding critical point closer zero preferable. reducing value possible make critical point near local minimum also assure local minimum. critical point domain solution well deﬁned. basically critical point near global minimum value boundary chosen. paper presented application canonical duality theory function approximation using radial basis functions. using sequential dual canonical transformation convex problem general function reformulated canonical dual form. associated strong duality theorem also proposed. applications used exponential function illustrated. particular properties exponential function able linear relation dual variables leads explicit form canonical dual problem. also found conditions hyper parameter order obtain reliable domain search best solution. research reveals important phenomenon complex systems i.e. global optimal solution best solution problem considered. still several open topics application canonical duality theory radial basis error functions. example kinds analyzed like multi quadratic multi quadratic inverse functions development future research expand dimensional case multidimensional case also considering variable parameter. case analyzed able realize neural networks based canonical duality theory.", "year": 2013}