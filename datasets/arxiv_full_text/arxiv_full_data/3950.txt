{"title": "Analysis of Estimation of Distribution Algorithms and Genetic Algorithms  on NK Landscapes", "tag": ["cs.NE", "cs.AI", "I.2.6; I.2.8; G.1.6"], "abstract": "This study analyzes performance of several genetic and evolutionary algorithms on randomly generated NK fitness landscapes with various values of n and k. A large number of NK problem instances are first generated for each n and k, and the global optimum of each instance is obtained using the branch-and-bound algorithm. Next, the hierarchical Bayesian optimization algorithm (hBOA), the univariate marginal distribution algorithm (UMDA), and the simple genetic algorithm (GA) with uniform and two-point crossover operators are applied to all generated instances. Performance of all algorithms is then analyzed and compared, and the results are discussed.", "text": "study analyzes performance several genetic evolutionary algorithms randomly generated ﬁtness landscapes various values large number problem instances ﬁrst generated global optimum instance obtained using branch-and-bound algorithm. next hierarchical bayesian optimization algorithm univariate marginal distribution algorithm simple genetic algorithm uniform two-point crossover operators applied generated instances. performance algorithms analyzed compared results discussed. missouri estimation distribution algorithms laboratory department mathematics computer science university missouri–st. louis university blvd. louis e-mail medalcs.umsl.edu http//medal.cs.umsl.edu/ study analyzes performance several genetic evolutionary algorithms randomly generated ﬁtness landscapes various values large number problem instances ﬁrst generated global optimum instance obtained using branch-and-bound algorithm. next hierarchical bayesian optimization algorithm univariate marginal distribution algorithm simple genetic algorithm uniform two-point crossover operators applied generated instances. performance algorithms analyzed compared results discussed. ﬁtness landscapes introduced kauﬀman tunable models rugged ﬁtness landscape. landscape function deﬁned binary strings ﬁxed length characterized parameters overall number bits neighborhood size. neighbors speciﬁed function given determines ﬁtness contribution neighbors. usually function given lookup table size neighbors well subfunction lookup tables initialized randomly way. landscapes np-complete although variants landscapes polynomially solvable exist approximation algorithms cases nonetheless landscapes remain challenge optimization algorithm also interesting perspective complexity theory computational biology; since inception landscapes attracted researchers areas paper presents in-depth empirical performance analysis various genetic evolutionary algorithms landscapes varying value large number problem instances ﬁrst generated. then branch-and-bound algorithm applied instances provide guaranteed global optimum instance. although application branch bound limits size problems study primary goals ensure able verify global optimum instance every algorithm considered study. several genetic evolutionary algorithms applied generated problem instances performance analyzed compared. speciﬁcally consider hierarchical bayesian optimization algorithm univariate marginal distribution algorithm simple genetic algorithm bit-ﬂip mutation uniform two-point crossover operator. additionally without crossover considered. results provide insight diﬃculty landscapes respect parameters performance diﬀerences compared algorithms. several interesting avenues future work outlined. paper starts describing landscapes branch-and-bound algorithm used verify global optima generated landscapes section section outlines compared algorithms. section presents experimental results. section discusses future work. finally section summarizes concludes paper. section describes landscapes method generate random problem instances landscapes. additionally section describes branch-and-bound algorithm used obtain global optima problem instances considered paper. branch bound complete algorithm thus guaranteed true global optimum; especially useful scalability experiments performance analyses diﬀerent evolutionary algorithms. nonetheless branch bound requires exponential time thus size instances solve practical time severely limited. diﬃculty optimizing landscapes depends four components deﬁning problem instance. useful approach analyzing complexity landscapes focus inﬂuence problem complexity. landscapes simple unimodal functions similar onemax binint solved linear time easy practically genetic evolutionary algorithm. global optimum landscapes obtained polynomial time even hand problem ﬁnding global figure branch bound traverses recursion tree level sets value leaf thus corresponds instance bits. subtrees lead solutions cannot improve best-so-far solution improve eﬃciency. optimum unrestricted landscapes np-complete problem becomes polynomially solvable dynamic programming even neighbors restricted adjacent string positions subfunctions generated according distributions unrestricted landscapes polynomial-time approximation algorithm exists approximation threshold typically neighbors well lookup tables deﬁning subfunctions generated randomly. paper string position ﬁrst generate random neighbors string position except selected equal probability. then lookup table deﬁning generated using uniform distribution consequently studied class landscapes np-complete since case extremely simple solve considered speciﬁcally considered step study scalability various evolutionary algorithms considered range values minimum value maximum value bounded mainly available computational resources scope empirical analysis. basic idea branch bound recursively explore possible binary strings bits using recursion tree level corresponds bits subtrees level correspond diﬀerent values corresponding level. make algorithm eﬃcient subtrees proven lead solution better best-so-far solution found. cannot eliminate exponential complexity expected np-completeness landscapes signiﬁcantly improves performance algorithm allows solve much larger problem instances complete recursion tree explored. branch-and-bound procedure illustrated ﬁgure bit-ﬂip mutation several random restarts locate high-quality local optima. best discovered optima used best-so-far solution branch-and-bound algorithm started. branch-and-bound approach used paper bits assigned sequentially although reordering bits might improve performance conditions. bits assumed ﬁxed values deﬁned path root recursion tree current node. solution found already higher ﬁtness maximum possible value processing currently processed node continue remaining unexplored parts recursion tree explored exception parts already cut. also tried another variant branch-and-bound algorithm best value objective function computed incrementally subsets containing ﬁrst bits approach eﬃcient solving instances sherrington-kirkpatrick spin glass model landscapes algorithm described earlier performed eﬃciently. aforedescribed branch-and-bound algorithm complete thus guaranteed global optimum problem instance. nonetheless complexity branch bound expected grow exponentially fast solving large instances becomes intractable algorithm. example proposed branch-and-bound algorithm fast enough solve thousand unique instances algorithm fast enough deal instances size evolutionary algorithms presented next section capable reliably solving larger instances convergence global optimum cannot guaranteed; nonetheless section discusses extend study deal larger problem instances intractable branch-and-bound algorithm. section outlines optimization algorithms discussed paper hierarchical bayesian optimization algorithm univariate marginal distribution algorithm genetic algorithm additionally section describes deterministic hill climber incorporated compared algorithms improve performance. compared algorithms candidate solutions represented binary strings bits niching technique called restricted tournament replacement used eﬀective diversity maintenance. genetic algorithm evolves population candidate solutions typically represented ﬁxed-length binary strings. ﬁrst population generated random. iteration starts selecting promising solutions current population. binary tournament selection. solutions created applying variation operators population selected solutions. speciﬁcally crossover used exchange bits pieces pairs candidate solutions mutation used perturb resulting solutions. uniform two-point crossover bit-ﬂip mutation ensure eﬀective diversity maintenance candidate solutions univariate marginal distribution algorithm also evolves population candidate solutions represented ﬁxed-length binary strings initial population generated random. iteration starts selecting population promising solutions using common selection method genetic evolutionary algorithms; binary tournament selection. then probability vector learned stores proportion position selected population. candidate solution probability equal proportion position; otherwise consequently variation operator umda preserves proportions position decorrelating diﬀerent string positions. candidate solutions incorporated original population using rtr. terminated termination criteria met. umda estimation distribution algorithm edas—also called probabilistic model-building genetic algorithms iterated density estimation algorithms —replace standard variation operators genetic algorithms crossover mutation building probabilistic model promising solutions sampling built model generate candidate solutions. diﬀerence umda selected solutions processed generate solutions. hierarchical bayesian optimization algorithm also basic procedure hboa similar umda variant described earlier. however model promising solutions sample solutions bayesian networks local structures used instead simple probability vector umda. similarly considered umda variants candidate solutions incorporated original population using terminated termination criteria met. deterministic hill climber incorporated umda hboa improve performance. takes candidate solution represented n-bit binary string input. then performs one-bit changes solution lead maximum improvement solution quality. terminated single-bit improves solution quality solution thus locally optimal. here used improve every solution population evaluation performed. section describes experiments presents experimental results. first problem instances experimental setup discussed. next analysis hboa umda several variants presented. finally algorithms compared results comparisons discussed. instances step studied. restriction problem size eﬃciency branch-and-bound algorithm complexity grew fast considered step considered step considered step considered step ﬁnally considered step combination generated random problem instances instance used branch-and-bound algorithm locate global optimum. then applied hboa umda several variants instances collected empirical results subsequently analyzed. means overall unique problem instances generated tested every algorithm included study. select promising solutions binary tournament selection used. solutions incorporated population using window size min{n suggested ref. hboa bayesian networks decision trees used models evaluated using bayesian-dirichlet metric likelihood equivalence penalty model complexity variants bit-ﬂip mutation probability ﬂipping common crossover operators considered two-point uniform crossover. crossover operators probability applying crossover emphasize importance using crossover results without crossover also included bit-ﬂip mutation used. stochastic hill climber bit-ﬂip mutation also considered initial stage performance algorithm inferior compared algorithm included comparison intractable solve problem instances included comparison; results algorithm omitted. problem instance algorithm adequate population size approximated bisection method estimates minimum population size required reliable convergence optimum. here bisection method ﬁnds adequate population size algorithms optimum independent runs. terminated global optimum found. results problem instance comprise following statistics population size number iterations number evaluations number ﬂips dhc. value observed statistics averaged random instances. since instance successful runs performed algorithm results averaged successful runs. overall algorithm results correspond successful runs total unique problem instances. figure shows average performance statistics hboa problem instances expected performance hboa gets worse increasing speciﬁcally population size number iterations number evaluations number ﬂips appear grow exponentially ﬁxed time complexity appears grow slightly faster polynomially regardless whether measured number evaluations number ﬂips. figure shows average performance statistics umda. similarly hboa time complexity umda grows exponentially fast growth ﬁxed appears slightly faster polynomial. figures show average performance statistics three variants. similarly hboa umda time complexity variants grows exponentially fast growth ﬁxed slightly faster polynomial. compare performance algorithms problem instance compute ratio number evaluations required number evaluations required analogically compute ratio number ﬂips required number ﬂips required then ratios averaged instances speciﬁc performs better computed ratios smaller performs ratios ﬁnally performs worse ratios greater comparison based aforementioned ratio computed pair algorithms studied work. make results easier read superior algorithm typically used second algorithm comparison ratios expected greater figure compares performance two-point crossover hboa. figure compares performance uniform crossover hboa. figure compares performance two-point crossover uniform crossover. finally ﬁgures compare performance without crossover. important trends observe results comparisons change cases algorithm outperforms another ratios problem size. cases although diﬀerences become signiﬁcant problem size increases. algorithm outperforms another small problems observed dynamics problem size expect situation reverse large problems. hboa. small values hboa outperformed algorithms included comparison increases situation changes rapidly. speciﬁcally larger hboa outperforms algorithms relative performance respect algorithms improves increasing problem size. larger favorably hboa compares algorithms. uniform crossover. uniform crossover performs better twopoint crossover umda regardless relative performance respect algorithms improves problem size. however mentioned above larger values uniform crossover outperformed hboa factor hboa outperforms uniform crossover grows problem size. two-point crossover. two-point crossover performs worse hboa uniform crossover larger values still outperforms umda respect number ﬂips important performance measure. crossover versus mutation. crossover proven outperform pure mutation clear results. first diﬃcult instances hboa—which pure selectorecombinative evolutionary algorithm explicit mutation—outperforms algorithms increasing second eliminating crossover signiﬁcantly decreases eﬃciency mutation-based approaches perform worst compared algorithms. figure comparison hboa two-point crossover respect number evaluations number ﬂips. comparison visualized average ratio number evaluations required two-point crossover number evaluations required hboa. greater ratio better performance hboa compared several interesting ways extending work presented paper. first problem instances generated work used analyzing performance optimization algorithms comparing diﬀerent optimization algorithms broad class problems tunable diﬃculty. second class problems considered study extended substantially using genetic evolutionary algorithms adequate settings solving instances unsolvable branch bound. although global optimum would longer guaranteed methods devised still guarantee global optimum found reliably. finally probability distributions generating problem instances considered provide insights diﬃculty various classes landscapes beneﬁts costs using alternative optimization strategies classes. paper presented in-depth empirical performance study several genetic evolutionary algorithms landscapes various values speciﬁcally algorithms considered work included hierarchical bayesian optimization algorithm univariate marginal distribution algorithm simple genetic algorithm bit-ﬂip mutation two-point uniform crossover. additionally bit-ﬂip mutation crossover considered. value large number instances generated solved branch-and-bound algorithm complete algorithm guaranteed figure comparison hboa uniform crossover respect number evaluations number ﬂips. comparison visualized average ratio number evaluations required uniform crossover number evaluations required hboa. greater ratio better performance hboa compared figure comparison hboa umda respect number evaluations number ﬂips. comparison visualized average ratio number evaluations required umda number evaluations required hboa. greater ratio better performance hboa compared umda. figure comparison two-point crossover umda respect number evaluations number ﬂips. comparison visualized average ratio number evaluations required umda number evaluations required two-point crossover. greater ratio better performance compared umda. figure comparison uniform crossover umda respect number evaluations number ﬂips. comparison visualized average ratio number evaluations required umda number evaluations required uniform crossover. greater ratio better performance compared umda. figure comparison uniform two-point crossover respect number evaluations number ﬂips. comparison visualized average ratio number evaluations required two-point crossover number evaluations required uniform crossover. greater ratio better performance uniform crossover compared two-point crossover. figure comparison uniform crossover crossover respect number evaluations number ﬂips. comparison visualized average ratio number evaluations required without crossover number evaluations required uniform crossover. greater ratio better performance uniform crossover compared mutation only. figure comparison two-point crossover crossover respect number evaluations number ﬂips. comparison visualized average ratio number evaluations required without crossover number evaluations required two-point crossover. greater ratio better performance two-point crossover compared mutation only. main contributions work summarized follows. first landscapes represent important class test problems despite practically work using advanced estimation distribution algorithms landscapes. work provides many experimental results advanced simple shows advanced edas signiﬁcantly outperform genetic evolutionary algorithms landscapes larger values second studies concerned landscapes verify global optimum considered problem instances thus often diﬃcult interpret results evaluate importance. study global optimum instance veriﬁed complete branch-and-bound algorithm. third diﬃculty landscapes expected vary substantially instance instance studies presented past used limited sample problem instances; provide in-depth study unique problem instances considered. finally results paper based evolutionary algorithm; instead consider several qualitatively diﬀerent evolutionary algorithms providing insight comparison genetic algorithms edas well comparison mutation-based recombination-based evolutionary algorithms. project sponsored national science foundation career grant force oﬃce scientiﬁc research force materiel command usaf grant fa--- university missouri louis high performance computing collaboratory sponsored information technology services research award research board programs. u.s. government authorized reproduce distribute reprints government purposes notwithstanding copyright notation thereon. opinions ﬁndings conclusions recommendations expressed material authors necessarily reﬂect views national science foundation force oﬃce scientiﬁc research u.s. government. experiments done using hboa software developed martin pelikan david goldberg university illinois urbana-champaign experiments performed beowulf cluster maintained university missouri louis.", "year": 2008}