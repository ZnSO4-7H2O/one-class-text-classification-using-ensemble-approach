{"title": "Spectral-Spatial Classification of Hyperspectral Image Using  Autoencoders", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Hyperspectral image (HSI) classification is a hot topic in the remote sensing community. This paper proposes a new framework of spectral-spatial feature extraction for HSI classification, in which for the first time the concept of deep learning is introduced. Specifically, the model of autoencoder is exploited in our framework to extract various kinds of features. First we verify the eligibility of autoencoder by following classical spectral information based classification and use autoencoders with different depth to classify hyperspectral image. Further in the proposed framework, we combine PCA on spectral dimension and autoencoder on the other two spatial dimensions to extract spectral-spatial information for classification. The experimental results show that this framework achieves the highest classification accuracy among all methods, and outperforms classical classifiers such as SVM and PCA-based SVM.", "text": "bstract‚Äîhyperspectral image classification topic remote sensing community. paper proposes framework spectral-spatial feature extraction classification first time concept deep learning introduced. specifically model autoencoder exploited framework extract various kinds features. first verify eligibility autoencoder following classical spectral information based classification autoencoders different depth classify hyperspectral image. proposed framework combine spectral dimension autoencoder spatial dimensions extract spectral-spatial information classification. experimental results show framework achieves highest classification accuracy among methods outperforms classical classifiers pca-based svm. combining imaging spectroscopy technology hyperspectral remote sensing spatially spectrally continuous data simultaneously. hyperspectral imagery becoming valuable tool monitoring earth‚Äôs surface successfully exploited hyperspectral image yield higher classification accuracies detailed class taxonomies traditional classification methods uses spectral information only classification algorithms typically include parallelepiped classification k-nearest-neighbors maximum likelihood minimum distance logistic regression since classification deals problem high-dimensional feature space number labeled data majority algorithms suffer curse dimensionality. tackle problem scholars remote sensing community introduce variety feature extraction methods like sequential forward floating search wavelet analysis however methods bring significant improvement classification cases resulting accuracies even fall direct-classification approaches. however large marginal machines like deals well fitting problem. cases based methods obtain better classification accuracy widely used pattern recognition techniques data introduced field feature extraction seldom used applying based method original data becomes state-of-the-art method classification. however ways generally used methods applied thing common deal spectral information pixel only. recently resolution imaging spectrometer burgeons spatial information seems growing important improving classification accuracy. recently methods proposed incorporating spatial information like mathematical morphology thread recent advantages training multilayer neural networks refurbished best records wide variety machine learning problems including classification regression tasks involve processing image language speech typical deep neural network architectures include deep belief networks deep boltzmann machines stacked autoencoders stacked denoising autoencoders layer-wise training framework bunch alternatives like restricted boltzmann machines pooling units convolutional neural networks autoencoders paper introduce deep learning based feature extraction classification first time. work focuses applying aforementioned models autoencoders learn representations hyperspectral image data unsupervised manner. since hidden layer activities exploited features initial data called representations neural network vocabulary word representation instead feature rest paper. methods exploit single-layer autoencoder multi-layer stacked autoencoder extract shallow deep representations hyperspectral image data respectively. propose extracting spectral-spatial representation classification. representations exploited deal classification problems. effectiveness methods verified classification accuracy. rest paper organized four sections. section description hyperspectral image classification task dealing with terse introduction autoencoder models used paper. section details extract various representations novel architecture. subsequent classification conducted logistic regression svm. section deals experimental results. finally section summarizes observations point probable future works complete paper. typical scene hyperspectral image covers several square kilometers lands hundreds spectral channels instead channels shown result task classifying hyperspectral image unique characters. unique that instead giving label whole image hyperspectral image classification task pixel-based arrange label pixel scene according spectral information provided hundreds spectral channels. autoencoder visible layer inputs hidden layer units activation function training first maps input ùë•ùúñùëÖùëë hidden layer latent representation ùë¶ùúñùëÖ‚Ñé; mapped output layer size input layer called reconstruction. reconstruction denoted ùëßùúñùëÖùëë figure single layer autoencoder classification. model learns hidden representation input reconstructing corresponding parameters denoted network. denotes input-to-hidden hidden-to-output weights respectively denotes bias hidden output units denotes activation function apply element-wise arguments. goal training minimize error input reconstructed input i.e. introduce stacked autoencoder help compute deep representations spectral data. multiple layers autoencoders yields deep representation input data output last layer. trained layer-wise manner. finish training former layer parameters subsequent layer trained according output previous layer. stacking input-to-hidden layers sequentially constructs stacked autoencoder. methods involve feature extraction classification. first compute representations autoencoder deem feature data construct classifier neural network finish classification phase. section focuses varieties features extracted incorporated classification. classical classification exploits spectral information only first propose kinds classification schemes exploiting shallow deep representations spectra respectively. last part section propose novel classification framework exploits spectral spatial information. +ùëí‚àíùë•. first-order second-order derivative special forms brings convenience computing ùëì]]. reduce number parameters tied weights training autoencoder i.e. there‚Äôs groups parameters remaining learn choose cross entropy cost function here accordance sigmoid output. implementation cost computed minibatch inputs since adopt minibatch update strategy large dataset. denotes input vector size denotes minibatch size. denotes ùëò-th element ùëñ-th input minibatch. inner summation input dimension outer whole minibatch. hope turns optimize using minibatch stochastic gradient descent. we‚Äôll derive partial differentials cost respect parameters first rewrite reconstruction scalar form exist motivations extract robust deep spectral representations. first complex situation lightening large scene objects class show different spectral characters different location. example lawn exposed direct sunshine shows different spectral characters lawn eclipsed sunshine high building. also scattering peripheral ground objects tilts spectra lawn change characters too. factors involve rotations sensor different atmospheric scattering condition according factors probability distribution certain class hard one-hot variations multiple directions feature space. complex variations spectra make hopeless analyze pixel pixel affected tangent pixels complicated real situation thus demand robust invariant features. believed deep architectures potentially lead progressively abstract features higher layers representation abstract features generally invariant local changes input generally invariant representations tackle problems stacked autoencoder corresponding deep spectral representations suitable problem. introduce stacked autoencoder help deep representations spectral data logistic regression classifier stacked autoencoder reach high classification accuracy. shows typical instance deep architecture used paper. first layer autoencoder maps inputs layer first layer representation layer trained manner aforementioned single layer autoencoder. logistic regression soft-max output layer activation output layer size total number classes. since implemented single-layer neural network merged former layers network. fitting classifier conducted whole architecture slight learning rates former layer autoencoders. figure classifying deep spectral representation. instance classification scheme shown layers input layer hidden layers autoencoders output layer logistic regression. unlike spectral-spatial information extraction methods tangent neighbors simple filtering deep framework takes pixels flat neighbor region consideration autoencoders learn representation itself. overall flowchart proposed method detailed first neighbor region certain pixel extracted original image. hundreds channels along spectral dimension data initial layer always tens thousands dimensions. large neighbor region result large input dimension classifier contains large amount redundancy. second layer introduced condense spectral information thus reducing data dimension acceptable scale reserve spatial information meantime. since mainly care incorporating spatial information method along spectral dimension retain first principle components. transformation matrix fitted whole image tagged untagged pixels. step cast away part spectral information since conducted within pixels spatial information remains intact. figure spectral-spatial representation extraction scheme. first step procesing compressing spectral dimension flatening data autoencoders introduced extract layer-wise deep representations. subsequent layers include layer-wise training autoencoders fine-tune whole model final logistic regression layer. steps similar former subsection deals deep spectral representation thus would repeat describing here. study hyperspectral images different environmental settings applied validate proposed autoencoder-based classification method. first mixed vegetation site kennedy space center florida land cover categories spectral channels. water absorption existence signal-noise ratio channels used experiments. pixels pixels labeled. second urban site city pavia italy land cover classes spectral channels. spatial size pixels labeled. experiments three-folded using aforementioned three methods respectively. data regularized interval feeding classifiers. conduct experiments ubuntu system intel processor cores .ghz. codes implemented using theano python library symbolic computation. implementations scikit-learn python machine learning package. since single layer autoencoder important building block methods proposed paper first inspect well input reconstructed epochs give resulting classification accuracies examine sample different training epochs. examined autoencoder hidden units trained data. shown autoencoder restitutes really perfect reconstruction several hundreds iterating epochs fig. shows classification performance autoencoders different sizes hidden layers ranging data pavia respectively. although hidden layer sizes range widely performance corresponding autoencoder-based always outperforms direct applying abundant number iterations. however accept feature extraction step conduct matter many principle components incorporated performances pca-svm never better direct svm. experiments show autoencoders help improving classification performance. addition unlike multilayer perceptron result sensitive number hidden units. figure ae-svm performance w.r.t. training epochs data pavia data. appropriately large iteration epochs autoencoder convergr useful representations svm. shown figures e-svms show considerable sensitivity hidden layer size. tried several stacked autoencoders different depths compare results traditional methods. data spectral channels hidden layer size plus logistic regression layer stacked autoencoder. neural networks constructed --‚Ä¶--. pavia dataset spectral channels classes performance reaches best using hidden layers size. neural networks like --‚Ä¶--. hidden layer numbers table correspond number -sized layers deep neural network. experiments show depth help descending classification error rate. comparison conduct traditional methods plugged feature extraction data. shown significant gain accuracies images. directly apply spectral-spatial information error rate unacceptably high shown table methods confirm kind representation also provides abundant information classification. former principle components neighbor region reach error rate data pavia data. classifiers control groups former subsection conducted pca-compressed data. however traditional methods fail yielding good enough accuracy; proposed method succeeds finding correct features dataset yields highest accuracies. experiments first confirm autoencoder-extracted representations help lowering error rate classical classifier previously considered state-of-the-art field. shown autoencoders sensitive hidden unit number. what‚Äôs more impact depth representation classifying hyperspectral images also inspected experiments suggest deeper representations always lead better classification accuracies. spectral-spatial information based classification proposed deep framework performs well succeeded classifying hyperspectral images highest accuracies. future work involves incorporating kinds deep learning models framework improve classification accuracy. ying yanfeng zhang hyperspectral feature extraction using selective based genetic algorithm subgroups innovative computing information control first international conference j.a. benediktsson \"classification feature extraction remote sensing images urban areas based morphological approaches\" ieee trans. geosci. remote sens. vol.", "year": 2015}