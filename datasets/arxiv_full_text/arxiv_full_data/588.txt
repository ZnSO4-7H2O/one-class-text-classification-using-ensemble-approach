{"title": "Segmental Recurrent Neural Networks for End-to-end Speech Recognition", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "We study the segmental recurrent neural network for end-to-end acoustic modelling. This model connects the segmental conditional random field (CRF) with a recurrent neural network (RNN) used for feature extraction. Compared to most previous CRF-based acoustic models, it does not rely on an external system to provide features or segmentation boundaries. Instead, this model marginalises out all the possible segmentations, and features are extracted from the RNN trained together with the segmental CRF. In essence, this model is self-contained and can be trained end-to-end. In this paper, we discuss practical training and decoding issues as well as the method to speed up the training in the context of speech recognition. We performed experiments on the TIMIT dataset. We achieved 17.3 phone error rate (PER) from the first-pass decoding --- the best reported result using CRFs, despite the fact that we only used a zeroth-order CRF and without using any language model.", "text": "approaches proposed demonstrated promising results. particular connectionist temporal classiﬁcation approach deﬁnes loss function directly maximise conditional probability output sequence given input sequence usually uses recurrent neural network extract features. however simpliﬁes sequence-level error function product frame-level error functions means essentially still frame-level classiﬁcation. also requires lengths input output sequence same inappropriate speech recognition. deals problem replicating output labels consecutive frames correspond output label blank token. attention-based rnns demonstrated powerful alternative sequence-to-sequence transducer e.g. machine translation speech recognition difference model hmms ctcs attention-based approach apply conditional independence assumption input sequence. instead maps variable-length input sequence ﬁxed-size vector representation decoding step attention-based scheme explanation). generates output sequence using conditioned vector representation source sequence. attentive scheme suits machine translation task well clear alignment source target sequence many language pairs. however approach naturally apply speech recognition task output token corresponds small size window acoustic spectrum. paper study segmental rnns acoustic modelling. model similar attention-based sense encoder also used feature extraction differs sense sequence-level conditional probability deﬁned using segmental extension standard numerous works crfs variants speech recognition overview). particular feed-forward neural networks used segmental crfs speech recognition however segmental rnns different endto-end models depend external systems provide segmentation boundaries features instead trained marginalising possible segmentations features derived encoder rnns trained jointly segmental crfs. experiments performed timit dataset achieved ﬁrst-pass decoding zeroth-order without using language model best reported result using crfs. study segmental recurrent neural network end-to-end acoustic modelling. model connects segmental conditional random ﬁeld recurrent neural network used feature extraction. compared previous crf-based acoustic models rely external system provide features segmentation boundaries. instead model marginalises possible segmentations features extracted trained together segmental crf. essentially model self-contained trained end-to-end. paper discuss practical training decoding issues well method speed training context speech recognition. performed experiments timit dataset. achieved phone error rate ﬁrst-pass decoding best reported result using crfs despite fact used zeroth-order without using language model. index terms end-to-end speech recognition segmental recurrent neural networks. speech recognition typical sequence sequence transduction problem i.e. given sequence acoustic observations speech recognition engine decodes corresponding sequence words phonemes. component speech recognition system acoustic model computes conditional probability output sequence given input sequence. however directly computing conditional probability challenging many factors including variable lengths input output sequences. hidden markov model converts sequence-level classiﬁcation task frame-level classiﬁcation problem acoustic frame classiﬁed hidden states output sequence corresponds sequence hidden states. make computationally tractable hmms usually rely conditional independence assumption ﬁrst-order markov rule well-known weaknesses hmms furthermore hmm-based pipeline composed relatively independent modules makes joint optimisation nontrivial. consistent research effort seek architectures replace hmms overcome limitation acoustic modelling e.g. however approaches improved speech recognition accuracy hmms. past years several neural network based equal contribution. renals funded epsrc programme grant ep/i/ natural speech technology research data collection accessed http//datashare.is.ed.ac.uk/handle//. speech recognition segmentation labels usually unknown training model maximising conditional probability therefore practical. problem addressed deﬁning loss function negative marginal log-likelihood however number possible segmentations exponential length makes naive computation impractical. fortunately addressed using following dynamic programming algorithm proposed ﬁrst summation possible segmentation timestep second summation possible labels vocabulary. computation cost algorithm size vocabulary. cost reduced introducing upper bound segment length case rewritten segmental recurrent neural networks segmental conditional random fields given sequence acoustic frames {x··· corresponding sequence output labels {y··· segmental conditional random ﬁeld deﬁnes sequence-level conditional probability auxiliary segment labels {e··· denotes feature function weight vector. previous works crf-based acoustic models mainly heuristically handcrafted feature function also usually rely external system provide segment labels. paper deﬁne using neural networks segmentation marginalised training makes model self-contained. feature representations neural networks deﬁne feature function maps acoustic segment corresponding label joint feature space. speciﬁcally ﬁrstly represented one-hot vector mapped continuous space linear embedding matrix corresponds layer multiple layers linear non-linear transformation. fact ﬂexible include relevant features additional inputs function e.g. duration feature obtained converting another embedding vector. practice multiple layers used transform acoustic signal extracting segment embedding vector table results hierarchical subsampling networks. denote dimension eqs. respectively. layers denotes number lstm layers hidden dimension lstm cells. reduced dimension lstm output computational reasons. conc short concatenating operation. joint maximization algorithm yield high search error considers segmentation. future shall investigate beam search algorithm yield lower search error. computationally expensive rnns model long sequences number possible segmentations exponential length input sequence mentioned before. computational cost signiﬁcantly reduced using hierarchical subsampling shorten input sequences subsampling layer takes window hidden states lower layer input shown figure work consider three variants concatenate hidden states subsampling window concatenated next layer; hidden states added vector next layer; skip last hidden state window kept others skipped. last schemes computationally cheaper introduce extra model parameters. used timit dataset evaluate segmental acoustic models. dataset preferred rapid evaluation different system settings comparison end-to-end systems. followed standard protocol timit dataset experiments based kaldi recipe used core test evaluation utterances. used dimensional ﬁterbanks delta double-delta coefﬁcients yielding dimensional feature vectors. models trained phonemes predictions converted phonemes scoring. dimension ﬁxed experiments used long short-term memory networks implementation rnns networks always bi-directional. initial learning rate exponentially decay learning rate factor validation error stopped decreasing. models trained dropout again limit length possible segments given loss function minimised using stochastic gradient decent algorithm similar training neural network models. losses example hinge considered future work. regularisation using speciﬁc implementation recurrent networks dropout rate unless speciﬁed otherwise. models randomly initialised random seed. ﬁrst demonstrate results hierarchical subsampling recurrent network speed experiments. size subsampling window therefore subsampling layer reduced time resolution factor maximum segment length milliseconds corresponded frames fbanks layers subsampling recurrent networks time resolution reduced factor value reduced yielding around times speedup shown table table compares three implementations recurrent subsampling network detailed section observed concatenating hidden states subsampling window yield lower phone error rate using simple skipping approach fact timit dataset small prefers smaller model. hand adding hidden states subsampling window together worked even worse possibly sequential information subsampling window ﬂattened. following experiments sticked skipping method using subsampling layers. evaluated model tuning hyperparameters results given table tuned number lstm layers dimension lstm cells well dimensions segment vector general larger models dropout regularisation yielded higher recognition accuracy. best result obtained using layers dimensional lstms. however without dropout regularisation model easily overﬁt small size training set. future shall evaluate model large dataset. table comparison related works. denotes language model denotes speaker-dependent transform. hmm-dnn baseline trained cross-entropy using kaldi recipe. sequence training improve small amount data. note transducer attention-based equipped built-in rnnlms. evaluated another types features using system conﬁguration achieved best result table increased number fbanks yielded slightly lower per. also evaluated standard kaldi features dimensional mfccs spliced context window followed mllt transform feature-space speaker-dependent mllr features used hmm-dnn baseline table well-engineered features improved accuracy system absolute. table compare result reported results using segmental crfs well recent end-to-end systems. previous state-of-the-art result using segmental crfs timit dataset reported ﬁrst-pass decoding used prune search space second-pass used re-score hypothesis using various features including neural network features. besides ground-truth segmentation used achieved considerably lower ﬁrstpass decoding despite fact zeroth-order language model. furthermore results also comparable attentionbased end-to-end systems. accuracy segmental rnns improved using higher-order crfs incorporating language model decode step using beam search reduce search error. paper present segmental novel acoustic model combines segmental encoder end-to-end speech recognition. discuss practical training decoding algorithms model speech recognition subsampling network reduce computational cost. experiments performed timit dataset achieved strong recognition accuracy using zeroth-order without using language model. future shall investigate discriminative training criteria incorporating language model decoding step. future works also include implementing weighted ﬁnite sate transducer based decoder scaling model large vocabulary datasets. povey ghoshal boulianne burget glembek goel hannemann motlıcek qian schwarz silovsk´y semmer vesel´y kaldi speech recognition toolkit proc. asru srivastava hinton krizhevsky sutskever salakhutdinov dropout simple prevent neural networks overﬁtting journal machine learning research vol. recurrent neural network regularization arxiv preprint arxiv. ostendorf digalakis kimball from hmm’s segment models uniﬁed view stochastic modeling speech recognition ieee transactions speech audio processing kong dyer smith segmental recurrent neural networks arxiv preprint arxiv. sarawagi cohen semi-markov conditional random ﬁelds information extraction advances neural information processing systems zweig nguyen compernolle demuynck atlas clark speech recognition segmental conditional random ﬁelds summary clsp summer workshop proc. icassp. ieee", "year": 2016}