{"title": "Multi-kernel learning of deep convolutional features for action  recognition", "tag": ["cs.CV", "stat.ML"], "abstract": "Image understanding using deep convolutional network has reached human-level performance, yet a closely related problem of video understanding especially, action recognition has not reached the requisite level of maturity. We combine multi-kernels based support-vector-machines (SVM) with a multi-stream deep convolutional neural network to achieve close to state-of-the-art performance on a 51-class activity recognition problem (HMDB-51 dataset); this specific dataset has proved to be particularly challenging for deep neural networks due to the heterogeneity in camera viewpoints, video quality, etc. The resulting architecture is named pillar networks as each (very) deep neural network acts as a pillar for the hierarchical classifiers. In addition, we illustrate that hand-crafted features such as improved dense trajectories (iDT) and Multi-skip Feature Stacking (MIFS), as additional pillars, can further supplement the performance.", "text": "curacy deep neural networks video classiﬁcation. videos unlike still images short long temporal correlations attributes single frame convolutional neural network fail discover. therefore ﬁrst hurdle designing recurrent networks feedforward networks learn latent temporal structure. nonetheless much progress devising novel neural network architecture since work another problem large storage memory requirement analysing moderately sized video snippets. requires relatively larger computing resource train ultra deep neural networks learn subtleties temporal correlations given varying lighting camera angles pose etc. also difﬁcult utilise classical image augmentation techniques video stream. additionally video-based features evolve dynamics across several orders time-scales. long list technical difﬁculties problem semantic i.e. whether classiﬁcation/labelling/captioning lead understanding video snippet? improve upon existing technology combining inception networks resnets using support-vectormachine classiﬁer combined multi-kernel setting yield best knowledge increased performance hmdb data-set notably work makes following contributions introduce pillar networks deep well wide enabling horizontal scalability. important production quality video analytics framework operate constraints computational time. hmdb- dataset wide variety heterogeneity camera angle video quality pose etc. given framework higher accuracy dataset methodology applicable datasets similar statistical heterogeneity embedded them. image understanding using deep convolutional network reached human-level performance closely related problem video understanding especially action recognition reached requisite level maturity. combine multi-kernels based support-vector-machines multi-stream deep convolutional neural network achieve close state-of-the-art performance -class activity recognition problem speciﬁc dataset proved particularly challenging deep neural networks heterogeneity camera viewpoints video quality etc. resulting architecture named pillar networks deep neural network acts pillar hierarchical classiﬁers. addition illustrate hand-crafted features improved dense trajectories multi-skip feature stacking additional pillars supplement performance. video understanding computer vision problem attracted deep-learning community notably usage two-stream convolutional network framework uses deep convolutional neural network extract static features well motion cues another network deconstructs optic-ﬂow given video clip. notably plenty work utilising different types network architectures factorising optical-ﬂow based features. example inception network uses convolutions inception block estimate cross-channel corrections followed estimation cross-spatial cross-channel correlations. residual network hand learns residuals inputs pre-trained imagenet dataset. temporal stream stacks optical images using pre-training protocol suggested feature size resnet network ﬁxed details network pre-training construction etc. please refer follow generating fisher encoded improved dense trajectory features. first tracking points created median ﬁltering dense optical ﬁeld frames. compute descriptors trajectory histogram oriented gradients histogram optical motion boundary histograms descriptors within space-time volume aligned trajectory encode motion information; fisher encoding applied local descriptors generate video representation classiﬁcation. similar fisher encoded instead using feature points extracted one-time scale multi-skip feature stacking extracts stacks feature points multiple time skips encoding fisher vector. mifs achieves shift-invariance frequency domain captures longer range action indicators recapturing information coarse scales. basis second stage classiﬁcation methodology rests maximum margin classiﬁer support vector machine given training tuples weights hinge loss solves primal problem customary kernel methods computations involving handled using kernel functions experiments radial basis function based kernel used. penalty parameter slack variable. section describe dataset network architectures multi-kernel learning based supportvector-machine setup utilise fourstream dcnn pillar network activity recognition. refer readers original network architectures technical details. report results here classiﬁcation methodologies like adaboost gradient boosting random forests etc. classiﬁcation accuracy range dataset either optic-ﬂow based features. dataset hmdb dataset action classiﬁcation dataset comprises video clips divided action classes. although much larger ucf-sports dataset exists action classes hmdb proven challenging. video ﬁlmed using variety viewpoints occlusions camera motions video quality etc. anointing challenges video-based prediction problems. second motivation behind using dataset lies fact hmdb storage compute requirement fulﬁlled modern workstation gpus alleviating deployment expensive cloud-based compute resources. experiments done intel xeon workstation nvidia titan gpus. original evaluation scheme report accuracy average three training/testing splits. inception layers extraction inception layer architecture described video divided segments short subsegment randomly selected segment preliminary prediction produced snippet. later combined form video-level prediction. inception batch normalisation network utilised spatial optic-ﬂow stream. feature size inception network ﬁxed details network pre-training construction etc. please refer residual layers extraction utilise network architecture proposed authors leverage recurrent networks convolutions temporally constructed feature matrices shown fig. instantiation truncate network yield features different features feed lstm network. spatial stream network takes images input resnet- feature extractor; resnet- spatial-stream convnet figure pillar network framework speciﬁc instantiation types networks namely resnets inception networks factorise static dynamic inputs obtained video. case speciﬁc deep tensors mifs multi-kernel learning framework. additional feature tensors learnt according speciﬁc need problem incorporated pillar. framework. utilising four networks yield four features tensors fused steps form single prediction feature tensors flow extracted output last connected layer dimension inception network resnet network. four separate svms trained feature tensors. results shown networks used inception resnet subsequently fuse multiple kernels learnt individual classiﬁers using semi-inﬁnite linear optimisation problem. average result three splits displayed contrast regularised regularised multiple kernel learnt formulating eqn. semi-inﬁnite linear programming problem. iteration solver ﬁrst instantiated obtain weighted support vectors; subsequently linear programming problem solved using mosek. fusing hand-crafted features mifs features generated dcnn performance pillar networks boosted. additional features take place ‘case-speciﬁc tensors’ figure apparent combining kernels various stages prediction process yields better accuracy. particularly confusion matrix suggests worst performing classes wave one’s hands confused walking throwing objects confused swinging baseball. unsurprisingly actions chewing confused eating action class. table compares method methods literature. notable mention ts-lstm temporal-inception methods form part framework here. short synergistically utilising multiple kernels boosts performance classiﬁcation framework enable state-of-the performance dataset. improvement using hand-crafted features i.e. mifs marginal. means commonly seen boost accuracy offered implicitly learnt combination features learnt inception resnet pillars. main contribution paper introduce pillar networks deep well wide enabling horizontal scalability. combining different methodologies allow reach state-of-the-art performance video classiﬁcation especially action recognition. utilised hmdb- dataset instead former proven difﬁcult deep networks heterogeneity image quality camera angles etc. well-known videos contain extensive long-range temporal structure; using different networks capture subtleties temporal structure absolute requirement. since network implements different non-linear transformation utilise learn deep features. utilising distributed architecture enables parcellate feature tensors computable chunks input svm-mkl classiﬁer. architectural choice therefore enables scale horizontally plugging variety networks requirement. used architecture video based classiﬁcation wide variety problems apply methodology speech processing natural-language-processing supplementary studies stacking features four network outputs softmax cross-entropy loss accuracy approximately highlighting necessity multi-kernel approach. thus framework rests stages training training neural networks training multiple kernels support vector machine since training stages decoupled allows scalability wherein different networks operate plug-and-play basis. indeed work combining deep neural networks svms facilitate end-to-end training would useful pillar networks perform immensely large datasets youtube-m data-set additionally recently published kinetics human action video dataset deepmind equally attractive pre-training pillar networks dataset ﬁnegrained training hmdb- invariably increase accuracy current network architecture.", "year": 2017}