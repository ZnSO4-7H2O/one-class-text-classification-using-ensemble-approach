{"title": "Inferring User Preferences by Probabilistic Logical Reasoning over  Social Networks", "tag": ["cs.SI", "cs.AI", "cs.CL", "cs.LG"], "abstract": "We propose a framework for inferring the latent attitudes or preferences of users by performing probabilistic first-order logical reasoning over the social network graph. Our method answers questions about Twitter users like {\\em Does this user like sushi?} or {\\em Is this user a New York Knicks fan?} by building a probabilistic model that reasons over user attributes (the user's location or gender) and the social network (the user's friends and spouse), via inferences like homophily (I am more likely to like sushi if spouse or friends like sushi, I am more likely to like the Knicks if I live in New York). The algorithm uses distant supervision, semi-supervised data harvesting and vector space models to extract user attributes (e.g. spouse, education, location) and preferences (likes and dislikes) from text. The extracted propositions are then fed into a probabilistic reasoner (we investigate both Markov Logic and Probabilistic Soft Logic). Our experiments show that probabilistic logical reasoning significantly improves the performance on attribute and relation extraction, and also achieves an F-score of 0.791 at predicting a users likes or dislikes, significantly better than two strong baselines.", "text": "popular approach draw knowledge help extract user preferences make collaborative ﬁltering typically applied structured data describing explicitly provided user preferences often enriched information social network methods thus combine information shared preferences attributes information social relations. many domains however user preferences user attributes explictly provided even explicit knowledge relations social network. cases ﬁrst need estimate latent attributes preferences resulting probabilistic estimates sources knowledge. reason user preferences given weak probabilistic sources knowledge users’ attributes preferences social ties? problem occurs domains like twitter knowledge users’ attitudes attributes social relations must inferred. propose infer user preferences domains like twitter without explicit information applying relational reasoning frameworks like markov logic networks probabilistic soft logic help infer relational rules. probabilistic logical systems able combine evidence probabilistically draw logical inference. example systems could learn individual probabilistic inference rules expressing facts like people work companies like electronic devices\" associated probability systems also able perform global inference entire network rules combining probabilistic information user attributes preference relations predict preferences users. algorithm stages. ﬁrst stage extract user attributes. unlike structured knowledge bases freebase wikipedia propositional knowledge describing attributes entities social networks sparse. although social media websites support structured data format personal attributes attributes still sparse since small proportion users particular proﬁle fact many sites provide all. hand users online social media frequently publish messages describing preferences activities often explicitly mentioning attributes religion education propose text extraction system abstract propose framework inferring latent attitudes preferences users performing probabilistic ﬁrst-order logical reasoning social network graph. method answers questions twitter users like user like sushi? user york knicks fan? building probabilistic model reasons user attributes social network inferences like homophily algorithm uses distant supervision semi-supervised data harvesting vector space models extract user attributes preferences text. extracted propositions probabilistic reasoner experiments show probabilistic logical reasoning signiﬁcantly improves performance attribute relation extraction also achieves f-score predicting users likes dislikes signiﬁcantly better strong baselines. extracting latent attitudes preferences users important goal practical applications like product recommendation targeted online advertising friend recommendation helping social scientists political analysts gain insights public opinion user behavior. permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights components work owned others must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. request permissions permissionsacm.org. copyright x-xxxxx-xx-x/xx/xx ..... twitter combines supervision semi-supervised data harvesting vector space models automatically extract structured proﬁles text users’ messages. based approach able construct comprehensive list personal attributes explicitly mentioned text user relations coverage user proﬁle information dramatically increased extracting information text users explicitly mention attributes. address this second stage work investigate whether possible extend coverage extracted user proﬁles inferring attributes explicitly mentioned text logical inference. finally feed extracted attributes relations relational reasoning frameworks including markov logic networks probabilistic soft logic infer relational rules among users attributes user relations allow predict user preferences. system described paper provides perspectives understanding predicting interests tendencies behaviors social media users everyday life. experiments limited dataset twitter techniques general easily adapted minor adjustments. major contributions paper summarized follows present attempt perform probabilistic logical framework estimates attributes online social framework combines probabilistic information user attributes preferences relations predict latent relations preferences. present large-scale user dataset speciﬁc task. next sections show user attributes relations preferences extracted text introduce probabilistic logical frameworks. algorithm results illustrated section given message streams twitter users ﬁrst task extract information user attributes relations preferences logical form; input global logical inference network. represent facts kinds propositional logic objects predicates functions. functions represent mappings object another object returning object capitalof=paris. predicates represent whether relation holds among objects return boolean value. example usra usrb friends twitter predicate isfriend true. predicates functions transformed other. given function wifeof=usrb predicate iscouple=true naturally hold. demonstrate later functions transformed predicates graph construction procedure. dataset random sample twitter users—after discarding users less tweets– consisting million twitter users. crawled published tweets network using twitgoal associate states united states user. signiﬁcant amount work inferring location given published tweet less focus user-level inference. paper employ rule-based approach user-location identiﬁcation. selected geo-tagged tweets speciﬁc user entity corresponds location current user satisﬁes following criteria designed ensure high-precision first user obtained full name google+ api. many google+ proﬁles publicly accessible many users explicitly list attributes education job. major challenge involved name disambiguation match users’ twitter accounts google+ accounts. adopted riend shared strategy taken percent least friends shared google+ circles twitter followers assume accounts point person. percent users’ education attributes ﬁnalized based google+ accounts. cases user names disambiguated relevant information obtained google+ turn system provided section system extracts education entities published twitter content user twitter user system returns education entity mentioned users tweets associated corresponding probability example since system system requires user explicitly mention education entities published content low-recall another percent users’ education attributes inferred system. many frameworks devoted gender prediction twitter posts studying whether high level tweet features help absence highly-predictive user name information. since limitations crawl tweets user. https//developers.google.com/+/api/ small property google+ accounts contain direct twitter links. cases accounts directly matched. goal guessing gender without names rather studying extent global probabilistic logical inference social network improve accuracy local predictors implement high-precision rule based approach uses national social security gender database ssgd contains ﬁrstname records annotated gender every birth since a.d. many names highly gender-speciﬁc others ambiguous. assign user gender his/her ﬁrst name appears dataset gender least times often other. using rule assign gender users dataset. user relations user-user relations consider work include friend spouse liveinsameplace friend twitter supports types following patterns following followed. consider people friends follow thus relation friend holds usra following followed usrb. friend relation extracted straightforwardly twitter network. spouse/boyfriend/girlfriend spouse relation turn al.’s system given twitter users published contents system returns score sspouse range indicating likely spouse relation hold. threshold pair users higher score continuous variable denote conﬁdence value computed linearly projecting sspouse space. liveinsameplace straightforwardly inferred location extraction approach described user preferences like dislike turn user preferences attitudes—a central focus work—and speciﬁcally predicates like dislike. like large literature sentiment analysis social media goal extract sentiment addition extract target object sentiment. work thus resembles work sentiment target extraction using supervised classiﬁers sequence models based manually-labeled datasets. unfortunately manually collecting training data task problematic tweets talking user likes/dislikes sparsely distributed among massive number topics people discuss twitter tweets expressing user likes exist great variety scenarios forms. deal data sparsity issues collect training data combining semi-supervised information harvesting techniques concept distant supervision follows semi-supervised information harvesting applied standard seed-based information-extraction method obtaining training data recursively using seed examples extract patterns used harvest examples used seeds train patterns. begin pattern seeds including like/love/enjoy hate/dislike good/ terriﬁc/ cool/ awesome/ fantastic\" bad/terrible/awful suck/sucks\". entities extracted nouns determined twitter-tuned package tweet-level classiﬁer distinguish tweets intend express like/dislike properties tweets purposes. tweet-level classiﬁer distinguish token-level sequence model idensvm classiﬁers trained using svmlight package unigram bigram features corresponding part-of-speech dictionary-derived features based subjectivity lexicon model trained using crf++ package based following features current word context words within window words name entity tags corresponding tags. capitalization word shape. trained models used harvest examples used train updated models. iteratively stopping condition satisﬁed. distant supervision main idea distant supervision obtain labeled data drawing external sort evidence. evidence come database common-sense knowledge. work assume relation like holds speciﬁc user many published tweets mentioning entity also express like relationship therefore treated positive training data. since semi-supervised approaches heavily rely seed quality patterns derived recursive framework strongly inﬂuenced starting seeds adding examples distant supervision helps increase diversity positive training examples. begin train tweet classiﬁcation model entity labeling model based positive/negative data harvested starting seeds. stopping condition satisﬁed also investigated -class classiﬁer like dislike notrelated found performance constantly underperforms using separate classiﬁers. https//code.google.com/p/crfpp/ example datasets says relation iscapital holds britain london sentences mention britain\" london\" treated expressing iscapital relation tweets happy emoticons positive sentiment towards goal train skip-gram neural language model based tweet dataset using wordvec word represented real-valued low-dimensional vector. skipgram language models draw local context order learn similar embeddings semantically similar words. next k-means clustering algorithm extracted entities using distance. learned clusters manually selected sensible ones including food sports movies politics electronic products albums/concerts/songs travels books fashions ﬁnancial stuff pets/animals. identiﬁed clusters matched human label. like attribute extracted network extract like/dislike preferences using following network twitter. twitter user followed current user bidirectionally contains followers treat public ﬁgure/celebrity liked current user markov logic probabilistic logic framework encodes weighted ﬁrst-order logic formulas markov network. translating logic expression people illinois like football team chicago bears expressed real world predicates ﬁrst converted symbols using logical connectives quantiﬁers. predicates corresponds node formula associated weighted value frameworks optimizes following probability exp. denotes normalization factor denotes states nodes network. early example could take following values i.e. number true groundings state consider simple logic network shown equ. weight given logic rule true false true probability three exp/). many approaches proposed fast effective learning mlns work discriminative training approach demonstrated section consecutive entities type labels merged. word embedding dimension stopping condition decide optimum number steps algorithm stop manually labeled dataset contains positive tweets entities. selected original tweet dataset rather automatically harvested data. positive dataset matched negative tweets. iteration data harvesting evaluate performance classiﬁcation models labeling model human-labeled dataset viewed development parameter tuning. results reported table seen precision score decreases algorithm iterates recall rises. best score obtained third round iteration. evaluation purposes data harvesting without distant supervision naturally constitutes baseline. another baseline employ train one-step model directly decide whether speciﬁc token corresponds like/dislike entity rather making tweet-level decision ﬁrst. one-step-crf rely recursive framework tune number iterations aforementioned gold standards. testing dataset comprised additional like/dislike property related tweets entity labels matched negative tweets. last baseline employ rule based extraction approach using seed patterns. report best performance model end-to-end entity extraction precision recall. note end-to-end evaluation setting different table tweet level models make erroneous decision labels assigned entity level would treated wrong seen table three points performance boost obtained incorporating user-entity information distant supervision. modeling tweet-level entity-level information separately yields better performance incorporating uniﬁed model queried. instead optimizing nodes along graph system optimizes probability predicting queried nodes given evidence nodes. prunes large number branches. queried models evidence nodes system optimizes conditional probability follows major challenge missing values example situations users mention entity; user mentioning entity necessarily mean like consider following situation drawing inference requires usrb indeed likes soccer usrb explicitly mentions soccer posts. satisfying premises luxury. inspired common existing approaches deal missing data treat users’ like/dislike preferences latent variables observed whether users explicitly mention preferences posts. latent variables observed variables connected binary distribution parameterized variable sentity indicating likely user would report correspondent entity posts. entity associated additional predicate mention denoting situation given user publishes posts speciﬁc entity. predicate publishentity comes following constraints denotes normalization factor denotes weight formula. inference straightforwardly performed calculating distance predicates. compared framework efﬁciently optimized based linear program. another distinguishing feature uses continuous variables rather binary ones mln. based extraction algorithm section user associated list attributes preferences related various relations users network. function symbols transformed predicates graph construction nodes graph take binary values assumptions simpliﬁcations edges relations like like friend hold entitiy entity different like-entity categories would like friend independent means would edge connecting nodes like like markov network. example usra likes usrb likes football football belong different entity categories would treat predicates independent. inference performed settings friend-observed neigh-latent. friend-observed addresses leave-onetesting infer speciﬁc attribute relation given rest. friend-latent refers another scenario attributes multiple users along network missing require joint inference multiple values along graph. real world applications network information partly retrieved likely fall between. inference friend-observed setting performed directly standard inference framework implemented using mcmc psl. friend-latent setting need jointly infer location attributes along users. objective function joint inference would difﬁcult optimize existing algorithms able scale size network consider turn greedy approach inspired recent work attributes initialized logic network based given attributes missing values considered. user along network iteratively re-estimate attributes given evidence attribute values friends performing standard inference psl. highly conﬁdent predictions made based individual features ﬁrst round user-user relations would either support contradict decisions. rounds iterations. expect friendobserved yield better results friend-latent setting since former beneﬁts gold network information turn experiments using global inference across logic networks augment individual local detectors infer user attributes user relations ﬁnally user preferences. results based datasets extracted previous section user represented series extracted attribute values users connected along social network. data training corpus reserving testing respectively extract testing data relations attribute preference described below. case goal understand whether global probabilistic logical inference entire social network graph improves baseline classiﬁers like svns local features. user attributes location goal location inference identify state user tweets from states. evaluation performed subset users rule-based approach section identiﬁed gold-standard location high precision. report settings. friend-latent setting makes joint predictions user locations across network precise friend-observed setting predicts locations user given attributes relations preferences. baselines employ include random assign location attributed distribution based uniﬁed assign populated state latter includes performances different models illustrated table expected friend-observed outperforms friendlatent detecting locations accuracy onlynetwork only-like models evidence partially considered consistently underperform settings evidence fully considered. logic networks capable capturing complicated interaction factors features yield better performance traditional naive bayes classiﬁers. table gives examples based conditional probability calculated respectively correspond people illinois like chicago bears people alabama like barbecue people hockey like hockey people north dakota like krumkake. user attributes gender evaluate gender based dataset users drawn users whose gold standard gender assigned sufﬁciently high precision social-security informed system section focus neigh-observe setting. baseline takes individual network features described section table shows results. using logic networks across attributes relations preferences accuracy algorithm course performance algorithm could likely even higher additionally incorporating features designed directly gender task achieves gender accuracies different dataset). nonetheless fact global probabilistic inference network attributes relations achieves high accuracies without features points strength network approach. table gives examples gender preference inferred mln. seen males prefer sports females prefer fashions females emphasize food movies males signiﬁcantly. predicting relations users tested relation prediction detection three relations deﬁned section friend spouse liveinsamelocation. positive training data selected pairs users among speciﬁc type relation holds random user pairs used negative examples. weighted toward negative examples match natural distribution statistics shown table relation evaluation focus neigh-observe setting. decisions made comparing conditional probability speciﬁc relation holds given types information example pr|·) -pr|·). baselines employ include liveinsamelocation prediction location identiﬁcation classiﬁer without global information naturally constitutes baseline users viewed living location classiﬁers trained assigned location labels. random assign labels randomly based proportion positive examples. report theoretical values preciperformance different approaches reported table seen logic models consistently yield better performances svms relation prediction tasks power leveraging global interactions different sources evidence. predicing preference likes dislikes evaluating ability detect user preferences complex since mentioned section don’t gold-standard labels twitter users’ true attitudes towards different entities. don’t actually know users actually like like. therefore evaluate ability detect users entity. tasks task estimate without using text message. goal understand useful social network structure alone solving problem. information could easily combined standard sentimentanalysis techniques future work. begin scenario know entity already mentioned user predict user’s attribute towards without looking text-level evidence. goal experiment predict sentiment given types attributes user frequent database total distinguished entities extracted like examples dislike examples dislike-barackobama). predictions make comparing pr|·) extracted gold standards data point random guess accuracy. evaluations performed terms prediction recall. consider neigh-latent setting. baselines employ include train binary classiﬁers decide speciﬁc entity whether user likes/dislikes features include individual attributes values network information collaborative filtering accounts popular approach recommendation system utilizes information user-item matrix recommendations. idea recommend similar items similar users. view like/dislike entity prediction entity recommendation problem adopt approach described constructing user-user similarity matrix weighted cosine similarity calculated shared attributes network information. entity-entity similarity computed based entity embedding regression model trained value user-entity matrix indicating whether speciﬁc user likes/hates speciﬁc entity. prediction made based weighted nearest neighbor algorithm. still confronted missing value problem section don’t know users actually believe predict believe. previous section assumed knew user talked entity predicted sentiment turn much difﬁcult task predicting whether user mention entity users attitude toward entity evaluations performed friend-observed setting friend-latent setting. construct testing dataset using random sample users average number like/dislike entities mentioned user baselines employ include random estimate overall popularity speciﬁc entity liked whole population. probability pentity decision made sampling variable binary distribution parameterized pentity. naive bayes train naive bayes classiﬁers decide whether speciﬁc user would express like/dislike attitude towards speciﬁc entity. features include individual attributes values network information collaborative filtering described previous note predicting like/dislike mention extremely difﬁcult task since users tweet small percentage entities like dislike world. predicting ones decide talk difﬁcult task requiring much kinds evidence individual network system access nonetheless given limited information hand considering great number entities proposed model surprisingly well precision recall signiﬁcantly outperforming collaborative filtering naive bayes. work related four different research areas. information extraction social media much work devoted automatic extraction well-structured information proﬁles online social media mainly fall major levels public level user level. former includes public event identiﬁcation event tracking event-referring expression extraction latter focus user studies examining users’ interests timeline personal events individual attributes gender political polarity locations jobs educations student information ﬁrst step proposed approach highly relies attribute extraction algorithm described extracts three categories user attributes given user based posts. gathers training data based concept distant supervision google+ treated used knowledge base\" provide supervision. algorithm returns probability whether following predicates hold workin study-at spouse attributes background higher chance becoming friends social media friends tend share attributes. properties harnessed applications like community detection friend recommendation extraction related strand work data harvesting/information extraction point seeds harvest data used learn additional rules patterns harvest data distant supervision another methodology data harvesting relies structured data sources source supervision data harvesting text. logic/relational reasoning logic reasoning usually based ﬁrst-order logic representations tracked back early days adequately explored since variety reasoning models proposed based ideas concepts ﬁelds graphical models relational logic programming languages generalization capabilities terms different types data. frameworks include stochastic logic programs combines logic programming log-linear models probabilistic relational networks incorporates bayesian networks reasoning relational markov networks uses dataset queries cliques model state clique markov network relational dependency networks combines bayes networks markov networks probabilistic similarity logic jointly considers probabilistic reasoning similarities relational structure. great number applications beneﬁt logical reasoning including natural language understanding health modeling group modeling link based clustering object identiﬁcation trust analysis many more. work propose framework applying probabilistic logical reasoning inference problems social networks. two-step procedure ﬁrst extracts logical predicates associated probability social networks performs logical reasoning. evaluated system predicting user attributes user relations user preferences results show using probabilistic logical reasoning course current system particularly weak recall since many true user attributes relations simply never explicitly expressed platforms like twitter. also gold-standard\" ﬁrstorder logics extracted really gold-standard. promising perspective integrate user information different sorts online social media. many websites directly offer gold-standard attributes; facebook contains user preference movies books religions musics locations; linkedin offers comprehensive professional information. combining different types information offer evidence decision making. discriminating gender twitter. proceedings conference empirical methods natural language processing pages association computational linguistics sources opinions conditional random ﬁelds extraction patterns. proceedings conference human language technology empirical methods natural language processing pages association computational linguistics constraint logic programming probabilistic knowledge. proceedings nineteenth conference uncertainty artiﬁcial intelligence pages morgan kaufmann publishers inc. debnath ganguly mitra. feature weighting content based recommendation system using social network analysis. proceedings international conference world wide pages topics microblogs. proceedings annual meeting association computational linguistics long papers-volume pages association computational linguistics hoffmann zhang ling zettlemoyer weld. knowledge-based weak supervision information extraction overlapping relations. proceedings annual meeting association computational linguistics human language technologies-volume pages association computational linguistics induction web-based corroboration. proceedings workshop unsupervised minimally supervised learning lexical semantics pages association computational linguistics holders topics expressed online news media text. proceedings workshop sentiment subjectivity text pages association computational linguistics quality text mining seeds. human language technologies annual conference north american chapter association computational linguistics pages association computational linguistics adaptive online language models topic tracking tweet streams. proceedings sigkdd international conference knowledge discovery data mining pages mikolov kombrink burget cernocky khudanpur. extensions recurrent neural network language model. acoustics speech signal processing ieee international conference pages ieee surdeanu jurafsky manning. multi-pass sieve coreference resolution. proceedings conference empirical methods natural language processing pages association computational linguistics learning ﬁrst-order horn clauses text. proceedings conference empirical methods natural language processing pages association computational linguistics probabilistic models relational data. proceedings eighteenth conference uncertainty artiﬁcial intelligence pages morgan kaufmann publishers inc. personalized pagerank locally groundable ﬁrst-order probabilistic logic. proceedings international conference information knowledge management efﬁcient ﬁrst-order probabilistic logic programming structure discovery parameter learning scalable inference. proceedings aaai workshop statistical relational cohen. efﬁcient inference learning large knowledge base reasoning extracted information using locally groundable ﬁrst-order probabilistic logic. progress wiebe wilson cardie. annotating expressions opinions emotions language. language resources evaluation", "year": 2014}