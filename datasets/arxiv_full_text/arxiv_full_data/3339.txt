{"title": "Deep Convolutional Neural Networks on Cartoon Functions", "tag": ["cs.LG", "cs.CV", "math.NA", "stat.ML"], "abstract": "Wiatowski and B\\\"olcskei, 2015, proved that deformation stability and vertical translation invariance of deep convolutional neural network-based feature extractors are guaranteed by the network structure per se rather than the specific convolution kernels and non-linearities. While the translation invariance result applies to square-integrable functions, the deformation stability bound holds for band-limited functions only. Many signals of practical relevance (such as natural images) exhibit, however, sharp and curved discontinuities and are, hence, not band-limited. The main contribution of this paper is a deformation stability result that takes these structural properties into account. Specifically, we establish deformation stability bounds for the class of cartoon functions introduced by Donoho, 2001.", "text": "speciﬁc choice ﬁlters non-linearities. vertical translation invariance result general sense applying function space deformation stability result pertains square-integrable band-limited functions. moreover corresponding deformation stability bound depends linearly bandwidth. many signals practical relevance modeled square-integrable functions however band-limited large bandwidth. large bandwidths render deformation stability bound void consequence linear dependence bandwidth. contributions. question considered paper whether taking structural properties natural images account lead stronger deformation stability bounds. show answer afﬁrmative analyzing class cartoon functions introduced cartoon functions satisfy mild decay properties piecewise continuously differentiable apart curved discontinuities along -hypersurfaces. moreover provide good model natural images mnist caltech cifar- datasets well images geometric objects different shapes sizes colors proof main result based decoupling technique introduced essence decoupling contractivity feature extractor combined deformation stability signal class consideration—under smoothness conditions deformation—establishes deformation stability feature extractor. main technical contribution prove deformation stability class cartoon functions. moreover show decay rate resulting deformation stability bound best possible. results obtain underpin observation made deformation stability vertical translation invariance induced network structure notation. refer reader general notation employed paper. addition need following notation. minkowski sets indicator function deﬁned rd\\b. measurable vold abstract—wiatowski b¨olcskei proved deformation stability vertical translation invariance deep convolutional neural network-based feature extractors guaranteed network structure rather speciﬁc convolution kernels non-linearities. translation invariance result applies square-integrable functions deformation stability bound holds band-limited functions only. many signals practical relevance exhibit however sharp curved discontinuities hence band-limited. main contribution paper deformation stability result takes structural properties account. speciﬁcally establish deformation stability bounds class cartoon functions introduced donoho feature extractors based so-called deep convolutional neural networks applied tremendous success wide range practical signal classiﬁcation tasks networks composed multiple layers computes convolutional transforms followed application non-linearities pooling operations. mathematical analysis feature extractors generated deep convolutional neural networks initiated seminal paper mallat speciﬁcally mallat analyzes so-called scattering networks signals propagated layers compute semi-discrete wavelet transforms followed modulus non-linearities. shown resulting wavelet-modulus feature extractor horizontally translationinvariant deformation-stable stability result applying function space depends underlying mother wavelet. recently wiatowski b¨olcskei extended mallat’s theory incorporate convolutional transforms ﬁlters pre-speciﬁed potentially structured weyl-heisenberg functions wavelets curvelets shearlets ridgelets pre-speciﬁed unstructured random ﬁlters learned supervised unsupervised fashion. furthermore networks employ general lipschitz-continuous nonlinearities pooling sub-sampling. essence results vertical translation invariance deformation stability induced network structure rather fig. network architecture underlying feature extractor index corresponds k-th atom collection associated n-th network layer. function output-generating atom n-th layer. layer. atoms n}∪{χn−} thus used across consecu{gλn}λn∈λn\\{λ∗ generating output tive layers sense layer remaining atoms {gλn}λn∈λn\\{λ∗ propagating signals n-th layer according fig. slight abuse notation write λn\\{λ∗ extracted features signal feature generated n-th layer network fig. shown feature extractor vertically translation-invariant sense layer depth determining extent features translation-invariant. furthermore condition referred weak admissibility condition satisﬁed wide variety module sequences following result established feature extractor deformation-stable w.r.t. deformations space r-band-limited functions i.e. exists universal constant stage brieﬂy reviewing deep convolutional feature extraction network presented basis referred module-sequence. triplet —associated n-th network layer—consists collection {gλn}λn∈λn so-called atoms indexed countable satisfying bessel operator satisfying lipschitz property sub-sampling factor associated deﬁne operator prop. hence easily satisﬁed even learned ﬁlters overview collections {gλn}λn∈λn structured atoms functions wavelets curvelets shearlets ridgelets) non-linearities widely used deep learning literature provided chose term size indicate length vold− hypersurface furthermore cart follows triangle inequality according last step used finally note main results—presented next section—can easily generalized ﬁnite linear combinations cartoon functions done simplicity exposition. start reviewing decoupling technique introduced prove deformation stability bounds band-limited functions. proof deformation stability bound band-limited functions based ingredients. ﬁrst contractivity property namely |||φω φω||| contractivity guarantees pairwise distances input signals increase feature extraction. second ingredient upper bound deformation error f−fτ speciﬁc signal class considered namely band-limited functions. recognizing combination ingredients yields simple proof deformation stability interesting shows whenever signal class exhibits inherent stability w.r.t. deformations form automatically obtain deformation stability feature extractor present paper employs decoupling technique establishes deformation stability class cartoon functions deriving upper bound deformation error proposition every exists constant cart right-hand side determines decay rate deformation error clearly larger results deformation error decaying faster deformation becomes smaller. following simple example shows best possible i.e. lipschitz exponent larger. consider ﬁxed satisfying corresponding deformation amounts simple translation then cart fτsf fig. left natural image typically governed areas little variation individual areas separated edges modeled curved singularities. right image handwritten digit. signal class e.g. image handwritten digit collection then images handwritten digit generated e.g. based different handwriting style. bound jacobian matrix imposes quantitative limit amount deformation tolerated rendering bound implicitly depend deformation stability bound guarantees features corresponding images differ much. bound applies space square-integrable r-band-limited functions. many signals practical signiﬁcance however band-limited exhibit large bandwidths. latter case deformation stability bound becomes void depends linearly goal paper take structural properties natural images account considering class cartoon functions introduced functions satisfy mild decay properties piecewise continuously differentiable apart curved discontinuities along -hypersurfaces. cartoon functions provide good model natural images caltech- cifar- data sets images handwritten digits images geometric objects different shapes sizes colors —slightly modiﬁed version cartoon functions. deﬁnition function referred cartoon function written compact domain whose boundary compact topologically embedded -hypersurface without boundary satisfy decay condition remark interesting note order obtain bounds form cτα∞ need impose non-trivial constraints indeed consider again small function energy concentrated small interval according supp then disjoint support sets hence fτsfs decay generally amount deformation induced given function depends strongly signal applied concretely deformation lead small bump around origin applied lowpass function whereas function experience signiﬁcant deformation. modulesequence satisfying weak admissibility condition every size feature extractor deformationstable space cartoon functions cart w.r.t. deformations i.e. every exists constant cart holds strength deformation stability result theorem condition derives fact need impose underlying module-sequence weak admissibility according argued easily normalizing elements appropriately. emphasize normalization impact constant shown appendix independent dependence does however reﬂect intuition deformation stability bound depend signal class description complexity. band-limited signals dependence exhibited linear bandwidth finally note vertical translation invariance result applies cart thanks carries cartoon functions. remark note thanks decoupling technique underlying arguments deformation stability bounds general sense applying every contractive mapping speciﬁcally identity mapping also leads deformation stability class cartoon functions interesting recently demonstrated employing identity mapping so-called shortcutconnection subset layers deep convolutional neural network yields state-of-the-art classiﬁcation performance imagenet dataset deformation stability result hence general sense applying broad class network architectures used practice. modulesequence satisfying weak admissibility condition every size feature extractor deformation-stable space kx−d} w.r.t. deformations i.e. every exists constant last inequality follows assumption. idea |h|dx integrals sets rd\\b. monotonicity function implies cτ∞−d rd\\b τ∞|x| together monotonicity yields cτ∞τ∞|x| )x−d cτ∞τ∞)x−d. putting things together hence proof. order |b−b)|dx ﬁrst note integrand satisﬁes tube radius around boundary exists constant vold voldτ∞ c∂bτ∞ therefore vold c∂bτ∞ completes proof. references wiatowski b¨olcskei mathematical theory deep convolutional neural networks feature extraction arxiv. gr¨ochening foundations time-frequency analysis. birkh¨auser huang lecun large-scale learning convolutional nets generic object categorization proc. ieee international conference computer vision pattern recognition ranzato huang boureau lecun unsupervised learning invariant feature hierarchies applications object recognition proc. ieee international conference computer vision pattern recognition", "year": 2016}