{"title": "Multiscale Inverse Reinforcement Learning using Diffusion Wavelets", "tag": ["cs.LG", "cs.AI"], "abstract": "This work presents a multiscale framework to solve an inverse reinforcement learning (IRL) problem for continuous-time/state stochastic systems. We take advantage of a diffusion wavelet representation of the associated Markov chain to abstract the state space. This not only allows for effectively handling the large (and geometrically complex) decision space but also provides more interpretable representations of the demonstrated state trajectories and also of the resulting policy of IRL. In the proposed framework, the problem is divided into the global and local IRL, where the global approximation of the optimal value functions are obtained using coarse features and the local details are quantified using fine local features. An illustrative numerical example on robot path control in a complex environment is presented to verify the proposed method.", "text": "work presents multiscale framework solve inverse reinforcement learning problem continuous-time/state stochastic systems. take advantage diffusion wavelet representation associated markov chain abstract state space. allows effectively handling large decision space also provides interpretable representations demonstrated state trajectories also resulting policy irl. proposed framework problem divided global local global approximation optimal value functions obtained using coarse features local details quantiﬁed using local features. illustrative numerical example robot path control complex environment presented verify proposed method. paper address inverse reinforcement learning problem robots operated complex environment long time horizon forward problem continuous time/continuous stochastic optimal control problem called linearly solvable optimal control objective problem recover value cost functions well optimal policy experts’ demonstrations given. general method solve problem standard often involves procedure solving corresponding forward problem every iteration method lsoc solution method lsoc formulated convex optimization problem gradient hessian obtained analytically. however optimization tends intractable size problem increases moreover real situation demonstration data sufﬁcient represent whole state space. finding sparse structure problem representing problem meaningful bases essential obtaining solution efﬁciently. address large-scale problems effectively conceivable hallmark human intelligence could provide insights particular work notes multiscale hierarchical structure human decision making. suppose someone currently writing paper his/her ofﬁce desk wants building; ofﬁce located third ﬂoor building staircases elevator. then would person’s control policy look like? person would ﬁgure he/she possible situations he/she could face like standard value function-based approach; instead he/she would ﬁgure building gate he/she would whether take elevator stairs door would exit room etc. detailed plans which particular start he/she left foot would determined later process executing piece overall plan example downstairs using staircase. noted human-like decision takes advantage underlying hierarchical structure state space; example detailed aspects particular certain sequence stairs abstracted single notion staircase. intuition applied inverse inference problem. utilizing contribution paper present systematic framework solving depicted fig. framework consists phases discretization phase markov chain associated robot dynamics constructed sampling ﬁnite states state-space. abstraction phase hierarchical bases structure obtained using diffusion wavelet method. global phase problem constructed using coarse bases solved; much tractable handle using original bases set. local planning phase ﬁner bases located focused regions demonstration data visit frequently sought detailed solution associated focused regions computed. control phase continuous control sequence computed applied robot receding horizon fashion. rest paper primarily focused elaborating details framework followed numerical example validation method. state control vector du-dimensional brownian motion process respectively. functions instantaneous state cost rate control policy respectively deﬁne instantaneous cost rate problem cost function dynamics called inﬁnite horizon average cost stochastic optimal control problem referred linearly-solvable optimal control problem since solution obtained linear partial differential equation time-axis discretized time step transition probability step without/with control input deﬁned called passive controlled dynamics respectively. passive controlled dynamics approximated gaussian distribution mean covariance small kullback-leibler divergence distributions approximated dkl||p) therefore cost functional written discrete time setting moreover state space discretized sampling states {xn} transition probability matrix passive dynamics means transition probability approximated gaussian distribution axn. truncate tails gaussian distribution make sparse. discrete states state-space well time-axis discretized version formulated markov decision process cost function given type called linearly-solvable solution known converge solution deﬁne optimal cost-to-go value minπ differential cost-to-go function desirability function exp) linear operator objective problem optimal control policy given system cost function objective inverse reinforcement learning problem recover value cost functions well optimal policy experts’ demonstrations given n}n=··· obtained optimal policy suppose dataset transitions vector representation value function then negative log-likelihood dataset given log) component represent visitation counts respectively. since convex gradient hessian computed analytically minimized applying iterative second order convex optimization methods. value function obtained cost function optimal policy recovered directly respectively. real situation however sparse since dataset sufﬁcient impossible compute whole state space. also optimization procedure gets intractable problems large size state space. represent problem efﬁciently linear value function approximation used column represents feature weight. note also convex. work obtain hierarchical structure feature sets naturally induced passive dynamics system utilize features solve problem efﬁciently. multiscale feature extraction diffusion wavelets consider notion simplicity; represents transition probability markov chain obtained discretizing diffusion process known interesting properties local smoothing contractive initial point state transitions neighbors smooth probability distribution. also since ||t|| dimension subspace \u0001-spanned jδm}xm∈x monotonically decreases increases especially irreducible markov chain increases limit corresponds stationary distribution markov chain. orthogonal complement i.e. suppose orthonormal bases span respectively. using aforementioned properties diffusion wavelets constructs hierarchical structure well-localized bases called scaling wavelet functions respectively order subspace spanned feature j\u0001-close subspace spanned +++···+j− j−δm}xm∈x. roughly speaking represent smooth bump function oscillatory function respectively. omit procedure diffusion wavelets algorithm space limitation would refer readers details. vectors represented basis columns coordinates vectors coordinates features level written original coordinate represented |xj| matrix. note column viewed abstract-state\" original markov chain. scale |xj| meaningful combinations states combination represents abstract-state. rather solving original |x|-dimensional optimization problem treat lowerdimensional coarsened problem. suppose abstract-state\" level utilized features means problem viewed lower resolution time scale. then approximated linear combination feature φjwj optimization problem also written compressed problem much tractable original problem |xj| |x|. note localization property features naturally interpretable thus user choose appropriate level considering trade-off size problem solution quality. also hierarchical structure diffusion wavelet tree utilized solve problem efﬁciently; solution level provide initial guess level problem; optimization level starts ˜wj− unpacking level solution. sharply changed scale initial guess would near optimum level problem optimization procedure would rapidly converge minimum. suppose solve level problem approximate solution using features then achieve exact solution considering additional features wavelet functions orthogonal wavelet bases also built well-localized. work utilize intuition important region optimal policy frequently visits highest resolution wavelet functions evaluated score r|x|−|xl| represents feature overlap visitation counts adding features high scores solving corresponding problem value cost functions policy higher resolution important region. also user easily choose additional features objective since wavelet features also interpretable. finally continuous-time optimal policy extracted multiscale quantiﬁcation optimal value structure interval krhc receding horizon control fashion. control computed matching order moment original optimal policy figure scaling functions level level exact approximate value functions. exact approximate cost functions. number features error solution level. consider simple two-dimensional stochastic single integrator fractal-like environment. environment consists groups rooms group made square rooms shown fig. observe environment level self-similarity makes problem multiscale nature. dynamics given position robot conﬁguration space controlled velocity input disturbed white noise. order discretize state space samples obtained room therefore discrete state total. transition data obtained true occupancy measure induced optimal policy equivalent using inﬁnite number samples. fig. shows multiscale features scaling functions diffusion wavelet tree level seen level roughly considered -step scaling functions roughly represent small room group -rooms respectively; meaning make distinction within room group rooms levels. fig. depict approximated value cost functions level respectively fig. shows number features error value functions scale. level basis functions used value cost functions recovered quite exactly; level bases used even though solution contains error interprets information optimal policy preference cost function groups rooms. omit computational time scale space limitation observe computational time decreases number feature increases; obvious trade-off solution quality computational cost appropriate level chosen observing features level. mauro maggioni sridhar mahadevan. fast direct policy evaluation using multiscale analysis markov diffusion processes. proceedings international conference machine learning pages sridhar mahadevan mauro maggioni. value function approximation diffusion wavelets laplacian eigenfunctions. advances neural information processing systems pages", "year": 2016}