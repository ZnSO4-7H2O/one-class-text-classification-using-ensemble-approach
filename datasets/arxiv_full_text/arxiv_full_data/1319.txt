{"title": "Do Convnets Learn Correspondence?", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Convolutional neural nets (convnets) trained from massive labeled datasets have substantially improved the state-of-the-art in image classification and object detection. However, visual understanding requires establishing correspondence on a finer level than object category. Given their large pooling regions and training from whole-image labels, it is not clear that convnets derive their success from an accurate correspondence model which could be used for precise localization. In this paper, we study the effectiveness of convnet activation features for tasks requiring correspondence. We present evidence that convnet features localize at a much finer scale than their receptive field sizes, that they can be used to perform intraclass alignment as well as conventional hand-engineered features, and that they outperform conventional features in keypoint prediction on objects from PASCAL VOC 2011.", "text": "convolutional neural nets trained massive labeled datasets substantially improved state-of-the-art image classiﬁcation object detection however visual understanding requires establishing correspondence ﬁner level object category. given large pooling regions training whole-image labels clear convnets derive success accurate correspondence model could used precise localization. paper study effectiveness convnet activation features tasks requiring correspondence. present evidence convnet features localize much ﬁner scale receptive ﬁeld sizes used perform intraclass alignment well conventional hand-engineered features outperform conventional features keypoint prediction objects pascal recent advances convolutional neural nets dramatically improved state-of-the-art image classiﬁcation. despite magnitude results many doubted resulting features spatial speciﬁcity necessary localization; whole image classiﬁcation rely context cues overly large pooling regions done. coarse localization doubts alleviated record breaking results extending features detection pascal questions loom ﬁner scale. modern convnets excel classiﬁcation detection also able precise correspondences object parts? large receptive ﬁelds mean correspondence effectively pooled away making task better suited hand-engineered features? paper provide evidence convnet features perform least well conventional ones even regime point-to-point correspondence show considerable performance improvement certain settings including category-level keypoint prediction. image alignment image alignment step many computer vision tasks including face veriﬁcation motion analysis stereo matching object recognition. alignment results correspondence across different images removing intraclass variability canonicalizing pose. alignment methods exist supervision spectrum requiring manually labeled ﬁducial points landmarks requiring class labels fully unsupervised joint alignment clustering models. congealing unsupervised joint alignment method based entropy objective. deep congealing builds idea replacing hand-engineered features unsupervised feature learning multiple resolutions. inspired optical sift matches densely sampled sift features correspondence applied motion prediction motion transfer. section apply sift using deep features aligning different instances class. keypoint localization semantic parts carry important information object recognition object detection pose estimation. particular ﬁne-grained categorization subject many recent works depends strongly part localization large pose appearance variation across examples make part localization generic object categories challenging task. existing works part localization keypoint prediction focus either facial landmark localization human pose estimation. human pose estimation approached using tree structured methods model spatial relationships parts also using poselets intermediate step localize human keypoints tree structured models poselets struggle applied generic objects large articulated deformations wide shape variance. deep learning convolutional neural networks gained much recent attention success image classiﬁcation convnets trained backpropagation initially succesful digit recognition feature representations learned large data sets found generalize well image classiﬁcation tasks even object detection recently toshev trained cascade regression-based convnets human pose estimation jain combine weak spatial model deep learning methods. latter work trains multiple small independent convnets patches binary bodypart detection. contrast employ powerful pretained imagenet model shares mid-elvel feature representations among parts section several recent works attempted analyze explain overwhelming success. zeiler fergus provide several heuristic visualizations suggesting coarse localization ability. szegedy show counterintuitive properties convnet representation suggest individual feature channels semantically meaningful bases feature space. concurrent work compares convnet features sift standard descriptor matching task. work illuminates extends comparison providing visual analysis moving beyond single instance matching intraclass correspondence keypoint prediction. perform experiments using network architecture almost identical popularized krizhevsky trained classiﬁcation using million images ilsvrc challenge dataset experiments implemented using caffe network publicly available caffe reference model. activations layer features referred convn pooln convolutional pooling fully connected layer respectively. term receptive ﬁeld abbreviated refer input pixels path-connected particular unit convnet. figure perform nonparametric reconstruction images features spirit hoggles rather paired dictionary learning however simply replace patches averages top-k nearest neighbors convnet feature space. ﬁrst compute features particular layer resulting grid feature vectors. associate feature vector patch original image center corresponding receptive ﬁeld size equal receptive ﬁeld stride. themselves overlap. refer table speciﬁc numbers.) replace patch average nearest neighbor patches using database features densely computed images pascal database contains least million patches every layer. features matched cosine similarity. even though feature cover large regions source images speciﬁc resemblance resulting images shows information spread uniformly throughout regions. notable features replaced corresponding locations. also note replacement appears become semantic less visually speciﬁc layer deepens eyes nose replaced differently colored shaped eyes noses gets replaced various animal furs diversity increasing layer number. figure gives feature-centric rather image-centric view feature locality. column ﬁrst pick random seed feature vector nearest neighbor features cosine similarity. instead averaging centers average entire receptive ﬁelds neighbors. resulting images show similar features tend respond similar colors speciﬁcally centers receptive ﬁelds. figure similar convnet features tend similar receptive ﬁeld centers. starting randomly selected seed patch occupying conv nearest neighbor features computed database natural images average together corresponding receptive ﬁelds. contrast image expanded averaging. conjecture category learning implicitly aligns instances pooling discriminative mid-level representation. true features useful post-hoc alignment similar fashion conventional features. test this convnet features task aligning different instances class. approach difﬁcult task style sift retrieve near neighbors using coarse similarity measure compute dense correspondences impose smoothness prior ﬁnally allows images warped alignment. nearest neighbors computed using features. since speciﬁcally testing quality alignment nearest neighbors convnet conventional features compute types features locations grid convnet centers response single image. alignment determined solving formulated grid feature locations. point grid feature vector source image point feature vector target image point. feature grid location source image vector giving displacement corresponding feature target image. energy function edges -neighborhood graph regularization parameter. optimization performed using belief propagation techniques suggested message passing performed efﬁciently using squared euclidean distance transform formulation maintains rotational invariance given alignment ﬁeld warp target source using bivariate spline interpolation figure gives examples alignment quality different seed images using sift convnet features. show warped nearest neighbors well keypoints transferred neighbors. quantitatively assess alignment measuring accuracy predicted keypoints. obtain good predictions warp nearest neighbors target image order smallest greatest deformation energy take predicted keypoints median points aligned keypoints according ordering. assess correctness using mean consider ground truth keypoint correctly predicted prediction lies within euclidean distance times maximum bounding figure convnet features bring different instances class good alignment least well traditional features. target image show warped versions nearest neighbor images aligned conv warped versions aligned sift keypoints warped images shown copied target image. shows case convnet features perform better bicycle shows case sift features perform better. table keypoint transfer accuracy using convnet sift simple copying nearest neighbors. accuracy shown category using means also shown stricter values average convnet performs well sift performs better stricter tolerances. width height picking compute overall accuracy type keypoint report average keypoint types. penalize predicted keypoints visible target image. results given table show category results using mean results indeed convnet learned features least capable sift alignment better might expected given size receptive ﬁelds. section speciﬁcally address ability convnet features understand semantic information scale parts. initial test consider task keypoint classiﬁcation given image coordinates keypoint image train classiﬁer label keypoint? table keypoint classiﬁcation accuracies percent twenty categories pascal trained sift convnet features. best sift convnet scores bolded category. figure cross validation scores keypoint classiﬁcation function parameter plot mean accuracy different convnet features; plot sift features different sizes. experiments table figure convnet features show localization ability even beyond stride cases sift features perform well. plot histogram locations maximum responses classifer pixel rectangle taken around ground truth keypoint. task keypoint data twenty classes pascal extract features keypoint using sift using column convnet layer whose center lies closest keypoint. trained one-vs-all linear svms train using sift different radii convolutional layer activations features parameter experiments based ﬁve-fold cross validation training table gives resulting accuracies set. features convnet layers consistently perform least well often better sift task highest performance coming layers conv conv. note speciﬁcally testing convnet features trained classiﬁcation; could expected achieve even higher performance trained task. finally study precise location understanding classiﬁers computing responses single-pixel stride around ground truth keypoint locations. example keypoints histogram locations maximum responses within pixel pixel rectangle around keypoint shown figure include maximum responses boundary rectangle. sift classiﬁers seem sensitive precise locations keypoints many cases convnet ones seem capable localization ﬁner strides receptive ﬁeld sizes. observation motivates ﬁnal experiments consider detection-based localization performance. seen despite large receptive ﬁeld sizes convnets work well handengineered feature sift alignment slightly better sift keypoint classiﬁcation. keypoint prediction provides natural follow-up test. section keypoint annotations pascal assume ground truth bounding box. inspired part train sliding window part detectors predict keypoint locations independently. r-cnn overfeat demonstrated effectiveness deep convolutional networks generic object detection task. however neither investigated application cnns keypoint prediction. r-cnn starts bottom-up region proposal tends overlook signal small parts. overfeat hand combines convnets trained classiﬁcation regression runs multi-scale sliding window fashion. rescale bounding compute conv cell conv contains -dimensional descriptor. concatenate conv descriptors local region cells giving overall receptive ﬁeld size feature dimension keypoint train linear hard negative mining. consider closest features ground truth keypoint positive examples features whose contain keypoint negative examples. also train using dense sift descriptors comparison. compute sift grid stride eight size eight using vlfeat sift consider features within twice size ground truth keypoint positives samples least four times size away negatives. augment detectors spherical gaussian prior candidate locations constructed nearest neighbor matching. mean gaussian taken location keypoint nearest neighbor training found using cosine similarity pool features ﬁxed standard deviation pixels. output score local detector keypoint prior score. combine yield ﬁnal score s−ηpη tradeoff parameter. experiments cross validation. test time predict keypoint location highest scoring candidate feature locations. evaluate predicted keypoints using measure introduced section taking predicted keypoint deﬁned correct distance ground truth keypoint less height width bounding box. results using conv sift without prior shown table table local part detectors trained conv feature outperform sift large margin prior information helpful cases. knowledge ﬁrst keypoint prediction results reported dataset. show example results different categories figure consists rescaled bounding images ground truth keypoint annotations predicted keypoints using sift conv features color corresponds keypoint. ﬁgure shows conv outperforms sift often managing satisfactory outputs despite challenge task. small offset noticed keypoints like eyes noses likely limited stride scanning windows. ﬁnal regression ﬁner stride could mitigate issue. visualization alignment keypoint prediction studied ability intermediate features implicitly learned state-of-the-art convnet classiﬁer understand speciﬁc local correspondence. despite large receptive ﬁelds weak label training found cases convnet features least useful conventional ones extracting local visual information. figure examples keypoint prediction classes pascal dataset aeroplane potted plant horse. keypoint associated color. ﬁrst column ground truth annotation second column prediction result sift+prior third column conv+prior. yang ramanan. articulated pose estimation using ﬂexible mixtures parts. cvpr savarese. articulated part-based model joint object detection pose estimation. toshev szegedy. deeppose human pose estimation deep neural networks. cvpr jain tompson andriluka taylor bregler. learning human pose estimation jones oliphant peterson scipy open source scientiﬁc tools python yang ramanan. articulated human detection ﬂexible mixtures parts. pami d.g. lowe. object recognition local scale-invariant features. iccv sermanet eigen zhang mathieu fergus lecun. overfeat integrated recognition", "year": 2014}