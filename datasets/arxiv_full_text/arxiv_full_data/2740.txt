{"title": "On formalizing fairness in prediction with machine learning", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Machine learning algorithms for prediction are increasingly being used in critical decisions affecting human lives. Various fairness formalizations, with no firm consensus yet, are employed to prevent such algorithms from systematically discriminating against people based on certain attributes protected by law. The aim of this article is to survey how fairness is formalized in the machine learning literature for the task of prediction and present these formalizations with their corresponding notions of distributive justice from the social sciences literature. We provide theoretical as well as empirical critiques of these notions from the social sciences literature and explain how these critiques limit the suitability of the corresponding fairness formalizations to certain domains. We also suggest two notions of distributive justice which address some of these critiques and discuss avenues for prospective fairness formalizations.", "text": "language domains included legislation include education employment access housing public services health care adoption credit insurance. number federal non-discrimination laws exist prevent discrimination similar domains similar legal frameworks present many countries nowadays machine learning algorithms increasingly used high-impact domains credit employment education criminal justice prone discrimination. observed human behaviors dictate algorithm transforms input output awed ability modern computing devices swily replicate decision-making lead magnifying erroneous behavior barocas selbst citron pasquale edelman luca sweeney show algorithms make discriminatory decisions even computing process well-intentioned. because barocas selbst assert training data simply reect widespread biases persist society large data mining discover surprisingly useful regularities really preexisting paerns exclusion inequality. report released government states discrimination sometimes inadvertent outcome data technologies structured used points toward potential encoding discrimination automated decisions. goal fairness prediction machine learning design algorithms make fair predictions devoid discrimination. article survey fairness formalized machine learning literature task prediction present formalizations corresponding notions social sciences literature. given outcomes prediction decisions social benets like education employment health-care fairness formalizations machine learning literature correspond notions distributive justice social sciences literature. since formalizations fairness conicting others predictions produced algorithms using would vastly dier well. machine learning prediction algorithms used high-impact domains predictions far-reaching effects society. erefore practical point view important study fairness formalized machine learning literature implications various formalizations. present theoretical well empirical critiques corresponding notions social sciences literature. co-presentation formalizations machine learning literature corresponding critiques social sciences literature intention assist following tasks abstract machine learning algorithms prediction increasingly used critical decisions aecting human lives. various fairness formalizations consensus employed prevent algorithms systematically discriminating people based certain aributes protected law. article survey fairness formalized machine learning literature task prediction present formalizations corresponding notions distributive justice social sciences literature. provide theoretical well empirical critiques notions social sciences literature explain critiques limit suitability corresponding fairness formalizations certain domains. also suggest notions distributive justice address critiques discuss avenues prospective fairness formalizations. introduction discrimination refers unfavourable treatment people membership certain demographic groups distinguished aributes protected ributes). discriminatory action direct indirect direct discrimination said occur person treated less favorably another would treated comparable situation account protected aribute. indirect discrimination said occur apparently neutral provision criterion practice would persons protected aribute particular disadvantage compared persons. discrimination occur simultaneously based aributes discrimination based many aributes several domains prohibited international legislation. european union formalized legislation achieve non-discrimination account protected aributes race ethnicity religion nationality gender disability marital status genetic features forge newer formalizations nominate notions social sciences literature answer critiques existing formalizations machine learning literature. fairness measured point readers ˇzliobait˙e multidisciplinary survey discrimination analysis recommend romei ruggieri context article mainly interested theories distributive justice social science literature. covering detail beyond scope article. roemer provide overview topic perspective economics philosophy. point view legislation overview analysis fairness provided franck section state mathematical formulation problem prediction machine learning. section review fairness formalizations literature prediction machine learning corresponding notions distributive justice social sciences literature. also provide critiques analyses notions explain critiques limit suitability formalizations certain domains. section illustrate dierences among surveyed fairness formalizations help prediction scenario. aempt answer critiques previous fairness formalizations propose prospective notions fairness section lastly section discuss avenues prospective fairness formalizations. individuals. term population. individuals population divided several groups depending upon protected aributes. individuals assigned outcome. denote outcomes formally outcome could continuous practice case nite number outcomes importance many applications. consequently literature focused problem seings nite number outcomes article. simplest case outcome binary i.e. prediction outcomes considered benecial desirable others. case outcomes parity-based fairness formalizations typically correspond egalitarianism school thought equates fairness form equality people. within egalitarianism various notions fairness social sciences literature turn elicit corresponding formalizations machine learning literature. preference-based fairness formalizations hand correspond non-egalitarian doctrine distributive justice. next existing formalizations fairness machine learning literature corresponding notions social sciences literature. table summarizes formalizations answer questions presented above. treatment parity treatment parity name suggests table shows follows particular notion egalitarian fairness treatment. formalized following denition. predictor group-conditional thus satises formalization fairness. treatment parity appealing because point view decision-maker using predictor easier deploy rather proving parity treatment. however aributes relevant prediction overlap protected aributes treatment parity lead accuracy hence sub-optimal utility decision-maker. number proposed predictors machine learning literature satisfy treatment parity don’t pedreshi show satisfying treatment parity sucient condition avoid discrimination background knowledge available. especially ubiquity social media many avenues personal information including protected aributes leaked information readily available public domain. indeed korolova note using data available facebook proles infer user sexual orientation religious aliation etc. kosinski show possible accurately predict range highly sensitive personal aributes including sexual orientation ethnicity religious views gender easily accessible digital records behaviour. furthermore calders ˇzliobait˙e show assumptions made construction predictor might hold real-life scenarios help ctitious examples. mismatch leads discrimination even information protected aributes removed prediction guided neutral arguments accuracy only. treatment parity corresponds chiey approach blind counter racial/gender discrimination. bonilla-silva submit discrimination still possible protected group because structural barriers hinder protected groups. particular bonilla-silva analyze notion race-blindness terms important frame abstract liberalism stated practice invoking abstract ideals ignoring concrete proposals reduce inequality ground results systematic discrimination. moreover bonilla-silva also extensively provide studies document various discriminatory practices domains like education housing credit etc. fryer provide study compare eciency race-blind approach. study based hypothetical experiment supposing seven selected colleges would admit fraction many students were fact admied. problem choose students retain achieving goal maintaining original racial representation. study shows that short race-blind approach ecient race-conscious approach long former less ecient laer. taslitz corresponding essays symposium articulate discrimination perpetuated american criminal justice system despite using race-blind approach. alternatively studies show blind approach sometimes work. example goldin rouse show using blind auditions help reducing discrimination women hiring musicians symphony orchestras. shown table group fairness follows particular notion egalitarian fairness impact. imposes condition predictor predict particular outcome individuals across groups almost equal probability. denition clear that group fairness fact imposes condition statistical parity predictor. statistical parity ensures individual belonging group population equally likely receive particular outcome individual belonging another group population. choose group individuals protected aributes statistical parity stipulates predictor treats general population statistically similarly protected group. statistical parity also called demographic parity makes demographics receiving benecial outcome almost identical demographics population whole. note unlike formalizations fairness group fairness independent ground truth i.e. label information. particularly useful reliable ground truth information available. might true scenarios aggregation historical manual decisions used training automated predictor used predict outcome future cases. domains like employment housing credit criminal justice discrimination protected groups well-documented erefore disproportionality respective outcomes individuals protected group non-protected group justied based historical data. alternatively cases disproportianlity respective outcomes justied using non-protected aributes imposing statistical parity leads incorrect outcomes amount discrimination qualied candidates. illustrate this consider example given luong consider requires special driving license predictor scenario takes resumes applicants produces binary outcome indicating whether called interview. younger applicants required special driving license elder applicants unequal positive outcome rates across groups predictor justied legally admissible aributes. dwork indicate another deciency group fairness noting predictor stipulated select qualied individuals within groups long maintains statistical parity. might lead predictor calibrated give benecial outcomes unqualied individuals group qualied individuals group unqualied individuals receiving benecial outcomes cause reduced performance argument made justify individuals group receive benecial outcomes future. formalization group fairness follows notion collectivist egalitarianism distributive justice. practice biggest ected) implementation group fairness application armative action address discrimination basis caste gender here mostly discuss armative action program india exactly equivalent stated notion group fairness unlike armative action program bagde study eects armative action program maintains group fairness respect protected groups admissions educational institutes. study shows armative action lile impact on-time graduation considered measure performance admied student. nding goes opinion armative action policies might harm intended beneciaries placing academic situations poorly suited. contrary study positive change test scores beneciaries armative action year college. galanter provide another assessment armative action program. major ndings interest follows armative action helped substantially redistributing access education employment wider spectrum society earlier although redistribution evenly spread among protected groups. armative action brought signicant increase number people protected group access prominent social roles would otherwise lacking. evidence also provided pande short people protected group availing social benets armative action might experience social rejection workplace educational institutes. although social rejection exists independently armative action magnify moreover long increased level education employment weaken stereotypical association protected groups incompetence ignorance. regarding claim equivalence aptitude merit test scores questioned furthermore social capital also contributes towards test scores. moreover underlying assumption behind claim allocation social benets without armative action meritocratic. however several studies conrmed discrimination basis protected aributes. second claim several studies conducted examine supporting evidence respect armative action policies usa. survey studies holzer neumark concludes empirical case armative action grounds eciency weak best. india deshpande weisskopf study eect armative action policies eciency workforce indian railways world’s largest employer subject armative action. study found evidence support claim increasing proportion protected group armative action policies leads loss eciency. individual fairness table shows individual fairness follows particular notion egalitarian fairness impact. ascertains predictor fair produces similar outputs similar individuals. formally dened follows dwork notion fairness. formulation problem predictor takes individual population input outputs probability distribution outcomes formulation individual fairness interpreted mean distributions assigned similar people similar. luong similar notion detecting discrimination. member protected group negative outcome look individuals similar non-protected aributes. outcomes individuals protected group non-protected group similar non-protected aributes signicantly dierent discrimination said occurred. dwork similarity modeled distance metric. social sciences literature notion fairness traced back book nicomachean ethics. called individualism egalitarianism. according sacksteder formal principle justice. idea treating similar cases similarly central theme legal framework countries. given denition notion delegates responsibility ensuring fairness predictor distance metric. distance metric uses protected aributes directly indirectly compute distance individuals predictor satisfying denition would deemed discriminative. erefore potency notion fairness prevent discrimination depends largely upon distance metric used. hence individual fairness stated above considered suitable domains reliable non-discriminating distance metric available equality opportunity shown table equality opportunity follows particular notion egalitarian fairness impact. literature machine learning formalization equality opportunity introduced hardt equivalent formalization also proposed concurrently independently zafar equal opportunity respect group considered stipulation states true positive rate groups. equivalent notion zafar called disparate mistreatment asks equivalence misclassication rates across groups. social sciences literature corresponding notion presented rawls central feature rawlsian theory original position parties deprived knowledge personal aributes social historical circumstances stunted ambition many parts world members protected group socially conditioned accept inappropriate aspire social benets including education jobs wealth. example women shunted socialization toward elds graduate study less well-funded frequently poorer professional employment prospects impediments social advantages presented account protected aributes well. example orat neuman argue basis surveys interviews protected caste groups face discrimination underlying aitudinal orientations. obvious equality opportunity could avoid discrimination social conditioning. notion equality opportunity also criticized considering eect discrimination protected aributes like gender race included list aributes aecting individual’s life prospects. shown protected aributes like race gender aect one’s access opportunities domains education business politics many parts world. example comprehensive recent study states economies covered least impeding women’s economic opportunities exclusion aributes like race gender list aributes deemed aecting individual’s life prospects notion equality opportunity thus calls question suitability domains exists vast evidence aributes indeed aect one’s prospects. preference-based fairness zafar introduce formalizations fairness follow particular notions non-egalitarian fairness impact treatment. order provide denitions same authors introduce notion group benet. definition group benet predictor particular group population dened expected proportion individuals group predictor predicts benecial outcome. definition group-conditional predictor {hs}s said satisfy preferred treatment group population receives benet respective predictor would received predictor i.e. preferred treatment compare predictors zafar suggest formalization preferred impact follows particular notion non-egalitarian fairness impact. certain applications might single universally accepted benecial outcome. possible individuals group prefer another outcome preferred majority group. order alleviate concerns collectivist denition group benet needs extended account individual preferences. utility values predictors. hand holcombe show freedom envy neither necessary sucient fairness. many real-world problems needs fair ecient solutions amongst groups. ecient solution ensures greatest possible benet groups. collective decision making problems like domain applications prediction machine learning formally expressed notion pareto-eciency. pareto-ecient solution increase benet group without strictly decreasing benet another group. however noted deciding whether pareto-ecient envy-free allocation computationally hard even simple additive preferences demonstrate fairness formalizations described above predictors satisfying would behave ctitious scenario. assume population evenly divided groups group aribute value group aribute value predictors employed predict outcome reliable label information available. note group-conditional i.e. uses individual group individual group assume distance metric individuals available predictors. refer figure exposition scenario. next shall predictors satisfy considered satises individual fairness close according distance metric receive output individuals away close together receive output predictors assign dissimilar outputs individuals similar according distance metric. satises equality opportunity prospective notions fairness section describe prospective notions fairness haven’t considered literature machine learning far. intention propose notions address following critique considered formalizations. seen section many past formalizations machine learning literature oset fact social benets proposed prediction algorithms used allocated unequally among people owing aributes suggest notions literature social sciences address concern. equality resources dworkin propose notion equality resources unequal distribution social benets considered fair results intentional decisions actions concerned individuals. notion stipulates distribution social benets satisfy following properties ambition-sensitive individual’s ambitions choices endowment-insensitive individual’s unchosen circumstances including natural endowments oset. circumstances aect one’s chances achieving social benets compensated. second property equality resources diers equality opportunity laer considers dierences natural endowments ributes sex) facts nature need adjusted achieve fairness. equality capability functioning extends insight people held responsible aributes include personal aributes cause diculty developing functionings. functionings states being doing various states existence activities individual undertake. example vary simple things well-nourished housed complex things happy self-respect. notion calls equalizing capabilities dened valuable functionings individual eective access argue variations related protected attributes like gender race caste give individuals unequal powers achieve goals even opportunities. order equalize capabilities people compensated unequal powers convert opportunities functionings. point sounds similar quality resources described above. crucially however notion equality capability calls addressing inequalities social endowments well natural endowments contrast equality resources main strengths notion fairness exible allows developed applied many dierent ways indeed notion used foundations human development paradigm united nations. major criticism equality capability theory concerns failure identify valuable capabilities another criticism informational requirement approach high second criticism applies equality resources well makes exact mathematical formalizations notions potentially dicult problem. however suitability prospective formalizations domains natural endowments social endowments impede individual’s prospect receive social benets makes open problem formalizing worthwhile. discussion directions plato’s republic socrates says long know shall hardly know whether virtue paraphrase socrates conforming fairness formalization accurately analyze fairness machine learning prediction algorithms evolving rapidly important analyze fairness formalizations considered far. juxtaposed fairness notions considered machine learning literature corresponding theories distributive justice social sciences literature. theoretical critique analysis fairness notions social sciences literature. outlined performance fairness notions used policy employed large population rmative action). critiques formalizations experimental studies large-scale practice serve guiding principles choosing fairness formalizations particular domains. also proposed prospective notions fairness studied extensively social sciences literature prediction machine learning. course claim notions serve panacea critiques notions already considered machine learning literature. intention behind nominating notions initiate discussion fairness formalizations prediction machine learning recognize following since individuals held responsible attributes change social benets receive turn aect prospects life depend upon attributes. machine learning prediction algorithms used make decisions social benets whose allocation exhibits discrimination people owing aributes fairness formalizations oset existing discrimination aributes. course obvious diculty lies determining attributes individual education glance might seem like aribute individual choose. however several studies show aributes individual impact level education. example jacobs provide comprehensive survey education demonstrates women particularly disadvantaged respect outcomes education. seen academia women make full professors university presidents presidents doctoral degree-granting institutions similar gender disparity higher echelons positions found politics business. moreover despite fact women fare relatively well access education usa. indeed college students women however easy access education women universal phenomenon discrimination present many parts world conrmed department economic social aairs united nations leads another insight level discrimination varies domain erent issues within single domain seen above) place interest. proposing notions fairness credible surveys appraising discrimination caused protected aributes taken consideration. fairness formalizations used prediction tasks corresponding particular social benet also depend upon whether benet question considered basic human right. domains like aordable housing essential health-care basic education fairness formalizations actively remove disparity provide benets individuals considered. however domains require qualications evenly distributed population justication could made relaxing stipulations. time independent eorts could made diuse ability qualications evenly population. richard arneson. rawlsian equality opportunity. philosophical studies international journal philosophy analytic tradition hp//www.jstor.org/stable/ surendrakumar bagde dennis epple lowell taylor others. armative action work? caste gender college quality academic success india. american economic review marianne bertrand sendhil mullainathan. emily greg employable lakisha jamal? field experiment labor market discrimination. american economic review eduardo bonilla-silva. racism without racists color-blind racism persistence racial inequality united states rowman lileeld publishers. john burn-murdoch. problem algorithms magnifying misbehaviour. hps//www.theguardian.com/news/datablog// aug//problem-with-algorithms-magnifying-misbehaviour toon calders sicco verwer. naive bayes approaches discrimination-free classication. data min. knowl. discov. doihp//dx.doi.org/./s---x toon calders indr˙e ˇzliobait˙e. unbiased computational processes lead discriminative decision procedures. springer berlin heidelberg berlin heidelberg doihp//dx.doi.org/./---- danielle keats citron frank pasquale. scored society process automated predictions. washington review //digitalcommons.law.umaryland.edu/fac pubs// lilia cortina dana kabat-farr emily leskinen marisela huerta vicki magley. selective incivility modern discrimination organizations. journal management doihp//dx.doi.org/. bart keijzer sylvain bouveret tomas klos yingqian zhang. complexity eciency envy-freeness fair division indivisible goods additive preferences. springer berlin heidelberg berlin heidelberg doihp//dx.doi.org/./---- ashwini deshpande katherine newman. path leads role caste post-university employment expectations. economic political weekly hp//www.jstor.org/stable/ ashwini deshpande omas weisskopf. armative action productivity indian railways. review black political economy doihp//dx.doi.org/./s--- satish deshpande. exclusive inequalities merit caste discrimination indian higher education today. economic political weekly hp//www.jstor.org/stable/ cynthia dwork moritz hardt toniann pitassi omer reingold richard zemel. fairness rough awareness. proceedings innovations eoretical computer science conference hp//doi.acm.org/./ claudia goldin cecilia rouse. orchestrating impartiality impact blind auditions female musicians. american economic review doihp//dx.doi.org/./aer... alessandro simoni guido boni. anti-discrimination legislation member states comparison national anti-discrimination legislation grounds racial ethnic origin religion belief council directives. www.pedz.uni-mannheim.de/daten/edz-b/ebr//art italy-en.pdf sukhadeo orat paul aewell. legacy social exclusion correspondence study discrimination india. economic political weekly hp//www.jstor.org/stable/ sukhadeo orat katherine neuman blocked caste economic discrimination modern india. oxford university press. //econpapers.repec.org/repecoxpobooks u.k. legislation. discrimination act. u.k. legislation. race relation act. u.s. federal legislation. civil right act. u.s. federal legislation. discrimination employment act. u.s. federal legislation. fair housing act. u.s. federal legislation. equal credit opportunity act. u.s. federal legislation. pregnancy discrimination act. kaveh waddell. algorithms bring minorities’ credit scores. hps//www.theatlantic.com/technology/archive/ //how-algorithms-can-bring-down-minorities-credit-scores// muhammad bilal zafar isabel valera manuel gomez rodriguez krishna gummadi. fairness beyond disparate treatment disparate impact learning classication without disparate mistreatment. proceedings international conference world wide international world wide conferences steering commiee republic canton geneva switzerland doihp//dx.doi.org/./. indre zliobaite. survey measuring indirect discrimination machine learning. corr abs/. hp//arxiv.org/abs/. indr˙e ˇzliobait˙e. measuring discrimination algorithmic decision making. data mining knowledge discovery //doi.org/./s--- data berkeley. jerry jacobs. gender equality higher education. surinder jodhka katherine newman. name globalisation meritocracy productivity hidden language caste. economic political weekly hp//www.jstor.org/stable/ toshihiro kamishima shotaro akaho hideki asoh sakuma. fairness-aware classier prejudice remover regularizer. proceedings european conference machine learning knowledge discovery databases volume part springer-verlag berlin heidelberg doihp//dx.doi.org/./---- mahew cynthia matuszek sean munson. unequal representation gender stereotypes image search results occupations. proceedings annual conference human factors computing systems hp//doi.acm.org/./. aleksandra korolova. privacy violations using microtargeted case study. icdmw ieee international conference data mining workshops sydney australia december doihp //dx.doi.org/./icdmw.. michal kosinski david stillwell graepel. private traits aributes predictable digital records human behavior. proceedings national academy sciences binh luong salvatore ruggieri franco turini. k-nn implementation situation testing discrimination discovery prevention. proceedings sigkdd international conference knowledge discovery data mining york hp//dx.doi.org/./. rohini pande. mandated political representation increase policy inuence disadvantaged minorities? eory evidence india. american economic review hp//www.jstor.org/stable/ dino pedreshi salvatore ruggieri franco turini. discriminationaware data mining. proceedings sigkdd international conference knowledge discovery data mining hp//doi.acm.org/ white house project. white house project report benchmarking women’s leadership. white house project. hps//books.google.fr/books?id= lenweacaaj mozaar qizilbash. capabilities wellbeing human development survey. journal development studies doihp //dx.doi.org/./ john rawls. eory justice. harvard university press. john roemer. eories distributive justice. william sacksteder. idea justice problem argument. chaim perelman. ethics doihp//dx.doi.org/./ amartya sen. justice means versus freedoms. philosophy public", "year": 2017}