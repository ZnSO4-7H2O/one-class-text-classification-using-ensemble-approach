{"title": "The Statistical Inefficiency of Sparse Coding for Images (or, One Gabor  to Rule them All)", "tag": ["cs.CV", "cs.AI"], "abstract": "Sparse coding is a proven principle for learning compact representations of images. However, sparse coding by itself often leads to very redundant dictionaries. With images, this often takes the form of similar edge detectors which are replicated many times at various positions, scales and orientations. An immediate consequence of this observation is that the estimation of the dictionary components is not statistically efficient. We propose a factored model in which factors of variation (e.g. position, scale and orientation) are untangled from the underlying Gabor-like filters. There is so much redundancy in sparse codes for natural images that our model requires only a single dictionary element (a Gabor-like edge detector) to outperform standard sparse coding. Our model scales naturally to arbitrary-sized images while achieving much greater statistical efficiency during learning. We validate this claim with a number of experiments showing, in part, superior compression of out-of-sample data using a sparse coding dictionary learned with only a single image.", "text": "k-dimensional observation k-dimensional basis vector scalar coeﬃcient expansion generates call dictionary code book role compression transmit pairs given ﬁnite support samples inference observed like sparse coding. learning model also like sparse coding sense pair take step direction negative gradient factored model must apply chain rule convexity appeal sparse coding inference convex. interestingly factored sparse coding approach presented retains property. learning dictionary lone generic ﬁlter subset dictionary learned factored sparse coding algorithm ﬁrst images cifar- dataset conventional sparse coding dictionaries elements elements well little data smaller dictionaries longer overcomplete larger dictionaries simply memorize training examples. figure panel factored coding model basis vectors reconstructs test images using largest coeﬃcients. individual gabor ﬁlters still visible combined together form reconstruction. panel shows mean reconstruction error using largest coeﬃcients ﬁrst test images cifar- dataset. variety dictionary sizes code lengths factored sparse coding models consistently require half many nonzero coeﬃcients order produce reconstruction error non-factored models estimation error rmse values negligeable error bars omitted clarity. figure unfactored sparse coding factored sparse coding out-of-sample data using dictionaries learned increasing amounts data. images enough factored model learn idealized gabor edge-ﬁlter conventional sparse coding approach requires enough data learn gabor many locations. compared figure values correspond right-most values", "year": 2011}