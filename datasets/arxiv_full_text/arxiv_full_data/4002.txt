{"title": "Feature Selection via Sparse Approximation for Face Recognition", "tag": ["cs.CV", "cs.AI"], "abstract": "Inspired by biological vision systems, the over-complete local features with huge cardinality are increasingly used for face recognition during the last decades. Accordingly, feature selection has become more and more important and plays a critical role for face data description and recognition. In this paper, we propose a trainable feature selection algorithm based on the regularized frame for face recognition. By enforcing a sparsity penalty term on the minimum squared error (MSE) criterion, we cast the feature selection problem into a combinatorial sparse approximation problem, which can be solved by greedy methods or convex relaxation methods. Moreover, based on the same frame, we propose a sparse Ho-Kashyap (HK) procedure to obtain simultaneously the optimal sparse solution and the corresponding margin vector of the MSE criterion. The proposed methods are used for selecting the most informative Gabor features of face images for recognition and the experimental results on benchmark face databases demonstrate the effectiveness of the proposed methods.", "text": "abstract—inspired biological vision systems over-complete local features huge cardinality increasingly used face recognition last decades. accordingly feature selection become important plays critical role face data description recognition. paper propose trainable feature selection algorithm based regularized frame face recognition. enforcing sparsity penalty term minimum squared error criterion cast feature selection problem combinatorial sparse approximation problem solved greedy methods convex relaxation methods. moreover based frame propose sparse ho-kashyap procedure obtain simultaneously optimal sparse solution corresponding margin vector criterion. proposed methods used selecting informative gabor features face images recognition experimental results benchmark face databases demonstrate effectiveness proposed methods. face recognition received extensive attention wide range application identity authentication access control surveillance human-computer interaction numerous novel face recognition algorithms proposed issue successful face recognition systems development effective face representation namely extract select discriminative features represent face image. according region features derived face representation methods generally divided categories holistic representation local representation. holistic representation extract features whole face image local representation calculating features local faical regions. authors institute information science engineering central south university changsha hunan china. e-mail {yxliang wanglei yxiang bjzou}mail.csu.edu.cn extensively studied however local areas often descriptive appropriate dealing facial variations expression partial occlusion illumination since variations appearance affect small part face region. local feature analysis pioneers study local representation face recognition. recently local representation approaches received attention shown promising results lots local feature descriptors haar-like features sift features histograms oriented gradient edge orientation histograms gabor features local binary patterns bio-inspired features learned descriptor etc. successfully applied face recognition. local features often over-completed whereas relatively small fraction relevant recognition task. thus feature selection crucial necessary step select discriminant local features obtain sparse face representation. prior knowledge choice local feature dictionary large cardinality often limited consistent theory still missing numerous learned methods emerging empirical practice effectiveness excellent review feature selection approaches machine learning). adaboost-based methods popular impressive feature selection methods face recognition scenario possible problem methods time consuming training stage need training evaluating classiﬁer feature component. alternative regularizedbased method sparsify respect dictionary features sparsity-enforcing regularization techniques main merits regularized approach effectiveness even presence small number data coupled fact supported well-grounded theory another potential merit regularized methods analyze feature components together appropriate capture groups correlated features whereas adaboost-based method consider relevance feature separately thus ignore possible dependencies features. based regularized frame paper propose novel feature selection method based classical minimum squared error criterion assumes linear dependence feature components discriminant functions. cast feature selection problem combinatorial sparse approximation problem enforcing sparsity penalty term criterion solution obtained greedy methods matching pursuit orthogonal matching pursuit convex relaxation methods restrict linear models relatively easy compute absence information suggesting otherwise linear models attractive candidates. further linear model extended nonlinear cases explicitly implicitly giving function local feature components. latter well-known kernel trick. arbitrary selection margin vector procedure cannot guarantee obtain optimal separating vector even separable case impose sparse constrains ho-kashyap procedure propose named sparse procedure obtain simultaneously optimal sparse solution corresponding margin vector. similar original procedure proposed procedure iterative scheme alternates solution sparse vector based current margin vector process updating margin vector. ﬂexible work greedy methods convex relaxation methods. gabor representative local features face recognition. select gabor feature start representation peculiar ability model spatial summation properties receptive ﬁelds called cells primary visual cortex. apply proposed feature selection method select informative gabor features face recognition. experimental results benchmark face databases demonstrate effectiveness proposed feature selection methods. method mainly inspired work also applying sparse regularized term linear model perform feature selection. nevertheless linear model neglects bias hand enforces linear dependence between feature components class labels hand. fact simple linear dependence equivalent entries margin vector equal criterion model. method starts criterion considers simultaneously bias adaptive margin vector hence seemed generalization method sparse solution moreover obtained iterative soft-thresholding method convergence relies careful normalization features component training samples time destroy structure features. method adheres original features without additional normalization also obtain convergence. solved gradient search procedure. however solution provide feature selection sense it’s typically non-sparse. enforcing sparse regularization term criterion turn feature selection solving following sparsity-enforcing criterion nonzero entries vector threshold quantiﬁes much improvement approximation error necessary admit additional term approximation. classic combinatorial sparse approximation problem solved greedy techniques construct sparse approximant step time selecting atom strongly correlated residual part signal update current approximation. alternative solving smse criterion convex relaxation methods replace problem relaxed version solved efﬁciently. norm provides natural convex relaxation quasi-norm suggests able solve sparse approximation problems introducing norm place quasi-norm. heuristic relaxed version smse criterion derived follows unconstrained convex function thus standard mathematical programming softwares used minimizer. parameter negotiates compromise approximation error sparsity. proved feature matrix incoherent threshold parameters correctly chosen solution rsmse criterion identiﬁes every signiﬁcant atom section start criterion propose novel feature selection method based sparsity-enforcing regularized techniques. based frame section present sparse extension classical procedure feature selection. section ﬁrst brieﬂy review gabor face representation illustrate apply proposed feature selection frame select informative gabor features face recognition. experiments analysis described section whereas section concludes paper. feature selection based sparse criterion section present feature selection algorithm based criterion. mentioned before restrict case linear discriminant functions linear components feature denotes discriminant function; bias threshold; weights; augmented feature vector augmented weight vector respectively. since face recognition cast classiﬁcation intra-personal extrapersonal variation focus binary classiﬁcation problem. suggested substitute negative samples negatives forget labels look weight vector samples. indeed relation invariant positive scaling thus deﬁne canonical hyperplane positive constant called margin. problem reformulated following linear system equations notice criterion entries margin vector arbitrary positive constants. obviously different choice would typically lead different solutions. solution directly related fisher discriminant vector proper choice margin vector smse solution rsmse solution gives natural sparse generalization fisher linear discriminant. hereafter refer resulting feature selection algorithm sparse fisher procedure. moreover special case rsmse criterion degenerates linear model described thus method also seemed generalization method feature selection based sparse procedure objective minimizing kya− discussed procedures yield solution whether samples linearly separable guarantee vector separating vector even separable case. however separable case exist margin vector positive entries corresponding solution separating vector. procedure extends procedure deal problem determining alternately components cannot decrease. borrowing ideas section propose sparse version procedure extend method described former section. speciﬁcally speaking proposed procedure stages iteration sparse approximating essentially evaluates updating margin vector sparse approximating conveniently performed using greedy convex relaxation algorithms solve smes criterion given similar original procedure updating rule start refuse reduce components namely initialization iteration index repreat convergence sparse approximation stage greedy algorithms convex relaxation methods computer approximating solution smes criterion noteworthy although convergence original procedure proven theoretically owing introduction sparse approximation stage exact analysis convergence proposed algorithm deterministic manner rather complicated even impossible. nevertheless obtain convergence noticeable problem discrete convolution choice proper size convolution mask. large enough show nature gabor kernels large computation efﬁciency. suggested truncate gabor ﬁlters times span gaussian function. span gaussian function gabor mask truncated width thus experiments size gabor ﬁlters corresponding scale time turn attention feature selection high dimensional gabor representation. similarly moghaddam temporarily cast face recognition classiﬁcation intra-personal extra-personal variation. pair face images compare corresponding gabor feature components. speciﬁcally pair input images obtain feature vector whose elements absolute difference corresponding gabor representations. given training augmented feature matrix following routine described section by-no-means negligible problem practical overwhelmingly huge size unbalance training samples instance given training includes images individuals total number obviously huge samples size lead severe memory computational problem. addition unbalance training samples bias performance feature selection. order obtain balanced systems reasonable size randomly sample positive negative samples comparable ratio build augmented feature matrix practical sample negative section describe specialize proposed feature selection frame case face recognition. ﬁrst brieﬂy review gabor representation face describe apply proposed feature selection methods select gabor features face recognition. start widely used gabor representation kernels gabor ﬁlters similar receptive ﬁeld proﬁles mammalian cortical simple cells exhibit desirable characteristics spatial locality orientation selectivity gabor representation face image obtained convolving image gabor ﬁlters commonly deﬁned follows coordinate vector; parameters deﬁne orientation scale gabor ﬁlter; parameters standard deviation gaussian window; wave vector given kνeiφµ kmax eight different orientations chosen; kmax maximum frequency spatial factor kernels frequency domain. face recognition area researchers commonly gabor ﬁlters rather using smaller size face images experiments. thus gabor ﬁlters used. convolving face image gabor ﬁlters extracting magnitudes information generate high dimensional gabor representation. example build augmented feature matrix solution smse criterion given adaptive margin vector according procedure previously described. gabor feature components corresponding non-zero entries augmented weight vector selected informative ones used face recognition. feature selection frame based linear discriminant functions also establishes linear classiﬁer bias discriminating intra-personal extrapersonal difference used face recognition directly. however also consider usage pure feature selection tool reduce numbers gabor features adopt common classiﬁers nearest neighbor classiﬁer fisher classiﬁer support vector machines recognition. experiments results order evaluate proposed approach carry experiments large face databases cas-peal-r face database. cas-peal-r face database contains images chinese subjects different variations pose expression accessories lighting. face database contains labeled face images collected news sites internet. images belong different individuals high variations position pose lighting background camera quality. therefore database appropriate evaluating face recognition methods realistic unconstrained environments. eyes locations given cas-peal-r database. database adopted standard ﬁducial point detector extract eyes locations annotated manually whenever automatic eyes locator failed. restrictively follow cas-peal-r evaluation protocol speciﬁes training gallery probe sets therefore training sets include images subjects ratio intrapersonal sample size extra-personal sample size keep intrapersonal samples randomly sampling extra-personal samples ratio gabor features considered linear problem build rather large. fact size augmented feature matrix multiplication matrix infeasible. possible choice reduce number gabor features possible. prior knowledge magnitude gabor ﬁlters sensitive positions reduce number positions simply sampling scheme factor thus number positions roughly sixteenth total number pixels. sampling size augmented conducted experiments cas-pealr training using ssmes sfisher procedure select informative gabor features respectively. characteristics observed statistics. location distribution selected gabor features shown fig. interesting selected gabor features resulting three methods located around prominet facial features eyebrows eyes nose mouth seldom located tribute different distribution features selected different methods somewhat uniform -scale -scale likely important scales horizontal vertical gabor kernels extracted stronger features orientation. classiﬁcation results selected gabor features adopted face recognition. classical classiﬁers chosen recognize faces. mentioned above proposed feature selection frame perform intra-personal extra-personal recognition task. thus also used face recognition treating face recognition series pair matching problems. however many situations subject satisfying separating condition. order make ﬁnal decision simply classify unknown face subject whose samples maximize linear discriminant function i.e. margin. therefore sense seen maximum margin classiﬁer also implemented previous gaborbased approaches comparison. ﬁrst using gabor feature without feature selection face representation recognition denoted g+nnc. second method g+fc denotes method i.e. pca+lda downsampled gabor features. third method ada+fc agfc method using adaboost select gabor features classiﬁcation. clarity ssmes+nnc sfisher+nnc shk+nnc respectively denote method using ssmes sfisher procedure select gabor features recognition. similarly classiﬁers corresponding methods denoted ssmes+mmc sfisher+mmc shk+mmc ssmes+fc sfisher+fc shk+fc. investigated kinds distance measurements distance distance cosine distance found distance achieves best performance cosine distance performing best. thus selected distance cosine distance cheek area. indicates prominent facial features regions carry important discriminating information cheek region conveying less information. moreover minority selected features located external features cheek contour line. fact although external region cover face much external features implicitly uses shape information thus useful distinguishing thin faces round faces. result agreed ref. also compared frequency gabor kernels selected gabor features. fig. illustrates frequency gabor kernels leading gabor features selected ssmes sfisher procedure. obviously different scales orientations confc. implementation number gabor features used g+fc downsampled dimension ada+fc gabor features selected adaboost. optimal dimension determined testing possible dimensions. results different probes sets shown compared table selection frame effective face recognition. third sfisher perform better ssmes sense feature selection classiﬁcation. results indicate consideration bias margin make learning process overﬁts training data increase generalizability. table obtain several major observations. first although proposed feature selection frame also establishes classiﬁer straightforwardly used face recognition performances satisfactory expected especially ssmes method. explanation though feature selection frame select effectively meaningful features overestimate underestimate corresponding weights leading over-ﬁtting problems. comparing ssmes classiﬁers used sfisher consider bias margin thus achieve better results. second observation based methods perform much better classiﬁers based methods. general algorithms regularized-based feature selection procedure gabor features slightly outperform ada+fc gabor features selected adaboost comparable g+fc using gabor features shows proposed feature also conducted experiments database investigation. unlike cas-peal-r database database larger degree variability recognition done pairs matching instead searching similar face database. still followed protocol gives views view model selection algorithm development view performance reporting. view speciﬁes training containing pairs testing containing pairs. view consists sets images case. combined different training/testing pairs. experiments training view chosen training feature selection model performance reported using -fold cross validation view proposed feature selection frame used feature selector select informative gabor features original original features. directly adopted proposed frame classiﬁer recognize unknown pairs company classiﬁer. corresponding methods referred smess sfisher smess+svm sfisher+svm shk+svm respectively. also investigated performance method g+fc uses original features representation classiﬁer. results experiments described table comparison curves different methods illustrated fig. seen direct application proposed feature selection frame classiﬁer perform somewhat worse performance achieved using classiﬁer. recalled sfisher algorithm actually performs sparse fisher classiﬁcation enforcing regularization techniques face recognition. cast feature selection problem combinatorial sparse approximation problem enforcing sparsity penalty term criterion solved greedy methods convex relaxation methods. moreover introduced sparsity constrain traditional procedure proposed sparse procedure obtain simultaneously optimal sparse solution corresponding margin vector criterion. proposed frame applied select informative gabor features face recognition experimental results cas-peal-r face database face database favorable previous state-ofthe-art gabor-based methods. future work includes exploring effective lowlevel face representation sophisticated classiﬁcation strategy produce better performance. acknowledgments research partially supported national natural science funds china doctoral program foundation institutions higher education china major program national natural science foundation china open project program state cad&cg zhejiang university. p.n. belhumeur j.p. hespanha d.j. kriegman eigenfaces fisherfaces recognition using class speciﬁc linear projection ieee trans. pattern anal. mach. intell. vol. uses features achieves comparable performance g+fc method using original features terms accuracy curve phenomena demonstrates effectiveness proposed feature selection frame. again sfisher especially perform better ssmes sense feature selection classiﬁcation dataset attributed consideration bias adaptive margin linear model s.g. shan x.l. chen d.l. zhou x.h. zhang d.b. zhao cas-peal large-scale chinese face database baseline evaluations ieee trans. syst. cybern. vol. g.b. huang ramesh berg learned-miller labeled faces wild database studying face recognition unconstrained environments university massachusetts amherst technical report october s.c. liao pietikainen s.t. gabor volume based local binary pattern face representation recognition proc. ieee conf. automatic face gesture recognition c.liu h.wechsler gabor feature based classiﬁcation using enhanced fisher linear discriminant model face recognition ieee trans. image process. vol. ruiz solar verschae correa recognition faces unconstrained environments comparative study eurasip adv. sig. vol. pp.- tibshirani regression shrinkage selection lasso roy. statist. soc. vol. j.a. tropp greed good algorithmic results sparse approximation ieee trans. inf. theory vol. wagner wright ganesh z.h. zhou towards practical face recognition system robust registration illumination sparse representation proc. ieee conf. computer vision pattern recognition x.g. wang zhang z.y. zhang boosted multi-task learning face veriﬁcation applications images video search proc. ieee conf. computer vision pattern recognition wright a.y. yang ganesh s.s. sastry robust face recognition sparse representation ieee trans. pattern anal. mach. intell. vol. wright implicit elastic matching random projections pose-variant face recognition proc. ieee conf. computer vision pattern recognition g.c. zhang x.s. huang s.z. y.s.wang x.h. boosting local binary pattern -based face recognition proc. advances biometric person authentication", "year": 2011}