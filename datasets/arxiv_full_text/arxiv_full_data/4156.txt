{"title": "Quick and energy-efficient Bayesian computing of binocular disparity  using stochastic digital signals", "tag": ["cs.CV", "cs.AI"], "abstract": "Reconstruction of the tridimensional geometry of a visual scene using the binocular disparity information is an important issue in computer vision and mobile robotics, which can be formulated as a Bayesian inference problem. However, computation of the full disparity distribution with an advanced Bayesian model is usually an intractable problem, and proves computationally challenging even with a simple model. In this paper, we show how probabilistic hardware using distributed memory and alternate representation of data as stochastic bitstreams can solve that problem with high performance and energy efficiency. We put forward a way to express discrete probability distributions using stochastic data representations and perform Bayesian fusion using those representations, and show how that approach can be applied to diparity computation. We evaluate the system using a simulated stochastic implementation and discuss possible hardware implementations of such architectures and their potential for sensorimotor processing and robotics.", "text": "reconstruction tridimensional geometry visual scene using binocular disparity information important issue computer vision mobile robotics formulated bayesian inference problem. however computation full disparity distribution advanced bayesian model usually intractable problem proves computationally challenging even simple model. paper show probabilistic hardware using distributed memory alternate representation data stochastic bitstreams solve problem high performance energy eﬃciency. forward express discrete probability distributions using stochastic data representations perform bayesian fusion using representations show approach applied diparity computation. evaluate system using simulated stochastic implementation discuss possible hardware implementations architectures potential sensorimotor processing robotics. using cameras stereoscopic setup reconstruct tridimensional geometry visual scene similar performed human stereopsis important issue computer vision major applications autonomous robotics issue active research topic since least years wide range methods algorithms proposed evaluated standardized benchmarks several works shown binocular disparity computation eﬃciently formulated bayesian inference problem disparity value pixel expressed discrete probability distribution computed probabilistic model using likelihood values speciﬁed image data. however computing full disparity distribution whole images proves challenging compuationally demanding. that’s works binocular disparity using bayesian models instead reduce output single disparity value pixel approach simpliﬁes computation allows reformulate energy minimization problem solved eﬃciently classic optimization techniques dynamic programming however means although computation based probabilistic formalism yields deterministic disparity values disparity distributions despite latter representation richer oﬀering many beneﬁts especially robotics sensorimotor systems. full disparity distributions accurately represent cases stereopsis suﬃcient completely determinate world geometry ambiguous pixels multiple matches pixels matches probabilistic representations also directly used bayesian mapping navigation methods bayesian occupation ﬁlter generally probabilistic bayesian robotics techniques bayesian inference also provides powerful framework express assumptions prior knowledge structure world prior probability distributions. stochastic computing ﬁeld dedicated designing using computing devices intentionally stochastic perform probabilistic reasoning using non-von neumann architectures distributed memory speciﬁc data representations. speciﬁcally bambi project research eﬀort develop stochastic machines implementing bayesian inference paper show bayesian machines used efﬁciently compute full binocular disparity distribution paving towards fully stochastic autonomous robots sensorimotor systems. remainder article ﬁrst give overview related work section stochastic computing fast binocular disparity computation. describe bayesian binocular disparity computation model section section dedicated description stochastic computer implementing model focusing ﬁrst general principles computation using stochastic bitstream second application bayesian disparity computation. evaluation system results presented section discussed section conclude section summing implications work design bayesian robotic systems using stochastic components discussing future prospects topic. general idea stochastic computations temporal coding traced back seminal works neumann gaines highlighted interest data representations approaches widely pursued rapid development eﬃcient deterministic computers. topic recently received renewed attention development probabilistic bayesian models computer science engineering speciﬁcally sensorimotor cognitive systems limitations classic computers implement models. idea developing hardware dedicated bayesian reasoning recently pursued several teams exploring diﬀerent computational paradigms perform probabilistic inference. address problem approximate inference mansinghka uses sampling methods approximate inference similar jonas designed markov chain monte carlo based algorithms provide representation probability distributions sets samplers compute exact inference number diﬀerent frameworks toolsets forward. vigoda designed architectures based probabilities represented analog signals used message passing algorithm compute exact inference. recently research project conducted nanoscale computing fabrics laboratory design unconventional hardware architecture based electro-magnetic computations perform inference bayesian network models ferreira also showed exact inference eﬃciently computed using hardware high-dimensional problems. finally approach taken thakur quite similar ours stochastic bitstreams target special inference problems. proposed frameworks beast bind perform inference using stochastic electronics types bayesian models hidden markov models direct acyclic graphs respectively. framework bambi project another stochastic architecture proposed perform naive bayesian fusion using muller c-elements achieves exact inference normalization binary random variables create harmful correlations stochastic signals can’t easily extended non-binary discrete distributions. recent work conducted within bambi project proposed using digital signals temporal coding perform bayesian inference proof-of-concept solve simple sensorimotor problem forward paper apply principles computationally challenging bayesian model highlight beneﬁts. provides estimate depth information using data standard digital cameras binocular disparity problem received wide attention since beginnings computer vision. existing approaches computing matching cost positive value associated possible pair matching pixels. matching cost dissimilarity measure least likely pixels match higher cost computed locally typically comparing luminance color individual pixels. common matching cost squared diﬀerence pixel values techniques preprocess image operators gradient banks linear spatial ﬁlters applying optional cost aggregation performs spatial integration pixel-wise information provided cost values. main goal step take account fact points disparity locally smooth therefore neighbouring pixels correlated disparity values. simplest form cost aggregation relies averaging cost values given disparity across given neighborhood. optimization step uses cost compute ﬁnal disparity image. step limited simply selecting disparity value associated lowest cost winner-takes-all way. also involve global computations optimize disparity regard given world model using techniques dynamic programming cases complement replace cost aggregation. several existing works bayesian inference framework describe process. example belhumeur proposes reconstruct scene geometry left right images using bayesian model cost aggregation step computing integrating prior constitutes optimization step. belhumeur uses squared diﬀerence compute cost proposes three increasingly complex world models deﬁne prior computation full posterior probability distribution most algorithms rectiﬁed image pairs allows consider pixels corresponding rows matching limit disparity maximum value dmax corresponding minimum distance. dmax depends image resolution camera focal length visual environment; typical values pixels. shows simpliﬁed form optimization problem solved dynamic programming. mentioned section despite algorithm based bayesian inference yields single disparity value pixel. development public image pairs datasets provided disparity baseline kitti dataset middlebury dataset made possible treat disparity computation supervised machine learning problem. algorithms deep convolutional networks learn matching cost perform cost aggregation optimization using techniques. techniques currently populate kitti leaderboard. although extremely accurate benchmarks eﬃciency depend existence relevant supervised training dataset. besides computationally intensive using high-end cpus gpus sometimes requiring computing time several minutes frame. features would make applying techniques mobile robotics context challenging. approach directly relevant positioning method proposed jonas application aforementioned hardware architecture approximate inference. work model disparity distribution using markov random ﬁeld hardware architecture using gibbs sampling sample posterior distribution. although approach eﬃcient allows computationally intensive bayesian disparity model global optimization uses unique centralized pseudo-random number generator source entropy lacks features system high parallelism robust computation full disparity number clock cycle. goal disparity computation estimate tridimensional geometry visual scene rectiﬁed images taken identical cameras focal length distant known baseline distance object projects left camera’s image plane position mentioned section main obstacle compute full disparity distributions high cardinality considered distribution integrating smoothness constraints probabilistic model requires perform inference distributions size npixels npixels number pixels domain optimization performed. optimization performed whole image entire rows columns problem becomes completely intractable even smaller integration neighborhoods problematic. order avoid issue perform spatial information integration image preprocessing operations perform pixelwise bayesian operations using preprocessed data. stereo matching method therefore relies preprocessing images using linear convolution ﬁlters extract relevant features. algorithms used convolution ﬁlters disparity computation although process feature information ﬁlter diﬀerent way. relevance using linear spatial ﬁlters preprocessing step also highlighted recent works using deep neural networks compute disparity convolutional layer input. feature maps output ﬁlters used compute feature matching costs pixel pairs corresponding possible disparities. costs used compute probabilistic likelihood functions similar used belhumeur likelihood terms combined using naive bayesian fusion. simple luminance linear averaging ﬁlter linear horizontal luminance gradient ﬁlter linear vertical luminance gradient ﬁlter three ﬁlters compute left right feature maps applying ﬁlter left right images size convolution ﬁlters feature maps width height equation expresses likelihood observing value right feature value observed left feature disparity coordinates probabilistic formulation allows specify base probability features matching even cost high parameter representing expected inaccuracy cost measurement following drop spatial coordinates described algorithm three simple ﬁlters operating luminance data method easily extended color processing using higher number ﬁlters using various convolution kernels. previous work shown naive bayesian fusion could performed stochastic machines. section describe structure bayesian machine architectured matrix stochastic operators explain used implement probabilistic binocular disparity computation detailed section stochastic computational architecture represents data using stochastic bitstreams. stochastic bitstreams random digital binary signals express probability value proportion bits given signal generating stochastic bitstream encoding probability therefore done using random number generator outputing random bits probability conversely extracting value storing ﬂoating point ﬁxed point number requires integrate information extended duration count proportion bits precision recovered value increasing integration time. probability values encoded uncorrelated stochastic bitstreams signals input logic gate probability pout output signal sout state given time given data representation implies average number bits obc·p number serving j-th signal tavg directly determines number bits necessary accurate reconstruction distribution using counters depends shape distribution value modiﬁed computations done often easily controlled computed. creates problems. first number bits necessary reconstruct distribution given desired precision can’t easily anticipated. second cases especially number high leads poor performance stochastic machine ﬁrst problem adressed integrating data given number bits observed signal instead ﬁxed number bits. easily achieved using counters overﬂow. stochastic bitstream width connected counters maximum value nmax signals counters overﬂows. computation stopped moment counter index jmax stores value nmax corresponding p-value pmax counters store values corresponding p-values process allows renormalize distribution regard maximum probability value pmax read ﬁxed-point numbers precision depending nmax. furthermore index overﬂowing counter immediately gives index probable value implements maximum a-posteriori estimator. common bayesian computing techniques naive bayesian fusion computing posterior probability distribution searched variable knowing prior distribution conditional distributions figure computing probability products stochastic bitstreams. fig. shows bits stochastic bitstream bits therefore encoding p-value fig. shows computational module performing probability product input signal bji− encodes ppart bayesian naive fusion operation value ki−) output signal encodes p-value ki−) tion constant generated data terms integrated using simple computational modules comprised memory random generator logic gate described line stochastic data term memory stores value random generator generates stochastic bitstream encoding probability gate perform probability product signal signal bji− previous element outputting signal bji. resulting architecture performs bayesian inference using matrix stochastic operators number rows equal cardinality variable number columns equal number data terms figure architecture computing naive bayesian fusion stochastic signals. element instance module described leftmost input signals constitute stochastic encoding prior distribution rightmost output signals constitute stochastic encoding posterior therefore matrix stochastic operators dmax compute stochastic representation posterior disparity representation. following uniform disparity prior stochastic signals constantly equal data terms integrated described section full disparity distribution pixel estimated using counters posterior disparity distribution unimodal clearly indicates disparity value value estimated maximum a-posteriori estimator simply getting index ﬁrst overﬂowing counter suggested section color processing three convolution ﬁlters applied color layer also considered experimented show signiﬁcant improvement luminance processing present case. figure sequence computational elements computing stochastic signal corresponding disparity value contains instance module described dmax structures allows compute disparity distribution small range values must adapt take account issues arise fact disparity values cannot always computed. describe problems consequence architecture forward solution. cases occlusion pixels left image matching pixel right matching costs therefore high every possible disparity value. bayesian model means values stochastic computation signals output stochastic p-value corresponds uniform distribution correct since information could inferred disparity value data distribution encoded problematic time dilution problem mentioned section example means average every bits machine average million cycles simply -bits counter ineﬃcient. cases large uniform areas texture distinctive features opposite problem arises many disparity values possible match therefore matching costs. likelihood p-value close encodes high-entropy close uniform distribution high normalization constant. again correct result high normalization constant means time dilution problem arises; output eﬃciently converted numerical values used stochastic computations. however high-entropy distributions ill-suited maximum a-posteriori estimator return random result among possible disparity values. determines time occluded pixel detected matching. enough pixel correctly matched stochastic signal corresponding disparity value p-value high enough described above match possible occlusion match signal ﬁlls counter stops computation reasonable time detecting absence match. second term equation handles poorly contrasted areas found characterized values vertical gradient weakly contrasted areas therefore value close corresponding stochastic signal quickly counter detect absence match spurious match attributed behavior estimator detected. note square gradient value left image used matching cost associated gradient equation therefore high gradient close zero weakly contrasted areas. figure bayesian stochastic machine implementing disparity computation. contains instance module described always-on signals corresponding uniform prior input left feature matching likelihood values integrated computational modules disparity distribution output stochastic right converted ﬁxed-point numeric representation counters. disparity computed counter linked corresponding signal overﬂow ﬁrst otherwise match channel overﬂow. implementations programs written desktop computer equipped intel xeon -bit cpu. reference implementation computations using ﬂoating point numbers. simulated stochastic implementation uses mersenne twister prng provided implementation generate stochastic bitstreams -bit bitwise boolean operation perform probability product. reference implementation seconds frame order magnitude fast disparity algorithms state art. simulated stochastic implementation seconds frame performance overhead simulating stochastic machines using non-stochastic hardware; performance stochastic system better estimated number simulated clock cycles used compute frame images rectiﬁed using triclops proprietary pointgrey middleware. camera mounted turtlebot mobile robot base manually controlled oﬃce environment collect data. total frames captured corresponding minutes seconds video. feature maps used compute likelihoods described equation likelihoods used reference implementation simulated stochastic implementation compute disparity distribution. feature stochastic computing using stochastic bitstreams progressive precision longer information bitstream integrated precisely corresponding p-value estimated. context stochastic framework described section means precision increases size counters used estimate distribution higher counters’ maximum value closer reference implementation resulting distribution expected therefore used simulated stochastic implementation variable counter sizes quantify phenomenon. stochastic disparity processor described section performs functions detecting match pixels computing disparity distribution matched pixels. performance match pixels discrimination task assessed computing f-score pixels identiﬁed match reference implementation simulated stochastic implementation. performance disparity distribution computation task assessed measuring error distributions estimated simulated stochastic implementation reference implementation. using kl-divergence also considered proved problematic frequent occurence p-value distributions estimated simulated stochastic implementation. figure performance simulated stochastic disparity processor. fig. shows detection match pixels quality reconstructed distribution exponentially improve counter value. fig. depicts linear relationship counter value simulated time data shows mean standard deviation subset images obtained regular sampling full dataset. figure shows relationship counter value average time simulated stochastic machine ﬁlling counter. expected grows linearly maximum value counter signals uncorrelated extra required counter generates constant overhead. fig. shows example reconstructed disparity image reference implementation simulated stochastic implementation using maximum counter values disparity image stochastic system larger counters visually close reference. image obtained using -bit counters clearly noisier lower quality still correctly describes general tridimensional structure scene could possibly used drive robust robot control system. according data figure disparity images obtained applying estimator output distribution exemple frame. fig. rectiﬁed frame left camera. fig. reference image obtained classic bits ﬂoating point computation. fig. show images obtained simulated stochastic implementation respectively counter values black pixels match pixels; white pixels disparity dmax gray pixels luminance however stochastic bitstream-based computational system described section supposes fast eﬃcient sources stochastic signals could integrated large scale hardware component jointly gates memories counters implement architecture seen section paper used simulated implementation using mersenne twister prngs evaluate potential approach absence components. recent advances nanodevices based spintronics superparamagnetic tunnel junction bear promise generators could available short medium term. experimental smtj devices shown able generate high-quality stochastic bitstreams frequency power consumption components built cmos technology using area equivalent bytes sram making suitable large scale integration components needed build stochastic machines described above. using ﬁgures guidelines compute order magnitude speed power consumption disparity computation systen described section evaluated simulation section system requires random signal generators would total power consumption using counters maximum value shown section adequate tradeoﬀ speed accuracy need represents average total clock cycles image. frequency architecture would therefore able process image pairs second. system processes data pixel independantly computation time power consumption expected grow linearly image width height. computations rough estimations; speciﬁcally energy consumption computation ignores energy cost gates memories counters also necessary implement circuit performance take account overhead induced reinitializing machine pixel bayesian algorithm also makes preprocessed images using spatial ﬁlters; cost preprocessing taken account global evaluation system. many methods exist perform spatial ﬁltering various cost performance energy-eﬃciency characteristics; work explore ways ﬁltering could done using stochastic computations. similarly cost computation step each dimension original images reduced pixels preﬁltering seen section horizontal dimension reduced dmax since distribution can’t computed dmax ﬁrst pixels shown equation hand computations assumed performed sequentially pixel unique instance systems described section using computing modules described bayesian machine architecture parallel design higher number modules would allow parallel processing many pixels increased performance cost higher circuit size energy consumption. forward architecture compute class bayesian inference problems probabilistic hardware using stochastic bitstreams evaluated system simulation example binocular disparity computation demonstrating high performance energy-eﬃciency. although work described paper uses simulations hypothetical stochastic machines using experimental hardware devices therefore oﬀer rough estimations performance systems belief results clearly highlight potential bayesian computation using stochastic bitstreams sensorimotor processing especially applications tight constraints computational energy resources mobile robotics embedded systems distributed sensors. proposed architecture allows solve many sensory fusion processing problems yielding full distributions expressed stochastic bitstreams power consumption reduced computational resources. parallel distributed nature architecture could allow easily address variety diﬀerent problems using arrays generic components similar fpgas. furthermore progressive precision stochastic bitstream data representation allows easily adjust speed/accuracy power/accuracy tradeoﬀs changing signal integration time making possible example maintain degraded operation lower accuracy energy conditions. future work entail continued collaboration projects partner physically instantiate system described simulated present work. partial implementation bayesian machine infrastructure using fpga systems demonstrated research also integrate technology developed teams working stochastic signal generator devices. eﬀorts also dedicated extending breadth computations implemented stochastic bitstream based systems combining disparity computation sensory computations create occupancy using extending existing bayesian spatial cognition algorithms could used obstacle avoidance robot navigation paving completely stochastic robot sensorimotor controller.", "year": 2016}