{"title": "Using KL-divergence to focus Deep Visual Explanation", "tag": ["cs.AI", "cs.CV", "stat.ML"], "abstract": "We present a method for explaining the image classification predictions of deep convolution neural networks, by highlighting the pixels in the image which influence the final class prediction. Our method requires the identification of a heuristic method to select parameters hypothesized to be most relevant in this prediction, and here we use Kullback-Leibler divergence to provide this focus. Overall, our approach helps in understanding and interpreting deep network predictions and we hope contributes to a foundation for such understanding of deep learning networks. In this brief paper, our experiments evaluate the performance of two popular networks in this context of interpretability.", "text": "present method explaining image classiﬁcation predictions deep convolution neural networks highlighting pixels image inﬂuence ﬁnal class prediction. method requires identiﬁcation heuristic method select parameters hypothesized relevant prediction kullback-leibler divergence provide focus. overall approach helps understanding interpreting deep network predictions hope contributes foundation understanding deep learning networks. brief paper experiments evaluate performance popular networks context interpretability. deep convolution neural networks shown impressive results many domains computer vision problems. fundamental improvement current deep learning methods that unlike earlier shallow network layers deep learning automatically identiﬁes appropriate stratiﬁcation relevant attributes construct predictive model despite improvements quality accuracy predictions models hard interpret especially become deeper training weight adjustments propagate fully connected layers. problem interpreting becomes extremely important sensitive domain dealing medical data i.e. wrong decision might directly affect patient’s well-being. therefore need able build models interpretable support explanation decisions. neural networks achieve high accuracy easily interpretable. improved interpret-ability help inform tradeoffs e.g. methods like bayesian nets easily interpretable less accurate. recently many methods proposed address trade-off interpret-ability approach based computing gradient output layer respect feature maps relaxation generalization gradient back-propagated feature layer distinguish discriminative pixels input image. gradient determined based network activation; focus attention network activation provides insight classiﬁer output consider popular methods. following explain approach describing simple method interpret deep neural network prediction. approach produces highlights salient region input image represents evidence related activations output layer network i.e. network arrived decision? reminder paper organized follows. section presents proposed approach. section describe experiments initial framework ﬁnally section concludes preliminary results followed discussion extensive future work. case image classiﬁcation focus loss spatial information fully connected layers deep convolutional networks identify approximate visual explanation using feature maps particular convolution layer able explain prediction black function rely computing kullback-leibler divergence gradient class scores respect ground truth estimate discriminative localization map. gradient evidence network prediction. achieve this ﬁrst compute joint probabilities obtained weights capture relevant information feature maps acquired network. weights applied every feature identify discriminative pixels inﬂuence ﬁnal prediction output follows runs features runs obtained weights output localization used evidence explain prediction black function. finally normalize heat-map ekl−divergence visualization. algorithm summarizes implementation method overall methodology depicted figure evaluate proposed method context visual explanation select images common objects context challenge learned models employed publicly available pre-trained model vgg- initial results visualization algorithm illustrated figure also compared explanation algorithm similar methods i.e. guided backpropagation gradient weighted class activation comparison results depicted figure also important understand inﬂuence network architectures visualization algorithms. purpose experiment tested algorithm vgg- alexnet networks. comparison results shown figure results quality visualization depends overall accuracy network. since vgg- reliable observe network pays attention smaller salient area compared alexnet network. therefore better accuracy better visualization interpretation. introduce approach explaining deep neural networks prediction. particular solution focuses identiﬁcation salient regions computing kl-divergence gradient ground truth label output layer. preliminary experiments image classiﬁcation problems compare performance networks. believe work extended evaluate decisions variety applications deep neural networks image classiﬁcation speech text. especially keen consider text domains interpretability expose patterns semantic relatedness beyond images.", "year": 2017}