{"title": "DeepDeath: Learning to Predict the Underlying Cause of Death with Big  Data", "tag": ["cs.CL", "cs.LG", "stat.ML"], "abstract": "Multiple cause-of-death data provides a valuable source of information that can be used to enhance health standards by predicting health related trajectories in societies with large populations. These data are often available in large quantities across U.S. states and require Big Data techniques to uncover complex hidden patterns. We design two different classes of models suitable for large-scale analysis of mortality data, a Hadoop-based ensemble of random forests trained over N-grams, and the DeepDeath, a deep classifier based on the recurrent neural network (RNN). We apply both classes to the mortality data provided by the National Center for Health Statistics and show that while both perform significantly better than the random classifier, the deep model that utilizes long short-term memory networks (LSTMs), surpasses the N-gram based models and is capable of learning the temporal aspect of the data without a need for building ad-hoc, expert-driven features.", "text": "abstract— multiple cause-of-death data provides valuable source information used enhance health standards predicting health related trajectories societies large populations. data often available large quantities across u.s. states require data techniques uncover complex hidden patterns. design different classes models suitable large-scale analysis mortality data hadoop-based ensemble random forests trained n-grams deepdeath deep classifier based recurrent neural network apply classes mortality data provided national center health statistics show perform significantly better random classifier deep model utilizes long short-term memory networks surpasses n-gram based models capable learning temporal aspect data without need building ad-hoc expert-driven features. many scientific discussions studies biomedical healthcare domains address tasks whose goal prevent death diseases. since emergence data science numerous machine learning based techniques technologies proposed applied improve human health solving different computational challenges face today. less obvious question remains extensively explored researchers whether data science contribute understanding factors leading death diseases analysis multiple-cause mortality data. fact widely believed counting dead significant investment reduce premature mortality number studies proven offer profound impacts understanding major causes death using statistical analysis recorded death data. light studies interested investigate feasibility emerging field learning hidden complex patterns available haystack mortality datasets. multiple causes death data provide valuable source information used analyze death event chronic diseases lung disease identify problems process coding/recording cause-of-death information moreover data *this work supported part grants department health human services centers disease control prevention hhsdfb national science foundation award microsoft research hewlett packard. article reflect official policy opinions department constitute endorsement individuals programs. potentially used analysis disease diffusion controlling plagues epidemics provide better understanding multi-morbid associations conditions leading death. such designing advanced analytics pipelines discovering descriptive statistics trajectories highly crucial. sheer amount available data collected registered death certificates makes amenable data analysis poses challenges time. particular multiple-causeof-death data unstructured often inaccurate noisy. moreover high number icd-/ mortality codes makes analysis multiple-cause associations even challenging. altogether call advanced techniques mining large datasets unstructured high dimensional noisy structure. despite importance subject handful studies conducted research seeking relate multiple causes death factors. studies often limited classical statistical methods scale efficiently four major categories univariate measures consisting counts frequencies cross-tabular measures incorporate variables identify roles associated multiple death causes measures association measure multiple mentions cause related measure mentions underlying cause; finally derived measures univariate measures multiple-cause rates integrated build higher order models. study present exploratory analysis well positioned fifth group building upon third fourth abovementioned categories utilizing advanced machine learning approaches. specifically propose different classes models large-scale analysis data namely shallow learners learn uni/bi-gram features derived multiple-cause data hadoop framework using mapreduce programming model deep recurrent neural network learns temporal dynamics event chains efficiently. rest paper organized follows. section detail data format well wang department biomedical engineering georgia institute technology emory university school electrical computer engineering georgia institute technology atlanta challenges face dealing describe shallow learners designed work hadoop framework. also present proposed deep model section motivation resort deep learning. next section compare accuracy model applied large dataset show deep pipeline outperforms baselines design utilizing ability learn temporal aspect data finally section conclude paper shed light future directions would like pursue. civil registration systems collect death information deceased persons form death certificates based standard format designed world health organization section interest public health researchers cause-of-death section completed medical certifier. ideal person complete death certificate attending physician sufficient clinical expertise judgement occurred death. however case manner death unnatural unplanned medical examiner coroner also fill death certificate. cause-of-death section divided parts part lists causal chain conditions directly leading death reverse chronological order part includes conditions contributes directly leads death conditions part ordered time. used mortality data published united states national center health statistics consists million deaths recorded u.s. year interested temporal information available multiple causes death filtered conditions listed part well underlying causes listed part. also removed records attributed unnatural underlying causes death suicide. based recode underlying causes assigned codes moreover excluded underlying causes appear less times throughout whole dataset leaving recoded classes underlying causes. goal study predict class attributed case given multiple cause conditions listed him/her. divided resulting training test comprising samples respectively. using n-gram models learn associations multiple causes construct baseline models derived n-gram features n-gram defined n-tuple consisting consecutive tokens within sequential data n-gram based models widely used natural language processing bioinformatics performance ease implementation. study uni-gram features bi-gram features. despite fact higher order n-grams provide expressiveness capture context data make models prone overfitting exponential increase number possible features also makes training resulting model computationally infeasible therefore study included uni-gram bi-gram features. n-gram features derived used random forest train extremely large sparse matrix features. efficient model dealing sparse features however properly scale size nchs datasets therefore implemented model hadoop framework. hadoop distributed storage computing framework inspired google file system google mapreduce uses reliable storage mechanism called hadoop distributed file system fast storage retrieval large size datasets. hadoop efficiently utilize commodity compute nodes distributed network split tasks smaller subtasks perform analysis smaller chunks data mapreduce efficient model runs hdfs file system. train baseline models complete dataset used hadoop streaming used python scikitlearn library train multiple random forests subsampled data provided mapping stage. multiple random forests trained reducer jobs aggregate majority voting using scores model predict test set. deepdeath deep learning emerging technology deployed wide range domains including biomedical areas success improving previously recorded state-of-the-art performance measures. deep learning becoming indispensable part winning model today’s complex computational challenges. long short-term memory networks trained three baseline methods differ pool n-gram features. first model trained unigram features appeared across samples. then take advantage temporal nature inputs trained similar model bi-gram features finally trained separate model include features models. proposed model empirically chose sub-optimal hyperparameters model architecture work best training set. particular selected memory size lstm block drop-out ratio trained network tesla gpus rmsprop efficient optimization technique training deep models training epochs learning rate evaluated deepdeath well baselines randomly compiled test set. table compares accuracies achieved model. according table four models result accuracy significantly higher accuracy derived random classifier uni-gram features turn informative bi-gram features interestingly integration results improvement classification performance suggesting temporal nature data convey useful information cannot otherwise captured. finally amongst four models deepdeath performing best ability learning sequential data. noteworthy point that opposed baselines need hand-craft features using ad-hoc rules proposed expert. instead without intuition nature data lstm network learn rules own. fact observation confirmed numerous applications factor leading versatility deep models lstms particular. important caveat deep pipelines lack interpretability. opposed many classical models decision trees deep models generate understandable rules human utilize generalize concept. light shortcoming interested interpretable intermediate features deapdeath generate. upon training model removed softmax drop-out layers applied model test stored intermediate features fully connected layer generates sample. then marked death either death caused infectious parasitic disease non-infectious cause next used t-sne popular visualization technique maintains locality samples features important class deep architectures able capture temporal dynamics sequential data. lstm networks recently proved outperform surprisingly well many traditional sequence learning algorithms hidden markov models conditional random fields supervised settings significant amount labeled data available. such lstms framework task would like solve namely using timed causes death events contributed final event death predict underlying cause initiated events first place. models recently attracted significant attention interest notable speed-ups grained utilizing advanced graphics processing units computational tasks simple matrix operations massively repeated generate outcome algorithm. figure depicts internal structure lstm block. composed number gates control flow information lstm memory. gates programmable differentiable rendering amenable gradient-based optimization technique. words training process teach gates type information useful predicting target future hence passed figure shows block diagram deepdeath. two-layer lstm network learn hidden patterns within multiple-cause sequences. lstm block second layer potentially generate output output generated last block readily integrate past history abstract representation input sequence. also used drop-out regularization output last block shown lead better generalization. intermediate features generated feed fully connected layer followed softmax layer generate probability sample belonging underlying cause class. pre-processing step generate data suitable deepdeath divided code three parts group letter major code etiology used one-hot coding represent part concatenated resulting binary codes long binary. plane. understanding pathology disease progression patterns infectious parasitic diseases often different diseases. figure depicts resulting visualization. interestingly observe meaningful pattern observed among samples group suggesting intermediate features generated features visualized interpreted human experts. study proposed classes models analyzing large scale mortality data. showed classes significantly perform better random classifier. moreover addition bi-gram features uni-gram features showed temporal aspects input data captured properly improvement classification task achieved fact motivated design model based deep long short-term memory networks. active research directions field deep learning finding effective ways interpret deep models learn. study used visualization intermediate features first step solve problem showed meaningful clusters intermediate features help understanding salient features deep models learned. study sets stage comprehensive decision support system assist physicians practitioners filling death certificate correctly. future work interested develop generative models suggest probably correct fill death certificate forms given available data physician/practitioner hand. brooks reed \"principles pitfalls guide death certification\" clinical medicine research vol. \"counting dead world’s best investments reduce premature mortality\" hypothesis vol. chorba holman clarke evatt \"effects infection cause death persons hemophilia united states\" american journal hematology vol. hooper holman clarke chorba \"trends nonhodgkin lymphoma hivassociated deaths united states\" american journal hematology vol. mannino brown giovino \"obstructive lung disease deaths united states analysis using multiple-cause mortality data\" american journal respiratory critical care medicine vol. gordon \"australian bureau statistics multiple cause death analysis. publication rahman \"measures multiple-cause mortality synthesis notational framework\" genus vol. organization international statistical classification diseases related health problems vol. world health organization israel rosenberg curtin \"analytical potential multiple cause-of-death data\" american journal epidemiology vol. brown desouza mercer pietra \"class-based n-gram models natural language\" computational linguistics vol. paroubek \"twitter corpus sentiment analysis opinion mining\" lrec marafino davies bardach dean dudley boscardin \"n-gram support vector machines scalable procedure diagnosis classification applications clinical free text data intensive care unit\" journal american medical informatics association vol. kešelj peng cercone thomas \"n-gram-based author profiles authorship attribution\" proceedings conference pacific association computational linguistics pacling tomović janičić kešelj \"n-gram-based classification unsupervised hierarchical clustering genome sequences\" computer methods programs biomedicine vol. wajid serpedin \"review general algorithmic features genome assemblers next generation sequencers\" genomics proteomics bioinformatics vol. dean ghemawat \"mapreduce simplified data processing large clusters\" communications vol. park kellis \"deep learning regulatory genomics\" biotechnol vol. hassanzadeh wang \"deeperbind enhancing prediction sequence specificities binding proteins\" presented bioinformatics biomedicine ieee international conference alipanahi delong weirauch frey \"predicting sequence specificities dna-and rna-binding proteins deep learning\" nature biotechnology vol. hochreiter schmidhuber \"long short-term memory\" neural computation vol. maaten hinton \"visualizing data using t-sne\" journal machine learning research vol.", "year": 2017}