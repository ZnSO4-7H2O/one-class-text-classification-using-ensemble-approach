{"title": "Cakewalk Sampling", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Combinatorial optimization is a common theme in computer science which underlies a considerable variety of problems. In contrast to the continuous setting, combinatorial problems require special solution strategies, and it's hard to come by generic schemes like gradient methods for continuous domains. We follow a standard construction of a parametric sampling distribution that transforms the problem to the continuous domain, allowing us to optimize the expectation of a given objective using estimates of the gradient. In spite of the apparent generality, such constructions are known to suffer from highly variable gradient estimates, and thus require careful tuning that is done in a problem specific manner. We show that a simple trick of converting the objective values to their cumulative probabilities fixes the distribution of the objective, allowing us to derive an online optimization algorithm that can be applied in a generic fashion. As an experimental benchmark we use the task of finding cliques in undirected graphs, and we show that our method, even when blindly applied, consistently outperforms related methods. Notably, on the DIMACS clique benchmark, our method approaches the performance of the best clique finding algorithms without access to the graph structure, and only through objective function evaluations, thus providing significant evidence to the generality and effectivity of our method.", "text": "machine cally optimal solutions great use. learning example classical task divide given examples ﬁxed number groups manner would minimize exemplar distances within group algorithms k-means frequently used approach problems. continuous persistent k-means wide variety applications till proves practical point view algorithms return locally optimal solutions quite useful. spite aforementioned understanding shared among many practitioners seems date single method emerged canonical method approaching combinatorial problems. stands stark contrast compared continuous optimization. former setting gradient based algorithms applied variety problems generic fashion seem provide useful solutions convex well non-convex settings property underlies much success deep learning methods thus continuous settings gradient based methods regarded canonical optimization method combinatorial case seems problem needs special consideration. sometimes problem speciﬁc greedy algorithms method choice. times algorithms iteratively transform solution another non-deterministic fashion mcmc genetic algorithm methods useful others cases gradient free methods dominate nonetheless seems overarching property whenever combinatorial problem could parameterized manner allows access gradient greater efﬁciency could achieved. standard achieve construct parametric distribution space solutions search parameters optimize expected value given objective function. problem transformed manner gradient estimated sampling gradient based updates used optimal parameters distribution. point sampling former returns locally optimal solutions high probability. combinatorial optimization common theme computer science underlies considerable variety problems. contrast continuous setting combinatorial problems require special solution strategies it’s hard come generic schemes like gradient methods continuous domains. follow standard construction parametric sampling distribution transforms problem continuous domain allowing optimize expectation given objective using estimates gradient. spite apparent generality constructions known suffer highly variable gradient estimates thus require careful tuning done problem speciﬁc manner. show simple trick converting objective values cumulative probabilities ﬁxes distribution objective allowing derive online optimization algorithm applied generic fashion. experimental benchmark task ﬁnding cliques undirected graphs show method even blindly applied consistently outperforms related methods. notably dimacs clique benchmark method approaches performance best clique ﬁnding algorithms without access graph structure objective function evaluations thus providing signiﬁcant evidence generality effectivity method. combinatorial optimization foundational problems computer science many theoretical real world problems described using formulation. though general problems np-hard many real world applications lolog-likelihood-gradient example multiplied objective value example. hand dependence objective values allows algorithms give higher likelihood examples achieve better objective values. other direct dependence objective values effects distribution gradient estimates property makes particularly hard right step size performing gradient update. phenomenon pronounced optimizing general objective functions whose scale unknown advance certainly course optimization optimum approached. methods rescaling estimated gradient actorcritic methods reinforcement learning methods reducing variance various estimators typically constructed problem speciﬁc manner. following understanding constructing generic surrogate objective function whose locally optimal solutions includes original problem distribution every possible objective function. outset seems ﬁnding general purpose surrogate objective function could hard. nonetheless show simple trick transforming actual objective values cumulative probabilities solves problem. transforming objective manner distribution objective values throughout optimization feat allows derive online stochastic optimization algorithm applied generic fashion. since crux method based capitalizing cumulative distribution function original objective refer method cakewalk stands cumulatively weighted likelihood. start describing standard stochastic optimization algorithm combinatorial problems section proceed present cakewalk method section section discuss cakewalk related multi-arm bandits algorithms policy-gradient methods reinforcement learning cross-entropy method particular show choice surrogate objective stochastic optimization framework produces online version cross entropy method furthermore show surrogate objective adapted ways experimentation demonstrate effectivity surrogate objective. guarantee method effective even hard combinatorial problems focus problems general np-hard. matter section demonstrate cakewalk could used inclusion-maximal cliques undirected graphs section report performance dataset graphs results regularly published. dataset show cakewalk signiﬁcantly outperforms similar constructing stochastic optimization algorithm combinatorial optimization problems start stating problem. objective function need maximize string describes items discrete items. text denote discrete sets using goal search space achieves optimal since discrete general problem np-hard hence focus ﬁnding locally optimal solutions rather global optimum thus suppose along we’re also given neighbourhood function maps neighboring goal return locally optimal solution locally optimal solutions preferably would like whose objective value large possible though general cannot guaranteed. section exemplify form optimization using problem ﬁnding inclusion maximal cliques. describe stochastic optimization algorithm tackling optimization problems form. random variable deﬁned distributed according parametric distribution algorithm maintains. addition random variable deﬁned values objective function i.e. emphasize text refer random variables using capital english letters bold refer elements appropriate sample spaces optimization algorithm iteratively samples solutions according updates parameters govern manner reﬂects good objective value associated. thus ’pushing’ towards associated high values algorithm increases probability sampling solutions closer sense good initially multivariate uniform optimization continues algorithm decreases entropy distribution eventually solutions become likely sampling high probability returns several locally optimal solutions. discuss iterative algorithm iteration uppoint we’ve stage discussing main innovation introduce work surrogate objective function preserves original optimal solutions optimized using generic online updates. achieve this start examining equations observing update direction considered step we’re taking direction. thus sign magnitude essentially determine whether increase decrease likelihood extent implication optimization distributions {ηty determine course optimization. example |ηty unbounded might take steps large might cause diverge. another scenario involves large steps converge though we’ll decrease entropy fast won’t chance sample enough solutions converging local optimum. steps small unfavorable well keep sampling distribution close uniform combinatorial nature ﬁnding good take exponentially many examples. extends scenarios involve functions different scale. example suppose functions every ﬁxed positive constant. clearly nonetheless sampling updating parameters using equations would change speed optimization factor though adjust learning rates particularities given objective approach would require tune optimization case case basis. lastly since general don’t know ahead time distribution seems follow construction presented section won’t able determine series {ηt}t manner would objective functions. reasoning leads conclude wish obtain generic updates aforementioned optimization scheme must come ﬁxed surrogate objective function would preserve optimal solutions original objective. achieve this suggest weight function composed produces surrogate objective meets criteria. since learn distribution function learning objective maximize expectation original objective denote parameters maximize derive gradient ascent algorithm relies gradient estimate ∇θeθ estimate gradient log-derivative trick learning rate parameter predetermined. describe update step using vanilla gradient update mostly illustratory purposes though practice gradient based update adagrad adam used instead. turns positive learning rates stochastic optimization scheme converges local maximum using optimal parameters sampling returns locally optimal solutions high probability nonetheless gradient estimates known highly variable requires drawing large samples iteration costly. though techniques reducing variance estimates mostly useful tied speciﬁcs given objective. approach problem differently consider instead adapt optimization objective manner allows rely highly noisy gradient estimates involve single example ensuring converge distribution still allows sample since focus online updates resection focus single iteration thus drop subscript cases. purpose ﬁrst option present illustrate connection algorithm method. reason denote weight function ˆwce associated transformation gce. given small decided user a-priori weight function deﬁned follows clearly ﬁxed monotonic increasing bounded ˆwce bernoulli random variable probability thus ˆwce bounded. notably using equation leads update considered online version method. main disadvantages gce. first relies another parameter requires manual tuning. importantly uses highest percentile examples update fact worst supply valuable information objective values thus likelihood decreased rather simply ignored. thus suggest weight functions issue. probably simplest option empirical directly i.e. would make uniform discrete weighting doesn’t involve extra parameters ignore information supplied every still major drawback leads increase likelihood every example sees. create bias towards already sampled compared weren’t even though associated objective value might better. since grows exponentially fast grows examples drawn early process inﬂuence course optimization dramatically. following reasoning adjust would increase likelihood half examples decrease likelihood half. deﬁne follows struct manner would distribution nonetheless basic probability tells uniformly distributed since every monotonic increasing construct using preserve original optimal solutions make signiﬁcant progress towards goal. next since insisting might ideal take idea step further rescale using another bounded monotonic increasing function desired bounds. summarize core element makes online optimization effective surrogate objective function following form next since don’t access general case gradient need estimate data. fortunately enough since image dimensional order statistics supply highly reliable non-parametric estimates question comes perform aforementioned estimation without drawing large sample iteration. equation sampling distribution bounded since bounded well bounded every main implication property control different parameters iterations i.e. iterations make θt−kk small want simply changing thus instead drawing sample size iteration last objective values yt−k approximately i.i.d according pθt− therefore small enough learning rates estimate follows note whenever assumption doesn’t hold draw large sample estimating gradient still enjoy beneﬁts ’varianceinvariant’ surrogate objective. ﬁxing distribution former bounded also ﬁxes variance gradient estimates likely improve reliability estimates. nonetheless example increased decreased extent. notably achieved along full speciﬁcation distribution major advantage compared with example transforming estimated z-score case can’t determine distributed might trip optimization whenever isn’t normal random variable. furthermore ztransform can’t guarantee that|w bounded without boundedness optimization might diverge online estimation suffer. summarize cakewalk gradient addition rule algorithm presenting speciﬁc distribution note construct problem speciﬁc distributions capture prior knowledge given problem. said that section describe simple distribution could used variety problems designed manner would reduce number parameters. factorize sequence independent distributions deﬁned different dimension therefore number parameters required represent grows linearly instead exponential number parameters required represent full joint distribution. search elements average useful many possible solutions terms associated objective value. combining elements different positions iteratively progress towards solutions overall perform well. formulation drawn independently according softmax distribution noted before method spite derived different perspective closely related method. method initially introduced rubinstein method estimating probability events iteratively adapting importance sampler towards event interest. later rubinstein adapted combinatorial optimization problems using sampling distribution similar presented section case likelihood ratio turns rubinstein’s construction case fact equivalent constructing weighted likelihood estimator similar stochastic optimization perspective we’ve used derive method. major beneﬁt perspective allows generalize type weights used particular show using empirical without thresholding used construct weighting schemes superior rubinstein’s. furthermore relying gradient updates provides cakewalk beneﬁts compared closed form updates first using gradient updates allows smoothly update parameters without smoothing tricks used rubinstein secondly paves using sampling distributions cannot updated closed form. lastly relying bounded gradient updates able estimate online manner thus avoid computational costs drawing large sample iteration. turn reduces runtime costs cakewalk orders magnitude. next family methods algorithm related policy gradient methods reinforcement learning. reinforcement learning concerned sequential decision problems whose purpose maximize long term goal. setting learner sequentially takes actions trail-and-error function maps states actions learned. like policy gradient methods construct parametric probability distribution updated manner give higher likelihood sequences actions resulted higher long term rewards. research methods initiated williams reinforce algorithm algorithm closely related cakewalk. notably reinforce parameter update written using notation takes following form clariﬁes connection two. work policy gradient methods essentially discusses rescale using different reﬂect estimates would behave various scenarios. example actor critic methods according estimates distributed markov decision process clearly requires modeling particular manner thus must applied problem problem basis. methods probably natural actor-critic algorithm better cakewalk’s general purpose nature. former rescales estimated gradient multiplying inverse fisher information matrix turn requires accurate estimates gradient fisher information matrix. makes natural actor-critic considerably computationally expensive online algorithms cakewalk reinforce requires large samples estimating accurately inversion operation. lastly note policy gradient methods effective careful tuning particular problem notorious highly sensitive choice learning rates. stands stark contrast cakewalk used ﬁxed learning rate since distribution ﬁxed therefore makes cakewalk general purpose optimizer. third family algorithms method related multi-arm bandits algorithms. bandits setting learner faced sequential decision problem round learner choose associated non-deterministic loss. chosen loss associated revealed learner update rule next action chosen. goal learner minimize cumulative loss suffered during process compared best single hindsight algorithms setting judged asymptotical comparison two. initially suggested thompson setting explored extensively notable successes algorithm cases losses stochastic even determined adversary years become basis wide variety algorithms particular interest setting case arms high dimensional compact subset online linear optimization algorithms pioneered subset combinatorial bandits algorithms pioneered cases achieve useful performance bounds faced inﬁnitely many arms losses assumed linear function arms. closer optimization setting pure exploration bandits algorithms judged optimal solution return idea even adapted combinatorial setting difference bandits algorithms method losses associated arms non-deterministic thus bandits setting main challenge balance estimating statistics associated arms exploiting information gathered thus far. optimization setting hand goal simply best deterministic solution using least number steps. thus spite apparent similarity fundamental difference separates optimization bandits settings accordingly leads different algorithms. section investigate problem ﬁnding cliques graph start stating problem. suppose we’re given graph vertices edges. undirected every follows directed. given undirected graph complete every follows call subgraph every clique subset vertices complete accordingly inclusion maximal clique subset complete gu∪{v} also complete graph. clique number graph size largest inclusion maximal clique. given graph integer decision problem maximum clique determine whether larger following seminal work karp follows maximum-clique problem np-complete thus unless p=np polynomial time decide problem. notion inclusion-maximality natural definition local optimality therefore study algorithms combinatorial optimization. thus proceed describe clique ﬁnding combinatorial optimization problem. given graph vertices space correspond strings determine membership subgraph variable since describes membership refer subsets elements place describe function maps returns positive value clique complete otherwise thus multiplying size returns clique size clique return not. point deﬁne combinatorial optimization problem. nonetheless optimizing directly hard all-or-none kind function i.e. returns positive value we’ve found clique doesn’t close clique. manner algorithm relies function evaluation source information hard time inferring well progresses. matter design another objective could inform algorithms densely connected subgraph. thus replace objective indicates densely connected accordingly refer soft-clique-size function. denoting fscs deﬁnition follows result fscs clique. nonetheless indication algorithm prefer larger cliques smaller ones. thus increasing gives larger cliques ’boost’ compared smaller cliques though could isn’t clique receive higher value smaller clique. nonetheless clique fscs |ux|− thus larger closer ratio manner fscs rewards larger cliques. empirically algorithms we’ve tested aren’t sensitive various values allows algorithms we’ve tested inclusion maximal cliques. note sampling clique non-trivial since sampling algorithms access graph itself cannot perform graph related search operations. compare stochastic online optimizers clique ﬁnding problem focus latter natural deﬁnition local optimality. goal provide best clique ﬁnding algorithm problem benchmark methods. differ clique ﬁnding algorithms like bron-kerbosch access graph itself receive information function evaluations. benchmark used undirected graphs published part second dimacs challenge speciﬁcally focused combinatorial optimization included instances clique problem. graph dataset generated using random generator specializes particular graph type conceals cliques different manner. graphs contain nodes compared methods term solutions’ quality terms sampling efﬁciency optimizers best solutions earlier others. terms solutions’ quality focused local optimality using inclusion maximality another criterion specify later. tested method graphs letting maximize soft-clique-size function using various values determine inclusion maximality since a-priori don’t know lead inclusion maximal clique we’ve executed method using values execution we’ve executed method samples execution’s recorded soft-clique-size clique-size best solution well sample number best solution found. term methods tested following discussion related work experimented method policy gradient algorithm bandits algorithm. method used online version derive work online version compared directly online methods terms sampling efﬁciency. threshold values suggested rubinstein refer oce. oce. accordingly standing online. policy gradient methods reinforce probably related cakewalk generic online fashion applied thus focus bandits family algorithms considered suitable candidate multi-dimensionality problem. example adding isolated vertex vertices clique damage objective. cases we’ve used instead ucb. didn’t combinatorial bandits algorithms computationally infeasible mostly useful theoretical purposes. applied elements independently. note assumption bounded losses/gains algorithm dependent upon soft-clique-size function. cakewalk method used unscaled empirical scaled counterpart denoting cakewalk cakewalk latter oce. oce. used last objective values estimate empirical cdf. altogether experimented stochastic online optimizers. addition experimented types gradient updates. first used vanilla gradient update refer stochastic gradient ascent addition experimented adagrad adam updates. methods considered scale invariant thus applied conjunction reinforce make important comparison cakewalk. adagrad particularly suited setting applying indicator data classical cases considered data). adam hand proven effective training neural networks wide variety problems nowadays probably mostly commonly used optimizer. decided experiment conjunction adagrad adam even though revokes theoretical guarantees completeness purposes. applied adagrad adam used learning rate executions. algorithms implemented julia authors. altogether we’ve tested optimization methods update steps graphs values leading total separate executions. analyzed performance measures optimizers gradient update types accordingly report results four tables. following refer combination optimizer gradient update method. first examined whether locally optimal solution found. test local optimality softclique-size given result graph compared every graph whose hamming distance checked achieved higher soft-clique-size. report average local optimality soft clique size table then test inclusion maximality returned solutions since soft-clique-size doesn’t guarantee convergence cliques every graph tested whether method returned least inclusion maximal clique applied κ.we report average inclusion maximality table next analyze sampling efﬁciency method calculated ratio best sample number total number samples used execution. report average best-sample total-samples ratio table ensure returned solutions aren’t trivial graph compared largest inclusion maximal clique found method compared best known solution graph. comparison using graphs results regularly published collected report average largest-found-clique largest-known-clique ratios table lastly compared every optimizer cakewalk experimental conditions. comparisons done using sided sign test control false discovery rate benjamini-hochberg method used calculate signiﬁcance threshold level table mark best performing method using bold fonts. table excluded reinforce comparison didn’t return locally optimal solutions results tables clearly indicate innovation reliance empirical produce surrogate objective making effective stochastic optimizers reinforce didn’t rely latter completely failed even aided updates supposedly render scale invariant. notably method spite performance return useful solutions indicated tables emphasizes claim objective values used directly. nonetheless all-ornone kind approach reduces sampling efﬁciency indicated superiority cakewalk table comparing cakewalk cakewalk superiority latter measures indicates cumulative probabilities need rescaling form indicates optimizer solutions good not. furthermore seems cakewalk adagrad under-the-hood results surprisingly effective optimizer quality returned solutions exceeds method we’ve tested. notably regime cakewalk approaches performance best clique ﬁnding algorithms directly search graph tailored speciﬁc task. note none tested methods enough samples recover graph itself graphs nodes we’ve allowed samples execution. thus could without limitations proper tuning cakewalk prove competitive clique ﬁnding algorithm though leave future research. overall results strong indication cakewalk sampling highly effective stochastic optimization method believe future research prove effectiveness domains continuous non-convex optimization reinforcement learning problems.", "year": 2018}