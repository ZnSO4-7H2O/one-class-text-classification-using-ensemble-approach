{"title": "Stacked Generative Adversarial Networks", "tag": ["cs.CV", "cs.LG", "cs.NE", "stat.ML"], "abstract": "In this paper, we propose a novel generative model named Stacked Generative Adversarial Networks (SGAN), which is trained to invert the hierarchical representations of a bottom-up discriminative network. Our model consists of a top-down stack of GANs, each learned to generate lower-level representations conditioned on higher-level representations. A representation discriminator is introduced at each feature hierarchy to encourage the representation manifold of the generator to align with that of the bottom-up discriminative network, leveraging the powerful discriminative representations to guide the generative model. In addition, we introduce a conditional loss that encourages the use of conditional information from the layer above, and a novel entropy loss that maximizes a variational lower bound on the conditional entropy of generator outputs. We first train each stack independently, and then train the whole model end-to-end. Unlike the original GAN that uses a single noise vector to represent all the variations, our SGAN decomposes variations into multiple levels and gradually resolves uncertainties in the top-down generative process. Based on visual inspection, Inception scores and visual Turing test, we demonstrate that SGAN is able to generate images of much higher quality than GANs without stacking.", "text": "paper propose novel generative model named stacked generative adversarial networks trained invert hierarchical representations bottom-up discriminative network. model consists top-down stack gans learned generate lower-level representations conditioned higher-level representations. representation discriminator introduced feature hierarchy encourage representation manifold generator align bottomdiscriminative network leveraging powerful discriminative representations guide generative model. addition introduce conditional loss encourages conditional information layer above novel entropy loss maximizes variational lower bound conditional entropy generator outputs. ﬁrst train stack independently train whole model end-to-end. unlike original uses single noise vector represent variations sgan decomposes variations multiple levels gradually resolves uncertainties top-down generative process. based visual inspection inception scores visual turing test demonstrate sgan able generate images much higher quality gans without stacking. recent years witnessed tremendous success deep neural networks especially kind bottom-up neural networks trained discriminative tasks. particular convolutional neural networks achieved impressive accuracy challenging imagenet classiﬁcation benchmark interestingly shown cnns trained imagenet classiﬁcation learn representations transferable tasks even modalities however bottom-up discriminative models focused learning useful representations data incapable capturing data distribution. learning top-down generative models explain complex data distribution long-standing problem machine learning research. expressive power deep neural networks makes natural candidates generative models several recent works shown promising results state-of-the-art dnns rival human performance certain discriminative tasks current best deep generative models still fail large variations data distribution. natural question therefore arises leverage hierarchical representations discriminatively trained model help learning top-down generative models? paper propose generative model named stacked generative adversarial networks model consists top-down stack gans trained generate plausible lower-level representations conditioned higher-level representations. similar image discriminator original model trained distinguish fake images real ones introduce representation discriminators trained distinguish fake representations real representations. adversarial loss introduced representation discriminator forces intermediate representations sgan manifold bottom-up dnn’s representation space. addition adversarial loss also introduce conditional loss imposes generator higher-level conditional information novel entropy loss encourages generator generate diverse representations. stacking several gans topway using top-most receive labels bottom-most generate images sgan trained model data distribution conditioned class labels. extensive experiments demonstrate sgan able generate images much higher quality vanilla gan. particular model obtains stateof-the-art inception scores cifar- dataset. learning. early efforts include restricted boltzmann machines deep belief networks recently several successful paradigms deep generative models emerged including auto-regressive models variational auto-encoders generative adversarial networks work builds upon framework employs generator transforms noise vector image discriminator distinguishes real generated images. however vast variations image content still challenging gans generate diverse images sufﬁcient details. several works attempted factorize series gans decomposing difﬁcult task several tractable sub-tasks. denton propose lapgan model factorizes generative process multi-resolution gans generating higher-resolution residual conditioned lower-resolution image. although lapgan sgan consist sequence gans working scale lapgan focuses generating multi-resolution images coarse sgan aims modeling multi-level representations abstract speciﬁc. wang gupta propose s-gan using generate surface normals another generate images conditioned surface normals. surface normals viewed speciﬁc type image representations capturing underlying structure indoor scene. hand framework leverage general powerful multi-level representations pretrained discriminative dnn. several works pre-trained discriminative model training generator. regularization term encourages reconstructed image similar original image feature space discriminative network. additional style loss based gram matrices feature activations. different method works loss terms regularize generator’s output without regularizing internal representations. matching intermediate representations dnns. works attempt match intermediate representations dnns. intermediate representations pre-trained guide another context knowledge transfer. method considered special kind knowledge transfer. however transferring knowledge bottom-up top-down generative model instead another bottom-up dnn. also auto-encoder architectures employ layer-wise reconstruction loss layer-wise loss usually accompanied lateral connections encoder decodery. hand sgan generative model require information encoder training completes. another important difference adversarial loss instead reconstruction loss match intermediate representations. visualizing deep representations. work also related recent efforts visualizing internal representations dnns. popular approach uses gradientbased optimization image whose representation close want visualize approaches train top-down deconvolutional network reconstruct input image feature representation minimizing euclidean reconstruction error image space. however inherent uncertainty reconstruction process since representations higher layers trained invariant irrelevant transformations ignore low-level details. euclidean training objective deconvolutional network tends produce blurry images. alleviate problem dosovitskiy brox propose feature loss adversarial loss enables much sharper reconstructions. however still tackle problem uncertainty reconstruction. given high-level feature representation deconvolutional network deterministically generates single image despite fact exist many images representation. also obvious sample images feature prior distribution unknown. concurrent work nguyen incorporate feature prior variant denoising auto-encoder sampling relies iterative optimization procedure focused efﬁcient feed-forward sampling. section introduce model architecture. sec. brieﬂy overview framework generative adversarial networks. describe proposal stacked generative adversarial networks sec. sect. focus novel loss functions conditional loss entropy loss respectively. background generative adversarial network shown fig. original trained using two-player min-max game discriminator trained distinguish generated images real images generator trained fool discriminator loss generator loss deﬁned follows figure overview sgan. original workﬂow training sgan generator tries generate plausible features fool corresponding representation discriminator generator receives conditional input encoders independent training stage upper generators joint training stage. images sampled sgan feeding random noise generator real image distribution pdata training set. words adversarial training forces generate images reside natural images manifold. stacked generative adversarial networks pre-trained encoder. ﬁrst consider bottom-up pre-trained classiﬁcation referred encoder throughout. deﬁne stack bottom-up deterministic nonlinear mappings consists sequence neural layers number hierarchies intermediate representations classiﬁcation result input image. note formulation contain multiple layers grouping layers together determined number stacks therefore less number layers also determined stacked generators. provided pre-trained encoder goal train top-down generator inverts speciﬁcally consists top-down stack generators trained invert bottom-up mapping takes higher-level feature noise vector inputs outputs lower-level feature ˆhi. ﬁrst train independently train jointly end-to-end manner shown fig. generator receives conditional input encoders independent training stage upper generators joint training stage. words during independent training joint training. loss equations shown section independent training stage easily modiﬁed joint training replacing ˆhi+. intuitively total variations images could decomposed multiple levels higher-level semantic variations lower-level variations model allows using different noise variables represent different levels variations. training procedure shown fig. generator trained linear combination three loss terms adversarial loss conditional loss entropy loss. denote adversarial loss condiladv tional loss entropy loss respectively. weights associated different loss terms. practice sufﬁcient weights magnitude different terms similar scales. subsection ﬁrst introduce adversarial loss ladv introduce lcond generator introduce representation discriminator distinguishes generated representations real representations speciﬁcally discriminator trained loss function ehi+∼pdatae zi∼pzi ladv joint training adversarial loss provided representational discriminators also regarded type deep supervision providing intermediate supervision signals. current formulation discriminative model generative model conditioned labels. however also possible train sgan without using label information trained unsupervised objective cast unconditional generative model removing label input generator. leave future exploration. modeled generator information-theoretic perspective sgan factorizes total entropy image distribution multiple conditional entropy terms thereby stack generator trained capture distribution lower-level representations conditioned higher-level representations hi+. however formulation generator might choose ignore generate plausible scratch. previous works tackle problem feeding conditional information generator discriminator. approach however might introduce unnecessary complexity discriminator increase model instability adopt different approach regularize named conditional generator adding loss term lcond loss. feed generated lower-level representations back encoder compute recovered higher-level representations. enforce recovered representations similar conditional representations. formally ehi+∼pdatae zi∼pzi lcond hi+)] distance measure. deﬁne euclidean distance intermediate representations crosssimilar entropy labels. conditional loss lcond feature loss used loss leads anissue generator learns ignore noise compute deterministically hi+. problem encountered various applications conditional gans e.g. synthesizing future frames conditioned previous frames generating images conditioned label maps related work synthesizing images conditioned feature representations works attempted generate diverse images/videos feeding noise generator failed conditional generator simply ignores noise. knowledge still principled deal issue. might tempting think minibatch discrimination encourages sample diversity minibatch could solve problem. however even generator generates deterministically generated samples minibatch still diverse since generators conditioned different hi+. thus obvariational conditional entropy maximization. tackle problem would like encourage generated representation sufﬁciently diverse conditioned i.e. conditional entropy high possible. since directly maximizing intractable propose maximize instead variational lower bound conditional entropy. speciﬁcally auxiliary distribution approximate true posterior augment training objective loss term named entropy loss images back latent space perform unsupervised feature learning. proposes regularize ebgan entropy maximization order prevent discriminator degenerating uniform prediction. entropy loss motivated generating multiple possible outputs conditional input. section perform experiments variety datasets including mnist svhn cifar- code pre-trained models available https//github.com/xunhuang/sgan. readers refer code repository details experimental setup hyper-parameters etc. encoder datasets small encoder convolutional conv-pool-conv-pool-fc-fc fully connected layer outputs classiﬁcation scores softmax. cifar- apply horizontal ﬂipping train encoder. data augmentation used datasets. generator generators stacks throughexperiments. note framework generally applicable setting multiple stacks hypothesize using stacks would helpful largescale high-resolution datasets. datasets generates features random noise conditioned label bottom generates images noise conditioned features generated loss coefﬁcient parameters mnist mnist dataset contains labeled images hand-written digits training test set. image sized svhn svhn dataset composed real-world color images house numbers collected google street view image size task classify digit center image. dataset contains training images test images. practice parameterize deep network predicts posterior distribution given ˆhi. shares parameters treat posterior diagonal gaussian ﬁxed standard deviations network predict posterior mean making lent iteration update minimize lent method similar variational mutual information maximization technique proposed chen difference uses q-network predict small deliberately constructed latent code tries predict noise variables stack. loss used therefore maximizes mutual information output latent code maximizes entropy output conditioned hi+. also train separate network figure mnist results. samples generated sgan conditioned class labels. corresponding nearest neighbor images training set. samples generated bottom conditioned ﬁxed feature activation generated gan. bottom trained without entropy loss. figure svhn results. samples generated sgan conditioned class labels. corresponding nearest neighbor images training set. samples generated bottom conditioned ﬁxed feature activation generated gan. bottom trained without entropy loss. fig. show mnist samples generated sgan. corresponds samples conditioned given digit class label. sgan able generate diverse images different characteristics. samples visually indistinguishable real mnist images shown fig. still differences compared corresponding nearest neighbor training images. examine effect entropy loss. fig. show samples generated bottom conditioned ﬁxed feature generated gan. samples sufﬁcient low-level variations reassures bottom learns generate images without ignoring noise contrast fig. show samples generated without using entropy loss bottom generator observe bottom ignores noise instead deterministically generates images features. interpretability decomposes total variations image different levels. example mnist decomposes variations represents high-level digit label captures mid-level coarse pose digit represents low-level spatial details. samples generated svhn cifar- datasets seen fig. fig. respectively. provided feature panel sgan able generate samples similar coarse outline different lighting conditions background clutters. also nearest neighbor images training indicate sgan simply memorizing training data truly generate novel images. here compare sgan state-of-the-art generative models cifar- dataset. visual quality generated images measured widely used metric inception score following sample images model code provided method infusion training gman egan-ent-vi lr-gan denoising feature matching dcgan† steingan† improved gan† ac-gan† dcgan dcgan dcgan dcgan sgan-no-joint† sgan† real data trained labels. sec. examined effect entropy loss. order understand effect different model components conduct extensive ablation studies evaluating several baseline methods cifar- dataset. mentioned otherwise models training hyper-parameters full sgan model. dcgan single model architecture bottom sgan except generator conditioned labels instead features. note techniques proposed paper including conditional loss lcond entropy loss lent still employed. also tried full generator sgan baseline instead bottom generator however failed make converge possibly because deep trained without intermediate supervision representation discriminators. figure mnist results. samples generated sgan conditioned class labels. corresponding nearest neighbor images training set. samples generated bottom conditioned ﬁxed feature activation generated gan. bottom trained without entropy loss. compute score. shown tab. sgan obtains score outperforming ac-gan improved also note techniques introduced used implementations. incorporating techniques might boost performance model. verify effectiveness sgan conduct human visual turing test workers distinguish real images images generated networks. exactly follow interface used improved workers given images time receive feedback whether answers correct. votes evaluated model workers error rate samples sgan samples dcgan conﬁrms stacked design signiﬁcantly improve image quality without stacking. sgan obtains slightly higher inception score sgan-no-joint. sgan-no-joint also generates high quality samples outperforms previous methods terms inception scores. sgan either without joint training achieves signiﬁcantly higher inception score better sample quality baseline dcgans. demonstrates effectiveness proposed stacked approach. shown fig. dcgan collapses generating single image category adding entropy loss enables generate diverse images demonstrates entropy loss effective improving output diversity. single dcgan model obtains higher inception score conditional dcgan reported suggests lcond +lent might offer advantages compared plain conditional dcgan even without stacking. general inception score correlates well visual quality images. however seems insensitive diversity issues example gives score fig. clearly collapsed. consistent results paper introduces top-down generative framework named sgan effectively leverages representational information pre-trained discriminative network. approach decomposes hard problem estimating image distribution multiple relatively easier tasks generating plausible representations conditioned higher-level representations. idea representation discriminators different training hierarchies provide intermediate supervision. also propose novel entropy loss tackle problem conditional gans tend ignore noise. entropy loss could employed applications conditional gans e.g. synthesizing different future frames given past frames generating diverse images conditioned label believe interesting research direction future. would like thank danlu chen help fig. also want thank danlu chen shuai tang saining zhuowen felix kilian weinberger helpful discussions. yixuan supported army research ofﬁce wnf---. serge belongie supported part google focused research award. figure ablation studies cifar-. samples full sgan sgan without joint training. dcgan trained ladv +lcond +lent dcgan trained ladv lcond dcgan trained ladv lent dcgan trained ladv. dcgan architecture trained without conditional loss lcond. model therefore label information. dcgan architecture trained neither conditional loss lcond entropy loss lent. model also label information. viewed plain unconditional dcgan model serves ultimate baseline.", "year": 2016}