{"title": "Within-Brain Classification for Brain Tumor Segmentation", "tag": ["cs.CV", "cs.AI"], "abstract": "Purpose: In this paper, we investigate a framework for interactive brain tumor segmentation which, at its core, treats the problem of interactive brain tumor segmentation as a machine learning problem.  Methods: This method has an advantage over typical machine learning methods for this task where generalization is made across brains. The problem with these methods is that they need to deal with intensity bias correction and other MRI-specific noise. In this paper, we avoid these issues by approaching the problem as one of within brain generalization. Specifically, we propose a semi-automatic method that segments a brain tumor by training and generalizing within that brain only, based on some minimum user interaction.  Conclusion: We investigate how adding spatial feature coordinates (i.e. $i$, $j$, $k$) to the intensity features can significantly improve the performance of different classification methods such as SVM, kNN and random forests. This would only be possible within an interactive framework. We also investigate the use of a more appropriate kernel and the adaptation of hyper-parameters specifically for each brain.  Results: As a result of these experiments, we obtain an interactive method whose results reported on the MICCAI-BRATS 2013 dataset are the second most accurate compared to published methods, while using significantly less memory and processing power than most state-of-the-art methods.", "text": "purpose paper investigate framework interactive brain tumor segmentation which core treats problem interactive brain tumor segmentation machine learning problem. methods method advantage typical machine learning methods task generalization made across brains. problem methods need deal intensity bias correction mri-speciﬁc noise. paper avoid issues approaching problem within brain generalization. speciﬁcally propose semi-automatic method segments brain tumor training generalizing within brain only based minimum user interaction. conclusion investigate adding spatial feature coordinates intensity features signiﬁcantly improve performance diﬀerent classiﬁcation methods random forests. would possible within interactive framework. also investigate appropriate kernel adaptation hyper-parameters speciﬁcally brain. results result experiments obtain interactive method whose results reported miccai-brats dataset second accurate compared published methods using signiﬁcantly less memory processing power stateof-the-art methods. brain tumor segmentation primarily used diagnosis patient monitoring treatment planning neurosurgery planning radiotherapy planning. task brain tumor segmentation locate tumor delineate different sub-regions tumor namely edema non-enhanced enhanced regions standard diagnose brain tumor using magnetic resonance imaging many diﬀerent modalities used. frequent modalities used brain tumor segmentation flair t-weighted tweighted t-weighted contrast-enhanced refer diﬀerent modalities often used jointly provide complementary information locating tumors. unfortunately tumors appear almost anywhere brain. prior shape often poorly deﬁned edges. also visually present grayscales present healthy tissues well. consequence brain tumor segmentation practice still done manually. manual segmentation time consuming tedious also subject variations observers also within observer many methods proposed facilitate tumor segmentation process. among them automatic methods rely machine learning popular cases eﬃcient methods trained number subjects generalize data might gathered diﬀerent scanners. because intensity standardization among scanners makes generalization diﬃcult automatic methods. attempt overcome diﬃculties prepossessing steps made time consuming. also improve generalization methods often compute high dimensional feature vectors processing time take memory. paper consider speciﬁc problem segmenting imaged brain classes edema non-enhancing tumor enhancing tumor healthy tissue note non-enhancing tumor sometimes includes necrotic tissue. approach halfway automatic semi-automatic methods. machine learning methods train pre-selected brains generalize testing brains method implements single brain supervised learning method. user roughly selects brain voxels associated class voxels used training data. method generalizes labeling non-selected voxels. paper ﬁrst evaluate performance nearest neighbor classiﬁer within framework. then extend framework thoroughly evaluate potential comparing several classiﬁers including support vector machines random forests boosted decision trees. second propose better distance metrics used classiﬁer context approach. also investigate importance performing hyper-parameter selection individually brain opposed using generic hyper-parameters every brain. thanks investigation able signiﬁcantly improve resulting brain segmentation system achieve competitive performance compared methods submitted brain tumor segmentation challenge online evaluation benchmark. brain tumor segmentation methods divided automatic methods semi-automatic methods. semi-automatic methods relying user interaction. methods either deformable models classiﬁcation methods perform segmentation survey). automatic methods machine learning classiﬁcation techniques tool choice designing systems easily integrate diﬀerent modalities well features. integrating diﬀerent intensity texture features methods decide class voxel belongs instance festa used series intensity texture based features make feature space dimensions random forest classiﬁer trained. tustison reza also used random forests tustison constructed multi-dimensional feature space incorporating ﬁrst order neighborhood statistical images markov random field posteriors template diﬀerences. performed binary segmentation using framework followed variation conditional random ﬁelds account neighborhood relationships. used kernel multiclass segmentation brain tumors used regularize results. schmidt compared combination many diﬀerent feature sets binary mask average intensity left right symmetry. luts also compared diﬀerent feature selection methods fisher discriminant analysis kruskal wallis relief-f ls-svm. automatic methods train multiple brains methods vulnerable variations data. variations come fact images generated diﬀerent machines unique noise intensity level. overcome diﬃculty methods rely large number features requires memory computation time. algorithms usually initialized user drawing contour around tumor. following energy minimization criterion contour shrinks towards borders tumor hamamci used socalled ca-based method weighted images produce probability tumor based seeds provided user. probability later used level framework. later extend method accept multi-modal inputs namely flair. class segmentation method takes minute user interaction minutes segmentation depending size tumor exists line research focusing eﬃciently initialize active contour thus remove user interaction. context location tumor roughly determined method deformable models used post-processing reﬁnement. diﬀerence together gaussian mixture model probability tumor used level-set model initialize contour. prastawa used voxel registration atlas probability abnormalities. active contour initialized using probability iterates change posterior probability certain threshold. although deformable models popular medical image analysis signiﬁcant disadvantages. methods rely image gradients likely fail object interest well deﬁned borders. contour attracted strong gradients surrounding objects. incorporating diﬀerent features model also non-trivial. finally without implementation methods extremely slow. research ensembling results multiple methods applied brain tumor segmentation. used three segmentation methods fuzzy connectedness growcut voxel classiﬁcation using generate candidate segmentations voxel. conﬁdance-based averaging used make ensemble. although method semi-automatic method shares automatic methods machine learning classiﬁcation algorithm feature representation voxels improved spatial dependency model. main diﬀerence generalization performed within brain based training data provided user’s interaction. simpliﬁed generalization problem allows simple feature space yielding interactive segmentation method fast eﬀective. used similar semi-automatic classiﬁcation method applied proton density modalities. also proposed semi-automatic segmentation method uses instead quadratic discriminative aanalysis approach motivated observation that current computers relatively small data sets small feature spaces machine learning experiment actually performed within short delay even sophisticated algorithms require simply storing data moreover segmenting within given brain removes challenging problem generalizing across brain imaging acquisition conditions. ﬁrst step method collect voxel label data given brain image segment. done user roughly selects subset voxels associated class graphical interface. number strokes required obtaining training data depends number tumors given brain. however usually strokes per-class must also decide feature representation diﬀerent voxels. brain image assumed come modalities tensor voxel vector containing grayscale values modalities. represented converting voxel n-dimensional feature representation possible train classiﬁer predict voxel label every voxel feature representation. propose simple dimensional feature represeentation consists modality gray scales position voxel features normalized zero one. built training manual interaction next step train classiﬁer generalize segmentation non-selected voxels. investigate diﬀerent machine learning algorithms produce classiﬁer. could theoretically consider existing algorithm natural prefer algorithms known robust fairly black use. instance want user manually tune hyper-parameters brain trial error. chose algorithms known easily tuned default values hyper-parameters tend work well. algorithms also shown successful automatic ered. every voxel ﬁnds among training data nearest neighbors based closest training point classiﬁcation rule assigns class label voxel following equation states probability observation class given proportion nearest neighbors assigned class. probabilistic formulation classiﬁer reused unary terms described section support vector machine probably frequently used classiﬁer. part existence many freely available mature easy-to-use implementations. parametric form linear classiﬁer attempts classify data points maximizing margin decision boundaries diﬀerent classes closest points. hyper-parameter. also slack variable used relax constraints optimization problem resulting classiﬁer eﬀectively takes form template matcher compares given input another popular approach classiﬁcation ensembles decision trees. decision tree trained recursively partitioning feature space according heuristic favors good separation classes. criterion stopping tree growth reached conditional class distribution computed leaf based training data falling performance single decision tree often disappointing. however constructing ensemble trees competitive classiﬁcation performance achievable. diﬀerent approaches combining decision trees ensemble. popular algorithms ensembles decision trees random forests adaboost considered algorithms experiments. modality features actually play diﬀerent roles. intuitively role spatial coordinates avoid user-labeled voxel starts inﬂuencing prediction made voxel away e.g. avoid false positives faraway regions. modality features thus mostly informative within vicinity user-labeled voxel. training classiﬁer hyper-parameter values must speciﬁed. approach commonly implemented choose hyper-parameters cross-validation grid search approach subset brains selected hyper-parameters rest brains. hypothesize given variations data using ﬁxed hyper-parameters generalization optimal. alternative perform hyperparameter selection individually brain order adapt speciﬁcity case. measure potential gains approach experiments selecting hyper-parameters namely slack variable coeﬃcient detailed discussion experiment presented section mentioned earlier segmentation accuracy easily improved leveraging model spatial regularity labels. enforcing spacial regularity deﬁne joint distribution labels voxels brain expresses expected dependencies neighboring voxels. conditional random fields provide convenient formalism that. crfs model directly posterior probabilities experiments conducted real patient data obtained brain tumor segmentation challenge dataset part miccai conference. dataset contains patient subjects training testing. subject exist modalities co-aligned together namely flair experiments used flair only. descriptive using improve overall performance model. brain user asked manually label voxels slices class. choice slices depend size spread tumor. considering fact user choose slices view tumor coverage suﬃcient results sensitive slices chosen labeling. average voxels containing pathology voxels corresponding healthy tissue manually selected thus providing minimal labeled data algorithm. make operations faster disregard voxels outside skull consider healthy. quantitative results method obtained brats online evaluation system provides dice speciﬁcity sensitivity measures performance. measures deﬁned follows represents model predictions represents ground truth labels. also note subset voxels predicted positives negatives tumor region question. similarly complete category union classes containing un-healthy tissue. i.e. {l|l core category classes containing tumor core i.e. {l|l enhancing category i.e. {l|l online evaluation sysenhancing tumor class. also provides ranking every method submitted evaluation. includes methods brats challenge published well anonymized unpublished methods reference available. methods table presented section ordered according ranking provided online evaluation system. please note could brats dataset problems system performing evaluation quality labeled data. reasons brats dataset removed oﬃcial website time submitting manuscript brats website still showed final data brats released soon reasons decided focus brats data. also article contain studies human participants performed authors. section report experimental results obtained machine learning methods presented section includes linear kernel kernel proposed product kernel decision trees trained ada-boost random forests methods explored without crf. parameters method crossvalidation brains training set. also investigate extent feature vector presented since method uses neither spatial coordinate features regularization performs signiﬁcantly worse related experiments. adding spatial coordinates method improves result signiﬁcant margin results svm-related experiments presented table results conﬁrm using spatial coordinate features using model improve performance linear kernel also quite clear experiment non-linearity kernel crucial signiﬁcantly outperforms linear experiments ﬁxed number decision trees adaboost random forests leaf size adaboost decision stumps used. quantitative results shown table adding spatial features beneﬁcial random forests adaboost using model mostly beneﬁcial except random forest without spatial coordinates. however segmentation systems relying decision trees tend worse using methods. method using classiﬁer hyper-parameters always cross-validated brain individually using automated grid search. hand automatic methods ﬁxed hyperparameters used generalization. given variation data tumor types hypothesize using ﬁxed hyper-parameters degrade performance quite signiﬁcantly. evaluate importance performing per-brain model selection conducted experiment used ﬁxed conﬁguration hyperparameters subjects. experiment considered segmentation methods pksvm-crf* ksvm-crf*. values hyper-parameters chosen taking hyper-parameter value frequently selected methods across brains. idea pick values likely work well general. ksvm-crf* pksvm-crf* results show decrease performance ﬁxed hyperparameters used brains. also performed experiment brats training data performance decreased even more. unexpected since training data varied actually consists high grade tumors grade tumors test data contains high grade tumors. appears tuning svm’s hyper-parameter brain beneﬁcial tested extent small changes optimal hyperparameters would aﬀect performance. meant simulate fact cross-validation might always hyper-parameters between variations manually labeled voxels. order measure resilient method slight hyper-parametric shifts another experiment measure sensitivity model. randomly selecting brains brats training data trained whose hyper-parameters obtained cross validation. added noise hyper-parameters measured eﬀect resulting segmentation. noise corresponded gaussian noise whose standard deviation certain percentage hyper-parameters’ values. figure shows resulting dice measure diﬀerent noise level. even noise level corresponding corruption hyperfinally importance optimizing hyper-parameters found less crucial methods. evaluated eﬀect using diﬀerent values consistently producing higher performance. type experiment performed measure eﬀect using diﬀerent number trees leaf size rdt. methods setting number decision trees leaf size always worked well. position almost same whose flair values likely identical. thus order speed-up segmentation procedure randomly down-sample training data. overall idea extent down-sample data without hurting much overall precision conducted experiment divide training points healthy non-healthy subsets subsample separately. done maintain balance size healthy class respect classes. outcome process smaller training roughly proportion healthy points non-healthy points. figure shows result experiment. curves obtained averaging results randomly selected brains brats training data. horizontal axes figure shows number training points subsampled training set. shown figure maximum number training points average dice measure considering training points average dice measure barely drops processing time decreases thus experiments submitted brats website done subsampling measure. ﬁnally present performing methods compare state-of-the-art methods. brats oﬃcial website provides ranking system purpose. however brats organizers recently made methods anonymous complete comparison possible. reason rank method based miccai-brats challenge results references methods available. shown table pksvm-crf* ksvm-crf* figure sensitivity model respect number training points. shows variation average dice measure shows variation average processing time memory usage. post-processing vital produce highly accurate results. many methods table random forests large number features. case random forests perform well methods. might dimensionality feature space. recently subbanna published competitive results brats dataset reporting dice measures complete core enhancing tumor regions. since report speciﬁcity sensitivity measures completely fair comparison method possible. however mentioned method takes minutes process subject signiﬁcantly slower method. figure shows visualisation segmentation results diﬀerent variations method. illustrates contribution adding spatial features using using improved kernel function improving general performance approach. figure illustration brain tumor segmentation maps predicted diﬀerent variations svm. left right modality ksvm ksvm* pksvm*. bottom left right ground truth ksvmcrf ksvm*-crf pksvm*-crf. advantage proposed method small processing time memory usage maintaining high accuracy. dimensionality feature space takes average store feature space brain. small compared state-of-the-art methods whose memory footprint feature space order gb’s. example festa feature space dimensions random forest approach would take .gb’s. tustison reza meier also take similar approach using random forests methods rely high number texture features computationally time consuming memory wise expensive. apart feature space proposed methods diﬀerent speed memory footprint. make comparison accuracy speed memory usage presented table processing time measured -core processor includes training testing. time required graphcut inference methods involves additional seconds. shown table pksvm-crf* highest accuracy requires higher processing time memory usage required store feature space. hand ksvm-crf* knn-crf* closer real time implementations negligeable memory consumption. allows expert interact real-time software. said methods presented table signiﬁcantly faster state-of-the-art methods. example tustison’s method takes around minutes process brain mentioned menze paper evaluated capability within brain generalization using variety classiﬁers. showed reached best performances thanks part kernel function speciﬁcally adapted feature space. interestingly also showed adopting ﬁxed hyperparameter conﬁguration brains actually decreases performance svm. better strategy also perform hyper-parameter selection procedures performed studies involving human participants accordance ethical standards institutional and/or national research committee helsinki declaration later amendments comparable ethical standards.", "year": 2015}