{"title": "Hyperparameter Optimization and Boosting for Classifying Facial  Expressions: How good can a \"Null\" Model be?", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "One of the goals of the ICML workshop on representation and learning is to establish benchmark scores for a new data set of labeled facial expressions. This paper presents the performance of a \"Null\" model consisting of convolutions with random weights, PCA, pooling, normalization, and a linear readout. Our approach focused on hyperparameter optimization rather than novel model components. On the Facial Expression Recognition Challenge held by the Kaggle website, our hyperparameter optimization approach achieved a score of 60% accuracy on the test data. This paper also introduces a new ensemble construction variant that combines hyperparameter optimization with the construction of ensembles. This algorithm constructed an ensemble of four models that scored 65.5% accuracy. These scores rank 12th and 5th respectively among the 56 challenge participants. It is worth noting that our approach was developed prior to the release of the data set, and applied without modification; our strong competition performance suggests that the TPE hyperparameter optimization algorithm and domain expertise encoded in our Null model can generalize to new image classification data sets.", "text": "goals icml workshop representation learning establish benchmark scores data labeled facial expressions. paper presents performance null model consisting convolutions random weights pooling normalization linear readout. approach focused hyperparameter optimization rather novel model components. facial expression recognition challenge held kaggle website hyperparameter optimization approach achieved score accuracy test data. paper also introduces ensemble construction variant combines hyperparameter optimization construction ensembles. algorithm constructed ensemble four models scored accuracy. scores rank respectively among challenge participants. worth noting approach developed prior release data applied without modiﬁcation; strong competition performance suggests hyperparameter optimization algorithm domain expertise encoded null model generalize image classiﬁcation data sets. make. techniques disposal designers machine learning systems intuition repeating worked settings seem similar search model selection trial error search using e.g. cross-validation. common practice intuition search typically carried informally. practitioner design complete system semi-automated search process small-scale searches update practitioner’s implicit beliefs regarding constitutes good model task hand. beliefs inform choice future small-scale searches iterative process makes progressive improvements system. practical problem arises common practice algorithms demonstrated work particular data sets notoriously diﬃcult adapt data sets. trouble implicit beliefs practitioner play crucial role process model selection. diﬃculty widely recognized domain experts status remains many experts feel search suﬃciently eﬃcient insights gained model selection process valuable. hope results taken together recent work hyperparameter optimization bergstra snoek thornton challenge beliefs induce researchers recognize automatic hyperparameter optimization important technique model evaluation. models coates relative bergstra possibility aﬃne warping input images remove input-cropping step. total conﬁguration space includes hyperparameters although conﬁguration uses once. many hyperparameters conditional hyperparameters active certain conditions; example hyperparameters governing creation third layer inactive twolayer models. details meta-model described bergstra implemented hyperopt-convnet software available http //github.com/jaberg/hyperopt-convnet. notable omissions model space include backpropagation unsupervised learning ﬁlters rbms sparse coding daas recent highperformance regularization strategies dropout maxout section describes ensemble construction method particularly well-suited hyperparameter optimization algorithm inner loop. algorithm presented context models form feature extractor linear classiﬁer. context ensemble simply larger linear function seen concatenation ensemble members. hyperboost algorithm understood piecewise training single giant linear classiﬁer. derive hyperboost algorithm suppose commit using ensemble size ideal ensemble weights hyperparameter conﬁguration settings binary classiﬁcation task would optimize generalization error hyperparameter optimization important standard performance-enhancing technique used improve scores model family given benchmark task. ensemble methods bagging boosting stacking bayesian model averaging also commonly employed exact every last drop accuracy given algorithmic technology. goals automating hyperparameter optimization assess objective good classiﬁcation system components pursuit goal automation ensemble creation also critical. paper presents ﬁrst attempt provide fully automated algorithm model selection ensemble construction. starts palette conﬁgurable pre-processing strategies classiﬁcation algorithms proceeds creates accurate ensemble optimized components can. algorithm uses boosting approach ensemble construction hyper-parameter optimization plays role base learner. setting creates unique challenges motivate boosting algorithm call hyperboost. basic approach described bergstra hyperopt describe conﬁguration space includes onelayer two-layer three-layer convolutional networks. elements image classiﬁcation model standard scaling aﬃne warp ﬁlterbank normalized crosscorrelation local spatial pooling di-histogram spatial pooling l-svm classiﬁer. layer architecture hyperparameters govern size ﬁlters volume pooling regions constants modulate local normalization ﬁlters either chosen randomly centered gaussian distribution random projections components training data random projections input patches features classiﬁcation derived output layer either signed unsigned pooling topographically local partitioning output features. conﬁguration space chosen span model space investigated pinto random-ﬁlter denotes indicator function values negative zero values negative. stand possible hyperparameter conﬁgurations argmin means choose optimal hyperparameter conﬁgurations notation argmin indicate ﬁnal weights vector known a-priori many elements have. rather logically divided pieces corresponding ensemble elements piece dimensionality matches strategy dealing complicated relationship select conﬁgurations greedily using algorithm illustrated figure strategy dealing expectation estimate typically called validation data argmin previous work called hyperparameter optimization. strategy dealing non-diﬀerentiability indicator function gradient-free optimization method namely normally boosting hinge loss zero-one loss would quickly trouble training margins pushed past decision boundary subsequent rounds nothing avoid nonsense using techniques. first boosting suﬃcient validation data helps because models training data seldom perfect validation data random chance second round hyperboost free scale contribution previous ensemble components standard regularization techniques allow meaningfully features improve even hinge loss reduced previous hyperboosting iteration. regularization parameter governing entire hyperparameter re-optimized every round figure hyperboost algorithm creates large linear piece-wise. ﬁrst round training standard training. ﬁrst round weights ﬁxed multiplicative scaling. subsequent rounds carry forward total contribution previous features corresponding ﬁxed weights toward label predictions. round hyperboost optimizes feature weights candidate feature re-scales weights previous rounds. approximate greedy procedure makes possible large svms large numbers examples feature computation also computationally costly. hyperboost suitable boosting strong base learners. fact boosting model ﬁtting conducted statistically independent example sets distinction distinction weak strong learners longer important. instead learners simply provide models hyperboosting chooses model improves validation performance ensemble. strong learners generally require additional regularization compared weak learners order generalize correctly training data strong weak base learners equally useful hyperboosting. icml workshop repsupport resentation aaron courville released data facial expression recognition kaggle competition faces labels pixel grayscale images expressions faces. faces automatically registered face approximately centered occupies amount area within image. task categorize face seven categories distributed kaggle consists training examples examples test examples. protocol model selection simple crossvalidation training examples. partitioned training data svm-ﬁtting examples validation examples performed hyperparameter optimization regard performance validation set. test examples used model selection. kaggle website provided images test examples prevent cheating contest. test scores listed facial expression recognition challenge obtained uploading predictions kaggle’s website computed test accuracy behalf. round hyperboosting evaluated non-degenerate hyperparameter proposals search best feature ensemble. proposals ranged accuracy chance baseline relatively strong experiments done using single computer four nvidia tesla gpus slow system typically jobs would simultaneously. many conﬁgurations invalid recognized relatively quickly. valid trials typically took minutes complete round hyperboost took three days using machine. accuracies models chosen hyperboost shown figure hyperboost creates small ensemble whose combined accuracy significantly better best individual model ranking relative models kaggle competition shown table ensemble size ranks among competition entries. figure hyperboost improves test generalization successive rounds individual feature sets chosen round hold steady accuracy round selects best non-degenerate candidate feature sets. training accuracy ranges ﬁrst round fourth round. entirely designed prior release data set. model space chosen span models pinto coates pinto reported excellent match veriﬁcation performance labeled faces wild data coates advanced state time cifar- object recognition data set. approach developed prior release facial expression recognition data good performance speaks directly ability metamodeling approach generalize image classiﬁcation tasks. also worth noting training accuracy models ensemble much higher generalization accuracy size individual feature sets capped best models approached maximum number features. although large feature sets demonstrated signiﬁcant over-ﬁtting training data hyperboost selected ensemble members brought steady improvement test set. familiar story boosting algorithms based exponential loss hyperboost produces eﬀect operating representative hinge loss. project supported rowland institute harvard united states’ national science foundation canada’s national science engineering research council banting fellowship program.", "year": 2013}