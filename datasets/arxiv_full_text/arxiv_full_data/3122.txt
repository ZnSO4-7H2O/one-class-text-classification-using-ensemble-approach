{"title": "Recognizing Static Signs from the Brazilian Sign Language: Comparing  Large-Margin Decision Directed Acyclic Graphs, Voting Support Vector Machines  and Artificial Neural Networks", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "In this paper, we explore and detail our experiments in a high-dimensionality, multi-class image classification problem often found in the automatic recognition of Sign Languages. Here, our efforts are directed towards comparing the characteristics, advantages and drawbacks of creating and training Support Vector Machines disposed in a Directed Acyclic Graph and Artificial Neural Networks to classify signs from the Brazilian Sign Language (LIBRAS). We explore how the different heuristics, hyperparameters and multi-class decision schemes affect the performance, efficiency and ease of use for each classifier. We provide hyperparameter surface maps capturing accuracy and efficiency, comparisons between DDAGs and 1-vs-1 SVMs, and effects of heuristics when training ANNs with Resilient Backpropagation. We report statistically significant results using Cohen's Kappa statistic for contingency tables.", "text": "abstract—in paper explore detail experiments high-dimensionality multi-class image classification problem often found automatic recognition sign languages. here efforts directed towards comparing characteristics advantages drawbacks creating training support vector machines disposed directed acyclic graph artificial neural networks classify signs brazilian sign language explore different heuristics hyperparameters multi-class decision schemes affect performance efficiency ease classifier. provide hyperparameter surface maps capturing accuracy efficiency comparisons ddags -vs- svms effects heuristics training anns resilient backpropagation. report statistically significant results using cohen’s kappa statistic contingency tables. last decade support vector machines extensively used extended explored ever increasing interest shown numerous works practical theoretical importance. however must diminish importance artificial neural networks many advantageous characteristics already proven several real world applications. choosing best classifier given task thus simple choosing classifier higher classification rates. often many factors balanced order achieve decision. work provide comparisons support vector machines large-margin decision directed acyclic graphs artificial neural networks task high dimensional classification; terms learning ability computational costs ease use. work explores results specific task high dimensional image classification presented aforementioned work created system dynamic hand gesture recognition based two-stage architecture; developing upon work done previous publication dealt static dynamic signs image classification problem first stage previous system. efforts mainly concentrated towards brazilian sign language’s manual alphabet. brazilian sign language hereinafter libras manual alphabet needed specific occasions. occasions include example explicitly spelling name person location. nevertheless many signs manual alphabet also subcomponents elaborated signs thus practical interest head towards fully functional recognition system. considered classification scheme dynamic signs based stage architecture. first stage responsible labeling still images image stream alphabet letters anns. second stage turn would receive sequence coded letters feed bank hidden markov models performing classification maximum likelihood decision rule. architecture achieved system fingerspelling recognition promising results. furthermore replaced stage architecture svms disposed large-margin ddags. also replaced hmm-based classifier discriminative counterpart given hidden conditional random fields results shown proper choice sequence classifier could play much bigger impact overall performance system would considered choices frame classifiers. still even overall results seemed affected choice static gesture classifier training costs evaluation speeds associated could major concern applicability gesture recognition systems resource-constrained environments within limited processing power memory capacity both. goal paper thus address concerns overview hyperparameter surfaces classifiers terms accuracy efficiency discussing drawbacks advantages alternatives. paper organized follows. first introduction section gives list related works raising points interest discussions. section gives overview gesture recognition field motivation brief literature review. section presents methods models tools used work. section detail experiments fingerspelling recognition presenting results section next conclude work giving final considerations indicating works section unlike anns svms seem suffer curse dimensionality nevertheless svms shown great performance many real-world problems including high dimensionality large-scale ones. interestingly enough svms initial roots early perceptron algorithm learning artificial neurons. perceptron algorithm tries find hyperplane separating data whose decision function given cortes vapnik proposed learning separating hyperplane using approximate version structural risk minimization principle minimizing structural risk maximization classification margin time enforcing capacity control controlling margin’s width. circumstances problem stated constrained optimization problem form subject slack variables regularization term imposing weight training error minimization contraposition minimizing model complexity. large value would increase variance model risking overfit. small would turn lead possible underfitting. adding lagrange multipliers differentiating respect imposing stationarity arrives dual form optimization problem given subject bound constraints interested reader much thorough derivation found moreover make classifier nonlinear take advantage cover’s theorem consider nonlinear transformation that applied input vectors returns projection high-dimensionality feature space considering write classifier following comprehensive survey conducted mitra acharya gesture recognition methods traditionally divided main categories device-based device-based approaches often constrain users wear tracking device tracking glove resulting less natural interaction. vision based approaches hand free user wearing possibly movement limiting expensive devices. paper thus deals visionbased approaches. gestures either static dynamic. static gestures often called poses still configurations performed user passive registered single still image. dynamic gestures turn vary time captured sequence still images image streams. often gestures elements case sign languages paper specifically covering static gesture signs. name implies creation artificial neural networks strong biologic inspiration. however despite biological origins anns seen simple function mapping given input corresponding output output vectors also restricted specific subset restricted particular range according choice activation function output neurons. case sigmoid activation function range case bipolar sigmoid function learning perspective function said belong class functions sharing particular form dictated choice architecture activation functions. functions also parameterized possible weight vectors total number weight parameters network. since anns seen standard mathematical functions learning problem cast standard optimization problem would like minimize divergence sense network outputs desired answers possible achieve minimization minimization error gradient; promising method achieve resilient backpropagation algorithm rprop algorithm fastest methods gradient learning restricted solely first-order information. basic operational principle eliminate influence gradient magnitude optimization step. unlike gradient based methods gradient descent step size always proportional gradient vector rprop takes account direction gradient making local adaptive learning algorithm. rprop relies first-order information required compute hessian matrix second derivatives learning problem making especially suitable high dimensional problems. since decision function expressed solely terms inner products feature space implies need compute explicitly anymore. inner products instead computed mercer’s kernel function form originally conceived binary-only classifier. thus decide classes time. several approaches proposed generalize svms multiclass problems; promising large-margin ddag common multi-class approaches one-vs-one one-vs-all classification strategies. decision problem classes one-vs-all demands creation classifiers trained distinguish class others. classifiers work binary subproblems instances class receives positive labels others instances negative labels. one-vs-one original multi-class problem divided sub-problems considering classes time final decision class obtained voting. despite looking intensive method often cheaper sub-problem typically much smaller original problem. this turn cause variance increase resulting increased chance overfitting. also leaves problem evaluating increased number machines every instance undergoing classification could easily become troublesome prohibitive time sensitive applications. ddag turn generalizes notion decision trees allowing undirected cycles reasoning process. decision seen process sequential elimination which round class tested others losing class removed next decisions. class eliminated sequentially ddags allows conciliate faster training times -vs- strategy evaluation speed linear number classes classes machines required evaluated runtime. authors also presented strong bounds generalization error dimension classifiers. data used study gathered part previous work whole dataset contains static gestures gathered subjects articulated signs libras manual alphabet registered single camera controlled environment. performed experiments subset static gesture samples randomly selected original static sign spurious corrupted samples removed. half samples separated testing purposes half training validation. hands located still images using otsu threshold subsequent cropping centering. images dimensioned grayscale windows forming vectors albeit optimal representation highdimensionality approach done purpose study behavior different classifiers without considering prior information problem form elaborated features specialized kernels. evaluation speed become significant drawback comparing svms classification methods. default formulation upper bounds number support vectors required solve given problem. since number often grows linearly number data samples training soon becomes problematic. conducted experiment order measure impact problem check feasibility ddag decision overcoming limitation. experiment considered three possible choices kernel functions; gaussian quadratic linear. gaussian kernel coarse-to-fine grid search conducted hyperparameter space order find optimum trained machine evaluated testing dataset twice first using -vs- voting scheme ddag decision. annotated performance classifiers measured terms cohen’s kappa total number unique support vectors needed voting scheme average number vector evaluations ddag decision path. linear machines also written compact form linear machines considered number machine evaluations instead vector evaluations. svms learned using sequential minimal optimization algorithm initial feasible points gaussian kernel identified using heuristic value suggested presented based inter-quartile range norm statistics training dataset. evaluation speed concern svms training behavior perhaps biggest concerns anns. optimization algorithms often deal multiple local minima heuristics learning control mechanisms become almost mandatory. goal experiment measure impact initialization heuristics specifically nguyen-widrow method high dimensionality problems. feed-forward multilayer networks single hidden layer created varying number hidden nodes attempt enforce capacity control. networks trained convergence mean squared training error using rprop algorithm. starting gaussian-kernel vector machine found behavior similar described specifically found influence performance classifier much would proper choice statistic number support vectors resulting classifier found mostly dependent rather figure shows grid-search procedure varying alongside average number machines. worth point heuristic choice proposed resulted overall good performance also resulted less svs. although leading best possible heuristic provided good balance accuracy efficiency experimented classifiers. hyperparameter surfaces terms kappa sparseness shown figure graphs observe almost direct relationship number generalization performance; specifically apparent inverse correlation number intuitive since higher number could possibly lead increased overfitting therefore degraded performance. specific problem shown little influence number except high values case increase seems counterbalance increase leading sparseness plateau centered heuristic line graphs also show values higher values failed converge. could understandable higher values soft-margin approximates hard-margin decision reducing ability cope misclassifications training set. gaussian next step measure linear quadratic kernels. proceed worth point problem exploring already large number dimensions. linear kernel thus already expected produce good results suspicion confirmed figure kernels linear quadratic produced overall good results. albeit depicted results shown significantly different results using homogeneous inhomogeneous kernels. results possible although nguyenwidrow initialization affect much performance small networks huge impact larger ones. instance networks hidden neurons could learn classes presenting zero classification rate number class labels. networks size trained using nguyen-widrow able present much stable results comparison. nguyen-widrow initialization proved extremely helpful reaching good local minima larger networks. without initialization larger networks would rapidly converge poor local minima number iterations. initialization technique seemed prevented often common performance degradation associated largerthan-necessary networks seen figure although depicted heuristic also helped smaller networks attain convergence much faster rates much reduced numbers iterations. furthermore finally note best attained shown better results best found considering test differences statistically significant significance level. differences would thus unlikely occurred chance. would select classifier based solely estimated value clear choice would gaussian polynomial classifier. however practical high number selected maintained together classifier order process decision. ddag decision hand provides considerable evaluation speed still requires possibly highly variable number vector evaluations classify observation. applications constant time regular evaluation speed desired ddags aside. instead opting using also brings many advantages. perform rather well task moderate number hidden neurons making suitable real-time processing however learning perspective many disadvantages choice. heuristics seems crucial overcome problem multiple local minima training time consuming proper hyperparameter tuning elaborated performance estimators k-fold cross-validation become problematic. graphs figure also provide comparison efficiency linear quadratic kernels terms function machine evaluations. since linear machines written compact form evaluation speed necessarily depend number rather number machines. comparisons accuracy among selected classifiers shown table table displays dramatic reduction average number evaluations actually needed computed ddag voting schemes comparison total number selected svs. voting scheme needs evaluate machines decision average number evaluations always equal total number unique vectors found learning. ddag hand needs much smaller although variable number depending evaluation machines. start describing results obtained anns. learned networks able achieve similar performance rates svms however huge training time cost especially considering costs involved running multiple random initializations ensure good local minimum. best values found amid neurons range found however seen maximum performance obtained anns similar baseline linear hee-deok yang stan sclaroff seong-whan \"sign language spotting threshold model based conditional random fields\" ieee trans. pattern anal. mach. intell. vol. july bauer k.-f. kraiss \"video-based sign recognition using selforganizing subunits\" pattern recognition proceedings. international conference vol. daniel dias renata madeo thiago rocha helton bíscaro sarajane peres \"hand movement recognition brazilian sign language study using distance-based neural networks\" proceedings international joint conference neural networks atlanta georgia mahmoud elmezain ayoub al-hamadi bernd michaelis \"discriminative models-based hand gesture recognition\" international conference machine vision alamitos martin riedmiller \"rprop description implementation details\" institut logik komplexität und. deduktionssysteme university karlsruhe karlsruhe technical report thomas cover \"geometrical statistical properties systems linear inequalities applications pattern recognition\" ieee transactions electronic computers vol. june mercer \"functions positive negative type connection theory integral equations\" philosophical transactions royal society london. series containing papers mathematical physical character vol. john platt \"sequential minimal optimization fast algorithm training support vector machines\" advances kernel methods support vector learning vol. caputo furesjo smola \"appearance-based object recognition using svms kernel use?\" proceedings nips workshop statistical methods computational experiments visual processing computer vision considering measured options best compromise choice seems given linear svm. model able provide evaluation speeds comparable anns; time offer ease convex learning algorithm. furthermore ddag based linear svms constant evaluation rate since evaluation depend number support vectors rather number classes problem. since ddag reduces computing constant-time evaluation effort decisions constant-time decisions attain highly efficient moderately performant classifier suitable used dynamic gesture recognition system. would like express thanks cnpq partially sponsoring project; pedroso collected gesture data used experiments. furthermore also would like thank advance referees sharing valuable comments views philipp michel rana kaliouby \"real time facial expression recognition video using support vector machines\" proceedings international conference multimodal interfaces vancouver british columbia canada thorsten joachims \"making large-scale support vector machine learning practical\" advances kernel methods bernhard scholkopf christopher burges alexander smola eds. cambridge press thorsten joachims \"text categorization support vector machines learning many relevant features machine learning\" machine learning ecml- claire nédellec céline rouveirol eds. berlin/heidelberg springer berlin heidelberg vol. lecture notes computer science. giorgio valentini thomas dietterich \"bias-variance analysis support vector machines development svm-based ensemble methods\" mach. learn. res. vol. december cesar souza mauro anjo ednaldo pizzolato \"fingerspelling recognition support vector machines hidden conditional random fields\" accepted appear proceedings ibero-american conference artificial intelligence cartagena indias colombia press. ednaldo pizzolato mauro santos anjo guilherme pedroso \"automatic recognition finger spelling libras based two-layer architecture\" proceedings symposium applied computing sierre switzerland", "year": 2012}