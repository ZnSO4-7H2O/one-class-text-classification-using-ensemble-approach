{"title": "Phone-aware Neural Language Identification", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "Pure acoustic neural models, particularly the LSTM-RNN model, have shown great potential in language identification (LID). However, the phonetic information has been largely overlooked by most of existing neural LID models, although this information has been used in the conventional phonetic LID systems with a great success. We present a phone-aware neural LID architecture, which is a deep LSTM-RNN LID system but accepts output from an RNN-based ASR system. By utilizing the phonetic knowledge, the LID performance can be significantly improved. Interestingly, even if the test language is not involved in the ASR training, the phonetic knowledge still presents a large contribution. Our experiments conducted on four languages within the Babel corpus demonstrated that the phone-aware approach is highly effective.", "text": "two-approaches disadvantages. pure neural approach entire system relies features ignoring phonetic information known important beginning research hybrid system still based probabilistic model involves strong gaussian assumption suitable dealing complex class boundaries; requires relatively speech frames estimate reliable i-vector applicable many real applications require quick identiﬁcation e.g. code-switch asr. paper follow pure neural model scheme enhance existing models introducing phonetic information auxiliary feature. clear advantage lstm-rnn adopt model study though idea leveraging phonetic information applicable neural models. architecture illustrated figure involves phonetic trained discriminate phones produces phonetic features training done receives phonetic features uses together acoustic feature perform lid. model following properties phonetic trained independently rnn. means trained using data languages totally different target languages task. particularly attractive task discriminate lowresource languages. architecture reminiscence early phonetic recognition language modeling approach phone recognizer used front-end decode phonetic units followed phonetic perform scoring. rnns architecture regarded corresponding phone recognizer respectively although structure much ﬂexible historic model. fact phonetic features derived output layer phonetic propagated input layer feature omitted obtain prlm system essentially rnn-based phone architecture recently studied salamea pure acoustic neural models particularly lstm-rnn model shown great potential language identiﬁcation however phonetic information largely overlooked existing neural models although information used conventional phonetic systems great success. present phone-aware neural architecture deep lstm-rnn system accepts output rnn-based system. utilizing phonetic knowledge performance signiﬁcantly improved. interestingly even test language involved training phonetic knowledge still presents large contribution. experiments conducted four languages within babel corpus demonstrated phone-aware approach highly effective. index terms language identiﬁcation long short-term memory language identiﬁcation lends wide range applications e.g. mix-lingual speech recognition. early methods based statistical models phonetic acoustic units recent methods based probabilistic acoustic modeling among i-vector model perhaps successful recently deep neural models attracted much attention lid. lopez-moreno proposed dnn-based approach uses discriminate different languages frame-level language posteriors utterance generated simple average frame-level posteriors utterance. rnn-based approach later proposed gonzalez-dominguez better performance obtained much less parameters compared dnn-based model. advantage temporal modeling approach followed number researchers e.g. neural model structures also investigated e.g. tdnn compared i-vector approach based probabilistic model pure neural methods show clear advantage short utterances main advantage neural-based methods compared i-vector model discriminative learn complex decision bounds languages provided sufﬁcient data provided. moreover power feature learning associated deep neural nets often provides better robustness noise speaker variation highly important lid. deep neural models also used hybrid i.e. generate features alignment i-vector model. case phonetic dnn/rnn model trained phone discrimination automatic speech recognition model used produce bottle-neck features acoustic alignment constructing i-vector model. using phonetic information directly related i-vector model consistently improved. equations terms denote weight matrices associated cells constrained diagonal implementation. terms denote bias vectors. input output symbols respectively; represent respectively input forget output gates; cell cell output. output components derived recurrent next time step recurrent contributes present output only. logistic sigmoid function non-linear activation functions often chosen hyperbolic. denotes element-wise multiplication. preliminary work demonstrate concept design simple phone-aware system shown figure phonetic involve single lstm layer. although phonetic features extracted places phonetic choose output recurrent projection layer. similarly receiver phonetic features also ﬂexible investigate performance difference choices. conﬁgure shown figure uses non-linear function receiver. conﬁgure computation remains same except cell value updated follows choose lstm-rnn phonetic components study. reason choice lstm-rnn demonstrated perform well pure neural approach hybrid approach another reason structure accordance motivation model phonetic dynamics prlm approach section ﬁrst describes lstm-rnn structure used study presents phone-aware system. study models conﬁguration lstm layer consists cells dimensionality recurrent non-recurrent projections natural stochastic gradient descent algorithm employed train model. three baseline rnns used candidates phonetic rnn. visualize discriminative power phonetic features produced rnns using pca. speciﬁcally test utterances randomly selected test language utterances phonetic frame frame. frame phonetic feature read recurrent projection layer tested projected -dimensional space pca. figure presents distribution features assamese georgian languages ‘known’ model training. figure shows distribution bengali turkish language ‘unknown’ model training. figure shows distribution features four languages. observed three rnns possess certain discriminative capability known unknown languages. comparing three models features generated asrbased clearly worse features generated multi-task looks discriminative. note phonetic features assamese bengali highly overlapped matter phonetic used. means four-language task highly difﬁcult shortly. develop speech technologies low-resource languages. paper chose speech data four languages babel corpus conduct study assamese georgian bengali turkish. language training dataset development dataset ofﬁcially provided. training dataset contains conversational speech scripted speech development dataset conversational speech. used entire training language model training randomly selected utterances development language perform test. training data sets four languages follows assamese hours georgian hours bengali hours turkish hours. average length test utterances seconds ranging seconds seconds. models dimensional fbanks symmetric -frame window splice neighboring frames. experiments conducted kaldi default conﬁgurations kaldi nnet recipe used train phonetic rnn. ﬁrst step build three baseline systems using speech data languages assamese georgian. three baselines multilingual system system asr-lid multi-task system ag-asr phone sets languages merged softmax group involves state targets experiment. performance terms word error rate assamese georgian whole development dataset respectively. training decoding follow standard nnet recipe kaldi. ag-lid output layer consists units corresponding languages respectively. training procedure similar used training ag-asr model. ag-mlt model involves groups targets training utilizes labels phones languages. assamese georgian conducted either ag-lid ag-mlt using language posteriors produce. performance results systems terms cavg equal error rate shown table frame-level performance utterance-level performance reported. utterance-level results frame-level posteriors averaged produce utterancelevel posterior conducted. language collection release iarpa-babelb-v.a. language collection release iarpa-babelb-v.a. language collection release iarpa-babelb-v.b. language collection release iarpa-babelb-v.. information phonetic provides generally valuable. fact demonstrates phonetic trained ﬂexibly using speech data languages. particulary interesting languages little training data obtain reasonable phonetic rnn. ﬁnal experiment tests performance four languages. baseline system model trained data four languages denoted agbt-lid. phone-aware system ag-mlt used produce phonetic feature function used feature receiver. results shown table again performance greatly improved involving phonetic feature. presented phone-aware lstm-rnn model language identiﬁcation. argument phonetic information important lid. information successfully used historical phonetic models famous prlm system largely ignored present pure acoustic methods either i-vector model pure neural model. particularly lstm-rnn model inherent power modeling temporal dynamics model largely wasted without phonetic information involved. phoneaware architecture proposed paper employs deep neural model produce phonetic features features propagated vanilla lstm-rnn system. experiments conducted data four languages babel corpus demonstrated phone-aware model dramatically improve performance lstm-rnn system. future test phone-aware approach languages complex conditions. particularly expect phonetic information rnn-based signiﬁcantly improved long utterances providing phonetic normalization. phonetic produce phonetic features. rnns trained discriminate known languages assamese georgian. results shown table four conﬁgurations ‘receiver’ phonetic feature tested input gate forget gate output gate function. compared results baseline rnns introducing phonetic feature leads clear performance improvement frame-level utterance-level terms cavg eer. ag-asr ag-lid models phonetic rnns best conﬁgurations above function output gate receiver. ag-asr results better performance baseline ag-lid conﬁrms conjecture phonetic information valuable neural-based lid. test generalizability phonetic feature. specifically feature help discriminate languages i.e. languages unknown phonetic training bengali turkish experiment. test gain phonetic feature trained target languages bengali turkish denoted bt-lid used baseline. simplicity test scenario ag-mlt used phonetic function used feature receiver. results shown table seen although phonetic knowledge target languages phonetic feature produces still highly valuable task. understandable phonetic units often shared human languages phonetic matejka burget schwarz cernocky brno university technology system nist language recognition evaluation speaker language recognition workshop ieee odyssey the. senior beaufays long short-term memory recurrent neural network architectures large scale acoustic modeling proceedings annual conference international speech communication association povey ghoshal boulianne burget glembek goel hannemann motlicek qian schwarz kaldi speech recognition toolkit ieee workshop automatic speech recognition understanding epflconf-. lamel j.-l. gauvain language identiﬁcation using phone-based acoustic likelihoods acoustics speech signal processing icassp-. ieee international conference vol. dehak a.-c. pedro reynolds dehak language recognition i-vectors dimensionality reduction proceedings annual conference international speech communication association lopez-moreno gonzalez-dominguez plchot martinez gonzalez-rodriguez moreno automatic language identiﬁcation using deep neural networks acoustics speech signal processing ieee international conference gonzalez-dominguez lopez-moreno gonzalezrodriguez moreno automatic language identiﬁcation using long short-term memory recurrent neural networks. interspeech gonzalez-dominguez toledano gonzalez-rodriguez language identiﬁcation short utterances using long short-term memory recurrent neural networks plos vol. lozano-diez zazo candil gonz´alez dom´ınguez toledano gonzalez-rodriguez end-to-end approach language identiﬁcation short utterances using convolutional neural networks proceedings annual conference international speech communication association interspeech. international speech communication association kotov nastasenko language identiﬁcation using time delay neural network d-vector short utterances speech computer international conference specom budapest hungary august proceedings vol. springer ferrer mclaren scheffer study senonebased deep neural network approaches spoken language recognition ieee/acm transactions audio speech language processing vol.", "year": 2017}