{"title": "Deep Binaries: Encoding Semantic-Rich Cues for Efficient Textual-Visual  Cross Retrieval", "tag": ["cs.CV", "cs.AI"], "abstract": "Cross-modal hashing is usually regarded as an effective technique for large-scale textual-visual cross retrieval, where data from different modalities are mapped into a shared Hamming space for matching. Most of the traditional textual-visual binary encoding methods only consider holistic image representations and fail to model descriptive sentences. This renders existing methods inappropriate to handle the rich semantics of informative cross-modal data for quality textual-visual search tasks. To address the problem of hashing cross-modal data with semantic-rich cues, in this paper, a novel integrated deep architecture is developed to effectively encode the detailed semantics of informative images and long descriptive sentences, named as Textual-Visual Deep Binaries (TVDB). In particular, region-based convolutional networks with long short-term memory units are introduced to fully explore image regional details while semantic cues of sentences are modeled by a text convolutional network. Additionally, we propose a stochastic batch-wise training routine, where high-quality binary codes and deep encoding functions are efficiently optimized in an alternating manner. Experiments are conducted on three multimedia datasets, i.e. Microsoft COCO, IAPR TC-12, and INRIA Web Queries, where the proposed TVDB model significantly outperforms state-of-the-art binary coding methods in the task of cross-modal retrieval.", "text": "future media center university electronic science technology china chengdu china yuming.shenuea.ac.uk li.liumalongtech.cn ling.shaoieee.org jingkuan.songgmail.com cross-modal hashing usually regarded effective technique large-scale textual-visual cross retrieval data different modalities mapped shared hamming space matching. traditional textual-visual binary encoding methods consider holistic image representations fail model descriptive sentences. renders existing methods inappropriate handle rich semantics informative cross-modal data quality textual-visual search tasks. address problem hashing cross-modal data semantic-rich cues paper novel integrated deep architecture developed effectively encode detailed semantics informative images long descriptive sentences named textual-visual deep binaries particular region-based convolutional networks long short-term memory units introduced fully explore image regional details semantic cues sentences modeled text convolutional network. additionally propose stochastic batch-wise training routine high-quality binary codes deep encoding functions efﬁciently optimized alternating manner. experiments conducted three multimedia datasets i.e. microsoft coco iapr inria queries proposed tvdb model signiﬁcantly outperforms state-ofthe-art binary coding methods task cross-modal retrieval. data retrieval image text modalities aroused recent attention becoming overwhelming research topic computer vision. deep learning technology develops dramatic progress achieved figure proposed model aims encoding informative words sentence possible attractive regions image. contrarily conventional textual-visual binary encoding methods utilize simple representations modality discard information resulting matching quality. recently area. handling large-scale image-text retrieval cross-modal hashing schemes proposed encode heterogeneous data high-dimensional feature space shared low-dimensional hamming space approximate nearest neighbour given query found efﬁciently. traditionally existing researches cross-modal hashing focus image-tag mapping holistic image representations semantic tags feed shallow binary coding procedure. insufﬁcient simply link images tags instead real sentences multimedia searching problems; detailed information images usually discarded holistic representations semantics enclosed descriptive sentences hardly explored. recent deep hashing methods also suffer several drawbacks. first image data likewise poorly modeled lack detailed regional information encoding. argue optimal images fruitful semantics. secondly deep models mentioned still utilize coarse text representations inappropriate modeling long sentences. moreover network training efﬁciency improved advanced code learning architectures. driven drawbacks previous works paper consider challenging task encode informative multi-modal data i.e. semantic-rich images descriptive sentences binary codes cross-modal search termed textual-visual deep binaries particularly popular region proposal network long short-term memory introduced formulate image binary coding function regional semantic details images well preserved dominant minor. meanwhile latest advances text convolutional neural networks adopted build text binary encoding network leveraging structural cues words sentence. proposed deep architecture produces highsemantic-retentivity binary codes achieves promising retrieval performance. intuitive difference proposed method traditional ones given figure seen proposed tvdb encodes many details possible images sentences leading representative binary codes matching. addition novel deep binary encoding networks tvdb efﬁcient stochastic batch-wise code learning inspired shen procedure proposed. binary codes tvdb discretely alternately optimized batch-wise learning procedure. batching data randomly iteratively proposed training routine guarantees effective learning objective convergency. contributions work summarized follows tvdb model proposed effectively encode rich regional information images well semantic dependencies cues words exploiting modal-speciﬁc deep binary embedding networks. intrinsic semantic correlation heterogeneous data quantitatively measured captured. novel stochastic batch-wise training strategy adopted optimize tvdb reliable binary codes deep encoding functions optimized alternating manner within every single batch. evaluation results model three semantically rich datasets highly surpass existing state-of-the-art binary coding methods cross-modal retrieval. cutting-edge studies vision language achieve promising results terms visual question answering caption generation real-valued cross-modal retrieval best-performing real-valued cross-modal retrieval models typically rely densely annotated imageregion text pairs embedding. however methods satisfactory large-scale data retrieval inefﬁcient similarity computation real-valued embeddings. hand exists several hashing methods aiming efﬁcient retrieval. textual-visual hashing traditional common solution encode images tags shallow embedding functions either unsupervised pairwise based supervised code learning methods. recently deep hashing methods provide promising results image recognition also adopted textual-visual retrieval. jiang proposed dcmh image-tag retrieval using multi-layer neural networks simply take deep holistic image features word count vectors input. dvsh proposed becomes feasible solution imagesentence hashing sequential information sentence data better encoded introducing recurrent neural networks combines data representation learning steps quantization error controlling hash coding methods deep neural networks still basically addresses image-tag hashing. general methods barely obtain adequate performance task coarse image text representations. deep encoding networks tvdb work addresses problem data retrieval between informative images long sentences using deep binary codes. shown figure proposed tvdb model composed deep neural networks batch-wise code learning phase. deep neural networks play role binary encoding functions images sentences denoted respectively. batch-wise optimization allows using binary codes supervision mini-batch training. preliminary notation introduced here. consider multi-media data collection containing image data {xi}n sentence data figure network architecture tvdb. lstm utilized form image encoding function encoding image regions dominant minor. sentence encoding network built text-cnn rightmost component refers batch-wise coding procedure. module computes region coordinates discussed subsection word refers linear word embedding procedure introduced subsection {yi}n denoting total number data points modality dataset. deep binary encoding functions tvdb parameterized sign function applied produce binary representations architecture image encoding network given subsection. discussed previously encoding holistic image discards informative patterns produces poor coding quality desirable task. consider deep neural network architecture embeds several salient regions image single binary vector enrich encoded semantic information. worthwhile note directly linking every image region certain concept sentence feasible cross-modal hashing problems contrary original intention binary encoding work. instead regional semantic cues images leveraged improve encoding quality. salient semantic region selection. shown figure image mini-batch tvdb ﬁrstly detects number regional proposals possibly carry informative parts e.g. recognizable dominative objects image. recent works region-based show great potential detecting semantically meaningful areas image. adopt framework state-of-the-art proposal detection basis tvdb. total number semantic regions sampled processing according simple heuristic attraction score descending order denotes conﬁdence score determined refers normalized proportion k-th detected proposal image. consider regional proposals high attraction score semantically dominating whole image usually recognizable image parts. heuristic region selection solution highly task cross-modal binary encoding since require additional supervision ﬁne-grained region-sentence relations. regional representation augmentation. selected image regions cnns extract vectorized representations. benchmark architecture alexnet involved here feature representation obtained. make structural information feature vector region augmented four additional digits indicating normalized height width center coordinates corresponding region bounding making whole regional representation vector each. recurrent network encoding. task desirable method capitalizes information selected ordered regions dominating image parts contribute ﬁnal representation. proved human eyes sequentially browse image parts dominant minor simulating procedure sort selected regional proposals according entire training procedure follows mini-batch stochastic gradient descent since deep neural networks utilized. suggest binary learning solution provide reliable target codes network supervision every time mini-batch feeds. batch-wise alternating optimization denote mini-match stochastically taken data collection {xi}nb {yi}nb image sentence data minibatch respectively. training process tvdb typically batch-based introduce in-batch pair-wise similarity matrix }nb×nb target binary code learning denoting number data points within mini-batch training. entry deﬁned follows learn target binary codes images sentences best describe in-batch samples. fully utilizing pairwise relations supervision trace-based prototypic learning objective hashing thus built relaxing binary constraints continuous i.e. results slow difﬁcult optimization process. inspired shen reformulate problem keeping binary constraints regarding auxiliary variables attraction scores descending order corresponding representation proposal sequentially dominant image parts well utilized. additionally feature holistic image also appended input sequence making total semantic regions encoding. particular two-level long short-term memory implemented unit output length following popular structure described shown figure outputs lstms averaged along time sequence appended relu activation. fully-connected layers applied averaged lstm outputs output dimension respectively. thus whole image encoded m-bit binary vector using sign function. choose identity function activation fully-connected layer convenience code regression. convolutional layers images built following alexnet although recurrent networks widely adopted textual-visual tasks still argued rnns lstms usually superior choice speciﬁc language tasks non-structural designs encoding structural contextual cues words sentence ensure produced binary codes adequate information capacity. text-cnn chosen text-side encoding network word descriptive sentence ﬁrstly embedded word vector certain dimension convolution performed along word sequence. pre-process text data following conventional manner sentences appended token padded truncated certain length full stops removed. sentence length preprocessing ﬁxed mean length text data datasets used experiments. word embedded vector using linear projection cnn. text-cnn architecture tvdb similar fully-connected layers coding. full conﬁguration text-cnn given bottom figure word layer figure refers word embedding parameters also involved back-propagation procedure. text convolution setups ﬁrst second digits kernel size denote height width convolutional kernels third digit kernel number. note that text convolution performed along word sequence second dimension kernel size convolutional layers always work number kernels convolutional layers also output hash function parameters randomly initialize }m×n repeat stochastic mini-batch respective indices build according data relations labels update update update outside batch thus batch-wise similarity skews statistics whole dataset. precise consider data batching scheme build every well explores cross-modal semantic relationships across entire dataset. stochastic batching routine designed. data mini-batch randomly formed input training procedure. therefore varies across batch ensures in-batch data diversity. combining stochastic batching method alternating parameter updating schemes whole training procedure tvdb illustrated algorithm operator algorithm indicates adaptive gradient scaler used adam optimizer work. unlike existing deep hashing methods update target binary codes whole epoch ﬁnished tvdb updates instantly minibatch arrives. training routine proves achieve fast convergency effectively learning encoding networks shown figure tvdb model trained given image query example compute binary code sign retrieval database uniﬁed binary codes sentence obtained sign sentence query processed similar manner. experiments tvdb cross-modal retrieval performed three semantically fruitful sentence-vision datasets microsoft coco iapr inria queries evaluation results reported according following themes comparison state-of-the-arts methods deep encoding network ablation study training routine feasibility. implementation details utilize quantization error binary codes binary coding function outputs proved sufﬁciently large value becomes close approximation slight disparities tolerant binary learning problem. comprehensive learning objective tvdb formulated. provide optimization schemes below. observed non-convex np-hard problem binary constraints. better access alternating solution based coordinate descent adopted sequentially optimize every single batch follows. variables ﬁxed. subproblems typically form norm differentiable problems thus optimized framework using back-propagation. updated auxiliary binary codes supervisions binary encoding networks stochastic-batched training procedure. subsection presented binary code learning algorithm mini-batch tvdb. however apply batch-wise learning objective whole dataset discussed. subsection overall training procedure mini-batch introduced. note simply keeping data every minibatch unaltered training epoch usually results poorly-learned hash functions. crossmodal in-batch data able interact data image proposal detection pick informative regions lstm-based encoding value problem cross-validation. image-side cnns alexnet without layer adopted pre-trained parameters imagenet classiﬁcation tvdb framework implemented using tensorﬂow experiments sentence-vision retrieval taken three multimedia datasets. following conventional textual-visual retrieval measures relevant instances query deﬁned sharing least label. microsoft coco coco dataset contains training image samples validation images. image assigned sentence descriptions labeled semantic topics. consistent randomly select images validation thus retrieval gallery becomes around images explicitly take pairs query images training. iapr consists images. image provided descriptive sentences average. addition category annotations given images concepts. following setting image-sentence pairs belong frequent topics retrieval gallery take inria queries dataset contains images categorized conceptual labels. sentence descriptions provided images. select images belonging frequent concepts making gallery image-sentence pairs. query images sentences randomly selected category rest used training data. baselines. several baselines traditional cross-modal hashing methods adopted comparison including cmfh cmssh seph cvfl plsr considered real-valued methods. i.e. deep-learning-based cross-modal hashing methods corrae cm-nn dcmh dvsh also included here. make fair comparisons utilize deep features traditional baseline methods mentioned codes available. image features directly alexnet pretrained representations. text features multi-label classiﬁcation text-cnn shares structure text encoding network excluding last layer pre-trained dataset. feature extracted sentence pooling layers. implementing dcmh build identical text coding network ours enabling handle sentence data. cite performances variants dnh-c provided since settings used. results analysis. retrieval performances three datasets reported table general proposed tvdb model outperforms existing methods three datasets large margins. traditional cross-modal hashing techniques usually designed speciﬁcally images sentences limperformances three datasets. suggests image-tag hashing retrieval unrepresentative vision-language tasks. recent deep hashing model dvsh hits closest overall ﬁgures modal-speciﬁc deep networks able explore intrinsic semantics images sentences. tvdb provides even superior performance since regional image information relations words well encoded making output binary codes discriminative. results left blank corresponding baseline codes available performances never reported. note overall scores inria queries relatively lower two. probably relatively image quality. corresponding precision-recall curves -bit code length given figure sentence query image example given figure top- closest retrieved candidates -bit coco. tvdb provides wellmatched results detailed information preserved compared methods not. baselines. four variants tvdb built baselines modifying deep encoding networks architectures tvdb-i built replacing region-based image encoding network tvdb holistic alexnet cnn. tvdb-i mixes image region features using average pooling instead rendering lstm units. tvdb-t takes text bag-of-words sentence features original text-cnn removed. figure intuitive sentence query image retrieval top- results microsoft coco bits. tvdb carries best matching candidates objects mentioned query included results analysis. self-comparison results cross-modal retrieval shown table expected scores drop dramatically simple image bag-of-words features still acceptable compared existing methods. image binary encoding without regional information still satisfactory. tvdb-t text-lstm obtains reasonable performance general superior state-of-the-art dvsh since lstm also capable modeling sentences. however tvdb-t performs poorer original tvdb suggesting proposed text-cnn architecture suitable choice cross-modal hashing task. seen proposed binary encoding network successfully designed components reasonably implemented. training. here refers similarity matrix whole training tvdb-e similar optimization dcmh performing epoch-wise binary code learning instead batch-wise i.e. updating similar manner whole training epoch. tvdb-e similar tvdb-e code learning updating performed after every epochs training instead one. figure -bit retrieval image query sentence sentence query image w.r.t. training epochs microsoft coco dataset shown here. corresponding losses also given top. results analysis. experiments conducted microsoft coco dataset code length cross-modal retrieval scores corresponding learning losses w.r.t. training epochs shown figure obvious tvdb converges quickly acceptable score gradually hits best performance epoch. tvdb generally superior compared baselines terms peak performance training efﬁciency. seen tvdb-n obtains similar rate convergency tvdb ﬁrst training epochs ends signiﬁcantly lower retrieval performance since network parameters disjointly optimized tvdb-s follows close path tvdb-n slightly higher performance. clear code learning strategy unaltered in-batch data appealing exploring generalized optima whole dataset. tvdb-e tvdb-e carry acceptable retrieval performances still outperformed tvdb. demonstrates aspect tvdb necessary obtain optimal performance. paper proposed deep binary encoding method termed textual-visual deep binaries able encode information-rich images descriptive sentences. modal-speciﬁc binary encoding networks built using lstm text-cnn leveraging image regional information semantics words obtain high-quality binary representations. addition proposed stochastic batch-wise code learning routine performs effective efﬁcient training. experiments justiﬁed proposed deep encoding networks training routine contribute greatly ﬁnal outstanding cross-modal retrieval performance.", "year": 2017}