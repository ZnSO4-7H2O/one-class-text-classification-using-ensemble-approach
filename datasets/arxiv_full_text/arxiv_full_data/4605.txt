{"title": "Learning Bayesian Networks from Incomplete Data with Stochastic Search  Algorithms", "tag": ["cs.AI", "cs.LG"], "abstract": "This paper describes stochastic search approaches, including a new stochastic algorithm and an adaptive mutation operator, for learning Bayesian networks from incomplete data. This problem is characterized by a huge solution space with a highly multimodal landscape. State-of-the-art approaches all involve using deterministic approaches such as the expectation-maximization algorithm. These approaches are guaranteed to find local maxima, but do not explore the landscape for other modes. Our approach evolves structure and the missing data. We compare our stochastic algorithms and show they all produce accurate results.", "text": "paper describes approaches algorithm mutation operator learning bayesian networks problem characterized solution space highly multimodal approaches involve using deterministic e�.-pectation-maximization approaches find local maxima explore modes. landscape approach evolves structure missing data. compare stochastic show produce accurate systems multisensor recently constructing process eliciting intensive experts. methods capturing construct bayesian networks expert improve efficiency knowledge engineering reason learning data become increasingly research. assumption values variables cases database. realistic involve learning bayesian network decomposed problem learning graph structure first attempts involved learning parameters network structure recently problem learning structure incomplete research closed form expressions missing metric used evaluate scoring structures. many path estimating parametric maximization algorithm. advantages believe. we'll begin describing algorithms. different terms common meaning. discuss common representation used common fitness function. section introduce mcmc. describe advantages also discuss describe thought mcmc. section describes empirical approach section future research. background evolutionary algorithms evolutionary consist selected discover space. specifically follows. generated. population manner. individuals population individual good solution provides. modified using genetic operators. common genetic operators crossover mutation. selected information individuals figure mutation modified binary string representation. individuals final step evolutionary algorithm imputing space becomes complex. must search missing data network structures. evolves structures approach representation structures. straightforward. dataset gene takes sampled values values corresponding variable. chromosome structure adjacency represents first member exception parents first member i.e. first column adjacency although show picture representation encodes variable adjacency list chromosome mutation accomplished randomly selecting values corresponding structure tailored mapping directed graph phenotype. recall gene structure gene's parent nodes graph. include gene node delete node. operators effect phenotype adding deleting third basic modification implemented parent-child genetic missing chose uniform parameterized probability occurrence define associated energy -logp+z] arbitrary chosen solution markov chain satisfies conditions ooique stationary markov chain specified holtzman distribution ensuring condition also known local reversibility. detailed balance ensures equilibrium transitions balanced transitions back formally markov chain satisfies balance convergence markov chain converge without stationary holding. however detailed simple recipe designing converge stationary normalization distribution). several sampler satisfies applied common sampling approaches sampling variable missing value originally state proposed adding arcs structure. whether changes used determine accepted thus ensuring chain satisfies detailed balance. order compare population-based population evolutionary markov evolutionary predict particular expectations within prior experience domain difficult determine solution problem many evolutionary genetic drift majority drifts single mode search population essentially stops. markov chain monte carlo algorithms sample target stationary distribution physics imaginary first principles predict long-term unfortunately converge mixing. given ability exchange information reasonable approach finding better mallick mallick mcmc approach also lead diverse convergence. sampling single mode. addition based samples directly distribution theoretically landscape solutions landscape. selected described section rejected according criterion individuals pair offspring rejected jointly posterior product posterior offspring crossover backward forward transition probabilities computed. note emcmc algorithm stationary consists posterior data. therefore stopping considered posterior obtain valid statistical properties probability direction missing observation value. important uses information solutions emcmc described crossover operator. operator propose states based mutation states current distribution population. adaptive operator probabilistically previous meta-mcmc overall mcmc. operator proposing structures missing data. nodes arcs represent individual structure difference placement population converges stationary distribution distribution approach exchange evolutionary maintaining detailed algorithm evolutionary monte carlo algorithm. emcmc population-based operators mcmc population chains evolved using metropolis­ hastings parameter individual population missing values distribution missing values. empirical results approach approach evaluating first find \"good\" parameters algorithms appropriate known network data training separate data test. true model. iterations values. joss commonly used metric appropriate probabilistic learning algorithms. proper scoring rules. proper scoring rules characteristic learned probability empirically loss variable convergence markov chain population distribution. stationary converges convergence metric developed gelman rubin measuring convergence multiple chains measure uses within chain variances call scale bayesian dirichlet mcmc adaptive much higher probable networks emcmc algorithms. loss plots overlap algorithms still improvement mcmc mcmc adaptive mutation emcmc. mcmc mutation find networks adaptive given data original probable networks whose loss almost good original score original network loss number unique structures run. quickly homes \"good\" structures effect sampling highly probable hand maintains completely diverse population mcmc exploring efficiently. addition earlier samples mcmc make inferences space. unclear inferences make samples advanced techniques theory lead improved performance reason performs well samples highly probable modes. reason mcmc adaptive superior performance mcmc emcmc obvious. theory mcmc algorithms distribution reason choosing stopping iterations mcmc algorithms figure distribution shows plots multiple chains plot gelman rubin metric single plots reasonable chains converged actuality emcmc algorithms converged. figure depicts multiple chains mcmc mcmc canonical adaptive mutation iterations converged canonical converged even iterations. mcmc still slowly learning bayesian networks incomplete data difficult problem. current state-of-the-art approaches approaches approach stochastic evolutionary markov chain monte carlo algorithms. also introduce hybrid family algorithms evolutionary markov chain monte carlo algorithm eaandmcmc. demonstrate learn bayesian networks incomplete data perform well. found mcmc algorithms probable networks original original local changes global information adaptive mutation make dramatic improvements myers laskey learning bayesian data using evoluationary algorithm proceedi genetic evolutionary morgan computation kaufmann. neal probabilistic using markov chain monte carlo methods. toronto university", "year": 2013}