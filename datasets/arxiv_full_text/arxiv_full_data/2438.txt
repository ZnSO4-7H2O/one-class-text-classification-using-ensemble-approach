{"title": "Learning to Make Predictions In Partially Observable Environments  Without a Generative Model", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "When faced with the problem of learning a model of a high-dimensional environment, a common approach is to limit the model to make only a restricted set of predictions, thereby simplifying the learning problem. These partial models may be directly useful for making decisions or may be combined together to form a more complete, structured model. However, in partially observable (non-Markov) environments, standard model-learning methods learn generative models, i.e. models that provide a probability distribution over all possible futures (such as POMDPs). It is not straightforward to restrict such models to make only certain predictions, and doing so does not always simplify the learning problem. In this paper we present prediction profile models: non-generative partial models for partially observable systems that make only a given set of predictions, and are therefore far simpler than generative models in some cases. We formalize the problem of learning a prediction profile model as a transformation of the original model-learning problem, and show empirically that one can learn prediction profile models that make a small set of important predictions even in systems that are too complex for standard generative models.", "text": "faced problem learning model high-dimensional environment common approach limit model make restricted predictions thereby simplifying learning problem. partial models directly useful making decisions combined together form complete structured model. however partially observable environments standard model-learning methods learn generative models i.e. models provide probability distribution possible futures straightforward restrict models make certain predictions always simplify learning problem. paper present prediction proﬁle models non-generative partial models partially observable systems make given predictions therefore simpler generative models cases. formalize problem learning prediction proﬁle model transformation original model-learning problem show empirically learn prediction proﬁle models make small important predictions even systems complex standard generative models. learning model dynamics environment experience critical capability artiﬁcial agent. agents learn make predictions future events anticipate consequences actions predictions plan make better decisions. agent’s environment complex however learning problem pose serious challenges. common approach dealing complex environments learn partial models focusing model-learning problem making restricted particularly important predictions. often predictions need made much complexity dynamics modeled safely ignored. sometimes partial model directly useful making decisions instance model makes predictions agent’s future rewards cases many partial models making restricted predictions combined form complete model instance factored mdps factored psrs collections local models common approach learning partial model apply abstraction ﬁlters detail training data irrelevant making important predictions. model-learning methods applied abstract data typically learning problem tractable result. however especially case partially observable systems abstraction alone suﬃciently simplify learning problem even model asked make intuitively simple predictions. counter-intuitive complexity learning partial model partially observable case direct result fact standard model-learning approaches partially observable systems learn generative models attempt make every possible prediction future cannot straightforwardly restricted making particularly important predictions. paper present alternative approach learns non-generative models following illustrative make speciﬁed predictions conditioned history. example sometimes small predictions necessary good control performance learning make predictions high-dimensional environment using standard generative models pose serious challenges. contrast exists simple non-generative model make maintain predictions form learning target method. consider simple game three card monte. dealer perhaps crowded street three cards ace. dealer shows location ﬂips cards mixes swapping cards every time step. player game must keep track location ace. eventually dealer stops mixing cards asks guess. player correctly guesses money. guess wrong lose money. consider artiﬁcial agent attempting learn model dynamics game experience. takes sequence actions perceives sequence observations. data received agent includes rich high-dimensional scene including activities crowd movement cars weather well game clearly learning model encompasses complex phenomena infeasible unnecessary. order game agent needs focus making predictions cards need anticipate future behavior city scene around particular agent need make three predictions card ace? corresponding predictions cards safely ignore much detail agent’s experience still make important predictions accurately. ﬁlters irrelevant detail agent’s experience might look like this agent takes action starting game observes dealer showing card position agent takes watch action observes dealer swapping cards takes watch action again observes dealer swapping cards dealer prompts agent guess data reﬂects movement cards. could learn model using data learning problem would simpler since complex irrelevant phenomena like crowd weather ignored. markov case agent directly observes entire state environment therefore learn make predictions direct function state. abstraction simpliﬁes representation state thereby simpliﬁes learning problem. note however three card monte problem partially observable agent cannot directly observe state environment partially observable case agent must learn maintain compact representation state well learn dynamics state. common methods achieve this expectation-maximization learning pomdps learn generative models provide probability distribution possible futures. three card monte even irrelevant details ignored data contains information cards’ movement generative model still intractably complex generative model makes predictions future events. includes predictions model meant make also many irrelevant predictions. generative model also predict instance whether ﬂipping card time-steps reveal whether cards swapped next time-step. make predictions model must capture dynamics cards also dealer’s decision-making process. dealer decides cards swap using complex process problem learning generative model abstract system correspondingly complex. course three card monte predicting dealer’s future behavior entirely unnecessary win. required maintain ace’s current location time. such learning model devotes complexity anticipating dealer’s decisions counter-intuitive best. reasonable model seen figure states model labeled predictions ace’s location. transitions labeled observations dealer’s behavior. agent plays game could model maintain predictions location time taking dealer’s behavior account predicting dealer’s future behavior. note non-generative model. provide distribution possible futures cannot used simulate world predict dealer’s next move. provides limited conditional predictions future given history past actions observations. hand simpler generative model would model dealer’s decision-making process model states regardless underlying process used dealer. model figure example term prediction proﬁle model. paper formalize prediction proﬁle models present algorithm learning data assumptions empirically demonstrate partially observable systems prove complex standard generative model-learning methods possible learn prediction proﬁle model makes small important predictions allow agent make good decisions. next sections formally describe setting establish notation terminology formalize general learning problem addressed. subsequent sections formally present prediction proﬁle models algorithm learning them well several relevant theoretical empirical results. focus discrete dynamical systems. agent ﬁnite actions take environment ﬁnite observations produce. every time step agent chooses action environment stochastically emits observation agent uses model make conditional predictions future events given history actions observations given future behavior. environment assumed stochastic predictions probabilities future events. primitive building block used describe future events called test test simply sequence actions observations could possibly occur akok. agent actually takes action sequence observes observation sequence test succeeded. prediction probability test succeeds history assuming agent takes actions test. essentially prediction test answer question take particular sequence actions probability would particular sequence observations given history far? formally {h}. model make prediction make conditional prediction future represents probability distribution futures model used sample distribution order simulate world sample possible future trajectories. such call model makes predictions generative model. note word generative closely related broader sense general density estimation. attempting represent conditional probability distribution generative approach would represent full joint distribution conditional probabilities computed generative model sense makes predictions even variables wish condition non-generative settings discriminitive approach would instead directly represent conditional distribution taking value un-modeled input. non-generative approach sometimes result signiﬁcant savings diﬃcult represent/learn relatively simple particular setting generative model provides probability distribution futures such would generative model compute particular fact equation prediction multi-step test computed predictions one-step tests non-generative model then would make one-step predictions histories consequently would directly represent prediction history un-modeled input. would condition given history necessarily capable computing probability history sequence. three card monte example beneﬁcial making maintaining predictions substantially simpler making predictions every possible action-observation sequence. note test describes speciﬁc future event many cases might wish make predictions abstract events. achieved composing predictions many tests. instance tests sequence actions observation sequences. test succeeds agent takes speciﬁed action sequence sees observation sequence contained within occur. traditional tests allow agent instance express question outside probability exact sequence images? test express useful abstract question outside probability sunny? grouping together observations sunny day. even generally option tests express future events agent’s behavior described abstractly well resulting observations. types abstract predictions computed linear combination concrete predictions. sometimes useful describe dynamical system using conceptual object called system dynamics matrix system dynamics matrix contains values possible predictions therefore fully encodes dynamics system. speciﬁcally deﬁnition system dynamics matrix dynamical system inﬁnity-by-inﬁnity matrix. column corresponding every test corresponding every history ijth entry system dynamics matrix prediction test corresponding column history corresponding entry every history-test pair. popular modeling representations linear dimension major factor complexity representing learning generative model system. instance pomdps number hidden states required represent system lower-bounded linear dimension. work adopt linear dimension measure complexity dynamical system. system simpler another mean lower linear dimension. markov case notational shorthand indicate prediction history ends observation markov case observations contain information needed make prediction future often called state system markov partially observable. partially observable systems predictions depend arbitrarily entire history. focus partially observable case. work assume that three card monte though agent live complex environment small important predictions make. predictions could identiﬁed important designer learning process. address problem identifying predictions made rather focus problem learning make predictions identiﬁed. general imagine given ﬁnite tests interest would like model make accurate predictions. term test construed broadly possibly including abstract tests addition sequences actions observations. tests interest future events model predict. instance three card monte problem order perform well agent must predict whether ﬂips card. three one-step tests interest agent learn maintain probability events time game. function histories predictions test interest history. note output necessarily probability distribution. tests interest selected arbitrarily therefore need represent mutually exclusive exhaustive events. call particular vector predictions tests interest prediction proﬁle. describe existing general approaches learning learning direct function history predictions learning fully generative model maintains ﬁnite-dimensional summary history strengths weaknesses approaches learning section contrast approach combines strengths approaches. learning takes histories input instead learn function arkov maps observation predictions tests interest resulting histories observation. note that immediate consequence discrete markov systems ﬁnite number distinct prediction proﬁles. fact distinct prediction proﬁles observations. main challenge learning markov models arises number observations large. becomes necessary generalize across observations using data gathered observation learn many others. speciﬁcally able exploit fact observations associated similar prediction proﬁles share data amongst them. restricting model’s attention predictions aﬀord generalization learning partial model beneﬁcial markov setting. even system partially observable still attempt learn directly typically performing sort regression features entire histories. instance u-tree takes history features learns decision tree attempts distinguish histories result diﬀerent expected asymptotic return optimal behavior. wolfe barto apply u-tree-like algorithm rather restricting model predicting future rewards learn make predictions pre-selected features next observation dinculescu precup learn expected value given feature future direct function given real-valued feature history clustering futures histories similar associated values. directly approximate types models make predictions therefore non-generative though approach demonstrated promise also faces clear pragmatic challenge especially partially observable setting feature selection. function history ever-expanding sequence actions observations ﬁnding reasonable compactly represented features collectively capture history information needed make predictions interest signiﬁcant challenge. sense even partially observable setting type approach takes small step away markov case. still requires good idea priori information extracted history order make predictions interest. bowling mccracken james neufeld wilkinson showed estimator unbiased case data collected using blind policy action selection depend history observations provided alternative estimator unbiased policies. simplicity’s sake however assume throughout data gathering policy blind. good idea priori features extracted history make accurate predictions faces additional challenge learning summarize relevant information history compact suﬃcient statistic. exist methods learn training data maintain ﬁnite-dimensional statistic history prediction computed. analogy markov case statistic called state vector. clearly model maintain state used compute brieﬂy mention examples approach particularly relevant development analysis method. pomdps popular representation models partially observable systems partially observable markov decision process pomdp posits underlying hidden states agent never observes. given time-step system particular hidden state agent takes action system transitions next state according transition probability observation emitted according probability distribution general depend upon agent observe hidden states cannot know hidden state system given moment. agent however maintain probability distribution represents agent’s current beliefs hidden state. probability distribution called belief state. belief state associated history known straightforward compute prediction test computed using transition observation emission probabilities. belief state ﬁnite summary history prediction future computed. belief state state vector pomdp. given transition probabilities observation emission probabilities possible maintain belief state time using bayes’ rule. current history knows hidden states agent takes action observes observation compute probability hidden state history parameters pomdp must learned order able maintain state transition probabilities observation emission probabilities. given parameters belief state corresponding given history recursively computed model thereby make prediction history. pomdp parameters typically learned using expectation maximization algorithm given training data number actions observations hidden states input essentially performs gradient ascent transition emission distributions maximize likelihood provided data. psrs another recently introduced modeling representation predictive state representation instead hidden states psrs deﬁned directly terms system dynamics matrix speciﬁcally psrs core tests whose corresponding columns system dynamics matrix form basis. recall system dynamics matrix often ﬁnite rank thus ﬁnite many systems interest. since predictions basis prediction test history computed linear combination predictions history. vector predictions called predictive state. belief state state vector pomdps predictive state state vector psrs. also maintained application bayes’ rule. speciﬁcally history known core tests agent takes action observes observation compute prediction core test history given core tests parameters must learned order maintain state coeﬃcients every action observation coeﬃcients maoq every action observation core tests given parameters predictive state given history recursively computed used make prediction future. psrs learned directly estimating system dynamics matrix recently sub-matrix derived matrix thereof using sample averages training data. estimated matrix used core tests parameters estimated using linear regression. note types models inherently generative. rely upon maintenance state vector order make predictions seen equations state update equations models rely upon access one-step predictions perform bayesian update. such unlike direct function approximation approach cannot simply choose predictions model make. models necessity make predictions. many reasons desire complete generative model. makes possible predictions model used sample possible future trajectories useful capability planning. generative model also deﬁnition ﬂexible predictions used make. hand many cases complete generative model diﬃcult obtain. pomdp training methods scale poorly linear dimension system learned. linear dimension lower-bounds number hidden states needed represent system pomdp precisely number core tests needed represent psr. learning methods pomdps psrs rarely successfully applied systems linear dimension furthermore complete generative model overkill problem hand. recall seek make predictions; focused making particularly important predictions even problems learning make predictions might intractable still possible make simple important predictions. discussed earlier restricted tests interest learning problem often simpliﬁed ignoring irrelevant details abstraction. course abstraction solve problem partial observability. typically done apply abstraction training data discarding irrelevant details apply model learning methods like ones described abstract data set. markov setting cases observation abstraction greatly simplify learning problem ignoring details irrelevant making predictions interest intuitive signiﬁcantly simplify learning problem. hand generative models abstract pomdp still make abstract predictions. typically includes predictions directly interest. extra predictions require complex model even abstract generative model intractible learn. true three card monte example following another simple example phenomenon. example. consider uncontrolled system pictured figure called ball bounce system. agent observes strip pixels black white. black pixel represents position ball moves around strip. ball current direction every time-step moves pixel direction. whenever reaches edge pixel current direction changes move away edge. figure complete pomdp model pixel version system pictured. pixels pomdp hidden states agent wishes predict whether ball position marked next time step. clearly prediction made paying attention immediate neighborhood details happens ball away matter making predictions. could apply abstraction lumps together observations neighborhood looks same. problem abstract generative model system makes predictions also pixels surrounding speciﬁcally model still makes predictions whether ball enter neighborhood near future. course depends long since ball left neighborhood. pomdp model abstract system exactly state diagram original system though observations changed reﬂect abstraction. abstract system primitive system linear dimension. order make predictions must condition information pixels surrounding consequently generative model also makes predictions pixels. counterintuitively abstract model’s complexity mainly devoted making predictions predictions interest. general learning abstract model drastically simplify learning problem ignoring irrelevant details abstract generative model still learns make predictions details relevant even directly interest. contribution paper prediction proﬁle models seek combine main strengths model-learning approaches discussed above. direct approximation prediction proﬁle model make predictions interest others. such simpler generative model typically make many extraneous predictions. however learning method prediction proﬁle models require history features given priori. leveraging existing generative model learning methods prediction proﬁle models learn maintain state information necessary making predictions interest. typical model learns make predictions future observations emitted system. main idea behind prediction proﬁle models instead model values predictions change time conditioned actions chosen agent observations emitted system. already seen example three card monte. prediction proﬁle model takes observations dealer’s behavior input outputs predictions tests interest. predict dealer’s behavior takes account updating predictions interest. recall that though three card monte system arbitrarily complicated prediction proﬁle system three states regardless dealer’s decision making process. another example shown figure prediction proﬁle system ball bounce system model must predict whether ball enter position next time-step. state prediction proﬁle model labeled prediction pixel transitions labeled observations -pixel neighborhood centered position case transitions capture ball entering neighborhood moving position leaving neighborhood staying away undetermined amount time returning again. recall pomdp model system hidden states number pixels even ignoring pixels irrelevant making predictions pixel contrast prediction proﬁle model always three states regardless number pixels. next section formally describe prediction proﬁle models models dynamical system results transformation original system. subsequent sections discuss learn prediction proﬁle models data present results help characterize conditions prediction proﬁle models best applied. formally describe theoretical dynamical system deﬁned terms dynamics original system given tests interest. call constructed system prediction proﬁle system. prediction proﬁle model goal construct model prediction proﬁle system such analysis problem learning prediction proﬁle model depend great deal understanding properties prediction proﬁle system. paper make restrictive assumption that markov case ﬁnite number distinct prediction proﬁles certainly true partially observable systems sets tests interest though true many interesting examples. formally assumption requires histories ﬁnite prediction proﬁles assumption allows deﬁnition prediction proﬁle system discrete dynamical system captures sequence prediction proﬁles time given action observation sequence. prediction proﬁle system’s actions observations dynamics deﬁned terms quantities associated original system dynamics dynamics prediction proﬁle system deterministically governed prediction proﬁle history oiρha ojiρj next -action haj+ oj+i prediction proﬁle system deterministically emits -observation present facts prediction proﬁle system. speciﬁcally noted prediction proﬁle system always deterministic. also though prediction proﬁle system markov general partially observable. proof. follows immediately deﬁnition every history corresponds exactly prediction proﬁle. -history action fully determine next -observation stochastic observations original system folded unmodeled actions prediction proﬁle system. proof. deﬁnition original system markov prediction proﬁle time step depends recent observation. time step current proﬁle agent takes action observes observation next proﬁle simply arkov. fact original system markov prediction proﬁle system satisﬁes even stronger condition next -observation fully determined -action dependence history whatsoever proof. consider three card monte example. original system clearly non-markov however prediction proﬁle system tests interest regarding location special card markov. next proﬁle fully determined current proﬁle -action. general however system partially observable. though three card monte example current prediction proﬁle next action-observation pair together fully determine next prediction proﬁle general next prediction proﬁle determined history action-observation pairs proof. recall ball bounce example. corresponding prediction proﬁle system shown figure note distinct states update graph associated prediction proﬁle given current prediction proﬁle -action cannot determine whether ball entering leaving neighborhood thus cannot uniquely determine next proﬁle. prediction proﬁle system partially observable. general prediction proﬁle system deterministic partially-observable dynamical system. model prediction proﬁle system used make predictions interest. such wishes prediction proﬁle model generative model must select tests interest carefully. instance special case prediction proﬁle model complete generative model system shown section desires generative model essentially never preferable learn prediction proﬁle model traditional representation. prediction proﬁle model best applied relatively simple make maintain predictions interest comparison making predictions. general prediction proﬁle model conditions observations necessarily predict next observation. such model prediction proﬁle system cannot typically used purposes model-based planning/control like generative model could. experiments section demonstrate output prediction proﬁle models however useful model-free control methods. deﬁnition prediction proﬁle system straightforwardly suggests method learning prediction proﬁle models section present learning algorithm discussing main practical challenges arise. training data trajectories experience original system tests interest. algorithm presented section learn model prediction proﬁle system data algorithm three main steps first training data used estimate prediction proﬁles next learned prediction proﬁles used translate training data trajectories experience prediction proﬁle system. finally applicable model learning method trained transformed data learn model prediction proﬁle system. ultimately experiments learned prediction proﬁle models evaluated useful predictions features control. given ﬁrst step learning prediction proﬁle model determine many distinct prediction proﬁles well values. estimated prediction test interest history could point directly estimate letting ˆpi. course sampling error unlikely estimated proﬁles exactly same even true underlying prediction proﬁles identical. compare proﬁles histories likelihood-ratio test homogeneity performed counts test interest histories. statistical test associated test interest rejects null hypothesis prediction histories histories diﬀerent prediction proﬁles. order distinct prediction proﬁles greedily cluster estimated prediction proﬁles. speciﬁcally initially empty exemplar histories maintained. algorithm searches histories agent’s experience comparing history’s estimated proﬁle exemplar histories’ estimated proﬁles. candidate history’s proﬁle signiﬁcantly diﬀerent proﬁles exemplar histories candidate added exemplar. estimated proﬁles corresponding exemplar histories used prediction proﬁles. order obtain best estimates possible search ordered prioritize histories lots associated data. prediction proﬁle estimation procedure main sources complexity. ﬁrst sample complexity estimating prediction proﬁles. take great deal exploration history enough times obtain good statistics especially number actions observations large. issue could addressed adding generalization estimation procedure data sample trajectory could improve estimates many similar histories. experiments section observation abstraction employed simple form generalization. second bottleneck computational complexity searching prediction proﬁles involves exhaustively enumerating histories agent’s experience. would valuable develop heuristics identify histories likely provide proﬁles order avoid searching histories. experiments section simple heuristic limiting search short histories employed. long histories tend less associated data therefore less likely provide distinguishably proﬁles. generated ﬁnite distinct prediction proﬁles next step translate agent’s experience sequences action-observation pairs prediction proﬁles. trajectories used train model prediction proﬁle system. process translating action-observation sequence prediction proﬁle trajectory straightforward apart practical concerns follows directly deﬁnition recall that action-observation sequence aoao akok corresponding -action sequence oiha oki. corresponding sequence proﬁles thus principle every primitive actionobservation sequence translated action-observation-proﬁle sequence. course available generate sequence prediction proﬁles. necessary approximation generated training data. speciﬁcally estimated predictions tests interest history compared using statistical tests distinct estimated prediction proﬁles section estimated proﬁle statistically signiﬁcantly diﬀerent estimated predictions given suﬃcient data statistical tests uniquely identify correct match high probability. practice however histories much associated data. possible case test homogeneity fail reject null hypothesis proﬁles. indicates enough data distinguish multiple possible matches. experiments section diﬀerent heuristic strategies handling situation employed. ﬁrst strategy lets matching proﬁle smallest empirical kl-divergence estimated predictions heuristic choice lead noise prediction proﬁle labeling could turn aﬀect accuracy learned model. second strategy simply trajectory point multiple matches occur rather risk assigning incorrect labeling. ensures labels appear prediction proﬁle trajectories reasonable level conﬁdence correctness. however wasteful throw training data way. translation step produces trajectories interaction prediction proﬁle system. recall prediction proﬁle system deterministic partially observable discrete dynamical system trajectories used train model prediction proﬁle system using principle applicable model-learning method. issue faced models prediction proﬁle system present usual discrete dynamical systems modeling setting. prediction proﬁle labels present training data actually using model available. current history action taken observation emitted. together action-observation pair constitutes -action. model prediction proﬁle system prediction proﬁle model identify next proﬁle proﬁle used compute predictions tests interest history hao. another action observation occur. necessary update pp-model’s state order obtain next prediction proﬁle. typical dynamical systems model makes predictions next observation able update state actual observation occurred. prediction proﬁle model’s observations prediction proﬁles themselves observable interacting world. such prediction proﬁle model update state prediction proﬁle predicted updated prediction proﬁle model obtain proﬁle follows gives predictions tests interest history haoao. prediction proﬁle model perfect model prediction proﬁle system poses problems. prediction proﬁle system deterministic need observe true prediction proﬁle label; fully determined history. practice course model imperfect diﬀerent modeling representations require diﬀerent considerations performing functions providing predictions tests interest providing proﬁle sake updating model. pomdp training using algorithm generally provide deterministic pomdp. thus given history learned pomdp model prediction proﬁle system provide distribution prediction proﬁles instead deterministically providing proﬁle associated history. implementation used section simply takes likely proﬁle distribution proﬁle associated history uses make predictions tests interest well update pomdp model. another natural choice representation prediction proﬁle model looping predictive suﬃx tree lpsts specialized deterministic partially observable systems. such could used model original system apply prediction proﬁle system brieﬂy lpst captures parts recent history relevant predicting next observation. every node tree corresponds action-observation pair. node leaf children loop ancestors. every leaf tree corresponds history suﬃx deterministic prediction observation every action. order predict next observation particular history reads history reverse order following corresponding links tree leaf reached gives prediction. holmes isbell provide learning algorithm that certain conditions training data guaranteed produce optimal tree. reader referred work holmes isbell details. weakness lpsts however fail make prediction next observation current history lead leaf node tree typically occurs history suﬃxes occur training data occur using model. pp-lpst mean histories model cannot uniquely determine corresponding prediction proﬁle. happens implementation used section simply ﬁnds longest suﬃx current history occur data. suﬃx associated multiple prediction proﬁles make predictions tests interest model provides average prediction proﬁles. proﬁle used update model picked uniformly randomly. applying learning algorithms prediction proﬁle data poses practical concern. speciﬁcally methods attempt estimate system dynamics matrix implicitly presume every action sequence could principle taken every history. action sequences taken histories others matrix undeﬁned entries. poses challenges rank estimation unfortunately case prediction proﬁle system since -actions completely agent’s control; partly selected environment itself. recent spectral learning algorithms presented boots able side-step issue ﬂexibility selecting predictions estimated model-learning process though investigated possibility work. note that though method learning prediction proﬁle model involves standard model-learning methods partially observable environments result generative model original system. prediction proﬁle model generative model prediction proﬁle system such cannot used make predictions original system predictions interest. learning algorithm presented evaluated empirically section first however analyze complexity prediction proﬁle system relation complexity original system. give indication diﬃcult learn prediction proﬁle model provide insight appropriate learn prediction proﬁle model typical generative model approach. many factors aﬀect complexity learning model. section largely focus linear dimension measure complexity taking view that generally speaking systems lower linear dimension easier learn systems larger linear dimension. discussed section generally true pomdps linear dimension lower-bounds number hidden states. comparing linear dimension prediction proﬁle system original system give idea whether would easier learn pp-pomdp learn standard pomdp original system. course model-learning methods complexity measures would appropriate extending results measures complexity interesting topic future investigation. section discuss linear dimension prediction proﬁle system relates original system. ﬁrst result proof concept simply states exist problems prediction proﬁle system vastly simple original system. fact problem already presented. proof. recall three card monte example. thus domain described without describing dealer’s behavior. however note prediction proﬁle system tests interest relating location special card linear dimension regardless dealer’s swaps chosen. complex dealer chosen original system high linear dimension prediction proﬁle system’s linear dimension remain constant. instance experiments section dealer chooses cards swap stochastically likely choose swap selected least often far. thus order predict dealer’s next decision must count many times swap chosen history result system eﬀectively inﬁnite linear dimension. hand prediction proﬁle models panacea. following results indicate problems learning prediction proﬁle model would advisable learning standard generative model linear dimension prediction proﬁle system greater original system. later section special cases characterized prediction proﬁle models likely useful. next result shows linear dimension prediction proﬁle model inﬁnite original system ﬁnite linear dimension lower bound linear dimension true deterministic dynamical systems. proposition applies deterministic dynamical systems certainly applies prediction proﬁle system. though loose bound basic implication number prediction proﬁles increases comparison number action-observation pairs linear dimension prediction proﬁle system necessarily increases. bound also clearly illustrates importance assumption ﬁnite number distinct prediction proﬁles. proof. clearly ﬁnite long ﬁnitely many actions observations. last result follows immediately number distinct prediction proﬁles approaches inﬁnity must linear dimension prediction proﬁle system. hence long prediction proﬁle models represented using methods rely ﬁnite linear dimension critical ﬁnitely many prediction proﬁles. note fundamental barrier side eﬀect representational choice. model learning methods sensitive linear dimension able eﬀectively capture systems inﬁnitely many prediction proﬁles. conclusion drawn last results knowing linear dimension original system itself necessarily much complexity prediction proﬁle system. prediction proﬁle system simpler complex original system. thus informative turn factors trying characterize complexity prediction proﬁle system. results previous section take account obviously important aspect prediction proﬁle system predictions asked make. predictions interest made simply keeping track little information. predictions rely great deal history information therefore require complex model. next result identiﬁes worst case tests interest system tests interest whose corresponding prediction proﬁle model highest linear dimension. ultimately section present conditions prediction proﬁle system likely simpler original system. proposition given system tests interest linear dimension corresponding prediction proﬁle system greater prediction proﬁle system associated core tests system corollary system tests interest corresponding prediction proﬁle system linear dimension greater number distinct predictive states original system. proof. prediction proﬁle system core tests deterministic observations prediction proﬁles state associated unique prediction proﬁle. linear dimension never greater number observations therefore previous result prediction proﬁle system tests interest linear dimension greater number predictive states. bounds presented help explain prediction proﬁle system complex original system. however focused worst possible choice tests interest little illuminate opposite true. prediction proﬁle model complex asked perform task generative model keep track much information history necessary make possible predictions results indicate that generally speaking desires generative model standard approaches would preferable learning prediction proﬁle model. hand stated goal learn generative model instead focus particular predictions hopefully simpler make predictions. examples seen make clear cases predictions made prediction proﬁle model simpler generative model original system. general might expect prediction proﬁle model simple predictions interest rely small amount state information required maintain generative model. next bound aligns intuitive reasoning. essentially result points often much hidden state information pomdp irrelevant predictions interest. linear dimension prediction proﬁle system bounded number distinct beliefs relevant parts hidden state rather number distinct beliefs states overall. idea result impose abstraction hidden states pomdp still allows predictions interest made accurately allows abstract belief states computed accurately prediction proﬁle system’s linear dimension bounded number abstract belief states. proposition consider pomdp hidden states actions observations tests interest. action taken time-step hidden state reached taking action observation emitted consider surjection mapping hidden states abstract states following properties things note result. first surjection always exists properties always deﬁne degenerate case trivially satisﬁes requirements proposition recovers bound given corollary however proposition applies surjections satisfy conditions. must surjection satisﬁes conditions results smallest number beliefs abstract states. essentially ignores much state information possible still allowing predictions interest made accurately surjection tightly bounds complexity prediction proﬁle system course still large even inﬁnite number distinct beliefs even abstract states factors must come play ensure simple prediction proﬁle system. furthermore result characterize settings prediction proﬁle system simple. said result support intuition order build intuition result relates earlier examples recall three card monte problem. three card monte sources hidden state ace’s unobserved position whatever hidden mechanism dealer uses make decisions. clearly agent’s predictions interest depend ﬁrst part hidden state. case satisfy property surjection maps hidden states abstract state position regardless dealer’s state. abstract states even though might inﬁnitely many true hidden states. diﬀerent states corresponding position diﬀerent distributions ace’s next position; distribution does depend upon dealer’s state. however property statement distribution next abstract state given observation emitted entering abstract state. knows current abstract state observes dealer does next abstract state fully determined. property holds well. fact since ace’s position known beginning game means current abstract state always known absolute certainty even though beliefs dealer’s state general uncertain. hence distinct beliefs abstract states such prediction proﬁle model’s linear dimension upper-bounded regardless dealer’s complexity previous section describes conditions prediction proﬁle system lower linear dimension original system. also concern number prediction proﬁles whether number ﬁnite. section brieﬂy discuss cases number prediction proﬁles bounded. case already discussed original system markov. case number prediction proﬁles bounded number observations course original system markov little need prediction proﬁle models. another similar case system partially observable completely deterministic system deterministic pomdp given history current hidden state known. such number belief states bounded number hidden states. since cannot prediction proﬁles belief states number prediction proﬁles bounded well. move away determinism diﬀerent ways. first note property deterministic pomdp hidden state fully determined history. possible satisfy property even stochastic systems long uniquely determine hidden state given observation emitted arriving there. case observations emitted stochastically number belief states still bounded number hidden states. observation function deterministic initial state distribution stochastic. det-pomdp deterministic dynamical system uncertainty hidden state. uncertainty system appears emit observations stochastically. underlying dynamics deterministic. littman showed det-pomdp hidden states initial state distribution states support distinct belief states. bounds number prediction proﬁles well. finally importantly hidden state abstracted proposition properties really need hold abstract beliefs. environment complex stochastic arbitrary ways abstract hidden state described proposition fully determined history number prediction proﬁles bounded number abstract states similarly det-pomdp-like properties imagined abstract hidden states well. cases means cover situations number prediction proﬁles bounded seem indicate class problems number prediction proﬁles ﬁnite quite broad contain many interesting examples. section empirically evaluate prediction proﬁle model learning procedure developed section experiment agent faces environment generative model would challenge learn high linear dimension. however problem agent could make good decisions could predictions small number important tests. prediction proﬁle model learned important tests accuracy learned predictions evaluated. experiments also demonstrate possible prediction proﬁle models control. generative prediction proﬁle models cannot typically used directly oﬄine model-based planning methods. however output useful model-free methods control. speciﬁcally experiments predictions made learned prediction proﬁle models provided features policy gradient algorithm. policy gradient methods successful viable options model-free control partially observable domains. though diﬀerences various algorithms common thread assume parametric form agent’s policy attempt alter parameters direction gradient respect expected average reward. experiments make online gpomdp average reward baseline olgarb olgarb assumes features history agent’s policy takes parametric form typically features used policy gradient features directly read history diﬃcult know priori historical features important making good control decisions. contrast idea experiments provide values predictions features. predictive features direct consequences control provide information eﬀects possible behaviors agent might engage such easier select predictive features likely informative optimal action take furthermore information expressed compactly terms prediction would complex specify purely terms past observations. seen discussion psrs section arbitrary-length history fully captured ﬁnite short-term predictions. reasons seems reasonable speculate predictive features maintained prediction proﬁle model particularly valuable model-free control methods like policy gradient. learning algorithm applied example problems. problem prediction proﬁle models learned various amounts training data prediction accuracy models evaluated well useful predictions features control. training data generated executing uniform random policy environment. free parameter learning algorithm signiﬁcance value statistical tests given large number contingency tests performed data compound probability false negative fairly low. experiments though several reasonable values tried similar results. discussed section also maximum length histories consider search prediction proﬁles. cutoﬀ allows search avoid considering long histories many long histories search unlikely provide prediction proﬁles. prediction proﬁle model learned predictions evaluated features policy gradient algorithm olgarb. speciﬁcally test interest unit interval split equally-sized bins binary feature provided prediction lies otherwise. also provided binary features possible observation feature recent observation otherwise. parameters olgarb learning rate discount factor respectively experiments. evaluate prediction proﬁle model olgarb steps. average reward obtained root mean squared error predictions tests interest accrued model along reported. prediction performance compared obtained learning pomdp training data using make predictions interest. problems complex feasibly train pomdp correct number underlying states -state pomdps used control performance compared obtained olgarb using predictions provided learned pomdp model features well olgarb using true predictions features olgarb using second-order markov features predictive features hand-coded expert policy. ﬁrst domain three card monte example. agent presented three cards. initially card middle ace. agent four actions available watch lip. agent chooses action observes whether card ﬂipped special card. agent chooses watch action dealer swap positions cards case agent observes cards swapped dealer guess. dealer asked guess watch results reward action results reward. dealer asks guess agent ﬂips special card agent gets reward agent ﬂips cards doesn’t card gets reward agent three tests interest take form lipx card discussed previously complexity system directly related complexity dealer’s decision-making process. experiment agent chooses watch dealer swaps pair cards swapped least probability probability chooses uniformly amongst pairs cards; otherwise asks guess. since dealer keeping count many times swap made process governing dynamics eﬀectively inﬁnite linear dimension. training trajectories length figure shows results various amounts training data averaged trials. pp-pomdps pp-lpsts learned make accurate predictions tests interest eventually achieving zero prediction error. case pp-pomdps using less data. likely pomdp model readily able take advantage fact prediction proﬁle system three card monte markov. expected standard pomdp model unable accurately predict tests interest. also compared diﬀerent strategies dealing multiple matches discussed section recall ﬁrst picks matching proﬁle smallest empirical kl-divergence estimated predictions. second simply cuts trajectory point multiple match avoid incorrect labels. problem strategies result almost exactly performance. likely proﬁles three card monte deterministic therefore quite easy distinguish next experiment stochastic proﬁles. predictive features provided prediction proﬁle models clearly useful control control performance olgarb using predictions approaches eventually exactly matches olgarb using true predictions inaccurate predictions provided pomdp useful control; olgarb using pomdp provided predictions even break even meaning loses game often wins. pomdp features however seem contain useful information beyond provided second-order markov features which might expect performed poorly. second example called shooting gallery pictured figure agent aimed ﬁxed position grid target moves diagonally bouncing boundaries image obstacles agent’s task shoot target. agent actions watch shoot. agent chooses watch gets reward. agent chooses shoot target crosshairs step agent shoots agent gets reward otherwise gets reward whenever agent hits target shooting range resets agent receives special reset observation square range made obstacle probability target placed random position. also probability range reset every time step. diﬃculty target sticky. every time step probability moves current direction probability sticks place. thus looking recent history agent able determine target’s current direction. agent needs know probability target sights next step clearly single test interest watch target target crosshairs prediction test target crosshairs target figure shooting gallery domain. possible arrangement obstacles trajectory target case target deﬁnitely enter agent’s crosshairs since bounce obstacle. abstraction applied recent observation. problem stochastic prediction proﬁles expected data required diﬀerentiate them. also number possible conﬁgurations obstacles positions target system roughly observations even latent states. results large number possible histories small probability occurring. discussed section lead large sample complexity obtaining good estimates prediction proﬁles. addressed simple form generalization observation abstraction. observations treated target position conﬁguration obstacles immediate vicinity target same. words abstract observation contains information target’s position obstacles surrounding target placement obstacles away target example. abstraction abstract observations still provide enough detail make accurate predictions. histories indeed prediction proﬁle action sequence observation sequences correspond sequence aggregate observations. enables sample trajectory improve estimates several histories though even abstraction still action-observation pairs. observation abstraction applied training pomdp model. training trajectories length search proﬁles restricted length histories. results shown figure perhaps eye-catching feature results upward trending curve prediction error graph corresponding pp-pomdp kl-divergence based matching recall danger kl-divergence based matching strategy produce incorrect labels training data. apparently errors severe enough problem drastically mislead pomdp model. small amount data obtained good prediction error data came misleading labelings performance suﬀered. pp-pomdp trained matching method displays typical learning curve though takes great deal data begins make reasonable predictions. cutting trajectories multiple matches throws away data might informative model. pp-lpsts generally outperform pp-pomdps problem. trajectory cutting method pp-lpst quickly outperforms pomdp enough data outperforms versions pp-pomdp. pp-lpst kl-divergence based matching best performer quickly achieving small prediction error. clearly incorrect labels training data dramatic eﬀect lpst learning possibly because suﬃx tree lpst mostly makes predictions based recent history limiting eﬀects labeling errors time-steps. control performance essentially mirrors prediction performance interesting exceptions. note even though pp-pomdp obtains roughly prediction error pomdp training trajectories predictive features provides still result substantially better control performance. indicates that even though pp-pomdp making errors exact values predictions still captured important dynamics predictions pomdp has. pomdp provides features roughly useful second-order markov features result good performance. again olgarb using features break even meaning wasting bullets target likely enter crosshairs. best-performing prediction proﬁle model pp-lpst approaches performance olgarb using true predictions suﬃcient data. gaussian models continuous partially observable environments dimensions observation treated unmodeled exogenous input. inputs assumed linear eﬀect state transition. along somewhat similar lines context model minimization wolfe constructed abstract model shadow model predicts observation details ignored abstraction. shadow model takes abstract observations abstract model unmodeled input. splitting observation modeled un-modeled components learning generative model certainly related approach. case model would make conditional predictions modeled portion observation given exogenous inputs prediction proﬁle models take extreme treating entire observation input. instead predicting future sequences piece next observation conditioned another piece prediction proﬁle models predict values arbitrary predictions interest next time step given entire action observation. allows signiﬁcantly freedom choosing predictions model make modeling method closely related prediction proﬁles causal state splitting reconstruction cssr algorithm learning generative models discrete partially observable uncontrolled dynamical systems. basic idea deﬁne equivalence relation histories histories considered equivalent associated identical distributions possible futures. equivalence classes relation called causal states. cssr algorithm learns number causal states distribution next observations associated causal state transitions causal state next given observation. straightforward one-to-one correspondance causal states predictive states psr. such causal state model precisely prediction proﬁle model tests interest core tests. correspondance hand results section show many cases number causal states greatly exceed linear dimension original system therefore cssr inadvisable many problems comparison standard modeling approaches. possible cssr algorithm could adapted general setting arbitrary sets tests interest however algorithm rely heavily fact prediction proﬁle model tests interest markov generally case sets tests interest. mentioned section mccallum presented utree suﬃx-tree-based algorithm learning value functions partially observable environments. utree learns value function make predictions observations utree learn non-generative partial model. wolfe barto extend utree make one-step predictions particular observation features rather limiting predictions value function. learns suﬃx tree utree able operate non-episodic domains required explicitly search distinct prediction proﬁles. utree also directly incorporates abstraction learning learning simultaneously observation features important history suﬃx attend them. said main drawback suﬃx tree approach tree takes account information relatively recent history cannot remember important information arbitrary number steps recurrent state-based model can. three card monte example instance access depth-limited suﬃx history would little help. order track must take account every move dealer made since beginning game. utree would essentially forget card game’s length surpassed depth memory. mccallum mahmud provide methods learning state machines predict immediate reward resulting given action-observation pair partially observable control tasks thus learning problem special case ours restrict models make one-step predictions immediate reward. cases simple model incrementally greedily elaborated proposing states split evaluating results mccallum expressed concern approach diﬃculty extracting long-range dependencies clear extent mahmud’s approach addresses issue. methods advantages utree notably applied non-episodic domains. said approach advantages well. re-casting problem learning non-generative model standard generative model-learning problem able gain deeper understanding complexity applicability prediction proﬁle models compared standard generative models. furthermore allowed incorporate standard well-studied generative model-learning methods learning algorithm thereby leveraging strengths non-generative setting. speciﬁcally resulting principled learning algorithm rely guess-and-check stochastic local search. prediction proﬁle system also similar spirit ﬁnite state controllers pomdps. sondik noted cases possible represent optimal policy pomdp ﬁnite state machine. ﬁnite state controllers much like prediction proﬁle models take action-observation pairs inputs instead outputting predictions associated current history output optimal action take. multiple authors provide techniques learning ﬁnite state controllers. however algorithms typically require access complete pomdp model world begin which setting assumed impractical. standard methods learning models partially observable environments learn generative models. small predictions interest make ignore irrelevant detail abstraction simplify learning problem. even generative model necessarily make predictions relevant details even directly interest. seen example resulting model counter-intuitively complex even predictions model asked make quite simple. presented prediction proﬁle models non-generative models partially observable systems make predictions interest others. main idea prediction proﬁle models learn model dynamics predictions change time rather model dynamics system. learning method prediction proﬁle models learns transformation training data applies standard methods transformed data result retains advantages methods like pomdps learn information history must maintained order make predictions showed prediction proﬁle model simpler generative model though also complex depending predictions asked make. however predictions interest depend relatively little state information prediction proﬁle models provide substantial savings standard modeling methods pomdps. experiments section demonstrate possible learn prediction proﬁle models contrived systems complex pomdps speciﬁc learning algorithm presented likely scale natural domains without modiﬁcation. critical scaling issues prediction proﬁle models sample complexity estimating prediction proﬁles computational complexity searching prediction proﬁles translating data. cases critical source complexity essentially many distinct histories training data such generalization prediction estimates across many histories would step toward applying ideas realistic domains. currently developing learning algorithms combine ideas behind prediction proﬁle models methods learning abstractions allow many essentially equivalent histories lumped together purposes estimating predictions interest. another limitation prediction proﬁle model learning method presented reliance assumption ﬁnite number prediction proﬁles. assumption hold many cases ideal method would able deal gracefully large inﬁnite number prediction proﬁles. possibility simply cluster predictions ways. instance desire certain level prediction accuracy therefore willing lump distinct prediction proﬁles together exchange simpler prediction proﬁle system. another idea would learn prediction proﬁle model using continuous-valued representations kalman ﬁlters plgs representations learning algorithms explicitly deal systems inﬁnite number observations even ﬁnitely many prediction proﬁles methods learning non-linear continuous models still able capture discrete dynamics. additionally though results focused discrete systems main motivation behind prediction proﬁle models also purchase continuous setting. typical methods learning models partially observable systems continuous systems much like discrete valued counterparts learn generative models. such non-generative approach prediction proﬁle models provide similar beneﬁts continuous setting predictions need made. setting prediction proﬁles might represented parametric form main idea prediction proﬁle models could still applied learn model dynamics distribution parameters rather dynamics system itself. finally discussed work tests interest determined predict selected. automatically selecting interesting/important predictive features targets partial models would certainly interesting research challenge. course would depend predictions used for. predictions used features control done experiments would certainly seem intuitive start predictive features regarding reward signal perhaps observation features strongly correlate reward also useful consider making predictions predictions style networks instance could imagine learning models make predictions proﬁle another model emit. models could chained together make predictions extant rewards rather focusing solely predicting immediate reward signal another common partial models decompose large modeling problem many small ones instance factored mdps factored psrs collections local models setting choosing tests interest would example structure learning problem decomposing one-step predictions relatively independent components assigning diﬀerent models. erik talvitie supported grfp. satinder singh supported grant iis-. opinions ﬁndings conclusions recommendations expressed material authors necessarily reﬂect views nsf. result follow straightforwardly general fact dynamical systems. sequence actions observations starting time-step sequence ending time-step sequence. convenience’s sake null sequence. following results show test ever positive probability must positive probability history length less linear dimension system. proof. note p...k]t pp...k] assume ph)p seek contradiction. consider submatrix system dynamics matrix. rows submatrix correspond preﬁxes columns correspond suﬃxes pre-pended test matrix. assumption matrix triangular positive entries along diagonal such matrix full rank contradiction since submatrix never higher rank matrix contains consequence corollary every test ever positive probability must positive probability following history length less fact hand proposition proven. proof. since system deterministic history action correspond exactly resulting observation. history sequence actions observations. however since sequence observations fully determined sequence actions deterministic system number distinct histories length simply |a|k. history action choices could result diﬀerent observation. number observations could possibly occur histories length simply |a|k+. corollary linear dimension observations must occur history length thus number observations possibly follow histories length less proposition given system tests interest linear dimension corresponding prediction proﬁle system greater prediction proﬁle system associated core tests system proof. recall discussion psrs section core tests tests whose corresponding columns system dynamics matrix constitute basis. predictions core tests given history form predictive state history. predictive state precisely prediction proﬁle core tests prediction test computed linear function prediction proﬁle note prediction proﬁle system mdp. shown section compute next predictive state given current predictive state action-observation pair. consider tests interest predictions used compute prediction test must function maps prediction proﬁles prediction proﬁles general multiple predictive states prediction proﬁle surjection. easy prediction proﬁle system result applying observation abstraction prediction proﬁle system performing observation abstraction generally produces pomdp never increases linear dimension hence prediction proﬁle system tests interest linear dimension greater prediction proﬁle system core tests proposition consider pomdp hidden states actions observations tests interest. action taken time-step hidden state reached taking action observation emitted proof. proof follows similar reasoning proof proposition note that property belief abstract states given history suﬃcient compute prediction proﬁle. history test interest consider dynamical system beliefs abstract states observations action-observation pairs actions. call abstract belief system. predictive state possible compute prediction proﬁle abstract beliefs prediction proﬁle model seen result observation aggregation abstract belief system. result prediction proﬁle system linear dimension greater abstract belief system. given probability distribution abstract states given history agent takes action observes observation possible compute probability abstract state history compute next abstract beliefs previous abstract beliefs abstract belief system therefore linear dimension greater number observations compute prediction proﬁle abstract beliefs prediction proﬁle system constructed applying observation abstraction abstract belief system. thus prediction proﬁle system linear dimension greater number distinct abstract beliefs.", "year": 2014}