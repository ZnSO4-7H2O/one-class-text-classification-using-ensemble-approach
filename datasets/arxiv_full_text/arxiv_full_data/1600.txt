{"title": "Towards Learning Object Affordance Priors from Technical Texts", "tag": ["cs.LG", "cs.AI", "cs.CL", "cs.RO", "68T05"], "abstract": "Everyday activities performed by artificial assistants can potentially be executed naively and dangerously given their lack of common sense knowledge. This paper presents conceptual work towards obtaining prior knowledge on the usual modality (passive or active) of any given entity, and their affordance estimates, by extracting high-confidence ability modality semantic relations (X can Y relationship) from non-figurative texts, by analyzing co-occurrence of grammatical instances of subjects and verbs, and verbs and objects. The discussion includes an outline of the concept, potential and limitations, and possible feature and learning framework adoption.", "text": "abstract— everyday activities performed artiﬁcial assistants potentially executed na¨ıvely dangerously given lack common sense knowledge. paper presents conceptual work towards obtaining prior knowledge usual modality given entity affordance estimates extracting high-conﬁdence ability modality semantic relations nonﬁgurative texts analyzing co-occurrence grammatical instances subjects verbs verbs objects. discussion includes outline concept potential limitations possible feature learning framework adoption. domain autonomous robot control artiﬁcial assistants require know actions executed given objects. information deﬁned object affordances usually obtained online reinforcement active learning execution actions processing percepts however safe human-robot interaction require robot have initialization understanding actions object execute actions object subject scope claim human-written technical texts informative source construct initial world estimate. probability distribution action-object relationships natural language text performed thanks co-occurrence understanding verb-noun pairs analysis known computational linguistic literature distributional information text characterize lexical semantics considering statistical co-occurrence neighboring words however majority current approaches make shallow syntactic features meaningfulness debatable semantic characterization therefore make grammatical features partial semantic characterization object affordances. semantic relationships employed engineering easily prone conﬁdent automatic extraction knowledge engineers recur manual ontology insertion author’s claim potentiality relationships robustly extracted grammar relationships subject-verb-object cooccurrences. choice ability modality relationship calls assumption training corpus derive data reliable non-ﬁgurative subject-verb-object co-occurrence tuples. formally cooccurrence every noun verb entails ability perform action cooccurring object simpler terms assume instance robot builds desk implies robot build therefore model symbolic knowledge potentiality joint probability distribution occurrences training source obtained learning typed dependency analysis output features source derive dual joint probability distributions encapsulate knowledge active passive noun roles induce distinct vector spaces representing passive active role information order learn distribution possible approach exploit markov logic networks previously extracted stanford typed dependencies latter labeled directed grammar relationship among pairs words capture word order relationship type considering ’nsubj’ ’dobj’ labels seen grounded action-object predicates. perception array. vector space induction enables high-dimensional tensor computations semantic characterization adopted linguistics unknown extent effectiveness within context. accuracy learnt ontology entries reﬁned reinforcement learning course task executions veriﬁed thanks active learning process. precisely entries encapsulated questions process called language generation order correctness limitations although assume text conﬁned technical domain authors source might make partly ﬁgurative wordings. result word frequency distribution would present bias outliers furthermore also independent word frequency occurrence provide information regarding entity existence would require form normalization. conclusions linguistic computational obstacles towards model effectiveness manifold surely require development processes bias removal outlier detection. however concept paper highlights usage technical text mining affordance acquisition mainly points potential induced vector spaces retrieving objects similar affordance affordance aggregates practical initial world affordance estimate. hidayat ohba learning affordance semantic robots using ontology approach intelligent robots systems iros ieee/rsj international conference ieee beltagy chau boleda garrette mooney montague meets markov deep semantics probabilistic logical form joint conference lexical computational semantics proceeding main conference shared task atlanta perform learning grounded models thanks knowledge representation formalism enables probabilistic learning inference combined ﬁrst order logic probabilistic undirected graphical models formally theory deﬁnes probability world log-linear model exponentiated weights binary feature partition function case consider binary formula evaluation logic formula representing grammar relations predicates substitute term latter number true groundings formula formalism aims learn stationary distribution true groundings possibly sufﬁcient heuristic condition scalability. related work systems focus initialization parameters ontologies debate source populated previous literature value mappings language constructs affordances analyze opposite problem closer work adopts grammar features proven successful mining natural language instructions robotics domain focus affordance understanding concentrates inferring likely action roles literature make employ grammar feature analysis closer work consider typed dependency extraction semantic characterization focus tuple analysis evaluation system process high number noun-action relationships require equally well populated ontology representing ground truth references. activity passivity labels scope might require manual annotation. potential fulﬁlling requirement providing initial affordance world estimate provide understanding hidden partially observable affordances particularly useful objects full reach boella caro robaldo semantic relation extraction legislative text using generalized syntactic dependencies support vector machines theory practice applications rules", "year": 2014}