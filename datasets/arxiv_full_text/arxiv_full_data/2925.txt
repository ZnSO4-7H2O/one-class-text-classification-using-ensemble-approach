{"title": "DeepFaceLIFT: Interpretable Personalized Models for Automatic Estimation  of Self-Reported Pain", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Previous research on automatic pain estimation from facial expressions has focused primarily on \"one-size-fits-all\" metrics (such as PSPI). In this work, we focus on directly estimating each individual's self-reported visual-analog scale (VAS) pain metric, as this is considered the gold standard for pain measurement. The VAS pain score is highly subjective and context-dependent, and its range can vary significantly among different persons. To tackle these issues, we propose a novel two-stage personalized model, named DeepFaceLIFT, for automatic estimation of VAS. This model is based on (1) Neural Network and (2) Gaussian process regression models, and is used to personalize the estimation of self-reported pain via a set of hand-crafted personal features and multi-task learning. We show on the benchmark dataset for pain analysis (The UNBC-McMaster Shoulder Pain Expression Archive) that the proposed personalized model largely outperforms the traditional, unpersonalized models: the intra-class correlation improves from a baseline performance of 19\\% to a personalized performance of 35\\% while also providing confidence in the model\\textquotesingle s estimates -- in contrast to existing models for the target task. Additionally, DeepFaceLIFT automatically discovers the pain-relevant facial regions for each person, allowing for an easy interpretation of the pain-related facial cues.", "text": "previous research automatic pain estimation facial expressions focused primarily one-size-ﬁts-all metrics work focus directly estimating individual’s self-reported visual-analog scale pain metric considered gold standard pain measurement. pain score highly subjective context-dependent range vary signiﬁcantly among different persons. tackle issues propose novel two-stage personalized model named deepfacelift automatic estimation vas. model based neural network gaussian process regression models used personalize estimation self-reported pain hand-crafted personal features multi-task learning. show benchmark dataset pain analysis proposed personalized model largely outperforms traditional unpersonalized models intra-class correlation improves baseline performance personalized performance also providing conﬁdence model's estimates contrast existing models target task. additionally deepfacelift automatically discovers pain-relevant facial regions person allowing easy interpretation pain-related facial cues. research automatic estimation pain levels facial expressions focused primarily estimating objective metrics rather self-reports. objective metrics prkachin solomon pain intensity facial action intensities quantify facial expressions score pain. using metrics individuals make facial expression given similar pain scores. however pain fundamentally subjective experience individuals express pain differently depending qualitative factors motor ability gender objective metrics sufﬁciently capture individual’s true pain. furthermore many studies found correlations facial expressions self-reported pain levels observations pose question well automatic estimates objective metrics capture individual’s actual experience. self-reported pain scores often considered gold standard provide information individual’s subjective experience therefore approach automatically estimates self-reported pain scores rather objective pain metrics useful individuals experiencing pain. figure graphical representation proposed deepfacelift two-stage learning model using facial landmarks extracted frame image sequence estimate sequence-level outputs frame-level estimates concatenated form used compute various statistics form vector statistics vector passed gaussian process regression model estimate sequence-level vas. individuals make different facial expressions depending personal factors method automatic pain estimation would likely improve accounting facial expressions speciﬁc facial actions vary also personalizing individual’s qualitative characteristics explicitly representing features. features could incorporated model. feature-level personalization differs model-level personalization single model consistently applied subjects. using another important aspect personalized applications ensuring model outputs traced back speciﬁc components input features crucial explaining speciﬁc characteristic behavioral differences individuals. problem broadly faced deep learning research lack interpretability learned representations respect original input features example methods shown personalizing models improve outputs however model outputs learned internal representations cannot easily intuitively linked speciﬁc portions original inputs. result improved performance achieved personalization indicates qualitative differences indeed exist training subjects exactly differences affect ﬁnal output clear. therefore ability examine speciﬁc aspects input features contribute ﬁnal outputs would provide insight differences exist among subjects differences inﬂuence model estimations. address challenges subjectivity personalization interpretability propose two-stage hierarchical learning algorithm called deepfacelift estimates pain scores obtained using self-reported visualanalog scale ﬁrst stage model comprises fully-connected neural network takes active appearance model facial landmark coordinates input features. second stage processes outputs passes features gaussian process regression model. addition producing accurate estimates model also provides interpretable learning framework. accomplished ﬁrst stage leveraging existing model called deeplift examine inputs second stage utilizing radial basis function kernel automatic relevance determination examine learned kernel weights. show unbc-mcmaster shoulder pain expression archive database proposed personalized approach automatic estimation outperforms traditional approaches. model outline shown fig.. although much research exists automated recognition affect human facial expressions calvo d’mello recently handful works focused automated pain estimation. advances computer vision recent release unbc-mcmaster dataset pain analysis face images seen signiﬁcant advances. dataset provides videos frame rated using pspi score. although still commonly accepted pain score clinical settings existing automatic methods pain estimation pain images focused estimating pspi scores. outline recently published works. face shape features used classify images faces showing typical mood versus pain expressions. monwar rezaei lucey ashraf used aam-based features combined support vector machine classiﬁers classify pain versus no-pain images. rather treating pain binary classiﬁcation task hammal cohn attempted estimate pain intensity -level scale using one-versus-all classiﬁers kaltwang performed estimation full level pspi scale using relevance vector regression models. likewise rudovic proposed conditional random field model heteroscedastic variance showing changing model variance provides better individual pain sequences. recently several works using deep learning proposed pspi estimation works attempted estimate pain intensity entire sequences. ruiz proposed hidden conditional random field semi-supervised learning method identify peak pain image sequences. sikka proposed multi-instance learning method identify expressive segments within image sequences. however sequence-level labels derived using heuristics relate established pain ratings vas. recently martinez proposed personalized model estimation based combination long-short term memory networks hcrfs parameters latter modulated person’s ’expressiveness score’ heuristic derived previous rating person. method showed promising results improving estimation performance compared traditional un-personalized models generalize previously unseen subjects certain number ratings collected. contrast approach proposed designed circumvent limitation generalizing persons without explicit need data prior applying model. aside unbc-mcmaster dataset pain recognition studies based datasets wilkie pain detection attempted using physiological signals brain hemodynamic responses using nirs nevertheless works neither attempted automatic estimation personalized manner. used unbc-mcmaster shoulder pain expression archive database publicly available dataset containing facial videos subjects suffer one-sided shoulder pain undergo various range-of-motion exercises. dataset contains image sequences gathered subjects totaling image frames. frame pspi score obtained -point ordinal scale using facial action unit intensities. pspi rating computed speciﬁc intensities image sequence dataset also includes observed pain index scores rated experienced pain-observers likert-like scale dataset also includes image sequence self-reported rating deﬁned ordinal scale. estimating subjects’ scores pspi training testing. however scores certain settings. although unbc-pain dataset contains large amount image frames estimating scores poses challenge comparatively limited number sequence-level labels additionally obtain three manually-labeled features personalize method. features derived subject’s appearance complexion gender. complexion divided three bins using fitzpatrick-like skin-tone scale pale-fair fair-olive olivedark also divided three bins young middle-aged elderly. finally gender divided bins male female. bins independently assigned agreed upon primary authors. personal features selected based straightforward labeling well relevance individuals express pain. example individuals different gender shown express pain differently. complexion used easily observed thought loosely contain information individuals medical information background and/or daily habits. input features facial landmarks instead images. primarily reasons. ﬁrst reduce feature space feature coordinates). second main reason ensure feature representations easily distinguished intuitive. furthermore allows apply deeplift interpret individual facial landmarks vary across persons contribute output scores. notation. estimation formulated regression problem given image sequences person number target persons. sequences person annotated terms individual per-sequence scores scores have additionally denote frame number denote sequence number. sequence represented input features xls} duration number frames given sequence leverage frame-level data making sequence-level estimations ﬁrst stage deepfacelift applies multi-instance multi-task learning train fully-connected network uses frame-level facial landmark features input feature labeled score corresponding sequence. applying appropriate setting facial landmarks related highly nonlinear manners relations learned automatically using nns. deepfacelift uses -layer relu activation functions ﬁrst stage training generate frame-level scores. hidden layer ﬁrst stage deepfacelift generates frame-level scores separate settings compare different personalization strategies. setting differs personal information used model table shows settings ﬁrst column labeled within settings another separate labeling schemes used train multi-task learning manner table shows settings second column labeled thus frame total number frames dataset estimates either various methods reported capture temporal information sequence image frames recurrent neural networks crfs instead using temporal model second stage personalized modeling consider problem static extracting sequence-level statistics outputs ﬁrst stage passing statistics regression model second stage. enables model capture encode frame-level sequence-level dependencies. speciﬁcally using frame-level estimations deepfacelift computes sequence-level statistics inputs model obtain ﬁnal estimate. model tested different settings. ﬁrst setting input statistics calculated using frame-level estimates. second setting frame-level estimates used. table shows settings ﬁrst column labeled image sequences vary length model creates consistently sized feature vector computing statistics sequence statistics form vector mean median minimum maximum variance moment moment moment values interquartile range}. sufﬁcient statistics chosen capture diverse important information used infer unknown parameters many distribution families using frame-level estimates compute statistics length using frame-level estimates length sets statistics calculated. input regression model formally regression model formulated follows i.i.d. additive gaussian noise. objective infer latent functions given training dataset following framework place prior function function values follow gaussian distribution diag diagonal matrix element indicates importance corresponding statistic feature value inverse length-scale indicates relevant input output extremes length-scale large covariance indicating output uncorrelated input effectively removing feature inference. contrastingly length scale small opposite true indicating feature high relevance inference regression mapping fully deﬁned hyperparameters σv}. application model appropriate given small number input sequences nonparametric probabilistic models ability generalize well small datasets rbf-ard kernel well since kernel provides uncertainties estimates important assessing reliability estimated vas. summarize learning inference two-stage approach proceeds follows ﬁrst stage deepfacelift trains using multi-task learning different personalization strategies next output trained used compute sequence-level statistics. statistics passed model obtain personalized estimate inference done straightforward manner propagating features two-stage model resulting uncertainty estimate subject per-subject estimation results also shown fig.. features evaluation scores. model takes input facial landmarks image frame. facial landmark stored coordinate resulting input feature vector length coordinates concatenated. mean absolute error figure deepfacelift results estimation facial landmarks. show ﬁnal mean absolute error scores subject estimating ﬁnal maes subjects lower nn-mv baseline. show estimated versus reported along model’s uncertainty estimate four randomly chosen subjects. model learns different uncertainty levels different individuals; attributed part inputfeature noise subjectivity self-reported scores etc. table performance different methods tested estimation terms results baseline models using nn-mv hcrf. model also tested appending personal features inputs; however improve estimates. used evaluation commonly used ordinal estimation tasks additionally intra-class correlation reported commonly used behavioral sciences measure agreement annotators also used indicates scores deceptively low. example provides good indication accuracy fails capture correlation model estimates true values. application model output mean input image sequences resulting would supposedly outperforming baseline models. however case would strongly penalize errors resulting approximately zero. learning. learning performed using -fold cross validation. data split folds fold contains data persons. trial folds used training held testing. estimates iteration testing saved iterations concatenated. estimates obtained sequences used compute icc. compare results deepfacelift baseline model comprising -node lstm layer dense layer hcrf model comprising hidden states. since rnns hcrfs common choices modeling sequential data. also construct baseline taking mean voting per-frame estimations sequence. using statistics derived estimates alone deepfacelift achieves lowest outperforming baseline nn-mv hcrf models. additionally compared baseline models deepfacelift yields best settings. ﬁnal deepfacelift improves upon nn-mv demonstrating effectiveness regression model feature statistics second stage model. note table using personalized features yields better results using non-personalized features improvements seen deepfacelift also hcrf baselines. appending personal features third layer deepfacelift achieves lower appending input features. improvement suggests personal features appended inputs effectiveness partially washed larger input feature dimension discussion personal feature affects estimation performance detailed sec.. likewise used second label nn-mv baseline model improve upon obtained using label alone. suggests provide control subjective self-reported pain scores yielding better estimates vas. also provides evidence additional task improves model’s estimation previously shown multiple learning tasks discussed earlier cumbersome blackbox nature. several approaches available allow researchers infer input feature contributes ﬁnal output however methods encounter issues saturation thresholding computationally expensive. deeplift robust estimates input contributions remaining computationally efﬁcient avoiding gradient discontinuities deeplift estimates contributions input features performing backpropagation neuron calculating difference neuron’s computed activation respective reference activation differences taken speciﬁc input output activations allowing deeplift explain variations input feature contributions represent output input respectively. subject features ﬁrst normalized using z-scores. next deeplift uses zero-vector reference activation input. passed input trained obtain output used reference activation output. input assigned contribution score c∆xf multiple layers backpropagated input layer using standard chain rule follows input neuron hidden layer multiplier used calculate contribution deﬁned m∆x∆y c∆x∆h assuming contribution landmark frame-level estimation shown fig.a darker colors indicate higher contributions input feature ﬁnal output. ﬁgure average face computed using image frames illustrate locations landmark. coordinates landmarks corresponding contribution score figure contribution score estimates generated deeplift landmark. facial images illustrate various statistics contribution scores darker colors indicate positive values. facial image shows mean contribution score facial landmark estimation. boxplot shows distribution distance origin facial landmarks highest mean contributions illustrate movement. facial image shows standard deviation contribution scores facial landmark estimation. boxplot shows distributions landmarks highest standard deviations. facial image shows mean contribution score facial landmark estimation. boxplot shows distribution distances origin facial landmarks highest mean contributions. facial image shows standard deviation contribution scores facial landmark estimation. boxplot shows distributions facial landmarks highest standard deviations. e-g). four randomly selected subjects different gender skin-tone groups. contributions facial landmarks estimation contribution scores normalized subject scores contributions facial landmarks estimation. images subjects provided dataset. statistic indicated well. interesting result deeplift ﬁnds highest average input contributions subset facial landmarks estimating another subset estimating little overlap. possible explanation difference model simply converged different sets parameters. another possibility come different ways scores obtained. words obtaining external observers perceive subject’s pain differently focusing facial regions differ ones engaged subject. additionally fig. shows standard deviation contribution scores across subjects fig. show mean standard deviation contribution scores respectively estimating similarly fig. examples four different subjects given fig. illustrate relative importance using labels accompanied pictures subjects. results suggest facial landmarks also contribute differently estimation contributions vary among subjects. based fig. also appears slightly greater contributions landmarks right side faces. attributed redundancy landmarks facial symmetry camera positioned relative faces. personal features. importance personal feature toward estimation approximated excluding feature individually ﬁrst stage calculating resulting mae. importance including label stage assessed including excluding output comparing resulting maes. personal features improves estimates personal features improve ﬁnal outputs ﬁndings consistent clinical studies indicate gender personal features affect pain perception expression. additionally labels seem contain information improves estimates. statistics. aggregated relevance feature statistic using -fold cross validation results shown fig.b. particular feature statistic lower numerical kernel value statistic contributes ﬁnal estimate. according model statistics contribute important. ﬁnding suggests average frame-level estimates length corresponding image sequence contribute greatly estimation related length sequence. connection length image sequence highest contributing statistics indicative correlation length captured pain-causing experience resulting score. presented two-stage interpretable machine learning model uses face images automatically estimate subjective self-reported pain scores. deepfacelift demonstrates weakly supervised learning model able accurately estimate image sequences using personalized features scores training improves model performance. apfigure contributions personal features estimation. y-axis indicates increase speciﬁc personal feature excluded training. aggregated relevance results feature statistics computed rbf-ard kernel model. lower negative values indicate statistic contributes ﬁnal output. feature statistic shown). ﬁgure shows mean frame-level estimates important statistics. additional contribution deepfacelift ability track contribution features stages learning. makes possible explore relationships input features output estimates providing greater insight facial expressions inﬂuence pain perception estimation. contributions input features estimated using deeplift suggest experienced observed pain perceived differently contributions speciﬁc facial landmarks towards pain detection varies considerably among subjects. analysis however needed verify whether differences reﬂect model’s behavior alone also result differences subjects observers rate pain. finally identiﬁed examined important personal features statistical embeddings elaborating improve model performance. also showed including personal features different locations ﬁrst stage deepfacelift results different performance gains optimal performance achieved embedding intermediate layer furthermore exploiting beneﬁts multi-task learning obtain robust estimation attribute fact comes external observer thus acts sort grounding estimating subjective scores. summarize proposed personalized machine learning approach estimating vas. illustrated personalization process several different settings using gp-based model results indicate beneﬁts feature-level personalization. future plan investigate relationships pain scores well relate facial aus. context another important aspect explored paper plan derive advanced statistics could potentially capture additional information improve estimates subjective pain. finally hope ﬁndings advance applications pain estimation clinical settings. work rudovic funded european union marie curie action individual fellowship work funded vest scholarship wellcome trust fellowship. also thank daniel lopez martinez kelly peterson help early stages project.", "year": 2017}