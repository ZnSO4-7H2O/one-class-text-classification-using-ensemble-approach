{"title": "Bayesian Poisson Tensor Factorization for Inferring Multilateral  Relations from Sparse Dyadic Event Counts", "tag": ["stat.ML", "cs.AI", "cs.LG", "cs.SI", "stat.AP"], "abstract": "We present a Bayesian tensor factorization model for inferring latent group structures from dynamic pairwise interaction patterns. For decades, political scientists have collected and analyzed records of the form \"country $i$ took action $a$ toward country $j$ at time $t$\"---known as dyadic events---in order to form and test theories of international relations. We represent these event data as a tensor of counts and develop Bayesian Poisson tensor factorization to infer a low-dimensional, interpretable representation of their salient patterns. We demonstrate that our model's predictive performance is better than that of standard non-negative tensor factorization methods. We also provide a comparison of our variational updates to their maximum likelihood counterparts. In doing so, we identify a better way to form point estimates of the latent factors than that typically used in Bayesian Poisson matrix factorization. Finally, we showcase our model as an exploratory analysis tool for political scientists. We show that the inferred latent factor matrices capture interpretable multilateral relations that both conform to and inform our knowledge of international affairs.", "text": "present bayesian tensor factorization model inferring latent group structures dynamic pairwise interaction patterns. decades political scientists collected analyzed records form country took action toward country time t—known dyadic events—in order form test theories international relations. represent event data tensor counts develop bayesian poisson tensor factorization infer lowdimensional interpretable representation salient patterns. demonstrate model’s predictive performance better standard non-negative tensor factorization methods. also provide comparison variational updates maximum likelihood counterparts. identify better form point estimates latent factors typically used bayesian poisson matrix factorization. finally showcase model exploratory analysis tool political scientists. show inferred latent factor matrices capture interpretable multilateral relations conform inform knowledge international aﬀairs. permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights components work owned others author must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. request permissions permissionsacm.org. august sydney australia copyright ----// ..... social processes characterized pairwise connections actors people organizations corporations countries. social processes actors declare connections researchers directly study them—e.g. friendships facebook co-authorships academia. processes however connections explicitly declared. rather evidenced time dynamic interaction patterns. inferring social processes implicit data challenging important task. task especially motivated international relations. decades scholars collected analyzed records pairwise interactions countries form country took action toward country time known dyadic events. data sets e.g. traditionally small well-curated help form test theories international relations often concern multilateral behavior groups countries. recently interest studying less structured larger scale sources pairwise interaction data. researchers created several large data sets e.g. automatically extracting encoding dyadic events internet news archives. modern data sets diﬀer substantially smaller counterparts previously dominated ﬁeld. rather documenting high-level aggregate behaviors formal wars military alliances document micro-level behaviors day-to-day granularity. although view world potentially paints accurate nuanced picture international relations data noisy disaggregated analyze eﬀectively using traditional techniques. need methods uncover latent multilateral relations underlie events. paper introduce bayesian poisson tensor factorization inferring latent multilateral relations observed dyadic events. present scalable variational inference algorithm demonstrate method predictive exploratory analyses large-scale international relations data. figure illustrates approach; model infers ongoing multilateral relations six-party talks well relations precipitated temporally localized anomalous activity september attacks figure model infers latent components correspond multilateral relations. component consists four factor vectors summarizing sender receiver action-type time-step activity respectively. here visualize inferred technical summary data dyadic events represented four-way tensor aggregating events within discrete time steps. element tensor count number actions type taken country toward country time model decomposes tensor latent factor matrices provide low-dimensional representation salient patterns counts—in case latent multilateral relations. tensors derived dyadic event data often sparse since countries rarely interact another. additionally non-zero counts countries interact highly dispersed—i.e. mean greatly exceeded variance. traditional tensor factorization methods involving maximum likelihood estimation unstable sparse count tensors bayesian poisson tensor factorization builds previous work bayesian poisson matrix factorization gamma priors avoid instabilities. validate model comparing out-of-sample predictive performance non-bayesian tensor factorization methods bptf signiﬁcantly outperforms models decomposing sparse highly dispersed count data. present eﬃcient variational inference algorithm bptf data outline relationship algorithm traditional maximum likelihood approach relationship explains bptf outperforms methods without sacriﬁce eﬃciency. also suggests constructing point estimates latent factors variational distribution researchers geometric expectation instead arithmetic expectation commonly used bayesian poisson matrix factorization. show using geometric expectation increases sparsity inferred factors improves predictive performance. therefore recommend finally showcase bayesian poisson tensor factorization exploratory analysis tool political scientists demonstrate inferred latent factor matrices capture interpretable multilateral relations conform inform knowledge international aﬀairs. past years researchers created large data sets dyadic events automatically extracting internet news archives. largest data sets global database events location tone introduced contains quarter billion events present updated events daily parallel government agencies contractors also started collect analyze dyadic events order forecast political instability develop early-warning systems lockheed martin publicly released integrated crisis early warning system database early ward provide comparison gdelt icews gdelt icews cameo coding scheme cameo-coded dyadic event consists four pieces information sender receiver action type timestamp. example event sentence could extracted cameo also assumes hierarchy action types level consisting twenty basic action classes. classes loosely ranked based sentiment make public statement unconventional mass violence. action class subdivided speciﬁc actions; example make public statement contains make empathetic comment. studying international relations using cameo-coded data researchers commonly consider countries origin actors twenty basic action classes action types. icews unique country-of-origin actors gdelt number action types aggregating events time steps basis timestamps. element yijat count number actions type taken country toward country time step described section experimented various date ranges time step granularities. example experiments used entire icews data spanning monthly time steps— elements non-zero. moreover non-zero counts highly dispersed variance-to-mean ratio realistic model data must therefore robust sparsity capable representing high levels dispersion. tensor factorization methods decompose observed tensor latent factor matrices provide low-dimensional representation salient patterns many diﬀerent tensor factorization methods; common methods tucker decomposition canonical polyadic decomposition methods viewed tensor generalizations singular value decomposition. here focus decomposition performs better tucker decomposition modeling sparse count data known factors ˆyijat known reconstruction count yijat reconstruction entire tensor factors used model aggregated four latent factor matrices; exi.e. length-n vector sender factors length-n vector receiver factors length-a vector action-type factors length-t vector time-step factors. figure visually depicts components inferred icews gdelt. viewed probabilistic perspective recontk thought mean distribution observed count yijat assumed drawn. distribution decomposing latent factor matrices known poisson tensor factorization performed maximum likelihood estimation sparse count data often yields better estimates latent factor matrices obtained assuming count drawn paper also assume observed count yijat drawn poisson distribution mean ˆyijat; however rather obtaining point estimates factor matrices using maximum likelihood estimation impose prior distributions latent factors perform full bayesian inference. bayesian inference poisson matrix factorization originally proposed cemgil successfully used several tasks including image reconstruction music tagging topic modeling content recommendation community detection here generalize bayesian tensors. suﬃcient statistic—can cached improve eﬃciency. note summand need computed values yijat provided sparse inference eﬃcient even large tensors. hyperparameters optimized empirical bayes method hyperparameter iteratively updated along variational parameters according following update equation update equations completely specify variational inference algorithm bptf. python implementation intended support arbitrary -way tensors addition four-way tensors described paper available open source license. baselines non-bayesian methods decomposition values latent factor matrices minimize cost function observed tensor reconstruction researchers proposed many cost functions often euclidean distance generalized divergence preferring latter observed tensor consists sparse counts. generalized divergence observed data only. standard method estimating values latent factors involves multiplicative update equations originally introduced matrix factorization seung later generalized tensors welling weber multiplicative nature update equations acts non-negativity constraint factors promotes interpretability gives algorithm name non-negative tensor factorization cost functions also permit probabilistic interpretation ﬁnding values latent factors minimize equivalent maximum likelihood estimation probabilistic model. likelihood function poisson terization gamma distribution rate parameter product shape parameter mean prior completely determined inferred data shape parameter determines sparsity latent factor matrices user. throughout experiments encourage sparsity hence promote interpretability factors. given observed tensor bayesian inference latent factors involves inverting generative process described previous section obtain posterior distribution latent factor matrices conditioned posterior distribution bptf analytically intractable must approximated. variational inference turns process approximating posterior distribution optimization algorithm. involves ﬁrst specifying parametric family distributions latent variables interest indexed values variational parameters functional form typically chosen facilitate eﬃcient optimization here product independent gamma distributions—one latent factor—e.g. achieved performing coordinate ascent iteratively updating variational parameter holding others ﬁxed convergence update equation parameter derived easily using auxiliary variable shown bayesian therefore omit derivations. update equations table out-of-sample predictive performance model non-negative tensor factorization euclidean distance generalized divergence contains results single experiment. i-top- means experiment used data icews predicted upper-left portion test slice g-top-c means experiment used data gdelt predicted complement upper-left portion test slice. experiment state density training model fully observed training set. ﬁxed values variational parameters sender receiver action-type factor matrices inferred training set. test slice indexed time step used infer variational parameters finally reconstructed missing portion test slice using equation reconstruction step obtain point estimates latent factors taking arithmetic expectations geometric expectations variational distribution. section report results obtained using geometric expectations only; explain choice section time-step factors inferred observed portion given test slice capture extent sender receiver action-type factors component inferred training describe slice. example component summarizes israeli– palestinian conﬂict israel palestine actors fight action type israeli–palestinian hostilities intense test time step israel observed data only. since equation equal negative equation constant maximum likelihood estimation poisson tensor factorization equivalent minimizing generalized divergence validate modeling assumptions compared out-of-sample predictive performance bptf non-negative tensor factorization euclidean distance non-negative tensor factorization generalized divergence experimental design using icews gdelt explored well model generalizes out-of-sample data varying degrees sparsity dispersion. data set—icews gdelt—we sorted country actors overall activity zero. ranking country actors overall activity four actors icews tensor russia china israel four actors gdelt tensor russia israel iraq. gdelt tensor contains many events icews tensor also much denser exhibits much higher level dispersion summary results out-of-sample predictive performance model shown table experimented several diﬀerent values found three models insensitive value; therefore report results obtained using computed three types error mean absolute error mean absolute error non-zero elements hamming loss zero elements ham-z corresponds fraction true zeros unobserved portion test whose reconstructions predicted greater data generated three training–test splits averaged error scores model across them. experiment included table display density dispersion corresponding test set. treated dense upper-left complement) models performed comparably. scenario ntf-ls consistently achieved lowest score lowest ham-z score lowest mae-nz score. pattern suggests ntf-ls overﬁts sparsity training unobserved portion test much sparser training achieved lowest mae-nz ham-z scores—in cases order magnitude ntf-kl. results suggest presence sparsity bptf much better model interesting portion tensor—i.e. dense non-zero portion. observation consistent previous work kolda demonstrated unstable particularly observed tensor sparse section provide detailed discussion comparing bptf explain bptf overcomes sparsity-related issues often suﬀered ntf. —collectively known component.) used model explore data gdelt icews several date ranges time step granularities including -year monthly-time-step tensors described previous section inferring factor matrices data span large date range expect inferred components correspond multilateral relations persist recur time. figure shows components inferred -year gdelt icews tensors. ﬁrst component corresponds ongoing negotiations north korea’s nuclear program second corresponds decade-long found many components inferred -year tensors summarize regional relations—i.e. multilateral relations persist geographic proximity—similar found found high correspondence regional components inferred gdelt regional components inferred icews despite ﬁve-year diﬀerence date ranges. figure illustrates correspondence. also found components summarizing regional relations exhibited least sparsity sender receiver time-step factors. example component depicted ﬁgure near-uniform values sender receiver actors time-step factors possess high activity throughout. contrast time-step factors component shown second plot ﬁgure exhibit major spike october component’s sender receiver factors also exhibit uneven activity actors afghanistan pakistan dominating. regional relations components conform understanding international aﬀairs foster conﬁdence bptf exploratory analysis tool. however reason also less interesting. explore temporally localized multilateral relations—i.e. anomalous interaction patterns simply reﬂect usual activity— used model infer components several subsets gdelt icews spanning two-year date range weekly time steps. ranked inferred components sparsity time-step factors measured using gini coeﬃcient ranking components gini coeﬃcients form anomaly detection components high gini coeﬃcients unequal time-step factor values— i.e. dramatic spikes. figure shows highest-ranked component inferred subset gdelt spanning component features unusual group actors clear burst activity around june interpret component performed search ecuador sweden june found wikipedia page julian assange editor-in-chief website wikileaks— australian national wanted sweden sought political asylum ecuadorian embassy june august countries indeed actors component timestep factors action types track dates nature reported events. general found existing knowledge insuﬃcient interpret inferred component performing search two-to-four actors along time step resulted either wikipedia page news article provided explanation. present examples anomalous components inferred two-year date ranges ﬁgure along searches performed order interpret them. previous work bayesian poisson matrix factorization presented update equations variational parameters terms auxiliary variables known latent sources made explicit reference geometric expectations. contrast write update equations bayesian poisson tensor factorization form equations order highlight relationship seung’s multiplicative updates non-negative tensor factorization—a parallel also drawn cemgil paper introducing bayesian —and show update equations suggest making out-of-sample predictions using bptf. section provide figure mode arithmetic expectation geometric expectation gamma-distributed random variable first three quantities diﬀerent values shape rate three grow linearly mode second geometric arithmetic expectations diﬀerent values shape mode undeﬁned distribution shape rate three quantities shown vertical lines. three close area highest density diﬀering half unit inverse rate i.e. fourth gamma distribution geometric arithmetic expectations shown vertical lines quantities diﬀer greatly much closer zero area higher density. expectations used point estimates predict presence absence rare event—e.g. otherwise —they would yield diﬀerent predictions. update equations sometimes converge locally nonoptimal values observed tensor sparse problem occurs factors inadmissible zeros; algorithm cannot recover values multiplicative nature update equations. several solutions proposed correct behavior minimizing euclidean distance. example gillis glineur small constant factor prevent ever becoming exactly zero. divergence kolda proposed algorithm—alternating poisson regression—that scooches factors away zero selectively bptf point estimates latent factors estimated directly. instead variational parameters factor e.g. estimated. parameters deﬁne gamma distribution factor equation thereby preserving uncertainty value. practice approach solves instability issues suﬀered methods without eﬃciency sacriﬁce. assertion supported empirically out-ofsample predictive performance results reported section also veriﬁed comparing form update equation updates equations speciﬁcally equations substituted expression arithmetic expectation single exactly form equation except point estimates factors replaced kinds expectation. equation makes clear properties diﬀerentiate variational inference bptf seung updates hyperparameters arithmetic geometric expectations factors instead direct point estimates. since hyperparameters provide form implicit correction bptf suﬀer inadmissible zeros unlike non-bayesian ptf. also interesting explore contribution geometric expectations. fact ˆyijat deﬁned terms geometric expectation suggests constructing point estimates latent factors variational distribution geometric expectation appropriate arithmetic expectation since inference algorithm implicitly optimizing reconstruction deﬁned terms geometric expectations factors. explore practical diﬀerences geometric arithmetic expectations latent factors variational distribution illustrative consider form gamma relevantly gamma distribution asymmetric mean tation approximately equidistant arithmetic expectation mode—i.e. properties depicted ﬁgure point take away ﬁgure geometric expectation much probable value arithmetic metic expectations close. observation suggests geometric expectation yield similar better point estimates latent factors obtained using arithmetic expectation. table provide comparison out-of-sample predictive performance bptf using arithmetic geometric expectations. indeed results show performance obtained using geometric expectations either better performance obtained instead using arithmetic expectations. past ﬁfteen years political scientists engaged ongoing debate using dyadic events study inherently multilateral phenomena. debate summarized stewart began green al.’s demonstration many regression analyses based dyadic events biased implausible independence assumptions researchers continue expose biases e.g. even advocated eschewing dyadic data principle calling instead development multilateral event data sets taking opposite viewpoint—i.e. dyadic events used conduct meaningful analyses multilateral phenomena—other researchers beginning developed bayesian latent factor regression models explicitly model unobserved dependencies occurring latent space thereby controlling eﬀects analyses. line research seen increase interest activity past years paper take latter viewpoint instead focusing latent factor models regression present bayesian latent factor model predictive exploratory data analysis—speciﬁcally identifying characterizing complex dependence structures international relations implicit dyadic event data. exploratory analysis revealed interpretable multilateral structures capture persistent regional relations temporally localized anomalies. evidenced empirically predictive experiments analytically comparison variational inference algorithm traditional algorithms performing non-negative tensor factorization bayesian poisson tensor factorization overcomes instability issues exhibited standard non-negative tensor factorization methods decomposing sparse dispersed count data. provided additional analysis empirical results demonstrating constructing point estimates latent factors variational distribution geometric expectation appropriate choice arithmetic expectation. therefore recommend subsequent work involving variational inference bayesian poisson matrix tensor factorization. thank mingyuan zhou brendan o’connor branstewart adams david belanger luke vilnis juston moore helpful discussions. work partially undertaken aaron schein intern microsoft research york city. work supported part umass amherst ciir part grants iis- sbe- iis; grant n---; darpa grant fa---. opinions ﬁndings conclusions recommendations expressed material authors’ necessarily reﬂect sponsor. gonzalez zhang. accelerating lee-seung algorithm non-negative matrix factorization. technical report tr-- department computational applied mathematics rice university", "year": 2015}