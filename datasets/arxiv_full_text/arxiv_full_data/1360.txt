{"title": "Adversarial Manipulation of Deep Representations", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "We show that the representation of an image in a deep neural network (DNN) can be manipulated to mimic those of other natural images, with only minor, imperceptible perturbations to the original image. Previous methods for generating adversarial images focused on image perturbations designed to produce erroneous class labels, while we concentrate on the internal layers of DNN representations. In this way our new class of adversarial images differs qualitatively from others. While the adversary is perceptually similar to one image, its internal representation appears remarkably similar to a different image, one from a different class, bearing little if any apparent similarity to the input; they appear generic and consistent with the space of natural images. This phenomenon raises questions about DNN representations, as well as the properties of natural images themselves.", "text": "sara sabour yanshuai cao∗ fartash faghri david fleet department computer science university toronto canada architech labs toronto canada {saaraacaoyfaghrifleet}cs.toronto.edu show image representations deep neural network manipulated mimic natural images minor imperceptible perturbations original image. previous methods generating adversarial images focused image perturbations designed produce erroneous class labels. instead concentrate internal layers representations produce class adversarial images differs qualitatively others. adversary perceptually similar image internal representation appears remarkably similar different image different class bearing little apparent similarity input. further appear generic consistent space natural images. phenomenon demonstrates possibility trick confound almost image chosen image raises questions representations well properties natural images themselves. recent papers shown deep neural networks image classiﬁcation fooled often using relatively simple methods generate so-called adversarial images existence adversarial images important reveal weaknesses learned representations classiﬁers provide opportunities explore fundamental questions nature dnns e.g. whether inherent network structure learned models adversarial images might harnessed improve learning algorithms yield better generalization robustness research adversarial images date focused mainly disrupting classiﬁcation i.e. algorithms produce images classiﬁed labels patently inconsistent human perception. given large potentially unbounded regions feature space associated given class label surprising easy disrupt classiﬁcation. paper constrast label adversaries consider somewhat incidious class adversarial images called feature adversaries confused images class label internal representations well. given source image target image trained small perturbations source image produce internal representation remarkably similar guide image hence source. class adversarial phenomena demonstrate possible fool confound almost image chosen image. show deep representations adversarial images outliers rather appear generic indistinguishable representations natural images multiple layers dnn. phenomena raises questions representations well properties natural images themselves. several methods generating adversarial images appeared recent years. nguyen describe evolutionary algorithm generate images comprising patterns classiﬁed dnns common objects high conﬁdence interesting adversarial images quite different natural images used training data. natural images occupy small volume space possible images surprising discriminative dnns trained natural images trouble coping out-of-sample data. szegedy focused adversarial images appear natural. used gradient-based optimization classiﬁcation loss respect image perturbation magnitude perturbation penalized ensure perturbation perceptually salient. given image classiﬁer erroneous label perturbation minimizes loss here chosen line-search smallest achieves authors argue resulting adversarial images occupy probability pockets manifold acting like blind spots dnn. adversarial construction paper extends approach szegedy sec. gradient-based optimization small image perturbations. instead inducing misclassiﬁcation induce dramatic changes internal representation. later work goodfellow showed adversarial images common found taking steps direction gradient loss goodfellow also show adversarial examples exist models including linear classiﬁers. argue problem arises models linear. fawzi later propose general framework explain adversarial images formalizing intuition problem occurs dnns models sufﬁciently ﬂexible given classiﬁcation task. sec. show category adversarial images exhibits qualitatively different properties above. particular representations adversarial images similar natural images. appear unnatural obvious except fact remain inconsistent human perception. denote source guide images. mapping image internal representation layer goal image euclidian distance small possible remains close source precisely deﬁned solution constrained optimization problem constraint distance formulated terms norm limit maximum deviation single pixel color goal constrain degree perturbation perceptible. norm best available measure human visual discriminability superior norm often used others. rather optimizing image ﬁxed value produces compelling adversarial images negligible perceptual distortion. further works well different intermediate layers different networks images. larger optimizing lower layers close input increases distortion becomes perceptible little perceptible trace guide image distortion. numerical optimization l-bfgs-b inequality expressed constraint around figure shows nine adversarial images generated using well-known bvlc caffe reference model fig. shows source guide three adversarial images along differences corresponding source. adversarial examples optimized different perturbation bounds using different layers namely inspecting adversarial images larger values allow noticeable perturbations. figure shows examples adversarial images optimized using different layers caffenet different values beside adversarial image difference corresponding source image. class label explicit factor optimization class labels assigned adversarial images almost always guide. example took random source-guide pairs images imagenet ilsvrc data applied optimization using layer caffenet found class labels assigned adversarial images never equal source images. instead cases matched guide class. remains true source images training validation test ilsvrc data. found similar pattern behavior networks datasets including alexnet googlenet cnn-s trained imagenet ilsvrc dataset. also used alexnet trained places dataset hybrid dataset comprising scene classes classes imagenet cases using random source-guide pairs class labels assigned adversarial images match source. rather cases predicted class label guide. like approaches generating adversarial images generated network usually misclassiﬁed networks using source-guide pairs models above that average adversarial images obtained network misclassiﬁed networks. said usually consistently classiﬁed label guide different netowrks. next turn consider internal representations resemble source guide combination two? probe internal representations following mahendran vedaldi invert mapping thereby reconstructing images internal representations speciﬁc layers. panel fig. shows reconstructed images source-guide pair. input displays source guide adervarisal images optimized match representations layers caffenet subsequent rows show reconstructions internal representations images layers note lower layers bear similarity source higher layers resemble guide. optimized using reconstructions shows mixture source guide. almost cases internal representations begin mimic guide layer targeted optimization. reconstructions suggest human perception representations adversarial images clearly odds another. bottom panel fig. depicts activation patterns source guide images fig. along corresponding adversarial images. note adversarial activations sparse much closely resemble guide encoding source encoding. supplementary material includes several examples adversarial images activation patterns reconstructions intermediate layers. figure shows source guide three adversarial images optimized using layers caffenet. next three rows show images obtained inverting mapping layers respectively activation patterns shown layer source guide adversarial above layer source guide adversarial image above. investigate properties adversarial images asking questions. extent internal representations adversarial images resemble respective guides representations unnatural obvious way? answer questions focus mainly caffenet random pairs source-guide images drawn imagenet ilsvrc datasets. ﬁrst report quantitative measures proximity source guide adversarial image encodings intermediate layers. surprisingly despite constraint forces adversarial source images remain perceptually indistinguishable intermediate representations adversarial images much closer guides source images. interestingly adversarial representations often nearest neighbors respective guides. true remarkably wide range natural images. optimizations layer test dataset comprising source-guide pairs sampled training test validation sets ilsvrc plus images wikipedia increase diversity. layers higher dimensionality computational expedience smaller pairs. additional details images sampled found supplementary material. simplify exposition follows denote figure histogram euclidean distances adversarial encodings corresponding source guide optimizations targetting here distance denotes average pairwise distances points images class source average distance nearest neighbor encoding among images class guide. histograms aggregate source-guide pairs. euclidean distance means quantifying qualitative results fig. large ensemble source-guide pairs optimized layer fig. shows histogram ratio euclidean distance adversarial guide distance source guide ratios less indicate adversarial encoding closer might think norm constraint perturbation limit extent adversarial encodings deviate source optimization fails reduce distance ratio less pairs figure shows relax bound deviation source image even closer adversarial encodings become closer goes higher layers dnn. figure compares distances average distance representations ilsvrc training images class guide nearest neighbors often distance much smaller distance points class. fig. shows distance relatively large compared typical pairwise distances encodings images source class. adversarial images closer source average pairwise distance within source class. intersection average distance nearest neighbors looking one’s nearest neighbors provides another measure similarity. useful densities points changes signiﬁcantly feature space case euclidean distance less meaningful. quantify similarity rank statistics near neighbors. take average distance point’s scalar score point. rank point along points label class within training set. such rank non-parametric transformation average distance independant unit distance. denote rank point below. since close construction exclude ﬁnding adversarial points table shows intersection well difference rank adversarial guide encodings close enough expect intersection high rank differences small magnitude. shown table cases share exactly least cases rank similar data points class. results sources guides taken ilsvrc training set. statistics observed data test validation sets. similarity natural representations established internal representations adversarial images close guides extent typical natural images? vicinity inlier characteristics points neighborhood? answer question examining neighborhood properties probabilistic parametric measure giving table results comparison nearest neighbors adversarial guide. randomly select pairs guide source images guide classiﬁed correctly source classiﬁed different class. optimization done maximum iterations statistics percentiles. likelihood point relative local manifold geometric non-parametric measure inspired high dimensional outlier detection methods. analysis follows denote point also nref reference points comprising random points remaining close guide nref finally guide. reference nref used measurement construction scored relative measures mentioned above. euclidean distance might meaningful similarity measure points high-dimensional space like cosine distance deﬁning nns. manifold tangent space build probabilistic subspace model probabilistic around compare likelihood points. precisely ppca applied nref whose principal space secant plane approximately normal direction tangent plane generally pass curvature manifold. correct small offset shifting plane pass ppca achieved moving mean high-dimensional gaussian evaluate likelihood points model relative likelihood denoted repeat measurement large number guide source pairs compare distribution points guide images sampled ilsvrc training validation sets results shown ﬁrst columns fig. since gaussian centred bounded zero. plots show well explained locally manifold tangent plane. comparing obtained sampled training validation sets observe patterns similar plots likelihood local subspace models. suggests phenomenon adversarial perturbation eqn. intrinsic property representation itself rather generalization model. angular consistency measure sparse high-dimensional feature space manifold high curvature linear gaussian model poor consider test whether inlier vicinity rely manifold assumption. take reference points near nref measure directions point. compare directions nearby points e.g. whether similar points around terms angular consistency. compared points within local manifold point manifold tend exhibit narrower range directions others points manifold. speciﬁcally given reference nref cardinality point angular consistency measure deﬁned fig. show histograms compared note maximum angular consistency case point behaves like differences scaling upper bound angular consistency plots strikingly similar likelihood comparisons ﬁrst columns fig. supporting conclusion inlier respect representations natural images. figure manifold inlier analysis ﬁrst columns results manifold tangent space analysis showing distribution difference likelihood point last column angular consistency analysis showing distribution angular consistency point eqn. deﬁnitions. comparisons analysis compare feature adversaries images created optimize mis-classiﬁcation part illustrate qualitative differences. also investigate linearity hypothesis mis-classiﬁcation adversaries goodfellow consistent explains class adversarial examples. hereby refer results feature adversaries optimization adversarial images designed trigger mis-classiﬁcation optimization described brieﬂy sec. referred label adversaries optimization comparison label-opt demonstrate label-opt differs qualitatively feature-opt report three empirical results. first rank points assigned class label according average distance three nearest neighbours sec. fig. shows rank versus rank nearest neighbor-n types adversaries. unlike featureopt label-opt rank correlate well rank words feature-opt close label-opt not. second manifold ppca approach sec. comparing peaked histogram standardized likelihood feature-opt shown fig. fig. shows label-opt examples represented well gaussian around ﬁrst third analyze sparsity patterns different layers different adversarial construction methods. well known dnns relu activation units produce sparse activations therefore degree sparsity increases adversarial perturbation adversarial example using additional paths manipulate resulting represenation. also investigate many activated units shared source adversary computing intersection union active units. high layers represenations share active paths. hand degree sparsity remains same adversary must closed activation paths opened ones. table difference proportion non-zero activations selected layers source image represenation types adversaries. except label-opt difference signiﬁcant. column also shows feature-opt uses different activation paths compared label-opt. testing linearity hypothesis feature-opt goodfellow suggests existence label adversaries consequence networks linear. linearity hypothesis applies class adversaries possible linearize around source image obtain similar adversaries optimization. formally jacobian matrix internal layer encoding respect source image input. then linearity hypothesis implies subject inﬁnity norm constraint eqn. refer adversaries feature-linear. shown fig. adversaries particularly close guide. closer feature-opt distance reduced less layers note unlike feature-opt objective feature-linear guarantee reduction distance constraint relaxed. results suggest linearity hypothesis explain existence feature-opt adversaries. networks random weights explored whether existence feature-opt adversaries learning algorithm training structure deep networks purpose randomly initialized layers caffenet orthonormal weights. optimized adversarial images above looked distance ratios interestingly distance ratios norm similar fig. deviation. results greater trained caffenet. note norm overcomplete representations input. table distance ratios found supplementary material. results random networks suggest existence feature-opt adversaries property network architecture. introduce method generating adversarial images appear perceptually similar given source image whose deep representations mimic characteristics natural guide images. indeed adversarial images representations intermediate layers appear quite natural much like guide images used construction. demonstrate empirically imposters capture generic nature guides different levels deep representations. includes proximity guide locations high density regions feature space. show properties shared categories adversarial images. also linearity hypothesis provide obvious explanation adversarial phenomena. appears existence adversarial images predicated network trained natural images example results random networks indicate structure network signiﬁcant factor. another future direction concerns exploration failure cases observed optimizing feature adversaries. mentioned supplementary material cases involve images hand-written digits networks ﬁne-tuned images narrow domain failures suggest adversarial phenomena factors network depth receptive ﬁeld size class natural images used. since analyze representation well-known networks leave exploration factors future work. another interesting question concerns whether existing discriminative models might trained detect feature adversaries. since training models requires diverse relatively large dataset adversarial images also leave future work. acknowledgments financial support research provided part mitacs nserc canada canadian institute advanced research would like thank foteini agraﬁoti support. would also like thank goodfellow xavier boix well anoynomous reviewers helpful feedback. fig. illustrates achieved goal paper. image fancy left training example ilsvrc dataset. right adversarial image generated guiding source image image fancy images close image space activation pattern adversarial almost identical max. shows mapping image space representation space natural image exists point small neighborhood image space mapped network point representation space small neighborhood representation different natural image. unless stated otherwise used following sets source guide images. ﬁrst used experiments layer second used computational expedience layers source images guided guide images show convergence depend class images. simplify reporting classiﬁcation behavior used guides training whose labels correctly predicted caffenet. sets used source images drawn random ilsvrc train test validation sets selected manually wikipedia ilsvrc validation provide greater diversity. guide ﬁrst consisted three images classes drawn random ilsvrc training images another images validation test sets. second drew guide images classes. fig. shows random sample source guide pairs along pool adversarial images. none images guide perceptable adversary regardless choice source guide layer. parameter affects visibility noise described sec. attempt analyzing architecture caffenet independent training initializing model random weights generating feature adversaries. results tab. show generate feature adversaries random networks well. ratio distances adversary guide source guide analysis. cell mean standard deviation ratio shown three random orthonormal random trained caffenet networks. weights random network drawn distribution caffenet initialized with. orthorgonal random weights obtained using singular value decomposition regular random weights. results tab. indicate convergence norm conv almost similar dimensionality norm quite smaller conv. hand fig. shows although norm smaller dimensionality conv optimization converges closer point conv rather conv hence norm. means relation dimensionality achieved distance adversary straightforward. discussed sec. goodfellow also proposed method construct label adversaries efﬁciently taking small step consistent gradient. fast gradient method shines light label adversary misclassiﬁcations useful adversarial training relevant whether linearity hypothesis explains feature adversaries. therefore omitted comparison sec. fast gradient method continue discussion here. input image refer resulting adversarial examples label-fgrad. also apply fast gradient method internal representation i.e. taking perturbation deﬁned δsignφ call type feature adversaries fast gradient experimental setup sec. used here. fig. show nearest neighbor rank analysis manifold analysis done sec. sec. moreover figs. compare figs. feature-opt results fig. label-opt results indicates adversaries represented well feature-opt gaussian around adversary too. also figs. compare fig. show obvious difference adversarial distribution source guide. cases optimization successful generating good adversaries. observed resolution images hand-drawn characters method always work well. successful lenet images mnist cifar cases found necessary relax magnitude bound perturbations point traces guide images perceptible. caffenet pre-trained imagenet ﬁne-tuned flickr style dataset could readily generate adversarial images using optimization however optimization often terminated without producing adversaries close guide images. possible cause ﬁne-tuning distorts original natural image representation beneﬁt style classiﬁcation. consequence layer longer gives good generic image represenation euclidean distance longer useful loss function. finally dedicate remaining pages several pairs source guide along adversaries activation patterns inverted images complementary fig. figs. similar setup discussed sec.", "year": 2015}