{"title": "Attention on Attention: Architectures for Visual Question Answering  (VQA)", "tag": ["cs.CL", "cs.AI", "cs.CV", "68Txx"], "abstract": "Visual Question Answering (VQA) is an increasingly popular topic in deep learning research, requiring coordination of natural language processing and computer vision modules into a single architecture. We build upon the model which placed first in the VQA Challenge by developing thirteen new attention mechanisms and introducing a simplified classifier. We performed 300 GPU hours of extensive hyperparameter and architecture searches and were able to achieve an evaluation score of 64.78%, outperforming the existing state-of-the-art single model's validation score of 63.15%.", "text": "visual question answering increasingly popular topic deep learning research requiring coordination natural language processing computer vision modules single architecture. build upon model placed ﬁrst challenge developing thirteen attention mechanisms introducing simpliﬁed classiﬁer. performed hours extensive hyperparameter architecture searches able achieve evaluation score outperforming existing state-of-the-art single model’s validation score code available github.com/singhjasdeep/attention-on-attentionfor-vqa. visual question answering increasingly popular topic deep learning research requires coordination several artiﬁcial intelligence-related disciplines including computer vision natural language processing. growing popularity last year version challenge initiated. vqa’s relative complexity need grained visual textual processing many intricate highly tuned architectures performance. chose build upon relatively simple model proposed last year’s winners investigate role attention ways improve performance. high level models require forms information text images. inputs model images free-form open-ended natural language questions image model’s goal produce natural language answer input pre-trained glove vectors tokenized questions produce question embeddings faster r-cnn generate objects centric features images. information passed attention module create joint embedding image-question joint embedding passed classiﬁer produce ﬁnal answer. project aims investigate previous methods implementing better understand characteristics successful network architectures task. build upon previous iterations winning challenge models developing thirteen attention mechanisms introducing simpliﬁed classiﬁer model. evaluate model implementations evaluation metric used challenge able beat challenge winners best single model scores. rapidly growing research topic since introduction seminal paper largely interdisciplinary nature. problems require model understand text-based question identify elements image evaluate inputs primary method approach tasks based three subcomponents creating representations image question; passing inputs neural network create co-dependent embedding; generating correct natural language response. past work xiong investigated several improvements input modules dynamic memory networks originally developed textual question answering order show basic architecture could utilized visual question answering. however since model architectures visual textual question answering specializing domains. models visual question answering preferring sophisticated single pass attention mechanisms. related paper show attend tell neural image caption generation visual attention introduced attention based model learned describe content images using different attention modules stochastic hard attention deterministic soft attention. current state-of-the-art model developed teney challenge show simple interpretable models achieve strong performance. experiments show signiﬁcance carefully designing image features attention mechanisms gated activations output embeddings model performance. many large-scale datasets developed application decided utilize dataset contains images million questions million answers least three questions image preventing model inferring question without considering input image data following preprocessing training questions answers tokenized trimmed/padded maximum length words. tokens represented using -dimentional pre-trained wikipedia+gigaword glove word embeddings thirty features image created passing images faster r-cnn bottom-up attention proposed faster r-cnn detects object centric elements input image. pre-trained held ﬁxed training model. images pre-converted faster r-cnn features efﬁciency purposes. proposed model derives inspiration winning architecture developed teney challenge. model implements joint rnn/cnn question image embeddings respectively. uses top-down attention guided question embedding image embeddings. model inputs preprocessed glove embeddings faster r-cnn feature vectors discussed section stated section question inputs tokenized represented using glove word embeddings. passed create ﬁnal question embedding. image feature vectors along question embedding size number-of-hidden-units passed dual one-way top-down attention module module computes relevance image vectors current question embedding using following equations. figure visual representation model architecture attention modules. speciﬁcs attention module described text performed best modules architectures investigated. ﬁnal image vector question embedding passed separate layer transformation modules rearrange convert input vectors dimensions. resulting vectors layer transformation modules element-wise multiplied together create ﬁnal joint embedding. joint embedding given simple layer classiﬁcation module outputs probability sigmoid layer possible answers answer vocabulary. word corresponding maximum output probabilities taken predicted answer accuracy calculated using equation initial experimentation performed using hyperparameters identical ones used teney however instead using adadelta optimizer chose adamax replaced gated tanh layers one-layer networks twice size found modiﬁcations able produce robust model larger range hyperparameters. literature review models found biggest determinants increased model accuracy improved attention mechanisms. investigate pattern implemented attention modules shown figure evaluated modules addition original attention proposed teney identiﬁed modules promising. model architectures evaluated based performance validation figure graphical representation attention module architecture evaluation. primary attention modules evaluated investigation conducted three optimally performing modules best performing attention module used hyperparameter tuning. however noticed many attention mechanisms used literature including tested softmax ﬁnal layer. hypothesized lead signal bottleneck model prevent model able answer questions images required equal attention several regions image. investigate this decided multiple attention modules model also added sigmoid ﬁnal layer best performing attention module time create evaluating parallel stacked attention modules sigmoid variants found perform optimally decided pursue hyperparameter search using attention module model. hyperparameters tuned time general presented figure ﬁrst took baseline model investigated effects using weight normalization. found weight normalization improved performance decided keep hyperparameter tuning. next investigated activation functions found leaky relu give optimal performance. subsequent hyperparameter step found optimal value following searches using updated value. approach thought greedy hyperparameter search. approach taken randomized hyperparameter search large space hyperparameters searched relatively resources. step determined optimal hyperparameters based validation accuracy. however seen figure models over-ﬁt training given enough epochs. compared papers found expected large disparity distribution questions validation training set. understandable open ended task inﬁnite number possible image-question-answer triplets. furthermore validation consisted total images training consisted nearly similar amount images. although model over-ﬁtting training unlikely dropout activation function tuning over-ﬁtting validation data set. determining optimal model experimentation tuning able achieve evaluation score performing existing state-of-the-art single model’s validation score believe signiﬁcant reasons score able beat state-of-the results sophisticated attention mechanism. ﬁnal model used attention mechanism takes attention mechanisms stacks parallel ability focus multiple aspects image. figure contains three heatmaps show adding second attention mechanism allows model learn different aspects input image. form image simple attention tasks attention mechanisms able appropriate locations image. however image task requires need focus highly multiple locations image model edge previously presented models theory leads increased accuracy. however complicated tasks image dual attention mechanism seems confused providing obvious advantages. computational time resources limited result class deadlines budget able begin extensive architecture hyperparameter search. future work would look synergistic effects hyperparameters well experiment bi-directional attention mechanism would impact performance. would like ensemble models accurate comparison could made state models test data. however teney like many others ensembled models state performance unfeasible resources. visual question answering unique challenge modern artiﬁcial intelligence research combines learnings computer vision natural language processing. paper presented ﬁndings done improve performance tasks expands upon preexisting work improving model’s image features creating attention mechanisms adding simple classiﬁer. able surpass existing state-of-the results hope insights learned completion project inform progress task.", "year": 2018}