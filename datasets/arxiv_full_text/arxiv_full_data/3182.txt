{"title": "A Supervised Neural Autoregressive Topic Model for Simultaneous Image  Classification and Annotation", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Topic modeling based on latent Dirichlet allocation (LDA) has been a framework of choice to perform scene recognition and annotation. Recently, a new type of topic model called the Document Neural Autoregressive Distribution Estimator (DocNADE) was proposed and demonstrated state-of-the-art performance for document modeling. In this work, we show how to successfully apply and extend this model to the context of visual scene modeling. Specifically, we propose SupDocNADE, a supervised extension of DocNADE, that increases the discriminative power of the hidden topic features by incorporating label information into the training objective of the model. We also describe how to leverage information about the spatial position of the visual words and how to embed additional image annotations, so as to simultaneously perform image classification and annotation. We test our model on the Scene15, LabelMe and UIUC-Sports datasets and show that it compares favorably to other topic models such as the supervised variant of LDA.", "text": "topic modeling based latent dirichlet allocation framework choice perform scene recognition annotation. recently type topic model called document neural autoregressive distribution estimator proposed demonstrated state-of-the-art performance document modeling. work show successfully apply extend model context visual scene modeling. specifically propose supdocnade supervised extension docnade increases discriminative power hidden topic features incorporating label information training objective model. also describe leverage information spatial position visual words embed additional image annotations simultaneously perform image classiﬁcation annotation. test model scene labelme uiuc-sports datasets show compares favorably topic models supervised variant lda. image classiﬁcation annotation important tasks computer vision. image classiﬁcation tries describe image globally single descriptive label annotation focuses tagging local content within image since problems related natural attempt solve jointly. example image labeled street likely annotated pedestrian building beach water. although work image classiﬁcation annotation separately less work looked solving problems simultaneously. work image classiﬁcation annotation often based topic model popular latent dirichlet allocation generative model documents originates natural language processing community great success computer vision scene modeling models document multinomial distribution topics topic multinomial distribution words. distribution topics speciﬁc document topic-dependent distributions words shared across documents. topic models thus extract meaningful semantic representation document inferring latent distribution topics words contains. context computer vision used ﬁrst extracting so-called visual words images convert images visual word documents training topic model bags visual words. image representations learned used successfully many computer vision tasks visual classiﬁcation annotation image retrieval although original topic model proposed unsupervised learning method supervised variants proposed modeling documents’ visual words class labels discriminative power learned image representations could thus improved. heart topic models generative story image’s latent representation generated ﬁrst visual words subsequently produced representation. appeal approach task extracting representation observations easily framed probabilistic inference problem many general purpose solutions exist. disadvantage however model becomes sophisticated inference becomes less trivial computationally expensive. instance inference distribution topics closed-form solution must approximated either using variational approximate inference mcmc sampling. model actually relatively simple making certain simplifying independence assumptions conditional independence visual words given image’s latent distribution topics. recently alternative generative modeling approach documents proposed larochelle lauly model document neural autoregressive distribution estimator models directly joint distribution words document decomposing probability chain rule product conditional distributions modeling conditional using neural network. hence docnade doesn’t incorporate latent random variables potentially expensive inference must performed. instead document representation computed efﬁciently simple feed-forward fashion using value neural network’s hidden layer. larochelle lauly also show docnade better generative model text documents extract useful representation text information retrieval. paper consider application docnade context computer vision. speciﬁcally propose supervised variant docnade models joint distribution image’s visual words annotation words class label. model illustrated figure investigate successfully incorporate spatial information visual words highlight importance calibrating generative discriminative components training objective. results conﬁrm approach outperform supervised variant competitive alternative scene modeling. simultaneous image classiﬁcation annotation often addressed using models extending basic topic model. wang proposed supervised formulation tackle problem. wang mori opted instead maximum margin formulation work also belongs line work extending topic models supervised computer vision problem contribution extend different topic model docnade context. distinguishes docnade topic models reliance neural network architecture. neural networks increasingly used probabilistic modeling images review). realm document modeling salakhutdinov hinton proposed replicated softmax model bags words. docnade fact inspired model shown improve performance much computationally efﬁcient. also proposed hybrid model combines neural network. applied model scene classiﬁcation only outperforming approaches based neural network only. experiments show approach outperforms theirs. generally speaking aware work considered problem jointly classifying annotating images using hybrid topic model/neural network approach. section describe original docnade model. larochelle lauly docnade model documents real words belonging predeﬁned vocabulary. model image data assume images ﬁrst converted visual words. standard approach learn vocabulary visual words figure illustration supdocnade joint classiﬁcation annotation images. visual annotation words extracted images modeled supdocnade models joint distribution conditionals modeled using neural networks shared weights. predictive word conditional follows tree decomposition leaf possible word. test time annotation words used compute image’s topic feature representation. performing k-means clustering sift descriptors densely exacted training images. section details procedure. point image thus represented visual words index closest k-means cluster sift descriptor extracted image number extracted descriptors. modeling instead conditional subvector containing notice equation true distribution based probability chain rule. hence main assumption made docnade form conditionals. speciﬁcally docnade assumes conditional modeled learned feedforward neural network. practice expensive since must computed visual words address issue larochelle lauly propose balanced binary tree decompose computation conditionals obtain complexity logarithmic achieved randomly assigning visual words different leaf binary tree. given tree probability word modeled probability reaching associated leaf root. model left/right transition probabilities binary tree using binary logistic regressors taking hidden layer input. probability given word obtained multiplying probabilities left/right choices associated tree path. speciﬁcally sequence tree nodes path root leaf sequence binary left/right choices internal nodes along path. example always root node binary tree word leaf left subtree otherwise. rt×h matrix containing logistic regression weights vector containing biases number inner nodes binary tree number hidden units. probability modeled internal node logistic regression outputs sigm sigmoid function. using balanced tree guaranteed computing equation involves logistic regression outputs. could attempt optimize organization words within tree random assignment words leaves works well practice document docnade. train parameters docnade simply optimize average negative log-likelihood training documents using stochastic gradient descent. model trained latent representation extracted document follows representation could standard classiﬁer perform supervised computer vision task. index used highlight representation used predict class label image. equations indicate conditional probability word requires computing position dependent hidden layer extracts representation previous visual words v<i. since computing average hidden layers compute naive procedure computing hidden layers would finally since computation complexity logistic regressions equation total complexity computing ohd). practice length document number hidden units tends small small even large vocabularies. thus docnade used trained efﬁciently. section describe approach paper inspired docnade simultaneously classify annotate image data. first describe supervised extension docnade incorporates class label information training learn discriminative hidden features classiﬁcation. describe exploit spatial position information visual words. last describe also perform annotation along classiﬁcation using supdocnade. observed learning image feature representations using unsupervised topic models perform worse training classiﬁer directly visual words themselves using appropriate kernel pyramid kernel reason unsupervised topic features trained explain much entire statistical structure images possible might model well particular discriminative structure computer vision task. issue addressed literature devising supervised variants supervised slda docnade also unsupervised topic model propose supervised variant docnade supdocnade attempt make learned image representation discriminative purpose image classiﬁcation. docnade conditional modeled neural network. architecture regular docnade. need deﬁne model since image representation we’ll perform classiﬁcation propose model multiclass logistic regression output computed bias parameter vector supervised layer differently modeled regular multiclass neural network taking input visual words crucial difference however regular neural network parameters also used model visual word conditionals averaged training images. known generative learning ﬁrst term purely discriminative term second unsupervised understood regularizer encourages solution also explains unsupervised statistical structure within visual words. practice regularizer bias solution strongly away discriminative solution generalizes well. hence similarly previous work hybrid generative/discriminative learning propose instead weight importance generative term training training average equation performed stochastic gradient descent using backpropagation compute parameter derivatives. regular docnade computation training objective gradient requires deﬁne ordering visual words. though could deﬁned arbitrary path across image order words follow larochelle lauly randomly permute words every stochastic gradient update. implication model effectively trained good inference model conditional ordering words helps ﬁghting overﬁtting better regularizes model. often outperforms activation functions shown work well image data since piece-wise linear function gradient respect input needed backpropagation compute parameter gradients simply true otherwise. algorithms give pseudocodes efﬁciently computing joint distribution parameter gradients equation required stochastic gradient descent training. spatial information plays important role understanding image. example often appear part image often appear bottom. previous work exploited intuition successfully. example seminal work spatial pyramids shown extracting different visual word histograms distinct regions instead single image-wide histogram yield substantial gains performance. follow similar approach whereby model presence visual words identity region appear speciﬁcally let’s assume image divided several distinct regions number regions. image represented region visual word extracted. model joint distribution treat possible visual word/region pair distinct word. implication binary tree visual words must larger leaf possible visual word/region pair. fortunately since computations grow logarithmically size tree problem still deal large number regions. dealing annotations annotation image consists list words describing content image. example image figure annotation might contain words trees people. annotations labels clearly dependent model jointly within supdocnade model. speciﬁcally predeﬁned vocabulary annotation words note annotation given image number words annotation. thus image annotation represented mixed visual annotation words embed annotation words supdocnade framework treat annotation word deal visual words. speciﬁcally joint indexing visual annotation words larger binary word tree augment leaves annotation words. training supdocnade joint image/annotation representation learn relationship labels spatially-embedded visual words annotation words. test time annotation words given wish predict them. achieve this compute document representation based visual words compute possible annotation word probability would next observed word based tree decomposition equation words compute probability paths reach leaf corresponding annotation word rank annotation words decreasing order probability select words predicted annotation. section test model real-world datasets subset labelme dataset uiuc-sports dataset scene dataset scene used evaluate image classiﬁcation performance only labelme uicu-sports come annotations popular classiﬁcation annotation benchmark. provide scene dataset contains images belonging different classes. following previous work ﬁrst resize images maximum side pixels wide without changing aspect ratio. experiment randomly select images training using remaining images test set. following wang constructed labelme dataset using online tool obtain images size pixels following classes highway inside city coast forest tall building street open country mountain. class images randomly selected split evenly training test sets yielding total images. uiuc-sports dataset contains images classiﬁed classes badminton bocce croquet polo rockclimbing rowing sailing snowboarding following previous work maximum side image resized pixels maintaining aspect ratio. randomly split images class evenly training test sets. labelme uiuc-sports datasets removed annotation words occurring less times wang following wang dimensional densely extracted sift features used extract visual words. step patch size dense sift extraction respectively. dense sift features training quantized clusters construct visual word vocabulary using k-means. divided image grid extract spatial position information described section produced different visual word/region pairs. classiﬁcation accuracy evaluate performance image classiﬁcation average f-measure predicted annotations evaluate annotation performance previous work. f-measure image deﬁned recall percentage correctly predicted annotations ground-truth annotations image precision percentage correctly predicted annotations predicted annotations. used random train/test splits estimate average accuracy f-measure. image classiﬁcation supdocnade performed feeding learned document representations kernel svm. experiments hyper-parameters chosen cross validation. emphasize annotation words available test time methods predict image’s class based solely visual words. section describe quantitative comparison supdocnade docnade slda. used implementation slda available http//www.cs.cmu.edu/˜chongw/slda/ comparison. models publicly available implementation mmlda compare instead results reported literature. ﬁrst test classiﬁcation performance method scene dataset. figure illustrates performance methods varying number topics. observe supdocnade outperforms slda large margin also improving orignal docnade model. figure classiﬁcation performance comparison scene dataset. left ﬁgure shows performance comparison supdocnade docnade slda. ﬁgure right compares performance different variants supdocnade. figure classiﬁcation performance comparison labelme uiuc-sports datasets. compare classiﬁcation performance supdocnade docnade slda. bottom compare performance different variants supdocnade. results labelme left results uiuc-sports right. figure also compare supdocnade design choices model performing purely generative purely discriminative training ignoring spatial position information using position information tuning weight important pure discriminative learning performing worse. also performed experiments scene dataset using hybrid topic/neural network model used slightly different setup used topics visual word vocabulary size dense sift patch size step size also didn’t incorporate spatial position information using spatial grid. running supdocnade using conﬁguration obtain classiﬁcation accuracy compared model. classiﬁcation results illustrated figure similarly observe supdocnade outperforms docnade slda. tuning trade-off generative discriminative learning exploiting position information usually beneﬁcial. exception labelme hidden topic units using grid slightly outperforms grid. image annotation computed performance model topics. supdocnade obtains -measure labelme uiuc-sports datasets respectively. slightly superior regular docnade obtains since code performing image annotation using slda publicly available compare directly results found corresponding paper wang report -measures slda supdocnade large margin. also compare mmlda max-margin formulation applied image classiﬁcation annotation separately. reported classiﬁcation accuracy mmlda less supdocnade. annotation -measures reported better supdocnade labelme worse uiuc-sports. mention mmlda address problem simultaneously classifying annotating images tasks treated separately. tried extract visual/annotation words strongly associated certain class labels within supdocnade. example given class label street corresponds column matrix selected topics largest connection weight then averaged columns matrix corresponding hidden topics selected visual/annotation words largest averaged weight connection. results procedure classes street sailing forest highway illustrated figure visualize visual words show image patches belonging visual word’s cluster extracted kmeans. learned associations intuitive example class street associated annotation words building buildings window person walking visual words showcase parts buildings windows. paper proposed supdocnade supervised extension docnade. like topic models model trained model distribution words representation images extract meaningful representation unlike topic models however image representation modeled latent random variable model instead hidden layer neural network. resulting model might less interpretable figure visualization learned representations. class labels colored red. class list visual words annotation words strongly associated class. section details. advantage requiring iterative approximate inference procedure compute image’s representation. experiments conﬁrm supdocnade competitive approach classiﬁcation annotation images.", "year": 2013}