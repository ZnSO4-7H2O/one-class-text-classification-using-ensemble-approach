{"title": "Recognition of Visually Perceived Compositional Human Actions by  Multiple Spatio-Temporal Scales Recurrent Neural Networks", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "The current paper proposes a novel neural network model for recognizing visually perceived human actions. The proposed multiple spatio-temporal scales recurrent neural network (MSTRNN) model is derived by introducing multiple timescale recurrent dynamics to the conventional convolutional neural network model. One of the essential characteristics of the MSTRNN is that its architecture imposes both spatial and temporal constraints simultaneously on the neural activity which vary in multiple scales among different layers. As suggested by the principle of the upward and downward causation, it is assumed that the network can develop meaningful structures such as functional hierarchy by taking advantage of such constraints during the course of learning. To evaluate the characteristics of the model, the current study uses three types of human action video dataset consisting of different types of primitive actions and different levels of compositionality on them. The performance of the MSTRNN in testing with these dataset is compared with the ones by other representative deep learning models used in the field. The analysis of the internal representation obtained through the learning with the dataset clarifies what sorts of functional hierarchy can be developed by extracting the essential compositionality underlying the dataset.", "text": "action recognition convolutional neural networks long-term recurrent convolutional networks two-stream convolutional networks d-cnn extracts spatio-temporal features videos convolutions temporal spatial domains ﬁxed window lrcn two-stage model ﬁrst extracts spatial features stage extracts temporal features long-short term memory stage two-stream convolutional network stream input stream input stacked optical ﬂows. streams joined make categorical output although d-cnn lrcn two-stream convolutional network perform well dynamics consistent neuroscientiﬁc evidences. important piece evidence mammals size spatio-temporal receptive ﬁeld cell increased level goes higher principle cybernetics so-called downward causation suggests spatio-temporal hierarchy naturally developed human brains taking advantage macroscopic constraints genetically assigned them. evidence principle suggest deep learning model action recognition form hierarchy assignment spatio-temporal constraints. model extract spatial temporal features simultaneously hierarchy. representative action recognition models lack properties. current study extension prior study using so-called multiple spatio-temporal scales neural network neural activity mstnn governed spatial temporal constraints means local connectivity convolutional layers time constants assigned leaky integrator neural units layer respectively. constraints make mstnn develop faster local interaction lower layer whereas develops slower global interactions higher level. enables mstnn extract spatio-temporal features multiple levels exemplar data patterns. formation spatio-temporal hierarchy consistent biological evidence principle mentioned earlier. however true temporal processing capacity mstnn quite limited fact essential dynamics decay dynamics exerted leaky integrator neurons compose model. time mstnn uses forward connectivity without recurrent connectivity considered source generating abstract—the current paper proposes novel neural network model recognizing visually perceived human actions. proposed multiple spatio-temporal scales recurrent neural network model derived introducing multiple timescale recurrent dynamics conventional convolutional neural network model. essential characteristics mstrnn architecture imposes spatial temporal constraints simultaneously neural activity vary multiple scales among different layers. suggested principle upward downward causation assumed network develop meaningful structures functional hierarchy taking advantage constraints course learning. evaluate characteristics model current study uses three types human action video dataset consisting different types primitive actions different levels compositionality them. performance mstrnn testing dataset compared ones representative deep learning models used ﬁeld. analysis internal representation obtained learning dataset clariﬁes sorts functional hierarchy developed extracting essential compositionality underlying dataset. inspired mammalian visual cortex showed remarkably better object image recognition performance conventional vision recognition schemes employ elaborately hand-coded visual features. trained million visual images imagenet able classify hundreds object images error rate demonstrated near-human performance however cnns lack capacity temporal information processing. consequence cnns less effective handling video image patterns static images. tani department electrical engineering korea institute science technology daejeon republic korea also okinawa institute science technology okinawa japan e-mail arbitrary complex dynamics known study biological brains context current study attempts recursive dynamics mstnn introducing recurrent connectivity convolutional layers. leads novel proposal multiple spatio-temporal scales recurrent neural network model current study. experiments mstrnns compared mstnns lrcns. mstrnns compared mstnns observe existence recurrent structures mstrnns effect action recognition performances. among introduced representative action recognition models lrcn also used baseline mstrnn since recurrent neural network structures. also chosen baseline model mstrnn effect setting spatio-temporal constraints extracting spatial temporal features simultaneously. mtsrnn model evaluated using three different human action datasets distinct types levels compositionality introduced action patterns. ﬁrst experiment mstrnn compared mstnn dataset prepared concatenating three action patterns appear weizmann dataset experiment shows recurrent structure implemented mstrnn effective action recognition task. also qualitative analysis neural activations generated models made show categorical memories formed. second third experiments aimed conduct comparative experiments using datasets natural human action patterns controlling level underlying compositionality. public video datasets containing natural human actions control compositionality level human action datasets prepared current study. second experiment video dataset built considering compositions objects actions directed objects. experiment performance mstrnn mstnn lrcn compared. analysis made internal dynamics mstrnn lrcn observing time series activation patterns. analysis made multiple timescale constraint assigned mstrnn strengthen model performance lrcn involve temporal constraints. third experiment triad compositions among objects objectdirected actions modiﬁers actions considered prepare dataset. mstrnn mstnn lrcn compared experiment. experiment designed require models extract temporal features longer temporal correlation recognition action modiﬁers objects actions. examining recognition accuracies among models advantage proposed model clariﬁed. sequences input layer. image sequences multiple context layers extract spatio-temporal features input image sequences. extracted spatio-temporal features several layers fully-connected layers. ﬁnally output layer categorical output made. output layer consists softmax neurons. context layer mstrnn simultaneously extracts spatio-temporal features core building block mstrnn. context layer consists feature units pooling units context units shown fig. context layer assigned time constant controls decay dynamics context units feature units. larger time constant causes internal states leaky integrator neurons context layer change slowly time step mstrnn assigns larger time constant higher layers develop spatio-temporal hierarchy fig. architecture mstrnn. full architecture mstrnn. time constant leaky integrator neurons context layer. structure context layer. arrow labeled indicates decay dynamics leaky integrator neurons feature units context units. arrow indicates recurrent connections made context units. feature units equivalent convolutional layer composed leaky integrator neurons time constants control decay dynamics feature units capable extracting temporal features decay dynamics leaky integrator neurons well capable extracting spatial features convolutional operations. feature units extract features context units pooling units previous context layer shown fig. convolutional kernels. forward dynamics feature units explained internal state represents time constant convolutional kernel bias convolution operation convolution operator total number maps pooling units total number maps context units recurrent convolutional kernel context units neural activations pooling units context units respectively. ﬁrst term right hand side describes decay dynamics leaky integrator neurons. second term represents convolution pooling units. third term describes recurrent dynamics terms recurrent shared weights. neural activations context units previous time step supplied recurrent convolutional kernels. activation function context units mstrnn uses hyperbolic tangent function used feature units shown training conducted supervised manner using delay response scheme black frames input mstrnn input image sequence delay response period. period errors calculated time step comparing outputs mstrnn true labels input image sequences using kullbackleibler divergence. cost function used training phase shown error calculated whole input image sequence represented delay response period duration input video total number softmax vectors output layer. output layer several softmax vectors depending task. total number neurons softmax vector output layer true output output categorized mstrnn. true output given one-hot-vector softmax vector. here term one-hot-vector refers vector values value correct category rest categories. error input action video obtained error used optimize learnable parameters using back propagation time stochastic gradient descent algorithms. prevent overﬁtting learnable parameters learned weight decay addition dropout random cropping input images pixels smaller width height also used avoid overﬁtting. represents time constant convolutional kernels extract features previous layer pooling units context units respectively. bias used convolution operation convolution operator total number maps pooling units total number maps context units. additionally activation values pooling units context units respectively. ﬁrst term right hand side describes decay dynamics leaky integrator neurons. second term represents convolution features pooling units. third term describes features extracted context units previous context layer. equation shows hyperbolic tangent function used activation functions feature units. context units equivalent feature units recurrent convolutional kernels. addition recurrent convolutional kernels structure features units enhanced temporal processing capacity feature units. recurrent dynamics context units enhance extraction latent temporal features input image sequences recurrent connections made convolutional kernels zero padding. context units inputs using recurrent kernels pooling units layer convolutional kernels. forward dynamics context units shown internal state activation value neuron coordinates context units context layer time step represented ˆctxy leave-onesubject-out cross-validation scheme used. method subject selected dataset his/her video clips left training data instead used test data. accuracies obtained possible validation sets averaged used evaluation measure. categories actions action-related objects recognition accuracy action-ado pair computed. epoch model showed best accuracy joint category picked. accuracy category epoch used evaluation. accuracies rounded second decimal place recorded measures overall performance. ﬁrst experiment mstrnn compared mstnn using relatively simple action dataset temporal compositionality. second third experiments mstrnn tested datasets look natural higher compositionality levels. second third experiments mstrnn compared mstnn lrcn. mstrnn compared mstnn mstrnn experiments. three models input output layer according datasets tested. table shows input image sizes according datasets cropping mentioned training method section. output layer conﬁgurations according datasets also described table three actions concatenated patterns weizmann dataset compositionality level action dataset compositionality level action dataset used ﬁrst second third experiments respectively. parameter settings differ models described below. mstrnn mstrnn model convolutional layer pooling layer fullyconnected layers softmax layer described fig. ﬁrst second context layers time constants respectively. convolutional layer pooling layer used context layers decrease size input context layers decrease computing time. context layer takes computing time convolutional layer pooling layer. exceptions convolutional pooling kernels used model stride stride respectively. used since found best cnns model tested acwd kernels used instead ﬁrst convolutional layer convolutional kernels ﬁrst used ﬁrst pooling layer experiment compositionality level action dataset compositionality level action dataset ﬁrst convolutional layer used kernels stride also exceptions made convolutional kernels connected context units recurrent convolutional kernels context units size stride zero padding. convolutional kernels connect pooling units context units context units next layer size stride exceptions made resulting size context units unchanged time step progresses. baselines baselines used experiments. baselines mstnn used three experiments. mstnn model convolutional layer convolutional layers consisted leaky integrator neurons three pooling layers fully-connected layers softmax layer ﬁrst second convolutional layers consisted leaky integrator neurons time constants respectively. also lrcn used baseline experiments clad clad. three convolutional layers three pooling layers lstm layer fully-connected layer softmax layer lstm layer used following works donahue mstrnn parameter settings exceptions convolutional pooling kernels mstnn lrcn stride stride respectively reason case mstrnn parameter settings. mstnn lrcn models exceptions using convolutional kernel stride ﬁrst convolutional layer ﬁrst convolutional kernels used ﬁrst pooling layer. parameters mstnns lrcns adjusted similar number parameters mstrnns. table shows number parameters used mstrnn mstnn lrcn second experiment. number parameters three models differ experiments different datasets. changes parameters models according datasets mentioned subtle number parameters kept similar experiments. next internal dynamics mstrnn mstnn assessed time series analysis neural activation values. activation values obtained third convolutional layer mstnn context units second context layer mstrnn time series neural activations visualized using principle component analysis ﬁrst second principle components neural activations used visualization. following discussion analysis indicates arbitrary primitive actions time series neural activations obtained given action primitives sequential manner designated trajectory a-bc. since models trained categorize actions based outputs obtained teaching length position trajectories differentiated based history images shown sequence. trajectories mstnn given time step largely affected primitive action input video time step. accordingly neural activations approached points representative current action mapped space. trajectories jp-x-x ohx-x th-x-x ﬁrst approached points marked fig. respectively presentation second third primitives. second third primitives given trajectories immediately changed directions toward representative positions primitives recently shown. therefore branching points seen jp-x-x oh-x-x th-x-x trajectories. unlike characteristics shown mstnn trajectories obtained context units second context layer mstrnn simply approach positions representative currently displayed action primitives mapped space tended differentiate primitives other. show characteristics mstnn mstrnn detail trajectories jp-jp-jp oh-jp-jp th-jp-jp mstnn mstrnn models shown fig. trajectories obtained mstnn jp-jp-jp trajectory directly approached marker ﬁgure. trajectories oh-jp-jp th-jp-jp ﬁrst approached regions marked respectively. second third primitives trajectories changed paths approached region marked trajectories obtained mstrnn converge position marked ﬁgure jp-jp-jp trajectory mstrnn directly approached marker ﬁgure mstnn. trajectories oh-jp-jp th-jp-jp ﬁrst approached regions marked respectively. then second third primitives shown trajectories changed paths. however direction trajectories point toward position section compares action categorization capability multiple spatio-temporal scales recurrent neural network multiple spatio-temporal scales neural network analyzing internal dynamics developed model. purpose three actions concatenated patterns prepared using weizmann dataset dataset compositional action videos prepared concatenating videos three different human actions weizmann dataset three actions jump-inplace one-hand-wave two-hand-wave shown fig. resulting categories video clip concatenated actions category. videos nine subjects exist dataset. foreground silhouettes resulting acwd emphasized background subtraction utilizing background sequences resized results categorization accuracy mstrnn acwd double categorization accuracy obtained mstnn result implies context units recurrent weights improve categorization long concatenated human action sequences. fig. mapping time series activation values obtained mstrnn mstnn test data given models. mapping generated third convolutional layer mstnn. mapping generated context units second context layer mstrnn. fig. mapping time series activation values obtained test subjects action videos jp-jp-jp oh-jp-jp th-jp-jp concatenated action sequences given mstnn mstrnn models. mapping generated third convolutional layer mstnn. mapping generated context units second context layer mstrnn. shows mstrnn better categorical memory mstnn since able keep temporal information previously shown action primitives prevent activation values becoming similar values obtained action primitive shown model. decay dynamics mstnn responsible trajectories fig. approaching markers represent current action primitives. described internal neural values feature units affected current spatial-temporal features processed previous context layer decayed internal neural values units previous time step. method previously extracted spatial features effectively inﬂuence internal neural values current time step keep track action primitives came past since gradually higher performance categorical memories mstrnn compared mstnn recurrent structure context units. context units retain important spatio-temporal features extracted previous time steps less reinforced current steps. inferred improved categorical memories mstrnn better categorization performance compared mstnn. categorization compositionality level action dataset experiment compared categorization performance mstrnn mstnn lrcn newly prepared compositionality level action dataset action pattern clad generated composition speciﬁc action corresponding action-directed-object category. experiment represendataset clad consists videos made subjects performing nine actions directed four objects. object-directed action categories total dataset designed categorization task nontrivial. non-ado appears along video prevent model inferring human action solely recognizing object video. object-directed action category videos shot subject three different non-ados appearing videos different states possible presented videos ados. recording dataset subjects generated action without constraints. objects located random positions task space. however camera view angle ﬁxed since problem view invariance beyond scope current study. dataset open public results results obtained testing mstrnn mstnn clad shown table mstrnn showed highest action categorization performance among models. conﬁrms mstrnn characterized multiscale spatiotemporal constraint recurrent connectivity outperformed mstnn without recurrent connectivity lrcn without multiscale temporal constraint. although lstm considered capability self-adapting timescale dynamics adjusting ratio forgetting gate perform well generating recognizing dimensional discrete sequence data performance cannot guaranteed extremely high dimensional temporal data video data without introducing simultaneous constraint spatial processing temporal layer. also current result mstrnn mstnn showed similar categorization accuracies higher lrcn. might resulted mstrnn mstnn extracted spatio-temporal features simultaneously lrcn extracted spatial features extract temporal features different stages. next observed temporal constraints mstrnn helped action categorization comparing time series activations mstrnn lrcn. neural activations ﬁrst fully-connected layer mstrnn lstm layer lrcn generated input action videos belonging close/drink-bottle visualized manner similar previous experiment. trajectories obtained mstrnn trajectories share paths point branch according action categories. bottle close/drink-bottle category ﬁrst appears opened states image movement videos similar subject hand reaches cup. image movement start differ objects reached subject subject starts according action category. trajectories seem represent perceptual time series inputs categorized space. trajectories lrcn also seem share paths early time steps differentiate certain points like trajectories mstrnn. however trajectories seem make ﬂuctuated movements sometimes even going back forth. phenomenon occurred lstm could learn develop temporal hierarchy temporal constraints imposed learning process. reason categorization performance lrcn lower mstrnn. categorization compositionality level action dataset third experiment categorization performances mstrnn mstnn lrcn compared introducing challenging task using compositionality level action dataset action pattern clad expressed object action action modiﬁer. dataset clad consists videos tagged labels objects actions action modiﬁers. categorization action modiﬁers often requires action recognition models extract longer temporal correlation recognition ados actions. example video book-touch- times category model acquire sufﬁcient information perceiving book twice touched model needs extract long-ranged temporal correlation similar events ﬁrst touch second touch order identify proper modiﬁer twice. fig. show sampled images clad dataset. static image hard infer action. even harder infer action modiﬁer. video clad describable compositions four objects four actions action modiﬁers. assumed categories dataset terms objectaction-modiﬁer triplets shown fig. total number triplets video recordings taken different subjects. subject shot videos object action modiﬁer triplet. dataset recording subjects generated action naturally. video nonado appears alongside ado. non-ado randomly picked categories excluding true video. objects located various positions task space. however camera view angle ﬁxed dataset open public results results obtained testing mstrnn mstnn lrcn clad shown table mstrnn exhibited higher modiﬁer categorization performance mstnn lrcn respectively. action categorization accuracies mstrnn performances higher lrcn lower mstnn small gap. performance difference mstrnn mstnn caused enhanced categorical memories mstrnn. explained previously categorization action modiﬁers requires temporal information categorization ados actions. therefore mstrnn better categorical memories mstnn able achieve higher modiﬁer categorization accuracy mstnn. mstnn shown higher accuracy action categorization mstrnn categorical memories effective modiﬁer categorization sufﬁcient fig. sample frames clad. hard infer action category static image. even harder infer action modiﬁer image. recognition action modiﬁers requires action recognition model extract longer temporal correlation recognition actions ados. proposed mstrnn model action recognition extracts spatio-temporal features simultaneously using multiscale spatio-temporal constraints imposed neural activity different layers. mstrnn mstnn compared using three actions concatenated patterns weizmann dataset ﬁrst experiment. results showed recurrent structure mstrnn model outperformed mstnn. comparative analysis neural activation sequences generated models suggest mstrnn develop enhanced categorical memories compositional categorization visually grounded data done effectively mstnn does. consistent biological evidences human brain utilizes recurrent pathways learn temporal sequences effectively second experiment performance mstrnn mstnn lrcn compared using compositionality level action dataset challenging categorization task ﬁrst one. mstrnn showed highest categorization accuracies action-directed object action categories among tested models. comparative analysis internal dynamics mstrnn lrcn suggested performance mstrnn better lrcn. temporal hierarchy mstrnn successfully developed temporal constraints adequately imposed model whereas lrcn temporal constraints could form hierarchy. mstrnn mstnn lrcn compared third experiment. experiment compositionality level action dataset triplets ados actions modiﬁers labels used. results mstrnn outperformed models modiﬁer categorization requires extraction longer temporal correlation categorization ados actions. mstrnn mstnn extract spatio-temporal features simultaneously showed higher categorization rate lrcn extracts spatial temporal features separately different layers. suggests simultaneous extraction spatial temporal features advantageous learningbased action recognition models. consistent biological evidences spatio-temporal receptive ﬁelds neuron mammalian cortex increases layer goes although mstrnn showed better performance models used comparison recognition accuracy less human level. main reasons degeneracy might overﬁtting. future study overﬁtting problem alleviated recently developed deep learning regularization techniques including dropout technique recurrent connections based variational inference recurrent batch normalization also help alleviate overﬁtting. cooijmans shown batchnormalization lstm improves generalization capacity encourages faster convergence learning phase. future study also investigate possible advantage adding top-down prediction pathway attention process mstrnn structure. adding top-down pathway attention recognition process involve dense interaction top-down proactive process projecting possible image attention bottom-up perceptual process reﬂecting top-down expectation perceptual reality. recognition process developed interactions sides considered robust possible perturbation input visual signals. finally future study scaling. mentioned previously current dataset used experiment built authors adequate tagged video data different levels action compositionality public datasets. however admitted size data relatively small model cannot tested general conditions view angle free size free conditions. future study explore enlarge data size efﬁciently purpose scaling generalization model system. szegedy sermanet reed anguelov erhan vanhoucke rabinovich going deeper convolutions proceedings ieee computer society conference computer vision pattern recognition vol. --june- russakovsky deng krause satheesh huang karpathy khosla bernstein berg fei-fei imagenet large scale visual recognition challenge international journal computer vision vol. donahue hendricks guadarrama rohrbach venugopalan darrell saenko long-term recurrent convolutional networks visual recognition description proceedings ieee computer society conference computer vision pattern recognition vol. --june- tani received b.s. degree mechanical engineering waseda university tokyo japan m.s. degrees electrical engineering mechanical engineering university michigan arbor d.eng. degree sophia university tokyo. started research career sony laboratory tokyo japan team leader laboratory behavior dynamic cognition riken brain science institute saitama japan years visiting associate professor university tokyo tokyo currently full professor electrical engineering department korea advanced institute science technology daejeon republic korea. also currently adjunct professor okinawa institute science technology okinawa japan. current research interests include neuroscience psychology phenomenology complex adaptive systems robotics. karpathy toderici shetty leung sukthankar feifei large-scale video classiﬁcation convolutional neural networks proceedings ieee conference computer vision pattern recognition haanvid received b.s. degree electrical electronic engineering yonsei university seoul republic korea m.s. degree electrical engineering korea advanced institute science technology daejeon republic korea", "year": 2016}