{"title": "Towards Automation of Knowledge Understanding: An Approach for  Probabilistic Generative Classifiers", "tag": ["cs.LG", "cs.AI"], "abstract": "After data selection, pre-processing, transformation, and feature extraction, knowledge extraction is not the final step in a data mining process. It is then necessary to understand this knowledge in order to apply it efficiently and effectively. Up to now, there is a lack of appropriate techniques that support this significant step. This is partly due to the fact that the assessment of knowledge is often highly subjective, e.g., regarding aspects such as novelty or usefulness. These aspects depend on the specific knowledge and requirements of the data miner. There are, however, a number of aspects that are objective and for which it is possible to provide appropriate measures. In this article we focus on classification problems and use probabilistic generative classifiers based on mixture density models that are quite common in data mining applications. We define objective measures to assess the informativeness, uniqueness, importance, discrimination, representativity, uncertainty, and distinguishability of rules contained in these classifiers numerically. These measures not only support a data miner in evaluating results of a data mining process based on such classifiers. As we will see in illustrative case studies, they may also be used to improve the data mining process itself or to support the later application of the extracted knowledge.", "text": "data selection pre-processing transformation feature extraction knowledge extraction ﬁnal step data mining process. necessary understand knowledge order apply eﬃciently eﬀectively. lack appropriate techniques support signiﬁcant step. partly fact assessment knowledge often highly subjective e.g. regarding aspects novelty usefulness. aspects depend speciﬁc knowledge requirements data miner. however number aspects objective possible provide appropriate measures. article focus classiﬁcation problems probabilistic generative classiﬁers based mixture density models quite common data mining applications. deﬁne objective measures assess informativeness uniqueness importance discrimination representativity uncertainty distinguishability rules contained classiﬁers numerically. measures support data miner evaluating results data mining process based classiﬁers. illustrative case studies also used improve data mining process support later application extracted knowledge. data mining seen multi-step process shown data mining pyramid introduced embrechts idea pyramid brieﬂy summarized follows data pre-processed condense application-speciﬁc information attributes features. then knowledge extracted e.g. building classiﬁcation regression models. analyzing knowledge oﬀ-line using given application possible come deeper understanding working principles gain experience using respectively. support eﬃcient eﬀective application knowledge. finally kind meta-knowledge eventually help solve similar kinds application problems. ﬁnal step wisdom reached transferring knowledge application domains. steps data information knowledge article address problem knowledge understanding analyzing properties oﬀ-line. classiﬁers based probabilistic mixture models used many applications. classiﬁers termed hybrid sense diﬀerent kinds distributions combined diﬀerent kinds attributes makes classiﬁer ﬂexible. trained data samples using expectation maximization related techniques variational bayesian approaches propose various measures assess informativeness uniqueness importance discrimination representativity uncertainty distinguishability rules contained classiﬁer. measures used diﬀerent ways example possible prune classiﬁers rank classiﬁcation rules detect novel kinds knowledge classiﬁer’s application. however proposed measures seen ﬁrst important step towards automation knowledge understanding. thus assumptions make cover possible aspects real world applications far. instance probability distributions needed attribute types. article substantially extended version conference article main contributions compared previous article existing measures revised introduce additional measures analyze diﬀerent aspects generative classiﬁers. evaluation measures also completely improved. four case studies utilizing artiﬁcial real-world benchmark data sets illustrate proposed measures help data scientists. remainder article ﬁrst brieﬂy discuss related work section then describe classiﬁer introduce various measures section illustrative case studies section show measures applied. section summarize ﬁndings give outlook future work. obviously measures looking closely related so-called interestingness measures data mining. data mining today often used synonym knowledge discovery databases deals nontrivial process identifying valid novel potentially useful ultimately understandable patterns data interestingness assessed numerically? obviously objective facets interestingness validity subjective facets usefulness objective measures analyze extracted knowledge without relating users’ prior knowledge needs. measures based e.g. so-called information criteria data-based measurement techniques overview). examples former akaike’s information criterion bayesian information criterion. examples latter statistical measures sensitivity speciﬁcity precision etc. determined crossvalidation bootstrapping method test data criteria assess complexity rules rule sets rule system size measure computational complexity measure rule complexity measure mean scoring rules measure fuzzy quality measure information gain association rules sometimes several measures combined interestingness measures rules evaluated regard four properties conﬁrmation locality symmetry property termed assures conclusively conﬁrmatory rules assigned higher interestingness value non-conclusively conﬁrmatory rules vice versa. especially weaker forms locality property proposed together interestingness measure fulﬁlls weaker forms properties. measures proposed compared measure terms properties fulﬁll. also bayesian conﬁrmation measures evaluation rule interestingness measures proposed. interestingness measure evaluate rules classiﬁer components individual samples presented there support vector machine used samples close decision boundary distant previous samples classiﬁed interesting. support vector machine used learn interestingness values twitter hashtags data. subjective measures consider additional knowledge application information data miner skills needs examples subjective measures novelty usefulness understandability actionability unexpectedness existing measures based diﬀerent techniques represent information human users depend form knowledge representation. often bayesian networks fuzzy classiﬁers association rules addressed related work. article focus objective measures beyond existing measures validity also focus measures classiﬁcation rules rule sets crisp consider samples knowledge uncertain. speciﬁcally consider probabilistic classiﬁers stay within probabilistic methodological framework assess rules contained classiﬁers. section also address question whether measures could transferred kinds classiﬁers too. section ﬁrst present generative classiﬁer paradigm. generative classiﬁer aims modeling processes underlying generation data termed generative processes modeled perfectly generative model could used generate artiﬁcial data exactly characteristics real data. contrast discriminative classiﬁers ﬁnding optimal decision boundary directly. today approaches often combined exploit respective advantages. here probabilistic techniques generative classiﬁers. second part section introduce measures knowledge understanding. dimensional input sample want compute posterior distribution i.e. probabilities class membership given input sample minimize risk classiﬁcation errors select class highest posterior probability generally posterior distribution determined multinomial distribution parameters termed class priors conditional densities called components. overall components model. approach separate sets components diﬀerent classes conclude components assigned certain class determine class posteriors altogether classiﬁer consisting linear combination components component described distribution keep notation uncluttered speciﬁc component identiﬁed single index following class relevant. kind density functions components? considering ddimensional sample dcont continuous dimensions dcat dcont categorical ones. without loss generality arrange dimensions many practical applications gaussian components gaussian mixture models motivated generalized central limit theorem roughly states independent samples distribution ﬁnite mean variance converges normal distribution sample size goes inﬁnity. moreover continuous distribution approximated arbitrarily well ﬁnite mixture normal densities categorical dimensions -of-kd coding scheme number possible categories attribute value attribute represented vector belongs category otherwise. approach possible model multivariate categorical data sets arbitrarily well despite independence assumption concerning categorical variables. dimensions handled relying distributions considered yet. beside that feature types conversions certain assumptions possible. instance rational integer dimensions might interpreted nearly continuous appropriate conditions attributes categorized preprocessing step trained. section compare classiﬁer paradigms regarding classiﬁcation accuracy. general probabilistic generative classiﬁers oﬀer interesting features risk minimizing cost functions easily combined probabilistic outputs class priors compensated diﬀerent models easily combined anomaly detection techniques deﬁned various parameters classiﬁer determined? given training samples assumed independent identically distributed first split subsets containing samples corresponding class i.e. mixture model trained. here perform parameter estimation means technique called variational bayesian inference realizes bayesian idea regarding model parameters random variables whose distributions must trained approach important advantages methods standard expectation maximization approach. first estimation process robust i.e. avoids collapsing components so-called singularities variance directions vanishes. second optimizes number components pruning irrelevant components i.e. considered notably contribute overall density therefore start training relatively large number components rely automatically reduce number components suﬃcient number. number model components critical parameter considered user. detailed discussion bayesian inference particularly details concerning training algorithm found conﬁrm comparable classiﬁcation paradigms regarding classiﬁcation accuracy thus suﬃciently meaningful deﬁne measures knowledge understanding evaluate performance benchmark data sets phoneme satimage australian credit_a credit_g ecoli glass heart iris pendigits pima quality seeds segment vehicle vowel wine yeast clouds ripley two_moons table contains general information data sets e.g. number samples feature types class distribution. australian clouds credit_a credit_g ecoli glass heart iris pendigits phoneme pima quality ripley satimage seeds segment two_moons vehicle vowel wine yeast training algorithm sequential minimal optimization support vector machines widely used discriminative approaches pattern recognition tasks. consequently train frequently used libsvm library using kernels another common paradigm decision trees familiar training algorithms successor instance. latter train among advantages trained tree structure easily used extract human-readable rules last competitor simple one-nearest-neighbor classiﬁer even though classiﬁes respect nearest neighbor shown maximum classiﬁcation error twice maximum classiﬁer yields best possible classiﬁcation performance evaluation classiﬁers done way. ﬁrst samples taken data function independent test set. remaining parameter search done using grid search combined -fold cross validation. parameters perform best folds selected determine performance test set. results independent test sets achieved parameters training sets table perform comparably well. substantial property actual number components mixture model strong inﬂuence decision boundary long suﬃcient number components model. fig. demonstrates exemplarily used data sets here trained components trained models cover smaller areas input space leads models components components fig. components fig. images show decision boundaries resulting classiﬁers quite similar. applications desirable extract human-readable rules trained classiﬁer. possible classiﬁer parametrized accordingly. moment focus single component omit identifying index restrictions concerning covariance matrix number categories necessary. however extract rule premises continuous input dimensions obtained univariate projections axes. implies information dependencies diﬀerent dimensions lost. thus recommend force covariance matrices diagonal. then multivariate gaussians split product consisting dcont univariate gaussians dcont. case univariate gaussians identical projections corresponding input dimensions. categorical dimensions simpliﬁed considering categories whose probability certain case-dependent threshold. rule derived classiﬁer follows variables input variables output variable represents class label. rule premises realized conjunctions univariate gaussians conjunctions settings categorical dimensions. settings written disjunctions categories probabilities speciﬁed threshold. conclusions given class derived class aﬃliation component premise. rules form similar fuzzy rules rather diﬀerent interpretation. figure diﬀerent models classiﬁers artiﬁcial two_moons data resulting almost identical decision boundaries. images show two-dimensional input spaces classiﬁer. crosses circles samples originate processes assigned diﬀerent classes. probabilistic models part classiﬁers depicted components represented ellipses diﬀerent shapes positions marked thick black lines decision boundaries separate regions assigned diﬀerent classes. fig. gives example used extract rule set. classiﬁer embedded three dimensional input space classes blue crosses green circles ﬁrst dimensions continuous modeled three bivariate gaussians. mean values described large crosses surrounding ellipses level curves gaussians shapes deﬁned covariance matrix since covariance matrices non-zero diagonal ellipses axes-oriented. corresponding projections onto axes also illustrated note projections marked high result gaussians since right component covered components continuous dimensions. third dimension categorical categories distributions categories illustrated histograms next every component. here categories probability strictly greater average considered order simplify resulting rules. altogether following rule extracted classiﬁer fig. following describe seven objective measures used assess knowledge incorporated objective way. term rule instead component wish explicitly extract human-readable rules cmm. article focus measures single components measures overall classiﬁers could easily figure example classiﬁer consisting three components continuous single categorical dimension simpliﬁed projections continuous densities depicted corresponding axes. distribution categorical dimension shown histogram attached aﬃliated component. obtained averaging measures components considering worst cases etc. then would also possible compare diﬀerent classiﬁers instance. addition classical performance measures also used. class component belongs relevant measure component identiﬁed single index e.g. otherwise explicitly denoted sample data needed evaluate measure training data purpose. component regarded informative assumed describe really distinct kind process generating data. assess informativeness component numerically hellinger distance probability densities compared statistical distance measures kullback-leibler divergence hellinger distance advantage bounded deﬁned assess informativeness overall classiﬁer weighted average informativeness values components used. weights determined depending respective mixing coeﬃcients class priors. knowledge contained components unambiguous. measured uniqueness component reﬂects degree samples belonging diﬀerent classes covered component. denote responsibility component generation sample i.e. run-time complexity required evaluate uniqueness component since evaluate density sample whole additionally boundary function comprised linear functions. projects mixing coeﬃcients smaller average interval maps mixing coeﬃcients larger average importance component computed discrimination measure evaluates inﬂuence component decision boundary— thus classiﬁcation performance—of overall classiﬁer. calculate discrimination component create second removing original re-normalizing mixing coeﬃcients remaining components. then compare achieved classiﬁcation error training data original classiﬁcation error without component required concrete application also possible detailed measures sensitivity speciﬁcity precision assess discrimination capability component. also consider class priors. performance generative classiﬁer also depends well models data. kind ﬁtness determined continuous dimensions explicitly assume data distribution modeled mixture gaussians. since categorical data always possible distribution perfectly models data representativity measure considers continuous dimensions xcont. true underlying distribution unknown real-world data sets must approximated non-parametric density estimation technique e.g. standard parzen window density estimator measure always takes values greater equal vanishes identical. would also possible hellinger distance measure distance true data distribution model however since measure restricted unit interval errors approximation result values close thus diﬀerence models without certain component typically close zero. eﬀect alleviated using upper bound thus inﬂuence component representativity model quantiﬁed reasonable precision even presence approximation errors. given distribution types cannot solved analytically. however given dataset whose elements distributed according divergence approximated follows representativity evaluates inﬂuence component goodness model regarding data distribution. calculate representativity component create second without described discrimination measure. then compare parameters estimated bayesian fashion i.e. regarded random variables whose distributions must determined sample data. parameters categorical dimensions corresponding distributions dirichlet concentrated probability mass distribution i.e. certain parameter estimate lower entropy value unbounded even negative continuous variables. also possible measure uncertainty every model parameter individually. work however want calculate aggregated value quantifying uncertainty estimation component thus entropies corresponding parameter distributions summation entropies naturally arises joint parameter distribution assumption continuous dimensions independent categorical ones categorical dimensions mutually independent. since absolute value entropy values categorical dimensions depends number categories entropies categorical dimensions depends number dimensions applications numbers diﬀerent desirable weight summands factors depending number categories dimension and/or number categorical dimensions. note consider mixing coeﬃcients here. distribution whole classiﬁer thus entropy value would added every component. entropies mentioned distributions contrast previous measures measure uses second-order distributions arise training distributions actual parameters cmm. details training models using second-order distributions found evaluate uncertainty whole classiﬁer could compute weighted average uncertainty values contained components using mixing coeﬃcients. additionally might take uncertainty second-order distribution models mixing coeﬃcients account. uncertainty modeled variances distributions. rule represented classiﬁer easily understandable human expert rules easily distinguishable. since categorical dimensions easily distinguishable humans consider continuous dimensions here. measure distinguishability components dimension dcont} ﬁrst project components onto yields univariate gaussians order restrict distinguishability measure unit interval omit normalizing coeﬃcients projected gaussians. also makes sure strongly overlapping gaussians easily distinguishable human assigned distinguishability value. assess distinguishability components regard dimension intersection point projected gaussians lies centers results run-time complexity required evaluate distinguishability component since continuous dimension iterate components classiﬁer compute intersection points projected gaussians. distinguishability rules deﬁned distinguishability rule lowest distinguishability. evaluating complete rule additional factors considered regarding interpretability rule human expert. second number diﬀerent terms dimension low. categorical dimension given number diﬀerent categories non-zero probability forming disjunctions. simplify categorical dimensions categories probability certain threshold considered categories dimension component continuous dimension number diﬀerent univariate gaussians counted. decide whether gaussians regarded diﬀerent hellinger distance gaussians. distance clearly ﬁxed threshold example regard gaussians identical threshold varied applications depending degree distinguishability desired. assess complete rule could average number diﬀerent terms categorical continuous dimensions. classiﬁer shown fig. resulting example. section investigate properties proposed measures detail analyzing correlations measures run-times conducting four case studies demonstrate measures used practical applications. case studies show measures used learning phase classiﬁer improve classiﬁcation performance active learning setting evaluating trained classiﬁer using on-line ﬁnally application phase classiﬁer. case studies seen illustrative examples; many ways using measures possible. ﬁrst experiments analyze correlations seven measures investigate dependencies. additionally measure run-time evaluations measures required compute correlations empirical evidence back theoretical run-times stated section experiment benchmark data sets. table spearman’s correlation coeﬃcients averaged seven interestingness measures benchmark data sets entries statistically signiﬁcant signiﬁcance level highlighted. repr table shows spearmans’s rank correlations computed seven interestingness measures averaged data sets. correlations statistically signiﬁcant signiﬁcance level highlighted bold typeface table signiﬁcant correlations informativeness positively correlated uniqueness. means isolated components cover many samples. furthermore components located relatively close components cover majority samples. fact many benchmark data sets consist real-world data normal distribution assumption fully satisﬁed. leads clusters modeled multiple components rather single component. also consistent importance negatively correlated uncertainty. uncertainty negatively correlated importance means components covering samples yield little additional information expressed entropy yields uncertainty. representativity positively correlated importance. fact components high mixing coeﬃcient comparison components model also high inﬂuence overall density function evaluated representativity measure. several combinations interestingness measures values correlation coeﬃcients quite. especially distinguishability measure signiﬁcant correlation measures. shows distinguishability measure evaluates completely diﬀerent aspects components classiﬁer measures. example component high distinguishability still either small inﬂuence decision boundary measured discrimination. apart distinguishability pair measures lowest correlation discrimination uniqueness. component high uniqueness mostly covers samples class uniqueness covers samples several classes. cases discrimination component i.e. inﬂuence decision boundary either high low. depends position component regard neighboring components decision boundary notably uniqueness component. altogether fact signiﬁcant correlations objective interestingness measures indicates measures cover many diﬀerent aspects knowledge understanding. also measured empirical run-times took compute results given table results presented table obtained using dedicated linux machine intel core running ghz. run-time measurements predominantly rough australian clouds credit_a credit_g ecoli glass heart iris pendigits phoneme pima quality ripley satimage seeds segment two_moons vehicle vowel wine yeast guideline estimate long takes evaluate individual measures actual applications. experimental implementation optimize many computations rely many caches possible. example inverse covariance matrices required evaluate densities already pre-computed training algorithm. thus contrast suggested theoretical run-time complexities interestingness measures stated section empirical run-times dominated matrix operations rather number samples data set. small data sets seeds ripley iris heart evaluations measures require less second. comparison pendigits quality data sets require highest run-times hours. regard measures representativity generally takes longest evaluate followed discrimination uniqueness. evaluation measures fast. experiments measures importance representativity uncertainty control based training process classiﬁer. training consists three steps step step additional pruning step consecutively executed convergence criterion met. step samples gradually assigned components classiﬁer step parameters classiﬁer updated according samples assigned them. pruning step unnecessary components removed classiﬁer. here focus pruning step consider three diﬀerent pruning methods resp method similar traditional pruning method used training component removed classiﬁer un-normalized responsibilities certain threshold. often threshold chosen means component removed eﬀectively responsible less sample training data. threshold means component responsible less samples threshold also possible case pruning done. figure comparison diﬀerent pruning methods applied benchmark data sets using -fold cross-validation. data ﬁrst reduced dimensions using normalized using z-transform. note images components pruned measure drops given threshold whereas images components pruned given threshold exceeded. contrast resp component considered mixing coeﬃcient relation average mixing coeﬃcient classiﬁer thus component removed importance certain threshold. since importance values interval thresholds interval considered. values close result slow pruning values close lead fast pruning. threshold means components whose mixing coeﬃcient average pruned. unct contrast resp impo method rely mixing coeﬃcients responsibilities takes completely diﬀerent approach. considers uncertainty component removes components whose uncertainty value lies certain threshold. uncertainty component unbounded thus diﬃcult determine suitable threshold. however following examples provide good starting points choosing threshold value. fig. visualizes classiﬁcation errors test data numbers resulting classiﬁer components numbers required training steps three diﬀerent pruning methods. used benchmark data sets section experiment australian clouds phoneme satimage. additionally added page_blocks data machine learning repository consists real-world data. seen resp method yields best results thresholds range still requires larger number steps methods. contrast resp impo pruning method leads faster decrease number required steps resulting similar test error number components. threshold used unct method rather sensitive type data used. australian data contains categorical dimensions addition continuous ones leads rather diﬀerent entropy values thus diﬀerent thresholds. conclusion state importance uncertainty used alternatives responsibilities pruning step training algorithm reducing number required steps thus making training process faster. however research automatic determination pruning threshold behavior pruning methods diﬀerent data sets necessary. experiment analyze components trained classiﬁer measures order help potential user classiﬁer understanding components rules extracted components trained classiﬁer phoneme data machine learning group using restriction diagonal covariance matrices enable rule extraction. fig. shows resulting classiﬁer. components colored according class densities opacity dependent mixing coeﬃcient. background plot colored according posterior probabilities classiﬁer. black solid line decision boundary. distinguishability measure deduce components least easily distinguished. conﬁrmed looking fig. shows components overlap great extent. components best distinguished others projected coordinate axes obvious especially case component well separated components. second measure evaluated table discrimination. since discrimination value component negative know classiﬁcation performance could increased removed component classiﬁer. case classiﬁcation error test data decreases also components important classiﬁcation decision since dominated component fig. figure fraction data phoneme data together trained classiﬁer. data reduced dimensions using pca. components ﬁrst class visualized dashed green ellipses numbered center. components second class shown dotted blue ellipses numbered center. informativeness measure info table yields components especially greatest distance components. fact nearly overlap components fig. least informative components components since almost totally overlap. ﬁnal measure evaluated table uniqueness. components highest uniqueness components particular means mostly cover samples class. components lowest uniqueness means cover samples classes. interestingly component nearly completely overlaps component higher uniqueness value. example shows proposed measures easily used analyze trained classiﬁer. emphasized evaluation classiﬁer also work described case higher dimensional input spaces looking two-dimensional visualization would help much. depending application diﬀerent goals could achieved ranking components classiﬁer using approach. reduce number components example might consider removing component since received worst evaluation four seven measures lowest uniqueness representativity importance highest uncertainty. pool-based active learning paradigm repetitively asks users provide label information unlabeled data e.g. order train classiﬁer based data. based assumption unlabeled data acquired costs whereas retrieving label information costly. therefore beginning learning cycle large unlabeled data small labeled data available. based data classiﬁer trained used build ranking unlabeled data based estimate likely sample increase performance classiﬁer labeled. selection strategy uses estimates decision basis selecting learning cycle next sample samples going labeled. fig. depicts learning cycle standard solid arrows. typically large pool unlabeled samples small labeled samples available beginning makes possible classiﬁer trained. then queried based selection strategy presented oracle labeling. labeled samples added classiﬁer updated. long given stopping condition cycle started. process starts generative model described section trained unsupervised way. process labels become available considered train cmm. general underlying generative model remains unchanged process. process extended transductive learner aims updating underlying model using uniqueness measure determines ambiguous knowledge modeled component uniqueness value determined component smaller predeﬁned threshold component considered disputed classes. case samples component responsible determined sample-based classiﬁer called resp-knn trained used transductively label underlying samples. then trained resulting components fused non-disputed components necessary). consequently information provided uniqueness measure allows iteratively improving process. information regarding transductive learner extension process also shown fig. case study presented section embed probabilistic generative model kernel function support vector machine described case study uniqueness measure applied once ﬁnal cycle emphasize possible performance improvement. conducted experiment mnist handwritten digits data consists training test gray-scaled images handwritten digits reduced size input dimensions applying principle component analysis thus keeping total variance. furthermore data z-normalized. process started initially labeled samples selected based selection strategy figure learning curve active training generative kernel mnist data indicates test accuracy reﬁning underlying kernel means uniqueness measure. process stopped adequate number labeled samples available. thus possible improve underlying density model means uniqueness measure sketched above. then density model better exploit structure information contained labeled samples. fig. illustrates learning curve test set. moreover emphasizes employing uniqueness measure classiﬁcation error reduced half. promising result indicates possible improvement standard process. regular time intervals underlying density model evaluated means uniqueness measure necessary reﬁned. last experiments deals application phase classiﬁer. consider task novelty detection i.e. task detecting need components model newly occurring processes input space known training time example based intrusion detection data speciﬁcally data attack types neptune smurf ipsweep satan. re-sampled data able consider longer time spans. four data sets constructed starts samples background traﬃc then attack phase starts lasts time step attack phase samples represent respective attack present ratio finally continue samples drawn background traﬃc observe novelty detectors react attack. classiﬁers trained separate training data consisting samples background traﬃc only. goal detect need component models data originating attack network. shows intrusion detection systems detect kinds attacks run-time build relying proposed interestingness measures. figure novelty detection representativity measure comparison novelty detector described intrusion detection data sets. grayed region marks time attack occurred. light gray area indicates size sliding window used representativity measure attack started stopped again. order achieve goal evaluate representativity overall classiﬁer newly observed sample. parzen window estimator representativity measure used evaluation repr computed sliding window recent samples. fig. representativity values classiﬁers shown. sake visualization representativity values normalized mean variance initial phase contains background traﬃc representativity values classiﬁers high. attack starts time step representativity values decrease sliding window ﬁlled data contains attack samples. representativity values stay small attack network stops time step then representativities classiﬁers rise high values similar ones initial phase. comparison fig. contains results obtained novelty detection technique called novelty proposed technique measures whether newly observed sample lies within certain region around classiﬁer components accumulates reward punishment values accordingly. fig. depicts accumulated novelty values. sake visualization values also normalized mean variance conclusion state representativity measure used detect need components classiﬁer. representativity sensitive novel samples novelty measure robust certainly worth investigate techniques combine advantages both. article presented approach support even automate process knowledge understanding important data mining step. however proposed measures seen ﬁrst step direction aspects real world applications could considered yet. knowledge understanding refer task analyzing knowledge extracted data order gather meta-knowledge either done oﬄine online applying knowledge. depending concrete application part measures useful. also preferable assess continuous categorical dimensions separately. measures proposed article objective measures relation subjective interestingness measures. example informativeness clearly related novelty conventional interestingness measure since rule quite informative also case user regards rule providing highly novel kind knowledge. uniqueness seen related understandability high uniqueness value implies rule associated single class thus making better understandable. importance discrimination measures reﬂecting usefulness component expressing relative weight classiﬁer inﬂuence decision boundary. another measure related usefulness uncertainty high value states parameters process underlying resulting component cannot precisely determined decreases usefulness component. last measure representativity expresses well component models data positive eﬀect understandability overall model. deﬁned various measures generative probabilistic classiﬁer. practical applications classiﬁer used combination discriminative classiﬁers support vector machines shown probabilistic classiﬁers continuous input dimensions functionally equivalent certain kinds support vector machines radial basis function neural networks fuzzy classiﬁers nonlinear fisher discrimination techniques relevance vector machines direct kernel machines. thus measures deﬁned could adapted kinds classiﬁers well. semantics underlying knowledge classiﬁers diﬀerent idea investigated detail. another option probabilistic model contained classiﬁers instance already shown create data dependent kernel function svm. article several cases deﬁned investigated demonstrate value applicability proposed measures. shown measures used control training process classiﬁer analyze knowledge contained trained classiﬁer support tasks novelty detection application phase classiﬁer. applications possible e.g. pruning training process extraction ranking rules contained classiﬁer concept drift obsoleteness detection. future work also focus measures quantiﬁcation experience gained applying knowledge extracted data extending training techniques apply large data sets applications measures e.g. ﬁeld collaborative intrusion detection cyber-physical systems", "year": 2016}