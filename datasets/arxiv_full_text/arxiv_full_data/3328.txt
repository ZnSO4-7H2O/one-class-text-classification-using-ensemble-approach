{"title": "A Deep Generative Deconvolutional Image Model", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "A deep generative model is developed for representation and analysis of images, based on a hierarchical convolutional dictionary-learning framework. Stochastic {\\em unpooling} is employed to link consecutive layers in the model, yielding top-down image generation. A Bayesian support vector machine is linked to the top-layer features, yielding max-margin discrimination. Deep deconvolutional inference is employed when testing, to infer the latent features, and the top-layer features are connected with the max-margin classifier for discrimination tasks. The model is efficiently trained using a Monte Carlo expectation-maximization (MCEM) algorithm, with implementation on graphical processor units (GPUs) for efficient large-scale learning, and fast testing. Excellent results are obtained on several benchmark datasets, including ImageNet, demonstrating that the proposed model achieves results that are highly competitive with similarly sized convolutional neural networks.", "text": "deep generative model developed representation analysis images based hierarchical convolutional dictionary-learning framework. stochastic unpooling employed link consecutive layers model yielding top-down image generation. bayesian support vector machine linked top-layer features yielding max-margin discrimination. deep deconvolutional inference employed testing infer latent features top-layer features connected max-margin classiﬁer discrimination tasks. model efﬁciently trained using monte carlo expectationmaximization algorithm implementation graphical processor units efﬁcient large-scale learning fast testing. excellent results obtained several benchmark datasets including imagenet demonstrating proposed model achieves results highly competitive similarly sized convolutional neural networks. convolutional neural networks effective tools image video analysis characterized feedforward sequential application convolutional ﬁlterbanks pointwise nonlinear functions pooling. supervision typically implemented fully-connected layer deep architecture usually softmax classiﬁer based image patches. setting imposes sparsity constraints dictionary weights data represented. image analysis/processing tasks rather using patch-based model recent interest deconvolutional networks uses dictionary learning entire image dictionary element convolved sparse weights exist across entire image. models termed deconvolutional because given learned dictionary features test found deconvolution. build deep deconvolutional models typically employ pooling step like convolutional ﬁlterbank replaced library convolutional dictionaries. paper develop deep generative model images based convolutional dictionary learning. test dictionary elements learned deconvolutional inference employed like aforementioned research. proposed method related chen complete top-down generative model developed stochastic unpooling connecting model layers chen trained layer separately sequentially ﬁnal coupling overall model further chen bayesian posterior inference approximated model parameters scales poorly. employ monte carlo expectation maximization point estimate learned dictionary elements parameters classiﬁer allowing learning large-scale data fast testing. forms stochastic pooling applied previously deﬁned stochastic pooling context energybased boltzmann machine zeiler fergus proposed stochastic pooling regularization technique. unpooling employed yielding top-down generative process. denoting element drawn |/b). laplace vectorized matrices appropriately sized identity matrix. maximum posterior solution laplace prior imposed independently component corresponds optimization problem hyperparameters play roles analogous sparsity manifested consequence geometry imposed operator; solution sparse probability draw laplace prior sparse impose sparsity within generative process consider spike-slab prior model motivated idea image represented terms convolutional dictionary elements shared across images. proposed deep model similarly motivated idea feature maps also represented terms convolutions dictionary elements. consider two-layer model impose supervision employ bayesian support vector machine used supervised dictionary learning proposed generative model amenable bayesian analysis bayesian learned simultaneously deep model. models donahue zeiler fergus train jointly instead trained separately using learned features paper makes several contributions deep model developed images based convolutional dictionary learning; model generative form earlier stochastic unpooling method proposed linking consecutive layers deep model. integrated layer model abling max-margin supervision training. algorithm implemented large-scale learning fast testing; demonstrate state-of-the-art classiﬁcation results several benchmark datasets demonstrate scalability analysis imagenet dataset. single layer convolutional dictionary learning consider images {x}n rnx×ny×nc represent number pixels spatial dimension; gray-scale images images. start relating model optimization-based dictionary learning work respectively. motivations details model elucidated making connections previous work. speciﬁcally consider optimization problem convolution operator. rnx×ny×nc typically spatially-dependent weights size layers spatially convolved summing dictionary elements manifests approximation layers form mairal norm imposing sparsity frobenius norm mairal imposing expected-energy constraint dictionary element; mairal convolution used otherwise dictionary elements replace representation weights connected stochastic operation unpool detailed below. motivated discussed above represented terms convolutions second-layer dictionary elements forms priors prior unchanged. tensor layer/slice k}). matrix pooled version speciﬁcally partitioned contiguous spatial pooling blocks pooling block dimen= ny/p sion pooling block all-zeros except non-zero element non-zero element deﬁned speciﬁcally element denoted mapped pooling block denoted vector zeros single location non-zero element identiﬁes location single non-zero element pooling block function unpool stochastic operation deﬁnes hence unpooled constitute sparse impose denotes symmetric dirichlet distribution; dirichlet distribution parameters equal value indicated dir. introducing two-layer model drawn spike-slab prior however extend three-layer model pooling blocks deﬁned convolutional dictionary representation similarly constituted stochastically unpooled generate continued layers hierarchical convolutional dictionary learning learns multi-scale structure weights consider {{d}kl drawing image generated starting {s}kl {s}kl− kl−= constituted convolving {s}kl summing dictionary elements performing stochastic unpooling. process convolution stochastic unpooling proceeds layers ultimately yielding bottom layer. note implementation detail found useful experiments. unpooling performed pooling block single non-zero element non-zero element deﬁned unpooling block speciﬁed vector all-zeros single one. slightly modiﬁed implementation )-dimensional considered zeros single dimensional. single also located among ﬁrst location non-zero element identiﬁes location single non-zero element pooling block before. however non-zero element position elements pooling block zero. imposes sparsity feature maps demonstrated supplementary material yields model elements feature relatively small encouraged zero. turning dictionary elements small weights analogous dropout used model also found yield slightly better classiﬁcation performance. supervision bayesian svms assume label associated images training denoted n)}n wish learn classiﬁer maps top-layer dictionary weights {s}kl associated label unfolded vector desire classiﬁer mapping goal learn dictionary classiﬁer jointly. generative process overall model activation weights drawn layer discussed sec. weights c-class class label manifested. speciﬁcally learns linear function given data class label deﬁned vectors {β}c connecting top-layer features classiﬁer play role analogous fullyconnected layer softmax-based constitute supervision max-margin svm. hence proposed model generative construction labels images. model training previous section described supervised deep generative model images based deep convolutional dictionary learning stochastic unpooling bayesian svm. conditional posterior distribution model parameter written closed form assuming model parameters ﬁxed relatively small datasets therefore employ gibbs sampler training deconvolutional inference yielding approximation posterior distribution parameters. large-scale datasets prohibit application standard gibbs sampling. large data stochastic mcem maximum posterior estimate model parameters. top-layer dicn tionary weights discussed above otherwise; indicator speciﬁes binary svms consideration. notational simplicity omit superscript remainder section consider bayesian binary learning tasks labeled data yn}n practice binary classiﬁers learned jointly value depends one-versus-all classiﬁer speciﬁed. hinge loss regularization term controls complexity tuning parameter controlling trade-off between error penalization complexity classiﬁcation function. decision boundary deﬁned sign) decision rule classifying either recently polson scott showed linear classiﬁer minimizing equivalent estimating mode pseudo-posterior pseudo-likelihood function prior distribution vector coefﬁcients choosing maximize corresponds prior associated polson scott showed admits location-scale mixture normals representation introducing latent variables note exponential gaussian described polson scott encourages data augmentation variable permits efﬁcient bayesian inference henao details). beneﬁts bayesian formulation svms ﬂexibly specify behavior able adaptively regularize specifying prior well. ﬁrst datasets show three classiﬁcation results using part model pretraining only model used extract features futures sent separate linear yielding -step procedure. unsupervised model model includes deep generative developed sec. also trained unsupervised manner features extracted model sent separate linear therefore also -step procedure. supervised model complete reﬁned supervised model developed sec. sec. imagenet used assess scalability model large datasets. case learn supervised model initialized priors proposed online learning method mcem based rmsprop developed training inference mini-batch size decay rate implementation mcem learning based publicly available cuda caffe toolbox contains signiﬁcant modiﬁcations model. model takes around week train imagenet using nvidia geforce titan memory. testing validation imagenet takes less minutes. subsequent tables providing classiﬁcation results best results achieved model bold. mnist data training testing images digits two-layer model used dictionary element size ﬁrst second layer respectively. pooling size number dictionary elements layers respectively. numbers dictionary elements obtained setting initial dictionary number relatively large value pretraining step discarding infrequently used elements counting corresponding binary indicator effectively inferring number needed dictionary elements chen table summarizes classiﬁcation results mnist. -layer supervised model outperforms modern approaches. methods outperforms complicated convnet model elastic disortions mcdnn combines several deep convolutional neural netφs sample full conditional posterior distribution number samples; seek maximize constituting recall conditional distributions gibbs sampler model analytic; allows convenient sampling local parameters conditioned speciﬁed global parameters therefore aforementioned sampling implemented efﬁciently approximation m-step implemented stochastic gradient descent stochastic mcem gradient iteration using mcem form mcem data-dependent latent variables φtest integrated expectation except toplayer feature ψtest gradient descent step yields point estimate. top-layer features sent trained predict label. details training inference provided experimental results present results mnist cifar- caltech imagenet datasets. hyperparameter settings used experiments; tuning required datasets. ﬁrst datasets model learned gibbs sampling. found effective layer-wise pretraining employed deep generative models pretraining performed sequentially bottom layer layer unsupervised manner. details layerwise pretraining discussed pretraining step average collection samples obtain parameter values ﬁrst discarding burn-in samples. following pre-training reﬁne entire model jointly using complete gibbs conditional distributions. burn-in iterations performed works speciﬁcally used committee convolutional networks width normalization elastic distortions data; used elastic distortions single convolutional neural network achieve similar error approach. examine performance proposed model plot selection top-layer dictionary elements learned supervised model right fig. left show corresponding elements inferred unsupervised model. seen elements inferred supervised model clearer whereas elements learned unsupervised model blurry similar results reported erhan since model generative using generate digits training mnist straightforward examples shown fig. also demonstrate ability model predict missing data reconstructions shown fig. results provided cifar- cifar- dataset composed classes natural images images training images testing. apply preprocessing technique global contrast normalization whitening used maxout network three-layer model used dictionary element size ﬁrst second third layer. pooling sizes numbers dictionary elements layer augment data translation horizontal ﬂipping used models achieve error. result competitive state-of-art integrates supervision every hidden layer constrast impose supervision layer. table summarizes classiﬁcation accuracy models related models. cifar- dataset cifar- size format except contains classes. settings cifar. table summarizes classiﬁcation accuracy model related models. seen results also close state-of-the-art caltech balance speed performance resize images caltech caltech followed local contrast normalization three layer model adopted. dictionary element sizes size pooling regions dictionary sizes layer caltech caltech tables summarize classiﬁcation accuracy model related models. using data inside caltech caltech training results exceed previous state-of-art results substantial margin best results obtained models without using deep convolutional models baseline implemented neural network consisting three convolutional layers fully-connected layers ﬁnal softmax classiﬁer. architecture three convolutional layers model. fully-connected layers neurons each. results neural network trained dropout carefully parameter tuning also shown tables veriﬁes model complexity needs selected based size data. also consistent results reported zeiler fergus classiﬁcation performance poor without training model imagenet. state-of-the-art results datasets achieved pretraining deep network large dataset imagenet consider similar imagenet pretraining sec. also observe table fewer training images accuracy diminishes. fig. shows selected dictionary elements learned unsupervised supervised model illustrate differences. observed dictionaries without supervision tend reconstruct data dictionary elements supervision tend extract features distinguish different classes. example dictionaries estimator model described sec. achieves top- error rate testing close zeiler fergus model averaging used bayesian inference often improves performance considered here. speciﬁcally running mcem algorithm estimate global parameters. using mini-batch data leverage analytic gibbs updates sample posterior therefore obtain multiple samples global model parameters. collect approximate posterior samples every iterations retain samples. averaging predictions samples gives top- error rate outperforms combination zf-nets. limited additional training time required model averaging. illustrate model generalize datasets follow setup keeping convolutional layers imagenet-trained model ﬁxed train bayesian classiﬁer using training images caltech caltech image resized results shown tables obtain state-of-art results caltech caltech result competitive stateof-the-art result combines spatial pyramid matching deep convolutional networks results demonstrate provide comparable results data generalization tasks also scaling well. supervised deep convolutional dictionary-learning model proposed within generative framework integrating bayesian support vector machine form stochastic unpooling. extensive image classiﬁcation experiments demonstrate excellent classiﬁcation performance small large datasets. top-down form model constitutes generative form deep deconvolutional network unique learning inference methods. learned supervision double sides image edges. model generative example generate images using dictionaries trained faces easy category random top-layer dictionary weights similar mnist example also show fig. interpolation results face data half image missing. though background little noisy face recovered great detail third layer dictionaries. results provided train model -category imagenet dataset consists .m/k/k training/validation/test images. training process follows procedure previous work smaller image dimension scaled crop chosen random locations within image. data augmented color alteration horizontal ﬂips layer convolutional model employed numbers dictionary elements layer pooling ratios number parameters model around million. emphasize intention directly compete best performance imagenet challenge requires consideration many additional aspects provide comparison dataset similar network architecture table", "year": 2015}