{"title": "Learning STRIPS Operators from Noisy and Incomplete Observations", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Agents learning to act autonomously in real-world domains must acquire a model of the dynamics of the domain in which they operate. Learning domain dynamics can be challenging, especially where an agent only has partial access to the world state, and/or noisy external sensors. Even in standard STRIPS domains, existing approaches cannot learn from noisy, incomplete observations typical of real-world domains. We propose a method which learns STRIPS action models in such domains, by decomposing the problem into first learning a transition function between states in the form of a set of classifiers, and then deriving explicit STRIPS rules from the classifiers' parameters. We evaluate our approach on simulated standard planning domains from the International Planning Competition, and show that it learns useful domain descriptions from noisy, incomplete observations.", "text": "agents learning autonomously realworld domains must acquire model dynamics domain operate. learning domain dynamics challenging especially agent partial access world state and/or noisy external sensors. even standard strips domains existing approaches cannot learn noisy incomplete observations typical real-world domains. propose method learns strips action models domains decomposing problem ﬁrst learning transition function states form classiﬁers deriving explicit strips rules classiﬁers’ parameters. evaluate approach simulated standard planning domains international planning competition show learns useful domain descriptions noisy incomplete observations. developing agents ability autonomously world major goal artiﬁcial intelligence. important aspect development acquisition domain models support planning decision-making operate effectively world agent must able accurately predict actions succeed effects actions have. reliable action model acquired agent usefully combine sequences actions plans order achieve wider goals. however learning domain dynamics challenging problem agents’ observations noisy incomplete; actions non-deterministic; world noisy contain many irrelevant objects relations. paper consider problem acquiring explicit domain models experiences agent exploring world agent’s observations incomplete observations actions subject noise. domains consider relational strips domains although approach potential extended expressive domains. given autonomous learning setting assume weak domain model agent knows identify objects acquired predicates describe object attributes relations knows types actions perform appropriate contexts actions effects. experience world developed observing changes object attributes relations motor-babbling primitive actions. approaches learning strips operators handle noisy incomplete observations develop two-stage approach problem decouples requirement tolerate noisy incomplete observations requirement learn compact strips operators. ﬁrst stage learn action models constructing kernel classiﬁers tolerate noise partial observability whose action models implicit learnt parameters classiﬁers similar work mour˜ao however additionally method learn preconditions well effects suggested explored earlier work. also evaluate additional kernels learning problem select better performing alternative. initial action model learnt ﬁrst stage acts noise-free fully observable source observations extract explicit action rules. second stage devise novel method derive explicit strips operators model implicit kernel classiﬁers. experiments resulting rules perform well original classiﬁers providing compact representation action models suitable automated planning systems. learning problem domain tuple ﬁnite world objects ﬁnite predicate symbols ﬁnite actions. predicate action also associated arity. ﬂuent expression statement form arity state ﬂuent expressions possible states. since state observations incomplete assume open world unobserved ﬂuents considered unknown. state ﬂuent expression true negation ﬂuent expression true ﬂuent expression unobserved. action deﬁned preconditions prea effects effa. strips domains prea ﬂuent expressions effa ﬂuent expressions negated ﬂuent expressions. action preconditions effects also parameterised. action parameters replaced objects said action instance. objects mentioned preconditions effects must listed action parameters task learning mechanism learn preconditions effects prea effa data generated agent performing sequence randomly selected actions world observing resulting states. sequence states action instances denoted instance data consists observations sequence states action instances state observations noisy incomplete action failures allowed agent attempt perform actions whose preconditions unsatisﬁed. cases world state change observed state still noisy incomplete. make accurate predictions domains action failures permitted learning mechanism must learn preconditions effects actions. previous work fulﬁls requirements learning models setting consider. autonomous robotics various techniques exist learn preconditions effects actions noisy partially observable worlds however none approaches learn relational models. conversely much previous work learning relational action models relies provision prior knowledge action model. strategies include seeding initial models approximate planning operators using known successful plans excluding action failures presence teacher knowledge unlikely available autonomous agent learning dynamics domain. additionally approaches capable learning either partial observability noise form approaches handle generating implicit action models must used black-box make predictions state changes generate symbolic action representations. extract rules classiﬁers based intuition discriminative features contribute classiﬁer’s objective function. similar insight underlying feature selection methods type rank feature according sensitivity classiﬁer’s objective function removal feature approach differs features selected separately individual examples rather across entire training deﬁne stopping criterion identiﬁes selected features longer form rule. work also links earlier work version spaces associated greedy search underlie many approaches rule learning rule search beneﬁts extra information guide search form weights associated hypothesis previously trained statistical classiﬁers highly robust noise incomplete observations. basis approach division learning problem parts initially classiﬁcation method used learn predict effects actions strips rules derived resulting action representations. deﬁne implicit action model model domain implicit learnt parameters classiﬁers explicit action model domain model described strips rules. learning implicit action model approach follows earlier work encodes learning problem terms inputs outputs classiﬁers. however none methods generate explicit action models. following approach mour˜ao encode state descriptions ﬁxed dimension vector representation considering objects mentioned action parameter list. sufﬁcient learn strips rules. action instance arguments therefore restrict state description possible ﬂuents whose arguments on}. also schematise descriptions replacing i-th action parameter label argi whenever appears ﬂuent. thus state descriptions written terms action parameters terms speciﬁc objects. ﬁxes small number objects consider action well roles allows relational state descriptions encoded vector possible ﬂuent state maps exactly possible ﬂuent state. encode state descriptions vectors vector corresponds possible ﬂuent could exist schematised state description. value ﬂuent true false wildcard value unobserved. state previous blocksworld example descriptions pickup action would include schematised form prior successor states sprior ssucc sprior pickup ssucc respectively give training example. descriptions conversely context stack action contain action parameters giving sprior ssucc obtain vprior ∗∗∗∗∗ vsucc ∗∗∗∗∗ vprior −∗−∗− vsucc given vectorised state descriptions changes vector vdiﬀ derived training example i-th vdiﬀ classiﬁers learns implicit action model. classiﬁer corresponds particular action domain predicts i-th changes vector. thus sprior ssucc training example input classiﬁer vprior target value vdiﬀ voted perceptron classiﬁers equipped kernel function previously applied problem learning action models computationally efﬁcient known tolerate noise take similar approach. mour˜ao used voted perceptrons combined kernel same same number bits equal values same calculation bits unobserved values excluded. features kernel possible conjunctions ﬂuents seemingly ideal learning action preconditions arbitrary conjunctions ﬂuents. however pac-learnable perceptron using kernel examples exist make exponentially many mistakes therefore consider alternative k-dnf kernel whose features possible conjunctions ﬂuents classiﬁers trained ﬁrst step deriving explicit action rules extract individual per-effect rules predict ﬂuent isolation. look combine rules extract postconditions section rule extraction process takes input classiﬁer returns preconditions predict ﬂuent corresponding change action performed. example blocksworld domain preconditions extracted classiﬁers stack shown figure figure node contains vector corresponding possible precondition weight assigned vector voted perceptron model. level lattice contains vectors fewer feature level above. lines join parent children nodes solid lines link candidate parent rule level children level below dashed lines link children alternative parent. shaded nodes preconditions selected iteration lattice. positive support vector seed vector weight following rule extraction algorithm child whose parents least weight difference vector chosen next candidate rule. process ends rule children negative counterexample training data support vectors corresponding target value parameters learnt classiﬁer effect predicted classiﬁer. predicted value weighte otherwise. child vector distinct vector obtained replacing single value similarly parent vector obtained replacing *-valued value basic intuition behind rule extraction process discriminative features contribute weight example. thus rule extraction process operates taking positive support vector repeatedly deleting feature contributes least weight stopping criterion satisﬁed. leaves discriminative features underlying example used form precondition. example process extracting rules shown figure outline algorithm figure follows. take positive support vector turn conjunction rulev covers cover negative training examples every child rulev covers least negative example. construct rulev greedy algorithm ﬁrst takes candidate rule repeatedly creates candidate rule choosing value. chosen considering difference weights between current candidate figure per-effect rules generated blocksworld stack action examples world noise observability. weights shown square brackets. fluents bold neither implied true action speciﬁcation. many ﬂuents later excluded rule combination process rules extracted voted perceptron kernel support vectors support vectors whose predicted values positive support vectors instances rule learnt perceptron used seed search rules. extraction process aims identify remove irrelevant bits support vector using voted perceptron’s prediction calculation removing resulting removes least discriminative current candidate rule. step candidate rule tested training examples. classiﬁes negative training example positive rule general rulev previous candidate rule otherwise process repeats. result rules action predicting particular output changes. many rules positive support vector consisting preconditions which satisﬁed predict output change. rule extraction process described produces rules action blocksworld stack action shown figure however strips expect single rule action consisting preconditions effects deﬁnition blocksworld stack action given section rule combination process therefore builds single strips-like rule action rules produced rule extraction process vector representing i-th preconditions changes holds. rule combination generates rule j-th element vrule given deﬁnitions section directly convert single state vector vrule effects erule precondition effect strips format. without noise partial observability combination process straightforward conjunction preconditions effects rules action i.e. however learning noisy examples unwanted additional ﬂuents introduced per-effect rules noisy support vectors. similarly incomplete training examples mean necessary ﬂuents missing individual per-effect rules. section describe approach identify eliminate ﬂuents introduced noise adding ﬂuents omitted partial observability. support process choosing different potential rules contain noisy ﬂuents omit necessary ﬂuents introduce ﬁltering functions. acceptprecons takes existing precondition effects action assesses whether precondition vnew predicts effects least well current precondition. accepteﬀects takes existing precondition effects action assesses whether precondition predicts effect enew least well predicts current effects. describe acceptprecons accepteﬀects detail section ﬁltering functions place describe rule combination process generates strips rules combining reﬁning per-effect rules. figure gives outline algorithm described below. action process derives rule rules produced rule extraction ordered weightei weightej process ﬁrst initialises vrule highest weighted precondition sets erule rule reﬁned combining remaining per-effect rules turn order highest weight. time process combines current precondition vrule precondition next per-effect rule name vnext candidate precondition vcandidate. includes resolving conﬂicts vrule vnext. candidate precondition vcandidate merge vrule vnext. process reﬁnes vcandidate testing alternatives simplifyprecons setting vcandidate best result. vcandidate tested original vrule using acceptprecons. vcandidate accepted vrule updated vcandidate. similarly enext tested original effects erule using accepteﬀects. enext accepted erule updated erule enext. finally process reﬁnes erule testing alternatives simplifyeﬀects setting erule best result. next section describe subprocedures detail. combineprecons attempting combine ﬁrst check whether enext contradicts effect erule. effects conﬂict rules predict change ﬂuent rules different values ﬂuent preconditions. figure conﬂict.) conﬂict rule rejected assume rule action higher weighted baseline rule likely correct. conﬂicting ﬂuent three possible values ﬂuent could take preconditions true rule weight weighte variant calculated preferred variant value indicating nondiscriminative feature giving simplest precondition. however variant acceptable weight resulting precondition positive effects erule since precondition still predicts effects current precondition vrule. accepted ﬂuent locked value prevent later possibly noisy rules resetting locked ﬂuents recorded locks variable ∗-variant unacceptable -valued -valued cases considered provided positive weights effects. variants acceptable whichever highest average weight effects selected. neither variant acceptable conﬂict unresolved ﬂuent. long conﬂicts every ﬂuent resolved rule combination process continue candidate precondition. current rule rejected simplifyprecons combineprecons generated candidate precondition vcandidate simplifyprecons considers alternative less speciﬁc preconditions. creates alternatives vcandidate\\i vcandidate differs vrule. vcandidate\\i vcandidate except vcandidate\\i whenever ﬁltering function acceptprecons rates vcandidate worse vcandidate\\i associated ﬂuent vcandidatei simplifyeﬀects preconditions simplifyeﬀects tests effects removed vrule instance speciﬁc preconditions lower incidence effects extent accepteﬀects rejects them. effect tested effects accepteﬀects rejected removed erule. acceptprecons precondition ﬁltering function before even making comparison preconditions precondition vnew must checked ensure consistent classiﬁers supported training data. require notion coverage training set. coverage deﬁned account partial observability precondition vnew covers example effect none ﬂuents example state contradict ﬂuents rule preconditions example state changes rule effects. vnew form rule precondition vnew consistent classiﬁers erule vnew classiﬁed classiﬁer predicting change erule weighte erule vnew cover least training example changed erule coverse additionally acceptprecons uses differences precision recall identify reject precondition performs signiﬁcantly worse existing precondition. rejects preconditions either precision recall training drops substantially erule. since precision recall trade-off comparison made using f-score precondition effect fpree. ideally want precondition improve f-score must introduce tolerance account effects noise. instance suppose vnew general vrule vnew fact true rule. f-score vrule calculated subset training examples vrule covers f-score vnew also includes training examples covers. training happens higher proportion training examples noisy outcome covered f-score vnew lower vrule. account effects noise allow f-score fvnewe drop fraction f-score existing precondition fvrulee effect erule. f-scores value precondition rejected. accepteﬀect effects ﬁltering function similarly compares f-scores. given compares well vrule predicts effect enew relative well predicts erule speciﬁcally compares fvruleenew fvrulee erule. identiﬁes effects inconsistent effects terms precision recall. particular effects occur fewer examples effects identiﬁed likely caused noise could conditional effects. effect rejected function f-score less fraction times f-score effect rule. efcombineprecons fects precondition denotes conﬂicting ﬂuent. resolve conﬂict weights vectors calculated cstack classiﬁers. accepted vcandidate simplifyprecons would consider alternative precondition last vcandidate different vrule. assuming compared vcandidate simplifyprecons original vrule unset vcandidate). vcandidate higher weight acceptprecons accepts vcandidate vrule vcandidate. conversely effect rejected accepteﬀects erule before. finally simplifyeﬀects uses accepteﬀects test relative prediction performance vrule effect changes. rule tested approach several simulated domains taken international planning competition http//ipc.icaps-conference.org/. domains differ terms number arity actions predicates number hierarchy types. main domain characteristics detailed table sequences random actions resulting states generated pddl domain descriptions used training testing data. data generated using random action generator available http//magma.cs.uiuc.edu/filter/ modiﬁed also generate action failures. table shows numbers objects used training testing data domain. different randomly generated training testing sets used. training testing sets sequences actions respectively. sequences contained equal mixture successful unsuccessful actions domains portions state space traversed once cases multiple shorter sequences actions generated randomly generated starting states. line previous work incomplete observations simulated randomly selecting fraction ﬂuents world observe action. remaining ﬂuents discarded reduced state vector generated observed ﬂuents. sensor noise simulated similarly ﬂipping value state vector probability ﬁrst tested performance different kernels learning implicit action model comparing results standard perceptron voted perceptron voted kernel perceptron. kernel k-dnf kernel tested. performance measured terms f-score predictions test sets. training blocks depot distributors trucks pallets hoists crates cities planes people road junctions drivers packages trucks rovers waypoints objectives cameras modes stores lander testing blocks depots distributors trucks pallets hoists crates cities planes people road junctions drivers packages trucks rovers waypoints objectives cameras modes stores lander formance voted perceptron without various kernels almost identical introduction unobserved ﬂuents noise voted perceptron performs better standard perceptron. however kernel improve performance unkernelised voted perceptron learning signiﬁcantly accurate action models. contrast k-dnf kernels produce signiﬁcantly accurate models kernel kernel figure gives comparison relative performance model. k-dnf kernels therefore represents signiﬁcant improvement previous work used kernel. light results -dnf kernel selected remainder experiments. next extracted explicit rules implicit action models. statistically signiﬁcant difference f-scores predictions made perceptron models made extracted rules also compared resulting models original domain descriptions using measure error rate error rate single action deﬁned number extra missing ﬂuents preconditions effects divided number possible ﬂuents preconditions effects rate error domain model actions error error rates indicate learnt models close actual strips domain deﬁnitions falling after around examples cases particular fully observable noiseless domains correct strips model given extracted rules fewer figure comparison performance different perceptrons learning action models random actions strips domains averaged across domains levels noise partial observability. error bars standard error. performance signiﬁcantly different models k-dnf kernel not. training examples except complex domain rovers. comparisons approaches literature difﬁcult differences learning settings. nevertheless notable error rates learnt action models comparison action models learnt domains error rates observability range around example action model shown figure demonstrating method derives compact strips-like rules even high levels incompleteness noise observations. also calculated f-scores predictions made learnt rules test sets f-scores noise levels observability above domains except rovers indicating practice rules correctly predict ﬂuents. rovers f-scores somewhat lower fewer training examples action domains possible ﬂuents. furthermore learning fast. longest-running example experiments takes hours single intel xeon processor train classiﬁers rule extraction combination. zenotravel example runs minutes. results demonstrate approach successfully learns strips operators noisy incomplete observations contrast previous work either generates explicit operators cannot tolerate noise incomplete examples tolerates noise incomplete examples generate explicit operators. also show empirically -dnf kernel appropriate choice figure results learning explicit action rules training examples varying levels observability noise simulated planning domains. error rate measures errors learnt domain model relative actual domain model f-score measures performance rules fully observable noiseless test domains approach depends decomposing learning problem stages learning implicit action models deriving explicit rules implicit models. crucially implicit models produce noise-free complete observations domain model learnt. alternative approach rule derivation process would apply existing action model learning techniques observations produced implicit models. however approach effectively restarts learning process ignoring information already learnt available perceptron models likely less efﬁcient. approach also depends strips scope assumption essentially identiﬁes objects relevant action ﬁxes roles. realworld scenarios apply. without learning must also consider state relating objects listed action parameters. implicit action models setting learnt using graphical representation states combined suitable graph kernel future work therefore plan extend rule extraction method derive rules classiﬁers trained graphical state representations. additional steps required efﬁciently handle complexity introduced requirement perform comparisons graphical state descriptions. positive results pac-learning existential conjunctive k-dnf concepts noise-free structural domains boolean relations apply learning implicit models suggesting approach scale graphical state representations. figure explicit action model output zenotravel domain training examples observability noise. missing ﬂuents bold italic incorrect ﬂuents bold. error rate example imperfect rules quite small effects performance future work improved eliminating reliability classiﬁers. authors grateful reviewers previous versions paper helpful comments. work partially funded european commission cognitive systems project xperience epsrc/mrc neuroinformatics computational neuroscience doctoral training centre university edinburgh.", "year": 2012}