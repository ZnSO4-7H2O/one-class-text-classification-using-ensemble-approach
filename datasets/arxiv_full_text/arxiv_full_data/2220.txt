{"title": "The Tensor Memory Hypothesis", "tag": ["cs.AI", "cs.LG", "q-bio.NC", "stat.ML"], "abstract": "We discuss memory models which are based on tensor decompositions using latent representations of entities and events. We show how episodic memory and semantic memory can be realized and discuss how new memory traces can be generated from sensory input: Existing memories are the basis for perception and new memories are generated via perception. We relate our mathematical approach to the hippocampal memory indexing theory. We describe the first detailed mathematical models for the complete processing pipeline from sensory input and its semantic decoding, i.e., perception, to the formation of episodic and semantic memories and their declarative semantic decodings. Our main hypothesis is that perception includes an active semantic decoding process, which relies on latent representations of entities and predicates, and that episodic and semantic memories depend on the same decoding process. We contribute to the debate between the leading memory consolidation theories, i.e., the standard consolidation theory (SCT) and the multiple trace theory (MTT). The latter is closely related to the complementary learning systems (CLS) framework. In particular, we show explicitly how episodic memory can teach the neocortex to form a semantic memory, which is a core issue in MTT and CLS.", "text": "abstract. discuss memory models based tensor decompositions using latent representations entities events. show episodic memory semantic memory realized discuss memory traces generated sensory input existing memories basis perception memories generated perception. relate mathematical approach hippocampal memory indexing theory. describe ﬁrst detailed mathematical models complete processing pipeline sensory input semantic decoding i.e. perception formation episodic semantic memories declarative semantic decodings. main hypothesis perception includes active semantic decoding process relies latent representations entities predicates episodic semantic memories depend decoding process. contribute debate leading memory consolidation theories i.e. standard consolidation theory multiple trace theory latter closely related complementary learning systems framework. particular show explicitly episodic memory teach neocortex form semantic memory core issue cls. still great puzzle brain easily deal continuous highdimensional signals images sounds time relies discrete concepts like jennifer aniston latter faculty apparent language clearly make statements discrete entities jennifer aniston american actress became famous television sitcom friends. argue concept might representation learning i.e. discrete entity represented vector real numbers. based latent representations diﬀerent declarative memory functions implemented particular episodic memory semantic memory. paper framework tensor decompositions mathematically describe declarative nature memory perception. eﬀectiveness tensor models realization technical memory functions well established explore relevance modelling human memories. representation learning might also basis perception memories formed mapping sensory inputs latent event representations stored episodic memories; also semantically decoded using tensor framework. thus sensory impressions interpreted brain become declarative thus verbally described. perception form semantic decoding sensor input well episodic semantic memory depend latent representations since brain must know entities entity classes understand interpret sensory inputs. describe ﬁrst detailed mathematical models complete processing pipeline sensory input semantic decoding i.e. perception formation episodic semantic memories declarative semantic decodings. contrast previous paper relate mathematical approach hippocampal memory indexing theory main theories forming episodic memories summary main hypothesis perception includes active semantic decoding process relies latent representations entities predicates episodic semantic memories depend decoding process. eventually memory consolidated hippocampal area neocortex. standard consolidation theory episodic memory ﬁnds representation neocortex essentially copy representations hippocampus. multiple trace theory episodic memory represented hippocampal area used train semantic memory neocortex. closely related complementary learning systems framework. discuss tensor memories context theories. particular show explicitly episodic memory teach neocortex form semantic memory core issue cls. paper organized follows. next section describe tensor memory models section discuss diﬀerent memory operations illustrate sensory inputs generate episodic memories. section discuss potential relevance model human perception human memories. section discuss memory consolidation. section contains conclusions make point brain might latent representations many additional functions prediction planning decision making. symbol represents entity associate latent vector aei. similarly assume predicate represented symbol latent representation propose probability triple statement part semantic memory modelled logistic function episodic memory representation time. symbol time instance latent representation aet. probability observation triple time θspot tucker decomposition whereas episodic memory would able retrieve fact semantic memory would represent note tensor models reconstruct known memories assigning high probability facts known true also assign high probabilities facts follow patterns found memory systems; thus realize form probabilistic inductive reasoning example consider know lives munich. probabilistic materialization happens factorization already predict also lives bavaria germany. generalization existing facts probabilistic inductive reasoning particular importance perception predicted triple probability might serve prior information extraction certain danger probabilistic materialization since might lead overgeneralizations reaching prejudice false memories eﬀectiveness tensor models technical semantic memories well established models calculated probability triple quadruple true. querying re-normalize model βθspo becomes proportional probability memory produces triple generative model. inverse temperature high highly likely triples produced. thus query answering implemented sampling process nonnegative models replace βθspo θspo. note associative memories similar concentration likely interpretations achieved exponentiation using polynomial energy functions fig. ﬁgure sketches hippocampal memory indexing theory. here represents sensory input relayed thalamus part forebrain forms input diﬀerent sensory processing paths. based sensory processing latent representation time instance generated. indicated earlier processing layers nodes activated higher layers smaller number scene-speciﬁc nodes active. mathematical model mapping described sensory inputs stored episodic memory —because event e.g. signiﬁcant novel attached emotion— index formed hippocampus. sparse weight pattern index sensory layers binds sensory activation patterns index recollecting memory past time corresponding index activated reactivates approximate weight patterns recall past previous events time simply means triples generated episodic memory using equation ﬁxed pattern might generated activation associative process. recall known entity applies generates triples semantic memory describing facts alternatively generate quadruples episodic memory describing events participated. triples could used language modules generate language i.e. verbally describe episodic semantic memory. also straightforward generate association e.g. retrieve entities semantically similar let’s aei. relate mathematical approach hippocampal memory indexing theory main theories forming episodic memories equation sensory input activates hierarchical multilayered activation pattern sensory layers cortex. indicated figure pattern speciﬁc towards higher sensory layers. thus also known deep convolutional neural networks given sensory input nodes activated hierarchy. following theory index formed hippocampus sensory impressions important remembered forming higher layers sensory hierarchy index. since representation sensory input becomes sparse toward higher order sensor processing layers representations diﬀerent sensory inputs become also orthogonal towards higher layers. sense index simply hierarchy complete index might involve large number neurons given sensory input activates small number them realizing sparse orthogonal distributed representation. feature typically present cnns connection assumed bidirectional activation index reactivate pattern memory recall back projection retrieving sensory pattern past episode. course back propagation realise gist episode. index performs binding memory patterns. instead hippocampus indexing neocortex probable participates hierarchical indexing scheme whereby indexes association cortex ventral dorsal streams) indexes rest neocortex thus hippocampal area sits perceptual hierarchy receiving input lower levels projecting back important biological function would recall previous episodic memories similar associate past emotional impressions predictions past actions past outcomes actions. formation index hippocampus highly complex interpret index associated weight patterns functional descriptions biological implementations indices explicit synaptic weights. details biological aspects index formation hippocampus found appendix. evidence time cells hippocampus recently found fact observed adult macaque monkey forms thousand neurons daily possibly encode information. time cells might related indices assumes form generalized nonlinear model. encoder-decoder networks basis neural machine translation systems example semantic decoding applied real-world images. cognitive neuroscience memory recollection stages described sometimes referred internal external stages internal generates pattern activation associative process. involves rapid unconscious interaction turn reactivates neocortical traces bound second stage cortical processes operate output ﬁrst stage reinstate conscious experience episode. involved conscious experience referred autonoetic consciousness process enables relive episodes subjective sense time self experienced episode possesses memory model second stage would interpreted generation triples episodic memory. fig. architecture implementing episodic memory. concrete example assume layer nodes corresponding subject predicate time activated. thus query would objects likely associated subject predicate time layer representation layer corresponding latent representations represented. nodes product layer calculate aesr aepr aetr since example query object latent representation object replaced ones layer second right decoder layer form aesr aepr aetr layer samples columns contain latent representations entities predicates time steps. following diﬀerent paths graph generate sample also sample marginalized distributions. since nonnegative tensor models belong class sum-product model marginalization means enter vector ones quantities marginalized. example marginalize would enter vector ones index layer predicates layer biologically interpreted neutral input. ﬁgure shows nicely entity communicates rest network latent representation. assume processing steps layers executed sequentially. here discuss distributed graphical implementations mathematical models. figure shows graphical structure layers. example given goal leads likely quadruples. second layer latent representations activated. latent representation unknown object ones indicated. third layer calculates aesr aepr aetr fourth layer calculates exploit multi-linear expression equation written interpreted activation pattern generated neocortex matched existing representations entities aeo. nonnegative tensor models also marginalize since tensor models belong class sum-product networks marginalization simply means application ones variable marginalized index layer note ﬁnal operation described equation product vector generated latent representations i.e. latent representations object i.e. general structure figure diﬀerent kinds tensor models whose implementations vary layer example rescal model calculates gpaes related many classical associative memory models. predicate matrix slice rescal’s core tensor. main diﬀerences classical associative memory models factors latent system trained end-to-end whereas classical systems rely form hebbian learning also classical memory models often auto-associative i.e. main concern restore noisy pattern whereas models considered associative predict object given subject predicate. predicate time apply vector ones layer object generation semantic memory episodic memory would biologically plausible. marginalization time index implemented simple iterative process shown section relationship memories supported cognitive studies brain memory functions argued semantic memory information individual encountered repeatedly often actual learning episodes blurred section discusses consolidation relationship episodic memory semantic memory detail. appears figure representations redundant. example appears several times ﬁgure. also layers represent latent representations layers represent indices. figure shows computational path without redundancies. also reﬂects entity sets subject object really identical. tensor models used previously memory models main focus learning simple associations compositional structures tensor product approach encoding binding realized tensor product composition tensor addition. star model predicates represented tensor products components predicates; triples considered here would subject predicate object. none approaches uses tensor decompositions. equation describes basic encoder-decoder system. made powerful integrating attention mechanisms serial processing recurrent structures part future work explore recent developments encoder-decoder approaches sensory processing semantic decoding. semantic prior combined triple extraction process involves visual attention based extracted bounding boxes. another line research worth exploring. memory consolidation controversial issue exist several theories concerning system consolidation memory. standard consolidation theory episodic memories hippocampal region memories ﬁrst encoded moved neo-cortex permanent form storage process hippocampus teaching cortex eventually fig. show information involves speciﬁc product node graphical representation figure ﬁgure also shows entities unique representations independent roles subject object. also layers identical figure layers reduced single representations shown here. nodes activation layer connected product node shown multiplicative bias discussed caption figure product node calculates aesr aepr aetr layer product nodes calculated form object sampled resulting probabilities layer although complexity network approximately number ﬁxed grow number entities predicates time steps. contrast explicit representations facts basis tensorbased memories number product nodes grows proportional number episodic facts stored. explicit fact representation might useful unusual facts cannot easily represented factorization models might related classical semantic network memory models knowledge graphs hypergraphs. alternative view given multiple trace theory clearly distinguishes episodic semantic memory argues hippocampus always involved retrieval storage episodic memories less necessary encoding semantic memories. episodic memory never transferred hippocampus neocortex episodic memories used train semantic memory located neocortex anterior temporal lobe basis complementary learning systems framework according theory eﬀective learning requires complementary systems located neocortex serves basis gradual acquisition structured knowledge environment other centered hippocampus allows rapid learning speciﬁcs individual items experiences. central claim framework hippocampus encodes information qualitatively diﬀerent neocortex words literal transfer information hippocampus cortex rather cortex learns distributed version hippocampus originally encoded. role hippocampus theory main purpose hippocampus form indices link sensory processing hierarchy aet. thus engram memory trace pair accordance mtt. course hippocampus also plays active role consolidation functions. beyond scope paper. semantic decoding semantic decoding episodic event would produce sets triples describing aet. episodic tensor model would require representations entities predicates well. decoding likely happening hippocampus semantic decoding episodic memory involves hippocampus neocortex memory neocortex proposed would straightforward time indices connection patterns memorable episodes would also build representations neocortex. simple mechanism would hippocampal indices reactivate past memory activation patterns trigger index formations neocortex replay. thus model representation episodic memory would similar hippocampus neocortex. would agree hypothesis. realized tensor decomposition model equation semantic memory would graphical structure similar episodic memory figure time-related structures right would removed core tensor calculation marginalization step described earlier might implementable biologically plausible process. iteration performed time perception i.e. semantic decoding sensory input. could realize episodic training process required mtt. concrete implementation form dynamic normalization might required. note although core tensor episodic memory ﬁxed slowly adapting core tensor semantic memory constantly changing integrating information. explicit triple generation episodic memory teaches semantic memory explicitly generating triples using equation produced during perception replay. mechanism would accordance mtt. discussed perform well generalization facts would represent sometimes called gist memories discussed contrast semantic memory also quite sharp munich part bavaria hard fact also perceived such. propose explicit semantic memory storage subset triples generated episodic decoding stored explicit semantic networks forming knowledge graphs corresponding hypergraph indices entities predicates nodes. representation cannot generalize facts. explicit memory currently part either mtt. three approaches episodic memory teaches neocortex form separate semantic memory core assumption cls. semantic memory becomes time-independent memory rely episodic memory particular aet. essence episodic memory represented would agree diﬀerent representation semantic memory. hand semantic decoding episodic memory relies entity representations predicate representations marginalization approach note forming semantic memories might sole role replay might also used improve implicit memories tasks like prediction control reinforcement learning case consolidation involved process likely happening sleep involving speciﬁc oscillation patterns sharp waves ripples relevance neural oscillations particular coupling theta gamma rhythms discussed would suggest indices entities formed area identiﬁed concept cells focussed responses individuals like actresses jennifer aniston halle berry. paper proposes assembly concept cells would encode given concept case index thus assumption making index might involve activation small assembly neurons uniquely identiﬁes entity recent studies found detailed semantic maps neocortex point clear might represent indices components latent representations. latent representations associated indices would certainly distributed brain. thus representation pattern concept hammer might activate brain regions associated typical appearance hammer also sound hammering activity hammering another example subject recalls person sensory impressions person restored. note entity distributed representation since index representation always jointly activated. quiroga formulates activation concept cells brings particular concept awareness embed within related circumstances enable creation associations memories consciousness. time activation concept cells points towards links related detailed semantic representations diﬀerent cortical areas. concepts subjective meaning attribute external stimuli depending want remember them. work presented paper extension hippocampal memory indexing theory main detailed theories forming episodic memory. extended model also considering semantic decoding explicit triples providing explicit models episodic semantic memory. approach built upon latent representations generalized entities representing e.g. objects persons locations predicates time instances. hippocampal memory indexing theory activation index past memory would activate representation association cortex might reconstruct sensory impressions past memories. useful function episodic memory would recall happened past episode similar current situation action applied consequences. contribution propose past representations also decoded semantically producing triples past memories. semantic decoding might important intermediate step generate language i.e. explicitly report perceived sensory inputs past episodes semantic knowledge. language course faculty speciﬁc humans. activations patterns might represent entity predicate time instance subsymbolic level whereas corresponding index represents concept discrete symbolic level. discussed transfer episodic hippocampus neocortex could realized model transfer core standard consolidation theory would assume mechanism. formation semantic memory introduced number concepts. particular show explicitly episodic memory teach neocortex form semantic memory core issue cls. although theory would agree semantic memory realized separately episodic memory would propose semantic decoding i.e. declarative part episodic memory closely linked semantic memory since rely latent representations entities predicates. demonstrated episodic semantic memories modelled using tensor decompositions. existence proof showing biologically plausible architectures implement episodic semantic memory. brain might diﬀerent mathematical structures although marginalization episodic memory basis approach semantic memory discussed strictly possible described sum-product models tensor decompositions. paper focussed memory models. propose functions like prediction planning reasoning decision making would indices latent representations well particular shortterm memory might exploit semantically decoded indices latent representations. cognitive control functions working memory functions typically associated prefrontal cortex.", "year": 2017}