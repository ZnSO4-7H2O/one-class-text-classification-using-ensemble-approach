{"title": "Learning Human Pose Estimation Features with Convolutional Networks", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "text": "paper introduces architecture human pose estimation using multilayer convolutional network architecture modiﬁed learning technique learns low-level features higher-level weak spatial model. unconstrained human pose estimation hardest problems computer vision architecture learning schema shows improvement current stateof-the-art. main contribution paper showing ﬁrst time speciﬁc variation deep learning able meet performance many cases outperform existing traditional architectures task. paper also discusses several lessons learned researching alternatives notably possible learn strong low-level feature detectors regions might cover pixels image. higher-level spatial models improve somewhat overall result much lesser extent expected. many researchers previously argued kinematic structure top-down information crucial domain purely bottom-up weak spatial model improve complicated architectures currently produce best results. echos many researchers like speech recognition object recognition domains experienced hardest tasks computer vision determining high degree-of-freedom conﬁguration human body limbs complex self-occlusion self-similar parts large variations clothing body-type lighting many factors. challenging scenario problem monocular image prior assumptions made using motion models pose models background models common heuristics current state-of-theart systems utilize. finding face frontal side view relatively simple determining exact location body parts hands elbows shoulders hips knees feet sometimes occupy pixels image front arbitrary cluttered background signiﬁcantly harder. best performing pose estimation methods including based deformable part models typically based body part detectors. body part detectors commonly consist multiple stages processing. ﬁrst stage processing typical pipeline consists extracting sets low-level features sift ﬁlters describe orientation statistics local image patches. next features pooled local spatial regions sometimes across multiple scales reduce size representation also develop local shift/scale invariance. finally aggregate features mapped vector either input standard classiﬁer support vector machine next stage processing much work devoted engineering system produce vector representation sensitive class remaining invariant various nuisance factors alternative approach representation learning relying data instead feature engineering learn good representation invariant nuisance factors. recent review common learn multiple layers representation referred deep learning. several techniques used unsupervised semi-supervised learning extract multi-layer domain-speciﬁc invariant representations however purely supervised techniques several recent challenges large margins including imagenet lsvrc end-to-end learning systems capitalized advances computing hardware larger datasets like imagenet algorithmic advances methods proven generic object recognition pose estimation limited. part challenge making end-to-end learning work human pose estimation related nonrigid structure body necessity precision complex multi-modal nature pose. paper present ﬁrst end-to-end learning approach full-body human pose estimation. approach based convolutional networks want stress na¨ıve implementation applying model off-the-shelf work. therefore contribution work model outperforms state deformable part models modern challenging dataset also analysis needed make convnets work human pose estimation. particular present two-stage ﬁltering approach whereby response maps convnet part detectors denoised second process informed part hierarchy. detecting people pose investigated decades. many early techniques rely sliding-window part detectors based hand-crafted learned features silhouette extraction techniques applied controlled recording conditions. examples include refer complete survey era. recently several approaches proposed applied unconstrained domains. domains good performance achieved so-called features followed regression-based nearest neighbor svm-based architectures. examples include shape-context edge-based histograms human body silhouette features shakhnarovich learn parameter sensitive hash function perform example-based pose estimation. many relevant techniques also applied hand tracking general survey large ﬁeld hand tracking found many techniques proposed extract learn reason entire body features. combination local detectors structural reasoning coarse tracking person-dependent tracking). similar spirit general techniques using pictorial structures poselets part-models received increased attention. focus techniques latest incarnations following sections. examples come humaneva dataset competitions approaches higher-resolution shape models scape extensions differ domain images considered higher quality less cluttered. also many techniques work images single camera need video sequence input achieve impressive results example technique works single images cluttered backgrounds shotton al.’s kinect based body part detector uses random forest decision trees trained synthetic depth data create simple body part detectors. proposed work also adopt simple partbased detectors however focus different learning strategy. number successful end-to-end representation learning techniques perform pose estimation limited subset body parts body poses. earliest examples type nowlan platt’s convolutional neural network hand tracker tracked single hand. osadchy applied convolutional network simultaneously detect estimate pitch roll face taylor trained convolutional neural network learn embedding images people similar pose nearby. used subset body parts namely head hand locations learn gist pose resorted nearest-neighbour matching rather explicitly modeling pose. perhaps relevant work taylor al.’s work tracking people video augmenting particle ﬁlter structured prior human pose dynamics based learning representations. estimated posterior whole body experiments limited humaneva dataset collected controlled laboratory setting. datasets consider experiments truly poses wild though consider dynamics. factor limiting earlier methods tacking full pose-estimation end-to-end learning methods particular deep networks limited amount labeled data. techniques millions parameters require data structured techniques priori knowledge dpms. attack issue fronts. first directly using larger labeled training sets become available past year flic second indirectly better exploiting data have. annotations provided typical pose estimation datasets contain much richer information compared class labels object recognition datasets particular show relationships among parts contained annotations used build better detectors. perform pose estimation convolutional network architecture obvious approach would image input directly vector coding articulated pose i.e. type labels found pose datasets. convnet output would represent unbounded positions joints alternatively hierarchy joint angles. however found worked poorly. issue pooling useful improving translation invariance during object recognition destroys precise spatial information necessary accurately predict pose. convnets produce segmentation maps example avoid pooling completely another issue direct mapping input space kinematic body pose coefﬁcients highly non-linear one-to-one. however even took route deeper issue attempting directly representation full body pose. valid poses represent much lower-dimensional manifold high-dimensional space captured. seems troublesome make discriminative network space majority conﬁgurations represent valid poses. words makes sense restrict net’s output much smaller class valid conﬁgurations. rather perform multiple-output regression using single convnet learn pose coefﬁcients directly found training multiple convnets perform independent binary body-part classiﬁcation network feature resulted improved performance dataset. convnets applied sliding windows overlapping regions input window pixels single binary output presence absence body part. result applying convnet response-map indicating conﬁdence body part location. lets much smaller convnets retain advantages pooling expense maintain separate parameters body part. course series independent part detectors cannot enforce consistency pose structured output model produces valid full-body conﬁgurations. following sections ﬁrst describe detail convolutional network architecture method enforcing pose consistency using parent-child relationships. lowest level two-stage feature detection pipeline based standard convnet architecture overview shown figure convnets like fully-connected deep neural network counterparts perform end-to-end feature learning trained back-propagation algorithm. however differ number respects notably local connectivity weight sharing local pooling. ﬁrst properties signiﬁcantly reduce number free parameters reduce need learn repeated feature detectors different locations input. third property makes learned representation invariant small translations input. convnet pipeline shown figure starts pixel input patch local contrast normalized emphasize geometric discontinuities improve generalization performance layer comprised pixel local subtractive normalization followed local divisive normalization. input processed three convolution subsampling layers rectiﬁed linear units max-pooling. expected found internal pooling layers help reduce computational complexity improve classiﬁcation tolerance small input image translations. unfortunately pooling also results loss spatial precision. since target application convnet ofﬂine body-pose detection since found sufﬁcient training exemplars invariance input translations learned choose stages pooling following three stages convolution subsampling top-level pooled ﬂattened vector processed three fully connected layers analogous used deep neural networks. output stages composed linear matrix-vector multiplication learned bias followed point-wise non-linearity output layer single logistic unit representing probability body part present patch. train convnet performed standard batch stochastic gradient descent. training images aside validation tune network hyper-parameters number size features learning rate momentum coefﬁcient etc. used nesterov momentum well rmsprop accelerate learning used regularization dropout input fully-connected linear stages reduce over-ﬁtting restricted-size training set. applied validation output network presented section produces many false-positives. believe factors small image context input convnet give model enough contextual information perform anatomically consistent joint position inference training size limited. therefore higher-level spatial model simple body-pose priors remove strong outliers convnet output. expect model improve performance poses close ground truth labels rather functions post processing step de-emphasize anatomically impossible poses strong outliers. inter-node connectivity simple spatial model displayed figure consists linear chain kinematic nodes single side human body. throughout experiments used left shoulder elbow wrist; however could used right side joints without loss generality node chain convnet detector generates response-map unary distributions pfac psho pelb pwri dense pixel positions face shoulder elbow wrist joints respectively. remainder section distributions assumed function pixel position notation dropped. output spatial model produce ﬁltered response maps ˆpfac ˆpsho ˆpelb ˆpwri. body part priors pair joints pa|b= calculated creating histogram joint locations training given adjacent joint located image center histograms smoothed normalized. learned priors psho|fac= pelb|sho= pwri|elb= shown figure note symmetry prior pelb|wri= rotation pwri|elb= rather assume simple gaussian distribution modeling pairwise interactions adjacent nodes standard many parts-based detector implementations found non-parametric spatial priors lead improved detection performance. given full prior conditional distributions convnet unary distributions construct ﬁltered distribution part using approach analogous sumproduct belief propagation algorithm. body part neighbouring nodes ﬁnal distribution deﬁned mixing parameter controls conﬁdence joint’s unary distribution towards ﬁnal ﬁltered distribution ﬁnal joint distribution therefore product unary distribution joint well beliefs neighbouring nodes space product shoulder joint becomes also perform equivalent computation elbow wrist joints. face joint treated special case. empirically found incorporating image evidence shoulder joint ﬁltered face distribution resulted poor performance. likely fact convnet good localizing face position incorporating noisy evidence shoulder detector actually increases uncertainty. instead global position prior face hfac obtained learning location histogram face positions training images shown figure space output distribution face given lastly since learned neural network convolution features spatial priors explicitly invariant scale must convnet spatial model images multiple scales test time likely joint location across scales ﬁnal joint location. datasets containing examples multiple persons non-maximal suppression multiple local maxima across ﬁltered response-maps scale take likely joint candidates person scene. evaluated architecture flic dataset comprised still images taken assortment hollywood movies. frame dataset contains least person frontal pose frame processed amazon mechanical turk obtain ground truth labels joint positions upper body single person. flic dataset challenging state-of-the-art pose estimation methodologies poses unconstrained body parts often occluded clothing background consistent. training images dataset also mirror horizontally obtain total examples. since training images scale also manually annotate bounding head training images bring canonical scale. further crop center shoulder annotations lies perform image normalization test time. following methodology felzenszwalb test time model images person provides python-based framework efﬁcient processing symbolic differentiation complex compound functions. reduce memory usage training cache mini-batches gpu; allows larger convnet models keep training data single gpu. part framework system main threads execution training function runs evaluating batched-sgd updates data dispatch function preprocesses data transfers thread ﬁnished processing mini batches. training convnet nvidia titan takes patch total. test cluster nodes. testing takes .sec image .min total. spatial model take negligible time. testing shared nature weights windows image convolve learned ﬁlters full image instead individual windows. dramatically reduces time perform forward propagation full test set. evaluate model flic dataset measure accuracy suggested sapp given joint precision radius report percentage joints test correct within radius threshold figure evaluate performance measure wrist elbow shoulder joints. also compare detector modec architectures. note subset images testing detectors. figure shows architecture out-performs equal modec detectors three body parts. wrist elbow joints simple spatial model improves joint localization approximately test cases enables outperform detectors. however shoulder joint spatial model actual decreases joint location accuracy large thresholds. likely poor performance convnet elbow. expected spatial model cannot improve joint accuracy points already close correct value however never-the-less successful removing outliers wrist elbow joints. figure example strong false positive results incorrect part location spatial model applied subsequently removed applying spatial model. shown successfully improve state-of-the-art complex computer vision tasks unconstrained human pose estimation. convnets impressive low-level feature detectors combined global position prior able outperform much complex popular models. explored many different higher level structural models improve results generic higher level spatial model achieved best results. mentioned introduction counter-intuitive common belief human kinematic structures mirrors results domains. instance speech recognition researchers observed learned transition probabilities reset equal probabilities recognition performance mainly driven emission probabilities reduce signiﬁcantly domains discussed detail expect obtain improvement enlarging training pose-based warping technique currently investigating. furthermore also currently experimenting multi-resolution input representations take larger spatial context account.", "year": 2013}