{"title": "Font Identification in Historical Documents Using Active Learning", "tag": ["cs.CV", "cs.AI", "cs.DL", "stat.AP", "stat.ML", "I.5; I.2"], "abstract": "Identifying the type of font (e.g., Roman, Blackletter) used in historical documents can help optical character recognition (OCR) systems produce more accurate text transcriptions. Towards this end, we present an active-learning strategy that can significantly reduce the number of labeled samples needed to train a font classifier. Our approach extracts image-based features that exploit geometric differences between fonts at the word level, and combines them into a bag-of-word representation for each page in a document. We evaluate six sampling strategies based on uncertainty, dissimilarity and diversity criteria, and test them on a database containing over 3,000 historical documents with Blackletter, Roman and Mixed fonts. Our results show that a combination of uncertainty and diversity achieves the highest predictive accuracy (89% of test cases correctly classified) while requiring only a small fraction of the data (17%) to be labeled. We discuss the implications of this result for mass digitization projects of historical documents.", "text": "printing font classes evolved multiple subclasses since first printed book. knowing font type characteristics document collection substantially improve performance systems large collections however hand-tagging individual document page text region according font becomes prohibitive. example eighteenth century collections online early english books online databases ‚Äìtwo largest collections available‚Äîcontain million pages. address problem present font-identification system used automatically individual documents within large collection according fonts. font identification best formulated supervised classification problem requires labeled data model building. classification models work best sufficient labelled data represent diversity exemplars corpus. case however obtaining large amounts labeled data corpus million page images varied font types daunting task. reason propose active-learning approach optimize hand labeling process. active learning mixed-initiative paradigm machine learning algorithm human work together during model building algorithm suggests highvalue unlabeled exemplars passed human obtain labels model adapted based newly-labeled exemplars process repeated model converges. remaining parts document organized follows. first review characteristics historical fonts exploited automated classification. next describe proposed active-learning work part early modern project texas university whose overarching goals produce accurate transcriptions ecco/eebo collections create tools used ocr'ing collections early modern texts libraries museums elsewhere. dentifying type font used historical documents help optical character recognition systems produce accurate text transcriptions. towards present activelearning strategy significantly reduce number labeled samples needed train font classifier. approach extracts exploit geometric differences fonts word level combines bag-of-word representation page document. evaluate sampling strategies based uncertainty dissimilarity diversity criteria test database containing historical documents blackletter roman mixed fonts. results show combination uncertainty diversity achieves highest predictive accuracy requiring small fraction data labeled. discuss implications result mass digitization projects historical documents. digitization provides easy access documents published modern texts images video. comparison printed historical documents‚Äî everything pamphlets ballads multi-volume poetry collections hand-press period ‚Äîare difficult access devoted scholars. need create machine-searchable collections accelerated work optical character recognition historical documents. historical documents challenging task partly physical integrity documents quality scanned images also font characteristics. historical documents hand-press period irregular fonts show large variations withsingle font class since early printing processes standardized. blackletter roman font classes main font types used early modmethodology including feature extraction process sampling strategies used select informative unlabeled instances classification model. then present experimental comparison database containing documents roman blackletter fonts. results show active learning achieve classification accuracy test data using small fraction training corpus. article concludes discussion results directions future work. historical fonts broadly categorized categories blackletter roman. name blackletter refers highly ornamental script style calligraphy widely used europe centuries. make printed books look similar hand-lettered johann gutenberg created font sets based blackletter style first printing press blackletter fonts tall narrow letters sharp straight angular lines. characters typically connect other especially round letters finally line strokes also drastically differ thickness between-letter spacing small makes text printed font quite difficult read. compared blackletter roman typefaces significantly less ornamental. first roman typefaces designed around nicholas jenson intention making easier-to-read font. roman fonts take space proportional shape less emphasis angled strokes possess serifs. curved strokes also thinnest parts character. summary angled strokes between-letter spacing stroke width distribution provide information discriminate broad types fonts. name suggests mono-font systems deal single font; result tend high recognition accuracy. contrast omni-font systems recognize text printed font generally show poor recognition accuracy. finally multi-font systems work fonts produce good results provided font classes good separability. systems work well modern documents historical documents. fonts layout historical documents vary substantially document other makes training single high-performance engine difficult. ait-mohand proposed hmm-based multi-font system modifies model document better recognize specific font class. tested dataset modern font classes authors reported recognition rate close recognition rates single-font systems alternative adapting multifont model train multiple mono-font systems direct documents respective engine. requires however font class document identified advance. extensive literature survey ghosh organize font recognition methodologies categories based extracted features structure-based appearance-based. structure-based methods extract connected components characters analyze shape structure recognize particular fonts. contrast appearance-based methods features capture visual appearance individual characters grouped words lines paragraphs. categories divided according whether operate document page paragraph word level. rani presented character-level font identifier. using gabor gradient features svmclassifier reported average accuracy dataset images characters numerals fonts english language fonts gurmukhi language. whether used classify documents words characters font identification systems incur large cost generate sufficient labeled data train classifier. recent studies however shown active learning effective reducing large overhead labeling data unsurprisingly active learning begun garner attention document analysis community. example bouguelia proposed semi-supervised active learning algorithm stream-based classification documents multiple classes bank checks medical receipts invoices prescriptions. compared model built fully labeled training dataset active learning provided precision boost using average labeled data. figure illustrates overall font-identification system. process starts selecting seed training images ecco/eebo collection passed system case open-source tesseract engine outputs generally contain number noisy bounding boxes around nontextual elements pictures decorative elements bleed through. noisy problematic font-identification since behave outliers computing features. reason first step apply de-noising algorithm eliminate noisy return likely contain text. text identified undergo image preprocessing step normalizes size filters salt-and-pepper noise removes skew preprocessed word images passed feature extraction module described next section‚Äìsee table resulting feature vectors vector quantized combined bag-of-words feature representation page. bofs become input font classifier. starting small seed training images iteratively train font classifier select informative documents human analyst label next. training-labeling process repeated performance criterion met. estimate stroke width. since multiple stroke widths store count compute maximum ùê∂ùëöùëéùë•. next select rows ùê∂ùëöùëéùë• calculate trimmed mean respective stroke widths. using robust statistics limiting computation rows ùê∂ùëöùëéùë• provides immunity outliers. estimate number slanted lines applying canny edge detector word image followed hough transform compute number lines slope range divide number recognized characters word available output engine. results estimate slant line density word image‚Äî figure summarized table extract three kinds features capture font information word-image level stroke width letter density slanted lines visual appearance word. characterize stroke width trimmed mean word image. namely scan rows preprocessed word image locate transitions background foreground transitions foreground background ‚Äìsee green points figure respectively. difference x-coordinates serves justification roman fonts smaller vertical stroke width blackletter fonts captures drastic differences stroke width typical black letters blackletters fonts characterized angled lines serifs captures overall shape font performance active learning depends heavily choice sampling strategy selects informative instances labeling. reason query function considers three separate criteria uncertainty. following settles unlabeled instances selected according classifier‚Äôs uncertainty labels ‚Äìsee figure particular compute uncertainty unlabeled data point entropy class-posterior distribution dissimilarity labeled data. promote exploration also consider instances unexplored regions feature space; figure unlabeled instance find mostsimilar labeled instances based llp‚Äôs similarity matrix samples highest dissimilarity selected querying diversity. iteration sampling engine selects batch unlabeled instances. prevent instances within batch similar other incorporate diversity metric constructs batch follows initialize unlabeled instance evaluate effectiveness font classifier devised experiments evaluate feature determine best active learning query function. first experiment examined whether proposed feausually extracted using small patches image case correspond word images. obtain page apply k-means distribution local features vector quantize word image compute number words assigned cluster. achieve word-count invariance normalize bofs total number words page. active learning comprises parts base classifier sampling engine. base classifier trained small amount labeled data sampling engine uses select batch informative instances unlabeled labelling. human annotator labels instances added retrain classifier. entire process training sampling repeated convergence. modified label-propagation model proposed kobayashi known logistic label propagation label propagation training instances treated nodes fully connected graph labels propagated unlabeled data points according proximity labeled data features vectors document respectively bandwidth hyperparameter. major drawback computational complexity recall; must reconstruct whole similarity matrix instances re-estimate class-posteriors predict labels. contrast trains logistic classifier semi-supervised fashion tures discriminate blackletter roman fonts word level. second experiment evaluated complete system using possible active sampling strategies derived combinations three query criteria described previous section. experiments created dataset consisting document images ecco/eebo databases printed blackletter roman text fonts documents hand labeled domain experts emop team. compare discriminatory power different word-level feature sets randomly selected blackletter documents roman documents extracted features shown table trained logistic regression classifier predict class label word. threshold classifier output selected maximizing -fold crossvalidation. results summarized figure slant angle density character width feature achieves classification rate whereas feature achieves feature sets combined classification performance improves modestly results indicate extracted features important font identification provide high between-class separability ‚Äìeven word level. trained using features zernike moments slant line density character width principal components analysis dataset using pagelevel features point represents document. evaluate overall system randomly selected documents test used remaining documents training set. these randomly selected labeled documents seed-set train font classifier; remaining documents became unlabeled oracle played role human labeler. newly-labeled documents added training font classifier retrained performance tested instances test set. repeated process unlabeled data consumed recording size labeled data classifier accuracy. comparison included baseline system iteratively selected random documents. evaluation purposes bandwidth parameter experiment repeated times random seeds stable performance estimate. learning curves scoring functions baseline random selection shown figure best performer requires labeled samples achieve maximum average test accuracy uncertainty criterion alone also performs well achieving maximum test accuracy using labeled samples. final analysis calculated area curve learning curve scalar performance measure active sampling approach. results summarized figure based values uncertainty criterion performs marginally better sampling based uncertainty+diversity. remaining sampling techniques dissimilarity perform notably worse. attributed characteristics dataset. shown figure distribution bofs reveals good degree separability between roman blackletter fonts overlap mixed class. arrangement data makes exploration less useful information captured instances class boundaries. result active sampling strategies involve exploration need labeled data reach desired accuracy compared exploitative technique samples class boundaries. oracle case training dataset itself fully labeled advance. consider diversity isolation primary sampling techniques pick diverse unlabeled instances. work also explore development graphical user interfaces interactive machine learning strategies allow scholars explore understand large document collections efficiently.", "year": 2016}