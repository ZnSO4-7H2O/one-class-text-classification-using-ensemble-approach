{"title": "Deep Multimodal Embedding: Manipulating Novel Objects with Point-clouds,  Language and Trajectories", "tag": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "abstract": "A robot operating in a real-world environment needs to perform reasoning over a variety of sensor modalities such as vision, language and motion trajectories. However, it is extremely challenging to manually design features relating such disparate modalities. In this work, we introduce an algorithm that learns to embed point-cloud, natural language, and manipulation trajectory data into a shared embedding space with a deep neural network. To learn semantically meaningful spaces throughout our network, we use a loss-based margin to bring embeddings of relevant pairs closer together while driving less-relevant cases from different modalities further apart. We use this both to pre-train its lower layers and fine-tune our final embedding space, leading to a more robust representation. We test our algorithm on the task of manipulating novel objects and appliances based on prior experience with other objects. On a large dataset, we achieve significant improvements in both accuracy and inference time over the previous state of the art. We also perform end-to-end experiments on a PR2 robot utilizing our learned embedding space.", "text": "fig. deep multimodal embedding deep neural network learns embed point-cloud/natural language instruction combinations manipulation trajectories semantically meaningful space distance represents relevance embedded data. expert knowledge extremely challenging design joint features disparate modalities. designing features different sensor inputs actions space required here particularly challenging. work deep neural network learn shared embedding pairing object parts environment natural language instructions manipulation trajectories means three modalities projected feature space. introduce algorithm learns pull semantically similar environment/language pairs corresponding trajectories regions push environment/language pairs away irrelevant trajectories based irrelevant are. algorithm allows efﬁcient inference because given instruction point-cloud need nearest trajectory projection pair learned embedding space done using fast nearest-neighbor algorithms past deep learning methods shown impressive results learning features wide variety domains even learning cross-domain embeddings contrast existing methods present pre-training algorithm initializing networks used joint embedding different modalities. algorithm trains layer similar cases similar areas feature space opposed methods either perform variational learning train reconstruction abstract— robot operating real-world environment needs perform reasoning variety sensor modalities vision language motion trajectories. however extremely challenging manually design features relating disparate modalities. work introduce algorithm learns embed point-cloud natural language manipulation trajectory data shared embedding space deep neural network. learn semantically meaningful spaces throughout network loss-based margin bring embeddings relevant pairs closer together driving lessrelevant cases different modalities apart. pre-train lower layers ﬁne-tune ﬁnal embedding space leading robust representation. test algorithm task manipulating novel objects appliances based prior experience objects. large dataset achieve signiﬁcant improvements accuracy inference time previous state art. also perform end-to-end experiments robot utilizing learned embedding space. consider robot manipulating appliance home kitchen e.g. toaster figure robot must combination observations world natural language instructions infer manipulate objects. ability fuse information different input modalities actions extremely useful many applications household robots including assembling furniture cooking recipes many more. even though similar concepts might appear differently different sensor modalities humans able understand concept. example asked turn knob counter-clockwise toaster able correlate instruction language appearance knob toaster motion also associate concept closely motion would incorrectly rotate opposite direction with example motion press toaster’s handle downwards. strong evidence humans able correlate different modalities common representations obtaining good common representation different modalities challenging main reasons. first modality might intrinsically different statistical properties example trajectory representation inherently dense representation language naturally sparse. makes challenging apply algorithms designed unimodal data. second even order validate approach test model large manipulation dataset robobarista dataset focuses learning infer manipulation trajectories novel objects. also present results series experiments robot showing algorithm able successfully manipulate several different objects. summary contributions work approach allows fast inference manipulation trajectories novel objects roughly faster previous work also improving accuracy large manipulation dataset several works machine learning make power shared embedding spaces. large margin nearest neighbors learns max-margin mahalanobis distance unimodal input feature space. learn linear mappings image language features common embedding space automatic image annotation. learn language tags shared embedding songs natural space. however approaches learn shallow linear mapping input features whereas learn deep non-linear mapping less sensitive input representations. multimodal data deep neural network used learn features video audio generative learning network robust missing modalities inference time works similar single network takes modalities inputs whereas perform joint embedding multiple modalities using multiple networks. joint embedding several works deep networks joint embedding different feature spaces. translation joint feature space learned different languages annotation retrieval images natural language tags mapped space present pre-training algorithm embedding spaces show outperforms conventional methods used works. deep network also used metric learning face veriﬁcation task enforces constant margin distances among inter-class objects among intra-class objects similar lmnn sec. vi-a show approach uses loss-dependent variable margin produces better results problem. many works robotic manipulation focus task-speciﬁc manipulation known objects example folding towels baking cookies planar contact manipulation others focus sequencing manipulation tasks choosing switch skills assuming manipulation primitives pour available. novel objects affordances predicted associated motions applied instead similar skip intermediate representations directly generalize novel objects. recent works deep learning approaches robotic manipulation. deep networks used detect stable grasps rgb-d data gaussian mixture model learn system dynamics learn manipulation policy using deep network. deep network learn system dynamics realtime model-predictive control. works focus learning low-level input-output controllers. here instead focus inferring full -dof trajectories controllers could used follow. sung perform object part-based transfer manipulation trajectories novel objects introduces large manipulation dataset including objects like epresso machine urinal. primarily test algorithm dataset. sec. vi-a show approach gives better accuracy prior work also running faster. main challenge work learn model maps three disparate modalities point-clouds natural language trajectories single semantically meaningful space. particular focus point-clouds object parts natural language instructing manipulation different objects trajectories would manipulate objects. learns common pointcloud/language/trajectory embedding space projection task higher similarity projections relevant trajectories task-irrelevant trajectories. among irrelevant trajectories might less relevant others thus pushed away. example given door knob needs grasped normal door surface instruction rotate clockwise trajectory correctly approaches door knob rotates counter-clockwise higher similarity task approaches knob completely incorrect angle execute rotation. learn non-linear embeddings using deep learning approach shown fig. maps data three different modalities joint embedding space. prior learning full joint embedding three modalities pre-train embeddings subsets modalities learn semantically meaningful embeddings modalities. language instruction end-effector trajectories goal learn joint embedding space different mapping functions space—one pointcloud/language pair trajectory. ﬁrst maps point-clouds languages deﬁned combination mappings. ﬁrst maps joint point-cloud/language space rnpl rnpl rnpl. represents size dimensions embedded jointly. mapped rnpl space mapped joint space shared trajectory information rnpl joint feature space proximity mapped points reﬂect relevant data-points other even completely different modalities. train network bring demonstrations manipulate given object according language instruction closer mapped point object/instruction pair push away demonstrations would correctly manipulate object. trajectories semantic relevance object pushed much away trajectories relevance even latter would fully manipulate object according instruction. every training point-cloud/language pair demonstrations optimal demon∈ using optimal demonstration stration trajectory loss function comparing demonstrations trajectories relevant task trajectories irrelevant dtw-mt distance function loss function could replaced function computes loss predicting correct demonstration. using strategy previously used handling noise crowd-sourced data thresholds generate sets pool trajectories pair want projections higher similarity projection tid. simple approach would train network distinguish sets enforcing ﬁnite distance similarities sets written form constraint pre-training lower layers visualization pre-training fig. approaches algorithm pushes matching point-clouds instructions similar. algorithm pushes trajectories higher dtw-mt similarity similar. rather simply able distinguish sets want learn semantically meaningful embedding spaces different modalities. recalling earlier example incorrect trajectory manipulating door knob much closer correct another clear learning algorithm drive incorrect trajectories dissimilar others. difference similarities projected point-cloud/language pair least loss written form constraint tis∀τk intuitively forces trajectories higher dtw-mt distance ground truth embed lower distance. enforcing combinations constraints could grow exponentially large. instead similar cutting plane method structural support vector machines violating trajectory training pair iteration. violating trajectory highest value similarity augmented loss scaled constant major advantage modern deep learning methods unsupervised pre-training initialize neural network parameters good starting point ﬁnal supervised ﬁne-tuning stage. pre-training helps highdimensional networks avoid overﬁtting training data. lower layers represent features extracted exclusively combination point-clouds system overview given point-cloud language instruction goal output trajectory would manipulate object according fig. instruction. given point-cloud scene segmented many parts ranked step instruction manual. embedding point-cloud language trajectory modalities joint embedding space algorithm selects best trajectory transfer object. language trajectories respectively. pretraining method initializes semantically meaningful embedding spaces similar shown later section vi-a. first pre-train layers leading layers using sparse de-noising autoencoders then process pre-training similar approach ﬁne-tuning semantically meaningful embedding space presented above except violating language still relying loss associated optimal trajectory argmax task inferring manipulation trajectories novel objects especially important similar trajectories similar regions feature space deﬁned trajectory embedding semantically meaningful turn mapped similar regions standard pretraining methods sparse denoising autoencoder would pre-train reconstruct individual trajectories. instead employ pretraining similar pre-training above except pre-train single modality trajectory data. shown right hand side fig. layer embeds duplicated. layers treated different modalities weights shared updated simultaneously. every trajectory violating minimize similar cost function hpl. example application consider manipulating novel appliances goal learned embedding space allow robot infer manipulation trajectory introduced appliance natural language instruction manual. example shown fig. given point-cloud scene toaster instruction ‘push right lever start toasting’ output trajectory representative two-ﬁngered end-effector move including approach grasp push lever. algorithm allows robot leverage prior experience different appliances example trajectory manipulates handles paper towel dispenser might transferred manipulate toaster handle. first order correctly identify part scene instruction asks manipulate point-cloud scene segmented many small potential candidates. segments ranked step manual instruction. multiple variations correct segmentations lots incorrect segmentation make embedding representation even robust shown later sec. vi-a. previous approach problem requires projecting point-cloud natural language instruction every trajectory training exhaustively network inference. instead approach allows pre-embed candidate trajectories shared embedding space. correct trajectory identiﬁed embedding pointcloud/language pair. shown sec. vi-a signiﬁcantly improves inference run-time accuracy makes much scalable larger training dataset. learning algorithm assumes object parts corresponding instruction already segmented point-cloud scene focus learning manipulate segmented parts also introduce segmentation approach allows build end-to-end system augment training data better unsupervised learning shown sec. vi-a. generating object part candidates employ series geometric feature based techniques segment scene small overlapping segments pn}. ﬁrst extract euclidean clusters points limiting difference normals local larger region ﬁlter segments human hands. handle wide variety object parts different scales generate sets candidates different sets parameters combined evaluation. part candidate ranking algorithm given segmented parts must training data select instruction best-matching part optimizing score segment step manual evaluated three parts score based kp-most identical segments training data based cosine similarity using grid representation score similarity segments associated sim). associated language exist given similarity value. similarly score ψlang based kl-most identical language instructions similarity identical language associated expert point-cloud segmentations. feature score computed weighted features described sec. v-a.. score segmented parts adjusted multiplying ratio score marginalized score manual mnew optimal segment scene chosen segment maximum score maxpi∈snew features three features computed segment context original scene. ﬁrst infer person would stand detecting ‘front’ object plane segmentation constrained normal axis less line object’s centroid original sensor location assuming robot introduced close ‘front’. compute ‘reach’ distance imaginary person tall deﬁned distance head person segment subtracted distance closest one. also stitched point-clouds signiﬁcant noise near edges compute distance imaginary view line deﬁned centroid scene head person. lastly objects like soda fountain sauce dispenser many identical parts making difﬁcult disambiguate different choices thus scenarios also provided point human pointing label desired selection. note point actual part rather label vicinity. distance point also used feature. point-cloud segment converted real-valued occupancy grid cell’s value proportional many points fall cube spans. grid cubic cells sides .cm. unlike previous work cell count also distributed neighboring cells exponential distribution. smooths missing points increases amount information represented. grid normalized dividing maximal count. approach focuses shape part question shape nearby scene also signiﬁcant effect part manipulated. account this assign value cell contains points belong scene speciﬁc part question within distance nearest point given part. hollow parts behind background tables walls raytrace starting location sensor cells ﬁlled background points similarly. segment ranking algorithm uses full-sized grid segment main embedding algorithm uses compact grids generated taking average cells grids cells sides natural language represented ﬁxed-size bag-ofwords. trajectories variable-length sequences waypoints waypoint contains position orientation gripper state deﬁned coordinate frame object part. trajectories normalized ﬁxed length waypoints. details trajectory representation please refer tested algorithms mobile robot arms seven degrees freedom software controlling robot written embedding algorithm written theano computations done remote computer utilizing embedding model. validation found optimal embedding space size intermediate-layer sizes loss scaled relatively small layer sizes also advantage fast inference shown sec. vi-a. improvements each. second present series realworld robotic experiments show system able produce trajectories successfully manipulate objects based natural language instructions. dataset. test model robobarista dataset dataset consists point-cloud scenes manuals consisting expert segmented point-clouds free-form natural language instructions. also contains crowd-sourced manipulation trajectories demonstrated point-cloud/language pairs. point-clouds collected stitching multiple views using kinect fusion. manipulation trajectories collected non-experts amazon mechanical turk. evaluation. algorithms evaluated using ﬁve-fold cross-validation data kept validation set. point-cloud/language pair test fold algorithm chooses trajectory training best suits pair. since focus testing ability reason different modalities transfer trajectory segmented parts provided input. evaluate transferred trajectories dataset contains separate expert demonstration point-cloud/language pair used training phase every transferred trajectory evaluated expert demonstrations. metrics. evaluation trajectories dynamic time warping manipulation trajectories non-linearly warps trajectories different lengths preserving weak ordering matched trajectory waypoints. since values intuitive also reports percentage transferred trajectories dtw-mt value less ground-truth trajectory indicates likely correctly manipulate according given instruction according expert survey. report three metrics dtw-mt manual dtw-mt instruction accuracy instruction. instruction refers every point-cloud/language pair manual refers list instructions comprises sequential tasks average over. baselines. compare model several baselines fig. accuracy-threshold graph showing results varying thresholds dtw-mt measures. algorithm consistently outperforms previous approach lmnn-like cost function also report several baselines work rely traditional approaches classifying pointclouds labels like ‘handle’ ‘lever’ hand-designing features multi-modal data lmnn -like cost function ﬁne-tuning pre-training deﬁne cost function without loss augmentation. similar lmnn give ﬁnite margin similarities. example cost function model without pretraining full model ﬁne) model without multiple segmentations model trained expert segmentations without taking utilizing candidate segmentations auto-encoders multiple correct segmentations part training. present results algorithm baseline approaches table additionally fig. shows accuracies obtained varying threshold dtw-mt measure. state-of-the-art result dataset dtwmt measure manual dtw-mt measure accuracy instruction. full model based joint embedding multimodal data achieved respectively. means robot encounters object never seen before model gives trajectory would correctly manipulate according given instruction approximately time. fig. algorithm consistently outperforms prior work lmnn-like cost function thresholds dtw-mt metric. learned deep embedding space represent? fig. shows visualization layer joint embedding space. visualization created projecting training data cross-validation folds embedding -dimensional space using t-sne system able naturally learn nozzle spout effectively synonyms purposes manipulation. clustered together upper-left fig. based solely fact associated similar point-cloud shapes manipulation trajectories. addition aforementioned cluster several logical clusters. importantly embedding maps vertical horizontal rotation operations different regions space roughly o’clock o’clock fig. respectively. despite fact nearly identical language instructions algorithm learns differently based point-clouds mapping nearby appropriate manipulation trajectories. cost function loss-augmented? change cost function pre-training ﬁnetuning constant margin relevant irrelvant demonstrations performance drops loss-augmentation also visible embedding space. notice purple cluster around o’clock region fig. right portion cluster o’clock region. purple cluster represents tasks demonstrations related pushing lower part cluster represents task holding nozzle. although motion required task would replaceable other motions shapes similar especially compared motions e.g. turning horizontal knob. pre-embedding important? seen table withpre-training model gives accuracy pre-training lower layers conventional stacked de-noising auto-encoder algorithm increases performance still signiﬁcantly underperforming pre-training algorithm shows metric embedding pre-training approach provides better initialization embedding space sda. automatically segmented object parts manipulated? table segmentation approach able good segmentation object parts question robotic trials time. failures occurred beverage dispenser small lever difﬁcult segment. cloud/language/trajectory features combinations current point-cloud/language pair candidate trajectory infer optimal trajectory. inefﬁcient scale well number training datapoints. however model pre-computes projection trajectories inference model requires projecting point-cloud/language combination ﬁnding trajectory maximal similarity embedding. practice results signiﬁcant improvement efﬁciency decreasing average time infer trajectory speed-up time measured hardware using theano measured inference times times ﬁrst test fold pool trajectories. times preprocess data load memory included measurement. robotic experiments test framework performed experiments robot three different scenes shown fig. presented robot object placed within reach different starting locations along language instruction. table shows results robotic experiments. able successfully complete task end-to-end autonomously times. segmentation reliable beverage dispenser small lever. however segmentation successful embedding algorithm able provide correct trajectory accuracy able correctly follow trajectories occasional slips relatively large size hand compared objects. work introduce algorithm learns semantically meaningful common embedding space three modalities point-cloud natural language trajectory. using loss-augmented cost function learn embed joint space similarity points space reﬂects relevant other. application test algorithm problem manipulating novel objects. empirically show large dataset embedding-based approach signiﬁcantly improve accuracy despite less number learned parameters much computationally efﬁcient state-of-the-art result. also show series robotic experiments segmentation algorithm embedding algorithm allows robot autonomously perform task. acknowledgment. work supported microsoft faculty fellowship career award saxena. fig. joint embedding space network fully ﬁne-tuned visualized using t-sne inverted triangles represent projected point-cloud/language pairs circles represent projected trajectories. occupancy grid representation object part point-clouds shown green blue grids. presentation purpose ‘neighbor’ cells shown. legend bottom right shows classiﬁcations object parts expert collected purpose building baseline. shown result baseline labels necessarily correlate well actual manipulation motion. thus full separation according labels deﬁned legend optimal occur. ﬁgures best viewed color. sung saxena robobarista object part-based transfer manipulation trajectories crowd-sourcing pointclouds international symposium robotics research erdogan yildirim jacobs transfer object shape knowledge across visual haptic modalities proceedings annual conference cognitive science society koval pollard srinivasa prepost-contact policy decomposition planar contact manipulation uncertainty international journal robotics research august quigley conley gerkey open-source robot operating system icra workshop open source software bastien lamblin pascanu theano features speed improvements deep learning unsupervised feature learning nips workshop", "year": 2015}