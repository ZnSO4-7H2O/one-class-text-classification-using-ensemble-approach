{"title": "On Discrimination Discovery and Removal in Ranked Data using Causal  Graph", "tag": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "abstract": "Predictive models learned from historical data are widely used to help companies and organizations make decisions. However, they may digitally unfairly treat unwanted groups, raising concerns about fairness and discrimination. In this paper, we study the fairness-aware ranking problem which aims to discover discrimination in ranked datasets and reconstruct the fair ranking. Existing methods in fairness-aware ranking are mainly based on statistical parity that cannot measure the true discriminatory effect since discrimination is causal. On the other hand, existing methods in causal-based anti-discrimination learning focus on classification problems and cannot be directly applied to handle the ranked data. To address these limitations, we propose to map the rank position to a continuous score variable that represents the qualification of the candidates. Then, we build a causal graph that consists of both the discrete profile attributes and the continuous score. The path-specific effect technique is extended to the mixed-variable causal graph to identify both direct and indirect discrimination. The relationship between the path-specific effects for the ranked data and those for the binary decision is theoretically analyzed. Finally, algorithms for discovering and removing discrimination from a ranked dataset are developed. Experiments using the real dataset show the effectiveness of our approaches.", "text": "prefix ranking identical demographics whole population. however already shown classification statistical parity take account fact part discrimination explainable non-protected attributes hence cannot accurately measure discrimination believe observation also holds ranked data. let’s consider illustrative example ranked data company recruiting system shown table ranked data contains four profile attributes race code education interview result race protected attribute favorable group unfavorable group education interview result objective requirements getting job. assume rankers compute qualification scores produce rankings shown figure first ranker denoted ranker produces qualification scores equalweighted linear combination attributes education interview result intuitively ranker produces fair ranking since purely depends objective attributes. however seen ranking results satisfy statistical parity. basis ranker second ranker ranker gives bonus score favorable group usage protected attribute explicitly results unfavorable treatment protected group nevertheless ranking results satisfy statistical parity race groups well-mixed equal proportion. example shows statistical parity produce misleading conclusions regarding discrimination. address limitation statistical parity-based methods causal graph-based discrimination detection removal methods recently proposed zhang shows correlation protected attribute decision nonlinear combination direct discrimination indirect abstract predictive models learned historical data widely used help companies organizations make decisions. however digitally unfairly treat unwanted groups raising concerns fairness discrimination. paper study fairness-aware ranking problem aims discover discrimination ranked datasets reconstruct fair ranking. existing methods fairness-aware ranking mainly based statistical parity cannot measure true discriminatory effect since discrimination causal. hand existing methods causal-based anti-discrimination learning focus classification problems cannot directly applied handle ranked data. address limitations propose rank position continuous score variable represents qualification candidates. then build causal graph consists discrete profile attributes continuous score. pathspecific effect technique extended mixed-variable causal graph identify direct indirect discrimination. relationship path-specific effects ranked data binary decision theoretically analyzed. finally algorithms discovering removing discrimination ranked dataset developed. experiments using real dataset show effectiveness approaches. introduction discrimination-aware machine learning aims construct discrimination-free machine learning models active research area recent years. many works conducted achieve goal detecting removing discrimination/biases historical training data constructed machine learning models however works focus classification models built categorical decisions especially binary decisions. paper investigate discrimination ranking models another widely used machine learning models adopted search engines recommendation systems auction systems etc. specific study discrimination discovery removal ranked data. ranked dataset combination candidate profiles permutation candidates decision. fairness concerns raised ranking models since biases discrimination also introduced ranking. discrimination well explainable effect. path-specific effect technique used capture causal effects passing different paths. however work focuses binary classification. ranking systems decisions given term permutation series unique concatenating integers cannot treated regular random variables. thus methods cannot applied directly deal ranked data. paper employ causal graph solve fair ranking problem adopting continuous variable called score instead ranking positions represent qualifications individuals rank. bradley-terry model obtain reasonable mapping ranking positions scores. construct causal graph individuals’ profiles scores categorical continuous data. challenge traditional causal graph construction inference limited single-datatype situations variables discrete continuous address challenge associate score conditional gaussian distributions instead conditional probability table then extend path-specific effect technique mixed-variable causal graph capturing direct indirect discrimination. also derive relationship path-specific effects ranked data binary decision assuming binary decision obtained based certain cut-off point imposed ranking. algorithms detecting discrimination causal graph well removing rank biases data developed. finally conduct experiments using real datasets show effectiveness methods. results show methods correctly detect remove direct indirect discrimination relatively small data utility loss statistical parity based methods neither correctly identify discrimination successfully mitigate discrimination. rest paper organized follows. section gives notations backgrounds used paper. section models direct indirect discrimination ranked data causal effects. sections develops discrimination discovery removal approaches based causal graph. experiment settings results reported section finally related work conclusions summarized sections section preliminaries throughout paper attributes denoted uppercase letter e.g. sets attributes denoted bold uppercase letter e.g. value certain attribute denoted lowercase letter e.g. values attributes denoted bold lowercase letter e.g. domain space attribute denoted domain space attribute cartesian product causal graph nodes edges. node graph represents attribute. edge denoted arrow pointing cause effect represents direct causal relationship. path traces arrows directed node another node called causal path node parents denoted children denoted usually local markov condition assumed satisfied means node independent non-descendants conditional parents. child-parent family graph associated deterministic function arbitrarily distributed random disturbance. functional characterization child-parent relationship leads conditional probability distribution characterizes graph i.e. variables discrete denoted conditional probability table inferring causal effects causal graph performed interventions simulate physical interventions values attributes certain constants. specifically intervention fixes values variables constants mathematically formalized simply post-intervention distribution attributes denoted simply calculated using truncated factorization formula p)δx=x δx=x means assigning attributes involved term ahead corresponding values result total causal effect assessed comparing difference post-intervention distributions different interventions common measure total causal effect expected difference shown definition note total causal effect measures effect intervention transmitted along causal paths extension total causal effect avin proposed path-specific effect measures causal effect intervention’s effect transmitted along subset causal paths denote subset causal paths denote post-intervention distribution intervention’s effect transmitted along based that πspecific effect given definition pointed condition pathspecific effect estimated observed data known identifiability path-specific effects. deal unidentifiable situation discussed shpitser gave method calculating identifiable path-specific effect strategies readily applied methods. probabilities estimated data using standard statistical estimation techniques continuous score associated conditional gaussian distributions instead cpt. pa\\{c}. value assignment parents distribution whose mean variance based thus distribution given example figure shows causal graph example presented introduction. associated representing conditional probability given parents associated distribution mean variance based parents four variables. section study model direct indirect discrimination ranked dataset causal effect. consider ranked dataset consisting individuals protected attribute several non-protected attributes rank permutation decision. subset attributes cause indirect discrimination referred redlining attributes. assume attributes categorical. make reasonable assumptions protected attribute parent; score child. first fact protected attribute usually inherent nature human beings second score output ranking system. building causal graph ranked data rank permutation series unique concatenating integers cannot treated normal categorical random variables. bradley-terry model ranking positions ranked data continuous scores. bradley-terry model assigns individual score indicate qualification preference individual. generally larger score represents better qualification. difference scores individuals corresponds log-odds probability individual ranked individual rank i.e. thus logarithm likelihood bradley-terry model given observed rank permutation given result optimal bradley-terry model best fits observed rank permutation obtained minimizing loss function. proved loss function convex could efficiently optimized gradient descent. obtaining score using bradley-terry model build causal graph variables first adopt pc-algorithm learning structure causal graph. since exist discrete continuous variables different conditional independence testing methods adopted chi-square test discrete variables partial correlation matrix continuous variables conditional gaussian likelihood ratio test mixed variables. then parameterizing causal graph treat discrete continuous variables different ways. discrete variables associated conditional probability table conditional quantitative measurement show direct indirect discrimination ranked data quantitatively measured based causal graph build. known discrimination causal effect protected attribute decision. first give quantitative measure total causal effect protected attribute score shown theorem fact sort nodes according topological ordering parents node ordering. addition since parent must zj’s non-descendant; since child cannot zj’s parent. thus based local markov condition according chain rule obtain thus follows authors show single-type causal graph total causal effect generally cannot correctly measure either direct discrimination indirect discrimination modeled path-specific effects. adopting similar strategy capture direct discrimination causal effect transmitted direct edge capture indirect discrimination causal effect transmitted paths pass redlining attributes. formally define path contains define path contains causal paths pass then direct discrimination captured πd-specific effect seπd indirect discrimination captured πi-specific effect seπi. extend method computing path-specific effect data mixed-variable causal graph computing seπd seπi. results shown theorem equation computed according truncated factorization formula compute follow steps first express truncated factorization formula. then divide children disjoint sets contains child edge segment path ¯vπd contains child either included path edge segment path finally replace values terms corresponding nodes replace values terms corresponding nodes ¯vπd theorems present quantitative measurement total causal effect well πi-specific effects. following proposition reveals relationship among seπd seπi. shows indirect effect equal total causal effect plus reversed direct effect. earlier work derived πi-specific effects protected attribute binary decision attribute positive decision negative decision distinguishing path-specific effects derived ranked data paper). assume decision made based cut-off point score. interesting question given discrimination-free rank whether binary decision made based cut-off point also discrimination free. answering question needs derive relationship subsection derive relationships condition µc−q σc−q first obtain formulas obtaining modified score distribution solving quadratic programming problem reconstruct fair ranking follows. consider individuals profile i.e. individual score regenerated distribution percentile score original distribution. specifically since ρσcq ρσcq value standard normal distribution percentile µcq). finally re-rank individuals according descending order scores. since scores contain discrimination rank. procedure shown algorithm referred frank. computational complexity discovery removal algorithms depends efficiently derive score using bradley-terry model. proved likelihood function convex optimal solution efficiently obtained using gradient descent. complexity also depends complexities building causal graph computing path-specific effect. many researches devoted improving performance network construction probabilistic inference causal graphs complexity analysis found related literature. discovery removal algorithms develop discrimination discovery removal algorithms based derived πi-specific effects. since values seπd seπi arbitrarily large give criterion direct indirect discrimination terms relative difference. require ratio seπd seπi expected score non-protected group i.e. smaller given threshold example equality human rights commission consider significant threshold gender gap. defining discrimination measures based analysis develop algorithm discovering discrimination rank referred fdetect shown algorithm direct indirect discrimination detected discriminatory effects need eliminated ranked data used training sharing. propose path-specific-effectbased fair ranking algorithm remove discrimination ranked data reconstruct fair ranking. first modify score distributions causal graph contains discrimination reconstruct fair ranking based modified causal graph. shown theorem discriminatory effect depends means score distributions. hence need modify means score. maximize utility modification process minimize distance original score distributions modified score distributions measured bhattacharyya distance specifically score distribution denote modified distribution bhattacharyya distance distributions given german credit dataset consists individuals attributes applying loans. small sample size select attributes experiments including dependant duration housing property purpose residence. treat protected attribute housing redlining attribute. employ weighted-sum ranking strategy proposed generate ranked datasets denoted weighted computed weighted linear summation certain attributes candidates ranked according weighted sum. attributes summed equal weight summation attributes except age. also another ranked data ranking directly based original attribute credit amount. that derive continuous qualification scores ranked dataset using bradley-terry model. causal graphs constructed using open source software tetrad parameterized described section constructed causal graph shown figure causal graphs datasets shown space constraints. quadratic programming solved using cvxopt discrimination threshold direct indirect discrimination. comparison involve statistical parity-based discrimination discovery removal algorithms proposed yang zehlike discrimination discovery yang proposed three set-based discrimination measures called compute difference protected group whole dataset terms risk difference risk ratio kullback-leibler distance. compute values difference several discrete points values logarithmic discounts. measures normalized range since don’t provide criterion discrimination discovery simply threshold three measures. zehlike proposed adjusted fairness condition requires minimum number protected candidates every prefix ranking list. discrimination removal yang proposed fair data generator manipulates permutation according user-defined figure causal graph yellow node protected attribute orange node housing redline attribute purple node score decision attribute. dash-dot line captures direct discrimination score green dashed line captures indirect discrimination throgh housing. preference example candidates well mixed equal proportion every prefix; candidates protected group ranked bottom. zehlike proposed discrimination removal methods fa*ir select qualified candidate corresponding group every prefix order satisfy adjusted fairness condition. evaluate data utility removal approaches adopt widely used metrics spearman’s footrule distance kendall’s distance spearman’s footrule distance measures total element-wise displacement modified permutation original one. kendall’s distance measures total number pairwise inversions permutations. distance metrics larger values indicate data utility loss. discrimination discovery quantify strength direct indirect discrimination using method fdetect three ranked datasets. results shown table dataset attributes including protected attribute used ranking directly. thus ground-truth direct indirect discrimination occurs dataset. method obtains showing direct indirect discrimination correctly identified. dataset since attributes except protected attribute ranking process groundtruth indirect discrimination occurs direct discrimination doesn’t. method shows also consistent ground-truth. dataset don’t ground-truth. method obtains results imply neither direct discrimination indirect discrimination exists dataset. statistical parity-based methods faircon cannot distinguish direct indirect discrimination. directly report results produced methods shown table method proposed yang shows zehlike’s faircon shows third position doesn’t satisfy minimum fair requirement. yang’s method shows faircon reports position doesn’t satisfy fair requirement. methods conclude discrimination dataset kind match conclusions. however yang’s method shows three values make contradictory conclusions discrimination according report significant discrimination. faircon shows ranking cannot satisfy fair requirement position. methods cannot obtain results consistent ours implying produce incorrect misleading conclusions. table comparison discrimination discovery methods direct discrimination. second column represents ground-truth direct indirect discrimination. discrimination removal perform frank remove discrimination reconstruct fairly ranked datasets neither direct indirect discrimination. theoretical results guarantee discrimination modification. comparison also execute fairgen fa*ir removing discrimination apply fdetect evaluate whether newly-generated data achieves truly discrimination-free. results three removal methods shown table seen method frank removes direct indirect discrimination precisely. however fairgen fa*ir cannot achieve discrimination-free. fairgen removes neither direct indirect discrimination. even introduces discrimination fa*ir mitigate part direct discrimination fails remove indirect discrimination. adopt spearman’s footrule distance kendall’s distance evaluate data utility loss mitigating discrimination. seen last columns table method frank incurs relatively small data utility loss fairgen suffers large data utility loss achieving discrimination-free. although fa*ir introduces quite small data utility loss fails mitigate indirect discrimination. worth pointing direct indirec discrimination frank doesn’t result distortion. contrary fairgen leads much utility loss. also examine data utility varies different values discrimination threshold perform frank vary threshold frank evaluating much data utility loss incurred. table spearman’s footrule distance kendall’s distance decrease increase means less utility loss incurred larger threshold. observation consistent analysis since larger relaxed constraints frank. related work fairness-aware learning active research area machine learning data mining. many methods proposed constructing discrimination-free machine learning models either based data preprocessing model tweaking. data preprocessing methods modify historical training data remove discrimination used learning model. model tweaking methods require tweak adjustment constructed machine learning models. fair ranking emerging topic fairness-aware learning. current works fair ranking mainly based statistical parity. required preset proportion protected individuals must maintained prefix ranking rank fair. however many works shown statistical parity alone insufficient general notion fairness. recently several studies devoted analyzing discrimination causal perspective authors proposed framework based suppes-bayes causal network developed several random-walk-based methods detect different types discrimination. however unclear number random walks related practical discrimination metrics. addition construction suppes-bayes causal network impractical large number attribute-value pairs. work adopt causal graph used causal graph probabilistic graph model widely used causation representation reasoning inference limitation works focus classification problems cannot applied directly fair ranking problem. models decision individual treated independent random variable ranking positions different individuals correlated. paper address limitations develop causal-based fair ranking algorithms. data science well-studied data mining model ranking using continuous score space several models plackett-luce model mallows model bradley-terry model widely used field. work adopt bradley-terry model characterize ranked data obtain continuous scores ranks. conclusions future work paper studied problem discovering discrimination rank reconstructing fair rank discrimination detected. made causal graph capture biases rank causal effect. address limitation existing single-datatype causal graph modeled ranking positions using continuous score built causal graph profile attributes well score. then extended path-specific effect technique mixed-variable causal graph used quantitatively measure direct indirect discrimination ranked data. also theoretically analyzed relationship path-specific effects ranked data binary decision. based that developed algorithm discovering direct indirect discrimination well algorithm reconstruct fair rank causal graph. experiments using german credit dataset showed methods correctly measure discrimination rank reconstruct rank contain either direct indirect discrimination statistical parity-based method obtain incorrect misleading results. theorem assume πi-specific effect identifiable data. cases πi-specific effect able computed data inherent unidentifiability path-specific effect another work discussed deal situation referred unidentifiable situation developed lower upper bound unidentifiable path-specific effect. similar ideas adopted deal unidentifiable situation ranked data. leave part future work. repeatability software together datasets used paper available http//tiny.cc/fair-ranking. references constantin aliferis alexander statnikov ioannis tsamardinos subramani mani xenofon koutsoukos. local causal markov blanket induction causal discovery feature selection classification part algorithms empirical evaluation. journal machine learning research francesco bonchi sara hajian mishra daniele ramazzotti. exposing probabilistic causal structure discrimination. international journal data science analytics flavio calmon dennis bhanukiran vinzamuri karthikeyan natesan ramamurthy kush varshney. optimized pre-processing discrimination prevention. advances neural information processing systems. david heckerman john breese. look causal independence. proceedings tenth international conference uncertainty artificial intelligence. morgan kaufmann publishers inc. david heckerman john breese. causal independence probability assessment inference using bayesian networks. ieee transactions systems cybernetics-part systems humans mallows. non-null ranking models. biometrika john marden. analyzing modeling rank data. press. razieh nabi ilya shpitser. fair inference outcomes. arxiv preprint ioannis tsamardinos constantin aliferis alexander statnikov laura brown. scaling-up bayesian network learning thousands variables using local learning techniques. vanderbilt university tr-- muhammad bilal zafar isabel valera manuel gomez rogriguez krishna gummadi. fairness constraints mechanisms fair classification. artificial intelligence statistics. zhang yongkai xintao causal framework discovering removing direct indirect discrimination. ijcai’. zhang yongkai xintao achieving non-discrimination", "year": 2018}