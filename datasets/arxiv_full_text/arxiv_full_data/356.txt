{"title": "How Much Chemistry Does a Deep Neural Network Need to Know to Make  Accurate Predictions?", "tag": ["stat.ML", "cs.AI", "cs.CV", "cs.LG"], "abstract": "The meteoric rise of deep learning models in computer vision research, having achieved human-level accuracy in image recognition tasks is firm evidence of the impact of representation learning of deep neural networks. In the chemistry domain, recent advances have also led to the development of similar CNN models, such as Chemception, that is trained to predict chemical properties using images of molecular drawings. In this work, we investigate the effects of systematically removing and adding localized domain-specific information to the image channels of the training data. By augmenting images with only 3 additional basic information, and without introducing any architectural changes, we demonstrate that an augmented Chemception (AugChemception) outperforms the original model in the prediction of toxicity, activity, and solvation free energy. Then, by altering the information content in the images, and examining the resulting model's performance, we also identify two distinct learning patterns in predicting toxicity/activity as compared to solvation free energy. These patterns suggest that Chemception is learning about its tasks in the manner that is consistent with established knowledge. Thus, our work demonstrates that advanced chemical knowledge is not a pre-requisite for deep learning models to accurately predict complex chemical properties.", "text": "meteoric rise deep learning models computer vision research achieved human-level accuracy image recognition tasks evidence impact representation learning deep neural networks. chemistry domain recent advances also development similar models chemception trained predict chemical properties using images molecular drawings. work investigate effects systematically removing adding localized domain-speciﬁc information image channels training data. augmenting images additional basic information without introducing architectural changes demonstrate augmented chemception outperforms original model prediction toxicity activity solvation free energy. then altering information content images examining resulting model’s performance also identify distinct learning patterns predicting toxicity/activity compared solvation free energy. patterns suggest chemception learning tasks manner consistent established knowledge. thus work demonstrates advanced chemical knowledge pre-requisite deep learning models accurately predict complex chemical properties. role deep learning transforming computer vision research signiﬁcant. prior deep learning computer vision researchers reached glass ceiling top- error rate image recognition tasks. within years using deep neural network models human-level accuracy top- error rate achieved models become dominant algorithm computer vision research chemistry models winning entry merck kaggle challenge challenge following trend several research groups started using models predict numerous properties including activity toxicity reactivity solubility admet properties various computed energies. across chemistry domain models frequently performing well better previous state-of-the-art models based traditional machine learning algorithms. models capable learning representations sets apart conventional algorithms used chemistry. representation learning process transforming input data feature effectively exploited identify patterns data. historically computer vision research invested signiﬁcant effort designing appropriate features using applied mathematics. however today expert-driven feature engineering research replaced deep learning models representation learning ability primary reason models able exceed glass ceilings ﬁeld. chemistry context analogous process would deep learning examine chemical structures construct features similar engineered chemical features minimal assistance expert chemist. approach leverages representation learning deep neural networks signiﬁcant departure traditional research paradigm chemistry. observe recent trends literature exhibited subtle shift relying heavily engineered chemistry features development engineered representations molecule. specifically aspuru-guzik pande groups developed deep learning algorithms analyzing molecular graphs using smiles data also found effective. recent work chemception model also demonstrated even unsophisticated data like images molecular drawings minimal chemical information used develop models average equivalent contemporary models trained molecular ﬁngerprints. despite accomplishments lack labeled data chemistry impediment unlocking full potential representation learning deep neural networks. building original chemception work research provides contributions ﬁeld appropriate method encoding domain-speciﬁc information images improve model performance results experiments illuminate nature deep neural networks learn chemical data. first developed novel image augmentation technique adds localized chemical information channels images used train chemception. hypothesis behind approach relevant domainspeciﬁc information provided neural network would need learn representations basic features instead able direct learning capacity develop sophisticated representations improve accuracy predicting complex chemical properties. using augmented chemical images show outperforms earlier chemception models well contemporary deep learning models predicting broad range chemical properties including toxicity activity solvation free energy. best knowledge approach reported chemistry deep learning literature manipulating image channel data localized domain-speciﬁc information also relatively unexplored avenue computer vision research. second performed comprehensive experiments altering information content encoded image channels examined impact model accuracy. results demonstrate grasp advanced chemical knowledge pre-requisite deep learning models accurately predict chemical properties. furthermore based chemception’s performance various information content scenarios predicting toxicity/activity compared solvation free energy identiﬁed chemception learns manner appears consistent established chemical knowledge. best knowledge approach altering information content order infer how/what neural network learns also reported literature. following identical approach original chemception paper obtained freesolv datasets moleculenet benchmark database evaluate performance chemception predicting toxicity activity solvation free energy respectively. datasets comprise large small datasets physical non-physical properties regression classiﬁcation problems. addition solvation free energy also included data alchemical free energy calculations used target comparison existing physics-based models. summary end-to-end workﬂow chemception illustrated figure brieﬂy used open-source cheminformatics software rdkit convert smiles strings respective molecular structures. resulting coordinates molecule mapped onto discretized image pixels corresponds resolution pixel used train chemception. work varied information content image channels create several different augmented reduced information image formats details outlined results section. dataset pre-processing steps identical reported previously. used -fold cross validation protocol training evaluated performance early stopping criterion model using validation set. also included performance separate test indicator generalizability. speciﬁcally dataset database separated form test freesolv dataset database used form test set. remaining rate used batch size also included early stopping protocol reduce overﬁtting. done monitoring loss validation improvement validation loss epochs last best model saved ﬁnal model. addition training chemception image representations tested performed additional real-time data augmentation image using imagedatagenerator function keras image randomly rotated degrees. classiﬁcation tasks used binary crossentropy loss function evaluation metric reported paper determines models performance area roc-curve regression tasks used mean-squared-error loss function rmse evaluation metric. unless stated otherwise reported results paper mean values obtained -fold cross validation runs. section outline design principles augmented images adding localized information image channels reduced images simplifying information content encoded. single-channel greyscale images hereon referred standard images depict molecular drawings used. number corresponding atomic number used unique identiﬁer different atoms chemical bonds identiﬁed apart data additional information encoded image channels. computer vision research colored images commonly used information relevant color encoded multiple image channels typically using -channel -channel cmyk color model. adopting prinfigure smiles structure conversion images discretized used train deep neural network. work different image representations used. augmented images included localized atom bond-speciﬁc chemical information reduced images simpliﬁed information encoded single image channel. dataset used random -fold cross validation approach training chemception. classiﬁcation tasks also oversampled minority class address class imbalance observed dataset appending additional data minority class factor ratio classes. oversampling step performed stratiﬁcation ensure molecule repeated across training/validation/test sets. network design work used chemception model without modiﬁcation refer readers original publication architectural details. brieﬂy chemception model optimized handling sparse images representations chemical structures incorporates major advances recent research inception modules residual learning. typical chemception model alternating sequences stacked inception-resnet blocks reduction blocks based earlier work evaluated baseline optimized architectures. nomenclature used refers general depth network refers number ﬁlters convolutional layers. training neural network chemception trained using tensorﬂow backend acceleration using nvidia cudnn libraries. network created executed using keras functional interface rmsprop algorithm train epochs chemical task using standard settings recommended atom and/or bond speciﬁc chemical information -channel image format create augmented image representation anticipate addition appropriate localized chemical information would accelerate chemception training information used directly neural network need learn additional representations information already provided image channels. also hypothesize beneﬁts training augmented images useful small labeled data limit insufﬁcient data neural network develop optimal internal representations. caveat additional information encoded useful long relevant task predicted either direct correlation formation higher-level representations correlates task. work goal develop general-purpose format encoding chemical images using following design principles quick compute scalable encode basic chemical information. rationale ﬁrst principle ensure scalability large chemical databases. addition maintain compatibility existing image analysis tools also limited maximum number channels analogous -channel cmyk images. second design principle hypothesize would effective generalizable provide neural network building blocks construct complex features thus favor selection basic chemical information also incidentally inexpensive compute. based design principles selected several computable properties encoding includes bond order hybridization valency partial charge. technically information pertaining bond order inferred general topology structure representation requires sufﬁcient data deep neural networks learn therefore still beneﬁts encoding directly. hybridization context refers type hybridization atom valence refers number explicit connections atom bonded combined together appropriate context atom’s hybridization valence lead inferences bond order lone pairs related basic chemical concepts. lastly partial charge computed methods developed gasteiger represents basic electrostatics descriptions atom computed quickly. marized schema enga engb engc provides different channel atomic identity bond identity engd compresses atomic bond identity information single channel adds atom-speciﬁc information remaining channels. also explored alternative single-channel image representations infer nature type chemical representations chemception learned training data. approach start standard images systematically reduced content channel. ﬁrst level simpliﬁcation redb atoms identical assigned bonds assigned effectively makes identity different atoms indistinguishable. reda bonds removed images atoms remain. furthermore devised noise representation random dispersion noise values representation intentionally constructed not-a-molecule thus serving negative control determine chemception making predictions noise. similar fashion constructed truth representation serve positive control. representation systematically assigned every atom bond pixel molecule’s property active. lastly based results work also motivated development scrambled representation test importance chemical periodicity. representation atom bond assigned random unique number ensuring still uniquely identiﬁed information chemical periodicity inferred atomic number information available. section experiments performed determine best augmented image representation. resulting augmented chemception model compared contemporary models literature. lastly exploring effectiveness various augmented reduced images using appropriate comparisons literature identiﬁed distinct learning patterns suggests chemception learning tasks manner consistent established chemical knowledge. trained baseline chemception model optimized chemception model dataset using reduced augmented images results summarized figure previous best model achieved validation/test using standard images. augmented images best performance achieved validation/test optimized chemception model using enga image representation. also observed engineered representation achieved comparable performance albeit range. augmented images better standard images indicate additional information encoded used model improve performance. validation/test respectively. fact indicates neural network learned chemistry distinguish toxic non-toxic molecules relative positions generic indistinguishable atoms. chemical information redb images bonds explicitly indicated observed marginal improvement validation/test respective model. results suggest explicit knowledge bonds apparently important requirement determining molecular toxicity. given fundamentally important concept chemical bonds chemistry ﬁrst glance observation paradoxical. however recall bond artiﬁcial construct introduced denote linkages various atoms role chemistry research make easier chemists formulate sophisticated concepts starting notion bond. lastly note images used training chemception extremely sparse compared natural images used typical computer vision research; means typically less image usable information likely representations learned neural network would identify relevant data sub-% portion image. peculiar image characteristic signiﬁcant concern neural network representations might robust random scattering pixels look different valid molecular structure. account possibility examine performance control images. training noise images achieved validation/test means resulting model zero predictive power. opposite spectrum training chemception truth images resulted validation/test ./.. sets control experiments verify chemception learning something nothing also conﬁrms ability neural network extract relevant information even extremely sparse image. mance address question whether effect generalized chemical properties. here examine model performance different type chemical properties related toxicity namely activity solvation free energy results activity prediction summarized figure previous best model achieved validation/test using standard images. best performance achieved using augmented images validation/test baseline model optimized model using engc image representation. similar performance metrics observed engineered representations achieved comparable performance range. addition best representation toxicity prediction best representation activity prediction although observed difference metrics minimal. toxicity using augmented images provided consistently better results. results reducing chemical information activity prediction also parallels observed toxicity prediction increasing information content reda redb gradual improvement baseline chemception model similar trend observed optimized model. last chemical property solvation free energy uses much smaller dataset molecules. previous work using standard images achieved validation/test rmse kcal/mol. summarized figure augmented images substantially improved models performance. best performance achieved validation/test rmse kcal/mol baseline chemception model kcal/mol optimized chemception model using engd image representation. also observed unlike toxicity/activity predictions augmented image representations performed comparably another difference enga engd accuracy relative engb engc upon examination enga engd partial charge hybridization information encoded engb engc not. using chemistry intuition unexpected partial charge would extremely relevant predict solvation free energies serves proxy electrostatic nature atom local environment. next examine performance reduced images. noise images attain validation/test rmse kcal/mol. earlier observations chemception models trained noise images toxicity activity resulted model zero predictive power above-speciﬁed rmse value reasonable zero baseline. results indicate reduced images achieved rmse metrics kcal/mol compared kcal/mol accuracy standard images signiﬁcantly worse closer null results obtained noise images. note performance trend unlike observed toxicity activity predictions reduced images accuracy similar standard images noise images. summarize collective results various experiments thus indicate using augmented image representations developed work provided consistent performance improvement chemception’s accuracy relative standard images. addition improvement appears consistent across different datasets chemical properties suggests performance lift obtained using augmented images generalizable chemical properties. established using augmented images provide consistent performance improvement compare performance augchemception contemporary models reported literature. particular account performance metrics well amount chemical information used and/or provided input data. baseline model comparison multilayer perceptron deep neural network model reported moleculenet benchmark. addition also compare novel convolutional graph algorithm instead providing explicit chemistry features convgraph algorithm uses engineered graph representation depict molecule nodes annotated localized chemical information edges denote connectivity between atoms. conceptually convgraph algorithm augmented images reported work similar methods engineered representation data opposed relying explicit feature engineering. however difference method encodes molecule image format whereas convgraph encodes graph. based assessment order level chemical information provided following ascendfigure summarize best augchemception results relative models listed above. toxicity activity predictions augchemception outperforms baseline model. despite fact model trained chemical information uses engineered features input data augchemception even augmented images beneﬁts additional pieces basic chemical information. augchemception’s better performance provides evidence leveraging representation learning ability deep models data viable approach reduce necessity manual feature engineering explicit chemistry features. also note compared convgraph augchemception trails performance. contrast solvation free energy prediction augchemception best performing model across methods outperforming convgraph physics-based models. current level performance augchemception approaching holy grail kcal/mol chemical accuracy acknowledge similar levels accuracy reported physical properties recent studies. deep learning black algorithm challenging directly determine chemception learns trained predict various chemical properties. however given systematically added removed information image channels also using results comparable models literature possible make inferences based consistent patterns model performance formulate additional hypothesis models chemception learns chemical data. first summarize observations. toxicity activity prediction training reduced images provide less predictive accuracy still resulted chemception models fairly predictive respective tasks. contrast solvation free energy prediction using reduced images resulted accuracy close trained noise images. therefore based difference model accuracy improvement increasing chemical information toxicity/activity free energy solvation predictions appear follow distinct learning patterns. current approach toxicity research involves identiﬁcation toxicophores predict molecular toxicity. activity current structure-based research paradigm premised ﬁnding appropriate functional groups interact well target molecule binds observed trends chemception’s accuracy toxicity/activity modeling evident position atoms sufﬁcient construct model accurate null model. reduced images representations reasonably learned patterns atoms arranged analogous identifying functional groups. therefore suggests chemception operating primarily functional group identiﬁer consistent current understanding toxicity activity. contrast solvation free energies unlike toxicity/activity prediction physical property computed physics-based simulation methods. reduced images almost inaccurate model trained noise images signiﬁcant improvement accuracy noted atomic number information ﬁrst introduced. suggests learning functional group identiﬁer sufﬁcient atomic number piece information. atomic number possible neural network form representations related periodic trends concept chemistry properties like number electrons inferred. ﬁnding relevant contemporary physics-based simulation methods calculating free energies incorporate above-mentioned information. therefore suggest signiﬁcant improvement chemception’s accuracy introduction atomic number indicator learning manner similar established physics-based models. validate hypothesis importance atomic number developed scrambled image representation contains almost amount information standard images. representation atoms uniquely identiﬁed information periodicity lost. chemception models trained scrambled images achieved validation/test toxicity prediction activity prediction. compared results using standard images relative noise images scrambling atomic identities little effect expected network primarily learning identify speciﬁc patterns pixels image result stark contrast performance scrambled images free energy solvation prediction achieved validation/test rmse kcal/mol. compared results using standard images relative noise images huge performance indicates chemception using atomic number information calculation solvation free energies. next identify another trend comparing chemception convgraph chemception systematically underperforms activity toxicity prediction outperforms solvation free energy prediction. despite fact almost type chemical information provided either data representation. earlier hypothesis chemception operates functional group identiﬁer activity toxicity prediction explains apparent underperformance relative convgraph algorithm. molecule represented graph topology implicit data representation making easier identify topological patterns facilitate functional group identiﬁcation. contrast image speciﬁc representations need developed chemception understand molecular topology. next observed convgraph algorithm encoded atomic identity one-hot vector opposed work used atomic number directly. means periodicity difﬁcult infer. earlier hypothesis atomic number enables chemception learn similarly physicsbased models explains apparent underperformance convgraph algorithm relative chemception. ﬁnal section address underlying question behind work much chemistry deep neural network need know make accurate predictions? based ﬁndings basic chemical information necessary deep neural network predict complex chemical properties advanced chemistry knowledge evidently pre-requisite achieve accurate predictions. addition identiﬁed atomic number information critical predicting solvation free energies possibly also physical properties computed physics-based methods. also observed high efﬁciency chemception uses relevant information less input data altered various image representations. corollary statement well-trained neural network provided sufﬁcient data cannot achieve desired accuracy likely data provided entirely relevant task predicted. image augmentation domains image augmentation techniques developed work unique chemistry ﬁndings design principles generalized domains. situations limited labeled data encoding relevant domain-speciﬁc information image channels used bootstrap training deep neural network increase overall model accuracy. encoding localized pixel-speciﬁc information recommended complements well cnn’s ability handle spatial correlations images. encoding basic information analogous providing conceptual building blocks neural network helps generalize across different tasks domain. therefore anticipate image augmentation techniques considerable impact ﬁelds substantial prior domain-speciﬁc research includes many scientiﬁc engineering ﬁnancial modeling applications. conclusion developed series augmented images training chemception deep model predicts chemical properties using images molecular diagrams. encoding localized basic chemical information image channels improved accuracy chemception consistently outperforms contemporary deep learning models trained engineered chemistry features. speciﬁcally chemception achieved validation/test toxicity prediction activity prediction validation/test rmse kcal/mol solvation free energy prediction. furthermore altering information content encoded images identiﬁed distinct learning patterns appears parallel established chemistry knowledge. speciﬁcally infer chemception learns toxicity activity primarily functional group identiﬁer analogous current research identifying functional groups responsible toxicity activity solvation free energy show atomic number information necessary chemception achieve predictive accuracy importance chemical periodicity parallels underlying principles behind current physics-based simulations. therefore ﬁndings indicate chemception valuable tool future deep learning assisted chemistry data-driven research paradigm used ﬁrst-pass approach developing baseline models novel research problems.", "year": 2017}