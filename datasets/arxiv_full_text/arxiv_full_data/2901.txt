{"title": "Visual Language Modeling on CNN Image Representations", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Measuring the naturalness of images is important to generate realistic images or to detect unnatural regions in images. Additionally, a method to measure naturalness can be complementary to Convolutional Neural Network (CNN) based features, which are known to be insensitive to the naturalness of images. However, most probabilistic image models have insufficient capability of modeling the complex and abstract naturalness that we feel because they are built directly on raw image pixels. In this work, we assume that naturalness can be measured by the predictability on high-level features during eye movement. Based on this assumption, we propose a novel method to evaluate the naturalness by building a variant of Recurrent Neural Network Language Models on pre-trained CNN representations. Our method is applied to two tasks, demonstrating that 1) using our method as a regularizer enables us to generate more understandable images from image features than existing approaches, and 2) unnaturalness maps produced by our method achieve state-of-the-art eye fixation prediction performance on two well-studied datasets.", "text": "figure pipeline measure unnaturalness image. first mid-level representations taken image using pre-trained cnn. normalized orthogonalized column naturalness sequence feature vectors evaluated using recurrent neural network language model naturalness rnnlm based predictability sequence. finally unnaturalness summed unnaturalness score. probabilistic image models proposed applicable small image patches large natural images. moreover generally built directly image pixels. although preferred property low-level image processing image denoising insufﬁcient capability modeling complex abstract naturalness feel. work assume naturalness measured predictability high-level features movement. example moving eyes left right feels strangeness viewing scene predicted seen along way. strangeness presumably based edges shapes semantic signals pixel-level information. type naturalness studied extensively used widely natural language processing method called language model applied mainly regularizing outputs speech recognition machine translation systems. given sequence words premeasuring naturalness images important generate realistic images detect unnatural regions images. additionally method measure naturalness complementary convolutional neural network based features known insensitive naturalness images. however probabilistic image models insufﬁcient capability modeling complex abstract naturalness feel built directly image pixels. work assume naturalness measured predictability high-level features movement. based assumption propose novel method evaluate naturalness building variant recurrent neural network language models pre-trained representations. method applied tasks demonstrating using method regularizer enables generate understandable images image features existing approaches unnaturalness maps produced method achieve state-of-the-art ﬁxation prediction performance well-studied datasets. convolutional neural networks extract abstract features image pixels hierarchically. because representations learned image classiﬁcation highly discriminative generalized extremely important component computer vision. however known insensitive naturalness images. example images generated appear strange unrealistic furthermore susceptible unnatural noise artiﬁcial fabrication therefore method measure naturalness complementary features. dicts next word past words timestep computes naturalness entire sequence product prediction accuracy timesteps. although traditional n-gram models predict next word prior words still prevalent based recurrent neural networks emerged favorable option predict next word using words. motivated description above propose method evaluate image naturalness building variant rnnlm mid-level image representations extracted pre-trained cnn. rnnlm cannot accommodate two-dimensional representations. therefore apply vertically horizontally. designate method visual language model figure presents illustration method. figure presents example unnaturalness maps obtained using method. cnn-vlm measures naturalness using contextual information related high-level discriminative features difﬁcult accomplish using probabilistic image modeling pixels. concept treat image representations like words related well-known bag-of-visual-words however case representations quantized. apply method image reconstruction image features eye-ﬁxation prediction. naturalness images plays important role tasks. brieﬂy describe below. kind must imposed images demonstrate empirically using cnn-vlm regularizer enables generate understandable images produced using existing methods. human ﬁxation points images shown predictable using shannon’s self-information fact many attention models explainable perspective information theory self-information interpreted unlikelihood unnaturalness unnaturalness useful saliency map. demonstrate cnn-vlm achieves state-of-the-art performances ﬁxation prediction task experiment section. contributions summarized follows. based assumption naturalness measured predictability high-level features movement proposed novel method evaluate naturalness building variant language models pre-trained representations. conﬁrmed using method regularizer enables generate understandable images features existing approaches. showed unnaturalness maps produced using method achieve state-of-the-art ﬁxation prediction performance well-studied datasets. section presents brief review existing approaches related modeling naturalness images. additionally describe image reconstruction features ﬁxation prediction. many probabilistic image models proposed however applicable small ﬁxed-size image patches simple contents. overcome matter gregor used attention mechanisms succeeded generating realistic images. denton applied generative adversarial networks hierarchical way. theis bethge proposed scalable image model using multi-dimensional lstms predict pixel values certain locations preceding pixels. also predictions like theirs. however capture high-level information train representations pixels. several vision papers explicitly tirilly trained quantized local descriptors visual words. although approach similar ours used classiﬁcation measuring naturalness. ranzato trained language model small region videos predicts next time frame learn spatial-temporal video representations. reconstructing image representation important task understand characteristics representation. many works addressed problem hand-crafted representations deep representations mahendran vedaldi showed image reconstructed gradient descent representation extracted differentiable functions. also demonstrated natural image prior necessary reconstruct interpretable images. regularized reconstructed images eliminate spikes pixels within natural range. simonyan adopted similar approach used regularization images. dosovitskiy brox inverted features directly learning translates features images. demonstrated colors rough compositions original image reconstructed. modeling visual attention fundamentally important efﬁciently process massive real-world data. especially task predict ﬁxation points humans examined extensively bruce tsotsos demonstrated ﬁxation points predicted using shannon’s self-information. information-theoretic view adopted many research efforts method also uses kind selfinformation. many recent methods based supervised training ﬁxation dataset also trainable ﬂexible model. however trained unsupervised manner requires images target domain require ﬁxation data. because making dataset troublesome task favorable property practical applications. neural network achieves state-of-the-art performance image classiﬁcation extract image representations applies convolution nonlinear activation function downsampling hierarchical way. weights convolution kernels learned data minimize classiﬁcation error. mid-level representations cnns trained largescale generic image classiﬁcation dataset shown work high-performance generic image feature therefore become facto standard image feature recent years. outputs immediately convolution layers alexnet vggnet extract midlevel representations. table shows layer name caffe pre-trained model output size convolution layers. concretely regarding gaussian distribution assume mean determined using described section also assume variance timestep small model know much context sequence predicted values less reliable. using assumption rewritten negative likelihood written follows. expand model mid-level representation application rnnlm forward backward column. apply rnnlm axis direction. therefore four rnnlms layer. fyxl representation immediately layer size then deﬁne unnaturalness uyxl follows. therein µright fyx−l. corresponds scanning image left right predicting next time-step. µleft µdown also deﬁned similar way. deﬁne total unnaturalness compute naturalness must train rnnlm advance minimizing many natural images. stochastic gradient descent back-propagation time train rnnlm. training ilsvrc image classiﬁcation dataset training. representations alexnet vggnet alexnet learning rate momentum respectively minibatch size vggnet learning rate momentum respectively minibatch size however cannot learn long-term dependencies fact because gradients vanish process ﬂowing many hidden-to-hidden connections. overcome problem variant recurrent layer called long-short term memory proposed used lstm recurrent layer deﬁned shown below. using lstm sequential prediction described later. concretely stack lstm layers linear layer predict sequences. dimensions lstm layers half input layer. example representation conv layer alexnet comprises vectors dimensions. normalize dimension vectors zeromean unit-variance. normalization apply principal component analysis orthogonalize reduce dimensions half. parameters normalization learned training ilsvrc image classiﬁcation dataset used measure naturalness sequence. length sequence dimensional vectors decompose probability ppp...p. intuitive interpretation probability determined next vector predictable past vectors. mahendran vedaldi demonstrated image features inverted original image gradient descent feature extraction function comprises differentiable elements. technique introduction natural image prior objective function. denote original image feature extraction function then using weight regularizer reconstructed image used keeps pixel values natural range penalizes strong intensity change neighboring pixels. instead uˆi. differentiable objective function minimized ﬁxation prediction suggested humans look locations shannon’s self-information high self-information identical negative logarithm probability unnaturalness regarded kind information predicts salient locations. unnaturalness saliency map. additionally apply gaussian blur size according common practice blurring take root prevent excessive expansion peaky values. example unnaturalness saliency presented figure section present evaluation effectiveness proposed method application tasks image reconstruction features ﬁxation prediction. image reconstruction features evaluate image reconstruction method proposed section first discuss evaluate reconstructed images. present reconstructed images compare results existing methods. subsequently combine method work dosovitskiy brox present improved results. finally examine role layer imposing regularizer target layer. common preceding works reconstructed images outputs last fullyconnected layer alexnet used ﬁrst hundred images validation ilsvrc classiﬁcation dataset table human evaluation reconstruction method. hundred images hundred people crowdflower selected similar image original image three reconstructed images. total votes. actually results selected similar ones original images. weight unnaturalness weight regularizer learning rate momentum section unless otherwise noted {conv conv conv conv conv} λconvn learning rate momentum respectively initial solution sampled gaussian distribution mean standard deviation learned values natural images using training ilsvrc classiﬁcation dataset quantitative evaluation whether reconstructed image similar original image straightforward. earlier reports liteature provided quantitative analysis. using kind image feature produce unfair comparison mean squared error correlation coefﬁcient reconstructed images original images used date. vondrick evaluated reconstructed images asking humans classify reported correlation coefﬁcient always match judgments humans. therefore work determine similarity images asking humans. provide human subjects original image corresponding reconstructed images. select image reconstructed images similar original image. asked hundred people crowdflower. figure depicts original images reconstructed images method existing methods results method clear edges rather results mahendran vedaldi regularizers prohibited strong change intensity neighboring pixels. figure presents cases results judged inferior methods. method good reconstruction absolute positions colors objects. additionally method vulnerable unnatural images trained natural images. initial solution known affect result strongly especially neural networks fact breakthroughs deep networks resulted smart initialization weights results method dosovitskiy brox interpreted average possible solutions good initial solutions. figure last figure portray reconstructed images initialized outputs method presented dosovitskiy brox. results improved considerably previous results. images absolute positions colors objects corrected indicates limitations method mostly attributable initialization strategy compensated method presented dosovitskiy brox. figure cases results inferior methods according human evaluation. bottom original image mahendran vedaldi dosovitskiy brox ours initialized results dosovitskiy brox. left four columns result mahendran vedaldi best. right columns result dosovitskiy brox best. method presented dosovitskiy brox reconstructs overall shapes colors well although details lost method outputs average possible solutions. results appear similar original images. clear understandable helps interpret image features capture. figure images reconstructed regularization various feature maps. original image. regularization. regularized naturalness pixels output conv conv conv convolution layers. result regularized pixels completely understandable indicate importance modeling naturalness high-level features generating realistic images image pixels. results regularized conv conv less clear result conv implies information contained lower layers affects naturalness images. higher layers regularize abstract information insufﬁcient generating images. many datasets used ﬁxation prediction. herein evaluate method popular datasets called toronto additionally evaluate saliency benchmark consists datasets cat. saliency benchmark online benchmarking service. evaluation done submission. recently introduced dataset. includes images different image categories including action affective black white cartoon fractal indoor inverted jumbled line drawing low-resolution noisy object outdoor man-made outdoor natural pattern random satellite sketch social. dataset challenging categories natural scenes. ﬁxation task interpreted detection task detect ﬁxation point image. therefore areaunder-the-curve score curve often used evaluation however humans tend look around center image metric assigns much value center-biased saliency maps. overcome problem shufﬂed proposed metric computes pixels uniformly center-biased ﬁxation points images. shufﬂed score centered gaussian metric evaluation. table presents result cat. compare salicon deep deep gaze salnet mr-cnn wmap ittikoch scores available scoreboard saliency benchmark. conv conv results took second place ﬁrst place cat. noteworthy higher layers produce better results shown figure additionally although tried combine saliency maps different layers supervised training preliminary experiments produce performance improvement. results indicate ﬁxation points determined exclusively higherlevel signals. gory dataset. compared methods superior social cartoon affective. presumably true images categories include high-level contents faces pedestrians. inferior pattern resolution fractal because trained natural images. images categories apparently natural. prediction accuracy improved training rnnlm images categories. top-scoring methods saliency benchmark based supervised training eye-ﬁxation dataset methods require large ﬁxation dataset target domain. dataset dataset small performance models drop. difference scores deepfix indicates that. based unsupervised training. therefore unaffected problem. work based assumption naturalness measured predictability high-level features movement proposed novel method measure naturalness image building variant rnnlms features. used regularizer reconstructing images image features. results experiments show regularizer helps generate feasible images existing approaches. found naturalness lower layers important generate natural images. additionally evaluated unnaturalness maps images saliency maps. motivated assumption saliency images based selfinformation location. demonstrated proposed unnaturalness achieves state-of-the-art shufﬂed scores well-studied ﬁxation prediction datasets. indicated naturalness higher layers predicts ﬁxation points well. naturalness images especially large images include rich contents studied well. nonetheless methods assess detect naturalness images extremely useful demonstrated experiments. hope work provoke active research ﬁeld.", "year": 2015}