{"title": "An Error-Oriented Approach to Word Embedding Pre-Training", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "We propose a novel word embedding pre-training approach that exploits writing errors in learners' scripts. We compare our method to previous models that tune the embeddings based on script scores and the discrimination between correct and corrupt word contexts in addition to the generic commonly-used embeddings pre-trained on large corpora. The comparison is achieved by using the aforementioned models to bootstrap a neural network that learns to predict a holistic score for scripts. Furthermore, we investigate augmenting our model with error corrections and monitor the impact on performance. Our results show that our error-oriented approach outperforms other comparable ones which is further demonstrated when training on more data. Additionally, extending the model with corrections provides further performance gains when data sparsity is an issue.", "text": "propose novel word embedding pretraining approach exploits writing errors learners’ scripts. compare method previous models tune embeddings based script scores discrimination correct corrupt word contexts addition generic commonly-used embeddings pre-trained large corpora. comparison achieved using aforementioned models bootstrap neural network learns predict holistic score scripts. furthermore investigate augmenting model error corrections monitor impact performance. results show error-oriented approach outperforms comparable ones demonstrated training data. additionally extending model corrections provides performance gains data sparsity issue. assessing students’ writing plays inherent pedagogical role overall evaluation learning outcomes. traditionally human graders required mark essays costtimeinefﬁcient especially growing numbers students. moreover evaluation process subjective leads possible variations awarded scores human assessor employed. remedy this automated assessment writing motivated order automatically evaluate writing competence hence reduce grader workload also bypass grader inconsistencies system would responsible assessment. numerous systems developed research purposes deployed commercial including project essay grade e-rater intelligent essay assessor bayesian essay test scoring system among others. employ statistical approaches exploit wide range textual features. recent direction research focused applying deep learning task order circumvent heavy feature engineering involved traditional systems. several neural architectures employed including variants long short-term memory convolutional neural networks applied automated student assessment prize dataset released kaggle contest contains essays written middle-school english speaking students. dataset neural models operate word embeddings outperformed state-of-the-art statistical methods rely rich linguistic features results obtained neural networks asap dataset demonstrate ability capture properties writing quality without recourse handcrafted features. however datasets pose challenge neural models still fail beat state-of-the-art methods evaluated sets. example datasets first certiﬁcate english applying rank preference support vector machine trained various lexical grammatical features achieved best results motivates investigation initializing neural models contextually rich word embeddings pre-trained large corpora used feed networks meaningful embeddings rather random initialization. embeddings generic widely employed natural language processing tasks attempts made learn task-speciﬁc embeddings. instance alikaniotis developed score-speciﬁc word embeddings address task asap dataset. embeddings constructed ranking correct ngrams noisy counterparts addition capturing words’ informativeness measured contribution overall score essay. propose task-speciﬁc approach pre-train word embeddings utilized neural models error-oriented fashion. writing errors strong indicators quality writing competence good predictors overall script score especially scripts written language learners case dataset. example spearman’s rank correlation coefﬁcient script scores ratio errors indicative importance errors writing evaluation correlation could even higher error severity accounted errors could serious others. therefore seems plausible exploit writing errors integrate systems successfully done yannakoudakis yannakoudakis capturing information directly word embeddings neural model. pre-training model learns predict score ngram based errors contains modiﬁes word vectors accordingly. idea arrange embedding space discriminates good ngrams based contribution writing errors. bootstrapping assessment neural model learned embeddings could help detect wrong patimplement model compare performance initialized embeddings tuned based natural writing errors obtained bootstrapped sswe proposed alikaniotis relies random noisy contexts script scores. furthermore implement another version model augments ngram errors corrections investigate effect performance. additionally compare aforementioned pre-training approaches commonly used embeddings trained large corpora results show approach outperforms initialization methods augmenting model error corrections helps alleviate effects data sparsity. finally analyse pre-trained representations demonstrate embeddings better detecting errors inherent various attempts employ neural networks assess essays asap dataset. taghipour compared performance neural network variants obtained best results lstm followed mean time layer averages output lstm layer. alikaniotis assessed dataset building bidirectional double-layer lstm outperformed distributed memory model paragraph vectors support vector machines baselines. dong zhang implemented ﬁrst layer convolves ﬁlter weights words sentence followed aggregative pooling function construct sentence representations. subsequently second ﬁlter applied sentence representations followed pooling operation fully-connected layer predict ﬁnal score. applied asap dataset efﬁcacy in-domain domain-adaptation essay evaluation demonstrated comparison traditional state-of-the-art baselines. ones grades equal average score rest poor ones. calculated fisher scores ngrams selected highest scores useful ngrams. similarly generated correct ngrams grammatically correct texts classiﬁed rest ngrams used along useful ngrams shallow lexical features bag-of-words features. applied bayesian linear ridge regression regression domain-adaptation essay scoring using asap dataset. alikaniotis applied similar idea; sswe model trained word embeddings distinguish correct noisy contexts addition focusing word’s contribution overall text score. bootsrapping lstm model embeddings offered performance gains. models directly leveraged error information exhibited text. example yannakoudakis demonstrated adding error-rate feature ranking model uses wide range lexical grammatical writing competence features improves performance. calculated error-rate using error annotations cambridge learner corpus addition classifying trigram erroneous occur large ukwac corpus highly scoring scripts. yannakoudakis proposed bidirectional lstm error detection learner data model predicts probability word correct word text. extension experiment incorporated average predicted probability word correctness additional feature self-assessment tutoring system applied supervised ranking perceptron rich linguistic features. adding correctness probability feature successfully enhanced predictive power sat. section describe three different neural networks pre-train word representations model implemented alikaniotis error-oriented models propose work. models’ output embeddings referred aa-speciﬁc embeddings used later bootstrap system. score-speciﬁc word embeddings compare pre-training models sswe developed alikaniotis method inspired work collobert weston learns word representations distinguishing target word’s context noisy counterparts. counterparts generated replacing target word randomly selected word vocabulary. network trained rank positive correct contexts higher negative corrupt ones. additionally model augmented score speciﬁc information focus informative words contribute overall score essays rather frequent words occur equally good essays. optimize overall loss function weighted ranking loss correct noisy ngrams score speciﬁc loss hyperparameter. experiment giving weight score-related information. error-speciﬁc word embeddings propose model ﬁne-tunes embedding space using supervised method leverages errors appearing training data. modiﬁes embedding space discriminate erroneous ngrams correct ones. core difference approach sswe relies writing errors occurring naturally training data instead randomly generating incorrect ngrams capturing words’ informativeness. motivation adopting approach twofold. first believe model could learn useful features actual errors rather introducing random contexts unlikely happen. second sswe ignores frequent words less predictive power however despite fact frequent words carry less topical information content ones errors associated constitute substantial portion errors committed non-native english speakers. instance determiner errors account total errors public training data. therefore learning representations eswe model predicts error scores word ngrams. first demonstrate true error scores ngrams calculated second describe approach applied estimate scores. word training document given error indicating score based whether part error respectively. subsequently ngram gold score calculated based errors contains follows ngram length. model estimate ngram scores convolutional operation applied depicted figure first word rdwrd remapped unique vector vwrd trieved embedding space |×dwrd vocabulary size. consequently ngram represented concatenation word vectors scoring ngrams accomplished sliding convolutional linear ﬁlter rn×dwrd hereafter error ﬁlter ngrams script followed sigmoid non-linearity predicted score probability space table error script refer ﬁlter sizes. pre-training models datasets error ﬁlter size displayed along script ﬁlter size used network initialized embeddings left. refers public fce. script’s subsequences generate feature maps ﬁlter height number output feature maps. refer ﬁlter script ﬁlter. previously error ﬁlter used eswe ecswe approaches represents predicted ngram score whereas here system extracts various contextual features ngram prestep towards predicting script’s score hence setting large value. convolutional operation followed relu non-linearity capture complex linguistic phenomena subsequently average pooling function applied output feature maps order select useful features unify scripts’ representations vector ﬁxed length. finally last layer network fully connected applying linear regression script representation order predict ﬁnal score sigmoid function. error ﬁlter work error detector evaluates correctness words given contexts arranges embedding space accordingly. optimization squared errors loss minimized gold ngram scores estimated ones error gradients backpropagated embedding matrix building eswe space ngram index. error-correction-speciﬁc word embeddings extension eswe propose augmenting errors’ corrections follows. build corrected version script replacing errors suggested corrections train eswe model using corrected scripts together original ones. corrected version ngrams given consequently score according equation eswe equations applied loss script calculated loss original script corrected version motivation model twofold. first could enrich embedding space allowing model learn faulty ngrams correct counterparts construct ecswe modiﬁed version eswe capable distinguishing good contexts. second could alleviate effects data sparsity training small datasets learning representations. model previous section discusses pre-training approaches word embeddings later used initialize model. model second predict holistic score script follows. word input script initialized vector vwrd rdwrd pre-trained embedding matrix ....; vwrd sulting script embedding length script. convolutional ﬁlter rm×dwrd×h slid neural networks different tasks. generic models trained large corpora capture general semantic syntactic regularities hence creating richer meaningful word vectors opposed random vectors. particular google news wordvec glove pre-trained models used. google wordvec skip-gram model learns predict context given word. trained google news articles contain around billion words million unique words. hand glove vectors learned leveraging word-word cooccurrence statistics corpus. glove embeddings trained wikipedia dump addition gigaword total billion words. evaluation. replicate sswe model implement eswe ecswe models google glove embeddings conduct comparison initilization approaches feeding output embeddings system section models implemented using open-source python library theano evaluation calculate spearman’s rank correlation coefﬁcient pearson’s product-moment correlation coefﬁcient root mean square error ﬁnal predicted script scores ground-truth values dataset. experiments dataset consists exam scripts written english learners upper-intermediate proﬁciency graded scores ranging script contains answers corresponding different prompts asking learner write either article letter report composition short story. apply script-level evaluation concatenating answers using special answer token separate answers script. <i></i> error <c></c> suggested correction error type refers replace preposition. error-oriented models word considered error occurs inside error correction retrieved according correction tag. train models released public dataset contains scripts training scripts testing. order examine effects training extra data conduct experiments augment public additional scripts refer extended version fceext contains scripts. report results datasets released test set. public dataset divided scripts training development fceext scripts used training held development. data preprocessing employed word tokenization achieved using robust accurate statistical parsing system training. hyperparameter tuning done model separately. sswe eswe ecswe models initialized glove vectors trained epochs learning rate sswe batch size number randomly generated counterparts ngram size hidden layer network initialized models learning rate training public fceext. sizes used error script ﬁlters shown table networks optimized using stochastic gradient descent system regularized regularization rate trained epochs performance monitored sets. finally model best mean square error sets selected. public results shown table reveal aa-speciﬁc embedding pre-training offers gains performance traditional embeddings trained large corpora suggests suited task. table also demonstrates eswe model outperforms sswe correlation metrics slight difference rmse value. variance correlations models noticeable suggests eswe model powerful rmse values weaken assumption. result could attributed fact public small dataset sparse error representations sswe trained times data ngram paired randomly generated counterparts. therefore relevant comparison needed could achieved either training data discussed later enriching embedding space corrections table demonstrates learning errors corrections enhances error pretraining performance public indicates usefulness approach ability mitigate effects data sparsity. according results training model based naturally occurring errors correct counterparts better suited task rather introducing artiﬁcial noisy contexts tuning embeddings according scripts’ scores relying word distributions learned large corpora. robust analysis examine performance training additional data shown table comparing results tables proves training data boosts predictive power models. also clear table data discrepancy performance between sswe eswe models becomes prominent eswe provides superior performance evaluation metrics suggests that qualitatively learning learners’ errors efﬁcient bootstrapping method. however fceext ecswe approach outperforms eswe correlation metrics giving worse rmse value. change results training bigger dataset indicates effect incorporating corrections training becomes less obvious enough data distribution correct incorrect ngrams enough learn from. conduct analysis scores predicted aa-speciﬁc embeddings investigating ability eswe sswe models detect errors text. model epochs public fceext training sets test models respective sets examine output predictions. simplicity assign binary true score ngram zero value contains errors otherwise. eswe predicts score ngram indicating correctness hence could used directly evaluation. hand sswe predicts scores ngram correct score maximizes comparison noisy ngrams script score high good ngrams occur highly-graded scripts. scores hence expected high high-quality ngrams otherwise suggests used proxies error detection. calculate ngram predicted score sswe model weighted correct script scores similar loss function output probability based minimum maximum generated scores. calculate average precision true scores predicted ones respect error representing class compare random baseline random probability scores generated. results displayed table shows eswe achieves higher score evaluation sets particularly public sswe’s performance similar random baseline. result expected since eswe model trained predict actual errors empirical veriﬁcation required. conclude analysis tuning embeddings based training writing errors increases sensitivity unseen errors learners’ data assessment yields better performance comparable pre-training approaches. writing assessment neural networks. ﬁrst approach learns discriminate good ngrams leveraging writing errors occurring learner data. second extends ﬁrst combining error representations suggested corrections tuning embedding space accordingly. motivation applying models provide neural assessment systems minimum features useful task attempt boost performance challenging datasets still avoiding heavy feature engineering. presented results demonstrate error-oriented embeddings better suited learners’ script assessment generic embeddings trained large corpora used bootstrap neural assessment model. additionally embeddings yielded superior performance rely ranking correct noisy contexts well words’ contributions script’s overall score. furthermore extending error embeddings error corrections enhanced performance trained small data less obvious effect trained greater amounts data shows efﬁcacy enrich embedding space mitigate data sparsity issues. analysed embeddings score-speciﬁc ones showed empirically error-oriented representations better error detection explicates superior performance learners’ data evaluation. best performing model still underperforms state-of-the-art system yannakoudakis utilises wide variety features even exclude error related features. however improvement obtained error-oriented models employing generic embeddings score-specifc ones suggests pre-training approach promising avenue research provides neural network assessment useful information motivates learning relevant properties associated language proﬁciency. future work interesting jointly train score-speciﬁc model errororiented test could improve performance. also suggest fully automating assessment process using outputs automated error detection correction systems build embeddings rather relying handcrafted error annotations. finally encourage examination types features could useful assessment models incorporating pre-training stage. performance could enhanced less information heavily engineered systems require.", "year": 2017}