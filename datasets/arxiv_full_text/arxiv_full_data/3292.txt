{"title": "Generative Image Modeling Using Spatial LSTMs", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "Modeling the distribution of natural images is challenging, partly because of strong statistical dependencies which can extend over hundreds of pixels. Recurrent neural networks have been successful in capturing long-range dependencies in a number of problems but only recently have found their way into generative image models. We here introduce a recurrent image model based on multi-dimensional long short-term memory units which are particularly suited for image modeling due to their spatial structure. Our model scales to images of arbitrary size and its likelihood is computationally tractable. We find that it outperforms the state of the art in quantitative comparisons on several image datasets and produces promising results when used for texture synthesis and inpainting.", "text": "modeling distribution natural images challenging partly strong statistical dependencies extend hundreds pixels. recurrent neural networks successful capturing long-range dependencies number problems recently found generative image models. introduce recurrent image model based multidimensional long short-term memory units particularly suited image modeling spatial structure. model scales images arbitrary size likelihood computationally tractable. outperforms state quantitative comparisons several image datasets produces promising results used texture synthesis inpainting. last years seen tremendous progress learning useful image representations early successes often achieved generative models recent breakthroughs mainly driven improvements supervised techniques unsupervised learning potential much larger source unlabeled data important training bigger systems capable general scene understanding. example multimodal data abundant often unlabeled still greatly beneﬁt unsupervised approaches generative models provide principled approach unsupervised learning. perfect model natural images would able optimally predict parts image given parts image thereby clearly demonstrate form scene understanding. extended labels bayesian framework used perform semi-supervised learning generative model less clear combine unsupervised approaches discriminative learning. generative image models also useful traditional applications image reconstruction compression recently renewed strong interest development generative image models work tried bring bear ﬂexibility deep neural networks problem modeling distribution natural images. challenge endeavor right balance tractability ﬂexibility. present article contributes line research introducing fully tractable highly ﬂexible image model. model combines multi-dimensional recurrent neural networks mixtures experts. speciﬁcally backbone model formed spatial variant long short-term memory one-dimensional lstms particularly successful modeling text speech also used model progression frames video recently model single images contrast earlier work modeling images multi-dimensional lstms naturally lend task generative image modeling spatial structure ability capture long-range correlations. figure factorize distribution images prediction pixel depend pixel upper-left green region. graphical model representation mcgsm causal neighborhood limited small region. visualization recurrent image model layers spatial lstms. pixels image represented twice arrows omitted clarity. feedforward connections prediction pixel depends directly neighborhood recurrent connections access information much larger region model distribution pixels conditioned hidden states neural network mixtures conditional gaussian scale mixtures class models viewed generalization gaussian mixture models parametrization makes much suitable natural images. treating images instances stationary stochastic process model allows sample capture correlations arbitrarily large images. following ﬁrst review extend mcgsm multi-dimensional lstms explaining combine recurrent image model. section demonstrate validity approach evaluating comparing model number image datasets. successful approach building ﬂexible tractable generative models fullyvisible belief networks apply model images give pixels ordering specify distribution pixel conditioned parent pixels. several parametrizations suggested conditional distributions context natural images review extend work theis proposed mixtures conditional gaussian scale mixtures grayscale image patch intensity pixel location further x<ij designate pixels distribution parametric model parameters note factorization make independence assumptions simply application probability chain rule. note conditional distributions share parameters. improve representational power model thus endow conditional distribution parameters applying trick mixtures gaussian scale mixtures yields mcgsm untying shared parameters drastically increase number parameters. images easily reduced adding assumptions. example limit x<ij smaller neighborhood surrounding pixel making markov assumption. refer resulting parents pixel’s causal neighborhood another reasonable assumption stationarity shift invariance case learn parameters used every pixel location. similar convolutions neural networks allows model easily scale images arbitrary size. assumption reintroduces parameter sharing constraints model constraints different ones induced joint mixture model. positive deﬁnite. number parameters mcgsm still grows quadratically dimensionality causal neighborhood. reduce number parameters introduce factorized form mcgsm additional parameter sharing replacing factorized mcgsm allows larger neighborhoods mixture components. detailed derivation general version also allows multivariate pixels given supplementary section following brieﬂy describe spatial lstm special case multidimensional lstm ﬁrst described graves schmidhuber core model memory units hidden units hij. location two-dimensional grid operations performed spatial lstm given logistic sigmoid function indicates pointwise product afﬁne transformation depends parameters network gating units determine memory units affected inputs memory states written hidden units hij. contrast regular lstm deﬁned time memory unit spatial lstm preceding states cij− ci−j corresponding forget gates grid slstm units sequentially read relatively small neighborhoods pixels image producing hidden vector every pixel. hidden states factorized mcgsm predict state corresponding pixel importantly state hidden vector depends pixels x<ij violate factorization given equation nevertheless recurrent network allows recurrent image density estimator pixels much larger region prediction nonlinearly transform pixels applying mcgsm. increase representational power model stacking spatial lstms obtain deep still completely tractable recurrent image model larochelle murray derived tractable density estimator manner similar mcgsm derived using restricted boltzmann machines instead mixture models starting point. contrast mcgsm nade tries keep weight sharing constraints induced uria extended nade real values introduced hidden layers model gregor describe related autoregressive network binary data additionally allows stochastic hidden units. gregor used one-dimensional lstms generate images sequential manner model deﬁned bernoulli variables normalized values treated probabilities making direct comparison image models difﬁcult. contrast model presence stochastic latent variables draw means likelihood cannot evaluated approximated. ranzato srivastava one-dimensional recurrent neural networks model videos recurrency used describe distribution individual frames. srivastava optimize squared error corresponding gaussian assumption ranzato side-step model pixel intensities quantizing image patches. contrast also solve problem modeling pixel intensities using mcgsm equipped model heavy-tailed well multi-modal distributions. ride trained using stochastic gradient descent batch size momentum decreasing learning rate varying pass training mcgsm ride ﬁnetuned using l-bfgs iterations decreasing learning rate. regularization used except early stopping based validation set. except indicated otherwise recurrent model used pixel wide neighborhood mcgsm components quadratic features spatial lstms implemented using caffe framework appropriate augmented data horizontal vertical ﬂipping images. found conditionally whitening data greatly sped training process models. letting represent pixel causal neighborhood conditional whitening replaces covariance mean addition speeding training variance normalization step helps make learning rates less dependent training data. evaluating conditional log-likelihood compensate change variance adding log-jacobian note preconditioning introduces shortcut connection pixel neighborhood predicted pixel shown figure uria found forming ensembles autoregressive model different pixel orderings signiﬁcantly improved performance. consider simple trick produce ensemble without need training different models change training procedures. linear transformations leaving targeted image distribution invariant tk|. distribution pretrained model form ensemble note simply mixture model images considered rotating well ﬂipping images along horizontal vertical axes could argued transformations leave distribution natural images invariant nevertheless observed noticeable boost performance. several recent image models evaluated small image patches sampled berkeley segmentation dataset although model’s strength lies ability scale large images capture long-range correlations include results bsds make connection part literature. followed protocol uria images turned grayscale uniform noise added account integer discretization resulting values divided training images split images training images validation test contained images. model rnade rnade rnade eornade layers comp. comp. deep layers mcgsm comp. mcgsm comp. mcgsm comp. mcgsm comp. eomcgsm comp. ride layer ride layers eoride layers extracted image patches subtracted average pixel intensity patch’s component zero. resulting image patches live dimensional subspace bottom-right pixel discarded. used patches training patches validation test patches evaluation. mcgsms evaluated dataset ﬁrst tested mcgsms training single factorized mcgsm pixel conditioned previous pixels ﬁxed ordering. already mcgsm outperforms single models including deep gaussian mixture model ensemble mcgsms outperforms ensemble rnades hidden layers knowledge currently best result reported dataset. training recurrent image density estimator dimensional dataset cumbersome. tried padding image patches zeros necessary able compute hidden state every pixel. bottom-right pixel ignored training evaluation. simple approach reduction performance relative mcgsm possible explanation model cannot distinguish pixel intensities zero zeros padded region. supplying model additional binary indicators inputs solve problem. however found ride outperforms mcgsm large margin images treated instances stochastic process mcgsms trained iterations l-bfgs pixels corresponding causal neighborhoods extracted training images. causal neighborhoods pixels wide pixels high. ride trained epochs image patches increasing size ranging pixels right column table shows average log-likelihood rates models. analogously entropy rate expected log-likelihood rate make sets numbers comparable transformed nats commonly reported dimensional data pixel log-likelihood rate using formula a|)// takes account log-likelihood missing component model mcgsm comp. mcgsm comp. diffusion ride hid. layer ride hid. layer ext. ride hid. layers ride hid. layers ride hid. layers eoride hid. layers table average log-likelihood rates dead leaf images. deep recurrent image model deep diffusion model using ensembles able improve likelihood. figure model performance dead leaves function causal neighborhood width. simply increasing neighborhood size mcgsm sufﬁcient improve performance. jacobian transformations applied preprocessing rates table comparable sense differences express much better model would losslessly compressing bsds test images another patch-based models would compress patches image independently. highlighted best result achieved model gray. note models list scale well large images mcgsm ride therefore unlikely beneﬁt much increasing patch size. comparison log-likelihood rates reveals mcgsm components applied large images already captures correlations model applied small image patches. difference particularly striking given factorized mcgsm approximately parameters components approximately parameters. using ensemble rides able improve number signiﬁcantly another dataset frequently used test generative image models dataset published hateren schaaf details preprocessing used paper given supplementary section reevaluated several models likelihood reported dataset likelihood rates well results patches given table larger patch size ride already outperforms mcgsm patches. dead leaf images generated superimposing disks random intensity size simple procedure leads images already share many statistical properties challenges natural images occlusions long-range correlations leaving others non-stationary statistics. therefore provide interesting test case natural image models. used images image pixels size. compare performance ride mcgsm recently introduced deep multiscale model based diffusion process images previous literature used evaluation used remaining images training. introduction slstm hidden units greatly improves performance mcgsm. also tried extended version slstm included memory units additional inputs yielded small improvement performance adding layers using hidden units drastic improvements. using layers hidden units layer recurrent image model deep diffusion model. using ensembles able beat previously published results dataset figure shows improved performance ride simply effectively larger causal neighborhood nonlinear transformations performed slstm units matter. simply increasing neighborhood size mcgsm yield improvement. instead performance quickly saturates. also performance ride slightly deteriorates larger neighborhoods likely caused optimization difﬁculties. figure bottom pixel crop texture sample generated mcgsm trained full texture sample generated ride. illustrates model capture variety different statistical patterns. addition recurrent neural network seems particularly helpful strong long-range correlations intuition kinds correlations ride capture fails capture tried synthesize textures. used several pixel textures published brodatz textures split sixteen pixel regions used training randomly selected region kept testing purposes. ride trained epochs patches increasing size ranging pixels. samples generated mcgsm ride shown figure models able capture wide range correlation structures. however mcgsm seems struggle textures bimodal marginal distributions periodic patterns ride clearly improves textures although also struggles faithfully reproduce periodic structure. possible explanations include lstms well suited capture periodicities failures penalized strong enough likelihood. textures ride produces samples nearly indistinguishable real textures application generative image models inpainting proof concept used model inpaint large region textures missing pixels replaced sampling posterior ride. unlike joint distribution posterior distribution cannot sampled directly resort markov chain monte carlo methods. found following metropolis within gibbs procedure efﬁcient enough. missing pixels initialized ancestral sampling. since ancestral sampling cheap generated candidates used largest posterior density. following initialization sequentially updated overlapping pixel regions metropolis sampling. proposals generated ancestral sampling accepted using acceptance probability represents pixel patch proposed replacement. since evaluating joint conditional densities entire image costly approximated using ride applied pixel patch surrounding randomly ﬂipping images vertically horizontally sampling helped. figure shows results gibbs sampling sweeps. introduced ride deep tractable recurrent image model based spatial lstms. model exempliﬁes recent insights deep learning exploited generative image modeling shows superior performance quantitative comparisons. ride able capture many different statistical patterns demonstrated application textures. important property considering intermediate level abstraction natural images viewed collections textures. furthermore introduced factorized version mcgsm allowed experts larger causal neighborhoods. model parameters easy train already performs well image model. therefore ideal building block used extend models draw video models deep generative image models come long since deep belief networks ﬁrst applied natural images unlike convolutional neural networks object recognition however approach proven likely solution problem generative image modeling. conceptual work necessary come model handle abstract high-level well low-level statistics natural images. authors would like thank a¨aron oord insightful discussions wieland brendel christian behrens matthias k¨ummerer helpful input paper. study ﬁnancially supported german research foundation", "year": 2015}