{"title": "ChemGAN challenge for drug discovery: can AI reproduce natural chemical  diversity?", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Generating molecules with desired chemical properties is important for drug discovery. The use of generative neural networks is promising for this task. However, from visual inspection, it often appears that generated samples lack diversity. In this paper, we quantify this internal chemical diversity, and we raise the following challenge: can a nontrivial AI model reproduce natural chemical diversity for desired molecules? To illustrate this question, we consider two generative models: a Reinforcement Learning model and the recently introduced ORGAN. Both fail at this challenge. We hope this challenge will stimulate research in this direction.", "text": "generating molecules desired chemical properties important drug discovery. generative neural networks promising task. however visual inspection often appears generated samples lack diversity. paper quantify internal chemical diversity raise following challenge nontrivial model reproduce natural chemical diversity desired molecules? illustrate question consider generative models reinforcement learning model recently introduced organ. fail challenge. hope challenge stimulate research direction. drug discovery like ﬁnding needle haysack. chemical space potential drugs contains molecules. moreover testing drug medical setting time-consuming expensive. getting drug market take years cost billion context computer-based methods increasingly employed accelerate drug discovery reduce development costs. particular growing interest ai-based generative models. goal generate lead compounds silico medical chemical properties predicted advance. examples approach include variational auto-encoders networks however research ﬁeld often remains exploratory stage generated samples sometimes evaluated visually respect metrics relevant actual drug discovery process. ated samples. generating chemically diverse stream molecules important drug candidates fail many unexpected ways later drug discovery pipeline. based visual inspection reports reinforcement learning generative model tends produce simplistic molecules. hand argues objective-reinforced generative adversarial network generates less repetitive less simplistic samples however argument also based visual inspection therefore remains subjective visual inspection organ-generated samples output satisfying non-trivial chemical property internal chemical diversity output least equal diversity found nature kind molecules? druglikeness deﬁned interested property experimental results facilitate discussion. however notion druglikeness different notion quantitative estimation druglikeness index measuring different physico-chemical properties facilitating oral drug action. here druglikeness arithmetic mean solubility novelty synthesizability conciseness mention recently considers organ deﬁnition druglikeness. however also performed experiments property affect conclusions. sufﬁciently large sufﬁciently large subset sampled uniform probability internal diversity property follows large numbers. thus deﬁne internal diversity generative model computing internal diversity sufﬁciently large generated sample. allows formalize challenge main insight paper compare internal diversities generated natural molecules respectively instead considering relative diversity generated natural molecules generator viewed reinforcement learning agent state currently produced sequence characters action next character selected alphabet agent policy corresponds probability choose given previous characters pre-train models epochs maximum likelihood estimation random subset molecules zinc database million commercially-available compounds virtual screening used drug discovery train models organ respectively epochs more. table show proportion valid smiles output average probability activity dopamine average internal diversity proportion molecules probability activity greater importantly average internal diversity among samples probability activity greater that’s important column related open problem. averages computed valid smiles whereas proportions computed generated smiles compute quantities d-active molecules excape-db output reinforcement learning model epochs epochs output organ epochs epochs epochs outputs samples. interesting case epochs. case increasing probability activity contradictory keeping diversity. epochs internal diversity still pretty good overall even higher diversity baseline. organ-. results mostly analogous note epochs diversity orders magnitude better however still remains order magnitude lower baseline epochs diversity dropped levels similar organ-. learning property still start epochs. situation analogous seqgan case described obtain organ brings character-aware neural language model parameterized basically convolutional neural network whose output given lstm. training data data generated plays role discriminator distinguish smiles output probability belongs training data. table show proportion valid smiles output average druglikeness average internal diversity proportion molecules druglikeness greater importantly average internal diversity among samples druglikeness greater again that’s important column related challenge. results show organ indeed improves since able raise internal diversity detectable levels. however organ diversity still remains orders magnitudes lower zinc diversity organ diversity also remains orders magnitude lower cccccccccsccccccc coccccccccccccccsc ccccccncccccccsc cocccccccccccccccccc ccccccccccccccccccccccc coccnccccccccc ccocccccccccccccnccccccccccc coccccccccccccccccc cccccsccccccccoc ccccoccccccccccsc conclude organ fail match natural chemical diversity desired molecules although organ slightly better future work organ training improved considering distinct problems organ training discriminator quickly becomes perfect perfectly distinguishes training data generated data. general situation good adversarial learning here discriminator still teaches something generator. average according discriminator probability generated sample belong training still remains although always smaller probability transmitted generator reward function. however able ’fool’ discriminator even seqgan case shows generator weakness shows inability reproduce plain druglike dataset like zinc. training seqgan properly ﬁrst step towards improving organ. discriminator might also overﬁt training data. taking larger training could help took samples small compared training sets natural language processing. hand datasets drug discovery rarely exceed molecules therefore could also interesting look direction low-data predictive neural networks adversarial training stabilized might interesting replace classiﬁers reward function discriminators adversarially trained different datasets. various desired properties might instilled generated molecules multiple discriminators. might better transmit chemical diversity present various training sets. problem weighted agent always focuses easiest objective ignores harder ones. moreover relative difﬁculty objectives evolves time. example average probability activity initially grows exponentially growth small probability near using time-varying adaptive weights might help. moreover weights might necessarily linear example reward function form converges towards using objective function form focuses generator hard objective case relative weights different objectives must determined automatically guesswork. drug discovery setting molecule must simultaneously satisfy large number objectives. example antipsychotic drug enough active molecule must also pass toxicity druglikeness tests. moreover avoid side-effects molecule must active serotonin histamine. that’s objectives include reward function.", "year": 2017}