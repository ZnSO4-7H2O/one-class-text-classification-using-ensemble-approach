{"title": "Multipartite Ranking-Selection of Low-Dimensional Instances by  Supervised Projection to High-Dimensional Space", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "Pruning of redundant or irrelevant instances of data is a key to every successful solution for pattern recognition. In this paper, we present a novel ranking-selection framework for low-length but highly correlated instances. Instead of working in the low-dimensional instance space, we learn a supervised projection to high-dimensional space spanned by the number of classes in the dataset under study. Imposing higher distinctions via exposing the notion of labels to the instances, lets to deploy one versus all ranking for each individual classes and selecting quality instances via adaptive thresholding of the overall scores. To prove the efficiency of our paradigm, we employ it for the purpose of texture understanding which is a hard recognition challenge due to high similarity of texture pixels and low dimensionality of their color features. Our experiments show considerable improvements in recognition performance over other local descriptors on several publicly available datasets.", "text": "abstract. pruning redundant irrelevant instances data every successful solution pattern recognition. paper present novel ranking-selection framework low-length highly correlated instances. instead working low-dimensional instance space learn supervised projection high-dimensional space spanned number classes dataset study. imposing higher distinctions exposing notion labels instances lets deploy versus ranking individual classes selecting quality instances adaptive thresholding overall scores. prove eﬃciency paradigm employ purpose texture understanding hard recognition challenge high similarity texture pixels dimensionality color features. experiments show considerable improvements recognition performance local descriptors several publicly available datasets. literature instance ranking selection vast. sampling conventional method relying random selection form subset data. another type methods based selecting relevant data form critical points boundary points prototypes highly separate groups data best represent group contrast classiﬁcation instance ranking typically produces ranking instances assigning score instance sorting scores instance ranking consists main proposals preference learning bipartite multipartite rankings generally count number ranking errors bipartite amounts area curve equivalently wilcoxon statistic multipartite generalizes concordance index statistics used evaluate discriminatory power predictive accuracy nonlinear statistical models work propose multipartite instance ranking-selection framework low-dimensional instances usually seem dense highly similar because short lengths. novel paradigm employs supervised learning project instances high-dimensional space spanned number classes dataset hand. result notion labels transfers projected instances space imposes higher distinction among several classes. make separation criterion measure rank projected instances. individual dimension exposes speciﬁc class method deploys multipartite ranking score separability instances. aggregating scores coming class measures overall distinction instances. scores hand algorithm selects high quality instances applying adaptive thresholding. figure visualizes multipartite instance ranking-selection framework details. conduct experiments texture understanding task. texture important visual clue various tasks scene understanding material recognition texture perception description segmentation synthesis hand texture features computed convolution images bank ﬁlters. highly correlated length corresponds number color channels three color images grayscale samples. average texture dataset number pixels becomes thousands millions means feature would array millions three/one-dimensional instances. huge number instances redundant similarity diﬀerent classes textures. hence seems employing well-crafted instance ranking-selection algorithm improve performance texture classiﬁers. worth mentioning framework general applied features. conclude introduction point three main contributions work. ﬁrst contribution supervised projection high dimensions contrast common dimensional reduction practices literature. second contribution using bipartite ranking perform multipartite scoring fact projected instances contains information available classes recorded higher dimensions. third contribution employing adaptive thresholding instance selection avoid processing irrelevant redundant instances. organize paper follows section introduces learning framework section appendix formulate supervised projection section elaborates instance ranking-selection framework. proceed reporting experiments section ﬁnally concluding section labels instances highly correlated. able classify directly number false matches would probably high degrade recognition precision dramatically. reﬂect notion labels instances ranking purpose project space spanned number classes separability gets maximized whilst scattering within becomes minimized. goal learn optimal projection impose highest possible distinction applying ranking-selection algorithm improves performance multi-label classiﬁcation dataset study. sponds l-norm. ﬁrst term equation aims making highest possible separability among instance classes. second part regularization term imposing orthogonality projection matrix. solution introducing scatterings expose number classes dimensions contrast conventional scatterings deﬁned based dimension input instances appendix formulate deﬁnitions equations prove eigenvectors corresponding largest eigenvalues solution high-dimensional projection. solve equation able start random initialization initial projection matrix come optimal projection matrix instead take eigenvectors initial projection matrix. although considered sub-optimal projection matrix employ starting point optimize equation fact equation appendix trace-of-quotient solved generalized eigenvalue method equation quotient-of-trace requires diﬀerent solution among variety solvers optimization problem equation employ fast iterative shrinkage-thresholding algorithm gradient descent method mathematical proof fast convergence. implementation utilize unlocbox toolbox algorithm summarizes procedure computing optimal projection projected instance instance ranking-selection projecting instance need employ rankingselection strategy. fact operate pixel level number instances quite huge handled reasonable amount time. target choosing minimal subset instances criteria removes irrelevant redundant ones hence dataset would better representative data distribution. number techniques literature deal feature selection generating randomized subset features directed classiﬁer sequential feature selection using ensemble methods ﬁnally ranking features class separability criteria focus ranking class separability criteria because already introduce class-spanned projection section based fisher criterion. here challenge tailor method instance ranking-selection. instances stands number classes dataset conceptual diﬀerence instance feature selection. feature selection aims pruning redundancy columns instance selection removes irrelevant rows. word tailor column-based feature ranking algorithm row-based instance selection problem. ranking scheme basically employs absolute value two-sample t-test pooled variance estimate independent evaluation criterion sake binary classiﬁcation. multi-class sets deploys versus ranking means holding class merging others simulate binary labeling regime algorithm. ﬁnds proper feature columns train then select correspondent ones test form instances. impossible adopt strategy instance selection reasons. first correspondence instance rows train test sets. second know labels test time hence able apply independent feature ranking test set. solution address problem based orthogonality imposed second term equation supervised projection paradigm. orthogonality lets suppose column projected instance corresponds directly individual class dataset. holds train test sets learn optimal projection former apply latter. means notion labels exposed test although know test time. hence consider spanned classes columns pseudo-labels start ﬁrst column corresponds ﬁrst pseudo-label. merge remaining columns single class employ feature ranking overall ranking score projected instances summing measures individual instance. highest score better separated instance projected overall scores hand able select high-ranked instances prune rest. several selection strategies applied overall scores. either select instances predeﬁned threshold prune them. another strategy adaptive thresholding deploy otsu’s method purpose fact roughly experiments employ three well-known local texture descriptors apply framework four publicly available texture datasets also deploy oxford visual geometry group’s implementation reports mean accuracy texture recognition averaged standard number splits according evaluation protocols. consider three ﬁlter banks consisting ﬁlters size gaussian ﬁlters three scales eight four gaussian ﬁlters scales second ﬁlter bank maximum-response includes ﬁlters three scales ﬁlter bank schmid contains rotationally invariant ﬁlters also conduct experiments following texture datasets. kthtips-a kth-tips-b stand textures varying illumination pose scale latter consists images former uses images samples. images material sample used train three samples test. flicker material dataset includes images selected manually flickr. follow evaluation using images class training remaining testing. describable texture dataset contains annotated texture images adjectives vocabulary english words preset splits equally-sized training validation test sets. input data employ cie-lab color components contrast using luminance channel common practice literature. gives chance deploying information texture luminance chrominance channels purpose recognition. table show performance texture classiﬁcation terms mean accuracy instance ranking-selection framework. ﬁrst column represents improved fisher vector baseline second provides performances combination selected instances third column shows percentage improvement baseline respectively. according results framework performs highly competitive nearly improvement precision texture recognition followed kth-tips-b kth-tips-a datasets. worth noting datasets consist quality texture images captured controlled lighting conditions distances hence better improvements comparison expected. spite huge diﬀerence number classes framework quite competitive although performance dataset. improvements fact learning framework highly separates texture classes proposed class space. also worth mentioning works quite competitive datasets texture images various number instances. also computationally eﬃcient learn supervised projection rather whole texture ﬁlter hence easily expands large number ﬁlters learned parallel better generalization. experiment optimize ﬁlter banks respect supervised projection scheme. suppose ﬁlter generated real function generally gaussian laplacian gaussian function deploys scale orientation resolution provide nonlinear optimization respect ﬁlter parameters. besides minimization problem suﬀers lack generalization might lead ill-conditioned scattering matrices. tackle challenges redeﬁne equation least-square minimization problem smoothing functions impose symmetry avoids biases towards majority texture classes. ﬁnally equation optimal ﬁlter parameters provides optimal texture ﬁlter convolution. wrap optimization process algorithm solve equation employ nonlinear least-squares minimization trust-region-reﬂective algorithm built-in implementation matlab optimization toolbox table presents performance texture recognition optimal ﬁlters. seen framework improves performance ranking-only datasets study. kth-tips-a kth-tips-b improvements related learning ﬁlter parameters added ranking-only experiment respectively. datasets almost improvement respect baseline previous experiment means learning ﬁlter parameters performance. datasets hence discrimination power supervised projection solely enough separate details similar texture classes tailoring ﬁlter parameters based complexity dataset performs signiﬁcantly better large number classes. paper propose novel instance ranking-selection framework targeting low-dimensional instances apply purpose texture understanding hard challenge pattern recognition. scheme consists supervised projection high-dimensional space using multipartite scoring space instance ranking employing adaptive thresholding selection prune irrelevant redundant instances contribution proposed recognition task. experiments several texture datasets conﬁrm eﬃciency framework make signiﬁcant improvements accuracy compared state-of-the-art local texture descriptors. explain speciﬁc interpretation projection higher dimensions start formulate classical dimension reduction method extend proposed projection paradigm. regarded average class-speciﬁc covariance whereas viewed mean distance diﬀerent classes. thus purpose equation maximize between-class scatter preserving within-class dispersion mapped space. here identity matrix. non-invertible matrix moore-penrose pseudo-inverse common generalized inverse based factorization here need compute inverses. solved either kronecker tensor trick using generalized eigen decomposition because deﬁne non-singular matrices. closed form solution equation roth’s removal rule", "year": 2016}