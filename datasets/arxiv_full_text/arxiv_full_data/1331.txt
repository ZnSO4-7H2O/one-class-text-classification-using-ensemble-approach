{"title": "Contour Detection Using Cost-Sensitive Convolutional Neural Networks", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "We address the problem of contour detection via per-pixel classifications of edge point. To facilitate the process, the proposed approach leverages with DenseNet, an efficient implementation of multiscale convolutional neural networks (CNNs), to extract an informative feature vector for each pixel and uses an SVM classifier to accomplish contour detection. The main challenge lies in adapting a pre-trained per-image CNN model for yielding per-pixel image features. We propose to base on the DenseNet architecture to achieve pixelwise fine-tuning and then consider a cost-sensitive strategy to further improve the learning with a small dataset of edge and non-edge image patches. In the experiment of contour detection, we look into the effectiveness of combining per-pixel features from different CNN layers and obtain comparable performances to the state-of-the-art on BSDS500.", "text": "address problem contour detection per-pixel classiﬁcations edge point. facilitate process proposed approach leverages densenet efﬁcient implementation multiscale convolutional neural networks extract informative feature vector pixel uses classiﬁer accomplish contour detection. main challenge lies adapting pre-trained per-image model yielding per-pixel image features. propose base densenet architecture achieve pixelwise ﬁne-tuning consider cost-sensitive strategy improve learning small dataset edge non-edge image patches. experiment contour detection look effectiveness combining per-pixel features different layers obtain comparable performances state-of-the-art bsds. contour detection fundamental wide range computer vision applications including image segmentation object detection recognition task often carried exploring local image cues intensity color gradients texture local structures take example doll´ar zitnick structured random forests learn local edge patterns report current state-of-the-art results impressive computation efﬁciency. recently object cues also considered kivinen ganin lempitsky boost performance. despite constant evolvement relevant techniques better solving problem seeking appropriate feature representation remains cornerstone efforts. thus motivated propose learning formulation generate suitable per-pixel features satisfactorily performing contour detection. consider deep neural networks construct desired per-pixel feature learner. particular since underlying task essentially classiﬁcation problem adopt deep convolutional neural networks establish discriminative approach. however subtle deviation typical applications cnns emphasized. method intend architecture e.g. alexnet generate features image pixel single feature vector whole input image. distinction would call different perspective parameter ﬁne-tuning pre-trained per-image imagenet adapted model per-pixel edge classiﬁcations. investigate property features different convolutional layers various ensembles carry number experiments evaluate effectiveness performing contour detection benchmark bsds segmentation dataset organization paper follows. section includes related work contour detection deep convolutional neural networks. section describe overall model learning per-pixel features useful techniques ﬁne-tuning parameters. section provides detailed experimental results comparisons demonstrate advantages method. section discuss ideas proposed techniques possible future research efforts. stated focus using deep convolutional neural network achieve feature learning improving contour detection. survey relevant work thus presented give insightful picture recent progress areas emphasis. early techniques contour detection mainly concern local image cues intensity color gradients. amongst them canny detector stands simplicity accuracy owing exploring peak gradient magnitude orthogonal contour direction. detailed discussions approaches found e.g. bowyer subsequent work along line also identiﬁes textures useful local cues increasing detection accuracy. apart detecting local cues learning-based techniques form notable group addressing intriguing task doll´ar adopt boosted classiﬁer independently label pixel learning surrounding image patch. zheng analyze combination low- mid- high-level information detect object-speciﬁc contours. addition xiaofeng propose compute sparse code gradients successfully improve arbelaez classify edge patches sketch tokens using random forest classiﬁers capture local edge structures. isola consider pointwise mutual information extract global object contours. results display crisp clean contours. like doll´ar zitnick structured random forests learn edge patches achieve current state-of-the-art results accuracy efﬁciency. relevant approach kivinen ganin lempitsky learn contour information deep architectures. kivinen encode decode contours using multilayer mean-and-covariance restricted boltzmann machines. ganin lempitsky establish deep architecture composes convolutional neural networks nearest neighbor search obtain convincing results. different ganin lempitsky strive designing ﬁne-tuning mechanisms small dataset adapting imagenet pre-trained convolutional neural network producing per-pixel image features. later effort leads state-of-the-art results contour detection benchmark testing. noticeably cnns popularized lecun colleagues ﬁrst apply cnns digit recognition generic object recognition contrast using hand-crafted features cnns learn discriminative features exhibit hierarchical semantic information along deep architecture. alexnet krizhevsky perhaps popular implementation cnns generic object classiﬁcation. model shown outperform competing approaches based traditional features solving number mainstream computer vision problems. turaga briggman cnns used image segmentation. extend cnns object detection farabet utilize cnns semantic segmentation. sermanet cnns predict object locations sliding window learning multi-stage features cnns pedestrian detection proposed sermanet girshick also consider features deep region proposal framework achieve state-of-the-art object detection results pascal dataset. cnns thrives generic object recognition detection less attention paid applications demanding per-pixel processing contour detection segmentation. method exploits alexnet model contour detection explores per-pixel ﬁne-tuning small dataset. recently independently work generating per-pixel features based cnns also found hariharan long learning features employing deep architecture neural shown effective existing techniques focus yielding feature vector input image design appropriate vision applications require investigating image characteristics pixel level. problem contour detection central task decide whether underlying pixel edge point not. thus would convenient deep network could yield per-pixel features. propose construct multiscale model contour detection. extract perpixel features alexnet using densenet pixelwise concatenate feed support vector machine classiﬁer. particular densenet provides fast multiscale feature pyramid extraction caffe convolutional neural networks convenience working images arbitrary size. extract per-pixel features upsample feature maps ﬁrst convolutional layer ﬁfth convolutional layer original size input image. pixelwise stack features differen convolutional layers constitute per-pixel features. depending selection convolutional layers resulting feature vector pixel would encode different level information underlying pixel. figure illustrates case concatenating features convolutional layers form feature vector pixel. decide pixel contour point readily feed corresponding feature vector classiﬁer. practice useful include information neighboring pixels local contour structures better distinguished. consider following eight neighboring pixels append starting respective feature vector clockwise order. implementation tested correspond image patch size respectively. densenet feature extraction efﬁciency ﬂexibility availability. densenet open source system computes dense multiscale features convolutional layers caffe based object classiﬁer. process feature extraction proceeds follows. given input image densenet computes multiscale versions stitches large plane. processing whole plane cnns densenet would unstitch descriptor planes obtain multiresolution descriptors. dimensions convolutional features ratios image size e.g. one-fourth conv one-eighth conv. rescale feature maps convolutional layers image size. feature vector every pixel. illustrated figure dimension resulting feature vector concatenated conv conv conv conv conv classiﬁcation ﬁrst concatenate features surrounding eight pixels incorporate information local contour structure combined per-pixel feature vectors train binary linear svm. speciﬁcally multiscale setting train based original resolution. test time classify test images using original double resolutions. average resulting edge maps ﬁnal output contour detection. ﬁne-tune parameters per-pixel contour detection exclude fully-connected layers imagenet pre-trained model layers cause restrict input image size consequently overall architecture. keep convolutional layers conv -way softmax layer edge classiﬁcation. speciﬁcally input image size imagenet pre-trained model suitable per-pixel design conv layer would still addition need remove padding conform densenet padding carry per-pixel ﬁne-tuning ﬁrst generate edge non-edge patches. image size would reduce conv -way softmax layer properly compute per-pixel probability contour point. note loss back-propagation computed label prediction ground truth center pixel input patch. compared number parameters densenet size training edge nonedge patches relatively small. using aforementioned per-pixel ﬁne-tuning alone usually insufﬁcient achieve good performance. still addressing edges evident certain underlying features especially crucial distinguishing edges non-edges. learn subtle features small database adopt concept cost-sensitive learning. original -way softmax training cost negative log-likelihood cost input image patch parameters binary edge label prediction. cost computed -way softmax layer back-propagated train convolutional layers. apply cost-sensitive ﬁne-tuning consider biased negative log-likelihood cost respectively bias positive negative training data. reduced original negative log-likelihood cost approach positive cost-sensitive ﬁne-tuning negative costsensitive ﬁne-tuning. notice that rather directly back-propagating convenient alternative strategy create biased sampling ﬁne-tuning positive costsensitive ﬁne-tuning sample twice edge patches non-edge ones vice versa negative cost-sensitive ﬁne-tuning. table contour detection results employing different ﬁne-tuning schemes. experiments conv features since setting reﬂects effectiveness ﬁne-tuning directly. contour detection results using features different layers. conv- denotes using features convolutional layers conv- layers note that sake comparisons models include features surrounding pixels described section overall framework ensemble model. combine imagenet pre-trained model perpixel ﬁne-tuned model positive cost-sensitive ﬁne-tuned model negative cost-sensitive ﬁnetuned model together. heuristic branch-and-bound scheme decide fusion coefﬁcients. idea fusing different training models capture different aspects features. worthy mentioning improvements owing model fusion indicates various ﬁne-tunings merits feature learning useful respect. test method berkeley segmentation dataset benchmark better assess effects various ﬁne-tuning techniques report respective performance contour detection. comparisons competitive methods also included demonstrate effectiveness proposed model. bsds dataset current facto standard image collection contour detection. dataset contains training validation testing images. boundaries image labeled several workers averaged form ground truth. accuracy contour detection evaluated three measures best f-measure dataset ﬁxed threshold aggregate f-measure dataset best threshold image average precision full recall range prior evaluation apply standard non-maximal suppression technique edge maps obtain thinned edges parameter ﬁne-tuning done server geforce titan black card. overall learning rate tenth original imagenet pre-trained learning rate softmax learning rate times overall learning rate. modiﬁcation proposed per-pixel ﬁne-tuning speeds parameter ﬁne-tuning process. takes days ﬁnish iterations per-pixel ﬁne-tuning requiring days traditional ﬁne-tuning. traditional ﬁne-tuning per-pixel ﬁne-tuning sample boundary nonboundary patches training image. positive cost-sensitive ﬁne-tuning sample boundary patches non-boundary patches training image boundary patches non-boundary patches training image negative cost-sensitive ﬁne-tuning. report results various ﬁne-tuning techniques table experiments conv features carried classiﬁcations. since setting similar softmax ﬁne-tuning architecture directly observe effectiveness ﬁne-tuning. experiment results show that compared baseline traditional ﬁne-tuning table comparisons methods bsds. compare methods seven competitive techniques including gpb-owt-ucm sketch tokens sparse code gradients deepnet pointwise mutual information -ﬁelds structured edges. except deepnet -ﬁelds also plot curves compared methods. original ﬁne-tuning architecture padding every layer degrades overall performance implies traditional per-image ﬁne-tuning appropriate learning per-pixel features per-pixel applications. hand per-pixel ﬁne-tuning improves performance measurements. pertaining cost-sensitive ﬁne-tuning compared per-pixel ﬁne-tuning positive ﬁne-tuning slightly degrades negative ﬁne-tuning slightly improves. possible explanation relatively non-boundary regions boundary points features learned non-boundary regions improve overall performance. however combine features positive negative ﬁne-tuning performance signiﬁcantly boosted performance gain signiﬁes complementary property positive negative ﬁne-tunings expected. conclusion per-pixel ﬁne-tuning raises performances per-pixel applications. also combination positive negative cost-sensitive ﬁne-tunings improves classiﬁcation performance most. therefore supports advantage using ensemble ﬁne-tuning model. next conduct experiments show features different convolutional layers contribute performance. table features second convolutional layer contribute most third fourth layer. suggest lowmid-level features useful contour detection lowesthigher-level features provide additional boost. although features ﬁrst ﬁfth convolutional layer less effective employed alone achieve best results combining streams. indicates local edge information low-level features object contour information higher-level features necessary achieving high performance contour detection tasks. finally show experimental results pre-trained model ﬁnal fusion model. table report contour detection performances bsds methods seven competitive techniques including sketch tokens sparse code gradients deepnet pointwise mutual information -ﬁelds structured edges -stream imagenet pre-trained model already achieves impressive results contour detection measurements proposed ﬁne-tuning techniques improve performance. particular ﬁnal ensemble model improves measurement measurement. also achieves state-of-the-art performance measurement. figure include number contour detection examples qualitative visualization. work describe densenet architecture tailor per-pixel computer vision problems contour detection. propose ﬁne-tuning techniques effectively carry parameter learning per-pixel based cost function overcome limitation using small training set. resulting cost-sensitive model appears promising generating useful per-pixel feature vectors useful computer vision applications requiring analyzing local image property. interesting future research direction establish proper dimensionality reduction framework resulting high-dimensional per-pixel feature vectors examine effects performance contour detection. references arbelaez pablo maire michael fowlkes charless malik jitendra. contour detection hierarchical image segmentation. pattern analysis machine intelligence ieee transactions bowyer kevin kranenburg christine dougherty sean. edge detector evaluation using empirical curves. computer vision pattern recognition ieee computer society conference volume ieee doll´ar piotr zhuowen belongie serge. supervised learning edges object boundaries. computer vision pattern recognition ieee computer society conference volume ieee farabet clement couprie camille najman laurent lecun yann. learning hierarchical features scene labeling. pattern analysis machine intelligence ieee transactions iandola forrest moskewicz matt karayev sergey girshick ross darrell trevor keutzer kurt. densenet implementing efﬁcient convnet descriptor pyramids. arxiv preprint arxiv. isola phillip zoran daniel krishnan dilip adelson edward crisp boundary detection using pointwise mutual information. computer vision–eccv springer jarrett kevin kavukcuoglu koray ranzato lecun yann. best multi-stage architecture object recognition? computer vision ieee international conference ieee yangqing shelhamer evan donahue jeff karayev sergey long jonathan girshick ross guadarrama sergio darrell trevor. caffe convolutional architecture fast feature embedding. arxiv preprint arxiv. kivinen jyri williams christopher heess nicolas technologies deepmind. visual boundary prediction deep neural prediction network quality dissection. proceedings seventeenth international conference artiﬁcial intelligence statistics krizhevsky alex sutskever ilya hinton geoffrey imagenet classiﬁcation deep convolutional neural networks. advances neural information processing systems lecun yann boser bernhard denker john henderson donnie howard richard hubbard wayne jackel lawrence backpropagation applied handwritten code recognition. neural computation joseph zitnick lawrence doll´ar piotr. sketch tokens learned mid-level representation contour object detection. computer vision pattern recognition ieee conference ieee martin david fowlkes charless doron malik jitendra. database human segmented natural images application evaluating segmentation algorithms measuring ecological statistics. computer vision iccv proceedings. eighth ieee international conference volume ieee martin david fowlkes charless malik jitendra. learning detect natural image boundaries using local brightness color texture cues. pattern analysis machine intelligence ieee transactions sermanet pierre eigen david zhang xiang mathieu micha¨el fergus lecun yann. overfeat integrated recognition localization detection using convolutional networks. arxiv preprint arxiv. shotton jamie blake andrew cipolla roberto. multiscale categorical object recognition using contour fragments. pattern analysis machine intelligence ieee transactions turaga srinivas murray joseph jain viren roth fabian helmstaedter moritz briggman kevin denk winfried seung sebastian. convolutional networks learn generate afﬁnity graphs image segmentation. neural computation", "year": 2014}