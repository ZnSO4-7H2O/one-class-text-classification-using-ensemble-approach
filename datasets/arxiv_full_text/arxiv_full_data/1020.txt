{"title": "Improving Power Generation Efficiency using Deep Neural Networks", "tag": ["stat.ML", "cs.LG", "cs.NE"], "abstract": "Recently there has been significant research on power generation, distribution and transmission efficiency especially in the case of renewable resources. The main objective is reduction of energy losses and this requires improvements on data acquisition and analysis. In this paper we address these concerns by using consumers' electrical smart meter readings to estimate network loading and this information can then be used for better capacity planning. We compare Deep Neural Network (DNN) methods with traditional methods for load forecasting. Our results indicate that DNN methods outperform most traditional methods. This comes at the cost of additional computational complexity but this can be addressed with the use of cloud resources. We also illustrate how these results can be used to better support dynamic pricing.", "text": "recently signiﬁcant research power generation distribution transmission efﬁciency especially case renewable resources. main objective reduction energy losses requires improvements data acquisition analysis. paper address concerns using consumers’ electrical smart meter readings estimate network loading information used better capacity planning. compare deep neural network methods traditional methods load forecasting. results indicate methods outperform traditional methods. comes cost additional computational complexity addressed cloud resources. also illustrate results used better support dynamic pricing. currently energy produced worldwide uses coal natural gas. however much energy wasted. united states america approximately energy produced wasted furthermore wasted energy industrial residential buildings. reducing energy wastage electric power industry reduce damage environment reduce dependence fossil fuels. short-term load forecasting assist since predicting load precise planning supply estimation price determination. leads decreased operating costs increased proﬁts reliable electricity supply customer. past decades research stlf numerous models proposed solve problem. models classiﬁed classical approaches like moving average regression models well machine learning based techniques regression trees support vector machines artiﬁcial neural networks recent years many deep learning methods shown achieve state-of-the-art performance various areas speech recognition computer vision natural language processing promise demonstrated areas computer science lack thorough research. deep learning methods representation-learning methods multiple levels representation obtained composing simple nonlinear modules transform representation level representation higher slightly abstract level composition enough transformations complex functions learned. paper compare deep learning traditional methods applied stlf problem also provide comprehensive analysis numerous deep learning models. show methods used assist pricing electricity lead less energy wastage. best knowledge little work comparisons power usage electrical grid. data based year smart meter data collected residential customers. apply deep traditional algorithms collected data also noting corresponding computational runtimes. differences electricity usage week weekend split data datasets weekends weekly data. algorithms applied datasets results analyzed. results show deep architectures superior traditional methods lowest error rate longest run-time. space limitations provide details traditional approaches provide references. ﬁrst look baseline methods table table performs worst mape would indicate problem linear however algorithm outperforms rest methods noticeable margin. shows problem split discrete segments would accurately forecast load. conﬁrmed looking load figure clear that depending time signiﬁcant overlap value load days. thus node determining time would signiﬁcantly improve accuracy. run-time algorithms quite short taking longest cross-validation step determined possible coefﬁcients steps dataset consists samples features collected several households. dataset broken parts training validation testing sizes respectively. readings recorded hourly intervals throughout year. features electrical load readings previous hour previous hours previous three hours previous hour previous previous hour previous previous hours previous days hour previous days previous hour previous days previous hours previous week hour average past hours average past days. rest features week hour weekend holiday temperature humidity. features selected typically used stlf. addition total electrical load change signiﬁcantly throughout year since households located tropical country temperature remains fairly constant throughout year. preprocessing step data cleaned scaled zero mean unit variance. traditional methods cross-validation determine appropriate values hyper-parameters. random grid search used determine hyper-parameters deep learning methods. several baseline algorithms chosen. include weighted moving average βyi− multiple linear regression quadratic regression regression tree minimum number branch nodes support vector regression linear kernel multilayer perception number hidden neurons typically long running time architectures algorithms restricted epocs. table clear difference looking epocs epocs mape columns algorithms lower mape running epocs compared epocs. especially true dnn-sa signiﬁcant drops mape. perform worst epocs always lower half accuracy. indicates shallow network might ﬁnding patterns structure data quickly architectures. however outperformed epocs. alludes fact hidden layer helping capture underlying dynamics cannot. looking epocs column dnn-w performs best mape hand stable architecture dnn-sa mape consistently less robustness shown epocs increased dnn-sa architecture outperforms methods pretraining certainly gave methods boost methods guides learning towards basins attraction minima support better generalization training data rnns extent lstm internal state gives ability exhibit dynamic temporal behavior. however require much longer time compute evident table since methods trouble mapping underlying dynamics data small number epocs. cnns maintain internal state however load forecasting data expect fair amount autocorrelation requires memory. could explain taking tables consideration architectures vastly outperform traditional approaches dnns require signiﬁcantly time thus trade-off. stlf dynamic environment cannot wait model complete training stage. hence another reason limited number epocs table shows limiting epocs adversely affect many architectures able surpass accuracy traditional methods selecting model would determine length time model worth trade-off accuracy runtime. know people different electrical usage patterns weekdays compared weekends. difference seen figure illustrates usage sample home. household uses energy weekdays weekends. electrical proﬁles opposite i.e. weekend electrical load more. whatever scenario usually different proﬁles weekdays weekends. clear algorithms lowest mape week. indicative patterns weekdays similar result data. data dnns better able capture underlying structure data thus able predict electrical load greater accuracy. weekend predictions higher mape since dnns require data perform accurate predictions weekends data limited. seem best sunday poor mape rest days. indicates models internal bias towards sunday result fail accurately predict values days. clear again dnns outperform traditional methods. particular domain electricity provider also interested changes electrical load opposed absolute error order adjust generation accordingly mostly starting additional plants takes time. mean percentage error used. would tell model positive value under-predicts load negative value overpredicts actual value adjust operations accordingly. many traditional methods predicted electrical load actual load including mlp. however dnns under-predicted load value. looking best table dnn-sas values positive indicates under-predicts value. however alone. example rnns positive however it’s mape epocs around indicates slightly larger values under-predicts over-predicts overall accuracy good deep architectures. using results stlf company accurately predict upcoming load. would mean power generating company produce energy much precise amount rather producing excess energy would wasted. since companies fossil fuels nonrenewable sources energy would conserving well reducing levels carbon dioxide released atmosphere toxic byproducts fossil fuels. another beneﬁt accurate load forecasting dynamic pricing. many residential customers ﬁxed rate kilowatt. dynamic pricing approach allows cost electricity based expensive electricity produce given time. production cost based many factors paper characterized algorithms stlf. precise forecast electrical load companies ability determine trends especially peak times. example would summer months many people want turn conditioners thus electricity becomes expensive produce company could start additional power generating plants account load. algorithms predict would increase electrical load around summer months would reﬂected higher price consumers would need pay. result people would want keep conditioner time necessary. taking example adding washing machines lights appliances immense decrease energy achieved consumer side. area short-term load forecasting studied many decades deep learning recently seen surge research applications. signiﬁcant research focused recurrent neural networks thesis rnns used compare methods stlf. methods included modiﬁcations training algorithms like particle swarm optimization genetic algorithms artiﬁcial immune systems. notable papers attempt apply stlf compare deep feedfoward neural networks rnns kernelized regression. paper used forecasting loads result compared feedfoward neural network. however thorough comparison various architectures lacking applications dynamic pricing energy efﬁciency absent. paper focused energy wastage electrical grid. achieve this ﬁrst needed accurate algorithm stlf. advent many deep learning algorithms compared accuracy number deep learning methods traditional methods. results indicate architectures achieve greater accuracy traditional methods even data split weekdays weekends. however algorithms longer runtimes. also discussed algorithms signiﬁcant impact conserving energy producer consumer levels. dong-xiao wang qiang jin-chao. advances machine learning cybernetics international conference chapter short term load forecasting model based support vector machine. sainath vinyals senior convolutional long short-term memory fully connected ieee international deep neural networks. conference acoustics speech signal processing shin hoo-chang orton collins d.j. doran leach m.o. autoencoder time-series analysis unsupervised tissues characterisation large unlabelled medical image dataset. machine learning applications workshops international conference collobert ronan weston jason. uniﬁed architecture natural language processing deep neural networks proceedings multitask learning. international conference machine learning andrade l.c.m. silva i.n. short-term load forecasting based arima model intelligent intelligent system applications power systems. systems isap international conference erhan dumitru bengio yoshua courville aaron manzagol pierre-antoine vincent pascal bengio samy. unsupervised pre-training help deep learning? mach. learn. res. march schmidhuber j¨urgen. artiﬁcial neural networks icann international conference vienna austria august proceedings chapter applying lstm time series predictable time-window approaches. hinton geoffrey deng dong rahman mohamed abdel jaitly navdeep senior andrew vanhoucke vincent nguyen patrick dahl tara sainath george kingsbury brian. deep neural networks acoustic modeling speech recognition. ieee signal processing magazine krizhevsky alex sutskever ilya hinton geoffrey imagenet classiﬁcation deep convolutional neural networks. advances neural information processing systems", "year": 2016}