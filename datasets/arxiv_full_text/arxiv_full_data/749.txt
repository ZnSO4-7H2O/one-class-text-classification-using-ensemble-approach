{"title": "Evolving Classifiers: Methods for Incremental Learning", "tag": ["cs.LG", "cs.AI", "cs.NE"], "abstract": "The ability of a classifier to take on new information and classes by evolving the classifier without it having to be fully retrained is known as incremental learning. Incremental learning has been successfully applied to many classification problems, where the data is changing and is not all available at once. In this paper there is a comparison between Learn++, which is one of the most recent incremental learning algorithms, and the new proposed method of Incremental Learning Using Genetic Algorithm (ILUGA). Learn++ has shown good incremental learning capabilities on benchmark datasets on which the new ILUGA method has been tested. ILUGA has also shown good incremental learning ability using only a few classifiers and does not suffer from catastrophic forgetting. The results obtained for ILUGA on the Optical Character Recognition (OCR) and Wine datasets are good, with an overall accuracy of 93% and 94% respectively showing a 4% improvement over Learn++.MT for the difficult multi-class OCR dataset.", "text": "optimal separating hyperplane classes found. svms find classifier minimizes misclassification rate. classifier implemented vector essentially kernel trick. validation sets binary classifiers trained using train evolved using find optimal parameters svm. variables optimized kernel functions train strong classifier using train optimize parameters using optimize voting weights binary decision classifier using respectively classes performed poorly training data classes performed poorly training data results svmlearn++.mt learn++.mt iluga shown table respectively. classes trained stage. thus generalized performance sections low. results learn++.mt svmlearn++.mt show learn classes well first time seen using dynamic weight update classes", "year": 2007}