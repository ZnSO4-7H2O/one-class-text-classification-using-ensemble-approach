{"title": "3D Object Dense Reconstruction from a Single Depth View", "tag": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "abstract": "In this paper, we propose a novel approach, 3D-RecGAN++, which reconstructs the complete 3D structure of a given object from a single arbitrary depth view using generative adversarial networks. Unlike existing work which typically requires multiple views of the same object or class labels to recover the full 3D geometry, the proposed 3D-RecGAN++ only takes the voxel grid representation of a depth view of the object as input, and is able to generate the complete 3D occupancy grid with a high resolution of 256^3 by recovering the occluded/missing regions. The key idea is to combine the generative capabilities of autoencoders and the conditional Generative Adversarial Networks (GAN) framework, to infer accurate and fine-grained 3D structures of objects in high-dimensional voxel space. Extensive experiments on large synthetic datasets and real-world Kinect datasets show that the proposed 3D-RecGAN++ significantly outperforms the state of the art in single view 3D object reconstruction, and is able to reconstruct unseen types of objects.", "text": "abstract—in paper propose novel approach d-recgan++ reconstructs complete structure given object single arbitrary depth view using generative adversarial networks. unlike existing work typically requires multiple views object class labels recover full geometry proposed d-recgan++ takes voxel grid representation depth view object input able generate complete occupancy grid high resolution recovering occluded/missing regions. idea combine generative capabilities autoencoders conditional generative adversarial networks framework infer accurate ﬁne-grained structures objects high-dimensional voxel space. extensive experiments large synthetic datasets real-world kinect datasets show proposed d-recgan++ signiﬁcantly outperforms state single view object reconstruction able reconstruct unseen types objects. object essential many graphics robotics applications ar/vr semantic understanding robot grasping obstacle avoidance. classic approaches off-the-shelf low-cost depth sensing devices kinect realsense cameras recover shape object captured depth images. approaches typically require multiple depth images different viewing angles object estimate complete structure however practice always feasible scan surfaces object reconstruction leads incomplete shapes occluded regions large holes. addition acquiring processing multiple depth views require computing power ideal many applications require real-time performance. paper tackle problem estimating complete structure object using single depth view. challenging task since partial observation object theoretically associated inﬁnite number possible models. traditional reconstruction approaches typically interpolation techniques plane ﬁtting laplacian hole ﬁlling poisson surface estimation infer underlying structure. however recover limited occluded missing regions e.g. small holes gaps quantization artifacts sensor noise insufﬁcient geometry information. yang stefano rosa andrew markham niki trigoni department computer science university oxford e-mail{bo.yangstefano.rosaandrew.markhamniki.trigoni}cs.ox.ac.uk corresponding hongkai department computer example given view chair rear legs occluded front legs humans easily able guess likely shape behind visible parts. recent advances deep neural networks data driven approaches show promising results dealing task. paper acquire complete highresolution shape object given single depth view. utilizing high performance convolutional neural nets large open datasets models approach learns smooth function view complete dense shape. particular train end-to-end model estimates full volumetric occupancy single depth view object. state-of-the-art deep learning approaches shape reconstruction single depth view achieve encouraging results limited small resolutions typically scale voxel grids. result learnt structure tends coarse inaccurate. however increase shape resolution without sacriﬁcing recovery accuracy challenging even slightly higher resolution would exponentially increase search space potential mapping functions resulting difﬁculties convergence neural nets. recently deep generative models achieve impressive success modeling complex high-dimensional data distributions among generative adversarial networks variational autoencoders emerge powerful frameworks generative learning including image text generation latent space learning past years number works applied generative models learn latent space represent object shapes order solve simple discriminative tasks image generation object classiﬁcation recognition shape retrieval. structure conditioned single view. particularly model ﬁrstly encodes view low-dimensional latent space vector implicitly represents general geometric structures decodes back recover likely full shape. rough shape conditional discriminator adversarially trained distinguish whether coarse structure plausible not. autoencoder able approximate corresponding shape adversarial training tends details estimated shape. ensure ﬁnal generated shape corresponds input single partial view adversarial training model based conditional instead random guessing. novel efﬁcient network design excels competing approaches either single fully connected layer capacity decoder multi-stage inefﬁcient lstms estimate full shapes. contributions follows propose novel generative model reconstruct complete accurate structure using single arbitrary depth view. particularly model takes simple occupancy grid input without requiring object class labels annotations predicting compelling shape within high resolution voxel grid. drawing autoencoder approach end-to-end trainable high level generality. best knowledge ﬁrst work reconstructs high resolution shapes using single view. exploit conditional training reﬁne shape estimated autoencoder. contribution mean value latent vector feature instead single scalar output discriminator stabilize training. conduct extensive experiments single category multi-category object reconstruction outperforming state art. importantly approach also able generalize previously unseen object categories. last model also performances robustly real-world dataset collected kinect trained purely synthetic datasets. best knowledge good open datasets ground truth occluded/missing parts holes view real world scenarios. therefore contribute real world testing dataset community. related work review different pipelines reconstruction shape completion. conventional geometry based techniques state deep learning based approaches covered. model/shape completion. uses plane ﬁtting complete small missing regions apply shape symmetry holes. although methods show good results relying predeﬁned geometric regularities fundamentally limits structure space hand-crafted shapes. besides approaches likely fail missing occluded regions relatively big. another similar ﬁtting pipeline leverage database priors. given partial shape input retrieve identical likely model align partial scan. however approaches explicitly assume database contains identical similar shapes thus unable generalize novel objects categories. multiple rgb/depth images reconstruction. traditionally dense reconstruction requires collection images geometric shape recovered dense feature extraction matching directly minimizing reprojection errors color images. recently leverage deep neural nets learn shape multiple images. however resolution recovered occupancy shape usually small scale advancement depth sensors depth images also used recover object shape. classic approaches usually fuse multiple depth images iterative closest point algorithms recent work learns shape using deep neural nets multiple depth views. single image reconstruction. predicting complete object model single view longstanding extremely challenging task. reconstructing speciﬁc object category model templates used. example morphable models exploited face recovery concept extended reconstruct simple objects general complex object reconstruction single image recent works infer shapes using multiple images weak supervision. however training procedure stage rather end-to-end uses simple autoencoder instead designing sophisticated learning frameworks shape learning still requires shape priors constraints. shape prior knowedge also required recover high resolution shapes octree representation proposed inverse discrete cosine transform technique. designed pseudo-renderer predict dense shapes sequentially estimates sketches dense shapes single image. single depth view reconstruction. task reconstruction single depth view complete occluded structures behind visible parts. shapenets among early work using deep neural nets estimate shapes single depth view. firman trained random decision forest infer unknown voxels. originally designed shape denoising vconvdae also used shape completion. facilitate robotic grasping varley proposed neural network infer full shape single depth view however approaches able generate resolution voxel grids less unlikely capture geometric details. recent works infer higher resolution shapes. however depn relies shape database synthesize higher resolution shapes learning small voxel grid depth view sscnet requires strong voxel-level annotations supervised scene completion semantic generating training pairs feed network. ﬁrst part network loosely follows idea autoencoder u-net architecture skip-connected autoencoder serves initial coarse generator followed up-sampling module generate high resolution shape within voxel grid. whole generator aims learn correlation partial complete structures. supervision complete labels generator able learn function infer reasonable shape given brand partial view. testing phase however results tend grainy without details. training phase reconstructed shape generator conditional discriminator verify plausibility. particular partial input view paired corresponding complete shape called ‘real reconstruction’ partial view paired corresponding output shape generator called ‘fake reconstruction’. discriminator aims discriminate ‘fake reconstruction’ ‘real reconstruction’. original framework task discriminator simply classify real fake input jensen-shannon divergence-based loss function difﬁcult converge. recent wgan leverages wasserstein distance weight clipping loss function stabilize training procedure whilst extended work wgan-gp improves training process using gradient penalty respect input. drecgan++ apply wgan-gp loss function conditional discriminator guarantees fast stable convergence. overall network architecture training shown figure testing phase needs well trained generator shown figure overall main challenge reconstruction arbitrary single view generate information including ﬁlling missing occluded regions unseen views keeping estimated shape corresponding speciﬁc input view. training phase d-recgan++ ﬁrstly leverages skip-connected autoencoder together up-sampling module generate reasonable ‘fake reconstruction’ within high resolution occupancy grid applies adversarial learning reﬁne ‘fake reconstruction’ make similar ‘real reconstruction’ jointly updating parameters generator. fig. t-sne embeddings partial views complete shapes multiple object categories. label prediction. originally designed shape inpainting instead directly reconstructing complete structure partial depth view. recent d-prnn predicts simple shape primitives using rnns estimated shapes ﬁner geometric details. deep generative frameworks. deep generative frameworks vaes gans achieved impressive success image super-resolution image generation text image synthesis etc. recently applied generative networks structure generation. however generate shapes random noise instead reconstructing structures speciﬁc single image. d-recgan++ overview method aims estimate complete dense structure object takes arbitrary single depth view input. output shape automatically aligned corresponding partial view. achieve task object model represented high resolution voxel grid. simple occupancy grid shape encoding represents occupied cell empty cell. speciﬁcally input partial view denoted occupancy grid output shape denoted high resolution probabilistic voxel grid. input partial shape directly calculated single depth image given camera parameters. ground truth dense shape aligned orientation input partial depth view supervise network. generate ground truth training evaluation pairs virtually scan objects shapenet figure t-sne visualization partial views corresponding full shapes multiple general chair models. green represents t-sne embedding view whilst embedding corresponding shape. seen multiple categories inherently similar mapping relationships. essentially neural network learn smooth function denoted maps green dots dots close possible high dimensional space shown equation function parametrized convolutional layers general. early stage training high dimensional real fake distributions overlap discriminator separate perfectly using single scalar output theoretically analyzed experiments original wgan-gp always crashes early epochs extremely high dimensionality stabilize propose mean feature discriminator. mean vector feature captures information input overall difﬁcult discriminator easily distinguish whether mean feature fake real input. enables useful information backpropagate generator. theoretical study mean feature matching method mean feature matching also applied stabilize gan. therefore discriminator distinguish distributions mean feature fake real reconstructions generator trained make distributions mean feature similar possible. apply wgan-gp loss functions modiﬁed mean feature matching. generator inspired modiﬁed binary cross-entropy loss function instead standard version. standard binary cross-entropy weights false positive false negative results equally. however voxel grid tends empty network easily gets false positive estimation. regard impose higher penalty false positive results false negatives. particularly weight hyper-parameter assigned false positives false negative results shown equation target value speciﬁc voxel ground truth voxel grid corresponding estimated value voxel autoencoder output calculate mean loss total voxels whole voxel grid. discriminator leverage state wgan-gp loss functions. unlike original loss function presents overall loss real fake inputs separately represent loss function equation generating fake reconstruction pairs equation discriminating fake real reconstruction pairs. detailed deﬁnitions derivation loss functions found modify conditional settings. generator consists skip-connected autoencoder up-sampling module. unlike vanilla generator generates data arbitrary latent distributions d-recgan++ generator synthesizes data latent distributions views. particularly encoder convolutional layers bank ﬁlters strides followed leaky relu activation function pooling layer ﬁlters strides number output channels pooling layer starts doubling subsequent layer ends encoder lastly followed fully-connected layers embed semantic information latent space. decoder composed symmetric up-convolutional layers followed relu activations. skip-connections encoder decoder guarantee propagation local structures input view. skip-connected autoencoder followed up-sampling module simply consists layers up-convolutional layers detailed figure simple efﬁcient up-sampling module directly upgrades output shape high resolution without requiring complex network design operations. noted without fully connected layers skip-connections vanilla autoencoder would unable learn reasonable complete structures latent space limited local structure preserved. without efﬁcient up-sampling module unable ﬁnally generate high resolution shapes. although complicated dedicated network design could also output shapes would unlikely effectively trained single extremely high computation consumption high resolution shape generation. loss function optimization methods described section discriminator aims distinguish whether estimated shapes plausible not. based conditional discriminator takes real reconstruction pairs fake reconstruction pairs input. particularly consists convolutional layers ﬁrst concatenates generated shape input partial view reshaped tensor. reshaping process done straightforwardly using tensorﬂow ‘tf.reshape’. basically inject condition information matched tensor dimension leave network learn useful features condition input. convolutional layer bank ﬁlters strides followed relu activation function except last layer followed sigmoid activation function. number output channels convolutional layers starts doubling subsequent layer ends fig. detailed architecture d-recgan++ showing main building blocks. note that although shown separate modules trained end-to-end. input partial depth view corresponding output autoencoder corresponding ground truth. controls trade-off optimizing gradient penalty original objective wgan. generator d-recgan++ network loss functions optimize. discussed section minimizing tends learn overall shapes whilst minimizing estimates plausible structures conditioned input views. minimize improve performance discriminator distinguish fake real reconstruction pairs. jointly optimize generator assign weights gan. overall loss functions generator discriminator follows training adopt end-to-end training procedure whole network. simultaneously optimize generator discriminator alternate gradient decent step discriminator step generator. wgan-gp gradient penalty ends modiﬁed cross entropy loss function joint loss function data synthesis task dense reconstruction single depth view obtaining large amount training data obstacle. existing real rgb-d datasets surface reconstruction suffer occlusions missing data ground truth complete high resolution shapes single view. recent work d-epn synthesizes data object completion encoding scheme complicated tsdf different network requirement. tackle issue shapenet database generate large amount training testing data synthetically rendered depth images corresponding complete shape ground truth. particularly subset object categories selected experiments. category generate training data around models synthesizing testing data around models. model create virtual depth camera scan different angles uniformly sampled views roll pitch space. virtual scan depth image corresponding complete voxelized structure generated regard camera angle. depth image simultaneously transformed partial voxel grid using virtual camera parameters. pair partial view complete shape synthesized. overall besides large quantity synthesized data also collect real world data order test proposed network. microsoft kinect camera manually scan common objects chairs tables etc. multiple angles. then elasticfusion reconstruct full shapes objects well camera pose scan. objects manually segmented background. extract ground truth information aligning full objects partial views. noted that noise quantization artifacts low-cost rgb-d sensors inaccuracy algorithm full ground truth accurate. metrics evaluate performance reconstruction consider mean intersection-over-union predicted voxel grids ground truth. individual voxel grid formally deﬁned follows indicator function predicted value voxel corresponding ground truth threshold voxelization total number voxels whole voxel grid. experiments predicted value likely occupied probabilistic aspect. higher value better reconstruction model. competing approaches compare three state deep learning based approaches single depth view reconstruction. also compare generator alone network i.e. without named d-recae short. d-epn. proposed neural network reconstruct shape voxel grid high resolution shape retrieved existing shape database. fair comparison compared neural network performance. besides occupancy grid representation used network training testing. global structure inference network local geometry reﬁnement network proposed complete high resolution shape noisy shape. network originally designed single depth view reconstruction output shape voxel grid comparable network. fair comparison occupancy grid representation used network. noted network involves many convoluted designs training procedure extremely slow inefﬁcient many lstms involved. d-recae. d-recgan++ remove discriminator keep generator infer complete shape single depth view. comparison illustrates beneﬁts adversarial learning. results. networks separately trained tested four different categories network conﬁgurations. fairly compare different approaches sample results voxel grids using pooling stride along three axes. table shows comparison methods voxel grids table shows comparison approaches higher resolution voxel grids. figure shows qualitative results single category reconstruction. paper meshgrid function matlab used plot shapes better visualization. analysis. proposed d-recgan++ signiﬁcantly outperforms competing approaches terms lower higher resolutions shapes generated drecgan++ much visually compelling others terms shape accuracy geometrical details. results. networks also trained tested multiple categories without given class labels. networks trained four categories {bench chair coach table}; tested separately individual category. table shows comparison methods resolution voxel grids table shows comparison methods higher resolution voxel grids. figure shows qualitative results approaches multiple categories. besides performance network trained multiple categories degrade compared training network individual categories. conﬁrms network enough capacity capability learn diverse features multiple categories. results. investigate generality networks train networks {bench chair coach table} test another totally different categories {airplane faucet guitar monitor}. categories single arbitrary views random selected objects testing data size used previous {bench chair coach table}. table shows comparison approaches voxel grids table shows comparison approaches higher resolution voxel grids. figure shows qualitative results methods unseen categories. evaluate generality d-recgan++ speciﬁc category. particularly conduct four groups experiments. ﬁrst group train drecgan++ bench separately test remaining categories {chair coach table}. second group analysis. proposed d-recgan++ achieves much higher across unseen categories competing approaches. network learns rich features different object categories also able generalize well completely types categories. implies network learn geometric relationships lines planes curves common across various object categories. also observed model trained bench tends general others bench likely general features learned simple categories coach unlikely consist many general features shared across different categories. network trained chair separately tested {bench coach table}. similarly another groups experiments conducted. basically experiment investigate well approach learns features category test real-world data collected microsoft kinect camera. real-world data collected different environments including ofﬁces homes outdoor university parks shown figure compared synthesized data real-world partial views noisier largely incomplete. object randomly selected different depth views testing. table shows performance approaches using voxel grids table compares analysis. reasons signiﬁcantly lower compared testing synthetic dataset. first ground truth objects obtained elasticfusion empty rather solid occupied surface. however networks predict dense solid voxel grids interior bulky objects like couches matching. secondly input depth view real world dataset noisy incomplete limitation rgb-d sensor many cases input view capture whole object contains small part object also leads failure cases lower scores overall. however proposed network still able reconstruct reasonable dense shapes given noisy incomplete input results. experiments proposed drecgan++ tends outperform ablated network drecae include adversarial learning part. visualization experiment results shapes d-recgan++ also compelling d-recae. investigate adversarial learning improves ﬁnal results comparing drecae calculate mean precision recall multi-category experiment results. table shows mean precision d-recgan++ d-recae individual categories using network trained multiple categories table shows mean recall. analysis. seen results drecgan++ much higher precision scores drecae means d-recgan++ much less false positive estimations d-recae tends estimate much false positives. therefore estimated shapes d-recae likely ’fatter’ ’bigger’ d-recgan++ tends output ’thinner’ shapes much shape details exposed. drecgan++ d-recae achieve extremely high recall scores although d-recgan++ lower recall scores compared d-recae. means d-recgan++ d-recae capable estimating almost object shapes without many false negatives. words ground truth shape tends subset estimated shape result. overall regard experiments per-category multi-category cross-category experiments drecgan++ outperforms others large margin although approaches reconstruct reasonable shapes. terms generality varley inferior uses single fully connected layers instead convnets shape generation unlikely general various shapes applies lstms shape blocks generation inefﬁcient unable learn general structures. however drecgan++ superior thanks generality simple efﬁcient autoencoder convolutional discriminator. besides d-recae tends estimate shape adversarial learning d-recgan++ likely remove over-estimated parts leave estimated shape clearer shape details. although d-recgan++ achieves state performance object reconstruction single depth view limitations. firstly network takes volumetric representation single depth view input instead taking depth image. therefore preprocessing depth images required network. however many application scenarios robot grasping preprocessing would trivial straightforward given depth camera parameters. secondly input depth view network contains clean object information without cluttered background. possible solution leverage existing segmentation algorithm mask-rcnn clearly segment target object instance depth view. conclusion work proposed novel framework drecgan++ reconstructs full structure object arbitrary depth view. leveraging generalization capabilities autoencoders generative adversarial networks d-recgan++ predicts dense accurate structures details outperforming state single-view shape completion individual object category. tested network’s ability reconstruct multiple categories without providing object class labels training testing showed network still able predict precise shapes. besides investigated network’s reconstruction performance unseen categories proposed approach also predict satisfactory structures. finally model robust real world noisy data infer accurate shapes although model purely trained synthesized data. conﬁrms network capability learning general latent features objects rather simply ﬁtting function training datasets adversarial learning d-recgan++ learns geometric details estimated shapes. summary network requires single depth view recover dense complete shape details. kazhdan hoppe screened poisson surface reconstruction transactions graphics vol. song khosla zhang tang xiao shapenets deep representation volumetric shapes cvpr chen duan houthooft schulman sutskever abbeel infogan interpretable representation learning information maximizing generative adversarial nets nips kulkarni whitney kohli tenenbaum deep grant kohli gerven deep disentangled representations volumetric reconstruction eccv workshops girdhar fouhey rodriguez gupta learning predictable generative vector representation objects eccv huang kalogerakis marlin analysis synthesis shape families deep-learned generative models surfaces computer graphics forum vol. zhang freeman tenenbaum learning probabilistic latent space object shapes generative-adversarial modeling nips gall zheng fang surfacenet endto-end neural network multiview stereopsis iccv whelan mcdonald kaess fallon johannsson leonard kintinuous spatially extended kinectfusion workshops ledig theis huszar caballero cunningham acosta aitken tejani totz wang photo-realistic single image super-resolution using generative adversarial network cvpr", "year": 2018}