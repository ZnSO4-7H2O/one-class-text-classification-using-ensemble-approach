{"title": "Predicting Customer Churn: Extreme Gradient Boosting with Temporal Data", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Accurately predicting customer churn using large scale time-series data is a common problem facing many business domains. The creation of model features across various time windows for training and testing can be particularly challenging due to temporal issues common to time-series data. In this paper, we will explore the application of extreme gradient boosting (XGBoost) on a customer dataset with a wide-variety of temporal features in order to create a highly-accurate customer churn model. In particular, we describe an effective method for handling temporally sensitive feature engineering. The proposed model was submitted in the WSDM Cup 2018 Churn Challenge and achieved first-place out of 575 teams.", "text": "accurately predicting customer churn using large scale time-series data common problem facing many business domains. creation model features across various time windows training testing particularly challenging temporal issues common time-series data. paper explore application extreme gradient boosting customer dataset wide-variety temporal features order create highly-accurate customer churn model. particular describe effective method handling temporally sensitive feature engineering. proposed model submitted wsdm churn challenge achieved first-place teams. many businesses accurately predicting customer churn critical long-term success. accurate prediction churn probability drives many aspects business including proactive customer marketing sales forecasting churn-sensitive pricing models. therefore even slight improvements accuracy lead dramatic improvements profit. although customer churn models existed business domain decades recently grown complexity accuracy modern machine learning methods advanced recent years. consequently modern machine learning libraries extreme gradient boosting applied create accurate models even high dimensional data. addition challenging aspects creating churn models handling issues associated temporal data ensuring features correctly accounting time-shifts across various time-windows used training crossvalidating testing machine learning model. model implemented method handling temporal feature engineering validated successful. purposes paper participated wsdm customer churn challenge address complicated task accurately predicting customer churn using modern machine learning libraries xgboost explore methods engineering temporally sensitive features input churn model. dataset analysis extracted kkbox leading music streaming service asia utilizes subscription based business model. goal challenge create accurate model possible predicting customer churn using provided dataset. model performance evaluated using loss. computation time considered factor therefore number features could created base data number variety learning algorithms could used. final model submissions scored final test ranked according loss accuracy. model described abstract scored final loss achieving first-place teams. success xgboost library creating highly-accurate models thereby winning large proportion data science competitions well documented recent years. tree boosting empirically proven highly effective approach predictive modeling shown success across wide array problem domains. therefore chose xgboost primary learning algorithm selecting classifier utilize developing customer churn model. dataset analyzed paper came wsdm challenge provided kkbox music streaming service. dataset consisted subscriber data distinct sources user activity logs transactions member data. years historical data included. user data included variety information subscriber activity transaction data covered payment subscription information including renewals cancellations member data contained demographic information subscriber birthdate gender. data sources contained logs transactions time-series member data containing initial registration date subscriber well birthdate. target variable model is_churn field binary label generated provided scala script. criteria defined true renewal activity took place within days member’s subscription expiration date model input utilized distinct methods creating features temporal elements. method used distinct subset features goal maximizing signal temporal feature reducing false bias. majority temporal features winning model utilized relative refactoring method using absolute method initial registration date birth date. absolute method used thought signal absolute date signal relative amount time passed relative refactoring method designed create features relative time period modelled. temporal context embedded feature model learn. relatively simple intuitive done carefully consistently time periods modeled feature known contain important signal instead leads prediction bias simply noise. relative refactoring method involves mapping date-driven feature feature space anchored particular time-series instead relative selected point choose static point time represents start time period modelled using unit time measurement selected part example days chosen select first time period modelled registration date sampled user january last login date user january using relative refactoring method create features data elements represent number days difference data elements start given prediction period. therefore training dataset time period days since registration feature calculated days since login feature calculated predicting cross-validation time period user updated activity days since registration feature calculated days since last login feature user calculated even though original date elements changed. method simply involves converting date field ordinal integer using input model. example registration date converted ordinal integer conversion necessary properly formatting input numerical datatype xgboost model. conversion step necessary kkbox dataset date fields given already integer format. method effective absolute date/time contains signal relative date/time. example kkbox dataset significant churn pattern users registered following major holiday absolute registration date important. applying relative method registration date would cause model incorrectly weight churn behavior relative point time future months. methods cannot used together time period training dataset. using absolute method data stronger relative signal causes model learn incorrectly vice-versa. method must chosen given time period feature. however methods final model submission weighted average ensemble xgboost lightgbm used. weights assigned using competition leaderboard feedback xgboost base model lightgbm base model. payment_plan_days ul_lastmo_lastwk_numunq_avg_diff ul_all_numunq_sum_y ul_mo_mo_trend ul_lastprevmo_secs_sum canc_per_payment_days std_dev_numunq_prev_mo ul_all_count_y last_trx_gt_no_cancel last_ul_days_s many important features came recent user activity prior months calculated comparing various time periods extract trends user activity. example created features measured change user activity across many different time windows prior weeks compared prior month prior month compared prior prior month. addition trend analysis performed many similar distinct variations ensure model could learn much possible user activity domain. various methods measuring user activity used mean etc. user’s seconds played number unique songs played logins aggregated various time windows. transaction features related cancellations found relevant customer churn well. examples features engineered domain were total number cancellations user’s transaction history boolean flag describing prior month contained cancellation transaction customer’s average cancellation rate month. size data analyzed data files provided loaded microsoft server instance cleaned munged using t-sql code stored views. cleaning steps included removing outliers imputing nulls converting integer date fields date datatypes ease later feature engineering utilizing date differences also churn labels created training cross-validation datasets using scala script provided competition sponsors. prior churn labels provided competition sponsors months discarded. features derived data within data sources well meta features higher order features example feature ratio number days since last login payment plan days. total features created tested crossvalidation february dataset. python function created iteratively feature existing validated features re-train xgboost model record model accuracy resulting additional feature. features increased accuracy added test model others discarded. features exhibited increase model accuracy found overlapping based high correlation manually discarded. xgboost library implemented python selected primary classifier. learners tested included lightgbm stacknet scikit-learn’s implementation gradient boosting machines. hyper-parameter optimization performed based cross-validation feedback month february. ensure relative temporal features also found important days since last login days since last significant usage days since last cancellation. method used engineering described section summary used supervised machine learning ensemble decision trees implemented modern xgboost library build highly accurate classification model purpose predicting customer churn. final accuracy boosted using weighted average ensemble base model trained using lightgbm library primary xgboost base model. overall accuracy achieved test dataset loss significantly out-performed known benchmarks demonstrating forecasting kkbox subscriber churn significant level accuracy achievable using methods described paper. addition model outscored models submitted challenge teams significantly outscored xgboost models submitted well. suggests feature engineering increasing accuracy model suggests methods crafting temporal features model valid successful. future work includes parameter optimization xgboost lightgbm base models stacking stacknet models exploration additional feature engineering tested. thank everyone associated organizing sponsoring wsdm dataset provided kkbox. challenge sponsored managed international conference search data mining competition platform hosted kaggle.", "year": 2018}