{"title": "Robust Logistic Regression using Shift Parameters (Long Version)", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "Annotation errors can significantly hurt classifier performance, yet datasets are only growing noisier with the increased use of Amazon Mechanical Turk and techniques like distant supervision that automatically generate labels. In this paper, we present a robust extension of logistic regression that incorporates the possibility of mislabelling directly into the objective. Our model can be trained through nearly the same means as logistic regression, and retains its efficiency on high-dimensional datasets. Through named entity recognition experiments, we demonstrate that our approach can provide a significant improvement over the standard model when annotation errors are present.", "text": "annotation errors signiﬁcantly hurt classiﬁer performance datasets growing noisier increased amazon mechanical turk techniques like distant supervision automatically generate labels. paper present robust extension logistic regression incorporates possibility mislabelling directly objective. model trained nearly means logistic regression retains eﬃciency high-dimensional datasets. named entity recognition experiments demonstrate approach provide signiﬁcant improvement standard model annotation errors present. almost large dataset annotation errors especially complex nuanced datasets commonly used natural language processing. low-quality annotations become even common recent years rise amazon mechanical turk well methods like distant supervision co-training involve automatically generating training data. although small amounts noise detrimental applications level high upon manually inspecting relation extraction corpus commonly used distant supervision riedel report false positive rate. cases like these annotation errors frequently observed hurt performance. dingare example conduct error analysis system extract relations biomedical text observe half system’s errors could attributed inconsistencies data annotated. similarly case study co-training natural language tasks pierce cardie degradation data quality automatic labelling prevents systems performing comparably fully-supervised counterparts. despite prevalence little work done designing models aware annotation errors. moreover much previous work focuses heuristic techniques ﬁlter data training might discard valuable examples simply closely model assumptions. work argue incorrect examples explicitly modelled during training present simple extension logistic regression incorporates possibility mislabelling directly objective. model introduces sparse ‘shift parameters’ allow datapoints slide along sigmoid changing class appropriate. convex objective handle high-dimensional data show eﬃciently trained minimal changes logistic regression pipeline. experiments large noisy datasets show method provide improvement standard logistic regression manually automatically annotated settings. model also provides means identify examples mislabeled experiments biological data demonstrate method used accurately identify annotation errors. robust extension logistic regression shows promise handling incorrect labels remaining eﬃcient large high-dimensional datasets. much previous work dealing annotation errors centers around ﬁltering data training. brodley friedl introduce perhaps simplest form supervised ﬁltering train various classiﬁers record predictions diﬀerent part train eliminate contentious examples. similar vein venkataraman ﬁlter using svms training diﬀerent subsets feature space create multiple ‘views’ data. obvious issue methods noise-detecting classiﬁers trained noisy labels. methods suﬀer well-known eﬀects like masking several mislabelled examples ‘mask’ undetected swamping mislabelled points inﬂuential cast doubt correct examples figure gives example phenomena context linear regression. unsupervised ﬁltering tries avoid problem clustering training instances based solely features using clusters detect labelling anomalies recently intxaurrondo applied approach distantly-supervised relation extraction using heuristics number mentions tuple eliminate suspicious examples. unsupervised ﬁltering however relies perhaps unwarranted assumption examples label close together feature space. moreover ﬁltering techniques general well-justiﬁed training example closely current model necessarily mislabeled. although figure resulting running linear regression given data includes clean examples outliers outliers large inﬂuence mask other’s presence longer appear unusual. also swamp procedure clean examples begin look suspicious. instance low-likelihood might represent important exception would improve overall example also appear unusual simply made poor modelling assumptions discarding valuable information could lost. perhaps promising approaches directly model annotation errors handling mislabelled examples train. active trade-oﬀ ﬁtting model identifying suspected errors. bootkrajang kaban present extension logistic regression models annotation errors ﬂipping probabilities. example authors posit hidden variable representing true label assume label probability ﬂipped observed. intuitive approach shortcomings objective function nonconvex authors note local optima issue model diﬃcult many features training examples. ﬁeld ‘robust statistics’ seeks develop estimators unduly eﬀected deviations model assumptions since mislabelled points type outlier goal naturally related interest dealing noisy data seems many existing techniques would relevant. common strategy modiﬁed loss function gives less inﬂuence points boundary several models along lines proposed unfortunately approaches require optimizing nonstandard often nonconvex objectives fail give insight datapoints mislabeled. recent advance owen demonstrate introducing regularized ‘shift parameter’ datapoint help increase robustness linear regression. candes propose similar approach principal component analysis wright explore eﬀectiveness sparse signal recovery. work adapt technique logistic regression. best knowledge ﬁrst experiment adding ‘shift parameters’ logistic regression demonstrate model especially well-suited type high-dimensional noisy datasets commonly used nlp. growing body literature learning several annotators inaccurate important note considering separate perhaps general problem source noisy labels errors need come human annotators could introduced contamination automatic labelling. parameters certain datapoints shift along sigmoid perhaps switching class other. datapoint correctly annotated would expect corresponding zero. actually belongs positive class labelled negative might positive analogously direction. interpret model allows log-odds select datapoints shifted. compared models based label-ﬂipping global ﬂipping probabilities method advantage targeting example individually. finally seem concerning introduced parameter datapoint. many applications number features already exceeds proper regularization increase actually quite reasonable. small complication parameters corresponding regularized corresponding practice situation pose much diﬃculty appendix show train models using standard software. parameter equation would normally chosen cross-validation. however set-up unusual training contain errors even designated development unlikely error-free. found simulations errors largely interfere selecting experiments therefore cross-validate normal. notice direct aﬀect number nonzero shifts hence suspected number errors training set. information noise level directly incorporate selection procedure. example believe training noise would restrict choice cross-validation values fewer estimated shift parameters nonzero consider situations parameters regularized well. assume example l-regularization equation would need optimize cases like common ﬁrst construct one-dimensional family cross-validate single parameter addition faster compute method gives accurate estimates true error rate. large high-dimensional datasets even procedure costly training accuracy always informative. natural language processing experiments below adopt simpler strategy present several experiments assess eﬀectiveness approach ranging simulations labels ﬂipped uniformly random experiments natural language datasets annotation errors quite systematic. experiments measure robust model standard logistic regression; comparison methods handling annotation errors please appendix ﬁrst experiment simulate logistic data features drawn uniform letting intercept zero. create training development test sets containing examples introduce noise training development sets ﬂipping labels uniformly random. regularization parameter chosen simply minimizing loss development set. simulation experiments glmnet package trains lasso -penalized elastic models cyclical coordinate descent results standard versus robust logistic regression shown table various levels noise. using tuning procedure described section next perform simulations original features l-penalized well generate logistic data features relevant intercept zero. training development test sets size label noise added data test set. regularization parameter baseline model tuned development set. additional implementation details found appendix table results various error-identiﬁcation methods colon cancer dataset. ﬁrst lists samples biologically conﬁrmed suspicious gives output automatic detection method. bootkrajang report conﬁdences threshold obtain results. results show robust logistic regression provides consistent improvement baseline. performance diﬀerence grows larger amount label noise also evident labels ﬂipped directions. onedimensional example improvement seen figure next apply approach biological dataset suspected labelling errors. called colon cancer dataset contains expression levels genes tumor normal tissues evidence literature certain tissue samples cross-contaminated. particular tumor normal samples labels ﬂipped. since dataset small diﬃcult accurately measure performance model baseline. instead examine ability identify mislabelled training examples. many features datapoints likely genes relevant choose place penalty using glmnet select using cross-validation procedure section looking resulting values shift parameters nonzero corresponds suspicious datapoint. conﬁrmation sign gammas correctly match direction mislabelling. compared previous attempts automatically detect errors dataset approach identiﬁes least many suspicious examples false positives. detailed comparison given table although bootkrajang kaban quite accurate worth noting nonconvexity model needed trained times achieve results. table statistics data used experiments. wikipedia train column represents fraction examples majority agreed negative chosen annotator marked positive still include examples majority consensus noise estimates quite conservative. muse data column gives fraction examples marked positive oﬃcial conll train automatic system labelled negative vice versa experiments focus classic task called named entity recognition. traditional set-up goal determine whether word person organization location named entity since model binary concentrate task deciding whether word person not. task trivially reduce ﬁnding capitalized words model must distinguish people named entities like organizations. training large noisy dataset collected jenny finkel. data created taking various wikipedia articles giving amazon mechanical turkers annotate. quality controls place certain annotators produced noisy labels. construct train chose turker average much disagreed majority vote used annotations. negative examples subsampled bring class ratio reasonable level evaluate development test conll shared task data consists news articles reuters corpus hand-annotated researchers university antwerp. details dataset found table extract features using stanford’s pipeline chosen simplicity highly engineered largely consists lexical features current word previous next words sentence well character n-grams various word shape features. choose l-regularize features penalty becomes robust model using orthant-wise limited-memory quasi newton technique optimizing l-penalized objective tune models -fold cross-validation obtain note cross-validate procedure give unfair advantage baseline. also compare algorithm proposed bootkrajang kaban extension logistic regression mentioned section prior work. model assumes annotation errors produced label-ﬂipping example’s true label ﬂipped certain probability observed. features linked latent ‘true’ labels standard logistic classiﬁer labels relate observed ones global parameters probability positive label ﬂipping negative probability negative label ﬂipping positive. model trained ﬁrst estimating latent ‘true’ labels learning weights logistic classiﬁer values ﬂipping probabilities. testing ﬂipping probabilities discarded predictions made using logistic classiﬁer. results experiments shown table well figure robust logistic regression oﬀers noticeable improvement baseline improvement holds essentially levels precision recall. interestingly ﬂipping model show substantial diﬀerence standard logistic regression. in-depth discussion outcome given section turn setting training data automatically generated. task previous experiment word sentence must identify whether represents person not. evaluation development test conll shared task extract simple features before. training data take sentences oﬃcial conll train simple system create noisy labels. system called muse makes gazetteers hand-crafted rules recognize named entities software distributed gate general purpose tools processing text tuned particular corpus subsampled negatives achieve ratio roughly information data found table somewhat expectedly system high false negative rate. -fold cross-validation tune regularization parameters ultimately picking ﬁrst attempt selecting gave large value nearly resulting parameters zero. therefore decided knowledge noise level guide choice regularization. particular restrict choice proportion parameters nonzero roughly matches fraction training examples mislabelled note even realistic situations expert labels available often gain reasonable estimate number. table shows experimental results. dataset robust logistic regression oﬀers modest improvement baseline. ﬂipping model behaves nearly identically standard logistic regression. simulation experiments section robust model oﬀers notable advantage baseline features uniformly distributed. rerun experiments features drawn normal improvement accuracy decreases much explanation follows situation datapoints therefore annotation errors tend cluster around border positive negative. logistic regression virtue probabilistic assumptions naturally forgiving toward points near decision boundary. noise concentrated border adding shift parameters provide beneﬁt. short robust model seems perform best good number mislabelled examples close cases. noted experiments robust model shows less improvement training data generated automatically rather manually. likely explanation human annotators rule-based systems tend make mistakes examples similar features. example certain word muse’s gazetteers incorrectly labelled every instance word negative might good number erroneous examples close together feature space. setting hard robust classiﬁer learn mislabelled. also observe ﬂipping model performs essentially standard logistic regression. training ﬂipping probabilities consistently converge corresponds situation label-ﬂipping occurred. learning weights logistic classiﬁer gives exactly likely explanation given large ratio features datapoints common applications classiﬁer’s weights already provide enough degrees freedom model essentially ignores extra ﬂipping parameters. example mislabelled likely better ‘ﬁddle’ many weights instead modifying global probability major repercussions across examples. neither strengthening l-regularization even switching penalty helped probabilities converge nonzero value. model manages avoid issue introducing shift parameter datapoint. variables allow ﬁne-grained corrections large enough presence compete classiﬁer’s weights. parameters correspond slack variables allow certain datapoints wrong side separating hyperplane. model slack variables l-penalized promote sparsity. reasonable interpretation approach we’ve added slack variables logistic regression much help robustify svms slack variables beneﬁt glms well. however important remember approaches signiﬁcant diﬀerences widely varying performance practice. take example following simulation positive negative examples drawn datapoint’s shift parameters drop together corresponds example correctly labelled. simpler approach one-vs-all classiﬁcation train binary robust model class vote example’s label. found preliminary success method relation extraction task. crfs sequence models could also beneﬁt addition shift parameters. since extra variables neatly folded linear term convexity preserved model could essentially trained usual. presented robust extension binary logistic regression outperform standard model annotation errors present. method introduces shift parameters allow datapoints move across decision boundary. largely maintains eﬃciency scalability logistic regression better equipped train noisy data also help identify mislabelled examples. large noisy datasets continue gain prevalence important develop classiﬁers robustness mind. promising seem models incorporate potential mislabelling train. presented model demonstrated explicitly accounting annotation errors provide signiﬁcant beneﬁt. grateful advisor chris manning encouraging past years many helpful insights suggestions. thank whole stanford group welcoming time undergraduate masters student. would especially like thank mihai surdeanu patient encouraging mentor gabor angeli suggestions. finally thankful tibshirani stefan wager invaluable give careful description model details missing original presentation. model assumes annotations errors produced label-ﬂipping example’s true label ﬂipped certain probability observed. notation derivations largely introduced section authors modify standard logistic regression contain latent variables representing ‘true label’ datapoint. relates logistic model usual connected observed label collection ﬂipping probabilities pair classes represents probability example’s label ﬂipping class figure represents set-up graphical model. testing discard parameters predict using authors present iterative algorithm learning simpler informative expectation maximization common method estimating parameters latent-variable models. begin log-likelihood data given interestingly cast procedure selecting form instanceweighting. concretely copy every datapoint times number classes copy corresponds possible class. weighting copy bapragada brodley thiel label-ﬂipping model contrast iteratively estimates probabilities model ways sophisticated previous instance-weighting methods shown eﬀective empirically still provide important insight. particular instead assuming datapoint ﬂips class ﬁxed probability could deﬁne function datapoint’s distance class centroids. ﬂipping probabilities ﬁne-grained encoding information speciﬁc datapoint. compare robust model methods designed handle annotation errors. particular test performance model bootkrajang kaban good representative approaches based label-ﬂipping model. also compare common form preﬁltering based k-nearest neighbors popularized brodley friedl unless noted otherwise experiments follow simulate logistic data features drawn uniform zero intercept. create training development test sets size noise introduced training development sets ﬂipping negative labels uniformly random probability. ﬁltering approach implemented follows example examine nearest neighbors feature space. label neighbors disagrees example’s label discarded train set. logistic classiﬁer trained ﬁltered dataset. select based development set. note examples ﬁltered model falls back standard logistic regression. implement label-ﬂipping model procedure derived appendix learning weights using standard package logistic regression supports instance weighting. results simulations found table experiment ﬁrst experiment errors introduced ﬂipping negative labels uniformly random probability. robust logistic regression provide improvement baseline preﬁltering ﬂipping models perform substantially better. assumptions simulation exactly match ﬂipping model naturally performs well. preﬁltering also achieves impressive accuracy simulation matches model’s assumption example’s nearest neighbors share label. experiment next simulate data features drawn normal. results similar ﬁrst experiment. preﬁltering still able correctly identify mislabelled examples although selects smaller values since many datapoints near decision boundary. robust ﬂipping models show somewhat less improvement baseline perhaps harder distinguish points truly mislabelled crossed boundary chance. experiment return drawing features uniform zero intercept. experiment errors introduced systematic negative examples feature values switched positive. set-up represents plausible scenario datapoints similar feature values likely ﬂipped together. discussed section situation could arise annotations generated noisy automatic process. observe training preﬁltering always reverts ﬁlter points performs identically baseline. simulation demonstrates drawbacks training ﬁltering classiﬁer noisy data. mislabelled examples clustered together feature space points classiﬁer fails recognize labels ﬂipped. moreover values classiﬁer begins ﬁlter correct points adjacent ﬂipped region. multi-variate gaussians covariance matrix follows logistic model. gaussians diﬀerent covariance matrices diﬀer slightly logistic. concretely still three models perform better baseline demonstrates robust small deviations logistic assumption. interestingly robust model shows improvement perhaps suggesting best choice realistic data. robust model provides signiﬁcant improvement ﬂipping model performs almost identically baseline. result simple explanation training observed matrix consistently converged identity class components zero. solution corresponds situation label-ﬂipping occurred gives values standard logistic regression. changing initialized seem help. tried randomly subsampling features achieve smaller ratio features training examples. fewer features model indeed learns matrix diﬀerent identity gives slightly better accuracy baseline although models perform poorly. ﬁnding suggests original experiment parameters already provide enough degrees freedom model essentially ignores extra parameters. example mislabelled better ‘ﬁddle’ many parameters instead modifying interestingly preﬁltering approach performs nearly well robust method dataset. looking examples chooses discard indeed misannotated. suspect preﬁltering succeeds training data highly redundant. example model threw word ‘wilson’ incorrectly marked negative many places corpus ‘wilson’ positive label. datasets less redundancy especially situations errors systematic expect preﬁltering approach perform worse. preﬁltering ultimately helps performance still discards examples appear unusual likely valuable. model throws tokens phrase ‘cosmic microwave’ example although correctly labelled negative. describe train robust model using glmnet starting case parameters penalized. equation section shows reparametrized training objective. equivalently written seem could also strategy supplying vector penalty factors glmnet internally rescales factors moreover provided technique used practically software regularization.", "year": 2013}