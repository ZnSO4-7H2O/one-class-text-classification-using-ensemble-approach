{"title": "STORM - A Novel Information Fusion and Cluster Interpretation Technique", "tag": ["cs.AI", "cs.NE"], "abstract": "Analysis of data without labels is commonly subject to scrutiny by unsupervised machine learning techniques. Such techniques provide more meaningful representations, useful for better understanding of a problem at hand, than by looking only at the data itself. Although abundant expert knowledge exists in many areas where unlabelled data is examined, such knowledge is rarely incorporated into automatic analysis. Incorporation of expert knowledge is frequently a matter of combining multiple data sources from disparate hypothetical spaces. In cases where such spaces belong to different data types, this task becomes even more challenging. In this paper we present a novel immune-inspired method that enables the fusion of such disparate types of data for a specific set of problems. We show that our method provides a better visual understanding of one hypothetical space with the help of data from another hypothetical space. We believe that our model has implications for the field of exploratory data analysis and knowledge discovery.", "text": "abstract. analysis data without labels commonly subject scrutiny unsupervised machine learning techniques. techniques provide meaningful representations useful better understanding problem hand looking data itself. although abundant expert knowledge exists many areas unlabelled data examined knowledge rarely incorporated automatic analysis. incorporation expert knowledge frequently matter combining multiple data sources disparate hypothetical spaces. cases spaces belong different data types task becomes even challenging. paper present novel immune-inspired method enables fusion disparate types data specific problems. show method provides better visual understanding hypothetical space help data another hypothetical space. believe model implications field exploratory data analysis knowledge discovery. machine learning community embraces types learning encompass majority algorithms present within field. supervised learning examples data interest exist unsupervised learning explicit examples available. examples present decision function found exploiting knowledge examples. hand without knowledge similarity data exploited order find groups data share common attributes human immune system inspired number algorithms fall categories simply operate within realms. knowledge embedded within passed generation generation eventually transforming biological entities functionalities provide additional knowledge learned lifetime living being. example inherited knowledge found within toll-like receptors present several types immune cells work show analogy tlrs provides insight third class learning encodes knowledge within hypothetical space knowledge encoded within training testing dataset. type learning becomes especially useful labelled examples exist knowledge classes interest acknowledged. believe incorporation provides better understanding underlying data based blind function approximation. remaining sections paper first outline functionality tlrs followed hypothesis. description underlying machine learning algorithm presented. theoretical specification storm model described outlining cluster interpretation technique stemming model. followed experimental evidence confirming hypothesis. tlrs receptors surface immune cells sensors foreign microbial products. interesting aspect receptors like piano keys. different sound played different combination keys pressed once. similar single receptor senses chemical results different action performed number receptors sense various chemicals within specific time period simple definition tlrs initial detectors pathogens attacking system. sound alarm encounter certain virusbacteria-specific chemicals trigger cascade events potentially resulting immune response. unlike many parts immune system possible evolved knowledge passed parents offspring many generations. detailed description research area tlrs reader directed idea tlrs purpose learning simple one. direct translation receptors’ functionality within human body. signature function encoding known truth. tlrs hand encode class interest. hypothesis formulating data hypothetical space tlrs able combine information disparate spaces give better understanding problem. fusion information especially useful cases knowledge data interest known limited amount examples exist. vapnik also realised missing area supervised unsupervised learning proposed related idea terms master-class learning. work however proposes extension supervised learning setting training dataset belonging space labels supplemented additional description data another space description data called hidden information exist form expert knowledge describing underlying problem. vapnik combines model support vector machine algorithm shows poetic description images numbers provides useful knowledge learning higher resolution image holds technical information underlying digits. vapnik’s work poetic description poet’s textual depiction underlying image. vapnik’s improve classification performance supervised function estimation based hidden information. contrast propose method fuse expert knowledge technical information purpose unsupervised analysis visualisation better exploratory data analysis. using vapnik’s notation formalise analogy. supervised learning pair given denotes vector dimensionality denotes class label. unsupervised learning given. model tuple given denotes data structure encodes additional knowledge side information data instance. knowledge might limited might empty knowledge exists. data belongs space related mean exists meaningful correlation without correlation state knowledge represented descriptive order incorporate expert knowledge part learning mechanism propose established machine learning technique provides numerous features beneficial model. description technique follows. self-organising network algorithms provide number mechanisms desirable many computational tasks. features manifold learning dimensionality reduction multidimensional scaling well clustering visualisation self-organisation mechanisms combination provide suitable basis incorporation analogy better understanding. type self-organising network self-organising algorithm developed teuvo kohonen detailed description algorithm reader referred kohonen’s extensive book topic important note however many types algorithms believe model applied general topology preserving manifold learning algorithm could possibly extended order achieve comparable outcome. chosen simplicity speed visualisation capabilities. number ways. divided categories. firstly data fusion correlation performed extension original som. secondly cluster interpretation algorithm devised exploiting extended order provide better visual representation underlying data. attribute input vector technical information trained. experiments vector example comprises normalised real-valued data describing time-based snapshot behaviour running process according number host based measures. model additional inputs exists. first input separate hypothetical space form vector however time comprising arbitrary number variables encode instance specific information related space experiments vector comprises calls process whose snapshot encoded imports. second vector encoding expert knowledge exists vector however comprise fixed data also functions express expert’s knowledge desired observed identified within contrast vector global rather instance vector. returning immunological analogy repertoire receptors individual receptor. experiments vector strings representative majority call names associated networking functionality windows element representative subclass networking functions function denotes neighbourhood function determines amount prototype vector affected learning process. depends node distance winner node generally following smoothing kernel written terms gaussian function used denotes learning rate defines width kernel. variables location vectors winner node currently observed node output grid. detailed explanation kohonen’s book learning terminates algorithm presents discrete regular grid containing lower dimensional representation input preserves topology learned data. grid comprises nodes reference vectors associated hold learned information. model additional reference vector exists. vector learns information according following additional computation step tlrs activated currently observed winner node operator boolean operator elements output i.e. learns known truth observed winner node duration learning process. result additional step desired knowledge separate hypothetical space correlated produced map. correlation exhibited enhanced output containing nodes associated reference vectors. technical correlated expert knowledge extracted separate hypothetical space experiments learns whether node ever deemed winner input associated process uses windows networking functions. encoding information used example cluster interpretation labelling. experiments exploited delineate cluster nodes responsible networking behaviour. important note information however exploited ways enhance output som. example affecting actual learning function order include information actual generation process. cluster interpretation topology preserving nature newly introduced expert knowledge used identify clusters interest within output map. proposed cluster interpretation technique comprises steps. firstly established algorithm called unified distance matrix exploited order find nodes possibly cluster boundaries. information subsequently used step cluster boundary search cluster boundary search algorithm exploits idea incorporated within u-matrix visualisation technique. method shows dissimilarities neighbouring nodes order highlight possible cluster boundaries lie. order find nodes boundaries propose collect information inter-node distances along dimensions. information obtained subjected variability function identifies distances nodes significantly differ distances majority nodes map. function subject future research however provide pointers might operate employed experiments. well trained thought comprising clusters existing within dataset trained. careful examination proportion clusters versus inter-cluster nodes needs performed order determine proportion correctly. example quantitative measure could used represent ratio found follows. assuming nodes within generated inter-cluster nodes define inter-node distance quantile inter-node distances lying cluster boundary. thus label nodes whose dissimilarity quantile threshold cluster boundary node. labelling using node connectivity obtain cluster boundary information learned knowledge order label clusters exist within map. order achieve this preservation topology within exploited exploring neighbouring nodes within segment delineated boundary nodes. labelling algorithm traverses nodes within connects nodes within neighbouring region. region usually bounded previously found boundary nodes. possible nodes connected connected region evaluated frequently occurring activated type. information provides label nodes within connected region. example result steps seen fig. literature cluster interpretation techniques exist. techniques exploit various additional machine learning methods achieve goal. example two-stage procedure output traditional clustering technique k-means hierarchical clustering evaluated help numerous cluster validity indices. similarly work brugger also exploit topographic surface however help algorithm called clusot rather u-matrix method used work. important note model cluster interpretation labelling technique. model provides method correlating data disparate sources paper used identify subsequently label clusters interest without traditionally labelled data. model however used purposes could benefit exploitation data fusion result functionality. mentioned before example learning function affected take account data separate hypothetical space. future research goals. experiments performed order validate proposed model. validate storm model present complex dataset. datasets comprising needed chosen. comprises expert knowledge correlates expert knowledge found. behavioural analysis running processes chosen target domain discrimination networking applications problem area. abundant expert knowledge exists domain. technical data behaviour running processes order collect technical data microsoft performance counters used. following seven process-specific attributes system wide attribute selected monitored write operations/sec read operations/sec operations/sec data operations/sec privileged time processor time user time datagrams sent/sec eight features yields ability observe behaviour running processes based activity network usage windows detailed explanation attribute reader referred data normalised transformed -dimensional input feature vector knowledge static analysis executables desire discriminate processes perform networking activity non-networking applications suitable expert knowledge chosen. windows calls used network communication windows selected msdn library library resource expert knowledge various windows specific libraries presented categorised according various system functions. following strings representative numerous calls chosen libraries used networking within operating system internet http winhttp uuid dhcp netbios snmp wnet. strings represent windows networking functions selected knowledge encoded static binary analysis running processes performed order evaluate calls process imports. information subsequently transformed input feature vector representing calls present executable. fig. storm results experiment sign denotes nodes cluster boundaries lines connect nodes belonging cluster interest numbers show amount tlrs flagged training. messaging client live messenger. applications chosen difference terms networking functionality. experiment want show incorporating extra knowledge part algorithm identify cluster within output corresponds networking activity thus identify messenger application. provide machine learning algorithm technical data generate clusters without labels therefore unable determine cluster belongs activity/process. using encoded information provide enough information order help distinguish clusters denote activity interest clusters irrelevant problem. results experiment seen figure figure shows component planes som. standard method visualising reference vectors node map. component represented slice size shows magnitude attribute given node. figure shows using u-matrix method. visualisations standard methods presenting output som. even though possibly clusters exist data difficult distinguish corresponds networking activity thus messenger. without labels much understanding data discrimination difficult. hand help storm model incorporation expert knowledge automatically delineate cluster interest seen figure connected nodes highlights cluster representative behaviour messenger application. result validated labels showing labelled true cluster region figure experiment times yielding following results seen table total nodes average nodes winner nodes correlated given expert knowledge fourteen percent nodes winner nodes correlation all. order confirm correlation correctness look mean networking level correlated versus uncorrelated winner nodes. perform calculation interested finding groups clusters nodes represent applications denoting networking behaviour. experiment correlated nodes identified correctly belonging messenger average networking level almost total networking activity present experiment whereas uncorrelated nodes belonging notepad average analysis four figures seen storm model provides correlating expert knowledge standard technical information purpose cluster identification labelling. correlation helps identification data clusters interest which without labels would otherwise difficult identify. experiment order assess storm model complex dataset larger number running processes monitored subsequently analysed. total running applications monitored session standard host machine approximately seconds. figure table show results experiment. complex dataset difficult interpret results using standard techniques seen figures possible deduce number clusters exist within underlying data however clusters interest difficult discern. help storm model however understanding output becomes much easier seen figure connected regions clearly highlight cluster nodes denoting applications exhibit networking activity implementation networking functions present windows labels figure show applications would intuitively regard networking functionality grouped within connected region non-networking applications outside cluster. true cases handful exceptions. attributed fact applications either windows networking functions active session. validate correct delineation networking cluster quantitative analysis performed correlated versus uncorrelated node mean networking activity. case discrimination groups apparent experiment one. reasons. networking attribute used technical data global measure rather process signal. secondly applications windows networking functions communication. runs performed analysed. produced output contains nodes winner nodes correlated expert knowledge winner nodes correlation. average networking activity correlated nodes approximately higher uncorrelated nodes result confirms cluster highlighted storm model delineates nodes representative class interest. work proposed novel immune-inspired idea provides possibilities knowledge discovery exploratory data analysis. proposed storm model incorporates analogy so-called toll-like receptors human immune system. model provides insight class learning additional knowledge fused traditional technical data. additional information need belong hypothetical space knowledge encoded within training testing dataset. proposed model explored help experiments grounded within behavioural analysis running processes host system. experimental mxcmettcapvnthstmdaejaesuchvtstndgtismcfmempoenthsdovaoaeschxgtntdticxclfem phvxtnstndss motaoooaellljoessssucvgyssstsccnrvvvvtiscmtttlfhmooeecmmvveollntuhhsmdvodsjaso govvssmmoajeeuucvvgtssnntiaaacssmmlfmeeemccmrreaccnttuhhsddvdohhhrssssaeesspchhhxnppppppttddghdxccqccccrraaooofaooo jupvxnsnsdmxmecanthstdeaeshtdcaaplggggggggggggggsvchosssvvtccccccccccccchhossvttchostalgctfmvvmmojuvnnnsmecnnnnnnnnnthddiaaeehhsstttdxccmppplsssssssssssssssosssssssssssssssrse seccpwhxtn doosjaaesssoucphhvvxgtttnnsttndgtfisscdmmxcclmetcmmappoennu pssssssssssssssssassssssssssssssssinsstmdvssmojssuvvtnnsmmecennnnnthtdjjaaaeuuuhvttttdssssssssssssssssssssssssspmcccipnnhgaectdtfmon sessaeracwrrssssssssccmhhpvpvvpvvpghhqccccccraooooiffpotovvhhhhhliiloooorrglrtmottaaooooooalllljoveessssuccvvgyyssssstsscnnrrgvvvvttiscmmttttttlffhmeoeecmmmvoeolnntuhhssmd dxclfffeeimmmmrapneacutdvooodhresspchxonnnppvhdxqwcraofaotvhliosrglttmtaoseljoesuvvysscnervsmthmoeacvolntrhhsmdcsjaaesouhvhtsttndssmcmetcpnthsdsaeshvtdccaphlgost aepcchxnstdhhhdxcefffapaiilltttreecrghhhfo mclfeeeecm eutmvodiejnupvxnsngfsdmxomeecaovcntthstmddoaaejaesuchvgrtsstnd eutovaoecpxgtnticdxlfem lhhmooasjooucvgtstsngtisscmtlfmeetcmmoentuhsdovodaesphxgntdgcdxclemapoutoadecpgtgticdlfem ilotssegttrlheouaspttidaetvaextixevxxcmd ttaosloeostyscrvsthot olhssotvscathlgossvgtcaaohllgggoaaccststttiict vhhcraoofot vmwwwarienns−dddweaoosuuauwweaartacssshuushrsssdeccchppseellahqtteroaarfotaiocrrlttcchrlossesch vvdooorsepchxxxnnnpahdxxxqorfatiocrlttaheleshyprvqhrot ortasosstypsceooooooaooohrllosscsgvvshetfoooailootrecggrghllheefoiultseppg toailocrlht ttaooosrllloseossschtyssspscrvvvshqtttheootftoailorlhtasrlseoschtyprvshqhotftooirlstaslseestyprvahoroocssshleshtpvaaqrrotccrstahhosehyppscaqeroorotalocrhtahrlososchyppccvshqrootfotilo tfot hrsllosaadeessesspchhxysnppscttedrvvahdxcqthero ioocsnhturhglsstd ooeecm tppppssnntiaschmuqlwfcrm indwwovuuwmaasuuswseccwasegllatteraireovnacrs−modcahrjsseuc ttaloeosycrvshott olhsot pythoppnyttthoppnythoppnython searmmcsheooinammdrcehxiencrdlaemxectirnlravafommyctwawrad iens−deaosauwertacshshrssdechppeahqroarfotiocrrlttachloeshypcrvhrooolhstsoeoptcasyot rthdcpsselarmmchoinmindfeoxcecairnlrafdomctawrwd inldlwoowwginlisndslpwooerwgaoinisrxndcsypwhoerwaoinsrxdcsywhoewainsrdcshoewasrcsiehexaprlochrvvemware−authss dervices domain provides meaningful selection expert knowledge encoded within model. knowledge form expert information provided existing functional categorisation programming methods implemented within windows performed experiments show encouraging results terms improved visualisation exploratory data analysis knowledge discovery proposed automatic cluster interpretation algorithm. model highlights unique type learning becomes especially useful labelled examples exist knowledge classes interest acknowledged. field information security medical sciences many domains expert knowledge abundant exist knowledge difficult incorporate within traditional knowledge discovery techniques. believe technique step forward towards combining disparate knowledge traditional sources information fusion greatly improve understanding problem hand.", "year": 2010}