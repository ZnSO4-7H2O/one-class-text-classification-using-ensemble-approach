{"title": "A Fully Convolutional Network for Semantic Labeling of 3D Point Clouds", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "When classifying point clouds, a large amount of time is devoted to the process of engineering a reliable set of features which are then passed to a classifier of choice. Generally, such features - usually derived from the 3D-covariance matrix - are computed using the surrounding neighborhood of points. While these features capture local information, the process is usually time-consuming, and requires the application at multiple scales combined with contextual methods in order to adequately describe the diversity of objects within a scene. In this paper we present a 1D-fully convolutional network that consumes terrain-normalized points directly with the corresponding spectral data,if available, to generate point-wise labeling while implicitly learning contextual features in an end-to-end fashion. Our method uses only the 3D-coordinates and three corresponding spectral features for each point. Spectral features may either be extracted from 2D-georeferenced images, as shown here for Light Detection and Ranging (LiDAR) point clouds, or extracted directly for passive-derived point clouds,i.e. from muliple-view imagery. We train our network by splitting the data into square regions, and use a pooling layer that respects the permutation-invariance of the input points. Evaluated using the ISPRS 3D Semantic Labeling Contest, our method scored second place with an overall accuracy of 81.6%. We ranked third place with a mean F1-score of 63.32%, surpassing the F1-score of the method with highest accuracy by 1.69%. In addition to labeling 3D-point clouds, we also show that our method can be easily extended to 2D-semantic segmentation tasks, with promising initial results.", "text": "classifying point clouds large amount time devoted process engineering reliable features passed classiﬁer choice. generally features usually derived dcovariance matrix computed using surrounding neighborhood points. features capture local information process usually time-consuming requires application multiple scales combined contextual methods order adequately describe diversity objects within scene. paper present d-fully convolutional network consumes terrain-normalized points directly corresponding spectral data available generate point-wise labeling implicitly learning contextual features end-to-end fashion. method uses d-coordinates three corresponding spectral features point. spectral features either extracted d-georeferenced images shown light detection ranging point clouds extracted directly passive-derived point clouds i.e. muliple-view imagery. train network splitting data square regions pooling layer respects permutation-invariance input points. evaluated using isprs semantic labeling contest method scored second place overall accuracy ranked third place mean f-score surpassing f-score method highest accuracy addition labeling d-point clouds also show method easily extended d-semantic segmentation tasks promising initial results. generation dense d-point clouds overhead sensing systems growing scope scale processes light detection ranging dense stereomultiview-photogrammetry computer vision domain structure motion despite prevalence d-point cloud data however automated interpretation knowledge discovery d-data remains challenging irregular structure point clouds. such exploitation typically limited simple visualization basic mensuration point cloud rasterized onto tractable .ddigital surface model conventional image processing techniques applied e.g. order generate exploitation-ready data products directly point cloud semantic classiﬁcation desired. similar per-pixel image labeling dsemantic labeling seeks attribute semantic classiﬁcation label d-point. classiﬁcation labels e.g. vegetation building road etc. subsequently used inform derivative processing efforts surface ﬁtting modeling object detection bareearth extraction. point cloud labeling algorithms generally grouped main categories. section describes direct methods operate immediately point clouds themselves change dnature data. section describes indirect methods transform input point cloud e.g. image volume known semantic segmentation methods applied. finally considering relative trade-offs techniques section proposes novel approach speciﬁc contributions semantic classiﬁcation point clouds. point-wise discriminative model operating point features. features known eigen-features derived covariance matrix local neighborhood provide information local geometry sampled surface e.g. planarity sphericity linearity improve classiﬁcation contextual information explicitly incorporated model. example blomley used covariance features multiple scales found using eigenentropy-based scale selection method evaluated four different classiﬁers using isprs semantic labeling contest. best-performing model used linear discriminant analysis classiﬁer conjunction various local geometric features. however scalability model limited dependence upon various handcrafted features need experiment various models don’t incorporate contextual features require effort tune. motivated frequent availability coincident data optical imagery ramiya proposed point coordinates spectral data directly forming per-point vector components. labeling achieved ﬁltering scene ground non-ground points according axelsson applying d-region-growing segmentation sets generate object proposals. like blomley several geometric features also derived although speciﬁc details published. without incorporating contextual features segment/proposal classiﬁed selected classes main isprs semantic labeling contest. several methods also reported literature work classiﬁed full-waveform lidar data using point-wise multiclass support vector machine used random forests feature detection classiﬁcation urban scenes collected airborne lidar. reader referred grilli review. simple discriminative models well-established unable consider interactions points. allow spatial dependencies object classes considering labels local neighborhood niemeyer proposed contextual classiﬁcation method based conditional random field linear random forest models compared used unary pairwise potentials. considering complex interactions points promising results achieved although came cost computation speed minutes testing using model minutes using linear model. speed excludes additional time needed estimate per-point -dimensional feature vector prior testing. contextual classiﬁcation model later extended two-layer hierarchical high-order incorporates spatial semantic context ﬁrst layer operates point level generate segments. second layer operates generated segments therefore incorporates larger spatial scale. used features include geometry intensity-based descriptors addition distance orientation road features iteratively propagating context layers incorrect classiﬁcations revised later stages; resulted good performance isprs semantic labeling contest. however method employed multiple algorithms designed separately would make challenging simultaneously optimize. also computationally-intensive inference methods would limits run-time performance. contrast relying multiple individually-trained components end-toend learning mechanism desired. indirect methods mostly rely deep learning offer potential learn local global features streamlined end-to-end fashion driven reintroduction improvement convolutional neural networks availability large-scale datasets affordability high-performance compute resources graphics processing units deep learning enjoyed unprecedented popularity recent years. success computer vision domains image labeling object detection semantic segmentation target tracking generated interest applying frameworks classiﬁcation. however nonuniform irregular nature dpoint clouds prevents straightforward extension d-cnns designed originally imagery. hence initial deep learning approaches focused computer-aided design objects relied transforming data tractable images. example rendered multiple synthetic views placing virtual camera around object. rendered views passed though replicas trained aggregated using viewpooling layer passed another learn classiﬁcation labels. several methods multiview approach various modiﬁcations rendered views. example generated depth images views methods accumulated unique signature multiple view features projected information channels modifying alexnet handle input. details reader referred similar multiview approaches also applied ground-based lidar point clouds. example boulch generated mesh semanticd large-scale point cloud classiﬁcation benchmark allowed generation synthetic views based information -channel depth composite. two-stream segnet network fused residual correction label corresponding pixels. labels backprojected point cloud generate semantic classiﬁcation labels. likewise caltagirone generated multiple overhead views embedded elevation density features assist road detection lidar data. fully-convolutional network used single-scale binary semantic segmentation {road not-road} based training kitti dataset despite initial adoption multiview transformation approaches applied point clouds lose information third spatial dimension projective rendering. simultaneously introduce interpolation artifacts void locations. together complicates process unnecessarily rendering data addition forcing network ignore artiﬁcial regions caused voids. less consequential binary classiﬁcation multi-class problems require point assigned separate class; increases complexity reduce network’s performance. light limitations multiview transformation methods authors taken volumetric approach handle points clouds using deep learning. example presented method vehicle detection ground-based lidar point clouds. input point cloud voxelized fourth binary channel appended representing binary occupancy i.e. presence absence point within voxel. d-fcn trained evaluated produce maps representing objectness bounding scores using kitti dataset. similarly huang generated occupancy voxel grids based lidar point cloud data labeling voxel according annotation center point. d-cnn trained label voxel seven classes; individual points labeled according parent voxel. authors explored variations voxelization methods including binary occupancy grid density grid grid. voxnet maturana scherer tested voxelization model individually train d-cnns grid inputs. handle multi-resolution inputs trained separate networks receiving occupancy grid different resolution parallel development multiview volumetric cnns resulted empirical performance gap. suggested results could collectively improved merging paradigms. address this hybrid volumentric proposed used long anisotropic kernels project dvolume d-representation. outputs processed using image-based based network network architecture combine multiview approach proposed volumetric methods d-object rotated generate different d-orientations. individual orientation processed individually network generate d-representations pooled together passed image-based cnn. finally took different approach combining image-like representations conditional random ﬁeld context data fusion. instead directly operating lidar data interpolated separate channel. using imagery lidar data separate probability maps generated. pre-trained used estimate ﬁrst probability using optical imagery. then handcrafting another features spectral logistic regression applied generate second probability maps. two-stream process probability maps combined using high-order label every pixel categories. although indirect methods introduced application deep learning semantic labeling task typically require transformation input data i.e. views volumes order meet ingest requirements conventional image-based networks. unfortunately transformations introduce computational overhead model complexity discard potentially relevant information. likewise direct methods relied proliferation various handcrafted features addition contextual relationships order meet increasing accuracy requirements simple discriminative models. added complexity come cost computational efﬁciency. meanwhile generation point cloud data increased rapidly recent years availability high-resolution optical satellite/airborne imagery explosion modern stereo photogrammetry algorithms leveraging computational resources. algorithms triangulate d-point coordinates directly optical imagery thus retain inherent spectral information; attributes considered development successful model. order scale semantic classiﬁcation task meet demands emerging data volumes potentially submeter resolution global coverage efﬁcient streamlined robust model directly operates point clouds needed. context propose simple fullyconvolutional network direct semantic labeling point clouds spectral information. proposed approach utilizes modiﬁed version pointnet deep network operates directly point clouds provides ﬂexible framework large capacity minimal overhead efﬁcient operation scale. moreover respects permutation-invariance input points therefore avoiding need transform points images volumes. inspired success pointnet applications object classiﬁcation part segmentation semantic labeling make following contributions extend pointnet handle complex data obtained overhead remote sensing platforms using multi-scale approach. unlike models precisely-scanned objects even indoor scenes airborne point clouds exhibit unique characteristics noise occlusions scene clutter terrain variation challenges semantic classiﬁcation task. present deep learning algorithm convolutional layers consume unordered unstructured point clouds directly therefore respects pedigree input data without modifying representation discarding information. crafted features achieve near state-of-the-art results three spatial coordinates three corresponding spectral values point. time overhead adding additional features model minimal compared adding channels dimensions volumetric cases. section present cnn-based deep learning method able learn point-level global features directly end-to-end fashion rather relying upon costly features contextual processing layers. section describe convolutional networks adapted irregular point cloud data. section describes batch normalization used precondition outputs activation functions. section describes pooling layer used learn contextual features. finally section details inference semantic classiﬁcation labels learned local global features. architectures consist multiple layered convolution operations wherein layer ﬁlter weights learned based training data speciﬁc task. recall single d-convolution ﬁlter layer channel slides across domain input signal accumulating redistributing signal output sliding process thought replicating ﬁlter every spatial location. replicating ﬁlter allows extraction features regardless position enables linear system shiftinvariant. additionally sharing weights multiple locations increases learning efﬁciency reducing number parameters model. based nature convolution cnns typically require highly regular data e.g. images organized based d-grid. also note convolution invariant permutations input members i.e. pixels. words spatial distribution pixels within ﬁlter window important capture local features edges. therefore reordering input points result meaningless output. introduces challenges application cnns classify irregular unstructured point cloud data. given input d-points every point represents d-array goal point cloud classiﬁcation assign every point object-level label predeﬁned labels total number classes. since point clouds deﬁned regular grids convolutional layers require regular inputs modiﬁcation either input network architecture needed. order directly operate point clouds avoid transforming data different representation follow adapting convolutional operations point clouds. complete architecture network shown figure input network array unordered data points number points number features point i.e. spatial coordinates and/or spectral information. shown figure simple case input data point cloud deﬁned spatial coordinates columns array. input could optionally expanded include features spectral information. ﬁrst layer network applies d-convolution ﬁlter width equal width input vector across columns capture interactions coordinates output layer single column value corresponds individual d-point within i.e. input array transformed output array. layer operates point independently advantage allows incorporation point-wise operations scaling rotation translation etc. since operations differentiable included within network layer trained end-to-end fashion. concept ﬁrst introduced allows network automatically align data canonical space therefore makes invariant geometric transformations. subsequent convolutional layers perform feature transformation dimensionality reduction feature expansion using convolutions.we avoid fully-connected layers expensive computational cost. since convolution process linear operation performs weighted inputs non-linear operation known activation function needed order derive learn complex features. three activation functions frequently used literature sigmoid hyperbolic tangent rectiﬁed linear unit sigmoid activation reduces input values range thought assigning likelihood value input. similarly tanh activation tanh maps input values range added advantage output zero centered. finally relu activation applies simple ramp function. reduces likelihood vanishing gradient greatly accelerates convergence rate involves simpler mathematical operations; therefore common activation function used deep convolutional networks. implement relu function network follows although relu activation function many advantages enforce zero-centered distribution activation values factor improve gradient ﬂow. adjust distribution change weight initialization mechanism. glorot bengio showed good initialization factor successful convergent network however control distribution activations handled indirectly. improved control ioffe szegedy introduced batch normalization directly operates activation values. empirical mean variance output computed training; figure basic semantic labeling network takes input points ﬁrst stage passes series convolutional layers learn local global features. second stage concatenated features passed though convolutional layers softmax classiﬁer perform semantic classiﬁcation. text white indicates ﬁlter size text indicates layer’s output shape. output convolutional layer scale shift parameters learned training. setting allows network recover identity mapping. improves network since values standardized simultaneously reduces strong dependence initialization. also since allows homogeneous distributions throughout network enables higher learning rates acts form regularization. incorporating advantages initialize weights using method glorot bengio insert layers every convolutional layer shown figure note layer functions differently testing training. testing mean variance computed. instead single ﬁxed value mean variance found empirically training using running average used testing. integrating activation function written follows evaluating equation multiple times different values allows layer capture various aspects input. results output array dimensions total number ﬁlters used. size per-layer shown figure following output series convolutional layers shown upper part figure deﬁned mathematically sequence nested operations training desire network learn local features global features provide additional contextual information support classiﬁcation stage. here describe global features extracted using pooling layer simultaneously provides permutation-invariance i.e. order input points affect classiﬁcation results. contrary d-images point clouds unstructured unordered appropriate network respect original pedigree. three options available sorting data preprocessing step using recurrent neural network incorporating permutation-agnostic function aggregates information points. ﬁrst case optimal sorting rules obvious. second case point cloud must considered sequential signal thus requiring costly augmentation input possible permutations. architectures long short-term memory gated recurrent unit neural networks deal relatively long sequences becomes difﬁcult scale millions steps common size point clouds. given considerations incorporate permutation-agnostic function additional layer. speciﬁcally pooling layers commonly used downsample d-images work perfectly purpose. instead downsampling point pool values across points form single global signature represents input point cloud. signature could used directly label whole set. however recall task semantic labeling label d-point desired. therefore local global features needed describe point capture contextual information within set. network local features obtained second convolutional layer output shape i.e. represents d-point dvector. hand global signature point derived output ﬁfth convolutional layer dimensions serves input global feature extraction function speciﬁcally max-pooling layer aggregates features across points produce signature shape follows global feature vector concatenated point level features yielding per-point vector contains local contextual information necessary point-wise labeling. concatenated feature vector passed series feature transformation layers ﬁnally softmax classiﬁer. cross-entropy cost function train network. crossentropy special case general kullback-leibler -divergence measures groundtruth probability distribution diverges output probability distribution i.e. discrete distribution zero everywhere except single location maximum probability expression reduced cross-entropy case ground truth distribution represented one-hot vectors encoding label per-point output softmax layer representing normalized class probabilities. here individual class probability calculated follows last convolutional layer input softmax layer current correct label input weight matrix softmax classiﬁer unnormalized probability output node indexed class index. section describes methodology used evaluate performance approach. section describe datasets used. section describe preprocessing steps. section outline training parameters. section present results d-point clouds along various experiments showing qualitative performance method applied different testing cases. section analyze effects input feature selection. finally section show extension network handle fusion lidar spectral data d-semantic segmentation tasks. paper data provided isprs d-semantic labeling contest part urban classiﬁcation d-reconstruction benchmark. airborne lidar data corresponding georeferenced ir-r-g imagery provided vaihingen germany contest classes deﬁned including powerline vegetation impervious surfaces cars fence/hedge roof facade shrub tree. area subdivided regions training testing. region includes text contains lidar-derived coordinates backscattered intensity return count information acquired using leica system mean height ground. point density approximately points/m. test area within center vaihingen city characterized dense complex buildings. training area hand mostly residential detached houses high rise buildings. preprocessing methods employed obtain desired input. first spectral information attributed triplet point cloud applying bilinear interpolation using georeferenced figure left right point cloud color-coded height spectral information test area; point cloud color-coded height spectral information training data. ir-r-g imagery shown figure note case stereo-derived point clouds optical imagery spectral information inherently available would need obtained separately. next normalize values point cloud subtracting digital terrain model generated using lastools order obtain height-above-ground. then train deep learning method scratch sufﬁciently large amount labeled data required; however single small training scene provided. solve issue subdividing training testing regions smaller d-blocks. blocks allowed overlap thus increasing quantity data available robustness allowing overlapped points part different blocks. point within block represented dvector containing per-block centered coordinates spectral data normalized coordinates full extent scene. note since method fully convolutional number points per-block vary training testing. contribution resolves typical challenge working point clouds varying density. test using different densities sample ﬁxed number points per-block training debugging batch training purposes. sample points block randomly choose points training without replacement. number points per-block lower desired number samples random points within block repeated. however number points per-block lower points block ignored. learn objects different scales e.g. building train separate networks network trained using down-sampled version point cloud maturana scherer however practical introduces additional unnecessary computational overhead. instead current deep learning approaches e.g. single network high capacity able handle multiscale objects end-to-end fashion given appropriate inputs. handle different resolutions generate blocks different sizes train network using scales simultaneously. blocks size work well case given scale features interest e.g. cars roofs. ﬁnal result testing average three scales. splitting data blocks different sizes increases number training samples robustness noise orientation could improved augmenting training data modiﬁed versions original training data. augment training data randomly rotating points around zaxis jittering coordinates. jitter added applying additive noise sampled zero-mean normal distribution coordinates coordinates. next clip values maximum horizontal vertical jitter respectively. values chosen empirically sufﬁcient noise preserving relative differences various objects. rotation jitter applied splitting data blocks. however also apply jitter per-block sampling process order avoid duplicating points. asses monitor performance model training validation needed. instead taking samples training directly desire validation different possible training data. address splitting original training data augmentation training validation subsets using stratiﬁed splits preserve distribution classes sets. class-distributions within balanced repeating underrepresented classes match class highest number members resulting uniform distribution classes. augment training data applying jitter rotations described section splitting training validation sets blocks train using augmented data input network shown figure adam optimizer initial learning rate momentum batch size learning rate iteratively reduced based current number epochs according proceeds total epochs i.e. epochtotal monitor progress validation loss save weights loss improves. loss improve epochs training terminated weights best validation loss used testing. training network takes around hours converge using tesla keras tensorﬂow backend. feed forward time testing full scene figure shows loss overall accuracy progress training validation. classiﬁcation results based isprs semantic labeling contest. testing split data blocks similar training stage order recover objects different scales. block sizes overlap number points per-block reported table forward pass data output dvector per-point indicating probability point belonging nine categories. since ﬁxed number points block size points original data remain unclassiﬁed sampling others duplicated repetition. therefore interpolate output results classify original points. nearest neighbor interpolation class probability separately generate total nine class probability maps. label corresponding index highest probability nine maps assigned point indicating classiﬁcation label. quantitative performance metrics based isprs contest per-class accuracy precision/correctness recall/completeness f-score addition overall accuracy. although possible submit results excluding classes chose evaluate method available classes. confusion matrix table shows resulting per-class accuracies. figure shows corresponding classiﬁcation along error provided contest organizers. shown table proposed method performs well impervious surfaces roof classes. worst performance fence/hedge powerline classes according table confusion closely-related classes. example powerline mainly confused roof fence/hedge confused shrub similar topological spectral characteristics. likewise accuracy vegetation affected presence impervious surfaces shrubs. shrub appears causing confusion. likely fact spectral information similar among vegetation classes vegetation shrub trees. height information improve results presence classes similar heights fence/hedge make differentiation challenging. evaluate performance others compare method submitted isprs contest results time paper submission. since submissions unpublished review brieﬂy using available information contest website; refer submitted methods according names posted contest website. interested readers encouraged review website details. method used spectral geometrical features combined segmentation based supervoxels color-based region growing. contrast don’t handcraft geometrical features utilize spectral information segment point cloud similar coherent regions classiﬁcation. method used one-vs-one classiﬁer based handcrafted features including point attributes number returns textural properties geometrical attributes. method utilized classiﬁer contrast-sensitive potts models along d-and d-geometrical features. whuy deep learning method used convolutional network operating four features multi-scale fashion. method used covariance features multiple scales. finally method used two-layer hierarchical explicitly deﬁnes contextual relationships utilizes voxel cloud connectivity segmentation along handcrafted features fast point feature histograms per-class accuracy overall accuracy submission including ours shown table seen table method ranks second overall sharing overall accuracy luh. method highest overall accuracy whuy achieving however whuy achieved per-class highest accuracy score opposed method shrub classes. likewise method achieved highest scores per-class basis spectral data well ranked eighth overall overall accuracy also evaluated results using f-score generally considered better comparative metric uneven class distribution exists and/or costs false positives false negtable per-class accuracy method corresponding overall accuracy values correspond highest score blue second highest score green third highest score. atives different. table compares method others using f-score. method performed well across classes except fence/hedge class. methods demonstrated similarly poor results class. score highest roof tree classes scores marginally better ours respectively. higher performance fence/hedge powerline classes however allow achieve highest f-score ranking second score presented technique ranked third score surpassing whuy scored highest overall accuracy scores tables thought context algorithm complexity. words minimal accuracy gains worth added computational overhead. method example fares well overall per-class accuracy f-scores. however method uses independent crfs handcrafted features segmentation methods force points within segment share label. likewise uses variety contrast-sensitive potts models help preserve edges segmentation adds np-hard components problem result smoother results achieved small data sets comes cost slow run-time performance scalability limitations massive data sets. contrast utilize series simple d-convolutions operate directly point cloud without engineering additional features requiring structured representations segments. instead point-wise features per-block contextual descriptors learned straightforward end-to-end fashion. average inference time point cloud approximately equal convolutional network ﬂexible input feature requirements consume directly spatial coordinates only i.e. point cloud spatial coordinates spectral information spectral information only. moreover spatial coordinates optionally normalized remove effects terrain providing finally models trained different scales adjusting block size. section provide experiments analyze impact feature selection digital terrain model model performance various use-cases. ﬁrst experiment investigate effect input feature selection i.e. spatial and/or spectral information training model based three sets input data. ﬁrst model trained using coordinates only. second model trained using spectral information only. third model trained using d-coordinates spectral information point; best-performing network evaluated detail section results shown figure multiple scales i.e. block sizes column average result across scales. using d-coordinates larger scale performs better smaller scale. hand using spectral information smaller scale performs better larger scale. result interesting since shows effect global features multiple scales. example using spectral data smaller scales generally include similar points opposed larger scales. therefore global features accurately describe group points smaller scale. contrast global features sufﬁciently describe structures using d-coordinates smaller scale. case larger scale needed capture structural information help distinguish objects. suggests combining features could improve results. result submitted isprs semantic labeling contest used average block sizes trained point coordinates spectral information. circle highlights using features helped correctly classify troublesome vegetation region. likewise highlights spectral data absence coordinates tends classify vegetation tree d-coordinates absence spectral data tends confuse impervious surfaces vegetation. figure reference regrading correctly classiﬁed regions submission. second experiment investigated effect normalizing z-coordinates height-aboveground based model. done absence presence spectral information always available. figure shows absence spectral information normalizing coordinates heightabove-ground provides cleaner less-fragmented classiﬁcation scales including average. shown figure best classiﬁcation results achieved spectral information available obtaining height-above-ground using dtm. close scrutiny regions marked shows terrain-normalized input points improves classiﬁcation especially parts roofs. however general spectral information available results withusing still reasonable. exciting opens door streamlined point cloud exploitation workﬂows directly ingest data original form. furthermore enable techniques generating scale precise dtms based spectral content inherent stereo-derived point clouds primary contributions method compact architecture. complements input data characteristics point clouds ways traditional cnns not. words deep learning methods rely mapping features image-like maps i.e. density maps don’t take account increased complexity adding features. case adding feature involves concatenating data d-channel subsequently requiring additional d-ﬁlters greatly increasing amount memory required. hand method operates directly point cloud representing point d-vector. adding feature requires appending perpoint vector single value; increases width d-convolutions element ﬁrst layer modify rest network. advantage provides elegant solution multisensor fusion problem allowing readily combine complementary information scene different modalities semantic segmentation. additionally show architecture easily extended traditional task d-image labeling. handle images preprocessing step simply restructures data raster representation d-array represents d-point vector.the spatial position point corresponds d-pixel coordinates height value corresponds digital counts image. spectral information point derived corresponding image’s digital numbers. train model described previously excluding data augmentation multi-scale stages high resolution nature images provided sufﬁcient training samples. qualitatively evaluated method relevant submissions potsdam d-semantic labeling contest. ﬁrst method used model logistic regression classiﬁer fuse normalized figure results matrix showing effect training network using different input features different block sizes submitted result isprs semantic labeling contest shown bottom right. markers indicate regions comparison. class color keys shown bottom. spectral information scoring overall accuracy method chosen comparison since uses explicitly utilize contextual information. second method casia ﬁne-tuned resnet used spectral data scoring overall accuracy casia method chosen comparison since relies large computationally intensive network contrast compact network. example network parameters resnet parameters. image show method able correctly classify challenging low-vegetation regions incorrectly classiﬁed clutter residuals building class casia. likewise circled regions lower image shows method method produced good results classifying center building. casia method missed right corner building; likely lack consideration height information. including height information another channel large model resnet trivial task three-channel design. also even height information included fourth channel ﬁnetuning would possible training would infeasible given limited number images provided contest. highlights advantages compact model adding another feature simple adding single value perpoint. given relatively number parameters simple data augmentation sufﬁcient train network. paper present deep learning framework semantically label point clouds spectral information. compact fully convolutional architecture directly consumes unstructured unordered point clouds without relying costly engineered features image transformations. achieved near state-of-the-art results using d-coordinates corresponding spectral information. design network consume regions varying densities able learn local global features end-to-end fashion. furthermore model ﬂexible readily extended semantic segmentation. also experiments showed promising results classifying unnormalized points. given compact end-to-end framework fast testing time model potential scale much larger datasets including derived optical satellite imagery. future work extend model operate optically derived point clouds improve performance respect unnormalized points investigate ﬁne-grained classes. manuscript authored employees ut-battelle contract de-ac-or u.s. department energy. united states government retains publisher accepting article publication acknowledges united states government retains non-exclusive paid-up irrevocable world-wide license publish reproduce published form manuscript allow others united states government purposes. department energy provide public access results federally sponsored research accordance public access plan", "year": 2017}