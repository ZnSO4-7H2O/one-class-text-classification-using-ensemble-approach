{"title": "Learning Deep Structure-Preserving Image-Text Embeddings", "tag": ["cs.CV", "cs.CL", "cs.LG"], "abstract": "This paper proposes a method for learning joint embeddings of images and text using a two-branch neural network with multiple layers of linear projections followed by nonlinearities. The network is trained using a large margin objective that combines cross-view ranking constraints with within-view neighborhood structure preservation constraints inspired by metric learning literature. Extensive experiments show that our approach gains significant improvements in accuracy for image-to-text and text-to-image retrieval. Our method achieves new state-of-the-art results on the Flickr30K and MSCOCO image-sentence datasets and shows promise on the new task of phrase localization on the Flickr30K Entities dataset.", "text": "scale large amounts data. particular stochastic gradient descent techniques cannot guarantee good solution original generalized eigenvalue problem since covariance estimated small batch extremely unstable. alternative learn joint embedding space using ranking loss. wsabie devise learn linear transformations visual textual features shared space using single-directional ranking loss applies margin-based penalty incorrect annotations ranked higher correct ones training image. compared cca-based methods ranking loss easily scales large amounts data stochastic optimization training. powerful objective function works proposed bi-directional ranking loss that addition ensuring correct sentences training image ranked incorrect ones also ensures sentence image described sentence gets ranked images described sentences however date proven frustratingly difﬁcult beat sgd-trained embedding klein shown properly normalized state-of-the-art image text features outperform considerably complex models. another strand research multi-modal embeddings based deep learning utilizing techniques deep boltzmann machines autoencoders lstms recurrent neural networks making possible learn nonlinear mappings deep methods principle provide greater representational power methods based linear projections work propose learn image-text embedding using two-view neural network layers nonlinearities representations image text views representations given outputs pre-trained networks off-the-shelf feature extractors trained jointly end-to-end embedding. train network bi-directional loss function similar combined conpaper proposes method learning joint embeddings images text using two-branch neural network multiple layers linear projections followed nonlinearities. network trained using largemargin objective combines cross-view ranking constraints within-view neighborhood structure preservation constraints inspired metric learning literature. extensive experiments show approach gains signiﬁcant improvements accuracy image-to-text textto-image retrieval. method achieves state-of-theart results flickrk mscoco image-sentence datasets shows promise task phrase localization flickrk entities dataset. computer vision moving predicting discrete categorical labels generating rich descriptions visual data example form natural language. surge interest image-text tasks image captioning visual question answering core problem applications measure semantic similarity visual data text data common solution learn joint embedding images text shared latent space vectors different modalities compared directly. space usually dimension convenient cross-view tasks image-to-text text-to-image retrieval. several recent embedding methods based canonical correlation analysis ﬁnds linear projections maximize correlation projected vectors views. kernel extension maximally correlated nonlinear projections restricted reproducing kernel hilbert spaces corresponding kernels found. extensions deep learning framework also proposed however pointed hard denote collections training images sentences encoded according feature vector representation. want image sentence vectors joint space common dimension. inner product embedding space measure similarity equivalent euclidean distance since outputs embeddings l-normalized. following denote euclidean distance between image sentence vectors embedded space. propose learn nonlinear embedding deep neural network framework. shown figure deep model branches composed fully connected layers weight matrices successive layers separated rectiﬁed linear unit nonlinearities. apply batch normalization right last linear layer. branch normalization. general branch different number layers inputs branches produced networks parameters networks trained together parameters embedding layers. however paper obtained satisfactory results using embedding layers branch pre-computed image text features training objective stochastic margin-based loss includes bidirectional cross-view ranking constraints together within-view structure-preserving constraints. bi-directional ranking constraints. given training image denote sets matching non-matching sentences respectively. want distance positive sentence smaller distance negative sentence enforced margin figure model structure branches network images text branch consists fully connected layers relu nonlinearities between them followed normalization end. straints preserve neighborhood structure within individual view. speciﬁcally learned latent space want images similar meaning close other. within-view structure preservation constraints extensively explored metric learning literature particular large margin nearest neighbor approach tries ensure image target neighbors class closer samples classes. work show constraints also provide useful regularization term cross-view matching task. viewpoint architecture method similar two-branch deep models though avoids deep cca’s training-time difﬁculties associated covariance matrix estimation. network also gains accuracy performing feature normalization embedding loss layer. finally work related deep similarity learning though solving cross-view within-view matching problem. siamese networks similarity learning considered special cases framework views come modality branches share weights. image-view constraints trivial neighborhood sentence members. however region-phrase dataset section many phrases multiple region exemplars nontrivial constraints image view. embedding loss function. convert constraints training objective standard using hinge loss. resulting loss function given sums triplets deﬁned constraints margin could different different types distance even different instances. make easy optimize terms across training samples weight balances strengths ranking terms. work bi-directional ranking loss always case found produces best results. weights control importance structure-preserving terms regularizers bi-directional retrieval tasks. usually small values like triplet sampling. loss involves triplets consisting target instance positive match negative match. optimizing triplets computationally infeasible. therefore sample triplets within minibatch optimize loss function using sgd. inspired instead choosing violating negative match instance space select violated matches mini-batch. done computing pairwise similarities within mini-batch. positive pair violations relevant constraint theoretical guarantees sampling strategy discussed though context deep learning. experiments observe convergence within epochs average. figure illustration proposed structure-preserving constraints joint embedding learning rectangles represent images circles represent sentences. color indicates matching images sentences. non-matching images structure-preserving constraints. denote neighborhood containing images share meaning. case images described sentence want enforce margin point outside neighborhood analogously deﬁne constraints senfigure gives intuitive illustration withinview structure preservation help cross-view matching. embedding space left satisﬁes crossview matching property. square closer circles color circles color. similarly circle closest square color. however image query embedding space gives ambiguous matching result since blue circles close problem mitigated embedding right within-view structure constraints added pushing semantically similar sentences closer other. note image-sentence datasets flickrk mscoco consist images paired sentences each. neighborhood image generally contains itself since rare different images described identical sentence. thus randomly sample pairs form minibatches. experiments structure-preserving constraints order non-empty constraint triplets need moderate number positive pairs mini-batch. however random sampling pairs canguarantee this. therefore given minibatch positive sentence distinct ones already included among sampled pairs resulting mini-batches variable size. section analyze contributions different components method evaluate imageto-sentence sentence-to-image retrieval popular flickrk mscoco datasets phrase localization flickrk entities dataset features network settings image-sentence retrieval experiments represent images follow implementation details given image extract -dimensional activations -layer model following standard procedure original image cropped different ways images four corners center x-axis mirror image. mean intensity subtracted color channel resulting images encoded network network outputs averaged. represent sentences phrases primarily fisher vector representation suggested klein starting -dimensional wordvec vectors sentence words apply construct codebook centers using ﬁrstsecond-order information resulting sentence features dimension hybrid gaussian-laplacian mixture model experiments rather combined hglmm+gmm model obtained best performance save memory training time perform -dimensional vectors reduce dimensions. also makes original features less sparse good numerical stability training procedure. since already powerful hand-crafted nonlinear transformation original sentences also interested exploring effectiveness approach simpler text representations. include results -dimensional means wordvec vectors words sentence/phrase tf-idf-weighted bagof-words vectors. tf-idf pre-process sentences wordnet’s lemmatizer remove stop words. flickrk dataset dictionary size side using -dimensional visual features matrix matrix. output dimensions layers text side output dimensions layers experiments using wordvec features lower dimension embedding space intermediate layers output accordingly changed train networks using momentum weight decay small learning rate starting decay learning rate every epochs. accelerate training also make gradient updates stable apply batch normalization right last linear layer network branches. also dropout layer relu probability mini-batch size ground truth imagesentence pairs augment pairs necessary described previous section. compared cca-based methods method much smaller memory requirements scalable larger amounts data. results image-tosentence sentence-to-image retrieval standard flickrk mscoco datasets. flickrk consists images accompanied descriptive sentences each. larger mscoco dataset consists images also sentences each. evaluation follow protocols recent work flickrk given test images corresponding sentences images retrieve sentences vice versa report performance recallk percentage queries least correct ground truth match ranked among matches. mscoco consistent also report results test images corresponding sentences. flickrk bidirectional retrieval results listed table part table summarizes performance reported number competing recent methods. part demonstrate impact different components model reporting results following variants. linear one-directional setting keep ﬁrst layers branch parameters immediately followed normalization. output dimensions changed embedding space dimension. objective function retaining mcnn m-rnn-vgg mean vector linear one-directional linear bi-directional linear bi-directional structure nonlinear one-directional nonlinear bi-directional nonlinear bi-directional structure nonlinear bi-directional nonlinear bi-directional structure nonlinear bi-directional nonlinear bi-directional structure table bidirectional retrieval results. numbers come published papers numbers results approach using different textual features. note deep results obtained alexnet results method alexnet still higher image-to-sentence retrieval higher sentence-to-image retrieval. note conﬁgurations structure-preserving constraint associated image space inactive since flickrk mscoco datasets direct supervisory information multiple images described sentence. however results region-phrase dataset section incorporate structure-preserving constraints spaces. table changing embedding function linear nonlinear improves accuracy across board. going onedirectional bi-directional constraints improves accuracy image-to-sentence retrieval bigger amount sentence-to-image retrieval. finally adding structure-preserving constraints provides additional improvement linear nonlinear cases. methods table comparable since underlying feature representation linear cca. linear model constraints outperform linear nonlinear does. finally check much method relies power input features parts table report results nonlinear models without structure-preserving constraints applied weaker text representations namely mean wordvec vectors sentence tf-idf vectors described section again structure-preserving constraints give additional improvement. results mean vector considerably better results feature fact comparable results powerful representation. tf-idf achieve results best results showing require highly nonlinear feature input order learn good embedding. another possible reason tf-idf performs strongly wordvec features pre-trained unrelated text corpus well adapted speciﬁc data. dvsa m-rnn-vgg mcnn nonlinear+bi-directional nonlinear+bi-directional+structure nonlinear+bi-directional nonlinear+bi-directional+structure nonlinear+bi-directional nonlinear+bi-directional+structure table bidirectional retrieval results mscoco -image test set. sistently improves performance results text feature considerably exceed state art. also tried ﬁne-tuning network backpropagating loss function layers obtained additional improvement. recently published flickrk entities dataset allows learn correspondences phrases image regions. speciﬁcally annotations dataset provide links mentions distinct entities sentences ground truth bounding boxes interested dataset unlike global image-sentence datasets provides many-to-many correspondences i.e. region described multiple phrases phrase multiple region exemplars across multiple images. allows take advantage structure-preserving constraints visual textual spaces. formulated goal phrase localization predict bounding image entity mention caption goes image. particular phrase perform search extracting edgebox region proposals scoring using embedding. good performance bestscoring high overlap ground truth region. considered ranking problem methods trained match phrases regions. hand realize problem like detection algorithm able distinguish foreground objects boxes contain background poorly localized objects. deep well suited scenario since negative boxes learning stage. however margin-based loss function makes possible. plummer reported baseline results regionphrase embedding using imagenet-trained features. following rohrbach obtained improvements phrase localization using detection-based features also fast r-cnn features ﬁne-tuned union pascal train-val sets consistent average multiple crops region features. text section feature. thus input dimension input dimension two-layer network structure intermediate layer dimensions sides ﬁrst experiment train embedding withnegative mining using positive region-phrase pairs cca. this training resampled regions phrase total region-phrase pairs unique. previous section initial minibatch size full version objective augment mini-batches sampling additional positive phrases regions also additional positive regions phrases make sure many triplets possible structure-preserving constraints region side phrase side results training model without negative mining epochs shown part table evaluation protocol proposed first treat phrase localization problem retrieving instances query phrase region proposals extracted test images report recallk percentage queries correct match rank fine-tuned negative mining fine-tuning epochs fine-tuning epochs fine-tuning epochs fine-tuning epochs phrase). second report average precision ranking bounding boxes phrase test images contain phrase following nonmaximum suppression. last column table shows unique phrases test unique phrase treated class label. table shows performance bi-directional ranking objective different combinations structure terms. including structure terms generally gives better results excluding them though effects turning term separately differ much. large part limited number structure-preserving constraint triples view. flickrk entities training pairs around unique phrases regions described single phrase. means that phrases/regions corresponding regions/phrases. line table gives baseline results. pre-trained model without using negative mining deep embedding comparable results recall recall lower results recall. mentioned earlier past experience found surprisingly hard beat complex methods order improve accuracy embedding need reﬁne using negative data background poorly localized regions. this take embedding trained without negative mining unique phrase training calculate distance between phrase ground truth boxes well proposal boxes. record hard negative boxes closer phrase ground truth boxes. efﬁciency sample hard negative regions unique phrase. next continue training region-phrase model training augmented hard negative boxes using bi-directional ranking constraints exclude structure-preserving constraints last four lines table show results ﬁnetuning models table hard negative samples. compared best model trained positive regions recall improved considerably better cca. note absolute terms rohrbach higher results much complex method includes lstms phrase reconstruction objective. paper proposed image-text embedding method two-branch network multiple layers trained using margin-based objective function consisting bi-directional ranking terms structure-preserving terms inspired metric learning. architecture simple ﬂexible applied various kinds visual textual features. extensive experiments demonstrate components system well chosen terms objective function justiﬁed. best knowledge retrieval results flickrk mscoco datasets considerably exceed state also demonstrate convincing improvements problem phrase localization flickrk entities dataset. material based upon work supported national science foundation grant cif- xerox sloan foundation. would like thank bryan plummer help phrase localization evaluation. figure example phrase localization results. image reference sentence phrases best-scoring corresponding regions shown color. ﬁrst shows output method second shows output best model table negative mining). ﬁrst example method gives accurate bounding boxes clothing headpiece. second example method ﬁnds correct bounding number completely misses third column method gives much tighter boxes horse clown; last example method accurately locates jacket.", "year": 2015}