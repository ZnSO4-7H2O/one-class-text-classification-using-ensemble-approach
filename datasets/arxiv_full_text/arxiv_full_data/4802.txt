{"title": "Strategic Dialogue Management via Deep Reinforcement Learning", "tag": ["cs.AI", "cs.LG"], "abstract": "Artificially intelligent agents equipped with strategic skills that can negotiate during their interactions with other natural or artificial agents are still underdeveloped. This paper describes a successful application of Deep Reinforcement Learning (DRL) for training intelligent agents with strategic conversational skills, in a situated dialogue setting. Previous studies have modelled the behaviour of strategic agents using supervised learning and traditional reinforcement learning techniques, the latter using tabular representations or learning with linear function approximation. In this study, we apply DRL with a high-dimensional state space to the strategic board game of Settlers of Catan---where players can offer resources in exchange for others and they can also reply to offers made by other players. Our experimental results report that the DRL-based learnt policies significantly outperformed several baselines including random, rule-based, and supervised-based behaviours. The DRL-based policy has a 53% win rate versus 3 automated players (`bots'), whereas a supervised player trained on a dialogue corpus in this setting achieved only 27%, versus the same 3 bots. This result supports the claim that DRL is a promising framework for training dialogue systems, and strategic agents with negotiation abilities.", "text": "artiﬁcially intelligent agents equipped strategic skills negotiate during interactions natural artiﬁcial agents still underdeveloped. paper describes successful application deep reinforcement learning training intelligent agents strategic conversational skills situated dialogue setting. previous studies modelled behaviour strategic agents using supervised learning traditional reinforcement learning techniques latter using tabular representations learning linear function approximation. study apply high-dimensional state space strategic board game settlers catan—where players offer resources exchange others also reply offers made players. experimental results report drl-based learnt policies signiﬁcantly outperformed several baselines including random rule-based supervised-based behaviours. drl-based policy rate versus automated players whereas supervised player trained dialogue corpus setting achieved versus bots. result supports claim promising framework training dialogue systems strategic agents negotiation abilities. artiﬁcially intelligent agents require strategic conversational skills negotiate interactions natural artiﬁcial agents e.g. give/tell give/tell okay. typical conversations artiﬁcial agents assume cooperative behaviour partner conversants strategic conversation assume full cooperation interaction agents throughout paper strategic card-trading board game illustrate approach. board games trading aspects entertaining people also training trading skills. popular board games kind include last will settlers catan power grid among others games played humans also played computers humans. trading behaviours agents computer games usually based carefully tuned rules search algorithms monte-carlo tree search reinforcement learning tabular representations linear function approximation however application reinforcement learning trivial complexity problem e.g. large state-action spaces exhibited strategic conversations. hand unique situations interaction described large number variables enumerating would result large state spaces. hand action space also large wide range unique negotiations optimising interaction compression search space usually clear features incorporate state representation. strong motivation applying deep reinforcement learning dialogue management ﬁrst proposed agent simultaneously learn feature representation policy. paper present application deep reinforcement learning learning trading dialogue game settlers catan. scenario strategic conversation game settlers catan players take role settlers ﬁctitious island catan—see figure board game consists hexes randomly connected hills mountains forests pastures ﬁelds desert. island hills produce clay mountains produce pastures produce sheep ﬁelds produce wheat forests produce wood desert produces nothing. setting four players attempt settle island building settlements cities connected roads. build players need speciﬁc resource cards example road requires clay wood; settlement requires clay sheep wheat wood; city requires three clay cards wheat cards; development card requires clay sheep wheat. player gets points example building settlement city obtaining victory point cards game consists sequence turns game turn starts roll make players obtain resources player turn trade resources bank dialogue players make available resources build roads settlements cities. game highly strategic players often face decisions trade resources request resources give away—which inﬂuenced need build. player extend build-ups locations connected existing pieces i.e. road settlement city settlements cities must separated least roads. ﬁrst player victory points wins others lose. paper extend previous work strategic conversation applied supervised reinforcement learning simultaneously learn feature representation dialogue policy using deep reinforcement learning compare learnt policies random rule-based supervised baselines show drl-based agents perform signiﬁcantly better baselines. reinforcement learning agent learns behaviour interaction environment physical virtual agents within situations mapped actions maximizing long-term reward signal agent typically characterized ﬁnite inﬁnite states {si}; ﬁnite inﬁnite actions {aj}; stochastic state transition function speciﬁes next state given current state action reward function speciﬁes reward given agent choosing action environment makes transition state state policy deﬁnes mapping states actions. goal agent select actions maximising cumulative discounted reward deﬁned maxπ function represents maximum rewards discounted factor time step. agent takes actions probability training takes best actions maxa test time. induce function deep reinforcement learning approximates using multilayer convolutional neural network. function agent parameterised parameters neural iteration speciﬁcally training agent requires dataset experiences ...en} every experience described tuple q-learning update iteration target parameters neural iteration latter updated every steps. process implemented learning algorithm deep q-learning experience replay described approach strategic interaction optimises tasks jointly learning offer learning reply offers. addition approach learns constrained search spaces rather unconstrained ones resulting quicker learning also learning legal decisions. strategic agent offer trade opponent agents case game settlers catan example trading offer give anyone sheep clay. several things observed simple example. first note offer include multiple givable receivable resources. second note offer addressed opponents third note offers allowed particular point game depend particular state game resources available player trading. goal agent learn make legal offers yield largest pay-off long run. strategic agent also reply trading offers made opponent. case game settlers catan responses narrowed accepting offer rejecting replying counteroffer note responses available point game offer made agent similarly task above goal agent learn choose response yield largest pay-off long run. optimising tasks above joint optimisation tasks equips automatic trading agent completeness. that given environment state space {si} trading negotiations responses goal strategic learning agent consists inducing optimal policy action selection deﬁned a∈{ao∪ar} function estimated described previous section trading negotiations turn responses. behaviour strategic agent trained described above using deep learning large action sets prohibitively expensive terms computation time. solution limitation consists learning constrained action sets rather whole static action sets. distinguish action sets action contains responses trading negotiations remains static action contains trading negotiations valid given point game refer latter action contains dynamic ¯ao| |ao| trading negotiations available according game state available resources thus reformulate goal strategic learning agent inducing optimal policy action selection deﬁned ¯ao∪ar function still estimated described section constrained trading negotiations turn responses. note size vary depending game state. figure integrated system deep reinforcement learning agent strategic interaction. board game settlers catan multilayer neural network agent–see text details. figure shows integrated learning environment. left-hand side jsettlers benchmark framework receives action outputs next game state numerical reward. right-hand side deep reinforcement learning agent receives state reward updates policy learning outputs action following learnt policy. integrated system based multi-threaded implementation player makes synchronised thread. addition system runs client-server architecture learning agent acts ‘server’ game acts ‘client’. communicate exchanging messages server tells client action execute client tells server game state reward observed. agents based convnetjs tool implements algorithm ‘deep q-learning experience replay’ proposed extended tool support multi-threaded client-server processing constrained search spaces. characterisation learning agent state space {si} learning agent includes non-binary features describe game board available resources. table describes state variables represent input nodes normalise range features represent high-dimensional state space—only approachable reinforcement learning function approximation. description number clay units available number units available number sheep units available number wheat units available number wood units available type resource =desert=clay=ore =sheep=wheat=wood builds located settlement city =opponent builds =agent builds roads located road given edge =opponent road =agent road type resource =desert=clay=ore =sheep=wheat=wood action space {ai} learning agents includes actions offering trading negotiations actions replying offers opponents. notice offer actions make givable resources receivable resource considered. state transition function agents based game using jsettlers framework addition strategic interactions carried semantic level rather word level example higher-level representation give sheep clay. furthermore trained agents active selection trading offers reply offers functionality rest game based jsettlers framework. reward function agent based game points provided jsettlers framework make distinction reply actions offer actions. fact consider reply actions high-level actions offer actions lower-level ones. reward function deﬁned gainedp oints=points time minus points time otalp oints refers accumulated number points trained agent game. used following weights reply actions {wgp following offer actions {wgp model architecture consists fully-connected multilayer neural network nodes input layer nodes ﬁrst hidden layer nodes second hidden layer nodes output layer. hidden layers relu activation functions normalise weights details. finally learning parameters follows experience replay size=k discount factor=. minimum epsilon=. learning rate=. batch size=. comprehensive analysis comparing multiple state representations action sets reward functions learning parameters left future work. following baselines compare trained strategic agents switch trading offers reply behaviours—the remaining behaviour game remains constant provided jsettlers framework table evaluation results comparing deep reinforcement learners baseline traders columns show average results—of player left— test games. notation drlran=drl agent trained random behaviour drlheu=drl agent trained heuristic opponents drlsup=drl agent trained supervised opponents. agent chooses trading negotiation offers randomly replies offers opponents also random fashion. although weak baseline analyse impact policies trained random behaviour. agent chooses trading negotiation offers using random forest classiﬁer replies offers opponents using heuristic behaviour above. agent trained games played different human players—labelled multiple annotators. compute probability distribution human-like trade givable refers class prediction evidence refers observed features posterior distribution tree normalisation constant classiﬁer used decision trees. assuming givables particular point time game extracting human-like trading offer given collected evidence deﬁned maxy∈y classiﬁcation accuracy statistical classiﬁer .%—according -fold cross-validation evaluation trained three agents random heuristic supervised opponents—see figure used training experiences evaluate learnt policies according cross-evaluation using following metrics terms averages game win-rate victory points offers total trades pieces built cards bought number turns. observations crossevaluation reported table follows agents acquire competitive strategic behaviour comparison types agents—they simply substantially opponents. random behaviour easy beat win-rate agents achieve win-rate heuristic opponents supervised opponents. results substantially outperform heuristic supervised agents achieve less win-rate figure learning curves deep reinforcement learners random heuristic supervised opponents. observed agents learn different types opponents—even randomly behaving ones. agents outperform baselines win-rates also metrics average victory points pieces built total trades. latter prominent example heuristic supervised agents achieve trades game agents compared heuristic supervised agents achieve trades. means agents tend trade opponents i.e. accept offered trading negotiations. differences suggest knowing accept reject counter offer trading negotiation crucial winning. training agent environment tested better training testing across environments. example drlheu versus heuristic behaviour better drlsup versus heuristic behaviour however results report agents trained using randomly behaving opponents almost good trained stronger opponents. suggests agents strategic interaction also trained without highly skilled opponents presumably tracking rewards time. agents supervised agent harder beat. supervised agent strongest baseline achieves best winning rate baseline agents. noted agents versus supervised behaviour make offers trade summary strategic dialogue agents trained deep reinforcement learning potential acquire highly competitive behaviour training strong opponents even opponents random behaviour. result help reduce resources required training future strategic agents. reinforcement learning applied strategic interaction includes following. proposes reinforcement learning multilayer neural networks training agent play game backgammon. ﬁnds agents trained approach able match even beat human performance. proposes hierarchical reinforcement learning automatic decision making object-placing trading actions game settlers catan. incorporates builtknowledge learning behaviours game quicker ﬁnds combination learned built-in knowledge able beat human players. used reinforcement learning non-cooperative dialogue focus small -player trading problem resource types without using real human dialogue data. work showed explicit manipulation moves used playing adversaries gullible also adversaries detect manipulation punish player manipulative recently designed model selecting trade offers trained evaluated within full jsettlers environment comparison model much restricted state-action space leading signiﬁcant modest improvements supervised learning hand-coded baselines. related work carried context automated non-cooperative dialogue systems agent satisfy goals rather participants game-theoretic underpinnings non-cooperative behaviour also investigated automated agents interest trying persuade argue debate area believable characters video games educational simulations another arena strategic conversational behaviour investigated negotiation hiding information advantageous. recent work deep learning applied games include following. train deep convolutional network game trained supervised fashion rather trained maximise long-term reward work. closely related work agent text-based games states based words policies induced using gamebased rewards actions based directions east/west/south/north’. another closely related work agents trained play atari games states based pixels down-sampled images policies make game-based rewards actions based joystick movements. contrast previous works based navigation commands agents trading dialogue moves essential behaviours strategic interaction. paper extends recent work training strategic agents using reinforcement learning either used small state-action spaces focused navigation commands rather negotiation dialogue. learning agents described paper high dimensional state representation fairly large action space learning strategic non-cooperative dialogue behaviour. knowledge results report highest winning rates reported date game settlers catan comprehensive evaluation reported previous section evidence argue deep reinforcement learning promising framework training strategic interactive agents. contribution paper ﬁrst application deep reinforcement learning optimising behaviour strategic conversational agents. learning agents able discover trading negotiations offer discover accept reject counteroffer; discover strategic behaviours based constrained action sets—i.e. action selection legal actions rather them; learn highly competitive behaviour different types opponents. supported comprehensive evaluation three agents trained three baselines analysed crossevaluation perspective. experimental results report agents substantially outperform baseline agents. results evidence argue promising framework training behaviour complex strategic interactive agents. future work example carry similar evaluations strategic environments also extend abilities agents strategic features forms learning addition comparison different model architectures training parameters reward functions explored future work. last least given learning agents trade semantic level extended language understanding/generation abilities communicate verbally funding european research council project stac strategic conversation gratefully acknowledged http//www.irit.fr/stac/. funding esprc project ep/mx/ babble gratefully acknowledged https//sites. google.com/site/hwinteractionlab/babble.", "year": 2015}