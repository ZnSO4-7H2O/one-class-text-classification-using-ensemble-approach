{"title": "Fashioning with Networks: Neural Style Transfer to Design Clothes", "tag": ["cs.CV", "cs.AI", "cs.IR", "cs.NE"], "abstract": "Convolutional Neural Networks have been highly successful in performing a host of computer vision tasks such as object recognition, object detection, image segmentation and texture synthesis. In 2015, Gatys et. al [7] show how the style of a painter can be extracted from an image of the painting and applied to another normal photograph, thus recreating the photo in the style of the painter. The method has been successfully applied to a wide range of images and has since spawned multiple applications and mobile apps. In this paper, the neural style transfer algorithm is applied to fashion so as to synthesize new custom clothes. We construct an approach to personalize and generate new custom clothes based on a users preference and by learning the users fashion choices from a limited set of clothes from their closet. The approach is evaluated by analyzing the generated images of clothes and how well they align with the users fashion style.", "text": "ciﬁc piece clothing improving retrieval images giants e-commerce expanding investment fashion. recently amazon patented system manufacture clothes demand also started shipping virtual assistant echo integrated camera clicks picture user’s outﬁt rates style stitchfix aims simplify user’s experience shop online. online fashion industry looks improve kind clothes recommended users understanding personal style preferences users recommending custom designs becomes important task. personalization recommendation models well researched area include methods collaborative ﬁltering content-based recommendation systems well hybrid systems combine both. collaborative ﬁltering tries analyze user behaviour preferences align users predeﬁned patterns recommend product. content-based methods recommend product based attributes features user searching for. hybrid system incorporates user preferences product features recommend item user. techniques retrieve product seek synthesize personalized merchandise. texture synthesis tries learn underlying texture image order generate samples texture. research space largely focused parametric non-parametric methods. non-parametric methods resample speciﬁc pixels image adopt speciﬁc patches original generate image parametric methods deﬁne statistical model represents texture gatys designed parametric model texture synthesis based convolutional neural networks. model style image extracting feature maps generated image pre-trained instance using layer vggnet. successfully separate style content arbitrary image demonstrate image stylized using textures prior. although convolutional neural networks provide stateof-the-art performance multiple computer vision tasks complexity opacity substantial research question. visualizing features learned network addressed multiple eﬀorts. zeilar convolutional neural networks highly successful performing host computer vision tasks object recognition object detection image segmentation texture synthesis. gatys show style painter extracted image painting applied another normal photograph thus recreating photo style painter. method successfully applied wide range images since spawned multiple applications mobile apps. paper neural style transfer algorithm applied fashion synthesize custom clothes. construct approach personalize generate custom clothes based user’s preference learning user’s fashion choices limited clothes closet. approach evaluated analyzing generated images clothes well align user’s fashion style. recently impressive advances computer vision tasks like object recognition detection segmentation revolution started krizhevsky substantially improving object recognition imagenet challenge using convolutional neural networks research subsequent improvements many tasks related fashion classiﬁcation clothes predicting diﬀerent kinds attributes spepermission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights third-party components work must honored. uses contact owner/author. deconvolution network reconstruct features learned layer cnn. simoyan backpropagate gradients generated class respect input image create artiﬁcial image represents class network. separation style content image gatys shows variant invariant parts image. contribution paper pipeline learn user’s unique fashion sense generate design patterns based preferences. figure shows sample clothing item generated using neural style transfer. ﬁrst clothing item given user provides shape dress. second initially provided user his/her closet learn preference. third ﬁnal generated design user prior research fashion data computer vision community dealt whole range challenges including clothes classiﬁcation predicting attributes clothes retrieval items create robust fashion dataset images contains annotations various types clothes attributes location landmarks well cross-domains pairs. also design predict attibutes landmarks. architecture based layer vggnet adds convolution fully-connected layers train network predict them. phillip perform image image translation using conditional adversarial network. perform experiments generate various fashion accessories provided sketch item. -layer pre-trained vggnet trained imagenet dataset network consists convolutional layers fully-connected layers. trained predict classes network known robust features generated used solve multiple downstream tasks. gatys pre-trained vggnet extract style content features. johnson create image transformation network trained transform image given style. feed-forward transformation network trained realtime using perceptual loss functions depend highlevel features pre-trained loss network rather per-pixel loss function based level pixel information. trained network start transforming image white-noise generates output directly thus speeding process. describes process using image representations encoded multiple layers vggnet separate content style images recombine form images. idea style extraction based texture synthesis process represents texture gram matrix feature maps generated convolutional layer. style extracted weighted gram matrices across convolutional layers pretrained vggnet processes image. content obtained feature maps extracted higher layers network image processed. style content losses computed mean squared error features maps gram matrices original image randomly generated image minimizing loss transforms white noise artistic image. section describes style content extracted image using neural style transfer implementation given pre-trained layer vggnet model takes content image style images input. consider input image convolutional neural network every convolution layer convolutional network distinct ﬁlters. upon completion convolution operation feature computed height width ﬂattened figure overall system architecture. a...an attributes dataset a...ak attributes given user. total loss gram matrix modiﬁed image gram matrices user’s personal style store ﬁrst phase user provides system access closet images user’s fashion preferences learned. phase user gives choices desired outline piece clothing custom design. figure shows entire pipeline personalize design custom clothes user. four modules architecture namely preprocessing personal style store creation style transfer post-processing generate ﬁnal design. following section discusses modules detail. minimize complexity problem consider images deepfashion dataset white background. images contain clothing objects humans artifacts. upper-body full-body apparel pieces. feature maps higher layers model give representation image biased towards content feature representations conv layer extract content. given feature representations layer original image generated white noise image respectively deﬁne number images every attribute picked depends distribution particular attribute across entire list images present. higher frequency attribute distribution higher bias towards certain label suppresses eﬀect others. makes certain image characteristics pronounced ﬁnal dress others. hence oﬀset bias weight utilized. here weights assigned content style losses respectively. user chosen outline lbfgs optimizer used minimize loss. output image post-processed ﬁnal image. objective minimize content style losses. size. original image placed center temporary image. resizes image expected size without deforming also mask image extracted stored using grabcut utility mask used postprocessing step patterns lying beyond contours apparel. attributes clothes assumed provided automatically labeling beyond scope paper. learn user’s fashion preferences user initially provides clothes closet. gram matrices clothes annotated attributes calculated. tensorﬂow allows partially computed functions style losses thus stored dictionary associated attributes. personal style store constructed user. perform style transfer inputs necessary. shown ﬁgure user inputs list attributes he/she like garment. list attributes like print stripes fabric chiﬀon. current system style learned attribute types texture fabric. dress shape considered representation style object. apart attributes user also gives image contains shape dress desire. called user chosen outline attributes dresses closet a...an. selected user attributes a...ak style loss functions corresponding attributes selected user’s personal style store. although style’s extracted user’s closet whole represent his/her fashion sense pick style functions chosen attributes assume user’s mental model dress likely simquantitative evaluation personalization models challenging task. standard approach create survey mechanical turk users styles transferred properly dress designs personalized given wardrobe. fashion presents unique challenge highly dependent user’s taste different kinds clothing. instead diﬀerent tact applied. figure shows evaluation performed. check style imparted given image verifying classiﬁer able identify style attributes present trained learn attributes clothes present user’s closet using features generated -layer vggnet test dataset created generated random combination attributes random combinations attributes dress images generated. featurized pre-trained vgg- check svm’s ability predict combinations attributes. images images used styling maintained separately. total ucos images user’s wardrobe. kinds tests considered experiment. ﬁrst test images generated images separate styles extracted training similar attributes. second test images generated styles extracted training data itself. figure shows f-score varying number test images generated. consistent performance baseline suggests style likely transferred able classify based features generated. experiments increasing number images used gaining styles showed drop score suggesting increasing number style functions impact quality result thus making diﬃcult identify patterns. hence necessary limit number style functions used generate dress. figure bar-chart showing f-scores baseline model actual test data using separate training test generation images using images training test data generation analyze quality dress images seeing similar style images used personalization process. quality generated image impacted number factors. eﬀect various hyper-parameters measured. figure shows image sheer draped blouse changed adopt styles extracted couple images. result nice blend patterns borrowed style images given. using multiple distinct style images produces interesting results. figure presents style four diﬀerent knit garments tank top. four diﬀerent textures fabric produce distinct results. paper show initial pipeline generate designs clothes based preference user. results indicate style transfer happens successfully personalized closet user. future like improve performance pipeline time consuming generate design. also plan experiment better methods personalize generate designs higher resolutions. chen citro corrado davis dean devin ghemawat goodfellow harp irving isard jozefowicz kaiser kudlur levenberg man´e monga moore murray olah schuster shlens steiner sutskever talwar tucker vanhoucke vasudevan vi´egas vinyals warden wattenberg wicke zheng. tensorflow large-scale machine learning efros freeman. image quilting texture synthesis transfer. proceedings annual conference computer graphics interactive techniques pages efros leung. texture synthesis russakovsky deng krause satheesh huang karpathy khosla bernstein imagenet large scale visual recognition challenge. international journal computer vision l.-y. levoy. fast texture synthesis using tree-structured vector quantization. proceedings annual conference computer graphics interactive techniques pages press/addison-wesley publishing xiao yang huang wang. learning massive noisy labeled data image classiﬁcation. proceedings ieee conference computer vision pattern recognition pages look clothing recognition segmentation automatic product suggestions everyday photos. proceedings conference international conference multimedia retrieval pages deepfashion powering robust clothes recognition retrieval rich annotations. proceedings ieee conference computer vision pattern recognition pages", "year": 2017}