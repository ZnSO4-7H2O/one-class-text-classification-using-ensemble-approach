{"title": "MoDeep: A Deep Learning Framework Using Motion Features for Human Pose  Estimation", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "In this work, we propose a novel and efficient method for articulated human pose estimation in videos using a convolutional network architecture, which incorporates both color and motion features. We propose a new human body pose dataset, FLIC-motion, that extends the FLIC dataset with additional motion features. We apply our architecture to this dataset and report significantly better performance than current state-of-the-art pose detection systems.", "text": "abstract. work propose novel eﬃcient method articulated human pose estimation videos using convolutional network architecture incorporates color motion features. propose human body pose dataset flic-motion extends flic dataset additional motion features. apply architecture dataset report signiﬁcantly better performance current state-of-the-art pose detection systems. human body pose recognition video long-standing problem computer vision wide range applications. however body pose recognition remains challenging problem high dimensionality input data high variability possible body poses. traditionally computer vision-based approaches tend rely appearance cues texture patches edges color histograms foreground silhouettes hand-crafted local features rather motion-based features. alternatively psychophysical experiments shown motion powerful visual alone used extract high-level information including articulated pose. previous work reported using motion features pose inference little impact performance. simply adding high-order temporal connectivity traditional models would often lead intractable inference. work show deep learning able successfully incorporate motion features able out-perform existing state-of-the-art techniques. further show using motion features alone method outperforms strengthens claim information coded motion features valuable used available. geometric model based tracking earliest works articulated tracking video hogg using edge features simple cylinder based body model. several model based articulated tracking systems reported past decades notably models used systems explicit jointed geometric models. systems hand-initialized focused incrementally updating pose parameters frame next. complex examples come humaneva dataset competitions video higher-resolution shape models scape extensions. refer reader complete survey era. recently techniques shown create high-resolution animations detailed body cloth deformations approach diﬀers since dealing single view videos unconstrained environments. statistical based recognition earliest systems used explicit geometric model reported freeman using oriented angle histograms recognize hand conﬁgurations. precursor bag-of-features sift stip histogram flow approaches boomed decade later notably including work dalal triggs diﬀerent architectures since proposed including shape-context edge-based histograms human body silhouette features shakhnarovich learn parameter sensitive hash function perform example-based pose estimation. many techniques proposed extract learn reason entire body features using combination local detectors structural reasoning coarse tracking person-dependent tracking). though idea using pictorial structures fischler elschlager around since matching eﬃciently images possible since famous work ‘deformable part models’ felzenszwalb many algorithms creating body part unary distribution spatial-models incorporating body-part relationship priors since developed. johnson everingham also proposed ‘leeds sports database’ employ cascade body part detectors obtain discriminative templates. almost best performing algorithms since solely built local evidence sophisticated spatial models. pishchulin proposes model augments unaries poselet conditioned priors. sapp taskar propose model cluster images posespace mode best describes input image. pose mode acts strong spatial prior whereas local evidence based gradient features. following poselets approach armlets approach gkioxari incorporates edges contours color histograms addition features. employ semi-global classiﬁer part conﬁguration show good performance real-world data. however show results arms. major drawback approaches local evidence global structure hand crafted whereas jointly learn local features global structure using multi-resolution convolutional network. shotton ensemble random trees perform per-pixel labeling body parts depth images. means reducing overall system latency avoiding repeated false detections work focuses pose inference using single depth image. contrast extend single frame requirement least frames input domain unconstrained images rather depth. deep learning based techniques recently state-of-the-art performance reported many vision tasks using deep learning algorithms also apply neural networks pose recognition speciﬁcally toshev show better state-of-the-art performance ‘flic’ ‘lsp’ datasets. contrast toshev work propose translation invariant model improves upon method especially high-precision region. propose convolutional network architecture task estimating location human joints video input network image motion features. investigate wide variety motion feature formulations finally also introduce simple spatial-model solve speciﬁc sub-problem associated evaluation model flic-motion dataset section incorporate features representative true motion-ﬁeld input detection network exploit motion body part localization. evaluate analyze four motion features fall broad categories using simple derivatives video frames using optical features. image pair fi+δ propose following features image pair simplest incorporating relative motion information frames. however representation clearly suﬀers redundancy extremely high dimensional. furthermore obvious deep network changes high dimensional input space relevant temporal information changes noise camera motion. simple modiﬁcation representation diﬀerence image reformulates input algorithm sees directly pixel locations high energy corresponds motion sophisticated representation optical-ﬂow considered high-quality approximation true motion-ﬁeld. implicitly learning infer optical-ﬂow input would nontrivial network estimate perform optical-ﬂow calculation pre-processing step flic-motion dataset propose dataset call flic-motion. comprised original flic dataset labeled images collected hollywood movies images held test augmented aforementioned motion features. experimented diﬀerent values investigated features without camera motion compensation; simple projective motion model fi+δ warp fi+δ onto using inverse best ﬁtting projection approximately remove camera motion. comparison image pairs without warping seen obtain fi+δ must know frames occur movie. unfortunately non-trivial authors sapp could provide exact version movie used creating original dataset. corresponding frames diﬀerent multiple versions movie estimate best similarity transform frame movie distance |fi−sf recent work shown convnet architectures well suited task human body pose detection availability modern graphics processing units perform forward propagation deep convnet architectures interactive frame-rates. similarly realize detection model deep convnet architecture. input tensor containing image corresponding motion features output tensor containing response-maps response-map joint. response-map describes per-pixel energy presence corresponding joint pixel location. convnet based sliding-window architecture. simpliﬁed version architecture shown input patches ﬁrst normalized using local contrast normalization channels normalization method motion features call local motion normalization formulate local subtraction response gaussian kernel large standard deviation followed divisive normalization. result removes unwanted background camera motion well normalizing local intensity motion prior processing convolution stages normalized motion channels concatenated along feature dimension normalized channels resulting tensor processed though stages convolution. ﬁrst convolution stages rectiﬁed linear units maxpooling last stage incorporates single relu layer. output last convolution stage passed three stage fully-connected neuralage stepped every pixels horizontally vertically. produces dense response-map output joint. major advantage model learned detector translation invariant construction. layers convolutional applying instances network overlapping input windows leads considerable amount redundant computation. recent work eliminates redundancy thus yields dramatic speed achieved applying layer convolutional network entire input image. fully connected layers window also replicated sub-windows input. formulation allows back-propagate though network windows simultaneously. note alternative model would replace last convolutional layers fully-connected neural network whose input context feature activations entire input image. model would appropriate knew priori existed strong correlation skeletal pose position person input frame since alternative model invariant respect translation person within image. however flic dataset strong pose-location bias therefore sliding-window based architecture appropriate task. extend single resolution convnet architecture incorporating multi-resolution input. down-sampling input resolution image processed either layer using normalization kernels bank producing approximate laplacian pyramid. role laplacian pyramid provide bank non-overlapping spectral content minimizes network redundancy. ﬁnal multi-resolution network shown outputs convolution banks concatenated point-wise up-scaling lower resolution bank bring feature maps canonical resolution. note ﬁnal implementation resolution banks. train part-detector network using supervised learning back propagation stochastic gradient descent. minimize mean squared error criterion distance inferred response-map activation ground truth response-map gaussian distribution centered target joint location small standard deviation nesterov momentum reduce training time randomly perturb input images epoch randomly ﬂipping scaling images prevent network overtraining improve generalization performance. model evaluated flic-motion dataset original flic dataset test images flic-motion contain multiple people however single actor frame labeled test set. such rough torso location labeled person provided test time help locate correct person. incorporate information means simple eﬃcient spatial-model. inclusion stage major advantages. firstly correct feature activation part-detector output selected person ground-truth label annotated. example shown secondly since joint locations part constrained proximity single ground-truth torso location connectivity joints also constrained enforcing inferred poses anatomically viable core spatial-model empirically calculated joint-mask shown joint-mask layer describes possible joint locations given supplied torso position center mask. create mask layer body part ﬁrst calculate empirical histogram part location relative torso position training examples; i.e. test time joint-mask shifted ground-truth torso location per-pixel energy part-model multiplied mask produce ﬁltered output. process carried body part independently. training time model flic-motion dataset approximately hours fprop single image takes approximately models optical motion feature input expensive part pipeline optical calculation takes approximately image pair. section compares performance motion features section section compares architecture techniques shows system signiﬁcantly outperforms existing state-of-the-art techniques. note experiments section smaller model convolutional features ﬁrst layers. model instead features ﬁrst convolutional layers used results section shows selection example images flic test highlights importance using motion features body pose detection. elbow position occluded actor’s sling examples exist training set; however presence body motion provides strong elbow location. figs extremely cluttered backgrounds correct joint location locally similar surrounding region images motion features essential correct joint localization. finally example motion blur reduces ﬁdelity edge features results incorrect localization motion features used. figs show performance motion features section flic-motion dataset elbow wrist joints respectively. evaluating test-set performance criterion proposed sapp count percentage test-set images joint predictions within given radius normalized pixel torso size. surprisingly even simple frame-diﬀerence temporal feature improves upon baseline note stable accurate calculation optical-ﬂow arbitrary videos challenging problem. therefore incorporating motion features input network adds non-trivial localization cues would diﬃcult network learn internally limited learning capacity. therefore expected best performing networks incorporate motion features. however surprising using magnitude vectors performs well cases outperforms full motion ﬂow. even though input data richer hypothesize using vectors network must learn invariance direction joint movement; instance network predict head position whether person turning his/her head left right next frame. hand magnitude vector used network sees high velocity motion cannot over-train direction movement. shows performance network relatively agnostic frame separation samples calculate motion ﬂow; average precision pixel radii degrades pixels oﬀset pixel oﬀset. frame diﬀerence corresponds approximately .sec expect large motions time period would result complex non-linear trajectories input space single ﬁnite diﬀerence approximation pixel velocity would inaccurate. accordingly results show performance indeed degrades larger frame step used. shown likely either removes constant background motion network able learn ignore remaining foreground-background parallax motion camera movement. compares performance system stateof-the-art models flic dataset elbow wrist joints respectively. detector able signiﬁcantly outperform prior techniques challenging dataset. note using motion features already outperforms also note using motion features less accurate using combination motion features images especially high accuracy region. details eyes noses missing motion features. toshev suﬀers inaccuracy high-precision region attribute ineﬃcient direct regression pose vectors images. modec eichner sapp build hand crafted features. suﬀer limitations jain multi-scale information evaluate model sliding window fashion whereas ‘one-shot’ approach. finally believe increasing complexity simple spatial model improve performance model speciﬁcally large radii. shown incorporating motion features deep convnet architecture network able outperform existing state-ofthe-art techniques task human body pose detection video. also shown using motion features alone outperform traditional algorithms ﬁndings suggest even simple temporal cues greatly improve performance minor increase model complexity. such suggest future work place emphasis correct motion features. would also like explore higher level temporal features potentially learned spatiotemporal convolution stages hope using expressive temporal-spatial model help improve performance signiﬁcantly.", "year": 2014}