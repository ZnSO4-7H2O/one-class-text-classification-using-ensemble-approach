{"title": "Cognitive Deep Machine Can Train Itself", "tag": ["cs.LG", "cs.AI", "cs.NE"], "abstract": "Machine learning is making substantial progress in diverse applications. The success is mostly due to advances in deep learning. However, deep learning can make mistakes and its generalization abilities to new tasks are questionable. We ask when and how one can combine network outputs, when (i) details of the observations are evaluated by learned deep components and (ii) facts and confirmation rules are available in knowledge based systems. We show that in limited contexts the required number of training samples can be low and self-improvement of pre-trained networks in more general context is possible. We argue that the combination of sparse outlier detection with deep components that can support each other diminish the fragility of deep methods, an important requirement for engineering applications. We argue that supervised learning of labels may be fully eliminated under certain conditions: a component based architecture together with a knowledge based system can train itself and provide high quality answers. We demonstrate these concepts on the State Farm Distracted Driver Detection benchmark. We argue that the view of the Study Panel (2016) may overestimate the requirements on `years of focused research' and `careful, unique construction' for `AI systems'.", "text": "l˝orincz csákvári fóthi milacski sárkány t˝osér department software technology methodology faculty informatics eötvös loránd university pázmány péter sétány budapest hungary machine learning making substantial progress diverse applications. success mostly advances deep learning. however deep learning make mistakes generalization abilities tasks questionable. combine network outputs details observations evaluated learned deep components facts conﬁrmation rules available knowledge based systems. show limited contexts required number training samples selfimprovement pre-trained networks general context possible. argue combination sparse outlier detection deep components support diminish fragility deep methods important requirement engineering applications. argue supervised learning labels fully eliminated certain conditions component based architecture together knowledge based system train provide high quality answers. demonstrate concepts state farm distracted driver detection benchmark. argue view study panel overestimate requirements ‘years focused research’ ‘careful unique construction’ systems’. machine learning progressing quickly deep learning. tool deep learning crowdsourcing i.e. exploitation human intelligence. success stories demonstrate superhuman performance reached still groundbreaking deep network approach seems limited ‘each application requires years focused research careful unique construction’ however take look human information processing example learn basic routes holistic recognition recognition components processing methodologies competing also complementing other. deep learning methods hand tend favor endto-end learning corresponds holistic recognition missing advantages component based approach. furthermore holistic recognition thus end-to-end learning fragile. fragility shown number studies. e.g. deep networks fooled described nguyen inputs differ enormously human observer given class assigned label class extremely high conﬁdence demonstrated sharif showing barely visible watermark-like modiﬁcations change class label small additional components designed change class index another desired making network prone attacks. admit highly sophisticated human visual recognition system also prone illusions misinterpret visual information. additional apparent source error dependency context. tool eventually want exploit diminishing problems mentioned above. illustrate problem examples. consider fig. figure looks like deﬂated football figure objects contexts. segmented object object environment coco training sample segmented horse placed different environments zoomed out. bounding white characters blue background best network proposals belonging scores. interpretation changed easily varying environment also chair. deep learning make similar ‘mistakes’ used faster r-cnn network pre-trained pascal database. training contains horse changed environment horse without adding occlusion. backgrounds chosen visual genome database. provide samples results. example best guess remained ‘horse’ horse along road changed ‘cow’ upon mirroring horse left-to-right inserting segmented horse bottom ofﬁce desk ‘dog’ best guess network intriguingly network proposals make sense context typically cows crossing roads dogs ofﬁce. somehow somewhere knowledge implicitly embedded database. make explicit. easy change output network trained many examples? good since context help e.g. words ambiguous. case category certain uncertainty seems worrying. forth idea holistic recognition disambiguated recognition components mane hoof case horse example. component based reasoning easily output network. furthermore time series available motion pattern help since differs considerably horses dogs cows. components several advantages smaller spaces environment correlated them like example face ‘environment’ eyes mouth temporal continuity present improve precision observation process. nonetheless cooperation competition holistic information processing component based inference overcome problems supported different visual auditory illusions certain combinations like mcgurk effect too. note also general information processing point view components useful; acquire additional knowledge hearsay connect lower level component detectors higher level symbols offering solution symbol grounding problem emphasized harnad holistic component based recognition mechanisms seem compete complement point sophisticated hierarchical construction beyond present deep neural network architectures. demonstrate traditional knowledge based systems capable bridging training deep neural networks working different correlated components larger recognition problem. general knowledge based systems include reasoning tools differential equations knowledge physics world ontologies among others. important ingredient approach condition components assume other. procedure three building blocks. ﬁrst robust principal component analysis ﬁlters apparent components fact outliers. related problem group fused lasso capable segmenting time series presence non-gaussian sparse deviations offering e.g. capability grouping samples time. second part self-training individual deep learning architectures pre-trained general scenarios ﬁne-tune limited context. third element derivation rule based systems episodic labels given even meaning labels hidden illustrate approach state farm distracted driver scenario kaggle benchmark. theoretical background procedures used given sect. treat driver monitoring benchmark sect. show deep components outlier detection rule based system together call cognitive deep machine improves performance. discussion considers generality results. section argue development novel engineering solutions exploiting deep learning much faster expected study panel reasons deep networks reused strengthen train narrow contexts connected high level rule-based expert systems. section elaborate concept within framework. short summary concludes technical report below describe outlier detection temporal segmentation schemes discuss optical flow unsupervised ﬁnding components followed list pre-trained deep networks ﬁne-tune self-supervision robust principal component analysis well known classical principal component analysis essentially works norm estimation hence breaks presence additional gross-but-sparse outliers. candès showed possible augment architecture term collects thus separates components call robust principal component analysis accordingly given rd×t deﬁne following convex optimization problem i.e. rd×t approximates low-rank regularizer singular value vector rd×t represents extra sparse outlier term regularizer). utilized inexact augmented lagrangian multiplier solver problem implemented python. rpca method require time series utilized way. convex multiple change point detection multivariate time series relies regularized frobenius norm estimation well regularizer acts ﬁnite difference optimization variable i.e. input rd×t weight matrix rd×t solve problem often called group fused lasso here indicates elementwise product rt×t−p ﬁnite differencing matrix differentiates rd×t times yielding piecewise polynomial model degree regularizer promotes used optical flow implemented opencv searching components across time estimating bounding motion neighbouring frames video. first applied object detector obtain bounding coordinates frame boxes scaled identical sizes. next original frames estimated motion feature points within bounding boxes. provided similarity measure consecutive frames. similarity threshold grouped bounding boxes together. kept multiple time steps. finally also merged groups similar. original method improved many ways including pyramidal evaluations start resolution work towards higher ones dense optical flow methods deep architectures also combinations e.g. work fischer references therein. years method serves illustration purposes here. deep learning thoroughly reviewed schmidhuber introduction details theory different networks found recent book goodfellow consequently refer interested reader excellent works restrict technical report collection references papers related software tools applied course work http//docs.opencv.org/.-beta/modules/optflow/doc/dense_optflow.html code https//github.com/rbgirshick/py-faster-rcnn code https//github.com/orpine/py-r-fcn code https//github.com/shihenw/convolutional-pose-machines-release database http//mscoco.org/ database http//host.robots.ox.ac.uk/pascal/voc/voc/index.html database https//visualgenome.org/ database http//www.robots.ox.ac.uk/~vgg/research/hands/index.html database http//cvrr.ucsd.edu/vivachallenge/index.php/hands performed evaluated methodology kaggle state farm distracted driver detection challenge ﬁnished months august database contains subjects video each. original benchmark consisted individual images later sorted assembled videos gilberto titericz junior. recordings consist driving scenarios viewed passenger’s seat camera facing driver. world outside window hazy light. chair body driver dashboard barely move. labels state farm distracted driver detection challenge ambiguous misleading. example image fig. correspond safe driving driver looking back overcome limits mirrors monitor blind spots directly. hand samples safe driving labels driver looking passenger laughing clearly distracted. rule based system takes account driver talking estimation gaze direction would classify latter ‘talking passenger’. decision correct label fig. require information past goals driver. example want change lanes asking passenger back seat move blind spot mirror vehicle. examples labeling ambiguous e.g. driver texting talking simultaneously. figure facial expression gaze direction estimation kaggle benchmark. ‘talking passenger’ category inferred single image absence acoustic signals narrow green lines connect facial markers broad green lines represent head pose turquoise arrows starting iris show estimated gaze directions. below show examples rpca analysis applied grayscale video independently default parameters. figure four sets three subﬁgures. left middle right subﬁgures represent original image rank outlier components respectively. large portion images stationary; parts form dimensional subspace rpca analysis. outliers mostly correspond short time intervals within driving episodes called example ‘operating radio’ ‘texting right hand’ ‘drinking’ ‘talking passenger’ more. note outlier parts well dimensional subspace parts differ projections onto subspace projections depend input. database https//www.kaggle.com/c/state-farm-distracted-driver-detection https//www.kaggle.com/titericz/state-farm-distracted-driver-detection/ figure effect robust principal component analysis subﬁgure left middle right images represent original typical part outlier components respectively. latter right hand follows. hand dashboard mobile hand paper hand calling attention position. algorithm collect atypical body head poses objects outlier component within rank subspace using superposition. similar outliers correlated ground truth labels sect. note driver body poses also associated. information determined means pose detector convolutional pose machine applied convolutional pose machine original frame independently extract joint coordinates. network pre-trained mostly frontal body samples still shows reasonable performance side views upper body conﬁgurations. network outputs extremely noisy across time tried extract underlying temporal segments constant pose using group fused lasso pose outputs normalized weighted scores. cvxpy yield truly sparse solution change point strengths thresholded. result nearly perfect match ground truth labels despite large portion noise videos shown fig. similar results achieved videos. cases temporally segmented frames form groups shall discuss later. applied optical flow region-based fully convolutional network handdetector videos. fig. illustrates results point. subﬁgure represents close-to periodic motion within larger image. labeled ‘drinking’ kaggle database driver holding starts stops drinking alternating manner. described sect. relevant portions images segmented hand detector coherence motion made visible subﬁgures green arrows show motion individual feature points. arrows change direction drinking phases optical flow serve episodic segmentation especially dense optical flow algorithms used. furthermore similarly group fused lasso example above bounding boxes connected optical form groups natural fashion detailed sect. episodic description detailed facial information predictors object detectors included shown fig. fig. respectively. object detection relatively weak kaggle benchmark occluded objects frequent lack rich datasets would scenarios e.g. objects hand. consider fig. showing test results faster r-cnn network coco fig. easy recognize cellphone. however figure temporal segmentation. blue lines represent left right wrist elbow coordinates convolutional pose machine output. lines group fused lasso estimations. switch estimations different threshold values legends. blue lines ground truth episode labels according kaggle database. lines episode labels computed group fused lasso. cellphone inferred higher order knowledge fig. classiﬁcation questioned. images test dataset higher order knowledge implicit labeling training database. proceeded follows. ‘know’ labels human activities manifested gaze either search focused something hands provide information actual manipulation speech don’t benchmark. used mittal’s hand dataset hand detection viva hand detection dataset left right hand classiﬁcation. employed region-based fully convolutional network localization hands vanilla convolutional network classifying hand left right. results encouraging left right hands frequently misclassiﬁed. combined outputs convolutional pose machine direction self-training; we/it exploit inference methods based knowledge knowledge bases point strengths classical artiﬁcial intelligence procedures. within kaggle database special scenario called ‘safe driving’. case hands steering wheel limited spatial region. furthermore driving scenarios hand always wheel; frames exceptions. interplay convolutional pose machine hand detectors together backing knowledge forms cognitive deep machine follows figure region-based fully convolutional network hand-detector lucas kanade optical flow. right hand left right poses head pose three bounding boxes selected hand detector subsequent frames. green lines represent motion vectors individual features. rigor could introduced means optical flow; require conditions fulﬁlled longer time interval depending frame rate. high score convolutional pose machine know hand which i.e. left right. variety limited learn recognize left right hands steering wheel. proceed here since scenarios hands steering wheel. turn backing knowledge says hand steering wheel hand provided pose machine supports proposition. note people car; next driver working camera. person sitting back seat taking notes making phone calls texting. figure object detection convolutional pose machine kaggle benchmark. cellphone bottle original image; blue boxes lines show hand detector pose results green line shows head pose results. procedure used label benchmark. note however information dropped recognize steering wheel. procedure would follow. imagenet samples class training feasible. knowledge based method brings good results kaggle scenario. information hands injected convolutional pose machine iterates heat maps suspected positions. heat figure warning robust principal component analysis inference based correction hand detector result injection convolutional pose machine. pose special full differs considerably average grey color. left image resolution middle dimensional projection right ‘outliers’. convolutional pose machine breaks arms hands classiﬁed right hands. hand wheel classiﬁcation trained thus trusted scenario label hand modiﬁed left pieces information injected convolutional pose machine giving rise improved pose estimation. training example also generated convolutional pose machine. outputs different input-output systems used self-training. example convolutional pose machine hand detector improved performances joining cognitive machine high scoring poses hand detector outputs improving recognition left right hands within kaggle scenarios. know context driving hand steering wheel time. information giving proper labels left right hands training itself. using inference inject information left and/or right hand convolutional pose machine. derived pose serve training convolutional pose machine within benchmark scenarios. actual context segmentation procedures provided group fused lasso warning signs rpca method outliers deep networks trained other general databases. applied heuristics although proved successful still accidental. nonetheless reinforcement learning discuss sect. discuss below. machinery used simpliﬁed kaggle benchmark considerably. recognize pose separate movements left right hands track face hand high precision. object detection raised high levels thus recognition cell phones cups/mugs problem. outcome considerations classiﬁcation according kaggle labels simple rule-based task require training. meaning label sufﬁcient proper classiﬁcation. furthermore ﬁlter ambiguous cases e.g. talking passenger texting occur simultaneously. main reason think study panel overestimate complexity developing applications. deep technology alone serve applications also knowledge components relations i.e. semantic ontological knowledge collected many years history. question emerges following assuming labels codes thus meaning could tell happening? temporal grouping means group fused lasso optical flow help examples driver picks telephone looks phone manipulates phone lifts phone talks. interpretation scenario guessed using conceptnet. turn derive number rules kaggle scenarios. particular example dialing holding phone involves hand driving scenarios. component searches learning followed inferences take back traditional enable fast learning since learn categories relations hearsay. zebra related horse illustration giraffe similar spots stripes neck much longer. learn kaggle labels too; also provide information. example ordinary communication separation class ‘safe driving’ involve categories safe. similarly suspect phones capable text messaging common sense today decades ago. reasoning capabilities make decision making turn applications relatively easy develop. components known reasoning based upon sufﬁcient many cases. found mankind thousands years passed child twenty years opinion knowledge components deep neural networks trained recognize them. principles applied hundred year gestalt principles also called gestalt laws grouping proximity similarity continuity closure connectedness. serve discover spatio-temporal phenomena episodes characterize predict them possible compress meaningful concepts human intelligence. tacitly exploited determinism used high scores temporal relationships optical flow group fused lasso. hypothesis outlier detection determinism together powerful tools learning recognize components knowledge spatio-temporal relationships. point view learning recognition high score time help track object learn interactions e.g. phone picked details know less likely make mistakes. also gestalt view. word cognition used many ways including information processing acquiring knowledge among others. view deep network capable cognizing. think cognition input-output mapping includes capability reasoning utilizes reasoning acquiring knowledge. note using word understanding since beyond present formulation. reasoning concerns considerations components reliability related observations well spatio-temporal context. cognition least ingredients holistic componentwise observations e.g. means deep networks outlier detection concerning observations reasoning best labels means observed components reasoning outliers collecting examples self-training means collected anomalies. went steps result section highlight milestones approach. note point provided algorithmic method name. since believe cognition meaningless without goals. thus view cognition closely linked reinforcement learning. learning supervision concerns input-output mapping. think difference supervised learning components like case pose machine unsupervised searches spatio-temporal structures. think latter built stepwise basic elements means gestalt principles example horse zebra giraffe look similar differ texture length neck shape body including mane hoof environment live reduction variables reinforcement learning work since reinforcement learning absence highly compressed factors restricted might relevant decision making blows exponentially. reduced spatio-temporal components ‘factored reinforcement learning’ becomes feasible summarized t˝osér l˝orincz cited references therein. important ingredient approach assumption close deterministic episodes concurrent start stop. concepts formulated within event learning framework single episodic series szita szita l˝orincz multiple events. success stories reinforcement learning using deep networks already numerous including atari games game turn conjecture applications built deep learning technology based reinforcement learning although technologically might challenging regarding sensory control systems appear relatively fast opposed view expressed study panel considered development deep learning technology combined traditional component based reasoning. provided examples state farm distracted driver detection benchmark. argued benchmark requires components learned deep learning problems outside benchmark itself. then components benchmark requires learning reasoning unsupervised anomaly detection data collection related detected anomalies searches temporal segments ﬁnally self-training within context distracted driver detection problem. conclude novel applications tackled bottleneck sensory information learning system itself. also argue component based construction several advantages overcome fragility deep learning means component-wise reasoning; detect anomalies means inverting input-output system; look spatio-temporal structures means gestalt principles; self-train component based reasoning capabilities. justify conclusion highlighting applications high level determinism training concerns limited context ontology rule based systems warranted operation potential errors modeled virtual reality data collected practice searching anomalies less stringent conditions. system train step-by-step. philipp fischer alexey dosovitskiy eddy philip häusser caner hazirbas vladimir golkov patrick smagt daniel cremers thomas brox. flownet learning optical convolutional networks. ieee international conference computer vision ieee ranjay krishna yuke oliver groth justin johnson kenji hata joshua kravitz stephanie chen yannis kalantidis li-jia david shamma visual genome connecting language vision using crowdsourced dense image annotations. arxiv preprint arxiv. tsung-yi michael maire serge belongie james hays pietro perona deva ramanan piotr dollár lawrence zitnick. microsoft coco common objects context. european conference computer vision springer andrás l˝orincz andrás sárkány zoltán milacski zoltán t˝osér. estimating cartesian compression deep learning. lecture notes computer science volume chapter artiﬁcial general intelligence springer volodymyr mnih koray kavukcuoglu david silver andrei rusu joel veness marc bellemare alex graves martin riedmiller andreas fidjeland georg ostrovski human-level control deep reinforcement learning. nature nguyen jason yosinski jeff clune. deep neural networks easily fooled high conﬁdence predictions unrecognizable images. international conference computer vision pattern recognition ieee mahmood sharif sruti bhagavatula lujo bauer michael reiter. accessorize crime real stealthy attacks state-of-the-art face recognition. proceedings sigsac conference computer communications security david silver huang chris maddison arthur guez laurent sifre george driessche julian schrittwieser ioannis antonoglou veda panneershelvam marc lanctot mastering game deep neural networks tree search. nature zoltán t˝osér andrás l˝orincz. cyber-physical system approach towards artiﬁcial general intelligence. lecture notes computer science volume chapter artiﬁcial general intelligence springer zoltán t˝osér róbert rill kinga faragó lászló jeni andrás l˝orincz. personalization gaze direction lecture notes computer science volume chapter", "year": 2016}