{"title": "Men Also Like Shopping: Reducing Gender Bias Amplification using  Corpus-level Constraints", "tag": ["cs.AI", "cs.CL", "cs.CV", "stat.ML"], "abstract": "Language is increasingly being used to define rich visual recognition problems with supporting image collections sourced from the web. Structured prediction models are used in these tasks to take advantage of correlations between co-occurring labels and visual input but risk inadvertently encoding social biases found in web corpora. In this work, we study data and models associated with multilabel object classification and visual semantic role labeling. We find that (a) datasets for these tasks contain significant gender bias and (b) models trained on these datasets further amplify existing bias. For example, the activity cooking is over 33% more likely to involve females than males in a training set, and a trained model further amplifies the disparity to 68% at test time. We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for collective inference. Our method results in almost no performance loss for the underlying recognition task but decreases the magnitude of bias amplification by 47.5% and 40.5% for multilabel classification and visual semantic role labeling, respectively.", "text": "language increasingly used deﬁne rich visual recognition problems supporting image collections sourced web. structured prediction models used tasks take advantage correlations co-occurring labels visual input risk inadvertently encoding social biases found corpora. work study data models associated multilabel object classiﬁcation visual semantic role labeling. datasets tasks contain signiﬁcant gender bias models trained datasets amplify existing bias. example activity cooking likely involve females males training trained model ampliﬁes disparity test time. propose inject corpus-level constraints calibrating existing structured prediction models design algorithm based lagrangian relaxation collective inference. method results almost performance loss underlying recognition task decreases magnitude bias ampliﬁcation multilabel classiﬁcation visual semantic role labeling respectively. visual recognition tasks involving language captioning visual question answering visual semantic role labeling emerged avenues expanding diversity information recovered images. tasks extracting rich semantics images require large quantities labeled data predominantly retrieved web. methods often combine structured prediction deep learning model correlations labels images make judgments otherwise would weak visual support. example ﬁrst image figure possible predict spatula considering common tool used activity cooking. methods risk discovering exploiting societal biases present underlying corpora. without properly quantifying reducing reliance correlations broad adoption models inadvertent effect magnifying stereotypes. paper develop general framework quantifying bias study concrete tasks visual semantic role labeling multilabel object classiﬁcation vsrl imsitu formalism goal predict activities objects roles objects play within activity. ms-coco recognition task covering object classes. gender bias running example show supporting datasets tasks biased respect gender binary. analysis reveals verbs objects respectively exhibit bias toward gender greater example seen figure cooking activity imsitu heavily biased verb. furthermore show training state-of-the-art structured predictors models amplify existing bias vsrl mlc. simplify analysis consider gender binary perceived annotators datasets. recognize ﬁne-grained analysis would needed deployment production system. also note proposed approach applied tasks variables identiﬁcation racial ethnic group. figure five example images imsitu visual semantic role labeling dataset. image paired table describing situation verb cooking semantic roles agent noun values ﬁlling role i.e. woman. imsitu training cooking images agent role rest woman. training conditional random field bias ampliﬁed ﬁlls agent roles cooking images. reduce bias ampliﬁcation calibration method adjusts weights potentials associated biased predictions. applying methods appears agent role cooking images reducing bias ampliﬁcation keeping vsrl performance unchanged. mitigate role bias ampliﬁcation training models biased corpora propose novel constrained inference framework called reducing bias ampliﬁcation predictions. method introduces corpus-level constraints gender indicators co-occur often together elements prediction task original training distribution. example seen figure would like noun occur agent role cooking often occurs imsitu training evaluating development set. combine calibration constraint original structured predictor lagrangian relaxation reweigh bias creating factors original model. evaluate calibration method imsitu vsrl coco instances models substantially reduce bias ampliﬁcation. vsrl reduce average magnitude bias ampliﬁcation able reduce average magnitude bias ampliﬁcation overall calibration methods affect performance underlying visual system substantially reducing reliance system socially biased correlations. intelligence systems start playing important roles daily life ethics artiﬁcial intelligence research attracted signiﬁcant interest. known big-data technologies sometimes inadvertently worsen discrimination implicit biases data issues demonstrated various learning systems including online advertisement systems word embedding models online news search credit score data collection biases discussed context creating image corpus text corpus contrast show given gender biased corpus structured models conditional random ﬁelds amplify bias. effect data imbalance easily detected ﬁxed prediction task simple. example classifying binary data unbalanced labels classiﬁer trained exclusively optimize accuracy learns always predict majority label cost making mistakes samples minority class neglected. various approaches proposed make fair binary classiﬁcation bias scores unlabeled evaluation images annotated predictor. assume evaluation identically distributed training set. therefore positively correlated larger bias ampliﬁed. example bias woman toward cooking ampliﬁed. finally deﬁne mean bias ampliﬁcation section introduce reducing bias ampliﬁcation debiasing technique calibrating predictions structured prediction model. intuition behind algorithm inject constraints ensure model predictions follow distribution observed training data. example constraints added vsrl system ensure gender ratio verb within given margin based statistics training data. constraints applied corpus level computing gender ratio requires predictions test lagrangian relaxation dual decomposition techniques widely used tasks dealing instance-level constraints. similar techniques applied handling corpus-level constraints semi-supervised multilabel classiﬁcation. contrast previous works aiming improving accuracy performance incorporate corpus-level constraints reducing gender bias. learning approaches capture modern statistical correlations among output variables order make coherent predictions. however realworld applications implicit correlations appropriate especially ampliﬁed. section present general framework analyze inherent biases learned ampliﬁed prediction model. identifying bias consider prediction problems involve several inter-dependent output variables ...yk represented structure ...yk} common setting applications including tagging parsing. example vsrl task output represented structured table shown modern techniques often model correlation sub-components make joint prediction using structured prediction model. details provided section assume subset output variables reﬂects demographic attributes gender race another subset output corelated goal identify correlations potentially ampliﬁed learned model. represents overall score assignment potentials subassignments. output space contains feasible assignments represented instance-wise constraints. examv ensures corpus-level constraints goal inject constraints ensure output labels follow desired distribution. example constraint ensure gender ratio activity within given margin. output assignment test instance activity constraints written note constraints involve test instances. therefore requires joint inference entire test corpus. general corpus-level constraints represented matrix rl×k coefﬁcients constraint constrained inference problem formulated instances. result joint inference test instances required. solving giant inference problem constraints hard. therefore present approximate inference algorithm based lagrangian relaxation. advantages approach algorithm iterative iteration joint inference problem decomposed per-instance basis. solved original inference algorithm. approach works metaalgorithm developers need implement inference algorithm. practice hard obtain solution corpus-level constrains satisﬁed. however show performance proposed approach empirically strong. imsitu vsrl running example explain algorithm. structured output prediction mentioned sec. assume structured output consists several sub-components. given test instance input inference problem scoring function based model learned training data. structured output scoring function decomposed small components based independence assumption. example vsrl task output consists types binary output variables {yv} {yvr}. variable activity chosen. similarly activity semantic role assigned scoring function decomposed accordingly that visual semantic role labeling dataset evaluate imsitu activity classes drawn verbs roles framenet noun categories drawn wordnet original dataset includes images training developing test. however dataset covers many non-human oriented activities ﬁlter verbs resulting verbs leaving roughly original images dataset. model build baseline released data shown effective compared non-structured prediction baseline model decomposes probability realized situation combination activity realized frame semantic pairs given image parameters afﬁne transformation layer. model explicitly captures correlation activities nouns semantic roles allowing learn common priors. model pretrained original task verbs. multilabel classiﬁcation dataset ms-coco common object detection benchmark multilabel object classiﬁcation. dataset contains object types make gender distinctions woman. associated image captions available image dataset annotate gender people integer linear program solve using offthe-shelf solver however involves test instances. solving constrained optimization problem scale difﬁcult. therefore consider relaxing constraints solve using lagrangian relaxation technique introduce lagrangian multiplier corpus-level constraint. lagrangian learning rate updating note ﬁxed solved using original inference algorithms. algorithm loops constraints satisﬁed reach maximal number iterations. section provide details visual recognition tasks evaluated bias visual semantic role labeling multi-label classiﬁcation focus gender deﬁning {man woman} focus agent imsitu gender biased figure along x-axis show male favoring bias imsitu verbs. overall dataset heavily biased toward male agents verbs favoring male agent average bias nearly half verbs extremely biased male female direction verbs favor gender bias least figure contains several activity labels revealing problematic biases. example shopping microwaving washing biased toward female agent. furthermore several verbs driving shooting coaching heavily biased toward male agent. training imsitu ampliﬁes bias figure along y-axis show ratio male agents predictions unseen development set. mean bias ampliﬁcation development high average verbs exhibiting ampliﬁcation. biased verbs tend stronger ampliﬁcation verbs training bias either male female direction mean ampliﬁcation several already problematic biases gotten much worse. example serving small bias toward females training heavily biased toward females verb tuning originally heavily biased toward males exclusively male agents. ms-coco gender biased figure along x-axis similarly imsitu analyze bias objects ms-coco respect males. ms-coco even heavily biased toward imsitu objects biased toward smaller average magnitude third nouns extremely biased toward males nouns favor bias least problematic examples include kitchen objects knife fork spoon biased toward woman. outdoor recreation related objects tennis racket snowboard boat tend biased toward men. images. captions mention word woman mark removing images mention genders. finally ﬁlter object category strongly associated humans removing objects occur woman least times training leaving total objects. model multi-label setting adapt similar model structured vsrl. decompose joint probability output consisting object categories gender person given image algorithm sec. calibrate predictions using model calibration tries enforce gender statistics derived training corpus applicable recognition problem. experiments match gender ratios test within margin value training set. adjust output test never ground truth test instead working assumption similarly distributed training set. running debiasing algorithm optimize iterations. figure gender bias analysis imsitu vsrl ms-coco mlc. gender bias verbs toward training versus bias predicted development set. gender bias nouns toward training versus bias predicted development set. values near zero indicate bias toward woman values near indicate unbiased variables. across dataset signiﬁcant bias toward males signiﬁcant bias ampliﬁcation training biased training data. training ms-coco ampliﬁes bias figure along y-axis show ratio predictions unseen development set. mean bias ampliﬁcation across objects nouns exhibiting ampliﬁcation. larger training bias tended indicate higher bias ampliﬁcation biased objects training bias mean ampliﬁcation again several problematic biases ampliﬁed. example kitchen categories already biased toward females knife fork spoon ampliﬁed. technology oriented categories initially biased toward keyboard mouse increased bias toward males discussion conﬁrmed hypothesis imsitu ms-coco datasets gathered heavily gender biased models trained perform prediction datasets amplify existing gender bias evaluated development data. furthermore across datasets showed degree bias ampliﬁcation related size initial bias highly biased object verb categories exhibiting bias ampliﬁcation. results demonstrate care needs taken deploying uncalibrated systems otherwise could reinforce existing social bias actually make worse. test methods reducing bias ampliﬁcation problem settings visual semantic role labeling imsitu dataset multilabel image classiﬁcation ms-coco settings derive corpus constraints using training calibration method batch either development testing set. results summarized table figure visual semantic role labeling quantitative results summarized ﬁrst sections table development number verbs whose bias exceed original bias decreases overall able signiﬁcantly reduce bias ampliﬁcation vsrl development evaluate underlying recognition performance using standard measure vsrl top- semantic role accuracy tests often correct verb predicted noun value correctly assigned semantic role. calibration method results negligible decrease performance figure overall distance training distribution applying decreased signiﬁcantly figure demonstrates across initial training bias able reduce bias ampliﬁcation. general struggles remove bias ampliﬁcation areas initial training bias figure results reducing bias ampliﬁcation using imsitu vsrl ms-coco mlc. figures show initial training bias along x-axis development bias along yaxis. dotted blue lines indicate margin used points violating margin shown points meeting margin shown green. across settings adding signiﬁcantly reduces number violations reduces bias ampliﬁcation signiﬁcantly. figures demonstrate bias ampliﬁcation function training bias without rba. across initial training biases able reduce bias ampliﬁcation. table number violated constraints mean ampliﬁed bias test performance after calibration using rba. test performances vsrl measured top- semantic role accuracy top- mean average precision respectively. likely bias encoded image statistics cannot removed effectively image agnostic adjustment. results test support development results decrease bias ampliﬁcation multilabel classiﬁcation quantitative results ms-coco summarized last sections table similarly vsrl able reduce number objects whose bias exceeds original training bias bias ampliﬁcation reduced development underlying recognition system evaluated standard measure mean average precision precision averaged across object categories. calibration method results negligible loss performance. figure demonstrate substantially reduce distance training bias bias development set. finally figure demonstrate decrease bias ampliﬁcation initial training bias settings. results test support development results decrease bias ampliﬁcation structured prediction models leverage correlations allow make correct predictions even little underlying evidence. models risk potentially leveraging social bias training data. paper presented general framework visualizing quantifying biases models proposed calibrate predictions different settings. taking gender bias example analysis demonstrates conditional random ﬁelds amplify social bias data approach help reduce bias. work ﬁrst demonstrate structured prediction models amplify bias ﬁrst propose methods reducing effect signiﬁcant avenues future work remain. applied structured predictor unclear whether different predictors amplify bias less. furthermore presented method measuring bias. extensive analysis could explore interaction among predictor bias measurement bias deampliﬁcation method. future work also includes applying bias reducing methods structured domains pronoun reference resolution references stanislaw antol aishwarya agrawal jiasen margaret mitchell dhruv batra lawrence zitnick devi parikh. visual question answering. proceedings ieee international conference computer vision pages kai-wei chang sundararajan sathiya keerthi. tractable semi-supervised learning procomplex structured prediction models. ceedings european conference machine learning pages xinlei chen fang tsung-yi ramakrishna vedantam saurabh gupta piotr doll´ar lawrence zitnick. microsoft coco captions data collection evaluation server. arxiv preprint arxiv.. cynthia dwork moritz hardt toniann pitassi omer fairness reingold richard zemel. proceedings inawareness. novations theoretical computer science conference pages acm. michael feldman sorelle friedler john moeller carlos scheidegger suresh venkatasubramanian. certifying removing disparate improceedings international conference pact. knowledge discovery data mining pages matthew cynthia matuszek sean munson. unequal representation gender stereotypes image search results occupations. human factors computing systems pages acm. tsung-yi michael maire serge belongie james hays pietro perona deva ramanan piotr doll´ar lawrence zitnick. microsoft coco european confercommon objects context. ence computer vision pages springer. ishan misra lawrence zitnick margaret mitchell ross girshick. seeing human reporting bias visual classiﬁers noisy humanconference computer vision centric labels. pattern recognition pages nanyun peng ryan cotterell jason eisner. dual decomposition inference graphical models strings. conference empirical methods natural language processing pages john podesta penny pritzker ernest moniz john holdren jefrey zients. data seizing opportunities preserving values. executive ofﬁce president. alexander rush michael collins. tutorial dual decomposition lagrangian relaxation inference natural language processing. journal artiﬁcial intelligence research oriol vinyals alexander toshev samy bengio dumitru erhan. show tell neural image caption generator. proceedings ieee conference computer vision pattern recognition pages mark yatskar vicente ordonez luke zettlemoyer farhadi. commonly uncommon semantic sparsity situation recognition. proceedings ieee conference computer vision pattern recognition mark yatskar luke zettlemoyer farhadi. situation recognition visual semantic role labeling image understanding. proceedings ieee conference computer vision pattern recognition pages", "year": 2017}