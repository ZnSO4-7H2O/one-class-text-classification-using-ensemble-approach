{"title": "DP-EM: Differentially Private Expectation Maximization", "tag": ["cs.LG", "cs.AI", "cs.CR", "stat.ME", "stat.ML"], "abstract": "The iterative nature of the expectation maximization (EM) algorithm presents a challenge for privacy-preserving estimation, as each iteration increases the amount of noise needed. We propose a practical private EM algorithm that overcomes this challenge using two innovations: (1) a novel moment perturbation formulation for differentially private EM (DP-EM), and (2) the use of two recently developed composition methods to bound the privacy \"cost\" of multiple EM iterations: the moments accountant (MA) and zero-mean concentrated differential privacy (zCDP). Both MA and zCDP bound the moment generating function of the privacy loss random variable and achieve a refined tail bound, which effectively decrease the amount of additive noise. We present empirical results showing the benefits of our approach, as well as similar performance between these two composition methods in the DP-EM setting for Gaussian mixture models. Our approach can be readily extended to many iterative learning algorithms, opening up various exciting future directions.", "text": "iterative nature expectation maximization algorithm presents challenge privacy-preserving estimation iteration increases amount noise needed. propose practical private algorithm overcomes challenge using innovations novel moment perturbation formulation diﬀerentially private recently developed composition methods bound privacy cost multiple iterations moments accountant zero-mean concentrated diﬀerential privacy zcdp bound moment generating function privacy loss random variable achieve reﬁned tail bound eﬀectively decrease amount additive noise. present empirical results showing beneﬁts approach well similar performance between composition methods dp-em setting gaussian mixture models. approach readily extended many iterative learning algorithms opening various exciting future directions. data aspects daily lives behavioural health ﬁnancial data increasingly collected stored analyzed corporations government agencies dire need developing machine learning tools analyze data still guaranteeing privacy individuals. much progress made recently developing privacy-preserving methods diﬀerential pripaper derive diﬀerentially private variants expectation maximization algorithm widely used solve statistical problems many areas science including bioinformatics neuroscience computer vision expectation maximization iteratively estimates parameters models unobserved variables. present general privacy-preserving algorithm used model complete-data likelihood exponential family. apply algorithm mixture gaussians density estimation model factor analysis model. access private density estimator particularly valuable provides means anonymize data principled simply sampling dataset model replacing original data sampled data. since diﬀerentially private machine learning algorithms usually achieve privacy adding noise perturb output algorithm intermediate stages main challenge developing privacypreserving algorithms controlling associated loss statistical eﬃciency utility sample. problem particularly exacerbated iterative algorithms example recent work k-means algorithm variant mixture gaussians requires adding noise parameters noise standard deviation order input dimension times number iterations necessitate early termination. avoid this recent work proposes apply standard k-means clustering algorithm privatized synopsis data synopsis generation method consists putting rectangular bounding boxes data space counting many data points box. however method applies mainly clustering task low-dimensional data. instead propose resolve privacy-utility dilemma using innovations private formulation based moment perturbation sensible privacy budget iteration recently proposed composition methods improve privacy cost across many iterations. moment perturbation approach applicable model complete-data likelihood exponential family. cases parameters functions moments latent observed variables perturb privacy. moment perturbation diﬀerentially private estimators concept however unlike require subsampling data. furthermore algorithm calculates cumulative privacy cost using reﬁned composition methods moments accountant zcdp. moments accountant bounds moments privacy loss random variable. inspired zcdp formulates moments privacy loss random variable terms r´enyi divergence output distributions obtained running algorithm datasets diﬀer value single individual. cases moments bound yields tighter tail bound consequently given total privacy budget allows higher per-iteration budget standard methods. experimental results show combining moment perturbation formulation privacy-preserving reﬁned composition methods obtain practical eﬀective algorithm privately estimating parameters latent variable models. start reviewing diﬀerential privacy moments accountant sec. sec. introduce general dp-em framework. derive dp-em algorithm mixture gaussians sec. sec. construct zcdp formulation mogs. sec. provide dp-em algorithm factor analysis illustrate eﬀectiveness algorithms sec. section provide background information deﬁnitions algorithmic privacy zcdp formulations provide reﬁned privacy analysis well general algorithm. change much single individual’s data modiﬁed thereby limiting amount information algorithm reveals individual. approximate version deﬁned hold concentrated diﬀerential privacy. concentrated diﬀerential privacy recently proposed relaxation diﬀerential privacy aims make privacy-preserving iterative algorithms practical still providing strong privacy guarantees. variants cdp. first mcdp subtracted mean subgaussian standard deviation e−µ)] second -zcdp arises connection moment generating function r´enyi divergence distributions require α-r´enyi divergence denoted dα)||p r))). observe case also subgaussian zero-mean. zcdp composition straightfoward since r´enyi divergence product distributions simply r´enyi divergences marginals. zcdp rather mcdp since many approximate mechanisms characterised terms zcdp terms mcdp without large loss privacy parameters. correspondence allow zcdp tool analyzing composition privacy deﬁnition fair comparison analyses. λ-th moment composes linearly yields composability theorem immediate result composibility theorem upper bound upper bound total moment compositions although straightforward derive closedform expression parameter update dependence parameters easy parameter update depends expected suﬃcient statistics i.e. moments denoted tized parameters need perturb moments compensate single data point’s change. sensitivity expected suﬃcient statistics given existing works among many others) also assume datasets pre-processed norm less meaning stays within unit ball. furthermore assume bounded support denoted |tl|. using assumptions sensitivity given max∈ sensitivity noise moment perturbed moments mapped model-speciﬁc deterministic function vector privatized parammakes second term zero free energy equals likelihood. then m-step maximum likelihood estimate maximum posteriori estimate prior parameters right hand side algorithm frequently used models whose joint distribution observed unobserved variables remains exponential family expt marginal not. case free energy rewritten figure abortion dataset provides per-marital-status abortion rates occurred state baden-w¨urttemberg well state individual came from. lack exact location simulated data points based abortion rate state notice person originally state north rhine-westphalia falls ‘married’ category. hence person’s information completely revealed mean parameter runs conventional algorithm. given data points privatizing mean variance parameters illustrated sec. married person’s information easily inferrable. times datapoints privatized parameters closer given conventional algorithm. however mean parameter married category provides aggregated information several people makes hard infer individual information. moving next section would like motivate important construct privacy preserving algorithm mog. fig. show runs algorithm given dataset individual’s information easily revealed looking parameters noised-up parameters obtained method described next protect private information eﬀectively. plug responsibilities given parameter update expressions given perturb taking account datapoint’s worst-case diﬀerence neighboring datasets. denote privacy budget allocated iteration. ﬁrst pre-processed data scaling magnitude maximum norm data points added noise parameter following derivations sec. visualisation results back original latitude/longtitude space. point represent membership gaussian datapoint belongs e.g. distribution distribution given joint distribution observed unobserved variables exponential family given zik]. estep compute responsibilities δzik=kq \u0001i-dp mixing coeﬃcients. neighbouring datasets single data point diﬀerence maximum diﬀerence occurs data point assigned k-th gaussian altered data point assigned another e.g. k-th gaussian hence following sensitivity perturbed covariance might positive deﬁnite. case project negative eigenvalues value near zero maintain positive deﬁniteness covariance matrix. combinations perturbations. among possible combinations parameter perturbation mechanisms focus scenarios. scenario uses \u0001i-dp laplace mechanism perturbing mixing coeﬃcients mean parameters gaussian mechanism perturbing covariance parameters since gaussians iterations compositions \u0001i-dp mechanism compositions mechanisms total scenario. scenario uses gaussian mechanism perturbing parameters. iterations compositions mechanism total scenario. describing method ﬁrst describe baseline methods. first linear composition privacy degrades linearly number iterations. result divergence privacy loss random variable bounded total budget. hence linear composition yields jkδi)-dp scenario jδi)-dp scenario ggg. second advanced composition satisﬁes \u0001i-dp satisﬁes -zcdp; proposition gaussian mechanism satisﬁes ∆/-zcdp sensitivity; lemma mechanisms satisfy ρzcdp ρ-zcdp respectively composition satisﬁes -zcdp; proposition moments accountant composition using ﬁrst step identify form privacy loss random variable λ-th moment mechanism use. \u0001i-dp laplace mechanism following form conjugacy posterior also gaussian ﬁrst second moments given ψ−xi zizi expected suﬃcient statistics become function data moment matrix denoted convergence extra privacy cost. therefore unlike mogs requires perturbing data second moment matrix privacy preservation. iterations post-processing steps free cumulative diﬀerential privacy loss. stroke dataset used predicting occurrence stroke within year atrial ﬁbrillation diagnosis. used principal components features recorded patients assuming private database given form. divided extracted dataset diﬀerent pairs training test sets reported average test log-likelihood datapoint across independent trials fig. setting overall scenario yielded higher test loglikelihoods scenario focused method experiments. found using zcdp compositions resulted accurate estimates also requiring less privacy budget compared compositions. zcdp performed better small privacy budget performed similarly well larger budget. diﬀerence small searching integer values computational reasons following life science dataset repository dataset contains records consisting principal components chemistry biology experiments following approaches divided dataset diﬀerent pairs training test sets reported average test log-likelihood data point across independent trials fig. experiment focused scenario ggg. using zcdp compositions resulted accurate estimates requiring less privacy budget linear advanced compositions. gowalla dataset contains social network’s users’ check-in locations terms longitude latitude total number data points divided cross-validation sets. performed k-means clustering compared method diﬀerentially private k-means clustering algorithm dplloyd standard lloyd algorithm k-means clustering ﬁrst partitions data clusters point assigned figure stroke dataset. test log-likelihood data point function cumulative privacy loss iterations. data using conventional ﬁrst private algorithm diﬀerent per-iteration privacy budget resulting diﬀerent composition methods order achieve parameters varies cluster nearest centroid updates centroid center data points cluster. summarized dplloyd adds noise updated centroids. speciﬁcally laplace noise added number data points assigned cluster well coordinate data points assigned cluster. hence sensitivity becomes original dplloyd algorithm conventional composition theorem noise distribution follows lapj/\u0001) iterations. also tested dplloyd algorithm zcdp compositions resulted better performance terms normalized intra-cluster variance across test sets. algorithm k-means clustering also perturbs centroids adding laplace noise zcdp composition sensitivity mean locations given algorithms. shown fig. method achieves smaller nicv dplloyd even small value olivetti faces dataset used illustrate private factor analysis method. dataset consists diﬀerent images distinct subjects image resulting features pixel ﬂoating point value interval image treated datapoint rather subject though could readily done group privacy lafigure k-means clustering. visualisation clustering results total privacy budget tolerance center locations depicted gray cross. numbers parenthesis normalised intra-cluster variance values obtained method. left dplloyd algorithm linear composition performed poorly relatively high level additive noise. middle dplloyd zcdp composition performed better original version. right algorithm achieves smaller nicv variants dplloyd given privacy budget. tent dimension tested non-private dpem showed column estimated loading matrix fig. components noisy components’ faces nearly recognizable non-private algorithm thereby accurately recovering typical faces dataset. developed practical algorithm outputs accurate privatized parameters based moment perturbation zcdp composition analyses eﬀectively decrease amount additive noise expected privacy guarantee compared standard analysis. illustrated eﬀectiveness algorithm four datasets. based results recommend zcdp composition analysis since performed better regimes easier compute. furthermore found combination performed private algorithms mixture gaussians factor analysis models discussed paper clearly examples much broader class models private framework applies. positive empirical results strongly suggest ideas likely beneﬁcial privatizing many iterative machine learning algorithms. future work plan apply general framework inference methods. broader vision practical privacy preserving machine learning algorithms increasingly relevant role play ﬁeld. foulds geumlek welling chaudhuri. theory practice privacy-preserving bayesian data analysis. proceedings conference uncertainty artiﬁcial intelligence daniel kifer adam smith abhradeep thakurta shie mannor nathan srebro robert williamson. private convex empirical risk minimization highdimensional regression. colt pages cynthia dwork kunal talwar abhradeep thakurta zhang. analyze gauss optimal bounds privacy-preserving principal component analysis. symposium theory computing stoc york june pages benjamin letham cynthia rudin tyler mccormick david madigan. interpretable classiﬁers using rules bayesian analysis building better stroke prediction model. department statistics technical report university washington prashanth mohan abhradeep thakurta elaine dawn song david culler. gupt privacy preserving data analysis made easy. sel¸cuk candan chen richard snodgrass luis gravano ariel fuxman editors sigmod conference pages figure life science dataset test log-likelihood data point function cumulative privacy loss iterations. data using conventional ﬁrst dp-em algorithm diﬀerent per-iteration privacy budget resulting diﬀerent composition methods order achieve parameters varies ﬁxed ﬁxed", "year": 2016}