{"title": "Shuffle and Learn: Unsupervised Learning using Temporal Order  Verification", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "In this paper, we present an approach for learning a visual representation from the raw spatiotemporal signals in videos. Our representation is learned without supervision from semantic labels. We formulate our method as an unsupervised sequential verification task, i.e., we determine whether a sequence of frames from a video is in the correct temporal order. With this simple task and no semantic labels, we learn a powerful visual representation using a Convolutional Neural Network (CNN). The representation contains complementary information to that learned from supervised image datasets like ImageNet. Qualitative results show that our method captures information that is temporally varying, such as human pose. When used as pre-training for action recognition, our method gives significant gains over learning without external data on benchmark datasets like UCF101 and HMDB51. To demonstrate its sensitivity to human pose, we show results for pose estimation on the FLIC and MPII datasets that are competitive, or better than approaches using significantly more supervision. Our method can be combined with supervised representations to provide an additional boost in accuracy.", "text": "abstract. paper present approach learning visual representation spatiotemporal signals videos. representation learned without supervision semantic labels. formulate method unsupervised sequential veriﬁcation task i.e. determine whether sequence frames video correct temporal order. simple task semantic labels learn powerful visual representation using convolutional neural network representation contains complementary information learned supervised image datasets like imagenet. qualitative results show method captures information temporally varying human pose. used pre-training action recognition method gives signiﬁcant gains learning without external data benchmark datasets like hmdb. demonstrate sensitivity human pose show results pose estimation flic mpii datasets competitive better approaches using signiﬁcantly supervision. method combined supervised representations provide additional boost accuracy. sequential data provides abundant source information form auditory visual percepts. learning observation sequential data natural implicit process humans informs level cognitive tasks high level abilities like decision making problem solving instance answering question where would moving ball requires development basic cognitive abilities like prediction sequential data like video paper explore power spatiotemporal signals i.e. videos context computer vision. study information available video signal isolation question agent learn spatiotemporal structure present video without using supervised semantic labels? representations learned using unsupervised spatiotemporal information present videos meaningful? ﬁnally representations complementary learned strongly supervised image data? paper explore questions using sequential learning approach. sequential learning used variety areas speech recognition robotic path planning adaptive control algorithms etc. approaches broadly categorized classes prediction veriﬁcation. sequential prediction goal predict signal given input sequence. popular application natural language processing ‘wordvec’ mikolov learns distributional representations using continuous bag-of-words task model learns predict missing word given sequence surrounding words. representation results task shown semantically meaningful unfortunately extending technique predict video frames challenging. unlike words represented using limited-sized vocabularies space possible video frames extremely large predicting pixels small image leads hypotheses avoid complex task predicting high-dimensional video frames sequential veriﬁcation. sequential veriﬁcation predicts ‘validity’ sequence rather individual items sequence. paper explore task determining whether given sequence ‘temporally valid’ i.e. whether sequence video frames correct temporal order figure demonstrate binary classiﬁcation problem capable learning useful visual representations videos. speciﬁcally explore well understood tasks human action recognition pose estimation. simple sequential veriﬁcation tasks useful learning? determining validity sequence requires reasoning object transformations relative locations time. turn forces representation capture object appearances deformations. convolutional neural network underlying feature representation. applied frame sequence trained end-to-end random initialization. sequence veriﬁcation task encourages features visually temporally grounded. demonstrate eﬀectiveness unsupervised method benchmark action recognition datasets hmdb flic mpii pose estimation datasets. using simple unsupervised learning approach pre-training show signiﬁcant boost accuracy learning cnns scratch random initialization. fact unsupervised approach even outperforms pre-training supervised training datasets. action recognition improved performance found combining existing supervised image-based representations unsupervised representation. training action videos humans approach learns representation sensitive human pose. remarkably applied pose estimation representation competitive pre-training signiﬁcantly larger supervised training datasets fig. video imposes natural temporal structure visual data. many cases easily verify whether frames correct temporal order simple sequential veriﬁcation task captures important spatiotemporal signals videos. task unsupervised pre-training convolutional neural network examples automatically extracted positive negative tuples used formulate classiﬁcation task cnn. work uses unlabeled video sequences learning representations. since source supervision ‘free’ work viewed form unsupervised learning. unsupervised representation learning single images popular area research computer vision. signiﬁcant body unsupervised learning literature uses hand-crafted features clustering based approaches discover objects mid-level elements deep learning methods like autoencoders deep boltzmann machines variational methods stacked auto-encoders others learn representations directly images. methods learn representation estimating latent parameters help reconstruct data regularize learning process priors sparsity techniques scale unsupervised learning large image datasets showing usefulness tasks pedestrian detection object detection terms using ‘context’ learning work similar uses spatial context images. approaches unsupervised videos cannot exploit temporal structure them. work related work unsupervised learning videos traditional methods domain utilize spatiotemporal continuity regularization learning process. since visual appearance changes smoothly videos common constraint enforcing temporal smoothness features zhang particular show constraints useful action recognition. moving beyond temporal smoothness enforces additional ‘steadiness’ constraints features change features across frames meaningful. work contrast explicitly impose regularizations features. reconstruction-based learning approaches include goroshin generative model predict video frames srivastava fig. sample tuples frames high motion windows video. form positive negative tuples based whether three input frames correct temporal order. triplet siamese network architecture three parallel network stacks shared weights upto layer. stack takes frame input produces representation layer. concatenated representations used predict whether input tuple correct temporal order. lstms unlike method works explicitly predict individual frames explore large image sizes datasets. also consider task predicting future videos consider task unsupervised pre-training. several recent papers egomotion constraints video constrain learning. jayaraman show learn equivariant transforms constraints. similar work full video frames learning little pre-processing. owens audio signals videos learn visual representations. another line work uses video data mine patches belong object learn representations useful distinguishing objects. typically approaches require signiﬁcant pre-processing create task. work also uses videos explore spirit sequence veriﬁcation action recognition learns video little pre-processing. demonstrate eﬀectiveness unsupervised pre-training using extensively studied vision tasks action recognition pose estimation. tasks well established benchmark datasets beyond scope paper refer reader survey action recognition survey pose estimation. goal learn feature representation using spatiotemporal signal naturally available videos. learn representation using sequential veriﬁcation task focus videos human actions. speciﬁcally shown figure extract tuple frames video whether frames correct temporal order. section begin motivating sequential tasks temporal structure videos. describe positive negative tuples sampled videos describe model. using videos input sequential veriﬁcation tasks oﬀer promising approach unsupervised learning. addition approach described below several alternative tasks explored section goal tasks encourage model reason motion appearance objects thus learn temporal structure videos. example tasks include reasoning ordering frames determining relative temporal proximity frames. tasks veriﬁcation temporal order many frames needed determine correct answer? want determine correct order frames question ambiguous cases cyclical motion present. example consider short video sequence person picking coﬀee cup. given frames temporal order ambiguous; person picking coﬀee placing down. reduce ambiguity propose sampling three frame tuple whether tuple’s frames correctly ordered. theoretically three frames suﬃcient resolve cyclical ambiguity found combining smart sampling removes signiﬁcant portion ambiguous cases. formalize problem classiﬁcation task. concritical challenge training network three-tuple ordering task sample positive negative training instances. naive method sample tuples uniformly video. however temporal windows little motion hard distinguish positive negative tuple resulting many ambiguous training examples. instead sample tuples temporal windows high motion. figure shows coarse frame level optical proxy measure motion frames. treat average magnitude per-frame weight frame bias sampling towards high motion windows. ensures classiﬁcation tuples ambiguous. figure shows examples tuples. create positive negative tuples sample frames temporal window positive instances created using negative instances created using additional training examples also created inverting order training instances positive. training critical beginning frame ending frame changing middle frame positive negative examples. since middle frame changes training examples network encouraged focus signal learn subtle diﬀerence positives negatives rather irrelevant features. avoid sampling ambiguous negative frames enforce appearance positive frame similar simple conditions eliminated ambiguous examples. provide analysis sampling data section learn feature representation tuple ordering task simple triplet siamese network. network three parallel stacks layers shared parameters every network stack follows standard caﬀenet architecture conv layer. stack takes input frames tuple produces representation layer. three outputs concatenated input linear classiﬁcation layer. classiﬁcation layer reason three frames predict whether order since layers conv shared across network stacks siamese architecture number parameters alexnet barring ﬁnal layer. update parameters network minimizing regularized cross-entropy loss predictions tuple. network takes three inputs training time testing obtain conv representations single input frame using stack parameters across three stacks shared. section present experiments analyze various design decisions training network. sections provide results action recognition pose estimation. dataset report results using split benchmark category label. standard performance metric action recognition dataset classiﬁcation accuracy. details unsupervised pre-training unsupervised pre-training semantic action labels. sample tuples table study eﬀect design choices temporal sampling parameters varying class ratios unsupervised pre-training. measure tuple prediction accuracy held ucf. also show action classiﬁcation results ﬁnetuning models action recognition task training videos. randomly initialize network train iterations ﬁxed learning rate mini-batch size tuples. tuple consists frames. using frames tuple show signiﬁcant improvement. batch normalization details action recognition spatial network wellestablished method action recognition uses appearance information. parameters spatial network initialized unsupervised pre-trained network. provided action labels video follow training testing protocol suggested brieﬂy training form mini-batches sampling random frames videos. test time frames uniformly sampled video. frame used generate caﬀenet architecture speed eﬃciency. initialize network parameters layer using parameters unsupervised pretrained network initialize layer action recognition task. ﬁnetune network following iterations batch size learning rate decaying iterations using momentum dropout used wider vggm- architecture found parameters transfer caﬀenet similarities architectures. ‘diﬃculty’ positives high value makes diﬃcult correspondence across positive tuple value gives almost identical frames thus easy positives. similarly compute minimum distance between frames used negative tuples frames fig. compute nearest neighbors using features dataset. compare results across three networks pre-trained imagenet pre-trained unsupervised task randomly initialized network. choose input query frame clip retrieve results clips dataset. since dataset contains multiple clips video near duplicate retrievals remove duplicates display results second row. imagenet focuses high level semantics network captures human pose. compute training testing accuracy networks tuple prediction task held videos. held union samples using temporal sampling parameters. show results table also networks ﬁnetuning action recognition task. results show tuple prediction accuracy performance action recognition task correlated. large temporal window positive sampling improves smaller temporal window large window negative sampling hurts performance another important factor training model class ratios mini-batch. observed empirically good class ratio mini-batch ensures model overﬁt particular class helps learning process. experiments choose single temporal window sampling vary ratio positive negative tuples mini-batch. compare accuracy networks tuple prediction task held videos table additionally report accuracy networks ﬁnetuning action recognition task. results show class ratio used unsupervised pre-training signiﬁcantly impact learning. important larger percentage negative examples. nearest neighbor retrieval retrieve nearest neighbors using unsupervised features dataset compare figure retrievals pre-trained imagenet features randomly initialized network. additional examples shown supplementary materials. pick input query frame clip retrieve neighbors clips dataset. since dataset clips video ﬁrst retrievals near duplicates informative remove near-duplicates computing squared distances frames display results second query. results make things clear imagenet pre-trained network focuses scene semantics unsupervised pre-trained network focuses pose person. would seem indicate information captured unsupervised pre-training complementary imagenet. behavior surprising consider network trained without semantic labels must reason spatiotemporal signals tuple veriﬁcation task. visualizing pool unit responses analyze feature representation unsupervised network trained using tuple prediction task ucf. following procedure show regions pool units alongwith receptive ﬁeld figure gives insight network’s internal feature representation shows many units show preference human body parts pose. surprising given network trained videos human action recognition must reason human movements tuple ordering task. previous experiments show unsupervised task learns meaningful representation. section compare unsupervised method existing baseline methods present quantitative results. organize experiments follows comparing unsupervised method learning random initialization. exploring unsupervised baselines comparing method them. combining unsupervised representation learning method supervised image representation. additional experiments supplementary material. describe common experimental setup. datasets evaluation dataset also used ablation analysis section measure accuracy fig. display image regions unit pool layer. follow method display receptive ﬁelds units. network trained human action recognition videos many units show preference human body parts pose. action classiﬁcation task. additionally hmdb dataset action recognition. dataset contains splits train/test videos train videos testing. video belongs action categories performance evaluated measuring classiﬁcation accuracy. follow train/test protocols hmdb implementation details pre-training tuples sampled using τmax τmin described section class ratio positive examples mini-batch parameters training/ﬁnetuning kept unchanged section action recognition details section caﬀenet architecture parameters training scratch ﬁnetuning. described ﬁnetuning parameters section training random initialization train iterations initial learning rate decaying factor steps training experiments study advantage unsupervised pre-training action recognition comparison learning without pre-training. tuple prediction task train network starting random initialization train split ucf. unsupervised pre-trained network ﬁnetuned hmdb datasets action recognition compared learning scratch report performance table unsupervised pre-training shows dramatic improvement training scratch signiﬁcant gain hmdb. impressive gain demonstrates informativeness unsupervised tuple veriﬁcation task. hmdb additionally ﬁnetune network trained scratch report performance table indicated ‘ucf supervised’. network performs worse unsupervised pre-trained network. hmdb action classes common hypothesize poor performance scratch network unable generalize actions hmdb. reference model pre-trained supervised imagenet dataset ﬁnetuned gives accuracy imagenet ﬁnetuned hmdb gives accuracy section enumerate variety alternative veriﬁcation tasks video frames temporal ordering. task similar frame sampling procedure described section compare performance ﬁnetuning task action recognition. informative task serve better task pre-training. close task frames considered temporally close ﬁxed temporal window video. drlim equation shows method enforces temporal smoothness learned features minimizing distance representations nearby frames requiring frames close separated margin samples ‘two close’ baseline tempcoh similar drlim method temporal coherence learns representations video using distance pairs frames rather distance drlim. obj. patch publicly available model unsupervised pre-trained videos objects. patch-mining code available unsupervised pre-training model. methods pre-trained training split without action labels ﬁnetuned test split actions hmdb actions. compare table scratch performance test split hmdb respectively. tuple veriﬁcation task outperforms sequential ordering tasks standard baselines signiﬁcant margin. attribute number fact focus object detection diﬀerent videos thus perform well action recognition. thus seen unsupervised pre-training gives signiﬁcant performance boost training random initialization. pre-training help improve existing image representations. speciﬁcally initialize model using weights imagenet pre-trained model table results using unsupervised pre-training adapt existing image representations trained imagenet. unsupervised data training split show mean accuracy ﬁnetuning hmdb. tuple-prediction task ﬁnetuning iterations. hypothesize complementary information imagenet representation. test this ﬁnetune model hmdb action recognition task. compare performance ﬁnetuning hmdb withtuple-prediction task. table shows results. results show combining pre-training imagenet helps improve accuracy model finally compare using multiple sources supervised data initialized using imagenet weights ﬁnetuned action recognition ﬁnetuned hmdb accuracy using sources supervised data slightly better performance model demonstrates eﬀectiveness simple powerful unsupervised pre-training. qualitative results suggest network captures information human pose. evaluate quantitatively conduct experiments task pose estimation using keypoint prediction. datasets metrics flic mpii datasets. wrists). compute keypoint head average keypoints eyes nose. evaluate probability correct keypoints measure keypoints. mpii keypoints full body report pckh. metric standard dataset. model training caﬀenet architecture regress keypoints. follow training procedure flic train/test split images respectively ﬁnetune models iterations. mpii train/test split images. batch size methods following setup compare various initializations network. consider supervised initalizations pretraining imagenet ucf. consider three unsupervised initializations tuple based method drlim method also combine unsupervised initialization imagenet pre-training. results pose estimation summarized table unsupervised pre-training method outperforms fully supervised network flic mpii. method also competitive imagenet pre-training datasets. unsupervised pre-training complementary imagenet pre-training improve results combined supports qualitative results show method learn human pose information unsupervised videos. paper studied unsupervised learning spatiotemporal signal videos. proposed method outperforms existing unsupervised methods competitive supervised methods. next step work explore diﬀerent types videos ‘free’ signals optical ﬂow. another direction combination cnns rnns extend tuple veriﬁcation task much longer sequences. believe combining semi-supervised methods promising future direction. acknowledgments authors thank pushmeet kohli ross girshick abhinav shrivastava saurabh gupta helpful discussions. walter timely help systems. work supported part muri army research laboratory program gratefully acknowledge hardware donation nvidia.", "year": 2016}