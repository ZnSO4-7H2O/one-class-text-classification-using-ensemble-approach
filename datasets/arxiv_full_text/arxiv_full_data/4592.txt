{"title": "A Bayesian Multiresolution Independence Test for Continuous Variables", "tag": ["cs.AI", "cs.LG"], "abstract": "In this paper we present a method ofcomputing the posterior probability ofconditional independence of two or morecontinuous variables from data,examined at several resolutions. Ourapproach is motivated by theobservation that the appearance ofcontinuous data varies widely atvarious resolutions, producing verydifferent independence estimatesbetween the variablesinvolved. Therefore, it is difficultto ascertain independence withoutexamining data at several carefullyselected resolutions. In our paper, weaccomplish this using the exactcomputation of the posteriorprobability of independence, calculatedanalytically given a resolution. Ateach examined resolution, we assume amultinomial distribution with Dirichletpriors for the discretized tableparameters, and compute the posteriorusing Bayesian integration. Acrossresolutions, we use a search procedureto approximate the Bayesian integral ofprobability over an exponential numberof possible histograms. Our methodgeneralizes to an arbitrary numbervariables in a straightforward manner.The test is suitable for Bayesiannetwork learning algorithms that useindependence tests to infer the networkstructure, in domains that contain anymix of continuous, ordinal andcategorical variables.", "text": "paper present method comput­ posterior independence ables data examined lutions. observation data varies producing mates fore difficult without eral carefully paper accomplish computation independence resolution. boundary nomial distribution discretized pute posterior tion. across cedure probability possible generalizes straightfor suitable algo­ rithms independence structure domains network tain continuous categorical variables. ments concerning greatly teractions example model effort find ways treating occurring pendence statements cause-effect similarly interaction proportions turing cies help focus attention rele­ manufac­ vant ones different stages turing simply aiding exist number algorithms causal structure domain given con­ ditional principled causal structures prevalent uncertain directed ships among variables quantitative description paper focus integral first part namely developing ditional discovery. discovery however mains latter score-maximization ture induction give guarantees producing correct description contrast constraint-based conditional independen inducing tions visible). proach constraint-based structure tinuous general that continuous probability domain. works eliciting data several probabilistic purpose necessary. case shown figure scatterplots shown together discretiza­ level dence. test potential bayesian situations independent fine resolutions formulation multi-resolution pendent first present ifold domain distribution functions. pendence advantages method conditional method relies resolution section. bution. \"unbiased\" implicit assumptions adjacent ing\"). denote resolution grid boundaries probability fully depen­ dent model class posterior pendence seen effect hyperparameters resent \"virtual table becomes counts ples becomes uniform obviously artificial choice useful dication large support adjusts overly note test applies variables and/or columns marginal however since cell positions changed them. powerful count ordering described \"sweeping\" plane midpoints along andy axes positions posterior uses fraction successive span entire goes resolutions conditional integral runs grid boundaries handled making smallest certain also possesses notably minimizes dependencies nate choice either iterate stop. pseudocode procedure shown figure typical situations binary dependent/independent would compare output independence decide \"inde­ prior probability independence implies probability creases remains examine data increasingly dependence probability non-decreasing. equal­ resolu­ occurs case independence tions. statement also intuitively true imagine example limiting cases single cell case resolution tends infinity ideal scenario infinite data disposal. inde­ pendence probability second unless data truly independent posterior every resolution probability sponding marginals eventually discretization probability combining observation concerning fine resolution mize posterior dependence resolution cern however artificially might unwarranted solution comes choice dirichlet statement non-increasing proba­ bility independence refers boundaries case adding boundaries vari­ able axes. difficult construct amples demonstrated. space present examples here. effect increasing tioning values increase decrease probability independence mensional histogram. respect conditioning directions summary follows olution pendence average aries resolution. plishes instead pendence employing resolutions value approximation bayesian reduces polynomial-order one. figure example data sets ones figure left data dependent. scatterplots data together grid output algorithm point minimum independence. probability grid. dashed horizontal resolutions. rior probability grid becomes strictly sion steps exactly plots show grid produces maximum dependence points note independent posterior four cells. independence data dependent one. housing data average number rooms dwelling median value owner-occupied homes thousands dollars. relation two-dimensional posterior algorithm. probability well-known independence rank correlation linear correlation points along axes latter reduces ranks binary ternary variables tests handle clear monotonic trends multitude approaches norm practice. main issues approaches first assume certain family distributions under­ lying data distribution well. second paper presented probabilistic tional independence continuous proposed posterior probability dependence given data taking account his­ tograms representing resolutions. observing range values quantity take across different resolutions stantially. grating possible boundary plane incorporating lutions. exists space discretizations approximate quantity required estimate exponential data polynomial. solution benefit networks domains contain number con­ tinuous ordinal discrete domains test applied straight­ forward fashion fact employ dis­ cretization. approach representation ditional probability test used purpose. another topic research. even though method polynomial time exponent number test. variables prohibitively expensive large conditioning sets and/or data sets. faster algorithm required situations.", "year": 2013}