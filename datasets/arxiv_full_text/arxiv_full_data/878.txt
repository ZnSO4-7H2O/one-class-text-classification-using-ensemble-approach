{"title": "Enhanced perceptrons using contrastive biclusters", "tag": ["cs.NE", "cs.LG", "stat.ML"], "abstract": "Perceptrons are neuronal devices capable of fully discriminating linearly separable classes. Although straightforward to implement and train, their applicability is usually hindered by non-trivial requirements imposed by real-world classification problems. Therefore, several approaches, such as kernel perceptrons, have been conceived to counteract such difficulties. In this paper, we investigate an enhanced perceptron model based on the notion of contrastive biclusters. From this perspective, a good discriminative bicluster comprises a subset of data instances belonging to one class that show high coherence across a subset of features and high differentiation from nearest instances of the other class under the same features (referred to as its contrastive bicluster). Upon each local subspace associated with a pair of contrastive biclusters a perceptron is trained and the model with highest area under the receiver operating characteristic curve (AUC) value is selected as the final classifier. Experiments conducted on a range of data sets, including those related to a difficult biosignal classification problem, show that the proposed variant can be indeed very useful, prevailing in most of the cases upon standard and kernel perceptrons in terms of accuracy and AUC measures.", "text": "abstract perceptrons neuronal devices capable fully discriminating linearly separable classes. although straightforward implement train applicability usually hindered non-trivial requirements imposed real-world classiﬁcation problems. therefore several approaches kernel perceptrons conceived counteract diﬃculties. paper investigate enhanced perceptron model based notion contrastive biclusters. perspective good discriminative bicluster comprises subset data instances belonging class show high coherence across subset features high diﬀerentiation nearest instances class features upon local subspace associated pair contrastive biclusters perceptron trained model highest area receiver operating characteristic curve value selected ﬁnal classiﬁer. experiments conducted range data sets including related diﬃcult biosignal classiﬁcation problem show proposed variant indeed useful prevailing cases upon standard kernel perceptrons terms accuracy measures. given data matrix composed rows columns bicluster deﬁned submatrix whose elements show high level similarity among themselves. deﬁnition generalizes well-known concept cluster sense instances grouped together considering subsets features vice-versa allowing elicitation contextualized data models since diﬀerent notions similarity bicluster representation adopted diﬀerent bicluster models investigated preceding years giving birth number biclustering algorithms deployed several application domains besides bicluster model biclustering algorithms usually diﬀer strategy adopted recover ﬁnal biclusters. common solution alternating clustering rows columns data allowing traditional clustering algorithms. another strategy employ greedy heuristics iteratively insert remove rows/columns bicluster maximize given objective function. also noteworthy probabilistic approaches seeking generative model underlying biclusters. divide-and-conquer methods especially useful ﬁnding block structure inside data set. hand population-based meta-heuristics also adopted optimizing criterion function promotes balance size bicluster homogeneity elements. finally small medium sized data sets sight constraints overlapping satisﬁed well-known class biclusters based notion coherence whereby values correlate according implicit linear model asset particular bicluster type simultaneously capture different coassociation patterns among instances features matrix generalizing simpler bicluster types. another advantage level coherence revealed given bicluster eﬃciently measured simple similarity function known mean-squared residue score conventional bicluster analyses unsupervised nature meaning class labels possibly associated instances taken account. recently another class algorithms referred discriminative biclustering algorithms gained increased attention methods somehow incorporate class label details process eliciting biclusters produce better predictive models. assuming instance context gene expression data analysis discriminative biclustering used discover sets genes correlated subset experimental conditions pertaining class conditions usually discriminative biclustering methods diﬀer according diﬀerent strategies apply identifying diﬀerential patterns among considered classes. paper propose novel supervised biclustering approach named bicneuron aiming detecting highly discriminative coherent biclusters leveraging accuracy generalization simple linear classiﬁcation models. focus speciﬁcally perceptrons studied classes neuronal devices several variants proposed. among them kernel perceptrons achieved notoriety elegant strategy dealing nonlinearities kernel functions aware ﬁrst study investigating usefulness combining discriminative biclusters simple neural models. nutshell bicneuron seeks subsets training instances belonging classes instances showing high coherence across subsets features also high diﬀerentiation nearest instances opposite class features. procedure yield several local discriminative subspaces captured pairs contrastive biclusters. upon data local subspace perceptron model induced highest value area receiver operating characteristic curve selected ﬁnal model classifying novel test instances. follows outline section theoretical background behind bicneuron whose steps detailed section next discuss results achieved experiments conducted range data sets also including case study diﬃcult biomedical classiﬁcation problem finally section concludes paper brings remarks future work. sequel brieﬂy revise main training steps behind standard kernel perceptrons. then provide account concepts approaches related coherent discriminative biclustering. free parameters deﬁning decision boundary sign otherwise. class prediction correct adjustment required; otherwise added update rule iteration iteration simply written notice initialized null vector latter become simple linear combination training instances αlylxl reconsidering perspective assuming denotes linear/non-linear transformation applied derive kernel-based type perceptron unsupervised approach useful ﬁnding subspaces linearly separable data additive coherence biclustering according approach subset data instances show strong linear coassociation pattern viewed perspective subset features. words instance vector bicluster presents similar proﬁle except constant bias projected onto selected coordinates bicluster. case element submatrix associated bicluster modeled minimization score constrained threshold another validation measure size bicluster often called volume since usually large bicluster modules sought. however good balance coherence volume necessary since tend conﬂictive nature. moreover calibration coherence volume thresholds trivial diﬀerent characteristics data set. huang devised additive coherencebased biclustering algorithm part unsupervised feature ranking approach. interesting property algorithm allows elicitation overlapped biclusters submatrices sharing rows and/or columns. moreover based easy-toapply procedures namely conventional hierarchical clustering instances feature; local search biclusters based operations expansion reﬁnement merging clusters discovered ﬁrst step cast bicluster seeds. besides algorithm hyperparameters calibrated respectively related volume coherence resulting biclusters. role cheng church’s speciﬁes level dendrogram associated feature thus delimits size resulting bicluster seeds. data column normalized standardization procedure sensitivity algorithm’s performance calibration parameters high recently coherence biclustering also adopted source accuracy improvement supervised classiﬁcation objects. example fran¸ca proposed novel algorithms coping multilabel classiﬁcation classiﬁcation noisy labels respectively replacing augmenting feature space elicitation good discriminative biclusters. means novel binary features extracted representing discriminative bicluster classes instances novel instances classiﬁed according match local patterns. means odibat proposed dibiclus algorithm aiming mine diﬀerential biclusters gene expression data labeled according types experimental conditions context gene over-expressed conditions represented positive numbers thus genes regarded positively co-expressed signs subset conditions. biclusters produced dibiclus genes much co-expressed class conditions other diﬀerent types coexpression among classes. notion diﬀerential biclusters also considered work wang proposed eﬃcient algorithm referred decluster. algorithm based construction weighted undirected graph algorithm turn based frequent pattern mining algorithm seeks patterns diﬀerence correlations classes conditions ﬁxed threshold. hand recently odibat reddy proposed novel algorithm referred di-rapocc extract large arbitrarily-positioned biclusters containing positively negatively correlated objects showing inter-class overlap. contrary abovementioned works study focuses speciﬁcally improvements accuracy/generalization discriminative biclusters bring simple classiﬁcation models perceptrons. instead considering bioinformatics problems majority reviewed works assessed potentials bicluster-enhanced perceptrons range classiﬁcation domains. moreover focus classiﬁcation data instances discrimination classes related features importantly algorithm used bicneuron eliciting discriminative biclusters conceptually diﬀerent sense based contrastive data groups coming pairs finally straightforward simple implement contrary approaches di-rapocc involve intricate steps. non-coherent nature manner yield good separation region classes. fact biclusters pair highly coherent associated instances would well aligned other hindering linear discrimination. resulting candidate pairs biclusters ﬁlter really allow considerable contrast classes quantiﬁed proper measure. upon local subspace associated pair good contrastive biclusters perceptron model trained ﬁnal classiﬁer predict label data instances chosen according model selection criterion. uncovering coherent biclusters classes firstly binary training data normalized instances divided subsets according class labels. then biclustering algorithm applied unsupervised manner solely yielding coherent biclusters bicneuron’s perspective high-quality bicluster denotes subset data instances given class shows high coherence across subset features also high separation nearest instances opposite class latter also projected onto feature subset. interpretation entails pair biclusters representing particular data subspace salient contrast classes hence refer groups contrastive biclusters. strategy followed bicneuron ﬁrst induce series coherent biclusters classes artiﬁcially generate biclusters composed instances class become associated former. hopefully artiﬁcially-generated biclusters generating contrastive biclusters bicluster contrastive bicluster artiﬁcially created comprises nearest objects class measured euclidean distances considering features important stress coherent fact less coherent better would contrast pair thus classes. centroid computed bicluster step results contrastive biclusters |bc|. filtering contrastive biclusters pairs contrastive biclusters sorted according levels contrast pairs high discrimination kept. here adopt ranking criterion coherence contrast contrastive biclusters meaning pairs showing high diﬀerentiation between values preferred. fulﬁll criterion ratio measure used which fig. first four steps bicneuron original data nine objects four features labels normalized data showing coherent biclusters ﬁrst class; centroids bicluster; based distances objects second class bicluster centroids contrastive biclusters generated assuming threshold considering ratio pair contrastive biclusters ﬁrst pair regarded good discriminative subspace training ﬁnal perceptron. employed evoke initial coherent biclusters ﬁrst class. however satisfactory properties reviewed section made algorithm conceived huang conducting experiments reported next section. considering training data time complexity huang al.’s algorithm bounded also complexity ﬁrst step bicneuron notice that worst case class number instances. considering time costs entailed operations contrastive biclusters bounded number biclusters delivered ﬁrst step assert time complexity ﬁrst four steps bicneuron limited |b|n time costs last steps depend exogeneous variables related training perceptrons calculation values since operations usually costly number training epochs ﬁxed reasonable value state computational performance bicneuron mostly inﬂuenced biclustering algorithm use. concerns possibility extracting coherent biclusters data second class could principle also pursued. however notice would signiﬁcantly increase time costs whole approach since biclustering algorithm would twice. concerning speciﬁcally size contrastive biclusters generated third step theory value could somehow tuned based characteristics classiﬁcation problem sight. however sake simplicity assumed pair contrastive biclusters denotes coherence value calculated since rmsr never undeﬁned zero perfect coherent bicluster. ranking pairs contrastive biclusters values ratio rmsr being previously ﬁxed threshold kept next step. denote number selected pairs contrastive biclusters sets selected biclusters classes respectively |bs| inducing perceptron models pair data assembled concatenating instances projected onto perceptron model trained results perceptron models {pk} selecting ﬁnal classiﬁer best model selected according given performance measure. here adopt area receiver operating characteristic curve since measure provide unbiased estimate accuracy averaged diﬀerent loss conditions moreover yields good assessment accuracies delivered diﬀerent classes data imbalanced. perceptron highest value calculated whole training returned ﬁnal classiﬁer. hand different criteria measures could adopted fourth sixth steps purpose quantifying contrast biclusters selecting best perceptron model respectively. instance geometrical separation contrastive biclusters could used alternative criterion coherence contrast. case diﬀerent notions margin could adopted measures ranking pairs taking euclidean distance centroids farthest instances. analysis impact alternative criteria/measures accuracy performance bicneuron scope paper. present version bicneuron three control parameters calibrated namely associated biclustering algorithm; threshold used selecting pairs contrastive biclusters. experiments kept ﬁxed suggested huang varied systematically value range conversely assumed values range order capture diﬀerent notions strictness criterion coherence contrast. order assess potentials bicneuron leveraging classiﬁcation performance displayed perceptrons developed prototype python based scikit-learn toolkit conducted extensive series experiments. next subsections give details experimental setup present discuss main results achieved. data assessment realized -fold stratiﬁed cross-validation iterations control parameter values bicneuron also calibrated cross-validation performed solely training partition. standard perceptron kernel perceptron models also trained tested folds bicneuron serve baseline comparison. contrary training performed stochastic gradient descent data shuﬄed epoch. besides linear kernel bias term kernel exp) adopted preliminary experimentation number training epochs whereas adopted value learning rate also value kernel. settings also used perceptron models induced bicneuron. classiﬁer generated best bicneuron conﬁguration cross-validation iteration well results collected following measures overall accuracy accuracy minority class accuracy majority class auc. finally non-parametric wilcoxon test applied separately acc/auc results achieved data order check whether diﬀerence performance classiﬁers signiﬁcant not. tables bring results obtained bicneuron well ﬁrst data sets table ﬁrst tables provide detailed results former focuses accm accm. main goal ﬁrst thirteen binary classiﬁcation data sets publiclyavailable repositories used purpose assessing quality linear subspaces uncovered bicneuron analysis performance associated perceptrons. besides multiclass data related diﬃcult task epilepsy diagnosis based electroencephalogram signal analysis also adopted yielding additional binary classiﬁcation problems. latter data feature extraction performed signals discrete wavelet transform using daubecchies order wavelet function. decision complies previous work subject choice data sets mostly motivated distinct natures structural properties number instances number features class distributions besides duch showed experimentally regarded ‘non-trivial’ simple classiﬁers. data sets comprise real-valued features only restriction imposed biclustering algorithm used. moreover focused data sets missing values moderate/large numbers features since would table results achieved linear classiﬁers binary classiﬁcation data set. performance measured separately test fold cross-validation process well terms average best values. cases highlighted bold performance bicneuron signiﬁcantly better given contestant measured wilcoxon test best average results underlined data set. table results achieved linear classiﬁers binary classiﬁcation data set. performance measured separately test fold cross-validation process well terms average best values. cases highlighted bold performance bicneuron signiﬁcantly better given contestant measured wilcoxon test best average results underlined data set. experiments assess quality discriminative subspaces discovered bicneuron. since employment non-linear transformation subspaces could make assessment diﬃcult unclear refrained adopting kernel bicneuron time. besides sake conciseness show results delivered bicneuron conﬁgured standard perceptrons although important stress cases noticed bicneuron’s performance could improved kernel perceptrons used associated classiﬁers. discussing qualitatively results worth explaining notation used tables regarding application wilcoxon test comparing classiﬁers’ performance since comparing results results delivered bicneuron decided highlight results former latter means notation become overloaded bicneuron time signiﬁcantly better methods signiﬁcantly worse consider instance data twonorm. here average perfortable accuracy results minor major classes achieved classiﬁcation approach binary classiﬁcation data set. performance measured terms average best values. table average results achieved approach discrimination pair classes data set. kprbf denote linear kernels respectively whereas bnrbf stand bicneuron standard perceptrons linear kernel perceptrons non-linear kernel perceptrons respectively. p-values wilcoxon test calculated pairwise reference best approach order assess whether diﬀerence performance statistically signiﬁcant mance bicneuron signiﬁcantly better marked latter value bold. hand average performance bicneuron signiﬁcantly worse marked latter value italics. notice relative performance could deduced relation bicneuron. tables ﬁrst notice three contestant approaches show variability performance across diﬀerent problems data deemed ‘easy’ them. variability mainly fact simple linear classiﬁers usually sensitive underlying characteristics problem sight. however variability three approaches same models usually showing distinct generalization capabilities evidenced fold-by-fold behavior. also noteworthy nine data sets bicneuron delivered better average results plus draw data besides cases bicneuron achieved maximum possible value acc/auc least fold cases wilcoxon test indicates bicneuron signiﬁcantly prevailed respectively. results testify usefulness proposed approach guess resorting biclustering algorithms better performance could achieved cases. hand single problem bicneuron signiﬁcantly outperformed even though case novel approach still much better regard reminded twonorm well ringnorm artiﬁcially conceived breiman studying bias/variance properties single versus aggregate classiﬁers. twonorm optimal separating surface oblique plane ringnorm separating surface sphere. problems considered hard approximate simple classiﬁer models besides amongst problems shown tables twonorm ringnorm ones lowest ratio number features number instances issue impact quality biclusters induced biclustering algorithm. role table reveal emphasis three contestant approaches diﬀerent classes show class distribution imbalance problem aﬀect performance. results thus regarded auxiliary reported tables ﬁrstly notice approaches really vary emphasis classes suggests combining models advanced architectures could useful. overall bicneuron shown balanced treatment explain yielded better average results cases. hand shown high sensitiveness high levels class imbalance although performance also wellbalanced problems finally concerns second computational experiments table brings average results delivered pairs classes data set. time since also aimed assessing eﬀects using non-linear kernel linear subspaces discovered bicneuron included contest model conﬁgured kernel bicneuron variants conﬁgured linear non-linear kernel perceptrons. total models considered analysis. order diﬀerentiate models used notation denoting linear kernel kprbf representing kernel. similar notation used bicneuron namely bnrbf interesting aspect observe experiments results models cases. comparing solely linear classiﬁers prevalence bicneuron models readily noticeable since always produced better values linear kernel. hand considering non-linear models well notice cases bicneuron models enhanced kernel could further improve average performance delivered conﬁgured kernel. remarkable performance achieved discriminating ﬁrst ﬁfth classes second third classes overall results provide evidence contrastive biclusters indeed leverage predictive performance simple models perceptrons coping non-trivial biosignal classiﬁcation problems like paper explored strategy using coherent biclusters means improve levels accuracy generalization exhibited simple linear classiﬁers perceptrons. systematically investigate potentials strategy novel supervised biclustering approach based notion contrastive biclusters formally devised empirically assessed range classiﬁcation problems. overall empirical results achieved show evidence usefulness linear subspaces discovered bicneuron better discriminating classes. possible extension present work adapt bicneuron handle multiclass multilabel data sets straightforward manner. moreover shall analyze tolerant bicneuron classiﬁers noisy data ongoing work currently investigating potentials combining several bicneuron models learning framework. idea better approximate non-linear class boundaries aggregating diﬀerent local discriminative subspaces original data. context diﬀerent ways selecting contrastive biclusters merging outputs trained perceptrons consideration. combinations bicneuron models standard kernel perceptrons also probed complementary proﬁles. finally whole approach could also extended ensemble settings including complex classiﬁers induced subspaces captured contrastive biclusters.", "year": 2016}