{"title": "Semantic Image Segmentation with Deep Convolutional Nets and Fully  Connected CRFs", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Deep Convolutional Neural Networks (DCNNs) have recently shown state of the art performance in high level vision tasks, such as image classification and object detection. This work brings together methods from DCNNs and probabilistic graphical models for addressing the task of pixel-level classification (also called \"semantic image segmentation\"). We show that responses at the final layer of DCNNs are not sufficiently localized for accurate object segmentation. This is due to the very invariance properties that make DCNNs good for high level tasks. We overcome this poor localization property of deep networks by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF). Qualitatively, our \"DeepLab\" system is able to localize segment boundaries at a level of accuracy which is beyond previous methods. Quantitatively, our method sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 71.6% IOU accuracy in the test set. We show how these results can be obtained efficiently: Careful network re-purposing and a novel application of the 'hole' algorithm from the wavelet community allow dense computation of neural net responses at 8 frames per second on a modern GPU.", "text": "deep convolutional neural networks recently shown state performance high level vision tasks image classiﬁcation object detection. work brings together methods dcnns probabilistic graphical models addressing task pixel-level classiﬁcation show responses ﬁnal layer dcnns sufﬁciently localized accurate object segmentation. invariance properties make dcnns good high level tasks. overcome poor localization property deep networks combining responses ﬁnal dcnn layer fully connected conditional random field qualitatively deeplab system able localize segment boundaries level accuracy beyond previous methods. quantitatively method sets state-of-art pascal voc- semantic image segmentation task reaching accuracy test set. show results obtained efﬁciently careful network re-purposing novel application ’hole’ algorithm wavelet community allow dense computation neural responses frames second modern gpu. deep convolutional neural networks method choice document recognition since lecun recently become mainstream high-level vision research. past years dcnns pushed performance computer vision systems soaring heights broad array high-level problems including image classiﬁcation object detection ﬁne-grained categorization among others. common theme works dcnns trained end-to-end manner deliver strikingly better results systems relying carefully engineered representations sift features. success partially attributed built-in invariance dcnns local image transformations underpins ability learn hierarchical abstractions data invariance clearly desirable high-level vision tasks hamper low-level tasks pose estimation semantic segmentation want precise localization rather abstraction spatial details. technical hurdles application dcnns image labeling tasks signal downsampling spatial ‘insensitivity’ ﬁrst problem relates reduction signal resolution incurred repeated combination max-pooling downsampling performed every layer standard dcnns instead papandreou employ ‘atrous’ algorithm originally developed efﬁciently computing undecimated discrete wavelet transform allows efﬁcient dense computation dcnn responses scheme substantially simpler earlier solutions problem second problem relates fact obtaining object-centric decisions classiﬁer requires invariance spatial transformations inherently limiting spatial accuracy dcnn model. boost model’s ability capture details employing fully-connected conditional random field conditional random fields broadly used semantic segmentation combine class scores computed multi-way classiﬁers low-level information captured local interactions pixels edges superpixels even though works increased sophistication proposed model hierarchical dependency and/or high-order dependencies segments fully connected pairwise proposed kr¨ahenb¨uhl koltun efﬁcient computation ability capture edge details also catering long range dependencies. model shown kr¨ahenb¨uhl koltun largely improve performance boosting-based pixel-level classiﬁer work demonstrate leads state-of-the-art results coupled dcnn-based pixel-level classiﬁer. three main advantages deeplab system speed virtue ‘atrous’ algorithm dense dcnn operates mean field inference fully-connected requires second accuracy obtain state-of-the-art results pascal semantic segmentation challenge outperforming second-best approach mostajabi margin simplicity system composed cascade fairly well-established modules dcnns crfs. system works directly pixel representation similarly long contrast two-stage approaches common semantic segmentation dcnns techniques typically cascade bottom-up image segmentation dcnn-based region classiﬁcation makes system commit potential errors front-end segmentation system. instance bounding proposals masked regions delivered used girshick inputs dcnn introduce shape information classiﬁcation process. similarly authors mostajabi rely superpixel representation. celebrated non-dcnn precursor works second order pooling method also assigns labels regions proposals delivered understanding perils committing single segmentation authors cogswell build explore diverse crf-based segmentation proposals computed also segmentation proposals re-ranked according dcnn trained particular reranking task. even though approach explicitly tries handle temperamental nature front-end segmentation algorithm still explicit exmoving towards works closer approach several researchers considered convolutionally computed dcnn features dense image labeling. among ﬁrst farabet apply dcnns multiple image resolutions employ segmentation tree smooth prediction results; recently hariharan propose concatenate computed inter-mediate feature maps within dcnns pixel classiﬁcation propose pool inter-mediate feature maps region proposals. even though works still employ segmentation algorithms decoupled dcnn classiﬁer’s results believe advantageous segmentation used later stage avoiding commitment premature decisions. recently segmentation-free techniques directly apply dcnns whole image sliding window fashion replacing last fully connected layers dcnn convolutional layers. order deal spatial localization issues outlined beginning introduction long upsample concatenate scores inter-mediate feature maps eigen fergus reﬁne prediction result coarse propagating coarse results another dcnn. main difference model state-of-the-art models combination pixel-level crfs dcnn-based ‘unary terms’. focusing closest works direction cogswell crfs proposal mechanism dcnn-based reranking system farabet treat superpixels nodes local pairwise graph-cuts discrete inference; results limited errors superpixel computations ignoring long-range superpixel dependencies. approach instead treats every pixel node exploits long-range dependencies uses inference directly optimize dcnn-driven cost function. note mean ﬁeld extensively studied traditional image segmentation/edge detection tasks e.g. recently kr¨ahenb¨uhl koltun showed inference efﬁcient fully connected particularly effective context semantic segmentation. ﬁrst version manuscript made publicly available came attention groups independently concurrently pursued similar direction combining dcnns densely connected crfs several differences technical aspects respective models. bell focus problem material classiﬁcation zheng unroll mean-ﬁeld inference steps convert whole system end-to-end trainable feed-forward network. herein describe re-purposed ﬁnetuned publicly available imagenetpretrained state-of-art -layer classiﬁcation network efﬁcient effective dense feature extractor dense semantic image segmentation system. dense spatial score evaluation instrumental success dense feature extractor. ﬁrst step implement this convert fully-connected layers vgg- convolutional ones network convolutional fashion image original resolution. however enough yields sparsely computed detection scores compute scores densely target stride pixels develop variation method previously employed giusti sermanet skip subsampling last max-pooling layers network simonyan zisserman modify convolutional ﬁlters layers follow introducing zeros increase length implement efﬁciently keeping ﬁlters intact instead sparsely sample feature maps applied using input stride pixels respectively. approach illustrated fig. known ‘hole algorithm’ developed efﬁcient computation undecimated wavelet transform implemented within caffe framework adding imcol function option sparsely sample underlying feature map. approach generally applicable allows efﬁciently compute dense feature maps target subsampling rate without introducing approximations. ﬁnetune model weights imagenet-pretrained vgg- network adapt image classiﬁcation task straightforward fashion following procedure long replace -way imagenet classiﬁer last layer vgg- -way one. loss function cross-entropy terms spatial position output positions labels equally weighted overall loss function. targets ground truth labels optimize objective function respect weights network layers standard procedure krizhevsky testing need class score maps original image resolution. illustrated figure elaborated section class score maps quite smooth allows simple bilinear interpolation increase resolution factor negligible computational cost. note method long hole algorithm produces coarse scores output. forced learned upsampling layers signiﬁcantly increasing complexity training time system fine-tuning network pascal takes hours report training time several days another ingredient re-purposing network dense score computation explicitly controlling network’s receptive ﬁeld size. recent dcnn-based image recognition methods rely networks pre-trained imagenet large-scale classiﬁcation task. networks typically large receptive ﬁeld size case vgg- consider receptive ﬁeld pixels applied convolutionally. converting network fully convolutional ﬁrst fully connected layer ﬁlters large spatial size becomes computational bottleneck dense score computation. addressed practical problem spatially subsampling ﬁrst layer spatial size. reduced receptive ﬁeld network reduced computation time ﬁrst layer times. using caffe-based implementation titan resulting vgg-derived network efﬁcient given input image produces dense feature scores network rate frames/sec testing. speed training frames/sec. also successfully experimented reducing number channels fully connected layers considerably decreasing computation time memory footprint without sacriﬁcing performance detailed section using smaller networks krizhevsky could allow video-rate test-time dense feature computation even light-weight gpus. illustrated figure dcnn score maps reliably predict presence rough position objects image less well suited pin-pointing exact outline. natural trade-off classiﬁcation accuracy localization accuracy convolutional networks deeper models multiple max-pooling layers proven successful classiﬁcation tasks however increased invariance large receptive ﬁelds make problem inferring position scores output levels challenging. recent work pursued directions address localization challenge. ﬁrst approach harness information multiple layers convolutional network order better estimate object boundaries second approach employ super-pixel representation essentially delegating localization task low-level segmentation method. route followed successful recent method mostajabi section pursue novel alternative direction based coupling recognition capacity dcnns ﬁne-grained localization accuracy fully connected crfs show remarkably successful addressing localization challenge producing accurate semantic segmentation results recovering object boundaries level detail well beyond reach existing methods. figure score belief aeroplane. show score belief maps mean ﬁeld iteration. output last dcnn layer used input mean ﬁeld inference. best viewed color. traditionally conditional random ﬁelds employed smooth noisy segmentation maps typically models contain energy terms couple neighboring nodes favoring same-label assignments spatially proximal pixels. qualitatively primary function short-range crfs clean spurious predictions weak classiﬁers built local hand-engineered features. compared weaker classiﬁers modern dcnn architectures work produce score maps semantic label predictions qualitatively different. illustrated figure score maps typically quite smooth produce homogeneous classiﬁcation results. regime using short-range crfs detrimental goal recover detailed local structure rather smooth using contrast-sensitive potentials upsampled bi-linear interpolation. fully connected applied reﬁne segmentation result. best viewed color. conjunction local-range crfs potentially improve localization still miss thin-structures typically requires solving expensive discrete optimization problem. label assignment pixels. unary potential label assignment probability pixel computed dcnn. pairwise potential zero otherwise pairwise term pair pixels image matter i.e. model’s factor graph fully connected. gaussian kernel depends features extracted pixel weighted parameter adopt bilateral position color terms speciﬁcally kernels ﬁrst kernel depends pixel positions pixel color intensities second kernel depends pixel positions. hyper parameters control scale gaussian kernels. crucially model amenable efﬁcient approximate probabilistic inference message passing updates fully decomposable mean ﬁeld approximabi expressed convolutions gaussian kernel feature space. high-dimensional ﬁltering algorithms signiﬁcantly speed-up computation resulting algorithm fast practice less average pascal images using publicly available implementation following promising recent results also explored multi-scale prediction method increase boundary localization accuracy. specifically attach input image output ﬁrst four pooling layers two-layer whose feature concatenated main network’s last layer feature map. aggregate feature softmax layer thus enhanced channels. adjust newly added weights keeping network parameters values learned method section discussed experimental section introducing extra direct connections ﬁne-resolution layers improves localization performance effect dramatic obtained fully-connected crf. method deeplab deeplab-crf deeplab-msc deeplab-msc-crf deeplab-x deeplab-crf-x deeplab-largefov deeplab-crf-largefov deeplab-msc-largefov deeplab-msc-crf-largefov table performance proposed models pascal ‘val’ best performance achieved exploiting multi-scale features large ﬁeld-of-view. performance proposed models compared state-of-art methods pascal ‘test’ set. dataset test deeplab model pascal segmentation benchmark consisting foreground object classes background class. original dataset contains images training validation testing respectively. dataset augmented extra annotations provided hariharan resulting training images. performance measured terms pixel intersectionover-union averaged across classes. dcnn training employ vgg- network pre-trained imagenet. ﬁne-tuned vgg- network -way pixel-classiﬁcation task stochastic gradient descent cross-entropy loss function described section mini-batch images initial learning rate multiplying learning rate every iterations. momentum weight decay dcnn ﬁne-tuned cross-validate parameters fully connected model along lines kr¨ahenb¨uhl koltun default values search best values cross-validation small subset validation employ coarse-to-ﬁne search scheme. speciﬁcally initial search range parameters reﬁne search step sizes around ﬁrst round’s best values. number mean ﬁeld iterations reported experiments. evaluation validation conduct majority evaluations pascal ‘val’ training model augmented pascal ‘train’ set. shown tab. incorporating fully connected model yields substantial performance boost improvement deeplab. note work kr¨ahenb¨uhl koltun improved result textonboost makes improvement report impressive. turning qualitative results provide visual comparisons deeplab deeplab-crf fig. employing fully connected signiﬁcantly improves results allowing model accurately capture intricate object boundaries. table effect field-of-view. show performance training speed pascal ‘val’ function kernel size ﬁrst fully connected layer input stride value employed atrous algorithm. deeplab model improves performance incorporating fully connected yields improvement. qualitative comparisons deeplab deeplab-msc shown fig. leveraging multi-scale features slightly reﬁne object boundaries. field view ‘atrous algorithm’ employed allows arbitrarily control field-ofview models adjusting input stride illustrated fig. tab. experiment several kernel sizes input strides ﬁrst fully connected layer. method deeplab-crf-x direct modiﬁcation vgg- kernel size input stride model yields performance ‘val’ relatively slow improved model speed images second reducing kernel size experimented network variants different sizes deeplab-crf deeplab-crf-x; latter large attains better performance. finally employ kernel size input stride change ﬁlter sizes last layers. interestingly resulting model deeplab-crf-largefov matches performance expensive deeplabcrf-x. time times faster signiﬁcantly fewer parameters figure incorporating multi-scale features improves boundary segmentation. show results obtained deeplab deeplab-msc ﬁrst second respectively. best viewed color. mean pixel along object boundaries quantify accuracy proposed model near object boundaries evaluate segmentation accuracy experiment similar kohli kr¨ahenb¨uhl koltun speciﬁcally ‘void’ label annotated usually occurs around object boundaries. compute mean pixels located within narrow band ‘void’ labels. shown fig. exploiting multi-scale features intermediate layers reﬁning segmentation results fully connected signiﬁcantly improve results around object boundaries. comparison state-of-art fig. qualitatively compare proposed model deeplabcrf state-of-art models fcn-s tti-zoomout- ‘val’ model able capture intricate object boundaries. figure trimap examples quality segmentation result within band around object boundaries proposed methods. pixelwise accuracy. pixel mean iou. figure comparisons state-of-the-art models set. first images. second ground truths. third recent models fourth deeplab-crf. best viewed color. reproducibility implemented proposed methods extending excellent caffe framework share source code conﬁguration ﬁles trained models allow reproducing results paper companion site https//bitbucket.org/ deeplab/deeplab-public. test results model choices validation evaluate model variants pascal ofﬁcial ‘test’ set. shown tab. deeplab-crf deeplabmsc-crf models achieve performance mean respectively. models outperform state-of-the-art models fcn-s msra-cfm increase models deeplab-crf-largefov yields performance deeplab-crfx training speed faster. furthermore best model deeplab-msc-crf-largefov attains best performance employing multi-scale features large fov. figure visualization results -val. show input image segmentation result delivered dcnn reﬁned segmentation result fully connected show failure modes last three rows. best viewed color. work combines ideas deep convolutional neural networks fully-connected conditional random ﬁelds yielding novel method able produce semantically accurate predictions detailed segmentation maps computationally efﬁcient. experimental results show proposed method signiﬁcantly advances state-of-art challenging pascal semantic image segmentation task. multiple aspects model intend reﬁne fully integrating main components train whole system end-to-end fashion similar kr¨ahenb¨uhl koltun chen zheng also plan experiment datasets apply method sources data depth maps videos. recently pursued model training weakly supervised annotations form bounding boxes image-level labels higher level work lies intersection convolutional neural networks probabilistic graphical models. plan investigate interplay powerful classes methods explore synergistic potential solving challenging computer vision tasks. work partly supported grant rey- project reconfig fp-ict- project mobot fp-ict--. also gratefully acknowledge support nvidia corporation donation gpus used research. would like thank anonymous reviewers detailed comments constructive feedback. rebuttal iclr adds model deeplab-msc-crf incorporates multi-scale features intermediate layers. deeplab-msc-crf yields performance pascal test set. camera-ready iclr experiments large field-of-view. pascal test deeplab-crf-largefov achieves performance exploiting mutliscale features large deeplab-msc-crf-largefov attains performance chen l.-c. papandreou kokkinos murphy yuille deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs. arxiv. papandreou kokkinos savalle p.-a. untangling local global deformations deep convolutional networks image classiﬁcation sliding window detection. arxiv. shotton winn rother criminisi textonboost image understanding multiclass object recognition segmentation jointly modeling texture layout context. ijcv", "year": 2014}