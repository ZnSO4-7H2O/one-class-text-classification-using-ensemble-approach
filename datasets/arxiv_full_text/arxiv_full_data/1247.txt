{"title": "Demystifying Neural Style Transfer", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Neural Style Transfer has recently demonstrated very exciting results which catches eyes in both academia and industry. Despite the amazing results, the principle of neural style transfer, especially why the Gram matrices could represent style remains unclear. In this paper, we propose a novel interpretation of neural style transfer by treating it as a domain adaptation problem. Specifically, we theoretically show that matching the Gram matrices of feature maps is equivalent to minimize the Maximum Mean Discrepancy (MMD) with the second order polynomial kernel. Thus, we argue that the essence of neural style transfer is to match the feature distributions between the style images and the generated images. To further support our standpoint, we experiment with several other distribution alignment methods, and achieve appealing results. We believe this novel interpretation connects these two important research fields, and could enlighten future researches.", "text": "neural style transfer recently demonstrated exciting results catches eyes academia industry. despite amazing results principle neural style transfer especially gram matrices could represent style remains unclear. paper propose novel interpretation neural style transfer treating domain adaptation problem. speciﬁcally theoretically show matching gram matrices feature maps equivalent minimize maximum mean discrepancy second order polynomial kernel. thus argue essence neural style transfer match feature distributions style images generated images. support standpoint experiment several distribution alignment methods achieve appealing results. believe novel interpretation connects important research ﬁelds could enlighten future researches. introduction transferring style image another image interesting difﬁcult problem. many efforts develop efﬁcient methods automatic style transfer recently gatys proposed seminal work captures style artistic images transfer images using convolutional neural networks work formulated problem ﬁnding image matching content style statistics based neural activations layer cnn. achieved impressive results several follow-up works improved upon innovative approaches despite fact work drawn lots attention fundamental element style representation gram matrix fully explained. reason paper propose novel interpretation neural style transfer casting special domain adaptation problem. theoretically prove matching gram matrices neural activations seen minimizing speciﬁc maximum mean discrepancy reveals neural style transfer intrinsically process distribution alignment neural activations images. based illuminating analysis also experiment distribution alignment methods including different kernels simpliﬁed moment matching method. methods achieve diverse reasonable style transfer results. speciﬁcally transfer method linear kernel achieves comparable visual results lower complexity. thus second order interaction gram matrix must style transfer. interpretation provides promising direction design style transfer methods different visual results. summarize contributions shown follows style transfer style transfer active topic academia industry. traditional methods mainly focus non-parametric patch-based texture synthesis transfer resamples pixels patches original source texture images different methods proposed improve quality patchbased synthesis constrain structure target image. example image quilting algorithm based dynamic programming proposed optimal texture since population vanishes statistic used measure difference distributions. speciﬁcally calculates deﬁned difference mean embedding sets samples. formally squared deﬁned understanding neural style transfer section ﬁrst theoretically demonstrate matching gram matrices equivalent minimizing speciﬁc form mmd. based interpretation extend original neural style transfer different distribution alignment methods. explaining observation ﬁrst brieﬂy review original neural style transfer approach goal style transfer generate stylized image given content image reference style image feature maps layer denoted rnl×ml rnl×ml rnl×ml respectively number feature maps layer height times width feature map. erates optimizing content loss style loss boundaries markov random field exploited preserve global texture structures however non-parametric methods suffer fundamental limitation low-level features images transfer. recently neural style transfer demonstrated remarkable results image stylization. fully takes advantage powerful representation deep convolutional neural networks method used gram matrices neural activations different layers represent artistic style image. used iterative optimization method generate image white noise matching neural activations content image gram matrices style image. novel technique attracts many follow-up works different aspects improvements applications. speed iterative optimization process johnson ulyanov trained feed-forward generative network fast neural style transfer. improve transfer results different complementary schemes proposed including spatial constraints semantic guidance markov random field prior also extension works apply neural style transfer applications. ruder incorporated temporal consistence terms penalizing deviations frames video style transfer. selim proposed novel spatial constraints gain portrait painting transfer. although methods improve original neural style transfer ignore fundamental question neural style transfer could gram matrices represent artistic style? vagueness understanding limits research neural style transfer. domain adaptation domain adaptation belongs area transfer learning aims transfer model learned source domain unlabeled target domain. component domain adaptation measure minimize difference source target distributions. common discrepancy metric maximum mean discrepancy measure difference sample mean reproducing kernel hilbert space. popular choice domain adaptation works besides aligned second order statistics whitening data source domain re-correlating target domain. proposed parameter-free deep adaptation method simply modulating statistics batch normalization layers. maximum mean discrepancy suppose sets samples {xi}n generated distributions respectively. maximum mean discrepancy popular test statistic two-sample testing problem acceptance rejection decisions made null hypothesis normalization term corresponding different scale feature layer choice kernel function. theoretically different kernel function implicitly maps features different higher dimensional space. thus believe different kernel functions capture different aspects style. adopt following three popular kernel functions experiments linear kernel polynomial kernel polynomial kernel version note matching gram matrices equivalent polynomial kernel gaussian kernel adopt unbiased estimation samples pairs thus computed linear complexity. statistics matching authors found statistics batch normalization layers contains traits different domains. inspired observation utilized separate statistics different domain. simple operation aligns different domain distributions effectively. special domain adaptation problem believe statistics certain layer also represent style. thus construct another style loss aligning statistics feature maps images feature sample column corresponds style image activations position feature maps considered individual sample. consequently style loss ignores positions features desired style transfer. conclusion reformulations suggest important ﬁndings interpretation reveals neural style transfer seen problem distribution alignment also core domain adaptation. consider style image certain layer domain style transfer also seen special domain adaptation problem. specialty problem lies treat feature position feature individual data sample instead traditional domain adaptation problem since scales gradients style loss differ different methods weights affect results style transfer factors make fair comparison. speciﬁcally content losses among different methods. then method ﬁrst manually select proper gradients style loss order magnitudes content loss. thus manipulate balance factor make trade-off content style matching. different style representations figure style reconstructions different methods layers respectively. corresponds method reconstruction results obtained using style loss lstyle also reconstruct different style representations different subsets layers network. example layer contains style loss ﬁrst layers results section brieﬂy introduce implementation details present results extended neural style transfer methods. furthermore also show results fusing different neural style transfer methods combine different style losses. following refer four extended style transfer methods introduced sec. linear poly gaussian respectively. images experiments collected public implementations neural style transfer. implementation details implementation vgg- network following choice also adopt relu layer content loss relu relu relu relu relu style loss. default weight factor speciﬁed. target image initialized randomly optimized iteratively relative change successive iterations maximum number iterations method gaussian kernel kernel bandwidth ﬁxed mean squared distances sampled pairs since ﬁrst visualize style reconstruction results different methods using style loss fig. moreover fig. also compares style representations different layers. hand speciﬁc method results show different layers capture different levels style textures layers usually larger granularity bottom layers. reasonable neuron layers larger receptive ﬁeld thus ability capture global textures. hand speciﬁc layer fig. also demonstrates style captured different methods differs. example layers textures captured linear kernel composed thick strokes. contrarily textures captured polynomial kernel grained. effect balance factor ﬁrst explore effect balance factor content loss style loss varying weight fig. shows results four transfer methods various intended global color information style image successfully transfered content image results smaller preserve content details shown fig. fig. becomes larger stylized textures incorporated results. example fig. fig. much similar illumination textures style image fig. shows balanced result content style. thus users make trade-off content style varying figure results fusion methods poly linear gaussian. rows results ﬁrst fusion method bottom rows correspond second one. column shows results balance weight methods. comparisons different transfer methods fig. presents results various pairs content style images different transfer methods. similar matching gram matrices equivalent poly method three methods also transfer satisﬁed styles speciﬁed style images. empirically demonstrates correctness interpretation neural style transfer style transfer essentially domain adaptation problem aligns feature distributions. particularly weight style loss becomes higher differences among four methods getting larger. indicates methods implicitly capture different aspects style also shown fig. since methods unique properties could provide choices users stylize content image. example linear achieves comparable results methods requires lower computation complexity. fusion different neural style transfer methods since several different neural style transfer methods propose combine produce transfer results. fig. demonstrates fusion results combinations presents results different balance methods. example fig. ﬁrst rows emphasize fig. emphasizes poly. results conclusion despite great success neural style transfer rationale behind neural style transfer crystal. vital trick style transfer match gram matrices features layer cnn. nevertheless subsequent literatures neural style transfer directly improves upon without investigating depth. paper present timely explanation interpretation first theoretically prove matching gram matrices equivalent speciﬁc maximum mean discrepancy process. thus style information neural style transfer intrinsically represented distributions activations style transfer achieved distribution alignment. moreover exploit several distribution alignment methods methods yield promising transfer results. thus justify claim neural style transfer essentially special domain adaptation problem theoretically empirically. believe interpretation provide lens re-examine style transfer problem inspire exciting works research area. tianqi chen yutian naiyan wang minjie wang tianjun xiao bing chiyuan zhang zheng zhang. mxnet ﬂexible efﬁcient machine learning library heterogeneous distributed systems. nips workshop machine learning systems arthur gretton dino sejdinovic heiko strathmann sivaraman balakrishnan massimiliano pontil kenji fukumizu bharath sriperumbudur. optimal kernel choice large-scale two-sample tests. nips christian ledig lucas theis ferenc husz´ar jose caballero andrew cunningham alejandro acosta andrew aitken alykhan tejani johannes totz zehan wang wenzhe shi. photo-realistic single image super-resolution using generative adversarial network. arxiv preprint arxiv.", "year": 2017}