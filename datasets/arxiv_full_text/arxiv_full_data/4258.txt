{"title": "PPFNet: Global Context Aware Local Features for Robust 3D Point Matching", "tag": ["cs.CV", "cs.AI"], "abstract": "We present PPFNet - Point Pair Feature NETwork for deeply learning a globally informed 3D local feature descriptor to find correspondences in unorganized point clouds. PPFNet learns local descriptors on pure geometry and is highly aware of the global context, an important cue in deep learning. Our 3D representation is computed as a collection of point-pair-features combined with the points and normals within a local vicinity. Our permutation invariant network design is inspired by PointNet and sets PPFNet to be ordering-free. As opposed to voxelization, our method is able to consume raw point clouds to exploit the full sparsity. PPFNet uses a novel $\\textit{N-tuple}$ loss and architecture injecting the global information naturally into the local descriptor. It shows that context awareness also boosts the local feature representation. Qualitative and quantitative evaluations of our network suggest increased recall, improved robustness and invariance as well as a vital step in the 3D descriptor extraction performance.", "text": "present ppfnet point pair feature network deeply learning globally informed local feature descriptor correspondences unorganized point clouds. ppfnet learns local descriptors pure geometry highly aware global context important deep learning. representation computed collection point-pair-features combined points normals within local vicinity. permutation invariant network design inspired pointnet sets ppfnet ordering-free. opposed voxelization method able consume point clouds exploit full sparsity. ppfnet uses novel n-tuple loss architecture injecting global information naturally local descriptor. shows context awareness also boosts local feature representation. qualitative quantitative evaluations network suggest increased recall improved robustness invariance well vital step descriptor extraction performance. local description geometry plays role vision precedes fundamental tasks correspondence estimation matching registration object detection shape retrieval. wide application makes local features amenable robotics navigation scene reconstruction creation contents digitalization. developing generalpurpose tool motivated scholars hand-craft feature descriptors/signatures decades unfortunately notice quest fruitful generating desired repeatable discriminative local descriptors point cloud data especially input partial noisy figure ppfnet generates repeatable discriminative descriptors discover correspondences simultaneously given pair fragments. point sets colored dimensional embedding local feature visualization. data illustrative image taken -scenes dataset deep neural networks latest works either base representation hand-crafted input encoding naively extend networks domain approaches sub-optimal address end-to-end learning data point sets. paper present ppfnet network deep learning fast discriminative local patch descriptor increased tolerance rotations. satisfy desirable properties ﬁrst represent local geometry augmented simple geometric relationships points normals point pair features design novel loss function term n-tuple loss simultaneously embed multiple matching nonmatching pairs euclidean domain. loss resembles contrastive loss instead pairs consider n-combination input points within scene grids limited maximal size convolutions kernels representations also used describing local neighbours context descriptor learning. contemporary work dmatch based robust volumetric tsdf encoding contrastive loss learn correspondences. albeit straightforward dmatch ignores nature input sparsity unstructured-ness. uses dense local grids cnns learn descriptor thus fall short training/testing performance recall. follow view based scheme sub-spaces information form projections depth learned well studied networks. promising potential methods cover sparse point sets. another spectrum research exploits graph networks also represent point sets direction prospers domains graph neural networks really suited point clouds require edges naturally arising point sets. khoury overcome local representation problem hand-crafted approach deep-network dimensionality reduction. algorithm also computes non-unique taking path deviates efforts end-to-end learning. hanging vital step taken pointnet network designed point input. pointnet demonstrated neural networks designed permutation invariant manner learn segmentation classiﬁcation keypoint extraction. extended pointnet++ better handle variations point density however work original form cannot tackle problem local geometry description successfully describe ppfnet trained ppfs points normals local patches boosts notion global context semi-local features pointnet optimizing combinatorial matching loss multitudes patches resulting powerful features outperforming prior art. background motivation explaining local descriptor setting. consider point sets rn×. denote coordinates points sets respectively. momentarily assume exists corresponding bijective map. following assuming rigidity sets related correspondence pose represented permutation matrix rigid transformation respectively. error point registration reads fragments boost separability. thanks many-tomany loss function able inject global context learning i.e. ppfnet aware local features establishing correspondence single one. also parallel processing ppfnet fast inference. finally combine contributions pipeline trains network correspondences fragment pairs. ppfnet extends pointnet thereby natural point clouds neutral permutations. fig. visualizes features illustrates robust matching perform. related work hand-crafted feature descriptors similar counterpart extracting meaningful robust local descriptors data kept computer vision researchers busy long period time unfortunately contrary repeatability distinctiveness features found expectations many approaches discover local reference frame simplest deﬁnition non-unique shifts attention lrf-free methods rotation invariant point pair features used basis creating powerful descriptors like ppfh fpfh ppfs also made semi-global perform reasonably well difﬁcult scenarios clutter occlusions thus applied many problems estimate poses retrieve recognize objects thanks simplicity invariance properties ppfs along points normals ppfnet describe local geometry learn strong local descriptor. learned feature descriptors advent deep learning several problems like retrieval recognition segmentation descriptor learning addressed using data majority operate depth images handful works target point clouds directly. address problem descriptor learning point sets review data representations regardless application consider learning local descriptors point cloud matching. many ways represent sparse unstructured data. early works exploited apparent dense voxels usually form binary-occupancy grid. idea quickly extended informative encoding tsdf multi-label occupancy different ones since mainly used context retrieval entire objects represented small voxel figure ppfnet inference network consists multiple pointnets responsible local patch. capture global context across local patches max-pooling aggregation fusing output back local description. able produce stronger discriminative local representations. pointnet pointnet inspiring pioneer addressing issue consuming point clouds within network architecture. composed stacking independent mlps anchored points last layers high dimensional descriptor synthesized. descriptor weak used max-pooling order aggregate global information task speciﬁc losses. max-pooling function makes network inconsiderate input ordering extends notions deep learning point sets. showed potential tasks like model classiﬁcation segmentation. local features pointnet suitable tasks targets generic. moreover spatial transformer layer employed bring marginal improvement basic architectures. aspect ppfnet successfully cure drawbacks task matching. note work vanilla version pointnet. overview begin explaining input preparation compute describing local geometry point cloud. elaborate ppfnet architecture designed process data merit. finally explain training method loss function solve combinatorial correspondence problem global manner. output network local descriptor sample point shown fig. also holds matching points sets action thus invariance desirable have ideally would like learn invariant permutations intolerant possible rigid transformations therefore paper choose minimally handcrafted point deeply learn representation. motivates exploit pointnet architecture intrinsically accounts unordered sets consumes sparse input. boost tolerance transformations beneﬁt point-pairfeatures true invariants euclidean isometry. point pair features point pair features antisymmetric descriptors describing surface pair oriented points constructed encoding local geometry given reference point lying point cloud deﬁne local region collect points {mi} local vicinity. also compute normals point associated local reference frame aligns patches canonical axes. altogether oriented {xi}} represent local geometry term local patch. pair neighboring point reference compute ppfs. note complexity-wise indifferent using points themselves omit quadratic pairing thanks ﬁxation central reference point shown fig. ﬁnal local geometry description input ppfnet combined points normals ppfs network architecture overall architecture ppfnet shown fig. input consists local patches uniformly sampled fragment. sparsity point-style data representation efﬁcient utilization pointnet ppfnet absorb patches concurrently. ﬁrst module ppfnet group mini-pointnets extracting features local patches. weights gradients shared across pointnets training. pooling layer aggregates local features global summarizing distinct local information global context whole fragment. global feature concatenated every local feature. group mlps used fuse global local features ﬁnal global-context aware local descriptor. n-tuple loss goal ppfnet extract features local patches process mapping high dimensional non-linear data space dimensional linear feature space. distinctiveness resulting features closely related separability embedded space. ideally proximity neighboring patches data space preserved feature space. figure illustration n-tuple sampling feature space. green lines link similar pairs coerced keep close. lines connect non-similar pairs pushed apart. without n-tuple loss remains non-similar patches close feature space distant similar patches. novel ntuple method pairs patch others guaranteeing similar patches remain close non-similar ones distant. state seems adopt loss functions contrastive triplet consider pairs triplets respectively. fragment consists patches case widely followed practice trains networks randomly retrieving /-tuples patches dataset. however networks trained manner learn differentiate maximum patches preventing uncovering true matching combinatorial patch count. generalizing losses n-patches propose ntuple loss n-to-n contrastive loss correctly learn solve combinatorial problem catering manyto-many relations depicted fig. given ground truth transformation n-tuple loss operates constructing correspondence matrix rn×n points aligned fragments. where stands hadamard product element-wise multiplication. hyper-parameter balancing weight between matching non-matching pairs lowerbound expected distance non-correspondent pairs. train ppfnet n-tuple loss shown fig. drawing random pairs fragments instead patches. also eases preparation training data. figure overall training pipeline ppfnet. local patches sampled pair fragments respectively feed ppfnet local features. based features feature distance matrix computed patch pairs. meanwhile distance matrix local patches formed based ground-truth rigid pose fragments. binarizing distance matrix correspondence matrix indicate matching non-matching relationships patches. n-tuple loss calculated coupling feature distance matrix correspondence matrix guide ppfnet optimal feature space. setup input encoding uses -point neighborhood compute normals entire scene using well accepted plane ﬁtting fragment anchor sample points distributed spatial uniformity. sample points keypoints within vicinity form patch compute local encoding. similarly down-sample points within patch facilitate training well increase robustness features various point density missing part. occasional patches insufﬁcient points deﬁned neighborhood randomly repeat points ensure identical patch size. ppfnet extracts compact descriptors dimension ppfnet implemented popular tensorﬂow initialization uses random weights adam optimizer minimizes loss. network operates simultaneously patches. learning rate exponentially decayed every epochs unreal datasets concentrate real sets rather synthetic ones therefore evaluations diverse dmatch rgbd benchmark different real-world scenes retrieved pool datasets analysis-by-synthesis -scenes sund rgb-d scenes halber collection split subsets training validation testing. dataset typically includes indoor scenes like living rooms ofﬁces bedrooms tabletops restrooms. details. input consists point geometry solely fragment reconstructions captured kinect sensor color. figure evaluating ppfnet real datasets method consistently outperforms state-of-the-art matching task terms recall. thanks careful design ppfnet clearly yields highest robustness change sparsity input even input data used. assessing different elements input training validation sets respectively. note combining cues global information point pair features help network achieve results. method expectedly outperforms vanilla pointnet show tab. adding samples brings beneﬁt certain level ppfnet adding samples also increases global context thus following advent hardware potential widen performance dmatch simply using local patches. show cherry-pick consistent gains also plot recall computed metric different inlier ratios fig. there practical choices ppfnet persistently remains others. application geometric registration similar ppfnet broader context transformation estimation. plug descriptors well established ransac based matching pipeline transformation fragments estimated running maximum ransac iterations initial correspondence set. transform source cloud target estimated pose compute pointto-point error. well established error metric tab. tabulates results real datasets. overall ppfnet performer showing higher recall majority scenes average. noteworthy always patches allowing dmatch original setting even could better recall half scenes. feed dmatch patches sampling level ppfnet dominates performance-wise scenes higher average accuracy. spin images shot fpfh well dmatch state deep learning based local feature descriptor vanilla pointnet hybrid hand-crafted deep descriptor designed compactness. experiments fair also show version dmatch local patches fragment instead method denoted dmatch-k. provided pretrained weights keep local patch size methods. evaluation data consists fragments -scenes sund datasets. begin showing comparisons without applying ransac prune false matches. believe show true quality correspondence estimator. inspired accredit recall effective measure experiment precision always improved better corresponding pruning evaluation metric directly computes recall averaging number matched fragments across datasets number ground truth matching fragment pairs least overlap ground-truth transformation denotes element found correspondence respectively come ﬁrst second fragment under matching. inlier ratio seen tab. ppfnet outperforms hand crafted counterparts mean recall. also shows consistent advantage dmatch-k using equal amount patches. finally remarkably able show improvement mean recall original dmatch using keypoints matching. performance boost dmatch-k dmatch also indicates keypoints advantageous matching. change sensor resolution distance scanners. motivates evaluate algorithm others varying sparsity levels. gradually decrease point density evaluation data record accuracy. fig. shows signiﬁcant advantage ppfnet especially severe loss density robustness achieved pointnet backend robust point pair features. fast ppfnet? found ppfnet lightning fast inference quick data preparation since consume representation data. majority runtime spent normal computation done whole fragment. extraction carried within neighborhoods sample points. tab. shows average running times different methods nvidia titanx pascal supported intel core .ghz core cpu. dramatic speed-up inference enabled parallelpointnet backend simultaneous correspondence estimation inference patches. currently prepare input network leaving idle work. part easily implemented gain even speed boosts. ablation study n-tuple loss train test network different losses contrastive triplet n-tuple loss dataset identical network conﬁguration. inter-distance distribution correspondent pairs non-correspondent pairs recorded train/validation data respectively. empirical results fig. show theoretical advantage loss immediately transfers practice features learned n-tuple better separable i.e. non-pairs distant embedding space pairs enjoy lower standard deviation. figure n-tuple loss lets ppfnet better separate matching non-matching pairs w.r.t. traditional contrastive triplet losses. table effect different components performance values depict number correct matches found inlier ratio. n-tuples loss repels non-pairs comparison contrastive triplet losses better knowledge global correspondence relationships. n-tuple loss general thus strongly encourage application also domains pose estimation useful global context local feature extraction? argue local features dependent context. corner belonging dining table share similar local features picture frame hanging wall. table generally supposed attached vertically wall. assess returns obtained adding global context simply remove global feature concatenation keep rest settings unaltered re-train test subsets pairs fragments. results shown tab. injecting global information local features improves matching training figure visualization estimated transformations. thanks robustness understanding global information ppfnet operate challenging scenarios confusing repetitive structures well mostly planar scenes less variation geometry. validation opposed baseline version vanilla pointnet free global context ppfs. signiﬁcance indicates global features discrimination valid cues also local descriptors. adding bring? similar experiment train versions network with/without incorporating input. contribution tabulated tab. there gain training validation achieved justifying inclusion increases discriminative power ﬁnal features. signiﬁcant jump beneﬁt adding ppf. note input representation composed rotation-invariant variant representations. already advantageous state rotation handling completely left network learn data. hypothesize input guidance would network tolerant rigid transformations. test this gradually rotate fragments around z-axis step size match fragment non-rotated one. observe tab. ppfs feature robust rotanote doesn’t correspond original version tion ratio matching performance networks opens rotation increases. accordance also show visualization descriptors fig. small large rotations. assign descriptor color projection high dimensional feature space color space learning linear qualitatively apparent strengthen robustness towards rotations. ppfs gain accuracy robustness rigid transformation best seemingly contradicting worlds. noteworthy using introduces full invariance besides invariance permutations renders task difﬁcult learn current network. leave future challenge. major limitation ppfnet quadratic memory footprint limiting number used patches hardware. instance cannot outperform dmatch fragments home-. upcoming gpus expect reach beyond point saturation. conclusion presented ppfnet descriptor tailored point cloud input. generalizing contrastive loss n-tuple loss fully utilize available correspondence relatioships retargeting training pipeline shown learn globally aware descriptor outperforms state terms recall also speed. features learned ppfnet capable dealing challenging scenarios shown fig. furthermore shown designing network suitable set-input point pair features advantageous developing invariance properties.", "year": 2018}