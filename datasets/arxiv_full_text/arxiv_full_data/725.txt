{"title": "Learning to Execute", "tag": ["cs.NE", "cs.AI", "cs.LG"], "abstract": "Recurrent Neural Networks (RNNs) with Long Short-Term Memory units (LSTM) are widely used because they are expressive and are easy to train. Our interest lies in empirically evaluating the expressiveness and the learnability of LSTMs in the sequence-to-sequence regime by training them to evaluate short computer programs, a domain that has traditionally been seen as too complex for neural networks. We consider a simple class of programs that can be evaluated with a single left-to-right pass using constant memory. Our main result is that LSTMs can learn to map the character-level representations of such programs to their correct outputs. Notably, it was necessary to use curriculum learning, and while conventional curriculum learning proved ineffective, we developed a new variant of curriculum learning that improved our networks' performance in all experimental conditions. The improved curriculum had a dramatic impact on an addition problem, making it possible to train an LSTM to add two 9-digit numbers with 99% accuracy.", "text": "recurrent neural networks long short-term memory units widely used expressive easy train. interest lies empirically evaluating expressiveness learnability lstms sequence-to-sequence regime training evaluate short computer programs domain traditionally seen complex neural networks. consider simple class programs evaluated single left-to-right pass using constant memory. main result lstms learn character-level representations programs correct outputs. notably necessary curriculum learning conventional curriculum learning proved ineffective developed variant curriculum learning improved networks’ performance experimental conditions. improved curriculum dramatic impact addition problem making possible train lstm -digit numbers accuracy. execution computer programs requires dealing number nontrivial concepts. execute program system understand numerical operations if-statements variable assignments compositionality operations many more. show recurrent neural networks long short-term memory units accurately evaluate short simple programs sequence-to-sequence framework sutskever lstm reads program character-by-character computes program’s output. consider constrained computer programs evaluated linear time constant memory lstm reads program memory capacity limited found difﬁcult train lstms execute computer programs used curriculum learning simplify learning problem. design curriculum procedure outperforms conventional training uses curriculum learning well naive curriculum learning strategy bengio provide plausible explanation effectiveness procedure relative naive curriculum learning finally addition curriculum learning strategies examine simple input transformations simplify sequence-to-sequence learning problem. show that many cases reversing input sequence replicating input sequence improves lstm’s performance memorization task related work related research used tree neural networks evaluate symbolic mathematical expressions logical formulas close spirit work. computer programs complex mathematical logical expressions possible simulate either appropriate computer program. methodological perspective formulate program evaluation task sequenceto-sequence learning problem recurrent neural network interesting applications recurrent neural networks include speech recognition machine translation handwriting recognition many more. maddison tarlow trained language model program text used neural network determine whether programs equivalent. approaches require parse trees programs input model string character representing program. predicting program output requires model deals long term dependencies arise variable assignment. reason chose long short-term memory model although many variants perform well tasks long term dependencies initially found difﬁcult train lstms accurately evaluate programs. compositional nature computer programs suggests lstm would learn faster ﬁrst taught individual operators combine them. approach implemented curriculum learning prescribes gradually increase difﬁculty level examples presented lstm. partially motivated fact humans animals learn much faster given hard manageable tasks. unfortunately found naive curriculum learning strategy bengio sometimes harmful. contributions formulation curriculum learning strategy substantially improves speed quality training every experimental setting considered. perform single pass program memory limited. programs python syntax constructed small number operations compositions allow following operations addition subtraction multiplication variable assignments ifstatements for-loops forbid double loops. every program ends single print statement whose output integer. example programs shown figure select programs family distributions parametrized length nesting. length parameter number digits integers appear programs appendix presents pseudocode algorithm used generate programs. example programs generated length nesting shown figure impose restrictions operands multiplication ranges for-loop since pose greater difﬁculty model. constrain arguments multiplication range for-loops chosen uniformly much smaller range since models able perform linear-time computation generic integer multiplication requires superlinear time. similar considerations apply for-loops since nested for-loops implement integer multiplication. nesting parameter number times allowed combine operations other. higher values nesting yield programs deeper parse trees. nesting makes task much harder lstms natural dealing compositionality unlike tree neural networks. surprising lstms handle nested expressions all. programs also receive external input. important emphasize lstm reads entire input character time produces output character time. characters initially meaningless model’s perspective; instance model know means addition followed fact scrambling input characters effect model’s ability solve problem. demonstrate difﬁculty task presenting input-output example scrambled characters figure finally wanted verify program trivial evaluate ensuring bias coming benford’s strong. setup possible output characters digits sequence character minus. output distribution uniform seen noticing minus sign occur frequency digits. assume output characters independent probability guessing correct character common character occurs probability entire output. however bias distribution ﬁrst character. possible choices randomly guessed probability common character occurs probability ﬁrst position indicating strong bias. still value model prediction accuracy. moreover probable second character ﬁrst position output occurs probability indistinguishable probability distribution digits positions. last character always sequence. common digit prior last character occures probability statistics computed randomly generated programs length nesting absence strong bias conﬁguration suggests even less bias greater nesting longer digits also conﬁrmed numerically. addition task difﬁcult intuitively assess accuracy lstm program evaluation task. example clear whether accuracy impressive. thus also evaluate models familiar addition task difﬁculty measured length inputs. consider addition numbers length chosen uniformly adding number length simpler adding variable length numbers. model doesn’t need align them. memorization task addition program evaluation addition also investigate task memorizing random sequence numbers. given example input lstm reads character time stores memory outputs character time. present explore simple performance enhancing techniques input reversing sutskever input doubling. idea input reversing reverse order input keeping desired output unchanged appear neutral operation average distance input corresponding target change. however input reversing introduces many short term dependencies make easier lstm learn make correct predictions. strategy ﬁrst introduced sutskever second performance enhancing technique input doubling present input sequence twice output remains unchanged method meaningless probabilistic perspective rnns approximate conditional distribution attempt learn still gives noticeable performance improvements. processing input several times producing output lstm given opportunity correct mistakes omissions made before. program generation procedure parametrized length nesting. parameters allow control complexity program. length nesting large enough learning problem becomes nearly intractable. indicates order learn evaluate programs given length nesting help ﬁrst learn evaluate programs length nesting evaluate following curriculum learning strategies curriculum learning baseline approach curriculum learning. means generate training samples length nesting strategy sound statistical perspective since generally recommended make training distribution identical test distribution. naive curriculum strategy begin length nesting learning stops making progress validation increase length repeat process length reaches case increase nesting reset length also choose ﬁrst increase nesting length. however make noticeable difference performance. skip option rest paper increase length ﬁrst experiments. strategy examined previous work curriculum learning however show sometimes gives even worse performance baseline. mixed strategy generate random sample ﬁrst pick random length random nesting independently every sample. mixed strategy uses balanced mixture easy difﬁcult examples every point training sizable fraction training samples appropriate difﬁculty lstm. combining mixed strategy naive curriculum strategy strategy combines strategy naive strategy. approach every training case obtained either naive strategy strategy. result combined strategy always exposes network least difﬁcult examples differs naive curriculum strategy. noticed always outperformed naive strategy would generally outperform strategy. explain curriculum learning strategies outperform naive curriculum strategy section lstm section brieﬂy describe deep lstm vectors n-dimensional unless hidden state layer timestep explicitly stated otherwise. biased linear mapping element-wise input deep lstm timestep activations multiplication layer lstm layers unrolled steps experiments. cells layer parameters initialized uniformly gives total parameters. initialize hidden states zero. ﬁnal hidden states current minibatch initial hidden state subsequent minibatch. thus possible program output could separated across different minibatches. size minibatch constrain norm gradients greater keep learning rate equal reach target length nesting reaching target accuracy decrease learning rate keep learning rate level improvement training set. decrease again improvement training set. difference experiments termination criteria. program output prediction stop learning rate becomes smaller copying task stop training epochs epoch samples. begin training length nesting ensure training validation test sets disjoint. achieved computing hash value sample taking modulo important note error rates teacher forcing compute accuracy lstms. predicting i-th digit target lstm provided correct ﬁrst digits target. different using lstm generate entire output done sutskever would almost surely result lower numerical accuracies. help make intuitive sense results present large number test cases outputs computed lstm albeit teacher forcing. figure shows absolute performance baseline strategy best performing strategy combined. moreover figure shows performance three curriculum strategies relative baseline. finally provide several example predictions test data supplementary materials. accuracy random predictor would since possible output symbols. figure absolute prediction accuracy baseline strategy combined strategy program evaluation task. deeper nesting longer integers make task difﬁcult. overall combined strategy outperformed baseline strategy every setting. figure relative prediction accuracy different strategies respect baseline strategy. naive curriculum strategy found sometime perform worse baseline. possible explanation provided section combined strategy outperforms strategies every conﬁguration program evaluation. results addition task figure presents accuracy achieved lstm various curriculum strategies addition task. remarkably combined curriculum strategy resulted accuracy addition -digit long numbers massive improvement naive curriculum. figure prediction accuracy memorization task four curriculum strategies. input length ranges digits. every strategy evaluated following input modiﬁcation schemes modiﬁcation; input inversion; input doubling; input doubling inversion. training time limited; network trained till convergence. produce output model processes input input character time reconstruct output loading entire input memory. task provides insight lstm’s ability learn remember. evaluated model sequences lengths ranging four curriculum strategies section addition investigate strategies modify input increase performance strategies described section figure shows absolute performance baseline strategy combined strategy. figure shows performance convergence. present supplementary material results epochs task combined strategy longer outperforms mixed strategy every experimental setting although strategies always better using curriculum naive curriculum strategy. graph contains settings correspond possible combinations input inversion input doubling. result clearly shows simultaneously doubling reversing input achieves best results. random guessing would achieve accuracy since possible output symbols. experimental results suggest proper curriculum learning strategy critical achieving good performance hard problems conventional stochastic gradient descent performs poorly. results problems show combined strategy better curriculum strategies including naive curriculum learning training target distribution. plausible explanation case. seems natural train models examples increasing difﬁculty. models chance learn correct intermediate concepts utilize difﬁcult problem instances. otherwise learning full task might difﬁcult random initialization. explanation proposed previous work curriculum learning bengio however based empirical results naive strategy curriculum learning sometimes worse learning target distribution. tasks neural network perform memorization. easier examples usually require less memorization hard examples. instance order -digit numbers remember least digits producing output. best accurately memorize numbers could spread entire hidden state memory cell indeed network incentive utilize fraction state always better make entire memory capacity. implies harder examples would require restructuring memory patterns. would need contract representations digit numbers order free space number. process memory pattern restructuring might difﬁcult implement could reason sometimes poor performance naive curriculum learning strategy relative baseline. combined strategy reduces need restructure memory patterns. combined strategy combination naive curriculum strategy strategy mixture examples difﬁculties. examples produced naive curriculum strategy help learn intermediate input-output mapping useful solving target task extra samples strategy prevent network utilizing memory easy examples thus eliminating need restructure memory patterns. perfect prediction program output requires complete understanding operands concepts precise combined. however imperfect prediction might achieved multitude ways could heavily rely memorization without genuine understanding underlying concepts. instance perfect addition relatively intricate lstm needs know order numbers correctly compute carry. many alternatives addition algorithm perfect output required. instance perform element-wise addition long carry output would perfectly correct. another alternative requires memory also simpler memorize results addition digit numbers. multi-digit addition broken multiple -digits additions element-wise. again algorithm would reasonably high prediction accuracy although would correct. know heavily model relies memorization learned algorithm actual correct algorithm. could tested creating discrepancy training test data work training test distributions same. plan examine well models would generalize different examples future work. shown possible learn evaluate programs limited prior knowledge. work demonstrate power expressiveness sequence-to-sequence lstms. also showed correct curriculum learning crucial achieving good results difﬁcult tasks cannot optimized standard sgd. also found general method doubling input reliably improves performance sequence-to-sequence lstms. results encouraging leave many questions open. example able evaluate arbitrary programs time). cannot achieved conventional rnns lstms runtime restrictions. also know wish thank oriol vinyals useful discussions koray kavukcuoglu help code development. moreover wish acknowledge marc’aurelio ranzato useful comments ﬁrst version paper. chunks code origin google deepmind repository. thank unknown developers lstm function auxiliary functions. bengio yoshua boulanger-lewandowski nicolas pascanu razvan. advances optimizing recurrent networks. acoustics speech signal processing ieee international conference ieee kyunghyun merrienboer bart gulcehre caglar bougares fethi schwenk holger bengio yoshua. learning phrase representations using encoder-decoder statistical machine translation. arxiv preprint arxiv. graves alex mohamed abdel-rahman hinton geoffrey. speech recognition deep recurrent neural networks. acoustics speech signal processing ieee international conference ieee hill theodore statistical derivation signiﬁcant-digit law. statistical science hochreiter sepp schmidhuber j¨urgen. long short-term memory. neural computation yong grauman kristen. learning easy things ﬁrst self-paced visual category discovery. computer vision pattern recognition ieee conference ieee maddison chris tarlow daniel. structured generative models natural source code. arxiv preprint sutskever ilya. training recurrent neural networks. thesis university toronto sutskever ilya vinyals oriol quoc sequence sequence learning neural networks. arxiv algorithm pseudocode algorithm used generate distribution python program. programs produced algorithm guaranteed never dead code. type sample determined hash modulo emphasize predictions rely teacher forcing. even lstm made incorrect prediction i-th output digit lstm provided input correct i-th output digit predicting digit. teacher forcing effect whenever lstm makes errors sample makes early error gets remainder digits correctly needs interpreted care. figure prediction accuracy memorization task four curriculum strategies. input length ranges digits. every strategy evaluated following input modiﬁcation schemes modiﬁcation; input inversion; input doubling; input doubling inversion. training time limited epochs.", "year": 2014}