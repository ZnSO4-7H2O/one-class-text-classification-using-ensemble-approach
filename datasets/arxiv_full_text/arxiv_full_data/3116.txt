{"title": "Unsupervised Detection and Tracking of Arbitrary Objects with Dependent  Dirichlet Process Mixtures", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "This paper proposes a technique for the unsupervised detection and tracking of arbitrary objects in videos. It is intended to reduce the need for detection and localization methods tailored to specific object types and serve as a general framework applicable to videos with varied objects, backgrounds, and image qualities. The technique uses a dependent Dirichlet process mixture (DDPM) known as the Generalized Polya Urn (GPUDDPM) to model image pixel data that can be easily and efficiently extracted from the regions in a video that represent objects. This paper describes a specific implementation of the model using spatial and color pixel data extracted via frame differencing and gives two algorithms for performing inference in the model to accomplish detection and tracking. This technique is demonstrated on multiple synthetic and benchmark video datasets that illustrate its ability to, without modification, detect and track objects with diverse physical characteristics moving over non-uniform backgrounds and through occlusion.", "text": "task broken three parts data extraction localization tracking. data extraction extracting features regions videoframes constitute objects localization ﬁnding positions and/or shapes distinct objects tracking maintaining identities detected objects time. paper introduces framework carrying three actions based type dependent dirichlet process mixture model. framework provides foundation class unsupervised algorithms detect track arbitrary objects wide range videos. research related general detection tracking objects tends focus either extraction localization tracking. integrating three tasks system multiple arbitrary objects diverse video types often primary focus. attempts accomplishing three tasks cohesive manner studied recent years paper furthers line work providing model could give rise number algorithms detect arbitrary objects videos—particularly cases frame-by-frame segmentation diﬃcult video quality extraction noisy—and maintain isolation distinct objects tracking occlusion. begin describing characteristics extracted data giving generalized form model implement model must specify data extraction procedure distributions representing objects chosen allow arbitrary object tracking tailored speciﬁc object type given application. implementation extract data basic frame difabstract paper proposes technique unsupervised detection tracking arbitrary objects videos. intended reduce need detection localization methods tailored speciﬁc object types serve general framework applicable videos varied objects backgrounds image qualities. technique uses dependent dirichlet process mixture known generalized polya model image pixel data easily eﬃciently extracted regions video represent objects. paper describes speciﬁc implementation model using spatial color pixel data extracted frame diﬀerencing gives algorithms performing inference model accomplish detection tracking. technique demonstrated multiple synthetic benchmark video datasets illustrate ability without modiﬁcation detect track objects diverse physical characteristics moving non-uniform backgrounds occlusion. deﬁne unsupervised detection tracking arbitrary objects videos task automatically identifying distinct objects present sequence images determining path object follows time. techniques accomplish task useful many ﬁelds make video data including robotics video surveillance time-lapse microscopy video summarization. studying task hope ferencing procedure specify distributions useful representing arbitrary objects describe inference algorithms model show output algorithms interpreted object localization tracking results implementation demonstrated multiple synthetic benchmark datasets. standard performance metric values computed quantify results benchmark datasets compare performance metrics method yielded specialized detection tracking algorithms tailored speciﬁc objects benchmark datasets. results support hypothesis approaches combining simple data extraction powerful model perform detection tracking arbitrary objects level comparable state-of-the-art object speciﬁc algorithms. variety methods ﬁelds image processing signal processing computer vision developed solve aspects problem unsupervised detection tracking arbitrary objects. methods might placed broad categories distinguish foreground regions images background segment images distinct regions perform localization track object sequence images track multiple objects sequence images segment sequence images distinct spatiotemporal regions combine previous methods create systems capable detecting tracking speciﬁed objects discerning regions video constitute distinct arbitrary objects tracking methods discern foreground background regions video allow data extracted areas frame objects reside. frame diﬀerencing background subtraction methods. record locations exhibit motion relative background. often background subtraction refers methods compare image containing targets image background model background learned video progresses frame differencing refers methods compare pairs consecutive images video frame diﬀerencing used sole extraction method object localization tracking schemes success great deal research focused developing algorithms track multiple objects simultaneously. particular emphasis developing ways deal problems object occlusion complex object interactions objects similar appearances variable numbers objects objects enter exit ﬁeld view diﬀerent times multiple independent single-object trackers running simultaneously shown ineﬀective tend coalesce track object remedy problem methods incorporated probabilistic principles maintaining isolation object trackers approach problem involving nonparametric mixture model also found success maintaining isolation distinct objects past decade attempts provide general algorithms fully unsupervised detection tracking arbitrary objects videos. blob tracking basic method carrying goal found success videos objects easily isolated background localization segmentation distinct objects possible blob tracking methods however problems faced videos detection difﬁcult object appearance orientation varies heavily exists object occlusion improve accuracy methods techniques developed performing extraction segmentation joint manner incorporating statistical methods maintaining hypotheses diﬀerent numbers detected objects introducing multi-object tracking methods described previously track distinct blobs segmented another family methods related task unsupervised detection tracking video objects goes heading video segmentation algorithms—these methods extend single-frame image segmentation maintain coherence image segments time success used explicit purpose detecting tracking foreground objects videos attempts perform unsupervised detection tracking include methods clustering short sequences positions extracted detecting motion objects return full-length distinct object tracks graph based methods carry similar task using spectral clustering another approach uses gaussian mixture model cluster data extracted moving objects method also nearly high accuracy object detection tracking methods tailored speciﬁc object types. methods rely detection criteria exploit knowledge appearance behavior objects video. methods make state-of-the-art detectors designed locate speciﬁed objects interest. contrast method described paper designed track arbitrary objects without using explicit detection criteria serve general strategy used withmodiﬁcation perform accurate detection tracking diverse objects wide range videos. technique introduce falls category clustering-based arbitrary object detection tracking methods. diﬀering previous work type time dependent bayesian nonparametric mixture model show applied variety easily extracted data perform detection tracking. method begins performing simple data extraction procedure yields noisy data. model data serves general framework choose variety object appearance distributions inference algorithms; choice provides method unsupervised detection tracking arbitrary objects videos. we’d like extraction procedure unsophisticated possible. consequently frame diﬀerencing. procedure locates pixels image regions undergo change. speciﬁcally frame pixels diﬀer previous frame beyond threshold recorded. here pixel corresponds observation frame diﬀerencing simple computationally inexpensive able applied wide range static single-camera videos locations spatial characteristics texture representations. principle extract image features used characterize appearance objects. implementation choose extract color information vicinity pixel. incorporating color features allows method infer distribution color detected object; improves ability distinguish adjacent objects track objects occlusion. information represent dimensional discrete distribution aspect color pixel’s immediate vicinity. details vector computed given section refer components vector color counts pixel. type dependent dirichlet process mixture model known generalized polya dependent dirichlet process mixture deﬁne general form model section specify distributions used implementation model section also deﬁne secondary form model section used inference algorithms. provide brief introduction mixture models dirichlet process appendix dirichlet process mixture models fall heading bayesian nonparametric models. models widely used past decade perform nonparametric density estimation cluster analysis. data extracted videos comprises spatiotemporal clusters corresponding distinct object. consequently interested using class models known dependent dirichlet process mixture models particularly useful estimating number latent classes time dependent data. since objects enter exit scene number clusters present throughout video constant cluster data properties choose ddpm known generalized polya dependent dirichlet process mixture model fig. three pairs consecutive frames results produced taking pixel-wise frame diﬀerence pair ﬁnal image shows results frame diﬀerencing sequence images conditioned cluster’s previous size assignments time deletion parameter fig. graphical model generalized polya dependent dirichlet process mixture. observations time xntt associated assignments cntt denoted respectively sections detail object representation distributions chosen fully specify implementation gpuddpm. speciﬁcation used experiments section distributions represent object appearance appearance prior object movement respectively. speciﬁcation kept general allow wide applicability though could choose incorporate known object appearance motion information speciﬁc tracking application future studies. addition variables parameters cluster given time depend directly value previous time; instead dependent intermediate sequence variables. allows cluster parameters time step marginally distributed according base distribution maintaining simple time varying behavior. multinomial distribution. note withhold writing subscripts specifying cluster number time section writing unnecessary. multivariate normal distribution spatial features models position spatial extent object. thought intuitively represent shape object oval. model color features draws multinomial distribution. incorporating distribution cluster likelihood allows exploit observation pixels associated distinct objects tend similar color count vectors. appearance distributions). conjugate priors base distribution allow eﬃcient computation. speciﬁcally implementation normalinverse-wishart prior placed multivariate norpect tracked objects move time. since implementation intended tracking arbitrary objects wish make sophisticated assumptions object motion. example choose incorporate complex objects dynamics though often used success certain object-speciﬁc tracking tasks people tracking assume position object given time close position previous time position varies directions equally time steps. multivariate normal-multinomial gpuddpm object tracking number parameters used specify object appearance prior distribution transition kernel generalized polya distributions object appearance prior parameters include section details mcmc sampler used perform inference. secondary formulation gpuddpm refer deletion variable formulation used here. formulation equivalent formulation given section allows easier sampling. instead incorporating cluster size variable directly gpuddpm model formulate equivalent model makes variables called deletion variables. introduce deletion variable observation denotes time observation removed assigned cluster. time cluster sizes reconstructed previous assignments deletion variables argument true otherwise. additionally deﬁne deletion variable thought lifetime assignment. deﬁnition distribution lifetime shown distributed geometrically written mean position prior. experiments performed section data recentered origin parameter scale factor mean prior. shape factor covariance prior. scale factor covariance prior. scale factor multinomial prior. concentration parameter dirichlet process. higher value increase tendency objects detected. deletion parameter. higher value give objects increased tendency bayesian inference used achieve detection tracking results. previously developed inference strategies applied generative model deﬁned section section provide details bayesian inference algorithms implemented study. ﬁrst type markov chain monte carlo batch inference uses gibbs sampling generate samples posterior distribution model. second type sequential monte carlo inference also known particle ﬁlter generates samples posterior distribution model sequential manner. cluster sampled assignment cluster parameters auxiliary variables cluster must initialized time steps sampling proceed. implementation newly sampled clusters initialized iteratively sampling forward time backwards time transition kernel. number observations prior parameters prior parameter respectively denote spatial color features observations respectively denote sample mean sample covariance observations deﬁned time sampler moves sequentially observations sampling assignment deletion variable each. afterwards cluster parameters active clusters sampled auxiliary variables active clusters sampled using metropolis hastings following sections detail distributions samples drawn. value proportional posterior probability computed possible value take values allow construct discrete probability distribution draw samples posterior distribution assignments. possible sampling deletion variables could performed manner similar sample assignment variables section computationally expensive large number possible deletion times. remedy this algorithm used generate samples posterior distribution possible deletion times proposal distribution section details sequential monte carlo sampler—also known particle ﬁlter—used perform inference. inference operates orginal gpuddpm formulation algorithm number samples referred particles generated; particle consists sample posterior distribution assignment observation cntt parameters cluster θktt size deletion cluster mktt. particles sampled time step relevant proposal distributions weight computed particle particles sampled ticles sampled associated weights computed resampling step carried out. step particles sampled current particles. resampling strategies described used. inferred cluster taken distinct object sequence means covariance matrices given cluster used determine position spatial region respectively given object sequence time steps. particular mean parameter taken centroid object -dimensional oval centered mean contains speciﬁed percentage normal distribution mass taken spatial region object. report maximum posteriori sample result. section provides details performance evaluation metrics developed quantify results object detection tracking studies synthetic video experiments verify aspects developed technique benchmark video experiments demonstrate performance technique relation strategies developed recent years. performance evaluation metrics provide standardized quantifying success detection tracking procedure given video started become consistently used past four years. metrics presented used become well established evaluating performance object detection tracking videos adopted video analysis content extraction program classiﬁcation events activities relationships consortium large-scale eﬀorts concerned video tracking interaction analysis. metrics used quantify experimental results study known sequence frame detection accuracy average tracking accuracy details metrics deﬁned computed given appendix metrics dependent upon ground-truth data specifying positions object frame throughout video sequence. experiments described below recorded synthetic video groundtruth construction videos used video performance evaluation resource ground-truth software open source tool commonly used video tracking community author ground-truth data benchmark datasets. ground-truth authored viper tool took form bounding boxes denoting spatial position object time step. consequentially spatial overlap results groundtruth intrinsic metrics rectangular bounding needed object time step results algorithm. took maximal minimal axially aligned values oval inferred algorithm sides representative bounding given object given frame. frame diﬀerencing used experiments identify pixels exhibiting motion. pixel recorded frame diﬀerencing also extracted color information. speciﬁcally speciﬁed square pixels length centered contained pixels surrounding frame chose capture pixel. possible values partitioned bins number pixels color value lying bins yielded dimensional vector color counts. experiments chose fig. plot shows sample posterior distribution model synthetic experiments vertical axis represents frame number horizontal axes represent spatial position objects denoted marker colors marker types mean standard deviation shown. cases objects successfully tracked occlusion whether travel straight line reverse direction combination sizes moving varied speeds trajectories black background. synthetic videos contain instances occlusion objects time-varying appearances behaviors notoriously decrease accuracy detection tracking. video constructed extraction procedure described section inference procedures described section carried return sequence multivariate-normal-parameters used determine sequence positions ovals approximating respectively locations shapes tracked object frame present video ﬁrst synthetic video experiment aimed test ability model inference procedure maintain identity independent objects based color information alone. videos constructed containing square opposite sides scene frame travel towards other arriving location second half videos diﬀer squares ﬁrst video continue direction other’s starting position squares second video reverse directions initial starting positions frame diﬀerence extraction yields parameters values inference videos inference carried using mcmc algorithm sample correctly tracked colored squares occlusion videos shown figure second synthetic video experiment aimed test tracking performance occlusion object appearance change motion change. video constructed showing square green square blue square square size video furthermore blue squares display behavior second video ﬁrst synthetic experiment green square begins point equidistant squares intersects overlap continues direction degree angle initial trajectory. parameters values chosen ﬁrst synthetic experiment. mcmc inference algorithm correctly tracked three objects occlusion inferred appearance size shifts. figure shows sample posterior distribution cluster parameters mean oval representation covariance matrix overlayed data. data plotted time vertical axis assignment data point three inferred clusters denoted color marker type. benchmark video datasets object tracking detection produced provide standard scenes researchers compare detection tracking results. videos primarily produced surveillance-related workshops—notably international workshop performance evaluation tracking surveillance —which provides researchers video datasets algorithmic goals focus. three commonly used benchmark videos pets workshops—one used pets pets used pets pets—were chosen demonstrate method presented study. performance metrics benchmark datasets allow methods developed paper quantitatively compared detection tracking algorithms. pets pets video datasets consist small number humans vehicles traveling across parking video taken above emulating might recorded standard outdoor surveillance equipment. test sequence images monocular stationary camera used pets workshop view dataset also taken monocular stationary camera used pets workshop. mcmc algorithm used inference experiments. computation required mcmc batch inference method ﬁnal frames video used datasets. extraction performed frame diﬀerencing described section using parameter values values synthetic experiments mcmc sampler successful benchmark videos; object detected tracked shape estimated manner consistent ground-truth. results pets dataset displayed figure pets dataset figure ﬁgures sample posterior distribution cluster parameters overlayed extracted data sequence frames assignment data point represented color marker type. calculate performance metrics must specify conﬁdence value allows oval representing region occupied object computed inferred covariance matrix cluster performance metrics found range conﬁdence intervals resulting curves pets pets video shown figure video dataset used pets pets conferences called time sequence chosen experimentation prominence number studies dataset consists monocular stationary camera frame video sequence. entire video sequence used experiment. large number frames objects video algorithm used inference. method sequential inference observed dataset converge better sample shorter period time comparison mcmc algorithm. extraction performed frame diﬀerencing described section using parameters model chosen additionally video datasets ground-truth bounding boxes around object authored using viper tool. inference algorithm yielded estimate posterior distribution model object detection tracking results obtained figure sample posterior distribution cluster parameters overlayed extracted data sequence frames assignment data point represented color marker type. fig. results pets pets dataset. plots show sample posterior distribution state vertical axis denotes time horizontal axes represent spatial position color represents assignment mean standard deviation shown. four frames pets pets sequence posterior sample mean covariance matrix representation shown frame dataset. dataset consists solely humans algorithms presented comparison developed speciﬁc purpose people tracking consequence many studies externally developed stateof-the-art human detectors exploit orientation humans speciﬁc dataset apply motion models based assumptions human motion. particular breitenstein base tracking ouput externally trained human-speciﬁc detector; yang assume tracking upright person perform feet head detection; conte group foreground fragments based geometry human shape recognized look shadows often present human surveillance scenarios; berclaz external detector makes multiple camera views models human cylinder; alahi base method modelling silhouettes humans; bolme train human speciﬁc detector; provide algorithm estimates typical human size orientation; arsic localize human feet positions. compare sfda results strategy methods show arbitrary object framework yield comparable results even compared object-speciﬁc trackers. table shows performance metric results comparison method achieves fourth best sfda third best ata. table sfda performance metric results shown method algorithms pets/ benchmark dataset. results listed descending order sfda value. results provided authors inference pets/ video dataset carried range generalized polya parameter values performance metric measures sfda computed combination parameters. sensitivity investigation focused parameters potential large eﬀect object detection accupresented model unsupervised detection tracking arbitrary objects videos. primary intention technique reduce need detection localization methods tailored speciﬁc object types serve general framework applicable videos varied objects backgrounds qualities. gpuddpm timedependent dirichlet process mixture introduced shown inference model fig. results pets/ dataset showing sample posterior distribution state frames vertical axis denotes time horizontal axes represent spatial position color represents assignment mean standard deviation shown. performance metrics covariance conﬁdence interval threshold. four frames posterior sample mean covariance matrix representation shown frame allows achieve detection tracking results. furthermore demonstrated speciﬁc implementation model using spatial color pixel data extracted frame diﬀerencing provided algorithms performing bayesian inference model accomplish detection tracking. algorithms carried multiple synthetic benchmark multi-object video datasets order demonstrate ability accomplish unsupervised detection tracking arbitrary objects manufactured real world settings. described computed standard performance metrics technique’s detection tracking results found comparable state-of-the-art object-speciﬁc detection tracking methods designed people tracking pets/ video dataset. results synthetic benchmark video datasets illustrate ability technique described paper without modiﬁcation perform completely unsupervised detection tracking objects diverse physical characteristics moving non-uniform backgrounds occlusion.", "year": 2012}