{"title": "Neighborhood Features Help Detecting Non-Technical Losses in Big Data  Sets", "tag": ["cs.LG", "cs.AI"], "abstract": "Electricity theft is a major problem around the world in both developed and developing countries and may range up to 40% of the total electricity distributed. More generally, electricity theft belongs to non-technical losses (NTL), which are losses that occur during the distribution of electricity in power grids. In this paper, we build features from the neighborhood of customers. We first split the area in which the customers are located into grids of different sizes. For each grid cell we then compute the proportion of inspected customers and the proportion of NTL found among the inspected customers. We then analyze the distributions of features generated and show why they are useful to predict NTL. In addition, we compute features from the consumption time series of customers. We also use master data features of customers, such as their customer class and voltage of their connection. We compute these features for a Big Data base of 31M meter readings, 700K customers and 400K inspection results. We then use these features to train four machine learning algorithms that are particularly suitable for Big Data sets because of their parallelizable structure: logistic regression, k-nearest neighbors, linear support vector machine and random forest. Using the neighborhood features instead of only analyzing the time series has resulted in appreciable results for Big Data sets for varying NTL proportions of 1%-90%. This work can therefore be deployed to a wide range of different regions around the world.", "text": "electricity theft occurs around world developed developing countries range total electricity distributed. generally electricity theft belongs non-technical losses occur distribution electricity power grids. paper build features neighborhood customers. ﬁrst split area customers located grids diﬀerent sizes. grid cell compute proportion inspected customers proportion found among inspected customers. analyze distributions features generated show useful predict ntl. addition compute features consumption time series customers. also master data features customers customer class voltage connection. compute features data base meter readings customers inspection results. features train four machine learning algorithms particularly suitable data sets parallelizable structure logistic regression k-nearest neighbors linear support vector machine random forest. using neighborhood features instead analyzing time series resulted appreciable results data sets varying proportions %-%. work therefore deployed wide range diﬀerent regions. permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights components work owned others must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. request permissions permissionsacm.org. bdcat’ december shanghai china acm. isbn ----//. http//dx.doi.org/./. concepts computing methodologies machine learning; supervised learning; feature selection; social professional topics geographic characteristics; data mining electricity theft detection feature engineering feature selection machine learning non-technical losses time series classiﬁcation modern life would unimaginable without reliable availability electricity. electricity generated diﬀerent infrastructure power plants wind farms solar cells. distributed customers electrical power grids. frequently appearing losses electricity theft predominantly known public. however losses classiﬁed accurately technical non-technical losses. technical losses naturally caused power dissipation particular internal electrical resistance wires. focus paper non-technical losses appear distribution include electricity theft. many forms electricity theft meter tampering bypassing meters arranged false meter readings example manipulating interfaces bribing meter readers forms include faulty broken meters un-metered supply human technical errors meter readings processing billing paper therefore considers electricity theft whole. example consumption time series customer monthly meter readings depicted figure beginning consumption signiﬁcantly decreased ﬁfth remained level course data. inspected customers sample customers. sample represent overall population customers previous inspections focused certain area. furthermore inspection results reported incorrect technicians threatened bribed fraudsters. main idea paper build scalable models neighborhood-based engineered features imbalanced data sets. using information neighborhood predict better geographic clusters among customers. best knowledge aware previously published research addressed topic. rest paper organized follows. section provides literature review detection. section describes data main contribution features include information neighborhood. analyze statistical properties show useful detection. furthermore describe diﬀerent proposed detection models explain particularly scalable data sets. section presents experimental results comparison models data diﬀerent proportions data. section summarizes work provides outreach future work. detection treated anomaly fraud detection problem. comprehensive surveys ﬁeld detection provided surveys advanced metering infrastructure manipulated provided detection research apply artiﬁcial intelligence methods particular methods used fall categories expert systems machine learning. expert systems incorporate hand-crafted rules order make decisions. contrast machine learning methods learn models data without explicitly programmed. method detect derive features customer consumption time series average consumption maximum consumption standard deviation number inspections average consumption residential neighborhood. features grouped classes using fuzzy c-means clustering. next customers classiﬁed using fuzzy memberships. average precision achieved test set. daily average consumption features last months used less highly imbalanced data customers. features used support vector machine gaussian kernel prediction test recall achieved. class imbalance problem addressed paper ensemble svms optimum-path forest decision tree applied test data. class imbalance problem addressed degree imbalance training examples reported. consumption proﬁles brazilian industrial customer proﬁles analyzed customer proﬁle contains features including demand billed maximum demand installed power etc. k-nearest neighbors perform similarly well test accuracies outperform neural network achieves test based pattern inspection carried beginning detected concretely electricity theft. manipulation infrastructure reverted electricity consumption resumed previous level. year later electricity consumption dropped third another inspection months later. ntls signiﬁcant harm economies eﬀects include loss revenue proﬁt decrease stability reliability power grids. reported range total electricity distributed countries brazil india malaysia lebanon also relevance developed countries example estimates ntls range billion carrying physical inspections customers costly. therefore predictions accurate. class imbalance evaluation metric feature description incorrect inspection results biased inspection results scalability comparison diﬀerent methods imbalanced classes data describe fact contains unequal amount labels class. accurate evaluation metrics need take property account. feature description long-standing challenge machine learning learning algorithms often work data need trained features computed previous research particularly addressed class imbalance detection assess models environment. compared boolean fuzzy expert systems support vector machine trained time series features proportion samples ranging brazilian customers. order assess models proposed area receiver-operating characteristic curve shown analyzing time series leads limited results data must taken account too. believe neighborhood customers contains information whether customer cause not. adequately addressed previous research. furthermore many models reported literature scale data sets perspective necessary take account order deploy models real environment. data used experiments paper electricity provider brazil. contains monthly meter readings january january customers. meter reading contains consumption date reading. customer master data includes limited location customer class voltage connection number wires going building contract status. also data includes inspection results found type notes written technician. database used previous research third inspections found ntl. however models paper must also work regions diﬀerent proportions. therefore samples inspects results generated following proportions proportion sample following three types features used customer neighborhood information daily average consumption categorial master data customer. also binary target vector created element recent inspection result customer respective period time. ntls encoded detected not. certain areas likely cause ntls others. therefore features based neighborhood interesting order improve predictions. data includes invalid coordinates customers coordinates ocean. this customers outside deviation mean coordinates removed. empirically found removing customers within standard deviations mean coordinates worked best. bounding around remaining valid coordinates along longitude along grid sizes used cells along longitude latitude respectively. grid size features assigned customer registered respective cell. area cell depicted table grid size. hood features computed customer. classes distributions values features four grid sizes depicted figure proportion figure balanced proportion. distributions neighborhood features represent prior distributions bayesian approach. however none distributions gaussian therefore interesting study properties change varying proportions data allow separate found found. found. exception grid size proportions variance found ratio feature greater customers found found proportions ﬂips around grid sizes. demonstrates inverse relationship distributions variances features proportions features variances diﬀerent ranges grid sizes helps separate classes. figure distributions neighborhood features varying grid sizes ntl. example peak around found ratio grid=x plot represents type favela neighborhood every second customer causes ntl. expected around customers proportion contains inspections. however means slightly decrease greater proportions customers found slightly increase customers found. found cause experiments however believe caused sampling data. however helps separate classes. means found ratio distributions approximately proportion expected. grid sizes distributions means approximately inspected ratio found ratio features respectively. third central moment mean standard deviation expectation operator. positively skewed data tail points right. contrast negatively skewed data tail points left. skewness feature distribution depicted figure inspected ratio distributions positively skewed. skewness means grid cells high inspected ratios cells inspection ratios. signiﬁcant diﬀerence classes proportions therefore property help much separate both. found ratio distributions positively skewed proportions negatively skewed class. change sign skewness distributions samples proportions shows existence clusters ntls different sizes. skewness feature generally greater class class grid sizes allows separate classes better. fourth moment mean standard deviation. distribution positive kurtosis value heavier tails sharper peak normal distribution. contrast distribution negative kurtosis value indicates distribution lighter tails ﬂatter peak normal distribution. kurtosis feature distribution depicted figure kurtosis values distributions features positive therefore sharper peaks normal distribution. inspection ratio features kurtosis greater class proportions meaning features less gaussian class helps separate classes. applies found ratio feature proportions overall plots variance skewness kurtosis classes show features values distributions diﬀerent grid sizes diﬀerent ranges. helpful order discriminate ntl. feature computed customers last months sumption meter reading month previous number days meter readings customer features based also used previous research experiments section experimentally determined work best. addition information customer considered prediction. categorial master data available customer summarized table feature converted one-hot coding. therefore binary features customer. order reduce overﬁtting representative binary features kept. could found using principal component analysis however able handle noise data well. since real data noisy proportion feature matrix least features neighborhood features combined daily average consumption features. depending distribution customers proportion binary master data features added. however fraction expressive enough improve prediction results. number retained number total features proportion sample summarized table logistic regression linear classiﬁer optimizes convex cross-entropy loss function training weights related linear regression feeds continuous output value sigmoid function +exp order predict probability binary class membership. scales data sets minibatch gradient descent used optimize weights parallelized among diﬀerent cores nodes. k-nearest neighbors instance-based lazy learning method weights training phase prediction class example determined selecting majority class nearest training examples. deﬁning proximity subject selection distance function popular ones include euclidean manhattan cosine. smoothing parameter. larger smoother output. since instance-based method predicting slow prediction times grow prediction class example test independent elements predictions distributed among diﬀerent cores nodes. support vector machine maximum margin classiﬁer i.e. creates maximum separation classes. support vectors hold separating hyperplane. practice small fraction training examples. therefore less prone overﬁtting classiﬁers neural network training deﬁned lagrangian dual problem convex cost function. default separating hyperplane linear. training svms using kernel input higher dimension feasible thousand training examples realistic amount time therefore data sets linear implementation svms practically usable random forest ensemble estimator comprises number decision trees tree trained subsample data feature order control overﬁtting. prediction phase majority vote made predictions individual trees. training individual trees independent other distributed among diﬀerent cores nodes. normalization makes values future data zero mean unit variance. allows reduce impact features broad range values. outcome feature contributes approximately proportionally classiﬁcation. performance measure used following experiments area receiver-operating curve plots true positive rate recall false positive rate. particularly useful detection allows handle imbalanced datasets puts correct incorrect inspection results relation other. many applications multiple thresholds used generate points plotted receiver-operating curve. however also computed single point connecting straight lines shown computations server cores ram. entire code written python. neighborhood features computed using spark experiments scikit-learn used allows distribute training evaluation four classiﬁers among cores. every proportion data split training validation test sets ratio respectively. four models trained using -fold cross-validation. four models trained classiﬁer performed best validation folds selected tested test report test auc. methodology related four models following parameter values determined empirically compromise expressiveness generalization models training time. logistic regression inverse regularization factor neighbors visited knn. random forest consists trees. diﬀerent proportions test logistic regression classiﬁers depicted figure using time series daily average consumption features last months results classiﬁer performs like chance proportions. performs better chance proportions maximum proportion however adding neighborhood selected categorial features classiﬁer performs noticeably better chance proportions signiﬁcantly better time series features proportions %-%. similar experiments random forest classiﬁers summarized table observed extra features help classiﬁers maximize overall scores classiﬁers perform noticeably better chance proportions. subscript denotes time series used models. subscript denotes features used time series neighborhood features selected master data. best proportion model bold. best using time series features respectively. however must noted classiﬁers perform close optimal scores achieved. likely ensemble allows better adopt variations data set. four models performed best features tested proportions. results summarized table visualized figure performs performs best proportions. classiﬁers perform similarly well proportion classiﬁer performs best proportion. even though achieved maximum also lowest throughout experiments. furthermore greatest standard deviation classiﬁers. overall four classiﬁers perform regime mean scores proportions close. observation often made machine learning actual algorithm less important representative data generally considered important also justiﬁed free lunch theorem states learning algorithm generally better others previous work used features derived consumption time series using also neighborhood information categorial customer master data four classiﬁers consistently performs better classiﬁers previous work proportions. section identiﬁed main challenges advance detection. believe detection using current inspection labels limited. therefore desirable analyze data unsupervised manner order insights structure. help compensate bias distribution labels also remove potentially wrong inspection labels. work proposed neighborhood features detection data customers inspection results splitting area grid ratio customers inspected ratio inspected customers detected. generated features four diﬀerent grid sizes. analyzed statistical properties distributions showed useful predicting ntl. features combined daily average consumption features last months recent inspection customer data contains meter readings total. furthermore also used selected customer master data customer class voltage connection customer. used four machine learning algorithms particularly suitable data sets predict customer causes logistic regression k-nearest neighbors linear support vector machine random forest. observed models signiﬁcantly perform better using neighborhood customer master data features compared using time series features. models perform regime measured score. total random forest classiﬁer slightly outperforms classiﬁers. future research planning investigate bias inspection labels correct using unsupervised methods. believe bias-free samples data allow train general accurate detection models. angelos saavedra cort´es souza. detection identiﬁcation abnormalities customer consumptions power distribution systems. ieee transactions power delivery corpora natural language disambiguation. proceedings annual meeting association computational linguistics pages association computational linguistics thirion grisel blondel prettenhofer weiss dubourg vanderplas passos cournapeau brucher perrot duchesnay. scikit-learn machine learning python. journal machine learning research papa. identiﬁcation feature selection non-technical losses industrial consumers using software weka. industry applications ieee/ias international conference pages ieee bettinger rangoni duarte. large-scale detection non-technical losses imbalanced data sets. innovative smart grid technologies conference ieee power energy society. ieee", "year": 2016}