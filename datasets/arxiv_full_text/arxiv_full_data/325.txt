{"title": "In Search of the Real Inductive Bias: On the Role of Implicit  Regularization in Deep Learning", "tag": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "abstract": "We present experiments demonstrating that some other form of capacity control, different from network size, plays a central role in learning multilayer feed-forward networks. We argue, partially through analogy to matrix factorization, that this is an inductive bias that can help shed light on deep learning.", "text": "present experiments demonstrating form capacity control different network size plays central role learning multi-layer feedforward networks. argue partially analogy matrix factorization inductive bias help shed light deep learning. central form learning inductive bias induces sort capacity control turn allows generalization. success learning depends well inductive bias captures reality relative capacity induced well computational complexity ﬁtting simple predictor training data. consider learning feed-forward networks perspective. search weights minimizing training error essentially considering hypothesis class predictors representable different weight vectors typically ﬁxed architecture. capacity controlled size network. justiﬁcation using networks many interesting realistic functions represented not-too-large feed-forward networks. indeed many cases show speciﬁc architectures capture desired behaviors. broadly time computable function captured sized network expressive power networks indeed great time also know learning even moderately sized networks computationally intractable—not np-hard minimize empirical error even three hidden units hard learn small feed-forward networks using learning method even binary classiﬁcation using network single hidden layer logarithmic number hidden units even know true targets exactly captured small network likely efﬁcient algorithm ensure error better —not algorithm tries network even tries much larger network fact matter algorithm represents predictors merely knowing not-too-large architecture excellent expressing reality explain able learn using using even larger network. succeed learning using multilayer feedforward networks? identify property makes possible learn? alternative inductive bias? exact correspondence depends activation function—for hard thresholding activation pseudodimension hence sample complexity scales number weights network. sigmoidal activation main observation based empirical experimentation single-hidden-layer networks increasing size size behave capacity control parameter fact must other implicit capacity control play. suggest hidden capacity control might real inductive bias learning deep networks. order gain understanding possible inductive bias draw analogy matrix factorization understand dimensionality versus norm control there. based analogy suggest implicit norm regularization might central also deep learning also think inﬁnite-sized bounded-norm models. also demonstrate weight decay inﬁnite two-layer network gives rise convex neural inﬁnite hidden layer regularization layer. consider training feed-forward network ﬁnding weights minimizing training error. speciﬁcally consider network real-valued inputs single hidden layer rectiﬁed linear units outputs happens training test errors increase network size training error necessarily decrease. test error might initially decrease approximation error reduced network better able capture targets. however size increases further loose capacity control generalization ability start overﬁtting. classic approximation-estimation tradeoff behavior. consider however results shown figure trained networks increasing size mnist cifar- datasets. training done using stochastic gradient descent momentum diminishing step sizes training error without explicit regularization. expected training test error initially decrease. surprising increase size network past size required achieve zero training error test error continues decreasing behavior predicted even contrary viewing learning ﬁtting hypothesis class controlled network size. example mnist units enough attain zero training error. allow units network ﬁtting training data better estimation error hence generalization error increase increase capacity. however test error goes down. fact parameters even beyond number training examples generalization error when using soft-max cross-entropy loss never exactly zero correct predictions ﬁnite margins/conﬁdences. instead data seperable order minimize loss weights need scaled toward inﬁnity cross entropy loss goes zero global minimum never attained. order able actually reaching zero loss solution hence global minimum slightly modiﬁed soft-max noticeably change results practice. truncated loss returns exact value wrong predictions correct prediction conﬁdences less threshold returns zero correct predictions large enough margins {si}k scores possible labels correct labels. soft-max cross-entropy loss written instead differentiable loss function otherwise. therefore deviate soft-max cross-entropy margin point effect deviation negligible .k)—if actual errors behavior would completely dominate correct examples margin errors capping amount need scale weights. figure training error test error based different stopping criteria -layer different number hidden units trained mnist cifar-. images datasets downsampled pixels. size training mnist cifar-. early stopping based error validation size training done using stochastic gradient descent momentum mini-batches size network initialized weights generated randomly gaussian distribution. initial step size momentum respectively. epoch used update rule step size min{. momentum. units. ﬁrst trained network small number hidden units entire dataset network disagreements correct labels switched labels agree network creating censored data set. think censored data representing artiﬁcial source distribution exactly captured network hidden units. approximation error zero networks least hidden units decrease further. still seen middle figure test error continues decreasing even reaching zero training error. next tried force overﬁtting adding random label noise data. wanted whether network higher capacity noise thus hurting generalization. however seen bottom figure even percent random labels signiﬁcant overﬁtting test error continues decreasing network size increases past size required achieving zero training error. happening here? possible explanation optimization introducing implicit regularization. implicitly trying solution small complexity notion complexity perhaps norm. explain overﬁt even number parameters huge. furthermore increasing number units might allow solutions actually lower complexity thus generalization better. perhaps ideal would inﬁnite network controlled hidden complexity. want emphasize including explicit regularization neither explicit penalty term modifying optimization through e.g. drop-outs weight decay one-pass stochastic methods. using stochastic method running convergence— achieve zero surrogate loss zero training error. fact also tried training using batch conjugate gradient descent observed almost identical behavior. seems even still getting random global minimum—indeed large networks vast majority many global minima training error would horribly overﬁt. instead optimization directing toward complexity global minimum. although know hidden notion complexity ﬁnal experiment tried effect adding explicit regularization form weight decay. results shown ﬁgure slight improvement generalization still increasing network size helps generalization. figure training error test error based different stopping criteria -layer different number hidden units trained small subsets mnist cifar-. images datasets downsampled pixels. sizes training validation sets mnist cifar- early stopping based error validation set. plots errors original datasets without explicit regularization.the best weight decay parameter chosen based validation error. middle plots censored data constructed switching labels agree predictions trained network small number hidden units mnist cifar-) entire dataset plots bottom also censored data except also percent noise labels randomly changing percent labels. optimization method figure results ﬁgure average error random repetitions. gain understanding might going consider slightly simpler model understand much better. instead rectiﬁed linear activations consider feed-forward course simply matrix-factorization model controlling capacity limiting number hidden units exactly corresponds constraining rank i.e. biasing toward dimensional factorizations. low-rank inductive bias indeed sensible though computationally intractable handle loss functions. however last decade seen much success learning norm factorizations. models constrain inner dimensionality instead constrain regularize norm. example constraining frobenius norm corresponds using trace-norm inductive bias unlike rank trace-norm convex leads tractable learning problems fact even learning done local search factor matrices dimensionality high enough norm regularized ensure convergence global minima stark contrast dimensionality-constrained low-rank situation limiting factor number hidden units local minima abundant furthermore trace-norm factorization norms well-justiﬁed sensible inductive biases. ensure generalization based trace-norm low-trace norm model corresponds realistic factor model many factors limited overall inﬂuence. fact empirical evidence suggests many cases low-norm factorization appropriate inductive bias compared low-rank models. then case linear activations norm factorization sense better inductive bias number weights ensures generalization grounded reality explain models learned tractably. interpret experimental results section light. perhaps learning succeeding good representation targets small number units rather good representation small overall norm optimization implicitly biasing toward low-norm models. inductive bias might potentially explain generalization ability computational tractability learning even using local search. interpretation really using inﬁnite-sized networks inﬁnite number hidden units. fitting ﬁnite network viewed approximation ﬁtting true inﬁnite network. situation also common matrix factorization e.g. successful approach training trace-norm models inﬁnite-dimensional bounded-norm factorization models approximate using ﬁnite dimensional representation rennie srebro srebro salakhutdinov ﬁnite dimensionality used capacity control purely computational reasons. indeed increasing allowed dimensionality generally improves generalization performance allows better approximate true inﬁnite model. ﬁnal section consider possible model inﬁnite sized norm-regularized networks. starting point global weight decay i.e. adding regularization term penalizes squares weights network might approximately introduced implicit regularization. result section global regularization equivalent convex neural network )—an inﬁnite network regularization layer. note models rather different inﬁnite networks regularization layer reduce linear methods speciﬁc kernel note also explain neural networks instead trying match performance deep models known shallow model done e.g. simplicity focus single output networks i.e. networks compute function ﬁrst consider ﬁnite two-layer networks show regularization layers equivalent constraint unit hidden layer regularization unit theorem loss function without changing input-output mapping rectiﬁed linear unit piece-wise linear piece hidden unit invariant rescaling weights. finally since right-hand side inequality invariant rescaling always choose norm kuhk bounded one. first recall deﬁnition convex ﬁxed library possible weight vectors positive measures representing positive negative part weights unit. convex neural given predictions form difference network inﬁnite network learning versus selecting hidden units limit number units used. possible units available merely need select want without constraint number units used norm. equivalence establishes long number allowed units large enough equivalent corollary long weight-decay regularized network equivalent summary learning selecting equivalent sufﬁciently many hidden units theorem gives alternative justiﬁcation employing regularization input hidden weights ﬁxed normalized unit norm namely equivalent regularization achieved weight decay implicit regularization stochastic gradient descent. equivalence holds also networks multiple output units i.e. kvhk. indeed matrix factorizations group-lasso regularized formulation known equivalent trace norm fazel maryam hindi haitham boyd stephen rank minimization heuristic application minimum order system approximation. proceedings american control conference zhiyun avner kuan garakani alireza bagheri dong bellet aurlien linxi collins michael kingsbury brian picheny michael fei. scale kernel methods good deep neural nets. technical report arxiv. rennie jasson srebro nathan. fast maximum margin matrix factorization collaborative prediction. proceedings international conference machine learning sherstov adam klivansand alexander cryptographic hardness learning intersections halfspaces. foundations computer science focs’. annual ieee symposium ieee srebro nathan salakhutdinov ruslan. collaborative ﬁltering non-uniform world learning weighted trace norm. advances neural information processing systems convenience reader formalize hardness learning feed-forward neural network mentioned introduction. results presented appropriate feed-forward networks relu activations really direct implication recent results learning intersections halfspaces. historical completeness note hardness learning logarithmic depth networks already established kearns valiant recent results discuss establish also hardness learning depth networks subject perhaps simpler cryptographic assumptions. presentation construction similar livni fact algorithm satisfying conditions even require labels perfectly predicted network single hidden layer super-constant e.g. number hidden units. proof. show every intersection homogeneous halfspaces {±}n normals realized unit margin feed-fowrad neural networks hidden units single hidden layer. hyperplane {±}d include units hidden layer incoming weights output node therefore network realizing following function since layer integer zero realizes intersection halfspaces unit margin. hence hypothesis class neural intersection halfspaces subset hypothesis class feed-forward neural networks hidden units single hidden layer. complete proof applying theorem daniely states subject cryptographic assumptions daniely hypothesis class intersection homogeneous halfspaces {±}n normals efﬁciently learnable theorem tells cannot expect small network data even data generated network also can’t expect learn using much larger network. even know labels perfectly predicted small network cannot expect learning algorithm learns much larger network non-trivial error. fact representable small network enough ensure tractable learning matter representation learning algorithm uses much stronger statement saying ﬁtting network data -hard. also precluding possibility tractable learning labels exactly explained small unknown network course also precludes possibility achieving error labels approximately explained small unknown network", "year": 2014}