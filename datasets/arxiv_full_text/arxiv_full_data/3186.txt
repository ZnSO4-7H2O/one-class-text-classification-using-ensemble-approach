{"title": "Structured Priors for Sparse-Representation-Based Hyperspectral Image  Classification", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Pixel-wise classification, where each pixel is assigned to a predefined class, is one of the most important procedures in hyperspectral image (HSI) analysis. By representing a test pixel as a linear combination of a small subset of labeled pixels, a sparse representation classifier (SRC) gives rather plausible results compared with that of traditional classifiers such as the support vector machine (SVM). Recently, by incorporating additional structured sparsity priors, the second generation SRCs have appeared in the literature and are reported to further improve the performance of HSI. These priors are based on exploiting the spatial dependencies between the neighboring pixels, the inherent structure of the dictionary, or both. In this paper, we review and compare several structured priors for sparse-representation-based HSI classification. We also propose a new structured prior called the low rank group prior, which can be considered as a modification of the low rank prior. Furthermore, we will investigate how different structured priors improve the result for the HSI classification.", "text": "structured dictionary formed concatenation several class-wise sub-dictionaries {ai}i=...n columns total number training samples classes scalar regularization parameter. case always suffers nonuniqueness instability sparse coefﬁcients high mutual coherency dictionary fortunately better reconstructed signal robust representation obtained either exploring dependencies neighboring pixels exploiting inherent dictionary structure. recently structured priors incorporated classiﬁcation sorted three categories. priors exploit correlations dependencies among neighboring spectral pixels sparse coefﬁcient vectors includes joint sparsity graph regularized lasso low-rank lasso priors exploit inherent structure dictionary group lasso priors enforce structural information sparse coefﬁcients dictionary collaborative group lasso collaborative hierarchical lasso besides structured sparsity prior also incorporated classiﬁers logistic regression classiﬁers main contributions paper assess performance using various structured sparsity priors classiﬁcation propose conceptually similar prior chilasso called low-rank group prior. abstract—pixel-wise classiﬁcation pixel assigned predeﬁned class important procedures hyperspectral image analysis. representing test pixel linear combination small subset labeled pixels sparse representation classiﬁer gives rather plausible results compared traditional classiﬁers support vector machine recently incorporating additional structured sparsity priors second generation srcs appeared literature reported improve performance hsi. priors based exploiting spatial dependencies neighboring pixels inherent structure dictionary both. paper review compare several structured priors sparserepresentation-based classiﬁcation. also propose structured prior called rank group prior considered modiﬁcation rank prior. furthermore investigate different structured priors improve result classiﬁcation. classiﬁcation pixels labeled classes based spectral characteristics. numerous demands mineralogy agriculture surveillance classiﬁcation task developing rapidly large number techniques proposed tackle problem comparing previous approaches found highly effective computational efﬁciency classiﬁcation results. wide variety svm’s modiﬁcations proposed improve performance. incorporate contextual information classiﬁers others design sparse order pursue sparse decision rule using ℓ-norm regularizer recently proposed solve many computer vision tasks sparsity prior often leads state-of-the-art performance. also applied classiﬁcation relying observation hyperspectral pixels belonging class approximately low-dimensional subspace. order alleviate problem introduced lack sufﬁcient training data proposed homotopy-based src. another solve problem insufﬁcient training data many cases neighboring pixels fall boundary several homogeneous regions neighboring pixels belong several distinct classes different sets sub-dictionary atoms. laplacian sparsity enhances differences sparse coefﬁcient vectors neighboring pixels belong different clusters. introduce weighting matrix characterizes similarity pair pixels within neighborhood. optimization additional laplacian sparsity prior expressed regularization parameters. matrix used characterize similarity among neighboring pixels spectra space. similar pixels possess larger weights therefore enforcing differences corresponding sparse coefﬁcient vectors become smaller similarly allowing difference sparse coefﬁcient vectors dissimilar pixels become larger. therefore laplacian sparsity prior ﬂexible joint sparsity prior always force neighboring pixels common support. paper weighting matrix computed using sparse subspace clustering method note grouping constraint enforced testing pixels instead dictionary atoms different group sparsity. d−/wd−/ normalized symmetric laplacian matrix degree matrix computed rewrite equation prior based assumption pure mixed pixels classes highly correlated represented combination sparse low-rank groups proposed prior takes advantage group sparsity prior enforces sparsity across groups rank prior encourages sparsity within groups using regularizer. following sections investigate roles different structured priors imposed optimization algorithm. starting classical sparsity ℓ-norm prior introduce several different priors experimental results. structured priors discussed joint sparsity laplacian sparsity group sparsity sparse group sparsity lowrank low-rank group prior. pixels within small neighborhood usually consist similar materials. thus spectral characteristics highly correlated. spatial correlation neighboring pixels indirectly incorporated joint sparsity model assuming underlying sparse vectors associated pixels share common sparsity support. consider pixels small neighborhood pixels. represent matrix whose columns correspond pixels spatial neighborhood hyperspectral image. columns represented linear combination dictionary atoms represents sparse matrix. sparse vectors neighboring pixels represented columns share support. therefore sparse matrix nonzero rows. row-sparse matrix recovered solving following lasso problem dictionary inherent group-structured property since composed several class sub-dictionaries i.e. atoms belonging class grouped together form sub-dictionary. sparse representation classify pixels measuring well pixels represented sub-dictionary. therefore would reasonable enforce pixels represented groups atoms instead individual ones. could accomplished encouraging coefﬁcients certain groups active remaining groups inactive. group lasso example uses sparsity prior sums euclidean norm every group coefﬁcients. dominate classiﬁcation performance especially input pixels inherently mixed pixels. group lasso optimization represented sparse representation high coherency dictionary atoms recovered sparse coefﬁcient vectors multiple neighboring pixels could partially different even neighboring pixels highly correlated misclassiﬁcation. mentioned previous section joint sparsity able solve problem enforcing multiple pixels select exactly atoms. however weight usually square root cardinality corresponding group compensate different group sizes. here refers coefﬁcients group. group sparsity easily extended case multiple neighboring pixels extending problem collaborative group lasso formulated fig. sparsity patterns example desired sparsity regions minimization using admm joint sparsity collaborative group sparsity collaborative sparse group sparsity rank sparsity rank group sparsity laplacian sparsity ffs. rank group prior able obtain within-group sparsity minimizing nuclear norm group. furthermore summation nuclear norms empowers proposed prior obtain group sparsity pattern. hence rank group prior able achieve sparsity within across groups using regularization term. evaluate various structured sparsity priors different hyperspectral images example. ﬁrst hyperspectral image assessed indian pine acquired airborne visible/infrared imaging spectrometer generates bands noisy bands removed classiﬁcation. spatial dimension image contains ground-truth classes shown table randomly choose pixels constructing dictionary remaining pixels testing. second image university pavia urban image acquired reﬂective optics system imaging spectrometer contains pixels. generates spectral bands noisy bands removed. nine groundtruth classes interests. image choose pixels constructing dictionary remaining pixels testing shown table iii. example consists different classes class contains pixels. dictionary indian pine. example used evaluate various sparsity patterns generated different structured priors. formulations coefﬁcients within group sparse atoms selected groups could active. sub-dictionary overcomplete necessary enforce sparsity within group. achieve sparsity within groups ℓ-norm regularizer added group lasso written based fact spectra neighboring pixels highly correlated reasonable enforce rank sparsity prior coefﬁcient matrix. rank prior ﬂexible compared joint sparsity prior strictly enforces sparsity. therefore neighboring pixels composed small non-homogeneous regions rank sparsity prior outperforms joint sparsity prior. rank sparse recovery problem well studied stated following lasso problem fig. results indian pine image ground truth training test set. classiﬁcation obtained ℓ-minimization using admm joint sparsity collaborative group sparsity collaborative sparse group sparsity rank sparsity rank group sparsity minimization laplacian sparsity fss. sparse group sparsity rank prior rank group prior corresponding eqs. respectively. parameters different structured priors range performance example visually examined difference desired sparsity regions recovered ones. hyperspectral images classiﬁcation performance evaluated overall accuracy average accuracy coefﬁcient measure test set. structured prior present result highest overall accuracy using cross validation. linear implemented comparison whose parameters fashion experiments joint sparsity group sparsity rank priors solved admm chilasso laplacian prior solved combining sparsa admm. addition conformity previous work laplacian regularized lasso also solved modiﬁed feature sign search method. paper present fair comparison among priors. according optimization technique sort structured priors categories priors solved admm sparsa priors solved fss-based method. ﬁrst table table show methods used implement sparse recovery structured prior. sparsity patterns example shown fig. expected sparsity regions shown fig. y-axis labels dictionary atom index x-axis labels test pixel index. green regions correspond ideal locations active atoms class respectively. nonzero coefﬁcients belong classes shown blue dots. joint sparsity fig. shows clear sparsity pattern many rows mistakenly activated. expected active atoms fig. demonstrate group sparsity patterns. comparing observed atoms deactivated within groups using sgs. rank group prior demonstrates similar sparsity pattern sgs. laplacian sparsity similarity sparse coefﬁcients belong classes clearly visible. table fig. show performance srcs different priors indian pine image. spatial window used since image consists mostly large homogeneous regions. among srcs different priors worst result occurs simple ℓ-admm. joint sparsity prior gives better result rank prior. large areas homogeneous regions image favors joint sparsity model. highest given laplacian sparsity prior high performance partly contributed accurate sparse recovery feature sign search method. outperform among admm-based based methods rank group prior yields smoothest result. computational time various structured priors indian pine image shown table among admm/sparsabased methods take roughly similar time process image require longer time signiﬁcantly impedes computational efﬁciency. results university pavia image shown table window size image since many narrow regions present image. group sparsity prior gives highest among priors optimized admm. rank sparsity prior gives much better result joint sparsity since image contains many small homogeneous regions. laplacian sparsity prior gives highest performance. however difference performance various structured priors quite small. paper reviews different structured sparse priors proposes rank group sparsity prior. using structured priors classiﬁcation results srcs generally improved compared classical sparsity prior. results conﬁrmed rank prior ﬂexible constraint compared joint sparsity prior latter works better large homogeneous regions. imposing group structured prior dictionary always gives higher overall accuracy compared prior. also observed performance determined structured priors also depend corresponding optimization techniques. plaza benediktsson boardman brazile bruzzone camps-valls chanussot fauvel gamba gualtieri marconcini tiltoni trianni recent advances techniques hyperspectral image processing remote sens. envir. vol. sept. camps-valls gomez-chova mu˜noz-mar`ı vila-franc´es calpe-maravilla composite kernels hyperspectral image classiﬁcation ieee geosci. remote sens. lett. vol. jan. gmez-chova camps-valls muoz-mar calpe-maravilla semi-supervised image classication laplacian support vector machines ieee geosci. remote sens. lett. vol. jul. chen nasrabadi tran hyperspectral image classiﬁcation using dictionary-based sparse representation ieee trans. geosci. remote sens. vol. oct. yang fast robust sparse approach hyperspectral data classiﬁcation using labeled samples ieee trans. geosci. remote sens. vol. june hong spectral-spatial constraint hyperspectral image classiﬁcation ieee trans. geosci. remote sens. vol. june s.kim xing tree-guided group lasso multi-task regression structured sparsity icml vol. june sprechmann ramirez sapiro eldar c-hilasso collaborative hierarchical sparse modeling framework ieee trans. signal processing vol. oct. qian zhou hyperspectral image classiﬁcation based structured sparse logistic regression three-dimensional wavelet texture features ieee trans. geosci. remote sens. vol. apr.", "year": 2014}