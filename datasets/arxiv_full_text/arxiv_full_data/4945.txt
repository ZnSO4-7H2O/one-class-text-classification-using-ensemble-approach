{"title": "Towards well-specified semi-supervised model-based classifiers via  structural adaptation", "tag": ["cs.LG", "cs.AI"], "abstract": "Semi-supervised learning plays an important role in large-scale machine learning. Properly using additional unlabeled data (largely available nowadays) often can improve the machine learning accuracy. However, if the machine learning model is misspecified for the underlying true data distribution, the model performance could be seriously jeopardized. This issue is known as model misspecification. To address this issue, we focus on generative models and propose a criterion to detect the onset of model misspecification by measuring the performance difference between models obtained using supervised and semi-supervised learning. Then, we propose to automatically modify the generative models during model training to achieve an unbiased generative model. Rigorous experiments were carried out to evaluate the proposed method using two image classification data sets PASCAL VOC'07 and MIR Flickr. Our proposed method has been demonstrated to outperform a number of state-of-the-art semi-supervised learning approaches for the classification task.", "text": "harbin institute technology shenzhen graduate school shenzhen china department computer science hong kong baptist university hong kong {qq.comwilliamcomp.hkbu.edu.hkzhangxiaofenghit.edu.cn} semi-supervised learning plays important role large-scale machine learning. properly using additional unlabeled data often improve machine learning accuracy. however machine learning model misspeciﬁed underlying true data distribution model performance could seriously jeopardized. issue known model misspeciﬁcation. address issue focus generative models propose criterion detect onset model misspeciﬁcation measuring performance difference models obtained using supervised semi-supervised learning. then propose automatically modify generative models during model training achieve unbiased generative model. rigorous experiments carried evaluate proposed method using image classiﬁcation data sets pascal voc’ flickr. proposed method demonstrated outperform number state-of-the-art semi-supervised learning approaches classiﬁcation task. semi-supervised learning plays important role many real world machine learning applications image classiﬁcation speech recognition categorization cost annotating unlabeled data generally considered high afford. tries make additional unlabeled data together limited amount labeled data enhance model learning accuracy thus gained researchers’ attention however generally believed using additional unlabeled data always guarantee increase model learning accuracy. performance degradation. phenomenon known model misspeciﬁcation safe semisupervised learning essence model misspeciﬁcation safe semi-supervised learning concepts proposed independently despite common goal designing approach performance even worst case still better simple supervised learning approach safe semi-supervised learning existing approaches proposed non-parametric models instance ﬁrst baseline classiﬁer corresponding supervised learners worst cases further optimize performance classiﬁer using proposed method. performance difference classiﬁers learned supervised semi-supervised manners crucial designing algorithms. approaches proposed perspective model parametric modmisspeciﬁcation loog jensen loog mismatch unlabeled data employed generative model often used guide model learning. mixture model adopted represent labeled unlabeled data formulates corresponding bayes plug-in classiﬁer based mixture density functions. performance bayes plug-in classiﬁer seriously relies learnt parameters true ones. performance degradation mainly comes model bias estimation error. unlabeled data could affect model performance theoretically analysed detect onset model misspeciﬁcation solve challenge addressed yet. along line lower bound upper bound performance semi-supervised generative models analyzed authors propose ratio unlabeled data labeled data control model performance. inspired works propose generative model based approach addressing model misspeciﬁcation issue. different aforementioned methods explore detect whether model misspeciﬁcation occurs also propose model modiﬁcation method instead controlling unlabeled data utilized. model misspeciﬁcation problem using generative models section proposed learning approach described section experimental results based image classiﬁcation datasets reported section conclude paper section difﬁculty achieve reliable semi-supervised learning method reported earlier works general believe better model always guaranteed even though additional unlabeled data used model learning. exist number factors affect performance quality training data well classiﬁer researchers considered consequence wrong model assumption practically hard assume perfect generative model without prior knowl underlying challenge viewed having unlabeled data assigned incorrect labels used augment labeled training data set. research works proposed safety-aware using risky unmechanisms restrict labeled earlier disagreement based several safe approaches proposed svms umvp promising experimental results. however fall leverage good generalization capabilities generative models based common many applicaimage classiﬁcation tions representative works addressing model misspeciﬁcation started asymptotic optimal parameters generative models obtained using fully supervised learning fully unsupervised learning respectively. then proved divergence distributions generated generative models small performance less likely affected addition unlabeled data. theoretical analysis provided local global bounds divergence formulated. then proposed unbiased generative deﬁned based unbiased likelihood estimator exponentially controlled ratio number labeled data total number data. given ﬁnite number labeled data inﬁnite number unlabeled data impossible directly detect whether model misspeciﬁcation occurs true data distribution generally unknown. figure gives illustrating example proposed approach. assume model estimation error ignored. figure assumed semisupervised generative model misspeciﬁed performance worst case would converge classiﬁcation loss bound unsup learnt unsupervised manner inﬁnite unlabeled data used. unbiased would converge classiﬁcation loss bound learnt supervised manner. however classiﬁcation loss bounds higher best classiﬁcation loss obtained well-speciﬁed model. therefore minimum model bias learnt sems true data model approximated indicated loss difference i.e. unsup. loss difference approximated distance sems. assumed well-speciﬁed plotted figure classiﬁcation loss bound unbiased well-speciﬁed same i.e. unsup ideal case. consequently model difference sems also small. inspired observation conjecture must exist model misspeciﬁcation sems getting large therefore value determine whether model misspeciﬁcation occurs not. problem formulated following paragraphs. work different follows. focus adaptively modifying structure generative models instead controlling risky data used. furthermore propose criterion determine whether model misspeciﬁcation occurs not. best knowledge neither approaches considered literature. denote training data corresponding label respectively. labeled data unlabeled data denoted respectively. mixed labeled unlabeled data denoted theorem shows semi-supervised learning yields degradation positive probability unlabeled data introduced. proof straightforward given page limitation. optimiztwo distributions acquired. then difference between original unbiased semi-supervised learning deﬁned effectiveness strategy quite tricky seriously relies whether enough labeled data not. becomes risky labeled data few. therefore propose safer strategy follows. generative model θsup denote parameter learnt supervised manner using similarly θsmsup θusmsup θunsup solutions eqs. respectively denoting original models unbiased models unsupervised models. data contains ﬁnite number data points best estimations proposed theorems corollaries theoretically proved correctness previous conjectures illustrated figure well-speciﬁed semisupervised model-based classiﬁer proposed next section. alleviate model misspeciﬁcation problem propose adapt model structure. particular focus kernel k-means model considered special case gaussian mixture models explore mechanisms learn model structure model parameters ensure model well-speciﬁed. although different model complexity measures proposed determine optimal generative models like measures designed primarily density estimation thus cannot directly applied semi-supervised setting address misspeciﬁcation problem. discussed section adopt divergence original unbiased semi-supervised learning guide adaptive model structure learning kernel kmeans model. section presents proposed adaptive model modiﬁcation based semi-supervised kernel k-means model illustrated figure assumed model misspeciﬁed original unbiased converge different classiﬁcation loss bound. difference classiﬁcation loss bounds approximated divergence sems. practically discrete divergence might problematic calculated limited number data points. therefore aggregated classiﬁcation disagreement adopted approximate bound difference. aggregated classiﬁcation disagreement large enough divergence must greater thus exists model misspeciﬁcation according theorem denote bayes plug-in classib ˆθusmsup ﬁers original unbiased respectively. criterion model misspeciﬁcation deﬁned model misspeciﬁcation occurs gradually increase model complexity employed semi-supervised generative model modifying i.e. number components. specially labeled training data label assigned criterion size label larger given class label i.e. classiﬁcation task mapping function label given label deﬁned respectively kernel maps centroids original weighted semisupervised kernel k-means cluster assignments assigned k-th cluster according intuitively speaking proposed approach tracks difference used check whether model misspeciﬁcation occurs not. details proposed askkm illustrated algorithm evaluate adaptive modiﬁcation model structure could affect model performance experiments performed data pascal voc’. binary classiﬁcation task ﬁxed original ubiased model however true data distributions image data contain clusters therefore proposed askkm adaptively modiﬁes model misspeciﬁcation detected experiments. comparison results plotted figure ﬁgure noticed model performance original gradually degrades unbiased better original value although slightly ﬂuctuates almost keeps around degrade. performance askkm slowly increases beginning part curve. value dramatically increases model misspeciﬁcation detected model structure accordingly modiﬁed. then askkm gradually converge addition unlabeled data. converged model performance askkm much better compared semi-supervised generative models. veriﬁes well-speciﬁed semi-supervised models could acquire superior model performance. pascal voc’ flickr pascal voc’ consists images classes annotated tags. among them images selected training rest form test set. flikr contains images tags classes collected flickr website. among them images randomly selected training rest form test set. image feature representations local features three global histogram features well gist used represent image. adopted different distance metrics features different types. particular manhattan distance euclidean distance chisquare distance used respectively histogram features gist features local features. state-ofthe-art algorithms well semi-supervised generative models chosen model comparison including co-training semisupervised addition utilizing labels images original also utilizes tags images. therefore extend proposed askkm utilize information. performance evaluation metric adopt average precision evaluation criterion used pascal competition written animals baby baby* bird bird* car* clouds clouds* dog* female female* ﬂower ﬂower* food indoor lake male male* night night* people people* plant life portrait portrait* river river* sea* structures sunset transport tree tree* water set. compare approach semisupervised generative models also representative semi-supervised learning algorithms co-training. experimental results reported table table table model performance askkm best classes classes information considered. achieves best value class aeroplane bottle. value askkm higher second best model svm. also noticed semi-supervised based algorithms performs better generative model based ones. superior performance proposed approach indicates superiority askkm rest approaches. information considered observed mkl+tag better approaches without integration information consistent intuition. however askkm+tag better mkl+tag classes overall askkm higher mkl+tag. verify effectiveness proposed approach. similar observations could found evaluation results flickr data reported table rigorous experimental results conclude proposed askkm superior state-of-the-art semisupervised learning approaches terms average precision mean average precision. learn reliable semi-supervised models utmost importance. existing works non-parametric based ones generative model based approach seldom studied. paper ﬁrst proposes criterion judge whether model misspeciﬁcatoin occurs not. adaptive semisupervised kernel k-means model proposed model misspeciﬁed problem. last rigorously evaluate proposed askkm image classiﬁcation data sets i.e. pascal voc’ flickr. promising results demonstrate efﬁcacy proposed approach.", "year": 2017}