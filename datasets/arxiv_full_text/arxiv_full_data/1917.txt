{"title": "Towards Multi-Agent Communication-Based Language Learning", "tag": ["cs.CL", "cs.CV", "cs.LG"], "abstract": "We propose an interactive multimodal framework for language learning. Instead of being passively exposed to large amounts of natural text, our learners (implemented as feed-forward neural networks) engage in cooperative referential games starting from a tabula rasa setup, and thus develop their own language from the need to communicate in order to succeed at the game. Preliminary experiments provide promising results, but also suggest that it is important to ensure that agents trained in this way do not develop an adhoc communication code only effective for the game they are playing", "text": "propose interactive multimodal framework language learning. instead passively exposed large amounts natural text learners engage cooperative referential games starting tabula rasa setup thus develop language need communicate order succeed game. preliminary experiments provide promising results also suggest important ensure agents trained develop adhoc communication code effective game playing. ambitious goals develop intelligent conversational agents able communicate humans assist tasks. thus communication interaction core learning process agents; failure integrate communication main building block raises concerns regarding usability. however traditional machine-learning approaches language based static passive mainly supervised regimes computational passive learners receive annotated data observing regularities them discover patterns apply data. great learn general statistical associations interactive communication proceeds active incremental updating speakers’ knowledge states. work blocks-world environment winograd experiencing revival interest language learning frameworks centered around communication interaction recent dialogue-based learning proposal weston similar trends also taking place ﬁelds artiﬁcial intelligence witness revival interest game playing recent ground-breaking results atari alphago following precursors deepblue tdgammon focusing language current approaches communication-based language learning simulate interactive environments diverse ways e.g. agents interacting directly humans scripted agents. approaches exhibit potentially important limitations. human-inthe-loop approach faces serious scalability issues active human intervention obviously required step training. scripted wizard-of-oz environments shift burden heavy manual engineering learning agent designing right behaviour programmed teaching agents. work proposing radically different research program namely multi-agent communication-based language learning within multimodal environment. essence proposal computational agents co-exist co-existence constitutes interactive environment. multi-agent environment agents need collaborate perform task hypothesize developing language production tial games speaker game asked refer visible objects uttering expression. listener sees objects knowledge regarding object speaker asked describe needs identify based speaker’s expression. importantly agents start tabula rasa state. possess form language understanding. prior notion semantics words. meanings assigned words playing game reinforced communication success. thus agents agree sort conceptualization assign word kind interpretation help effectively solve tasks. essentially aligns view wittgenstein language meaning derived usage. report next pilot experiments showing that feasible within multiagent environment learn efﬁcient communication protocols succeeding referential game protocols might necessarily aligned sort semantics exists natural language. interestingly seminal language evolution experiment talking heads steels robots left free interact other developed artiﬁcial language bearing little resemblance natural language. thus anticipate that want move forward research programme grounding agents’ communication natural language crucial since ultimate goal able develop agents capable communication humans. return point section figure schematic representation referential game. agent describe dashed object attribute. agent guess object referring example agents agree referent communicative successful. understanding prerequisites successful communication. note suggesting passive setup abandoned even interactive paradigm large-scale statistical learning expected important e.g. agents discover produce grammatical sentences recognize object categories general even provide generic descriptions present scene. still interaction required many tasks make sense within communicative setup e.g. refer speciﬁc things good question respond several points make proposal attractive. first framework requires minimum human intervention designing agents environment physics rewards although humans still need specify nature tasks agents need perform. computational agents co-exist selforganize freely interacting being encouraged learn order achieve communication. example imagine simple case agent needs object agent possesses starts asking various ways. manages make understood able hold object. sort learning taking place setup based active request information probably foster incremental agreement interaction. observe co-operative game i.e. agents must work together achieve game points. learn provide accurate phrases discriminate object others good interpreting presence objects order point correct one. thus game learn perform referring expression generation reference resolution respectively. visual scenes reducing complexity ﬁrst simulations unlike referitgame work real-world visual scenes. instead construct visual scenes consisting objects depicted images. speciﬁcally current setup consists visual scenes objects referent context. allows control complexity image processing required game itself e.g. referent visually dissimilar context thus easily discriminated. towards created games different datasets controlling type objects involved visual scene. dataset focuses particular aspect referential game. apply number heuristics annotate referent context pair gold attributes acting res. allow conduct various analyses regarding nature semantics agents assign induced attributes. table exempliﬁes instance game different scenarios reports descriptive statistics datasets. referit ﬁrst game scenario uses data derived referitgame general format referitgame contains annotations bounding boxes real images referring expressions produced humans playing game. order create plausible visual situations consisting objects only synthesize scenes pairing referent distractor context comes image bounding initial refetitgame associated pre-process eliminate stop words punctuation spatial information deriving single words attributes. follow heuristic obtain gold attributes acting referring expression given referent context pair selecting words produced describe intended referent context. rationale decision necessary condition achieving successful reference accurately distinguish intended referent object context maximizing quality generated gold attributes disregarded distractor context whose bounding overlapped signiﬁcantly referent’s bounding disregarded distractor contexts full attribute overlap referent thus resulting null referring expression referent context pair. objects control complexity visual scenes attributes maintaining real images created simpler dataset referent context always different objects. list concrete objects ranging across different categories synthesized referent context pairs taking possible combinations objects object sampling image respective imagenet object label entry. re/gold attributes given pair straightforwardly obtained using object name referent. shapes finally introduce third dataset controls complexity real images have allowing referent context differ diverse number attributes exactly like real scenes. following andreas created geometric shapes dataset consisting images contain single object. generate single-object images varying values types attributes follow similar approach referit dataset annotate referent context pairs gold attributes agent players agent agent performing task analogous referring expression generation. unlike traditional research produces phrases words current framework agent learns predict single attribute discriminates referent context. note however attribute meaning pre-deﬁned. instead emerges on-demand usage referential game. particular ideally agent learn associate attributes systematic conﬁgurations lower-level perceptual features present images. current expershape=triangle square circle border color=fuchsia indigo crimson cyan limegreen brown gray horizontal position=up black down vertical position=right left shape size=small medium figure illustrates network architecture model presented images constitute visual scene. assume agents already equipped pre-trained visual system converts pixel input referent context higher-level visual vectors games using referit objects dataset used pretrained vgg-network shapes given nature images different usual imagenet data used train networks trained model. speciﬁcally trained smaller network i.e. alexnet predicting bundles attributes. models second-to-last fully connected layer represent images vectors. visual vectors mapped attribute vectors dimensionality weights r×|v shared across objects. intuitively layer learns attributes active speciﬁc objects. pairwise interactions attribute vectors referent context captured discriminative layer. layer processes attribute units object applying linear transformation weights followed sigmoid activation function ﬁnally derives single value another linear transformation weights producing encodes degree discriminativeness attribute speciﬁc referent. process shared weights across attributes applied attributes derive estimated discriminativeness vector finally discriminativeness vector converted probability distribution player samples attribute acting referring expression. attribute encoded reference vector one-hot like representation passed learnable parameters receive supervised data regarding attributes active pictures regarding attributes used refer referent. supervision regarding goodness attributes given referent context pair comes success interaction agents playing referential game. agent purposes game needs perform task similar reference resolution. given visual input produced attribute choose objects scene intended referent. following reasoning design simple implementation depicted figure presented objects without knowing referent embeds attribute space using weights shared across objects r×|v note case receive direct imageattribute supervision. resulting attribute vectors encode active attributes across objects. following that computes product similarities reference vector attribute vectors objects. intuitively reference vector encodes attribute characterizes referent result similarity high attribute active attribute vector. similarities converted probability distribution image indices index sampled indicating objects chosen referent. learnable parameters general training details parameters agents learned jointly playing game. supervision used communication success i.e. whether agents agreed referent. setup naturally modeled reinforcement learning under framework parameters agents implement policy. executing policy i.e. picks attribute picks image. loss function agents minimizing −ie˜o∼p] objects visual scene conditional probability objects computed given objects attribute produced reward function returns referent. parameter updates done following reinforce update rule mini-batch updates batch-size train datasets iterations. figure communication success across different datasets training epochs. dataset vary number attributes available vocabulary agents. note best viewed color. results pilot experiments ascertain whether proposal result agents learn play game correctly. moreover given agents start clean state worth looking nature induced semantics attributes. simply communication-based learning enough allow agents attributes reﬂects high-level understanding images? agents learn develop communication protocol within referential game? figure shows communication success performance i.e. often intended referent guessed correctly overall agents able come communication protocol allowing solve task takes approximately iterations start communicating effectively. expected agents knowledge game rules refer things must induce observing rewards receive. moreover fewer attributes vocabulary translates faster necessarily better learning. sanity check restricted vocabulary attributes only. case agents also came close solving task although without approaching performance tendency observed across datasets. ﬁrst glance might seem suspicious; even humans language ﬂexibly polysemy however closely inspected used attributes became clear agent sense cheating. instead communicating high-level semantics agents agreed exploit attributes communicate low-level embedding properties referent context pairs might seem strategies fact best order communicate efﬁciently attributes. resembles so-called conceptual pacts humans form make conversation efﬁcient i.e. mutually agreeing using unconventional semantics refer things still words discovered ad-hoc meaning generalize useful task beyond speciﬁcs game would want agents learn them. thus turn analysis semantic nature induced attributes agents larger vocabulary available attributes learn general meanings corresponding high-level visual properties cat. nature induced attributes? revealing semantics assigned induced attributes trivial. tested whether semantics induced attributes align semantics referring expressions expressed gold attributes. focused objects shapes datasets relatively small number attributes trained agents using attribute votable proportion referentially inconsistent attributes i.e. across different datasets different attribute vocabulary size smaller values reﬂect consistent use. ages referent context sets normalized times appears either. ideally value happens never case induced attribute activated image referent context slot. table reports proportion induced active attributes across datasets expected communicating attributes only agents seem using semantically meaningful since referential consistency violated. however ought mention also possible agents case learned attributes relative imagine pair image mona lisa image frowning face context image broadly smiling face. would acceptable smiling denote mona lisa ﬁrst pair would also possible refer overtly smiling face second case mona lisa smiley frowning face deﬁnitely less fully smiling face case datasets attributes referential consistency largely respected. finally consider third assess degree induced attributes reﬂect intuitive semantic properties images. hypothesis that induced attributes used coherently across visually similar referents reﬂect properties typical class shared referents experiment focus objects dataset annotated gold attributes denoting objects depicted pictures gold attribute construct vector records often induced attribute used referent context pair annotated essentially representing gold attributes vector space cabulary size respectively. training assign induced attribute gold attribute appears often annotations referent context pairs predicted enforcing mapping tendency make available attributes vocabulary thus either using attributes polysemous assigning semantics different gold attributes encode. example plot figure inferred alignment induced gold attributes shapes dataset. irrespective exact interpretation attributes meanings induced within referential framework consistent across referent context pairs. example agent used word refer object context cannot used refer object context since also property latter. however cheating approach reported -attribute case attribute used communicate whether low-level feature higher referent context would respect consistency constraint might higher value relevant feature compared lower respect capture this devised measure termed referential inconsistency speciﬁcally image compute containing induced attributes activated referent slot context slot. referential inconsistency attribute computed induced attributes dimensions. compute pairwise cosine similarities gold attributes vector space plotted figure structure similarity matrix. however organize rows columns similarity matrix figure down objects category cluster together pattern along diagonal starts emerge suggesting induced attributes reﬂect least degree similarity exists objects category. presented proposal developing intelligent agents language capabilities breaks away current passive supervised regimes. agents co-exist able interact other. proposed framework restrict number agents role games i.e. envision community agents interact perform different tasks taking turns them requiring either co-operate antagonize minmax sort zero-sum games agents test case considered basic communication learning refer things designed grounded cooperative task takes form referential games played agents. ﬁrst experiments encouraging revealed essential ensure agents drift language instead evolve aligned natural languages. thus inspired success alphago combines passive learning interactive learning believe crucial combine dynamic interactive learning static statistical learning patterns association something ensure grounding communication natural language. plan move along similar direction introducing agents multi-tasking. example could expose large collections texts train language modeling task requiring manual annotation basic word associations patterns learned. similarly could trained image retrieval task basic concept recognition naming capabilities acquired i.e. associating phonetic string instances cats. still agents would trained playing game producing good referring expressions task depends predominantly success communication margaret mitchell kees deemter ehud reiter. natural reference proceedings objects visual domain. international natural language generation conference pages association computational linguistics. terry winograd. procedures representation data computer program understanding natural language. technical report massachusetts institute technology. koray kavukcuoglu david silver andrei rusu joel veness marc bellemare alex graves martin riedmiller andreas fidjeland georg ostrovski stig petersen charles beattie amir sadik ioannis antonoglou helen king dharshan kumaran daan wierstra shane legg demis hassabis. human-level control deep reinforcement learning. nature david silver huang christopher maddison arthur guez laurent sifre george driessche julian schrittwieser ioannis antonoglou veda panneershelvam marc lanctot sander dieleman dominik grewe john nham kalchbrenner ilya sutskever timothy lillicrap madeleine leach koray kavukcuoglu thore graepel demis hassabis. mastering game deep neural networks tree search. nature", "year": 2016}