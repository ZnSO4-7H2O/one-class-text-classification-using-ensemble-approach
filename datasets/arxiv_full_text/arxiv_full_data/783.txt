{"title": "Bounded Rational Decision-Making in Feedforward Neural Networks", "tag": ["cs.AI", "cs.LG", "cs.NE"], "abstract": "Bounded rational decision-makers transform sensory input into motor output under limited computational resources. Mathematically, such decision-makers can be modeled as information-theoretic channels with limited transmission rate. Here, we apply this formalism for the first time to multilayer feedforward neural networks. We derive synaptic weight update rules for two scenarios, where either each neuron is considered as a bounded rational decision-maker or the network as a whole. In the update rules, bounded rationality translates into information-theoretically motivated types of regularization in weight space. In experiments on the MNIST benchmark classification task for handwritten digits, we show that such information-theoretic regularization successfully prevents overfitting across different architectures and attains results that are competitive with other recent techniques like dropout, dropconnect and Bayes by backprop, for both ordinary and convolutional neural networks.", "text": "transform bounded rational decision-makers sensory input motor output limited computational resources. mathematically decision-makers modeled informationtheoretic channels limited transmission rate. here apply formalism ﬁrst time multilayer feedforward neural networks. derive synaptic weight update rules scenarios either neuron considered bounded rational decision-maker network whole. update rules bounded rationality translates information-theoretically motivated types regularization weight space. experiments mnist benchmark classiﬁcation task handwritten digits show information-theoretic regularization successfully prevents overﬁtting across different architectures attains results competitive recent techniques like dropout dropconnect bayes backprop ordinary convolutional neural networks. intelligent systems biology excel ability ﬂexibly adapt behavior changing environments maximize beneﬁt. order understand biological intelligence design artiﬁcial intelligent systems central goal analyze adaptive behavior theoretical point view. formal framework achieve goal decision theory. important idea originating foundations decision theory principle maximum expected utility according principle maximum expected utility intelligent agent formalized decision-maker chooses optimal actions maximize expected beneﬁt outcome agent’s beneﬁt quantiﬁed utility function. fundamental problem maximum expected utility principle take account computational resources necessary identify optimal actions— example computationally prohibitive compute optimal chess move vast amount potential board conﬁgurations. taking computational resources account study optimal decisionmaking information-processing constraints study information-theoretic model bounded rational decision-making precursors economic literature closely related recent advances harnessing information theory machine learning perception-action systems previously information-theoretic bounded rationality model applied derive synaptic weight update rule single reward-maximizing spiking neuron shown neuron tries keep ﬁring rate close average ﬁring rate ultimately leads economizing synaptic weights. mathematically economizing equivalent regularization prevents synaptic weights growing without bounds. bounded rational weight update rule furthermore generalizes synaptic weight update rule ordinary reward-maximizing spiking neuron presented example current work extend framework informationtheoretic bounded rationality networks neurons restrict start deterministic settings. particular investigate scenarios either single neuron considered bounded rational decisionmaker network whole. remainder manuscript organized follows. section explain information-theoretic bounded rationality model use. section apply model derive bounded rational synaptic weight update rules single neurons networks neurons. section demonstrate regularizing effect bounded rational weight update rules mnist benchmark classiﬁcation task. section conclude. respectively maxy represents action globally maximizes utility function. decision-maker without computational resources sticks prior strategy whereas decisionmaker access arbitrarily large amount resources always picks globally optimal action recovers thus fully rational decision-maker. face multiple contexts fully rational decisionmaking requires optimal action environment optimality deﬁned utility function bounded rational decision-making multiple contexts means compute multiple strategies expressed conditional probability distributions limited computational resources. limited computational resources modeled upper bound expected kullback-leibler divergence dkl||p)p strategies common prior averaged possible environments described distribution resulting optimization problem formalized governs trade-off expected shown utility informational cost. economic prior given marginal disx marginal distribution minimizes expected kullbackleibler divergence given conditional distributions p—see case expected kullbackleibler divergence becomes identical mutual information environment action accordingly bounded rational decision-making formalized following objective decision-maker faced task choose optimal action actions. action associated given task-speciﬁc utility value fully rational decision-maker picks action globally maximizes utility function maxy assuming notational simplicity global maximum unique. limited computational resources however decision-maker able identify globally optimal action leads question limited computational resources quantiﬁed. general decision-maker’s behavior expressed probability distribution actions basic idea information-theoretic bounded rationality changes probability distributions costly necessitate computational resources. precisely computational resources quantiﬁed informational cost evoked changing prior probabilistic strategy posterior probabilistic strategy deliberation process preceding choice. mathematically informational cost given kullback-leibler divergence dkl||p) prior posterior strategy computational resources modeled upper bound accordingly bounded rational decision-making formalized following free energy objective controls trade-off expected utility informational cost. note upper bound imposed kullback-leibler divergence determines value choosing value hence equivalent choosing value therefore assume parameterized form strategy decision-maker draw samples given sample environment optimize rate distortion objective equation help gradient ascent —also referred policy gradient reinforcement learning literature gradient ascent requires compute derivative objective function respect strategy parameters update parameters according rule time step denotes learning rate note update rule equation requires computation expected value expected value approximated environmentaction samples either batch online manner. rest paper assume online update rule agent adapts behavior instantaneously after interaction environment response immediate reward signal typical reinforcement learning. informally rate distortion model bounded rational decision-making translates speciﬁc form regularization penalizes deviations decision-maker’s instantaneous strategy given current environment decision-maker’s mean strategy averaged possible environments. previously equation applied single spiking neuron stochastic here generalize approach deterministic networks neurons neural input neural output reward signal derive parameter update rules style equation allow adsynaptic weights online fashion. particular investigate scenarios either single neuron considered bounded rational decision-maker network whole. rate distortion objective equation concave respect unfortunately closed analytic form solution. however possible express optimal solution self-consistent equations self-consistent equations solved replacing initial arbitrary distribution iterating equations alternating fashion. procedure known blahut-arimoto algorithm guaranteed converge global optimum presupposed assign zero probability mass limit cases none inﬁnite resources optimal strategy equations expressed closed analytic form maxy refers action globally maximizes expected utility averaged possible environments refers action globally maximizes utility particular environment x—assuming notational simplicity global maxima unique cases. absence computational resources decision-maker chooses strategy matter environment encountered order minimize deviation conditional strategies average strategy decision-maker chooses however strategy maximizes average expected utility. case access arbitrarily large amount computational resources decision-maker picks best action environment recovers thus fully rational decision-maker. computing optimal solution rate distortion problem equation help equations blahut-arimoto algorithm severe drawbacks. first requires compute store conditional strategies marginal strategy explicitly prohibitive large environment action spaces. second requires decisionmaker able evaluate utility function arbitrary denotes difference utility ﬁring ﬁring given conditional marginal strategies initialized roughly equal refers initial value hyperparameter determines fast decisionmaker’s strategy converges. high value implies little computational resources quick convergence fact conditional marginal strategies initially alequal. opposite value indicating vast computational resources allows decision-maker optimal strategy environment conditional marginal strategies deviate substantially. real-valued column vector indicating presynaptic ﬁring rates monotonically increasing function. similar fashion neuron’s mean ﬁring behavior given φξ)p refers neuron’s mean ﬁring rate averaged possible presynaptic ﬁring rates accordance previous section mean ﬁring rate conveniently approximated online manner exponential window time constant interpreted environmental context neuron’s output interpreted action variable. neuron’s parameterized strategy corresponds ﬁring behavior given binary variable reﬂecting neuron’s current ﬁring state binary column vector representing neuron’s current presynaptic input real-valued column vector representing strength presynaptic weights. monotonically increasing function denoting neuron’s current ﬁring probability. similar neuron’s mean ﬁring behavior expressed ρx)p denotes neuron’s mean ﬁring probability averaged possible inputs mean ﬁring probability easily estimated help exponential window online manner according assuming task-speciﬁc utility function determining neuron’s instantaneous reward assuming furthermore neuron’s output impact presynaptic input next time step bounded rational neuron thought optimizing rate distortion objective according equation gradient ascent outlined section equation applicable using quantities derivation equation found section assuming rate-dependent utility function deterministic neuron interpreted bounded rational decision-maker similar equation folfocusing individual neurons bounded rational decision-makers previous section also possible interpret entire feedforward multilayer perceptron bounded rational decision-maker. allow interpretation consider following network’s output rates event probabilities categorical distribution importantly categorical distribution considered bounded rational strategy denotes derivative utility function respect neuron’s ﬁring rate. solution equation requires derivative terms respect derivative straightforward information rate trivial explained here consider feedforward multilayer perceptron imagined consist individual bounded rational deterministic neurons described previous section. assuming neurons maximizing global utility function time minimizing local mutual information rate neuron interpreted solving deterministic rate distortion objective utility function shared among neurons mutual information cost neuron-speciﬁc refer presynaptic weight vector presynaptic ﬁring rates current ﬁring state neuron respectively denotes entirety weights whole neural network. global utility expressed function network’s input rates network’s output rates mnist test consisting examples. simulations used network hidden layers rectiﬁed linear units layer softmax units implemented torch chose optimization criterion negative cross entropy class labels network output order assess robustness regularizers performed experiments networks different architectures. particular used network architectures hidden layers varied number neurons hidden layer. performed gradient ascent learning rate updating weights online training example. trained networks epochs epoch corresponded sweep entire training set. epoch learning rate decayed according +t·η denotes current epoch decay parameter. weights updated momentum according randomly ini∆wn tialized range )−.; )−.) help uniform distribution beginning simulation denotes number inputs neuron non-input neuron additional bias weight initialized presynaptic weights neuron. rate distortion regularization required furthermore compute mean ﬁring rate individual neurons exponential window online fashion time constant order ensure numerical stability using rate distortion regularization terms form φξn) weight update rules computed according max{φξn) max{ optimal values rate distortion trade-off parameter conducted pilot studies small networks comprising neurons hidden layer trained epochs mnist training according aforementioned training scheme subsequently evaluated mnist test set. might induce overﬁtting test small networks used β-values heuristic larger architectures tune hyperparameter further. global rate distortion regularization best test error achieved around although grdi seems behave rather robust range —see middle denotes derivative respect denotes weight neuron derivative utility function respect ﬁring rate output neuron. equation requires differentiate terms respect derivative expected utility straightforward derivative mutual information explained section note derivative rate distortion objective takes convenient form easily computed extending ordinary backpropagation ordinary backpropagation quantity propagated backwards network. core algorithm ordinary backpropagation employed simply replacing derivative computing genutility function eral quantity simulations applied types rate distortion regularization mnist benchmark classiﬁcation task. particular investigated information-theoretically motivated regularization subserves generalization. trained classiﬁcation mnist training consisting grayscale images handwritten digits tested generalization left panel figure local rate distortion regularization best test error achieved ordinary utility maximization without regularization—see middle right panel. however measuring performance terms expected utility test lrdi achieved signiﬁcant performance increase compared ordinary utility maximization range —see upper right panel. ﬁnal studies could furthermore ascertain lrdi performs reasonably well larger architectures achieved test error compared ordinary utility maximization increasing number units hidden layer results ﬁnal studies trained networks epochs illustrated table compares rate distortion regularization techniques literature different network architectures comprising hidden layers. seen local global rate distortion regularization attain results permutation invariant setting competitive recent techniques like dropout dropconnect bayes backprop furthermore shown rate distortion regularizers lead decreasing generalization error increasing number neurons hidden layers demonstrates successful prevention overﬁtting. successful prevention overﬁtting additionally demonstrated applying global rate distortion regularization convolutional neural network architecture according —see section —attaining error without tuning hyperparameters result also competitive recent techniques permutation non-invariant setting— compare dropout dropconnect line preprocessed input whitening added max-norm regularizer limit size presynaptic weight vectors lower panels figure show development test error epochs rate distortion regularizers compared ordinary utility maximization withregularization different network architectures used permutation invariant setting. seen global variant regularizer leads signiﬁcant increase performance across different architectures demonstrated separate clusters trajectories. addition grdi also leads faster learning trajectories lower left panel figure decrease signiﬁcantly faster black trajectories ﬁrst epochs training. local variant regularizer performance improvements less prominent compared global variant. previously synaptic weight update rule single reward-maximizing spiking neuron devised neuron interpreted bounded rational decisionmaker limited computational resources help rate distortion theory shown bounded rational weight update rule leads efﬁcient regularization preventing synaptic weights growing without bounds. current work extend results deterministic neurons neural networks. mnist benchmark classiﬁcation task demonstrated regularizing effect approach networks successfully prevented overﬁtting. results robust conducted experiments different network architectures achieving performance competitive recent techniques like dropout dropconnect bayes backprop ordinary convolutional networks. strength rate distortion regularization principled approach example dropout dropconnect applied general artiﬁcial agents parameterized policies neural networks. parameterized policies optimize rate distortion objective previously applied unsupervised density estimation tasks autoencoder networks current work extends kind approach theory reinforcement supervised learning feedforward neural networks also provides evidence approach scales well large data sets. figure performance mnist permutation invariant setup. left column refers analyses global rate distortion regularization right column analyses local rate distortion regularization upper middle panels show results pilot studies smallest network architecture. trajectories upper panels illustrate expected utility epochs training different values β—black solid lines reﬂect expected utility training solid lines reﬂect expected utility test dashed horizontal lines reﬂect expected utility test ordinary utility maximization middle panels show classiﬁcation errors instead utility values. grdi case negative cross entropy drops sharply larger betas regularization drives output rates towards ﬂatter distribution even though mode distribution maintained allows robust performance terms classiﬁcation error. lower panels show results ﬁnal simulations four different network architectures ﬁxed β-values. plots compare development test error epochs ordinary utility maximization rate distortion regularization trajectory corresponds four different network architectures.", "year": 2016}