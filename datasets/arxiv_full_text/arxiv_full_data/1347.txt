{"title": "Multimodal Deep Learning for Robust RGB-D Object Recognition", "tag": ["cs.CV", "cs.LG", "cs.NE", "cs.RO"], "abstract": "Robust object recognition is a crucial ingredient of many, if not all, real-world robotics applications. This paper leverages recent progress on Convolutional Neural Networks (CNNs) and proposes a novel RGB-D architecture for object recognition. Our architecture is composed of two separate CNN processing streams - one for each modality - which are consecutively combined with a late fusion network. We focus on learning with imperfect sensor data, a typical problem in real-world robotics tasks. For accurate learning, we introduce a multi-stage training methodology and two crucial ingredients for handling depth data with CNNs. The first, an effective encoding of depth information for CNNs that enables learning without the need for large depth datasets. The second, a data augmentation scheme for robust learning with depth images by corrupting them with realistic noise patterns. We present state-of-the-art results on the RGB-D object dataset and show recognition in challenging RGB-D real-world noisy settings.", "text": "fig. two-stream convolutional neural network rgbobject recognition. input network depth image pair size stream consists convolutional layers fully connected layers. streams converge fully connected layer softmax classiﬁer classiﬁcation. initialize depth stream network weights network pre-trained imagenet dataset initializing network pre-trained imagenet network straight-forward using network processing depth data not. ideally would want directly train network recognition depth data without pre-training different modality which however infeasible lack large scale labeled depth datasets. lack labeled training data pre-training phase depth-modality leveraging data becomes importance. therefore propose depth data encoding enable re-use cnns trained imagenet recognition depth data. intuition proved experimentally simply encode depth image rendered image spreading information contained depth data three channels using standard recongition. real-world environments objects often subject occlusions sensor noise. paper propose data augmentation technique depth data used robust training. augment available training examples corrupting depth data missing data patterns sampled real-world environments. using techniques system learn robust depth features implicitly weight importance modalities. abstract— robust object recognition crucial ingredient many real-world robotics applications. paper leverages recent progress convolutional neural networks proposes novel rgb-d architecture object recognition. architecture composed separate processing streams modality consecutively combined late fusion network. focus learning imperfect sensor data typical problem real-world robotics tasks. accurate learning introduce multi-stage training methodology crucial ingredients handling depth data cnns. ﬁrst effective encoding depth information cnns enables learning without need large depth datasets. second data augmentation scheme robust learning depth images corrupting realistic noise patterns. present stateof-the-art results rgb-d object dataset show recognition challenging rgb-d real-world noisy settings. rgb-d object recognition challenging task core many applications robotics indoor outdoor. nowadays rgb-d sensors ubiquitous many robotic systems. inexpensive widely supported open source software require complicated hardware provide unique sensing capabilities. compared data provides information appearance texture depth data contains additional information object shape invariant lighting color variations. paper propose method object recognition rgb-d data. particular focus making recognition robust imperfect sensor data. scenario typical many robotics tasks. approach builds recent advances machine learning computer vision community. speciﬁcally extend classical convolutional neural network networks recently shown remarkably successful recognition images domain rgb-d data. architecture depicted fig. consists convolutional network streams operating color depth information respectively. network automatically learns combine processing streams late fusion approach. architecture bears similarity recent multi-stream approaches training individual stream networks well combined architecture follows stage-wise approach. start separately training networks modality followed third training stage streams jointly ﬁnetuned together fusion network performs ﬁnal authors department computer science university freiburg germany. work partially funded priority programm autonomous learning {eitel springj riedmiller spinello burgard}cs.uni-freiburg.de tested method support claims ﬁrst report rgb-d recognition accuracy robustness respect real-world noise. ﬁrst show work outperforms current state rgb-d object dataset second show data augmentation approach improves object recognition accuracy challenging real-world noisy environment using rgb-d scenes dataset approach related large body work convolutional neural networks object recognition well applications computer vision techniques problem recognition rgb-d data. although comprehensive review literature cnns object recognition scope paper brieﬂy highlight connections differences approach existing work focus recent literature. among many successful algorithms rgb-d object recognition large portion still relies hand designed features sift combination multiple shape features depth channel however following success many computer vision problems unsupervised feature learning methods recently extended rgb-d recognition settings. blum proposed rgb-d descriptor relies k-means based feature learning approach. recently proposed hierarchical matching pursuit hierarchical sparsecoding method learn features multiple channel input. different approach pursued socher relies combining convolutional ﬁlters recursive neural network recognition architecture. asif report improved recognition performance using cascade random forest classiﬁers fused hierarchical manner. finally recent independent work schwarz proposed features extracted cnns pre-trained imagenet rgb-d object recognition. also make two-stream network ﬁne-tune rgb-d recognition rather pre-trained network interestingly also discovered simple colorization methods depth competitive involved preprocessing techniques. contrast work achieves higher accuracy training fusion end-to-end mapping pixels object classes supervised manner features learned therefore construction discriminative task hand. using cnns trained object recognition long history computer vision machine learning. known yield good results supervised image classiﬁcation tasks mnist long time recently shown outperform classical methods large scale image classiﬁcation tasks object detection semantic segmentation also produce features transfer tasks recent success story made possible optimized implementations majority work deep learning focused images recent research also directed towards using depth information improving scene labeling object detection among them work similar object detection gupta introduces generalized method r-cnn detector applied depth data. speciﬁcally large cnns already trained images also extract features depth data encoding depth information three channels speciﬁcally encode pixel height ground horizontal disparity pixelwise angle surface normal gravity direction. fusion network architecture shares similarities work usage pre-trained networks images. method differs encoding depth color image data fusion approach taken combine information modalities. encoding step propose encoding method depth images rely complicated preprocessing results improved performance compared encoding. accomplish sensor fusion introduce additional layers pipeline allowing automatically learn fusion strategy recognition task contrast simply training linear classiﬁer features extracted modalities. multi-stream architectures also used tasks action recognition detection image retrieval interesting recent overview different network architectures fusing depth image information given saxena there authors compared different models multimodal learning early fusion input image concatenated existing image channels processed alongside; approach denote late fusion features trained separately modality merged higher layers; combining early late fusion; concluding late fusion combined approach perform best problem grasp detection. compared work model similar late fusion approach widely differs training saxena layer-wise unsupervised training approach scale overview architecture given fig. network consists streams processing depth data independently combined late fusion approach. stream consists deep pretrained object classiﬁcation imagenet database implementation krizhevsky reason behind starting data augmentation). ﬁrst processing step consists scaling images appropriate image size. simplest approach achieve image warping directly rescaling original image required image dimensions disregarding original object ratio. depicted fig. found experiments process detrimental object recognition performance effect attribute loss shape information therefore devise different preprocessing approach scale longest side original image pixels resulting sized image. tile borders longest side along axis shorter side. resulting depth image shows artiﬁcial context around object borders scaling operation applied depth images. images directly used inputs cnns processing step rescaled depth data requires additional steps. realize this recall network trained imagenet trained recognize objects images follow speciﬁc input distribution incompatible data coming depth sensor essentially encodes distance objects sensor. nonetheless looking typical depth image household object scene conclude many features qualitatively appear images edges corners shaded regions also visible e.g. grayscale rendering depth data. realization previously idea simply using rendered version recorded depth data input cnns trained imagenet compare different encoding strategies rendering depth images experiments. prevalent encodings rendering depth data grayscale replicating grayscale values three channels required network input; using surface normals dimension normal vector corresponds channel resulting image. involved method called encoding encodes three channels height ground horizontal disparity pixelwise angle surface normal gravity direction. propose fourth effective computationally inexpensive encoding depth color images found outperform encoding object recognition. method ﬁrst normalizes depth values then apply colormap given image transforms input single three channel image pixel depth image size distance color values ranging green blue essenfig. cnns require ﬁxed size input. instead widely used image warping approach method preserves shape information ratio objects. rescale longer side create additional image context tiling pixels border longer side e.g. assume depth image already transformed three channels using colorization method. pre-trained network enable training large millions parameters using limited training data available washington rgb-d object dataset recent discussion). ﬁrst pre-process data modalities fully leverage imagenet pre-training. then train multimodal stage-wise manner. ﬁne-tune parameters individual stream network classiﬁcation target data proceed ﬁnal training stage jointly train parameters fusion network. different steps outlined following sections. fully leverage power cnns pre-trained imagenet pre-process depth input data compatible kind original imagenet input. speciﬁcally reference implementation caffenet expects pixel images input typically randomly cropped larger images sensor noise. depth sensors especially affected non-negligible amount noise setups. mainly fact reﬂective properties materials well coating often result missing depth information. example noisy depth data depicted fig. contrast relatively clean training data washington rgb-d object dataset depicted scene contains considerable amounts missing depth values partial occlusions achieve robustness unpredictable factors propose data augmentation scheme generates noised training examples training tailored speciﬁcally robust classiﬁcation depth data. approach utilizes observation noise depth data often shows characteristic pattern appears object boundaries object surfaces. concretely sampled tially distributing depth information three channels. edges three channels often correspond interesting object boundaries. since network designed images colorization procedure provides enough common structure depth image learn suitable feature representations labeled data available training multimodal cnn; denoting pre-processed depth image respectively corresponding image label one-hot encoding i.e. vector dimensionality position denoting image label. train model using three-stage approach ﬁrst training stream networks individually followed joint ﬁne-tuning stage. training stream networks ﬁrst proceed training individual stream networks representation extracted last fully connected layer caffenet parameters applied image analogously representation depth image. assume parameters initialized copying parameters caffenet trained imagenet dataset. train individual stream network placing randomly initialized softmax classiﬁcation layer minimizing negative likelihood training data. depth image stream network solve weights softmax layer mapping softmax function given softmax exp/z loss computed training stream network performed analogous optimization. training resulting networks used perform separate classiﬁcation modality. training fusion network individual stream networks trained discard softmax weights concatenate ﬁne-tuned last layer responses feed additional fusion stream gd]; parameters fusion network ends softmax classiﬁcation layer. complete setup depicted fig. layers concatenated merge fusion network analogous fusion network therefore trained jointly optimizing parameters minimize negative representative noise patterns occur recording typical indoor scenes kinect sensor. sampling noise patterns used rgb-d slam dataset first extract random noise patches size different sequences varying positions divide groups based number missing depth readings contain. noise patches binary masks patterns. randomly sample pairs noise patches different groups randomly added subtracted optionally inverted produce ﬁnal noise mask pattern. repeat process collected noise patterns total. examples resulting noise patterns application training examples shown fig. training depth network artiﬁcial noise patterns proceeds minimizing objective equation depth sample randomly replaced noised variant probability formally evaluate multimodal network architecture washington rgb-d object dataset consists household objects belonging different classes. additional experiment evaluate robustness approach classiﬁcation real-world environments considered classiﬁcation objects rgb-d scenes dataset whose class distribution partially overlaps rgb-d object dataset. experiments performed using publicly available caffe framework described previously caffenet basis fusion network. consists convolutional layers followed fully connected layers softmax classiﬁcation layer. rectiﬁed linear units used ﬁnal classiﬁcation layer. initialized stream networks weights biases ﬁrst eight layers pre-trained network discarding softmax layer. proceeded stage-wise training. ﬁrst stage parameters layers adapted using ﬁxed learning rate schedule second stage experimented ﬁne-tuning weights found ﬁxing individual stream networks training fusion part network resulted best performance. number training iterations chosen based validation performance training validation split table comparisons fusion network approaches reported rgb-d dataset. results recognition accuracy percent. multi-modal outperforms previous approaches. preliminary experiment. ﬁxed momentum value mini-batch size used experiments stated otherwise. also adopted common data augmentation practices randomly cropping sub-images larger input examples perform random horizontal ﬂipping. training single network stream takes hours using nvidia graphics card. washington rgb-d object dataset consists rgb-d images containing household objects organized different classes total instances classes captured three different viewpoint angles. evaluation every frame subsampled. evaluate method challenging category recognition task using cross-validation splits split consists roughly training images images testing. object class instance left testing training performed remaining instances. test time task assign correct class label previously unseen object instance. table shows average accuracy multi-modal comparison best results reported literature. best multi-modal using jet-colorization yields overall accuracy using depth best knowledge highest accuracy reported dataset date. also report results combining computationally intensive network seen table result increased performance. depth colorization method slightly outperforms fusion network computationally cheaper. overall experiments show pretrained adapted recognition depth data using depth colorization method. apart results reported table also experimented different fusion architectures. speciﬁcally performance slightly drops intermediate fusion layer removed network. adding additional fusion layers table comparison domain adapted depth network baseline six-class recognition results rgb-d scenes dataset contains everyday objects real-world environments. finally conducted experiments compare different depth encoding methods described fig. rescaling images proposed preprocessing method described fig. tested different depth encoding. scenarios considered training scratch using single channel depth images encoding method ﬁne-tuning network using procedure described section iii-b.. training scratch initial learning rate changed iterations thus stopped iterations. training iterations improve accuracy. results presented table clear training network scratch solely rgb-d dataset inferior ﬁne-tuning. latter setting results suggest simplest encoding method performs considerably worse three methods. among encodings surface normals encoding require additional image preprocessing meanwhile colorizing depth using depthjet encoding negligible computational overhead. potential reason encoding underperforms setup objects captured turntable height ground. height channel used encoding therefore encode additional information solving classiﬁcation task. experiment using surface normals yields slightly better performance depth-jet encoding. therefore tested fusion architecture splits rgbobject dataset using surface normals encoding improve performance. speciﬁcally recognition accuracy test-set comparable reported results table introduce novel multimodal neural network architecture rgb-d object recognition achieves state performance rgb-d object dataset method consists two-stream convolutional neural network learn fuse information depth automatically classiﬁcation. make effective encoding method depth image data allows leverage large cnns trained object recognition imagenet dataset. present novel effectiveness depth augmentation technique real world scenes performed additional recognition experiments challenging rgb-d scenes dataset. dataset consists object classes large amount depth images subjected noise. experiment trained single-stream depthnetworks using object dataset used scenes dataset testing. further assume groundtruth bounding given order report recognition performance. ﬁrst baseline network trained following procedure described section iii-b. total number labels second network trained making depth augmentation outlined iii-c. results experiment shown table reports recognition accuracy object class averaged eight video sequences. evident table adapted network trained data augmentation outperforms baseline model classes clearly indicating additional domain adaptation necessary robust recognition real world scenes. however classes beneﬁt noise aware training others kitchen scene depicted fig. gives visual intuition result. hand objects often present noisy object boundaries surfaces thus show improved recognition performance using adapted approach. hand small objects often captured lying table either less noisy small hence susceptible completely erased noise data augmentation approach. fig. shows several exemplary noisy depth images test correctly classiﬁed domain-adapted network baseline network labels incorrectly. also tested effect different input image rescaling techniques previously described fig. setting. shown left column table standard image warping performs poorly supports intuition shape information girshick donahue darrell malik rich feature hierarchies accurate object detection semantic segmentation ieee int. conf. computer vision pattern recognition schwarz schulz behnke rgb-d object recognition pose estimation based pre-trained convolutional neural network features proc. ieee int. conf. robotics automation socher huval bhat manning convolutional-recursive deep learning object classiﬁcation advances neural information processing systems srivastava salakhutdinov multimodal learning deep boltzmann machines advances neural information processing systems sturm engelhard endres burgard cremers benchmark evaluation rgb-d slam systems proc. ieee/rsj int. conf. intelligent robots systems yosinski clune bengio lipson transferable features deep neural networks? advances neural information processing systems depth data augmentation aims improving recognition noisy real-world setups situations typical many robotics scenarios. present extensive experimental results conﬁrm method accurate able learn rich features domains. also show robust object recognition realworld environments prove noiseaware training effective improves recognition accuracy rgb-d scenes dataset asif bennamoun sohel efﬁcient rgb-d object categorization using cascaded ensembles randomized decision trees proc. ieee int. conf. robotics automation azizpour razavian sullivan maki carlsson from generic speciﬁc deep representations visual recognition arxiv preprint arxiv.", "year": 2015}