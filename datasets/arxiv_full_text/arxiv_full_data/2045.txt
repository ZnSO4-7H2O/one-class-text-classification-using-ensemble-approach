{"title": "Dynamic Teaching in Sequential Decision Making Environments", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "We describe theoretical bounds and a practical algorithm for teaching a model by demonstration in a sequential decision making environment. Unlike previous efforts that have optimized learners that watch a teacher demonstrate a static policy, we focus on the teacher as a decision maker who can dynamically choose different policies to teach different parts of the environment. We develop several teaching frameworks based on previously defined supervised protocols, such as Teaching Dimension, extending them to handle noise and sequences of inputs encountered in an MDP.We provide theoretical bounds on the learnability of several important model classes in this setting and suggest a practical algorithm for dynamic teaching.", "text": "describe theoretical bounds practical algorithm teaching model demonstration sequential decision making environment. unlike previous eﬀorts optimized learners watch teacher demonstrate static policy focus teacher decision maker dynamically choose diﬀerent policies teach different parts environment. develop several teaching frameworks based previously deﬁned supervised protocols teaching dimension extending handle noise sequences inputs encountered mdp. provide theoretical bounds learnability several important model classes setting suggest practical algorithm dynamic teaching. situations agent teaches another community largely focused teachers demonstrate static policy learning agent however demonstration even optimal policy often best teach. instance consider learner trained play billiards observing nearoptimal player. since hallmark good play simplifying next shot optimal player likely demonstrate easy shots. really want teach learner shoot pool need show diﬃcult shots novel situations optimal policy rarely encounter. generally teachers improve learning eﬃciency showing highly informative examples static policy might often encounter. paper show cast problem optimal teaching decision problem right provide bounds teachability approach uses lessons supervisedlearning community established number frameworks quantifying teachability domain class. speciﬁcally extend classical teaching dimension framework recently described subset teaching dimension quantify teachability deterministic hypothesis classes. adapt frameworks type data encountered particularly handling noise sequential inputs. allows characterize teachability several concept classes bernoulli distributions k-armed bandits dbns supervised setting. supervised algorithms analyses form foundation teaching algorithms sequential decision making setting teachers constrained examples select dynamics environment current state. show cast problem optimal teaching decision problem right exact optimization often intractable. results supervised setting construct approximations optimal teaching strategy successful practice. result general algorithm teacher markov decision process that contrast work demonstrating static policies dynamically chooses highly informative examples teach model. apprenticeship learning however settings emphasis better learning algorithms interpret static teaching policy repeated many episodes. contrast providing algorithms teaching side teacher show trajectories built teach demonstrate. also learning eﬃciency static demonstrators measured either time needed achieve policy teacher perform well better teacher current work focus algorithms teach entire model given environment rather speciﬁc policy. note diﬀerent problem learner cannot rely policy bias towards teacher demonstrations. signiﬁcant work human teachers guiding agents including direct demonstration providing shaping rewards works focus either optimizing learner human inputs studying diﬀerent human interfaces reward signals impact learner. area future work studying similar optimal teaching policies human teachers results indicate behaviors diﬀerent domains teaching model less eﬃcient directly teaching optimal policy value function. instance bandit setting teaching model requires pulling number times teaching optimal policy directly might require pulling optimal once. situation similar behavioral cloning supervised learning techniques employed policy space though focus ﬁeld learning algorithms teaching. focus teaching model large structured domains number parameters model usually much smaller number parameters needed encode value function policy though techniques could extended teach policy space. section begin describing several teaching frameworks supervised-learning literature. describe modiﬁcations protocols accommodate teaching setting. speciﬁcally need account noise labels sequences instances rather sets. deal ﬁrst problem section describe several domain classes taught noisy describe frameworks used measure sample complexity teaching supervised setting teacher picking examples. frameworks diﬀer considerably much teacher learner infer another. first consider classical teaching dimension model teacher providing helpful examples learner learner unaware actually teacher. deﬁnition teaching dimension concept class instance space labels maxc∈c min|s| {c}) cons concepts consistent makes teaching intuitively represents minimum number examples needed uniquely identify because learner know taught teacher know learner providing samples teachers optimally speciﬁc learner. however natural extension protocol learner teacher understand interacting shared goal notions formalised ﬁrst balbach zeugmann devised protocol learner would make inferences hypotheses teacher clearly trying teach based size teaching set. reasoning teacher learner formalised subset teaching dimension learner teacher assume optimal. deﬁnition subset teaching dimension hypothesis class equal worst case number samples needed teach learner teacher learner know performing task optimally. done iteratively constructing subset teaching sets stsi starting stsi stsi− stsi subset stsi− intuitively captures ﬁxed point behavior learner teacher recursively assume optimally. think process reaching ﬁxed point iteratively starting teaching sets concepts original framework denoted ﬁrst step reasoning learner assumes taught using therefore assume instances come optimal teaching set. turn allows notice seen subsets instances must leading sts. next step reasoning goes back teacher infers teach using subsets sts. process repeats changes sts. uniqueness reachability ﬁxed point detailed zilles reasoning process complicated resulting behavior quite intuitive. instance original setting teaching singleton concept variables empty also possibility negative instances needed show empty hypothesis correct. however hypotheses taught using example section extend protocols setting concept learned noisy. begin deﬁning stochastic concept unordered collection deﬁnition stochastic concept maps possible instance distribution label space unordered example collection concept consists pairs inputs labels y...xn drawn next need address consistency learner longer expected predict exact label every instance. instead consider learners predict distribution labels given input. deﬁnition distribution consistent learner parameters makes predictions input based current unordered collection form predicted distribution label space consistency means d||t probability total variation labels distribution observed extend notion teaching deﬁnition three ways. first instead sets consider collections duplicates. second assume teacher control label associated given input label instance added teaching collection. therefore teacher choose instances time collection always knows current examples labeled. practical terms teacher able choose execute stop action declare collection ﬁnished notice learner aware order examples added. finally collection teaching collection distribution consistent learner must ˆd|| probability seeing sequence. components deﬁne noisy teaching dimension deﬁnition noisy teaching dimension parameters stochastic concept class maximum size minimum teaching collection concepts maxc minτ∈t s|τ| next consider case noisy subset teaching dimension extend std. here need redeﬁne notion subset used original account duplicates incremental construction teaching collection. introduce consistent subcollection relation deﬁnition collection consistent subcollection another collection every element mapped function element range probability distributions represented same. replacing original consistent subset requirement deﬁnition requirement iteration reasoning must produce consistent subcollection assuming learner distribution consistent gives full deﬁnition nstd. cases original collection improved upon worst case many cases teachers ability stop constructing collection cause signiﬁcant decrease expected teaching time nstd deﬁnitions assumes teacher’s construction ordering hidden learner later sequential setting reveals order allows stronger inference. conjunctions terms simple important model pre-conditions actions simple conditional outcomes. monotone conjunction input space boolean terms labeled relevant variables otherwise. setting complexity learning monotone conjunction types examples slightly diﬀerent teacher’s recourse provide samples. nstd learner aware taught suppose teacher presents collection size learner. inconsistent region label probability teacher correct consistent region stopping early. instantaneous region teacher would stopped construction treating consistent subcollection guarantee learner picks distribution within therefore case teacher stops construction consistent region still larger instantaneous region teacher’s current collection consistent subcollection possible collection learner pick hypothesis instantaneous region correct. prove expected time teaching distribution nstd framework signiﬁcantly smaller standard hoeﬀding bound determines number samples needed learn protocol. believe result interesting right describes useful fact expected time empirical average needs ﬁrst interval interest centered true expected value random variable. technique formulating evolution empirical average random walk reducing problem hitting desired interval problem computing mean ﬁrst passage time ﬁxed barrier. models introduced bernoulli standard example learning noisy concept. interest technical brevity actually prove result case noise model normal distribution. reason proof insightful continuous distribution known literature ﬁrst passage time properties continuous case approximate discrete version well. theorem given normal distribution unknown mean ability sample expected number samples teacher needs teach nstd protocol scales classical mistake-bound case requires positive examples. cannot assume anything learner defaults predictions. instead teacher present speciﬁc positive example negative examples relevant variable alone protocol bound actually becomes optimal strategy show positive example case learner infer negative examples. results provide intuition preconditions conditional eﬀects taught sequential setting topic return section fundamental noisy hypothesis classes model-based bernoulli distribution learned observation outcomes coin observing ﬂips). case teacher provide samples interpreted type consistent learner following strategy produces optimal teaching high probability. theorem setting proper teaching strategy collect samples bernoulli distribution stop. proof. strategy produces enough samples learners requires samples make predictions suppose learner existed made inaccurate predictions probability seeing samples empirical mean deﬁnition learner would inconsistent hoeﬀding’s inequality states surprising since also sample complexity autonomous coin learner however nstd teacher signiﬁcant impact. following theorems reasoning leads diﬀerent behavior sample complexity coin learning protocol. theorem general nstd teaching policy teaching probability weighted coin coin times teacher stop building collection whenever empirical mean coin’s bias within true probability. proving bound expected time takes ﬁrst interval equivalent showing bound expected time takes random walk dynamic interval process encodes time evolution upper bound dynamic interval. ﬁrst focus expected time takes random walk ﬁrst inside interval perspective upper bound. last equality follows symmetric stochastic process around since looking expected time ﬁrst becomes larger equivalent asking expected ﬁrst time hits origin ﬁrst starts negative side approximate discrete-time stochastic process continuous-time process goal getting qualitative result expected mean time. technique commonly used study ﬁrst passage-time properties discrete time random processes viewed perspective actually standard brownian motion positive drift well known mean ﬁrst passage time ﬁxed positive constant brownian motion positive drift governed inverse gaussian dis\u0001 parameters expected value distribution take expected ﬁrst time become larger since expected time ﬁrst origin started negative side naturally upper bounded expected time bound expected time needs ﬁrst ’catch random walk symmetrically show expected time become larger lower bound dynamic interval also natural extension coin-learning teaching complete model k-armed bandit case teaching expected payout arms diﬀerent noisy payout function. note teaching full model here optimal policy. treated bernoulli distribution needs learned within probability ensure total failure probability note change corresponds diﬀerent input parameter hence arms solution pull times giving bound nstd teacher pull arms ordering stop pulling either pulled times empirical average within true payout. expected savings factor speedup eﬀect actually multiplied across arms. figure illustrates bandit setting increasing algorithms described labeled ntd-ind nstd-ind growth ntd-ind actually quickly diverges approaches here showing increasingly better expected performance nstd-ind. applicable complexity teaching pulling arms parallel informative next section investigate here. goal still learn arm’s expected payout \u0001-accuracy teacher access action pulls arms reports individual payouts. case performs parallel pulls saving factor individual above. nstd parallel pulls introduce tension speedup parallelizing previously noted speedup able stop pulling empirical mean close true mean. arms close empirical mean others parallel pull disturb empirical means learned arms. figure shows nstd-par strategy forced either perform parallel pull stop empirical payouts within true payout pulled times. small sequential pulls actually eﬃcient larger number arms parallel pulls signiﬁcant beneﬁt despite danger unlearning arm. consider dynamic bayesian networks dbns multiple noisy factors learned parallel. case similar parallel bandit case total error aggregate subproblem errors nstd strategy dramatically diﬀerent. dynamic bayesian network composed discrete valued factors. every timestep next value factor determined probability distribution maps factor parent factors. assume consider binary case bounds generalize ordinal values extra terms including mapping back learning protocols input space possible conﬁgurations factors predictions made distribution factors next timestep. simple example consider case every variable parent variable. assume structure known deterministic learned relationship parent value child value. traditional mistake bound setting teacher control inputs worst case learning bound example ﬁrst could show parent pattern ﬁrst except single ﬂipped. connection mistake bound learnability teaching demonstration worstcase bound teaching type demonstration static policy. however dynamic teaching protocols much better. speciﬁcally case sample complexity teacher pick parent values. ﬁrst example teacher pick arbitrary setting factors show result. needs show complement string second stochastic setting consequences teaching factor probabilities parallel complicated deterministic case. unlike bandit case total error predicting next state probability based aggregate error subproblems. factor needs predicted accuracy. means teacher need worse nstd-par empirical demonstration teaching strategies shown figure representation noisy bitﬂip domain input simply string length actions shift however eﬀect shift noisy probability shift successful otherwise retains value currently has. figure shows number steps needed teach pi’s three teaching protocols described teaches setting inputs alternating string ending bit’s shift probability observed every step nstd-par uses alternating string every example stops building collection values within true value. nstd-ind sets state highest taught that. teaches probability shifting time deterministic outcomes bits. unlike bandit case nstd-ind dominates strategies even number bits increases. continually shrinking accuracy requirements increase chances parallel strategy unteaching factor. however nstdpar still outperforms situations background knowledge available teacher learner aware other preferred strategy. finally note bitﬂip also showcases beneﬁt teaching versus demonstration optimal policy. consider bitﬂip reward bits optimal policy otherwise shift. however strategy produces useful samples turned episode never even expected number useful samples episode probability samples drops exponentially. optimal performance policy almost always take steps teach domain teaching protocols described above. above established teachability several concept classes supervised setting. however interested teachers acting lessons transition function governs agent movement therefore teacher access possible states every timestep. extend previously deﬁned frameworks sequential setting forcing handle teaching sequences drawn mdp. describe teaching process planning problem right present demonstrate heuristic solution based supervised learning results. sequential domains teacher able access possible states every timestep instead take multiple steps reach target teaching state. hence adapt deﬁnitions consider sequences states actions rather randomly accessed inputs labels. formally need protocol handle following constrained teaching sequences. sequence deﬁnition sequence hhxari...hxt rtii xi+i reachable taking action starting witnessing sequence learned consistent learner must either distributionally consistent high probability deﬁnition above concept part transition reward function instead considering instances labels needs consider sequence states actions drawn based teacher’s potentially non-stationary policy denote distribution sequences formally deﬁne sequential teaching dimension deﬁnition sequential teaching dimension concept class taught accuracy parameters maximum minimum expected length teaching sequence individual concept class maxc minπ arbitrary potentially non-stationary policy deﬁnition general using constructively full stochastic case topic future work cases optimal dynamic teaching policy clear. instance transition function deterministic teacher simply needs shortest-length teaching sequence starting contains enough samples teach consistent learner. also heuristic solutions approximating optimal teaching deﬁned manner successfully teach deterministic stochastic setting. conversion zille’s protocol sequential setting even complicated learner makes inferences teacher showing certain instances every instance accessible every step. main intuition resolve diﬃculties case deterministic instead apply recursive reasoning teaching sequences deﬁned above. intuitively allow learner reason teacher trying teach concept teacher chooses path leads state consistent instead paths would teach diﬀerent concepts. saves teacher walking entire path. formalize using notion example subsequence preﬁx. deﬁnition example subsequence example sequence contiguous series inputs labels yi...xj...yji preﬁx subsequence suﬃx subsequence using deﬁnition replace previous deﬁnitions subsets collections nstd deﬁne subsequence teaching dimension natural mdps deterministic transition function concrete example powerful reasoning sequences sstd nsstd consider coin learning instead predicting probability assume learner needs predict whether coin biased towards heads tails without loss generality assume coin biased towards tails comes heads ﬁrst trial. nstd ordering examples hidden learner need keep ﬂipping coin observed tails heads. nsstd need teacher teaching matter outcome second coin biased heads teacher would made second ﬂip; would stopped ﬁrst heads observation. similar reasoning done predicting every choice indicates previous step’s instantaneous region above. however even deterministic setting problem determining exact optimal teaching sequence intractable. theorem determining optimal teaching sequence concept deterministic conditions deﬁnition np-hard. proof. encode graph traveling salesman problem integer edge costs deterministic unit costs adding number dummy states cities distance original graph. consider teaching reward function known every non-city state unknown value cities. shortest tour teaching reward function provides solution original tsp. line previous results intractability determining teaching sets supervised setting however tractable approximations algorithm certainly possible. perform approximations ﬁrst greedy approximation supervised teaching collection construction instances teach target concept greedily construct tour instances set. input concept taught start state learning protocol reachable teaching teaches parameters closest current state reachable fastest policy demonstrate demonstrated sstd setting ﬁrst approximation could problematic inference process based optimality assumptions shared learner teacher. teacher uses suboptimal teaching sequence learner make wrong inference. extending sstd nsstd practical setting approximations used teacher construct teaching touring policy need shared teacher learner allowing simulate other’s behavior. motivation behind sharing engender natural teacher-student interactions learner teacher share common assumptions finally consider noise transition function states actions part target concept taught. case would ideally like create tour instances shortest stochastic path length certainly hard deterministic touring case. however modify heuristic algorithm used simply state shortest stochastic path focus reaching state. allows heuristic teach concepts arbitrary mdps. demonstrate heuristic teaching algorithm conducted experiments object-oriented encoding taxi domain environment consists square grid controllable taxi actions down left right}. also several landmarks grid initially contains passenger another passenger’s destination. taxi’s goal passenger execute pickup action transport destination execute dropoﬀ. oomdp encoding domain every state predicates associated actions parameters stipulating objects scope taxi passenger landmark). predicates domain include indicators walls clearness every direction object well predicates indicating objects square passenger taxi. also action conjunction variablized predicates serves pre-condition action. focus teaching pre-conditions. perform experiments deterministic taxi domain starting modiﬁed td-style conjunction teacher constructor algorithm modiﬁcation conjunction learner section instead using speciﬁc positive example contains irrelevant predicates because state-space restrictions. teacher must show positive examples discredit irrelevant predicates addition negative examples indicate relevant variables. demonstrate beneﬁts used approximation behavior described section shows speciﬁc state shows positive examples irrelevant variables stops demonstrating table shows number steps needed fully teach pre-conditions several sets actions others known. agent cases starts middle grid landmarks bottom-left top-right corners. several interesting behaviors observed including teacher using landmarks corners areas gather many positive examples teacher also made lack type constraints variables create negative instances swapping order arguments indicate speciﬁc relations relevant. results compare favorably previous result teaching taxi conditions static-policy demonstration static policy approaches made look arbitrarily situation teach subtle aspects domain unless actually goal. contrast approach ignores current goal focuses best teacher best performer. also experimented sequential bitﬂip domain bits deterministic shift outcomes. experiments showed approximations using nstd signiﬁcantly outperforming using ntd. average steps teach version parallel versions eﬃcient despite ﬂipping every action. extended supervised learning frameworks handle noisy observations sequential data. frameworks provide eﬃcient ways teach several classes including dbns bernoulli distributions. also presented practical heuristic algorithm leveraging perform eﬃcient teaching demonstrated eﬀectiveness taxi domain. unlike previous eﬀorts teaching domains static policy algorithms actually target individual parameters domain task-independent manner leading agents truly teach rather show.", "year": 2012}