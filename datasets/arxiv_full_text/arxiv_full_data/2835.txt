{"title": "Combining Linear Non-Gaussian Acyclic Model with Logistic Regression  Model for Estimating Causal Structure from Mixed Continuous and Discrete Data", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Estimating causal models from observational data is a crucial task in data analysis. For continuous-valued data, Shimizu et al. have proposed a linear acyclic non-Gaussian model to understand the data generating process, and have shown that their model is identifiable when the number of data is sufficiently large. However, situations in which continuous and discrete variables coexist in the same problem are common in practice. Most existing causal discovery methods either ignore the discrete data and apply a continuous-valued algorithm or discretize all the continuous data and then apply a discrete Bayesian network approach. These methods possibly loss important information when we ignore discrete data or introduce the approximation error due to discretization. In this paper, we define a novel hybrid causal model which consists of both continuous and discrete variables. The model assumes: (1) the value of a continuous variable is a linear function of its parent variables plus a non-Gaussian noise, and (2) each discrete variable is a logistic variable whose distribution parameters depend on the values of its parent variables. In addition, we derive the BIC scoring function for model selection. The new discovery algorithm can learn causal structures from mixed continuous and discrete data without discretization. We empirically demonstrate the power of our method through thorough simulations.", "text": "dependencies identify causal directions different models entail identical conditional independencies. cope identiﬁability problem extend additive noise model discrete case demonstrate causal direction model identiﬁed general. however model imposes linear dependence assumptions data assumption often satisﬁed practice especially binary categorical data. multivariate count data proposed poisson model node corresponds poisson random variable rate parameters depending parent variables. again model applied count data instead categorical data. continuous-valued data traditional methods causal discovery based linear model gaussian noise however linear gaussian approach usually outputs possible models belong markov equivalence class true model. avoid limitation shimizu proposed linear non-gaussian acyclic model showed full causal structure identiﬁable given sufﬁciently large number data. relax assumption variables non-gaussian proposed pclingam algorithm combines independence based algorithm ica-based lingam algorithm algorithm ﬁrst algorithm obtain candidate models apply scoring directions scheme model selection. real data often contains mixture discrete continuous variables approaches described assumed data either discrete continuous. commonly employed approach mixed data ignore discrete variable apply linear causal network approach continuous data. causal analysis losses sight important information ignorance discrete data. another discretize continuous variables apply discrete bayesian network analysis causal relationships since many efﬁcient bayesian network learning algorithm proposed discrete data. choice discretization policy signiﬁcant impact resulting model discretization lead wrong estimating causal models observational data crucial task data analysis. continuousvalued data shimizu proposed linear acyclic non-gaussian model understand data generating process shown model identiﬁable number data sufﬁciently large. however situations continuous discrete variables coexist problem common practice. existing causal discovery methods either ignore discrete data apply continuous-valued algorithm discretize continuous data apply discrete bayesian network approach. methods possibly loss important information ignore discrete data introduce approximation error discretization. paper deﬁne novel hybrid causal model consists continuous discrete variables. model assumes value continuous variable linear function parent variables plus nongaussian noise discrete variable logistic variable whose distribution parameters depend values parent variables. addition derive scoring function model selection. discovery algorithm learn causal structures mixed continuous discrete data without discretization. empirically demonstrate power method thorough simulations. introduction estimating causal directed acyclic graph model observational data challenging problem applications many research areas including bioinformatics economics social science existing methods causal discovery commonly assume involved variables either discrete continuous valued. discrete case principled approaches constrained-based method relies results conditional independence tests. approach dose impose functional assumptions independence constraints imposed structure model characterized markov conditions constraints variable independent non-descendants given parents. structures markov equivalent conditional independence constraints imposed identical another dag. markov equivalence class dags encode conditional independencies. constraint based causal discovery algorithm requires faithfulness assumption conditional independencies data distribution exactly equal ones encoded causal structure. constraint based approach causal inference considers independence constraints methods markov equivalent class true causal structure. identify edge directions estimated causal structure propose combine lingam model logistic model causal discovery. therefore review concepts next subsections. lingam estimate causal structure continuous data shimizu proposed linear non-gaussian acyclic model special case structural equation models continuous-valued bayesian networks. lingam model assumes observed data generated process represented graphically directed acyclic graph moreover assumes relations variables linear. denote connection strength variable another variable model represented model much information lost discretization process. recently chen proposed discretization strategy mitigate problem. nevertheless traditional methods learn markov equivalence class therefore causal directions edges determined. contribution propose novel hybrid causal model consists continuous discrete variables. model based lingam model logistic regression model. model assume important features model model handle continuous discrete variables simultaneously without using discretization. addition derive scoring function evaluating possible model also propose score causal discovery. constraintbased discovery algorithms e.g. algorithm markov equivalent class models. contrast method leverage identiﬁability lingam model expected able identify full causal structure observational data. finally empirically demonstrate power method thorough simulations. remainder paper structured follows section summaries necessary notation reviews lingam model logistic model. section deﬁnes hybrid causal model derives scoring function model selection. section empirically evaluates methods. section concludes paper. background section ﬁrst introduce necessary notation deﬁnitions directed acyclic graph models. brieﬂy review building blocks model linear non-gaussian acyclic model logistic conditional probability distribution. models consider random variables index following convention previous studies causal graph variables node represents random variables edge represents direct dependency relationships variables. directed edge node node denoted node called parent parent node consists nodes discovery algorithms causal discovery consists ﬁnding causal model best sample data according certain criterion. since causal model consists causal graph structure associated parameters discovery algorithms often need deal highly related tasks search causal graph estimation parameters. order estimate parameters must know causal structure; order evaluate candidate causal structure must estimate parameters data causal graph. paper mainly interested algorithms learning causal structure view parameter estimation part subroutine search algorithm. constraint-based algorithms typically apply statistical tests identify conditional independence relations attempt causal graph represents relations precise possible. since accuracy statistical test sensitive number data complexity independence tests constraint-based algorithms work well insufﬁcient data. another issue constraint-based algorithm independence test based approach distinguish dags markov equivalence class. since markov equivalence classes contain graph conditional independence based methods leave arrows undirected cannot uniquely identify true causal graph. recently hoyer constraint-based methods infer markov equivalence class true causal model score belonging equivalence class. scoring hybrid causal model order evaluate hybrid causal model derive bayesian information criterion scoring function model. basic idea select causal structure maximizes log-likelihood called noise variable. noise variables continuous random variables non-gaussian distributions zero means non-zero variances independent latent confounding variables figure concrete example lingam model data generated ﬁrst drawing independently respective nongaussian distributions subsequently setting remarkable result shown shimizu non-gaussian assumption noise distribution full causal structure associated parameters identiﬁable. contrast constraint-based algorithms estimate markov equivalence class thus directions edges estimated logistic conditional probability distribution section describe logistic regression model local causal structure. consider discrete variable whose distribution depends causes study restrict analysis binary variables takes values assume conditional probability distribution given dependent variables logistic deﬁned follows. binary-valued random variable deﬁned domain parents take numerical values. conditional probability distribution logistic weights that logistic natural model many real-world applications naturally aggregates inﬂuence different parents. koller friedman also provide variant binary logistic handle multivalued variables however implemented feature software yet. hybrid causal model section propose novel hybrid causal model i.e. model consisting continuous discrete variables. discuss commonly used approaches causal discovery. finally derive scoring function evaluate ﬁtness model data. deﬁnition model partition variables model types continuous variables discrete variables. paper assume discrete variable take values penalized number parameters necessary specify causal model. denote model pair denotes causal graph represents parameter graph structure score structure deﬁned logl logarithm likelihood function maximum likelihood estimated parameters stands number data points signiﬁes number free parameters model. since model conditional probability distribution number parent variables plus constant parameter total number parameters number edges plus number variables. next discuss methods obtain parameters. logistic variables easy estimate dependence coefﬁcients maximum likelihood principle however continuous variables assume gaussian noise obtain exact parameters estimate noise distribution ﬁrst. would complicated easy implementation. simplicity estimation obtain coefﬁcients estimated using ordinary least-square regression. note provide consistent estimates. number data sufﬁciently large approximation error becomes zero. discrete bayesian network well known scoring function assigns score structures equivalence class. however assumptions described subsection using scoring function expected able unique true causal structure well associated parameters. experiments section evaluated proposed algorithm respect accuracy rate discovering causal structure extensive experiments. also showed algorithm better performance compared state algorithm. simulations simulation study conducted random models continuous discrete variables. random graph generated adding edge probability pair possible nodes constraints newly added edge introduce directed cycle. data generating process continuous variable j∈pa bijxj; discrete variable sampled probability distrij∈pa bijxj). using scoring function equation searched structure maximum score among possible structures. search algorithm implemented python compared algorithm algorithm implemented latest versions pgmpy library. since discrete algorithm directly applied mixed continuous discrete data discretized continuous data using mean value since algorithm recover directions measure often algorithm correctly infer skeleton true undirected graph resulting removing arrowheads dag. figure provides comparison proposed algorithm algorithm terms skeleton accuracy. first observed proposed method learns correct causal structure number data increases. results empirically show method asymptotic consistency. contrast discrete algorithm able estimate correct causal structure even large numbers samples. second number continuous variables increases performance algorithm decreases. reason considered information might lost discretization. number continuous variables discretized information loses. another experiment assume skeleton model obtained oracle procedure. score consistent skeleton. figure reported accuracy rate hybrid-oracle approach previous generated models. comparison also reported performance analysis full search approach. observation know undirected structure hybrid-oracle learn full causal structure accuracy even data samples. insight quite important practical case. many analysis might know pair variables correlate know causal direction. score search approach efﬁciency know undirected structure. hand start undirected structure instead scratch necessary number data samples decreases huge advantage practice. aapo hyv¨arinen zhang shohei shimizu patrik hoyer. estimation structural vector autoregression model using nonjournal machine learning research gaussianity. gunwoong park garvesh raskutti. learning large-scale poisson models based overdispersion scoring. nips pages judea pearl. causality models reasoning peters janzing scholkopf. causal inference discrete data using additive noise models. ieee transactions pattern analysis machine intelligence gideon schwarz. estimating dimension model. annals statistics shohei shimizu patrik hoyer aapo hyv¨arinen antti kerminen. linear nongaussian acyclic model causal discovery. journal machine learning research summary causal discovery mixture continuous discrete data important research problem practical value. existing causal discovery methods either ignore discrete data discretize continuous data. paper proposed hybrid causal model derived scoring function evaluating model.", "year": 2018}